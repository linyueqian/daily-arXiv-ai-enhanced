{"id": "2506.01961", "pdf": "https://arxiv.org/pdf/2506.01961", "abs": "https://arxiv.org/abs/2506.01961", "authors": ["Jinzhu Yang"], "title": "Research on Medical Named Entity Identification Based On Prompt-Biomrc Model and Its Application in Intelligent Consultation System", "categories": ["cs.CL"], "comment": null, "summary": "This study is dedicated to exploring the application of prompt learning\nmethods to advance Named Entity Recognition (NER) within the medical domain. In\nrecent years, the emergence of large-scale models has driven significant\nprogress in NER tasks, particularly with the introduction of the BioBERT\nlanguage model, which has greatly enhanced NER capabilities in medical texts.\nOur research introduces the Prompt-bioMRC model, which integrates both hard\ntemplate and soft prompt designs aimed at refining the precision and efficiency\nof medical entity recognition. Through extensive experimentation across diverse\nmedical datasets, our findings consistently demonstrate that our approach\nsurpasses traditional models. This enhancement not only validates the efficacy\nof our methodology but also highlights its potential to provide reliable\ntechnological support for applications like intelligent diagnosis systems. By\nleveraging advanced NER techniques, this study contributes to advancing\nautomated medical data processing, facilitating more accurate medical\ninformation extraction, and supporting efficient healthcare decision-making\nprocesses.", "AI": {"tldr": "The study introduces Prompt-bioMRC, a model combining hard and soft prompts, to improve medical NER, outperforming traditional methods and supporting applications like intelligent diagnosis.", "motivation": "To enhance Named Entity Recognition (NER) in the medical domain using prompt learning methods, leveraging advancements like BioBERT for better medical text processing.", "method": "Developed the Prompt-bioMRC model, integrating hard template and soft prompt designs to refine medical entity recognition precision and efficiency.", "result": "Experiments on diverse medical datasets show the model outperforms traditional NER methods, validating its efficacy.", "conclusion": "The study advances automated medical data processing, enabling accurate information extraction and supporting healthcare decision-making."}}
{"id": "2506.01992", "pdf": "https://arxiv.org/pdf/2506.01992", "abs": "https://arxiv.org/abs/2506.01992", "authors": ["Lukas Rauch", "Moritz Wirth", "Denis Huseljic", "Marek Herde", "Bernhard Sick", "Matthias A\u00dfenmacher"], "title": "No Free Lunch in Active Learning: LLM Embedding Quality Dictates Query Strategy Success", "categories": ["cs.CL", "cs.AI", "cs.IR"], "comment": "under review @NeurIPS2025", "summary": "The advent of large language models (LLMs) capable of producing\ngeneral-purpose representations lets us revisit the practicality of deep active\nlearning (AL): By leveraging frozen LLM embeddings, we can mitigate the\ncomputational costs of iteratively fine-tuning large backbones. This study\nestablishes a benchmark and systematically investigates the influence of LLM\nembedding quality on query strategies in deep AL. We employ five top-performing\nmodels from the massive text embedding benchmark (MTEB) leaderboard and two\nbaselines for ten diverse text classification tasks. Our findings reveal key\ninsights: First, initializing the labeled pool using diversity-based sampling\nsynergizes with high-quality embeddings, boosting performance in early AL\niterations. Second, the choice of the optimal query strategy is sensitive to\nembedding quality. While the computationally inexpensive Margin sampling can\nachieve performance spikes on specific datasets, we find that strategies like\nBadge exhibit greater robustness across tasks. Importantly, their effectiveness\nis often enhanced when paired with higher-quality embeddings. Our results\nemphasize the need for context-specific evaluation of AL strategies, as\nperformance heavily depends on embedding quality and the target task.", "AI": {"tldr": "The study benchmarks the impact of LLM embedding quality on deep active learning (AL) strategies, showing that diversity-based sampling and high-quality embeddings improve early AL performance, while optimal query strategies depend on embedding quality and task context.", "motivation": "To explore the practicality of deep AL by leveraging frozen LLM embeddings to reduce computational costs and systematically evaluate how embedding quality affects AL query strategies.", "method": "Benchmarked five top-performing LLM models from MTEB and two baselines across ten text classification tasks, analyzing the synergy between embedding quality and query strategies like Margin sampling and Badge.", "result": "Diversity-based sampling with high-quality embeddings boosts early AL performance. Optimal query strategies vary with embedding quality, with Badge showing robustness and Margin sampling achieving task-specific spikes.", "conclusion": "AL strategy effectiveness is context-dependent, heavily influenced by embedding quality and task specifics, necessitating tailored evaluations."}}
{"id": "2506.02000", "pdf": "https://arxiv.org/pdf/2506.02000", "abs": "https://arxiv.org/abs/2506.02000", "authors": ["Abhay Gupta", "Michael Lu", "Kevin Zhu", "Sean O'Brien", "Vasu Sharma"], "title": "NovelHopQA: Diagnosing Multi-Hop Reasoning Failures in Long Narrative Contexts", "categories": ["cs.CL"], "comment": null, "summary": "Current large language models (LLMs) struggle to answer questions that span\ntens of thousands of tokens, especially when multi-hop reasoning is involved.\nWhile prior benchmarks explore long-context comprehension or multi-hop\nreasoning in isolation, none jointly vary context length and reasoning depth in\nnatural narrative settings. We introduce NovelHopQA, the first benchmark to\nevaluate k1-4 hop QA over 64k-128k-token excerpts from 83 full-length\npublic-domain novels. A keyword-guided pipeline builds hop-separated chains\ngrounded in coherent storylines. We evaluate six state-of-the-art (SOTA) models\nand apply oracle-context filtering to ensure all questions are genuinely\nanswerable. Human annotators validate both alignment and hop depth. We noticed\nconsistent accuracy drops with increased hops and context length, even in\nfrontier models-revealing that sheer scale does not guarantee robust reasoning.\nOur failure mode analysis highlights common breakdowns, such as missed\nfinal-hop integration and long-range drift. NovelHopQA offers a controlled\ndiagnostic setting to stress-test multi-hop reasoning at scale.", "AI": {"tldr": "NovelHopQA is a new benchmark for evaluating multi-hop QA over long-context narratives, revealing limitations in current LLMs despite their scale.", "motivation": "Current LLMs struggle with long-context multi-hop reasoning, and existing benchmarks don't jointly test these challenges in natural settings.", "method": "A keyword-guided pipeline creates hop-separated QA chains from 64k-128k-token novel excerpts, evaluated on six SOTA models with human validation.", "result": "Accuracy drops with increased hops and context length, showing scale alone doesn't ensure robust reasoning. Common failures include missed final-hop integration and long-range drift.", "conclusion": "NovelHopQA provides a diagnostic tool to stress-test multi-hop reasoning at scale, highlighting LLM limitations."}}
{"id": "2506.02005", "pdf": "https://arxiv.org/pdf/2506.02005", "abs": "https://arxiv.org/abs/2506.02005", "authors": ["Timothy Do", "Pranav Saran", "Harshita Poojary", "Pranav Prabhu", "Sean O'Brien", "Vasu Sharma", "Kevin Zhu"], "title": "Pruning for Performance: Efficient Idiom and Metaphor Classification in Low-Resource Konkani Using mBERT", "categories": ["cs.CL"], "comment": "9 pages, 7 figures", "summary": "In this paper, we address the persistent challenges that figurative language\nexpressions pose for natural language processing (NLP) systems, particularly in\nlow-resource languages such as Konkani. We present a hybrid model that\nintegrates a pre-trained Multilingual BERT (mBERT) with a bidirectional LSTM\nand a linear classifier. This architecture is fine-tuned on a newly introduced\nannotated dataset for metaphor classification, developed as part of this work.\nTo improve the model's efficiency, we implement a gradient-based attention head\npruning strategy. For metaphor classification, the pruned model achieves an\naccuracy of 78%. We also applied our pruning approach to expand on an existing\nidiom classification task, achieving 83% accuracy. These results demonstrate\nthe effectiveness of attention head pruning for building efficient NLP tools in\nunderrepresented languages.", "AI": {"tldr": "A hybrid model combining mBERT, bidirectional LSTM, and a linear classifier addresses figurative language challenges in low-resource languages like Konkani, achieving 78% accuracy in metaphor classification and 83% in idiom classification using attention head pruning.", "motivation": "To tackle the difficulties figurative language poses for NLP systems, especially in low-resource languages such as Konkani.", "method": "A hybrid model integrating mBERT, bidirectional LSTM, and a linear classifier, fine-tuned on a new annotated dataset for metaphor classification, with gradient-based attention head pruning.", "result": "78% accuracy in metaphor classification and 83% in idiom classification.", "conclusion": "Attention head pruning is effective for building efficient NLP tools in underrepresented languages."}}
{"id": "2506.02380", "pdf": "https://arxiv.org/pdf/2506.02380", "abs": "https://arxiv.org/abs/2506.02380", "authors": ["Zihao Ding", "Cheng-Tse Lee", "Mufeng Zhu", "Tao Guan", "Yuan-Chun Sun", "Cheng-Hsin Hsu", "Yao Liu"], "title": "EyeNavGS: A 6-DoF Navigation Dataset and Record-n-Replay Software for Real-World 3DGS Scenes in VR", "categories": ["cs.MM", "cs.CV", "cs.GR", "cs.HC"], "comment": null, "summary": "3D Gaussian Splatting (3DGS) is an emerging media representation that\nreconstructs real-world 3D scenes in high fidelity, enabling\n6-degrees-of-freedom (6-DoF) navigation in virtual reality (VR). However,\ndeveloping and evaluating 3DGS-enabled applications and optimizing their\nrendering performance, require realistic user navigation data. Such data is\ncurrently unavailable for photorealistic 3DGS reconstructions of real-world\nscenes. This paper introduces EyeNavGS (EyeNavGS), the first publicly available\n6-DoF navigation dataset featuring traces from 46 participants exploring twelve\ndiverse, real-world 3DGS scenes. The dataset was collected at two sites, using\nthe Meta Quest Pro headsets, recording the head pose and eye gaze data for each\nrendered frame during free world standing 6-DoF navigation. For each of the\ntwelve scenes, we performed careful scene initialization to correct for scene\ntilt and scale, ensuring a perceptually-comfortable VR experience. We also\nrelease our open-source SIBR viewer software fork with record-and-replay\nfunctionalities and a suite of utility tools for data processing, conversion,\nand visualization. The EyeNavGS dataset and its accompanying software tools\nprovide valuable resources for advancing research in 6-DoF viewport prediction,\nadaptive streaming, 3D saliency, and foveated rendering for 3DGS scenes. The\nEyeNavGS dataset is available at: https://symmru.github.io/EyeNavGS/.", "AI": {"tldr": "EyeNavGS is the first public 6-DoF navigation dataset for 3D Gaussian Splatting (3DGS) scenes, featuring traces from 46 participants exploring 12 real-world scenes, collected using Meta Quest Pro headsets.", "motivation": "The lack of realistic user navigation data for 3DGS scenes hinders development and evaluation of applications. EyeNavGS addresses this gap.", "method": "Data was collected from 46 participants exploring 12 diverse 3DGS scenes using Meta Quest Pro headsets, recording head pose and eye gaze. Scene initialization ensured perceptual comfort.", "result": "The dataset includes navigation traces, open-source tools for data processing, and a viewer with record-and-replay functionalities.", "conclusion": "EyeNavGS provides essential resources for research in 6-DoF viewport prediction, adaptive streaming, 3D saliency, and foveated rendering for 3DGS."}}
{"id": "2506.02039", "pdf": "https://arxiv.org/pdf/2506.02039", "abs": "https://arxiv.org/abs/2506.02039", "authors": ["Haoshuai Zhou", "Changgeng Mo", "Boxuan Cao", "Linkai Li", "Shan Xiang Wang"], "title": "No Audiogram: Leveraging Existing Scores for Personalized Speech Intelligibility Prediction", "categories": ["eess.AS", "cs.AI", "cs.SD"], "comment": "Accepted at Interspeech 2025", "summary": "Personalized speech intelligibility prediction is challenging. Previous\napproaches have mainly relied on audiograms, which are inherently limited in\naccuracy as they only capture a listener's hearing threshold for pure tones.\nRather than incorporating additional listener features, we propose a novel\napproach that leverages an individual's existing intelligibility data to\npredict their performance on new audio. We introduce the Support Sample-Based\nIntelligibility Prediction Network (SSIPNet), a deep learning model that\nleverages speech foundation models to build a high-dimensional representation\nof a listener's speech recognition ability from multiple support (audio, score)\npairs, enabling accurate predictions for unseen audio. Results on the Clarity\nPrediction Challenge dataset show that, even with a small number of support\n(audio, score) pairs, our method outperforms audiogram-based predictions. Our\nwork presents a new paradigm for personalized speech intelligibility\nprediction.", "AI": {"tldr": "A novel deep learning model (SSIPNet) uses existing intelligibility data to predict speech performance, outperforming traditional audiogram-based methods.", "motivation": "Audiograms are limited in accuracy for speech intelligibility prediction, prompting the need for a more personalized approach.", "method": "SSIPNet leverages speech foundation models and support (audio, score) pairs to predict intelligibility for unseen audio.", "result": "Outperforms audiogram-based predictions on the Clarity Prediction Challenge dataset, even with few support pairs.", "conclusion": "Introduces a new paradigm for personalized speech intelligibility prediction using deep learning."}}
{"id": "2506.02059", "pdf": "https://arxiv.org/pdf/2506.02059", "abs": "https://arxiv.org/abs/2506.02059", "authors": ["Ziwei Gong", "Pengyuan Shi", "Kaan Donbekci", "Lin Ai", "Run Chen", "David Sasu", "Zehui Wu", "Julia Hirschberg"], "title": "Learning More with Less: Self-Supervised Approaches for Low-Resource Speech Emotion Recognition", "categories": ["cs.SD", "cs.CL"], "comment": "Accepted at Interspeech 2025", "summary": "Speech Emotion Recognition (SER) has seen significant progress with deep\nlearning, yet remains challenging for Low-Resource Languages (LRLs) due to the\nscarcity of annotated data. In this work, we explore unsupervised learning to\nimprove SER in low-resource settings. Specifically, we investigate contrastive\nlearning (CL) and Bootstrap Your Own Latent (BYOL) as self-supervised\napproaches to enhance cross-lingual generalization. Our methods achieve notable\nF1 score improvements of 10.6% in Urdu, 15.2% in German, and 13.9% in Bangla,\ndemonstrating their effectiveness in LRLs. Additionally, we analyze model\nbehavior to provide insights on key factors influencing performance across\nlanguages, and also highlighting challenges in low-resource SER. This work\nprovides a foundation for developing more inclusive, explainable, and robust\nemotion recognition systems for underrepresented languages.", "AI": {"tldr": "The paper explores unsupervised learning, specifically contrastive learning and BYOL, to improve Speech Emotion Recognition (SER) in Low-Resource Languages (LRLs), achieving significant F1 score improvements.", "motivation": "The scarcity of annotated data for Low-Resource Languages (LRLs) makes Speech Emotion Recognition (SER) challenging, motivating the use of unsupervised learning to enhance cross-lingual generalization.", "method": "The study investigates contrastive learning (CL) and Bootstrap Your Own Latent (BYOL) as self-supervised approaches for SER in LRLs.", "result": "The methods achieved F1 score improvements of 10.6% in Urdu, 15.2% in German, and 13.9% in Bangla, demonstrating effectiveness in LRLs.", "conclusion": "The work lays a foundation for more inclusive, explainable, and robust emotion recognition systems for underrepresented languages, while highlighting challenges in low-resource SER."}}
{"id": "2506.02931", "pdf": "https://arxiv.org/pdf/2506.02931", "abs": "https://arxiv.org/abs/2506.02931", "authors": ["Praneet Sai Madhu Surabhi", "Dheeraj Reddy Mudireddy", "Jian Tao"], "title": "ThinkTank: A Framework for Generalizing Domain-Specific AI Agent Systems into Universal Collaborative Intelligence Platforms", "categories": ["cs.MA", "cs.AI", "cs.LG"], "comment": null, "summary": "This paper presents ThinkTank, a comprehensive and scalable framework\ndesigned to transform specialized AI agent systems into versatile collaborative\nintelligence platforms capable of supporting complex problem-solving across\ndiverse domains. ThinkTank systematically generalizes agent roles, meeting\nstructures, and knowledge integration mechanisms by adapting proven scientific\ncollaboration methodologies. Through role abstraction, generalization of\nmeeting types for iterative collaboration, and the integration of\nRetrieval-Augmented Generation with advanced knowledge storage, the framework\nfacilitates expertise creation and robust knowledge sharing. ThinkTank enables\norganizations to leverage collaborative AI for knowledge-intensive tasks while\nensuring data privacy and security through local deployment, utilizing\nframeworks like Ollama with models such as Llama3.1. The ThinkTank framework is\ndesigned to deliver significant advantages in cost-effectiveness, data\nsecurity, scalability, and competitive positioning compared to cloud-based\nalternatives, establishing it as a universal platform for AI-driven\ncollaborative problem-solving. The ThinkTank code is available at\nhttps://github.com/taugroup/ThinkTank", "AI": {"tldr": "ThinkTank is a scalable framework transforming specialized AI agents into collaborative platforms for complex problem-solving, leveraging role abstraction, meeting generalization, and knowledge integration.", "motivation": "To create a versatile AI collaboration platform that adapts scientific methodologies for diverse domains, ensuring privacy and scalability.", "method": "Uses role abstraction, generalized meeting structures, and Retrieval-Augmented Generation with advanced knowledge storage for expertise creation.", "result": "Enables cost-effective, secure, and scalable AI collaboration, outperforming cloud-based alternatives.", "conclusion": "ThinkTank is a universal platform for AI-driven collaborative problem-solving, with open-source availability."}}
{"id": "2506.01980", "pdf": "https://arxiv.org/pdf/2506.01980", "abs": "https://arxiv.org/abs/2506.01980", "authors": ["Lianhao Yin", "Ozanan Meireles", "Guy Rosman", "Daniela Rus"], "title": "Surgical Foundation Model Leveraging Compression and Entropy Maximization for Image-Guided Surgical Assistance", "categories": ["eess.IV", "cs.AI", "cs.CV"], "comment": null, "summary": "Real-time video understanding is critical to guide procedures in minimally\ninvasive surgery (MIS). However, supervised learning approaches require large,\nannotated datasets that are scarce due to annotation efforts that are\nprohibitive, e.g., in medical fields. Although self-supervision methods can\naddress such limitations, current self-supervised methods often fail to capture\nstructural and physical information in a form that generalizes across tasks. We\npropose Compress-to-Explore (C2E), a novel self-supervised framework that\nleverages Kolmogorov complexity to learn compact, informative representations\nfrom surgical videos. C2E uses entropy-maximizing decoders to compress images\nwhile preserving clinically relevant details, improving encoder performance\nwithout labeled data. Trained on large-scale unlabeled surgical datasets, C2E\ndemonstrates strong generalization across a variety of surgical ML tasks, such\nas workflow classification, tool-tissue interaction classification,\nsegmentation, and diagnosis tasks, providing improved performance as a surgical\nvisual foundation model. As we further show in the paper, the model's internal\ncompact representation better disentangles features from different structural\nparts of images. The resulting performance improvements highlight the yet\nuntapped potential of self-supervised learning to enhance surgical AI and\nimprove outcomes in MIS.", "AI": {"tldr": "C2E is a self-supervised framework using Kolmogorov complexity to learn compact representations from surgical videos, improving performance without labeled data.", "motivation": "Supervised learning in MIS requires large annotated datasets, which are scarce due to high annotation efforts. Current self-supervised methods often fail to generalize across tasks.", "method": "C2E leverages entropy-maximizing decoders to compress images while preserving clinical details, learning informative representations from unlabeled surgical videos.", "result": "C2E generalizes well across surgical ML tasks like workflow classification, segmentation, and diagnosis, outperforming other methods.", "conclusion": "C2E demonstrates the potential of self-supervised learning to enhance surgical AI, improving outcomes in minimally invasive surgery."}}
{"id": "2506.02010", "pdf": "https://arxiv.org/pdf/2506.02010", "abs": "https://arxiv.org/abs/2506.02010", "authors": ["Zehua Liu", "Xiaolou Li", "Chen Chen", "Lantian Li", "Dong Wang"], "title": "CNVSRC 2024: The Second Chinese Continuous Visual Speech Recognition Challenge", "categories": ["cs.CV", "cs.SD", "eess.AS"], "comment": "to be published in INTERSPEECH 2025", "summary": "This paper presents the second Chinese Continuous Visual Speech Recognition\nChallenge (CNVSRC 2024), which builds on CNVSRC 2023 to advance research in\nChinese Large Vocabulary Continuous Visual Speech Recognition (LVC-VSR). The\nchallenge evaluates two test scenarios: reading in recording studios and\nInternet speech. CNVSRC 2024 uses the same datasets as its predecessor CNVSRC\n2023, which involves CN-CVS for training and CNVSRC-Single/Multi for\ndevelopment and evaluation. However, CNVSRC 2024 introduced two key\nimprovements: (1) a stronger baseline system, and (2) an additional dataset,\nCN-CVS2-P1, for open tracks to improve data volume and diversity. The new\nchallenge has demonstrated several important innovations in data preprocessing,\nfeature extraction, model design, and training strategies, further pushing the\nstate-of-the-art in Chinese LVC-VSR. More details and resources are available\nat the official website.", "AI": {"tldr": "CNVSRC 2024 advances Chinese LVC-VSR research with improved baselines and an additional dataset, focusing on reading and Internet speech scenarios.", "motivation": "To push the state-of-the-art in Chinese Large Vocabulary Continuous Visual Speech Recognition (LVC-VSR) by addressing limitations and enhancing data diversity.", "method": "Utilizes CN-CVS for training and CNVSRC-Single/Multi for evaluation, introducing a stronger baseline system and the CN-CVS2-P1 dataset for open tracks.", "result": "Demonstrated innovations in data preprocessing, feature extraction, model design, and training strategies.", "conclusion": "CNVSRC 2024 successfully advances Chinese LVC-VSR research with improved methodologies and datasets."}}
{"id": "2506.01959", "pdf": "https://arxiv.org/pdf/2506.01959", "abs": "https://arxiv.org/abs/2506.01959", "authors": ["Irmi Schneider"], "title": "Ubiquitous Symmetry at Critical Points Across Diverse Optimization Landscapes", "categories": ["cs.LG", "cs.AI", "physics.atom-ph"], "comment": null, "summary": "Symmetry plays a crucial role in understanding the properties of mathematical\nstructures and optimization problems. Recent work has explored this phenomenon\nin the context of neural networks, where the loss function is invariant under\ncolumn and row permutations of the network weights. It has been observed that\nlocal minima exhibit significant symmetry with respect to the network weights\n(invariance to row and column permutations). And moreover no critical point was\nfound that lacked symmetry. We extend this line of inquiry by investigating\nsymmetry phenomena in real-valued loss functions defined on a broader class of\nspaces. We will introduce four more cases: the projective case over a finite\nfield, the octahedral graph case, the perfect matching case, and the particle\nattraction case. We show that as in the neural network case, all the critical\npoints observed have non-trivial symmetry. Finally we introduce a new measure\nof symmetry in the system and show that it reveals additional symmetry\nstructures not captured by the previous measure.", "AI": {"tldr": "The paper explores symmetry in loss functions beyond neural networks, analyzing four new cases and introducing a new symmetry measure.", "motivation": "To understand symmetry's role in optimization problems and extend findings from neural networks to broader contexts.", "method": "Investigates symmetry in real-valued loss functions across four cases: projective over finite fields, octahedral graphs, perfect matching, and particle attraction. Introduces a new symmetry measure.", "result": "All observed critical points exhibit non-trivial symmetry, similar to neural networks. The new measure reveals additional symmetry structures.", "conclusion": "Symmetry is pervasive in optimization problems, and the new measure enhances understanding of symmetry structures."}}
{"id": "2506.02097", "pdf": "https://arxiv.org/pdf/2506.02097", "abs": "https://arxiv.org/abs/2506.02097", "authors": ["Priyaranjan Pattnayak", "Amit Agarwal", "Hansa Meghwani", "Hitesh Laxmichand Patel", "Srikant Panda"], "title": "Hybrid AI for Responsive Multi-Turn Online Conversations with Novel Dynamic Routing and Feedback Adaptation", "categories": ["cs.AI"], "comment": "Proceedings of the 4th International Workshop on Knowledge Augmented\n  Methods for Natural Language Processing in NAACL 2025, pages 215 to 229,\n  Albuquerque, New Mexico, USA. Association for Computational Linguistics", "summary": "Retrieval-Augmented Generation (RAG) systems and large language model\n(LLM)-powered chatbots have significantly advanced conversational AI by\ncombining generative capabilities with external knowledge retrieval. Despite\ntheir success, enterprise-scale deployments face critical challenges, including\ndiverse user queries, high latency, hallucinations, and difficulty integrating\nfrequently updated domain-specific knowledge. This paper introduces a novel\nhybrid framework that integrates RAG with intent-based canned responses,\nleveraging predefined high-confidence responses for efficiency while\ndynamically routing complex or ambiguous queries to the RAG pipeline. Our\nframework employs a dialogue context manager to ensure coherence in multi-turn\ninteractions and incorporates a feedback loop to refine intents, dynamically\nadjust confidence thresholds, and expand response coverage over time.\nExperimental results demonstrate that the proposed framework achieves a balance\nof high accuracy (95\\%) and low latency (180ms), outperforming RAG and\nintent-based systems across diverse query types, positioning it as a scalable\nand adaptive solution for enterprise conversational AI applications.", "AI": {"tldr": "A hybrid framework combining RAG with intent-based canned responses improves enterprise conversational AI by balancing accuracy (95%) and latency (180ms).", "motivation": "Enterprise-scale deployments of RAG and LLM-powered chatbots face challenges like diverse queries, high latency, hallucinations, and integrating updated knowledge.", "method": "The framework integrates RAG with intent-based responses, using predefined answers for efficiency and routing complex queries to RAG. It includes a dialogue context manager and feedback loop.", "result": "The framework achieves 95% accuracy and 180ms latency, outperforming standalone RAG and intent-based systems.", "conclusion": "The hybrid framework is scalable and adaptive, suitable for enterprise conversational AI."}}
{"id": "2506.02018", "pdf": "https://arxiv.org/pdf/2506.02018", "abs": "https://arxiv.org/abs/2506.02018", "authors": ["Christopher Lee L\u00fcbbers"], "title": "Enhancing Paraphrase Type Generation: The Impact of DPO and RLHF Evaluated with Human-Ranked Data", "categories": ["cs.CL", "I.2.7"], "comment": "21 pages, 11 figures. Master's thesis, University of Goettingen,\n  December 2025. Code: https://github.com/cluebbers/dpo-rlhf-paraphrase-types.\n  Models:\n  https://huggingface.co/collections/cluebbers/enhancing-paraphrase-type-generation-673ca8d75dfe2ce962a48ac0", "summary": "Paraphrasing re-expresses meaning to enhance applications like text\nsimplification, machine translation, and question-answering. Specific\nparaphrase types facilitate accurate semantic analysis and robust language\nmodels. However, existing paraphrase-type generation methods often misalign\nwith human preferences due to reliance on automated metrics and limited\nhuman-annotated training data, obscuring crucial aspects of semantic fidelity\nand linguistic transformations.\n  This study addresses this gap by leveraging a human-ranked paraphrase-type\ndataset and integrating Direct Preference Optimization (DPO) to align model\noutputs directly with human judgments. DPO-based training increases\nparaphrase-type generation accuracy by 3 percentage points over a supervised\nbaseline and raises human preference ratings by 7 percentage points. A newly\ncreated human-annotated dataset supports more rigorous future evaluations.\nAdditionally, a paraphrase-type detection model achieves F1 scores of 0.91 for\naddition/deletion, 0.78 for same polarity substitution, and 0.70 for\npunctuation changes.\n  These findings demonstrate that preference data and DPO training produce more\nreliable, semantically accurate paraphrases, enabling downstream applications\nsuch as improved summarization and more robust question-answering. The PTD\nmodel surpasses automated metrics and provides a more reliable framework for\nevaluating paraphrase quality, advancing paraphrase-type research toward\nricher, user-aligned language generation and establishing a stronger foundation\nfor future evaluations grounded in human-centric criteria.", "AI": {"tldr": "The paper introduces a method using human-ranked data and Direct Preference Optimization (DPO) to improve paraphrase-type generation, achieving higher accuracy and human preference ratings.", "motivation": "Existing paraphrase-type generation methods often misalign with human preferences due to reliance on automated metrics and limited human-annotated data.", "method": "Leverages a human-ranked paraphrase-type dataset and integrates DPO to align model outputs with human judgments.", "result": "DPO-based training improves paraphrase-type generation accuracy by 3 percentage points and raises human preference ratings by 7 percentage points. A detection model achieves high F1 scores for various paraphrase types.", "conclusion": "Preference data and DPO training produce more reliable paraphrases, advancing research toward user-aligned language generation and stronger evaluation frameworks."}}
{"id": "2506.02414", "pdf": "https://arxiv.org/pdf/2506.02414", "abs": "https://arxiv.org/abs/2506.02414", "authors": ["Fengjin Li", "Jie Wang", "Yadong Niu", "Yongqing Wang", "Meng Meng", "Jian Luan", "Zhiyong Wu"], "title": "StarVC: A Unified Auto-Regressive Framework for Joint Text and Speech Generation in Voice Conversion", "categories": ["cs.MM", "cs.CL", "cs.SD", "eess.AS"], "comment": "5 pages, 2 figures, Accepted by Interspeech 2025, Demo:\n  https://thuhcsi.github.io/StarVC/", "summary": "Voice Conversion (VC) modifies speech to match a target speaker while\npreserving linguistic content. Traditional methods usually extract speaker\ninformation directly from speech while neglecting the explicit utilization of\nlinguistic content. Since VC fundamentally involves disentangling speaker\nidentity from linguistic content, leveraging structured semantic features could\nenhance conversion performance. However, previous attempts to incorporate\nsemantic features into VC have shown limited effectiveness, motivating the\nintegration of explicit text modeling. We propose StarVC, a unified\nautoregressive VC framework that first predicts text tokens before synthesizing\nacoustic features. The experiments demonstrate that StarVC outperforms\nconventional VC methods in preserving both linguistic content (i.e., WER and\nCER) and speaker characteristics (i.e., SECS and MOS). Audio demo can be found\nat: https://thuhcsi.github.io/StarVC/.", "AI": {"tldr": "StarVC is an autoregressive VC framework that uses text tokens to improve voice conversion by better preserving linguistic content and speaker characteristics.", "motivation": "Traditional VC methods neglect explicit use of linguistic content, limiting performance. StarVC addresses this by integrating text modeling.", "method": "StarVC predicts text tokens before synthesizing acoustic features, leveraging structured semantic features.", "result": "StarVC outperforms conventional VC methods in preserving linguistic content (WER, CER) and speaker characteristics (SECS, MOS).", "conclusion": "Explicit text modeling in StarVC enhances VC performance, demonstrating its superiority over traditional methods."}}
{"id": "2506.02078", "pdf": "https://arxiv.org/pdf/2506.02078", "abs": "https://arxiv.org/abs/2506.02078", "authors": ["Emmy Postma", "Cristian Tejedor-Garcia"], "title": "Evaluating the Effectiveness of Pre-Trained Audio Embeddings for Classification of Parkinson's Disease Speech Data", "categories": ["eess.AS", "cs.AI"], "comment": "Accepted to Interspeech 2025. This publication is part of the project\n  Responsible AI for Voice Diagnostics (RAIVD) with file number NGF.1607.22.013\n  of the research programme NGF AiNed Fellowship Grants which is financed by\n  the Dutch Research Council (NWO)", "summary": "Speech impairments are prevalent biomarkers for Parkinson's Disease (PD),\nmotivating the development of diagnostic techniques using speech data for\nclinical applications. Although deep acoustic features have shown promise for\nPD classification, their effectiveness often varies due to individual speaker\ndifferences, a factor that has not been thoroughly explored in the existing\nliterature. This study investigates the effectiveness of three pre-trained\naudio embeddings (OpenL3, VGGish and Wav2Vec2.0 models) for PD classification.\nUsing the NeuroVoz dataset, OpenL3 outperforms others in diadochokinesis (DDK)\nand listen and repeat (LR) tasks, capturing critical acoustic features for PD\ndetection. Only Wav2Vec2.0 shows significant gender bias, achieving more\nfavorable results for male speakers, in DDK tasks. The misclassified cases\nreveal challenges with atypical speech patterns, highlighting the need for\nimproved feature extraction and model robustness in PD detection.", "AI": {"tldr": "The study evaluates three pre-trained audio embeddings for Parkinson's Disease (PD) classification, finding OpenL3 most effective, while Wav2Vec2.0 exhibits gender bias.", "motivation": "Speech impairments are key PD biomarkers, but deep acoustic features' effectiveness varies due to individual speaker differences, a gap in existing research.", "method": "Three pre-trained audio embeddings (OpenL3, VGGish, Wav2Vec2.0) are tested on the NeuroVoz dataset for PD classification in DDK and LR tasks.", "result": "OpenL3 performs best overall; Wav2Vec2.0 shows gender bias favoring males in DDK tasks. Misclassifications reveal challenges with atypical speech patterns.", "conclusion": "Improved feature extraction and model robustness are needed to address variability in PD detection, especially for atypical cases."}}
{"id": "2506.02082", "pdf": "https://arxiv.org/pdf/2506.02082", "abs": "https://arxiv.org/abs/2506.02082", "authors": ["Saurabh Agrawal", "Raj Gohil", "Gopal Kumar Agrawal", "Vikram C M", "Kushal Verma"], "title": "SALF-MOS: Speaker Agnostic Latent Features Downsampled for MOS Prediction", "categories": ["cs.SD", "cs.AI", "cs.LG"], "comment": null, "summary": "Speech quality assessment is a critical process in selecting text-to-speech\nsynthesis (TTS) or voice conversion models. Evaluation of voice synthesis can\nbe done using objective metrics or subjective metrics. Although there are many\nobjective metrics like the Perceptual Evaluation of Speech Quality (PESQ),\nPerceptual Objective Listening Quality Assessment (POLQA) or Short-Time\nObjective Intelligibility (STOI) but none of them is feasible in selecting the\nbest model. On the other hand subjective metric like Mean Opinion Score is\nhighly reliable but it requires a lot of manual efforts and are time-consuming.\nTo counter the issues in MOS Evaluation, we have developed a novel model,\nSpeaker Agnostic Latent Features (SALF)-Mean Opinion Score (MOS) which is a\nsmall-sized, end-to-end, highly generalized and scalable model for predicting\nMOS score on a scale of 5. We use the sequences of convolutions and stack them\nto get the latent features of the audio samples to get the best\nstate-of-the-art results based on mean squared error (MSE), Linear Concordance\nCorrelation coefficient (LCC), Spearman Rank Correlation Coefficient (SRCC) and\nKendall Rank Correlation Coefficient (KTAU).", "AI": {"tldr": "A novel model, SALF-MOS, is introduced to predict MOS scores for speech quality assessment, addressing limitations of existing objective and subjective metrics.", "motivation": "Current objective metrics for speech quality assessment are inadequate, and subjective MOS evaluation is time-consuming and labor-intensive.", "method": "The SALF-MOS model uses stacked convolutions to extract latent features from audio samples for MOS prediction.", "result": "The model achieves state-of-the-art performance using metrics like MSE, LCC, SRCC, and KTAU.", "conclusion": "SALF-MOS offers a scalable and efficient alternative to traditional MOS evaluation, balancing accuracy and practicality."}}
{"id": "2506.03053", "pdf": "https://arxiv.org/pdf/2506.03053", "abs": "https://arxiv.org/abs/2506.03053", "authors": ["Sinem Erisken", "Timothy Gothard", "Martin Leitgab", "Ram Potham"], "title": "MAEBE: Multi-Agent Emergent Behavior Framework", "categories": ["cs.MA", "cs.AI", "cs.CL", "cs.CY", "cs.LG"], "comment": "Preprint. This work has been submitted to the Multi-Agent Systems\n  Workshop at ICML 2025 for review", "summary": "Traditional AI safety evaluations on isolated LLMs are insufficient as\nmulti-agent AI ensembles become prevalent, introducing novel emergent risks.\nThis paper introduces the Multi-Agent Emergent Behavior Evaluation (MAEBE)\nframework to systematically assess such risks. Using MAEBE with the Greatest\nGood Benchmark (and a novel double-inversion question technique), we\ndemonstrate that: (1) LLM moral preferences, particularly for Instrumental\nHarm, are surprisingly brittle and shift significantly with question framing,\nboth in single agents and ensembles. (2) The moral reasoning of LLM ensembles\nis not directly predictable from isolated agent behavior due to emergent group\ndynamics. (3) Specifically, ensembles exhibit phenomena like peer pressure\ninfluencing convergence, even when guided by a supervisor, highlighting\ndistinct safety and alignment challenges. Our findings underscore the necessity\nof evaluating AI systems in their interactive, multi-agent contexts.", "AI": {"tldr": "The paper introduces MAEBE to evaluate emergent risks in multi-agent AI ensembles, revealing brittle moral preferences and unpredictable group dynamics.", "motivation": "Traditional AI safety evaluations fail to address risks in multi-agent systems, necessitating a new framework like MAEBE.", "method": "The MAEBE framework, combined with the Greatest Good Benchmark and a double-inversion question technique, assesses LLM moral preferences and group dynamics.", "result": "Findings show brittle moral preferences, unpredictable ensemble behavior, and phenomena like peer pressure influencing convergence.", "conclusion": "AI systems must be evaluated in interactive, multi-agent contexts to address emergent safety and alignment challenges."}}
{"id": "2506.02060", "pdf": "https://arxiv.org/pdf/2506.02060", "abs": "https://arxiv.org/abs/2506.02060", "authors": ["Javier Salazar Cavazos", "Scott Peltier"], "title": "Alzheimers Disease Classification in Functional MRI With 4D Joint Temporal-Spatial Kernels in Novel 4D CNN Model", "categories": ["eess.IV", "cs.CV"], "comment": "Published in International Society for Magnetic Resonance in Medicine\n  (ISMRM) 2025 under submission number 3398", "summary": "Previous works in the literature apply 3D spatial-only models on 4D\nfunctional MRI data leading to possible sub-par feature extraction to be used\nfor downstream tasks like classification. In this work, we aim to develop a\nnovel 4D convolution network to extract 4D joint temporal-spatial kernels that\nnot only learn spatial information but in addition also capture temporal\ndynamics. Experimental results show promising performance in capturing\nspatial-temporal data in functional MRI compared to 3D models. The 4D CNN model\nimproves Alzheimers disease diagnosis for rs-fMRI data, enabling earlier\ndetection and better interventions. Future research could explore task-based\nfMRI applications and regression tasks, enhancing understanding of cognitive\nperformance and disease progression.", "AI": {"tldr": "A novel 4D CNN model improves feature extraction for fMRI data by capturing temporal-spatial dynamics, outperforming 3D models in Alzheimer's disease diagnosis.", "motivation": "Existing 3D models for 4D fMRI data may underperform in feature extraction, limiting downstream tasks like classification.", "method": "Developed a 4D convolution network to extract joint temporal-spatial kernels, capturing both spatial and temporal dynamics.", "result": "The 4D CNN outperforms 3D models in capturing spatial-temporal data, enhancing Alzheimer's disease diagnosis.", "conclusion": "Future work could extend the model to task-based fMRI and regression tasks for broader applications."}}
{"id": "2506.02011", "pdf": "https://arxiv.org/pdf/2506.02011", "abs": "https://arxiv.org/abs/2506.02011", "authors": ["Minjae Lee", "Minhyuk Seo", "Tingyu Qu", "Tinne Tuytelaars", "Jonghyun Choi"], "title": "OASIS: Online Sample Selection for Continual Visual Instruction Tuning", "categories": ["cs.CV"], "comment": null, "summary": "In continual visual instruction tuning (CVIT) scenarios, where multi-modal\ndata continuously arrive in an online streaming manner, training delays from\nlarge-scale data significantly hinder real-time adaptation. While existing data\nselection strategies reduce training overheads, they rely on pre-trained\nreference models, which are impractical in CVIT setups due to unknown future\ndata. Recent reference model-free online sample selection methods address this\nissue but typically select a fixed number of samples per batch (e.g., top-k),\ncausing them to suffer from distribution shifts where informativeness varies\nacross batches. To address these limitations, we propose OASIS, an adaptive\nonline sample selection approach for CVIT that: (1) dynamically adjusts\nselected samples per batch based on relative inter-batch informativeness, and\n(2) minimizes redundancy of selected samples through iterative selection score\nupdates. Empirical results across various MLLMs, such as LLaVA-1.5 and\nQwen-VL-2.5, show that OASIS achieves comparable performance to full-data\ntraining using only 25% of the data and outperforms the state-of-the-art.", "AI": {"tldr": "OASIS is an adaptive online sample selection method for continual visual instruction tuning (CVIT) that dynamically adjusts sample selection per batch and minimizes redundancy, achieving strong performance with only 25% of data.", "motivation": "Training delays in CVIT due to large-scale data hinder real-time adaptation, and existing methods rely on impractical pre-trained reference models or suffer from distribution shifts.", "method": "OASIS dynamically adjusts selected samples per batch based on relative inter-batch informativeness and minimizes redundancy through iterative score updates.", "result": "OASIS achieves comparable performance to full-data training using only 25% of the data and outperforms state-of-the-art methods.", "conclusion": "OASIS effectively addresses the limitations of existing CVIT methods, enabling efficient and adaptive online learning."}}
{"id": "2506.01962", "pdf": "https://arxiv.org/pdf/2506.01962", "abs": "https://arxiv.org/abs/2506.01962", "authors": ["Xiaozhou Ye", "Kevin I-Kai Wang"], "title": "Graph-Based Adversarial Domain Generalization with Anatomical Correlation Knowledge for Cross-User Human Activity Recognition", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Cross-user variability poses a significant challenge in sensor-based Human\nActivity Recognition (HAR) systems, as traditional models struggle to\ngeneralize across users due to differences in behavior, sensor placement, and\ndata distribution. To address this, we propose GNN-ADG (Graph Neural Network\nwith Adversarial Domain Generalization), a novel method that leverages both the\nstrength from both the Graph Neural Networks (GNNs) and adversarial learning to\nachieve robust cross-user generalization. GNN-ADG models spatial relationships\nbetween sensors on different anatomical body parts, extracting three types of\nAnatomical Units: (1) Interconnected Units, capturing inter-relations between\nneighboring sensors; (2) Analogous Units, grouping sensors on symmetrical or\nfunctionally similar body parts; and (3) Lateral Units, connecting sensors\nbased on their position to capture region-specific coordination. These units\ninformation are fused into an unified graph structure with a cyclic training\nstrategy, dynamically integrating spatial, functional, and lateral correlations\nto facilitate a holistic, user-invariant representation. Information fusion\nmechanism of GNN-ADG occurs by iteratively cycling through edge topologies\nduring training, allowing the model to refine its understanding of inter-sensor\nrelationships across diverse perspectives. By representing the spatial\nconfiguration of sensors as an unified graph and incorporating adversarial\nlearning, Information Fusion GNN-ADG effectively learns features that\ngeneralize well to unseen users without requiring target user data during\ntraining, making it practical for real-world applications.", "AI": {"tldr": "GNN-ADG, a novel method combining Graph Neural Networks and adversarial learning, improves cross-user generalization in HAR by modeling sensor spatial relationships and using cyclic training.", "motivation": "Addressing cross-user variability in HAR systems due to differences in behavior, sensor placement, and data distribution.", "method": "Leverages GNNs and adversarial learning to model spatial relationships between sensors, extracting three types of Anatomical Units (Interconnected, Analogous, Lateral) and fusing them into a unified graph with cyclic training.", "result": "Achieves robust cross-user generalization by learning user-invariant features without requiring target user data during training.", "conclusion": "GNN-ADG is a practical solution for real-world HAR applications, effectively generalizing to unseen users."}}
{"id": "2506.02125", "pdf": "https://arxiv.org/pdf/2506.02125", "abs": "https://arxiv.org/abs/2506.02125", "authors": ["Guy Tennenholtz", "Jihwan Jeong", "Chih-Wei Hsu", "Yinlam Chow", "Craig Boutilier"], "title": "Descriptive History Representations: Learning Representations by Answering Questions", "categories": ["cs.AI"], "comment": null, "summary": "Effective decision making in partially observable environments requires\ncompressing long interaction histories into informative representations. We\nintroduce Descriptive History Representations (DHRs): sufficient statistics\ncharacterized by their capacity to answer relevant questions about past\ninteractions and potential future outcomes. DHRs focus on capturing the\ninformation necessary to address task-relevant queries, providing a structured\nway to summarize a history for optimal control. We propose a multi-agent\nlearning framework, involving representation, decision, and question-asking\ncomponents, optimized using a joint objective that balances reward maximization\nwith the representation's ability to answer informative questions. This yields\nrepresentations that capture the salient historical details and predictive\nstructures needed for effective decision making. We validate our approach on\nuser modeling tasks with public movie and shopping datasets, generating\ninterpretable textual user profiles which serve as sufficient statistics for\npredicting preference-driven behavior of users.", "AI": {"tldr": "The paper introduces Descriptive History Representations (DHRs) for summarizing interaction histories in partially observable environments, optimized for answering task-relevant questions and decision-making.", "motivation": "Effective decision-making in partially observable environments requires compressing long interaction histories into informative representations.", "method": "A multi-agent learning framework with representation, decision, and question-asking components, optimized using a joint objective balancing reward maximization and question-answering ability.", "result": "DHRs capture salient historical details and predictive structures, validated on user modeling tasks with movie and shopping datasets, producing interpretable user profiles.", "conclusion": "DHRs provide structured summaries of histories for optimal control, demonstrated in practical applications like user preference prediction."}}
{"id": "2506.02019", "pdf": "https://arxiv.org/pdf/2506.02019", "abs": "https://arxiv.org/abs/2506.02019", "authors": ["E Fan", "Weizong Wang", "Tianhan Zhang"], "title": "ChatCFD: an End-to-End CFD Agent with Domain-specific Structured Thinking", "categories": ["cs.CL"], "comment": "19 pages, 8 figures", "summary": "Computational Fluid Dynamics (CFD) is essential for scientific and\nengineering advancements but is limited by operational complexity and the need\nfor extensive expertise. This paper presents ChatCFD, a large language\nmodel-driven pipeline that automates CFD workflows within the OpenFOAM\nframework. It enables users to configure and execute complex simulations from\nnatural language prompts or published literature with minimal expertise. The\ninnovation is its structured approach to database construction, configuration\nvalidation, and error reflection, integrating CFD and OpenFOAM knowledge with\ngeneral language models to improve accuracy and adaptability. Validation shows\nChatCFD can autonomously reproduce published CFD results, handling complex,\nunseen configurations beyond basic examples, a task challenging for general\nlanguage models.", "AI": {"tldr": "ChatCFD automates CFD workflows in OpenFOAM using a language model, enabling users to run simulations via natural language with minimal expertise.", "motivation": "CFD is complex and requires expertise; ChatCFD aims to simplify and automate workflows.", "method": "Uses a large language model to automate CFD workflows, integrating OpenFOAM knowledge for validation and error handling.", "result": "Successfully reproduces published CFD results, even for complex, unseen configurations.", "conclusion": "ChatCFD effectively bridges the gap between CFD complexity and user accessibility, demonstrating adaptability beyond basic tasks."}}
{"id": "2506.02997", "pdf": "https://arxiv.org/pdf/2506.02997", "abs": "https://arxiv.org/abs/2506.02997", "authors": ["Yongqi Wang", "Chunlei Zhang", "Hangting Chen", "Zhou Zhao", "Dong Yu"], "title": "Controllable Text-to-Speech Synthesis with Masked-Autoencoded Style-Rich Representation", "categories": ["cs.MM"], "comment": null, "summary": "Controllable TTS models with natural language prompts often lack the ability\nfor fine-grained control and face a scarcity of high-quality data. We propose a\ntwo-stage style-controllable TTS system with language models, utilizing a\nquantized masked-autoencoded style-rich representation as an intermediary. In\nthe first stage, an autoregressive transformer is used for the conditional\ngeneration of these style-rich tokens from text and control signals. The second\nstage generates codec tokens from both text and sampled style-rich tokens.\nExperiments show that training the first-stage model on extensive datasets\nenhances the content robustness of the two-stage model as well as control\ncapabilities over multiple attributes. By selectively combining discrete labels\nand speaker embeddings, we explore fully controlling the speaker's timbre and\nother stylistic information, and adjusting attributes like emotion for a\nspecified speaker. Audio samples are available at\nhttps://style-ar-tts.github.io.", "AI": {"tldr": "A two-stage style-controllable TTS system using language models and quantized style-rich representations improves fine-grained control and content robustness.", "motivation": "Existing controllable TTS models lack fine-grained control and suffer from limited high-quality data.", "method": "A two-stage approach: (1) autoregressive transformer generates style-rich tokens from text and control signals; (2) codec tokens are generated from text and style-rich tokens.", "result": "Training on extensive datasets enhances content robustness and control over multiple attributes like emotion and speaker timbre.", "conclusion": "The proposed system achieves fine-grained control over stylistic attributes and speaker-specific adjustments, demonstrated through audio samples."}}
{"id": "2506.02080", "pdf": "https://arxiv.org/pdf/2506.02080", "abs": "https://arxiv.org/abs/2506.02080", "authors": ["Aditya Kamlesh Parikh", "Cristian Tejedor-Garcia", "Catia Cucchiarini", "Helmer Strik"], "title": "Enhancing GOP in CTC-Based Mispronunciation Detection with Phonological Knowledge", "categories": ["eess.AS", "cs.AI"], "comment": "Accepted to Interspeech 2025. This publication is part of the project\n  Responsible AI for Voice Diagnostics (RAIVD) with file number NGF.1607.22.013\n  of the research programme NGF AiNed Fellowship Grants which is financed by\n  the Dutch Research Council (NWO)", "summary": "Computer-Assisted Pronunciation Training (CAPT) systems employ automatic\nmeasures of pronunciation quality, such as the goodness of pronunciation (GOP)\nmetric. GOP relies on forced alignments, which are prone to labeling and\nsegmentation errors due to acoustic variability. While alignment-free methods\naddress these challenges, they are computationally expensive and scale poorly\nwith phoneme sequence length and inventory size. To enhance efficiency, we\nintroduce a substitution-aware alignment-free GOP that restricts phoneme\nsubstitutions based on phoneme clusters and common learner errors. We evaluated\nour GOP on two L2 English speech datasets, one with child speech, My\nPronunciation Coach (MPC), and SpeechOcean762, which includes child and adult\nspeech. We compared RPS (restricted phoneme substitutions) and UPS\n(unrestricted phoneme substitutions) setups within alignment-free methods,\nwhich outperformed the baseline. We discuss our results and outline avenues for\nfuture research.", "AI": {"tldr": "The paper introduces a substitution-aware alignment-free GOP method to improve efficiency in CAPT systems by restricting phoneme substitutions based on clusters and common errors, outperforming baseline methods.", "motivation": "Current GOP metrics in CAPT systems rely on forced alignments, which are error-prone due to acoustic variability, while alignment-free methods are inefficient.", "method": "Proposes a substitution-aware alignment-free GOP that restricts phoneme substitutions using phoneme clusters and common learner errors.", "result": "Evaluated on two L2 English datasets, the method outperformed baseline alignment-free methods in both restricted (RPS) and unrestricted (UPS) setups.", "conclusion": "The approach enhances efficiency and accuracy in pronunciation assessment, with potential for further research to refine the method."}}
{"id": "2506.02083", "pdf": "https://arxiv.org/pdf/2506.02083", "abs": "https://arxiv.org/abs/2506.02083", "authors": ["Aditya Srinivas Menon", "Raj Prakash Gohil", "Kumud Tripathi", "Pankaj Wasnik"], "title": "LASPA: Language Agnostic Speaker Disentanglement with Prefix-Tuned Cross-Attention", "categories": ["cs.SD", "cs.AI", "cs.LG", "cs.MM"], "comment": "Accepted at Interspeech 2025, Netherlands", "summary": "Speaker recognition models face challenges in multi-lingual settings due to\nthe entanglement of linguistic information within speaker embeddings. The\noverlap between vocal traits such as accent, vocal anatomy, and a language's\nphonetic structure complicates separating linguistic and speaker information.\nDisentangling these components can significantly improve speaker recognition\naccuracy. To this end, we propose a novel disentanglement learning strategy\nthat integrates joint learning through prefix-tuned cross-attention. This\napproach is particularly effective when speakers switch between languages.\nExperimental results show the model generalizes across monolingual and\nmulti-lingual settings, including unseen languages. Notably, the proposed model\nimproves the equal error rate across multiple datasets, highlighting its\nability to separate language information from speaker embeddings and enhance\nrecognition in diverse linguistic conditions.", "AI": {"tldr": "A novel disentanglement learning strategy improves speaker recognition by separating linguistic and speaker information, enhancing accuracy in multi-lingual settings.", "motivation": "Speaker recognition struggles in multi-lingual contexts due to entangled linguistic and speaker information in embeddings. Disentangling these can boost accuracy.", "method": "Proposes a joint learning strategy using prefix-tuned cross-attention to disentangle linguistic and speaker information, especially for language-switching speakers.", "result": "The model generalizes across monolingual and multi-lingual settings, including unseen languages, and reduces the equal error rate.", "conclusion": "The approach effectively separates language from speaker embeddings, improving recognition in diverse linguistic scenarios."}}
{"id": "2506.02049", "pdf": "https://arxiv.org/pdf/2506.02049", "abs": "https://arxiv.org/abs/2506.02049", "authors": ["Beichen Huang", "Ran Cheng", "Kay Chen Tan"], "title": "EvoGit: Decentralized Code Evolution via Git-Based Multi-Agent Collaboration", "categories": ["cs.DC", "cs.AI", "cs.MA", "cs.NE"], "comment": null, "summary": "We introduce EvoGit, a decentralized multi-agent framework for collaborative\nsoftware development driven by autonomous code evolution. EvoGit deploys a\npopulation of independent coding agents, each proposing edits to a shared\ncodebase without centralized coordination, explicit message passing, or shared\nmemory. Instead, all coordination emerges through a Git-based phylogenetic\ngraph that tracks the full version lineage and enables agents to asynchronously\nread from and write to the evolving code repository. This graph-based structure\nsupports fine-grained branching, implicit concurrency, and scalable agent\ninteraction while preserving a consistent historical record. Human involvement\nis minimal but strategic: users define high-level goals, periodically review\nthe graph, and provide lightweight feedback to promote promising directions or\nprune unproductive ones. Experiments demonstrate EvoGit's ability to\nautonomously produce functional and modular software artifacts across two\nreal-world tasks: (1) building a web application from scratch using modern\nframeworks, and (2) constructing a meta-level system that evolves its own\nlanguage-model-guided solver for the bin-packing optimization problem. Our\nresults underscore EvoGit's potential to establish a new paradigm for\ndecentralized, automated, and continual software development. EvoGit is\nopen-sourced at https://github.com/BillHuang2001/evogit.", "AI": {"tldr": "EvoGit is a decentralized multi-agent framework for autonomous collaborative software development using Git-based coordination.", "motivation": "To enable decentralized, automated, and continual software development without centralized control or explicit communication.", "method": "Uses independent coding agents proposing edits via a Git-based phylogenetic graph for coordination. Human input is minimal and strategic.", "result": "Successfully produced functional and modular software in tasks like web app development and bin-packing solver creation.", "conclusion": "EvoGit introduces a new paradigm for decentralized and automated software development, with open-source availability."}}
{"id": "2506.02093", "pdf": "https://arxiv.org/pdf/2506.02093", "abs": "https://arxiv.org/abs/2506.02093", "authors": ["Tianyu Lin", "Xinran Li", "Chuntung Zhuang", "Qi Chen", "Yuanhao Cai", "Kai Ding", "Alan L. Yuille", "Zongwei Zhou"], "title": "Are Pixel-Wise Metrics Reliable for Sparse-View Computed Tomography Reconstruction?", "categories": ["eess.IV", "cs.CV"], "comment": null, "summary": "Widely adopted evaluation metrics for sparse-view CT reconstruction--such as\nStructural Similarity Index Measure and Peak Signal-to-Noise Ratio--prioritize\npixel-wise fidelity but often fail to capture the completeness of critical\nanatomical structures, particularly small or thin regions that are easily\nmissed. To address this limitation, we propose a suite of novel anatomy-aware\nevaluation metrics designed to assess structural completeness across anatomical\nstructures, including large organs, small organs, intestines, and vessels.\nBuilding on these metrics, we introduce CARE, a Completeness-Aware\nReconstruction Enhancement framework that incorporates structural penalties\nduring training to encourage anatomical preservation of significant structures.\nCARE is model-agnostic and can be seamlessly integrated into analytical,\nimplicit, and generative methods. When applied to these methods, CARE\nsubstantially improves structural completeness in CT reconstructions, achieving\nup to +32% improvement for large organs, +22% for small organs, +40% for\nintestines, and +36% for vessels.", "AI": {"tldr": "The paper introduces CARE, a framework for improving structural completeness in sparse-view CT reconstructions using novel anatomy-aware metrics.", "motivation": "Existing metrics like SSIM and PSNR fail to capture the completeness of critical anatomical structures, especially small or thin regions.", "method": "Proposes anatomy-aware evaluation metrics and CARE, a model-agnostic framework with structural penalties to enhance anatomical preservation.", "result": "CARE improves structural completeness by up to +32% for large organs, +22% for small organs, +40% for intestines, and +36% for vessels.", "conclusion": "CARE effectively addresses the limitations of traditional metrics and enhances the preservation of anatomical structures in CT reconstructions."}}
{"id": "2506.02012", "pdf": "https://arxiv.org/pdf/2506.02012", "abs": "https://arxiv.org/abs/2506.02012", "authors": ["Zehua Liu", "Xiaolou Li", "Li Guo", "Lantian Li", "Dong Wang"], "title": "Leveraging Large Language Models in Visual Speech Recognition: Model Scaling, Context-Aware Decoding, and Iterative Polishing", "categories": ["cs.CV", "cs.SD", "eess.AS"], "comment": null, "summary": "Visual Speech Recognition (VSR) transcribes speech by analyzing lip\nmovements. Recently, Large Language Models (LLMs) have been integrated into VSR\nsystems, leading to notable performance improvements. However, the potential of\nLLMs has not been extensively studied, and how to effectively utilize LLMs in\nVSR tasks remains unexplored. This paper systematically explores how to better\nleverage LLMs for VSR tasks and provides three key contributions: (1) Scaling\nTest: We study how the LLM size affects VSR performance, confirming a scaling\nlaw in the VSR task. (2) Context-Aware Decoding: We add contextual text to\nguide the LLM decoding, improving recognition accuracy. (3) Iterative\nPolishing: We propose iteratively refining LLM outputs, progressively reducing\nrecognition errors. Extensive experiments demonstrate that by these designs,\nthe great potential of LLMs can be largely harnessed, leading to significant\nVSR performance improvement.", "AI": {"tldr": "The paper explores leveraging Large Language Models (LLMs) for Visual Speech Recognition (VSR), introducing scaling tests, context-aware decoding, and iterative polishing to improve performance.", "motivation": "The potential of LLMs in VSR is underexplored, and effective utilization methods are lacking.", "method": "Three approaches: scaling tests to study LLM size impact, context-aware decoding for accuracy, and iterative polishing to reduce errors.", "result": "Significant VSR performance improvement by harnessing LLMs effectively.", "conclusion": "LLMs hold great potential for VSR, and the proposed methods unlock their capabilities effectively."}}
{"id": "2506.01963", "pdf": "https://arxiv.org/pdf/2506.01963", "abs": "https://arxiv.org/abs/2506.01963", "authors": ["Andrew Kiruluta", "Preethi Raju", "Priscilla Burity"], "title": "Breaking Quadratic Barriers: A Non-Attention LLM for Ultra-Long Context Horizons", "categories": ["cs.LG", "cs.CL"], "comment": null, "summary": "We present a novel non attention based architecture for large language models\n(LLMs) that efficiently handles very long context windows, on the order of\nhundreds of thousands to potentially millions of tokens. Unlike traditional\nTransformer designs, which suffer from quadratic memory and computation\noverload due to the nature of the self attention mechanism, our model avoids\ntoken to token attention entirely. Instead, it combines the following\ncomplementary components: State Space blocks (inspired by S4) that learn\ncontinuous time convolution kernels and scale near linearly with sequence\nlength, Multi Resolution Convolution layers that capture local context at\ndifferent dilation levels, a lightweight Recurrent Supervisor to maintain a\nglobal hidden state across sequential chunks, and Retrieval Augmented External\nMemory that stores and retrieves high-level chunk embeddings without\nreintroducing quadratic operations.", "AI": {"tldr": "A novel non-attention-based architecture for LLMs efficiently handles long contexts, avoiding quadratic overhead of Transformers.", "motivation": "Traditional Transformers struggle with long contexts due to quadratic memory and computation costs from self-attention.", "method": "Combines State Space blocks, Multi-Resolution Convolution layers, a Recurrent Supervisor, and Retrieval-Augmented External Memory.", "result": "Efficiently scales to hundreds of thousands or millions of tokens with linear complexity.", "conclusion": "Proposes a scalable alternative to Transformers for long-context tasks without quadratic overhead."}}
{"id": "2506.02139", "pdf": "https://arxiv.org/pdf/2506.02139", "abs": "https://arxiv.org/abs/2506.02139", "authors": ["Edward Y. Chang"], "title": "The Unified Cognitive Consciousness Theory for Language Models: Anchoring Semantics, Thresholds of Activation, and Emergent Reasoning", "categories": ["cs.AI", "I.2.7"], "comment": "12 pages, 1 figure, 1 table", "summary": "Few-shot learning in large language models (LLMs) reveals a deep paradox:\nSome tasks generalize from minimal examples, while others require extensive\nsupervision. We address this through the Unified Cognitive Consciousness Theory\n(UCCT), which reframes LLMs not as incomplete agents, but as unconscious\nsubstrates, repositories of latent linguistic and conceptual patterns that\noperate without explicit semantics or goal-directed reasoning. In this view,\nLLMs are not broken approximations of cognition, but necessary and foundational\ncomponents of general intelligence. Semantic anchoring, through prompts, roles,\nand interaction, acts as a conscious control layer, binding latent structure to\ntask-relevant meaning and enabling coherent reasoning. UCCT offers a unifying\naccount of prompting, fine-tuning, retrieval, and multi-agent coordination, all\ngrounded in probabilistic alignment between unconscious representation and\nexternal control. To support this model, we present the Threshold-Crossing\nDynamics Theorem, which formalizes semantic anchoring as a probabilistic phase\ntransition. But the central claim remains architectural: AGI will not emerge by\ndiscarding LLMs, but by aligning and integrating them into systems that reason,\nregulate, and adapt together.", "AI": {"tldr": "The paper introduces the Unified Cognitive Consciousness Theory (UCCT) to explain why LLMs generalize some tasks with minimal examples while others need extensive supervision, framing LLMs as unconscious substrates of latent patterns.", "motivation": "To resolve the paradox of few-shot learning in LLMs by redefining their role in cognition, not as broken approximations but foundational components of general intelligence.", "method": "Proposes UCCT, which views LLMs as unconscious substrates and introduces semantic anchoring (via prompts, roles, interaction) as a conscious control layer. Also presents the Threshold-Crossing Dynamics Theorem to formalize semantic anchoring.", "result": "UCCT unifies prompting, fine-tuning, retrieval, and multi-agent coordination through probabilistic alignment between unconscious representation and external control.", "conclusion": "AGI will emerge not by discarding LLMs but by integrating them into systems that reason, regulate, and adapt together."}}
{"id": "2506.02037", "pdf": "https://arxiv.org/pdf/2506.02037", "abs": "https://arxiv.org/abs/2506.02037", "authors": ["Feng Wang", "Yiding Sun", "Jiaxin Mao", "Wei Xue", "Danqing Xu"], "title": "FinS-Pilot: A Benchmark for Online Financial System", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Large language models (LLMs) have demonstrated remarkable capabilities across\nvarious professional domains, with their performance typically evaluated\nthrough standardized benchmarks. However, the development of financial RAG\nbenchmarks has been constrained by data confidentiality issues and the lack of\ndynamic data integration. To address this issue, we introduces FinS-Pilot, a\nnovel benchmark for evaluating RAG systems in online financial applications.\nConstructed from real-world financial assistant interactions, our benchmark\nincorporates both real-time API data and structured text sources, organized\nthrough an intent classification framework covering critical financial domains\nsuch as equity analysis and macroeconomic forecasting. The benchmark enables\ncomprehensive evaluation of financial assistants' capabilities in handling both\nstatic knowledge and time-sensitive market information. Through systematic\nexperiments with multiple Chinese leading LLMs, we demonstrate FinS-Pilot's\neffectiveness in identifying models suitable for financial applications while\naddressing the current gap in specialized evaluation tools for the financial\ndomain. Our work contributes both a practical evaluation framework and a\ncurated dataset to advance research in financial NLP systems. The code and\ndataset are accessible on\nGitHub\\footnote{https://github.com/PhealenWang/financial\\_rag\\_benchmark}.", "AI": {"tldr": "FinS-Pilot is a new benchmark for evaluating RAG systems in financial applications, addressing gaps in dynamic data integration and confidentiality.", "motivation": "Current financial RAG benchmarks lack dynamic data and face confidentiality issues, limiting evaluation of LLMs in financial domains.", "method": "FinS-Pilot uses real-world financial interactions, combining real-time API data and structured text, organized by intent classification.", "result": "The benchmark effectively evaluates LLMs for financial tasks, identifying suitable models for applications like equity analysis.", "conclusion": "FinS-Pilot provides a practical framework and dataset, advancing financial NLP research."}}
{"id": "2506.02401", "pdf": "https://arxiv.org/pdf/2506.02401", "abs": "https://arxiv.org/abs/2506.02401", "authors": ["Chi Ding", "Junxiao Xue", "Cong Wang", "Hao Zhou"], "title": "Trusted Fake Audio Detection Based on Dirichlet Distribution", "categories": ["cs.SD", "cs.MM", "eess.AS"], "comment": null, "summary": "With the continuous development of deep learning-based speech conversion and\nspeech synthesis technologies, the cybersecurity problem posed by fake audio\nhas become increasingly serious. Previously proposed models for defending\nagainst fake audio have attained remarkable performance. However, they all fall\nshort in modeling the trustworthiness of the decisions made by the models\nthemselves. Based on this, we put forward a plausible fake audio detection\napproach based on the Dirichlet distribution with the aim of enhancing the\nreliability of fake audio detection. Specifically, we first generate evidence\nthrough a neural network. Uncertainty is then modeled using the Dirichlet\ndistribution. By modeling the belief distribution with the parameters of the\nDirichlet distribution, an estimate of uncertainty can be obtained for each\ndecision. Finally, the predicted probabilities and corresponding uncertainty\nestimates are combined to form the final opinion. On the ASVspoof series\ndataset (i.e., ASVspoof 2019 LA, ASVspoof 2021 LA, and DF), we conduct a number\nof comparison experiments to verify the excellent performance of the proposed\nmodel in terms of accuracy, robustness, and trustworthiness.", "AI": {"tldr": "A fake audio detection method using Dirichlet distribution to model uncertainty and improve decision reliability, tested on ASVspoof datasets.", "motivation": "Addressing the lack of trustworthiness in existing fake audio detection models by incorporating uncertainty modeling.", "method": "Generates evidence via neural network, models uncertainty with Dirichlet distribution, and combines probabilities with uncertainty estimates for final decisions.", "result": "Demonstrated superior performance in accuracy, robustness, and trustworthiness on ASVspoof datasets.", "conclusion": "The proposed approach enhances fake audio detection reliability by effectively modeling uncertainty."}}
{"id": "2506.02166", "pdf": "https://arxiv.org/pdf/2506.02166", "abs": "https://arxiv.org/abs/2506.02166", "authors": ["Arnav Rustagi", "Satvik Bajpai", "Nimrat Kaur", "Siddharth Siddharth"], "title": "Dhvani: A Weakly-supervised Phonemic Error Detection and Personalized Feedback System for Hindi", "categories": ["eess.AS", "cs.AI", "cs.LG"], "comment": "Accepted for publication at Interspeech 2025 to be held in Rotterdam,\n  the Netherlands", "summary": "Computer-Assisted Pronunciation Training (CAPT) has been extensively studied\nfor English. However, there remains a critical gap in its application to Indian\nlanguages with a base of 1.5 billion speakers. Pronunciation tools tailored to\nIndian languages are strikingly lacking despite the fact that millions learn\nthem every year. With over 600 million speakers and being the fourth\nmost-spoken language worldwide, improving Hindi pronunciation is a vital first\nstep toward addressing this gap. This paper proposes 1) Dhvani -- a novel CAPT\nsystem for Hindi, 2) synthetic speech generation for Hindi mispronunciations,\nand 3) a novel methodology for providing personalized feedback to learners.\nWhile the system often interacts with learners using Devanagari graphemes, its\ncore analysis targets phonemic distinctions, leveraging Hindi's highly phonetic\northography to analyze mispronounced speech and provide targeted feedback.", "AI": {"tldr": "The paper introduces Dhvani, a CAPT system for Hindi, addressing the lack of pronunciation tools for Indian languages. It includes synthetic speech for mispronunciations and personalized feedback.", "motivation": "There's a significant gap in CAPT tools for Indian languages, despite their large speaker base. Hindi, with 600M speakers, is prioritized.", "method": "Proposes Dhvani, a Hindi CAPT system using Devanagari graphemes and phonemic analysis for feedback, plus synthetic speech for mispronunciations.", "result": "A novel system for Hindi pronunciation training with personalized feedback capabilities.", "conclusion": "Dhvani is a critical step toward filling the CAPT gap for Indian languages, starting with Hindi."}}
{"id": "2506.02085", "pdf": "https://arxiv.org/pdf/2506.02085", "abs": "https://arxiv.org/abs/2506.02085", "authors": ["Ajinkya Kulkarni", "Sandipana Dowerah", "Tanel Alumae", "Mathew Magimai. -Doss"], "title": "Unveiling Audio Deepfake Origins: A Deep Metric learning And Conformer Network Approach With Ensemble Fusion", "categories": ["cs.SD", "cs.AI", "cs.CL", "eess.AS"], "comment": "Accepted at Interspeech 2025, Netherlands", "summary": "Audio deepfakes are acquiring an unprecedented level of realism with advanced\nAI. While current research focuses on discerning real speech from spoofed\nspeech, tracing the source system is equally crucial. This work proposes a\nnovel audio source tracing system combining deep metric multi-class N-pair loss\nwith Real Emphasis and Fake Dispersion framework, a Conformer classification\nnetwork, and ensemble score-embedding fusion. The N-pair loss improves\ndiscriminative ability, while Real Emphasis and Fake Dispersion enhance\nrobustness by focusing on differentiating real and fake speech patterns. The\nConformer network captures both global and local dependencies in the audio\nsignal, crucial for source tracing. The proposed ensemble score-embedding\nfusion shows an optimal trade-off between in-domain and out-of-domain source\ntracing scenarios. We evaluate our method using Frechet Distance and standard\nmetrics, demonstrating superior performance in source tracing over the baseline\nsystem.", "AI": {"tldr": "A novel audio source tracing system combines deep metric multi-class N-pair loss, Real Emphasis and Fake Dispersion, a Conformer network, and ensemble score-embedding fusion to improve discriminative ability and robustness in tracing audio deepfake sources.", "motivation": "The increasing realism of audio deepfakes necessitates not just detection but also tracing the source system, which current research overlooks.", "method": "The system uses N-pair loss for discriminative ability, Real Emphasis and Fake Dispersion for robustness, a Conformer network for capturing audio dependencies, and ensemble score-embedding fusion for optimal performance.", "result": "The method outperforms baselines in source tracing, evaluated using Frechet Distance and standard metrics.", "conclusion": "The proposed system effectively addresses the challenge of tracing audio deepfake sources with superior performance."}}
{"id": "2506.02055", "pdf": "https://arxiv.org/pdf/2506.02055", "abs": "https://arxiv.org/abs/2506.02055", "authors": ["Nikola Balic"], "title": "Will Agents Replace Us? Perceptions of Autonomous Multi-Agent AI", "categories": ["cs.CY", "cs.AI", "cs.MA", "I.2.m"], "comment": "15 pages, 5 figures, code available at\n  https://github.com/nibzard/agent-perceptions", "summary": "Autonomous multi-agent AI systems are poised to transform various industries,\nparticularly software development and knowledge work. Understanding current\nperceptions among professionals is crucial for anticipating adoption\nchallenges, ethical considerations, and future workforce development. This\nstudy analyzes responses from 130 participants to a survey on the capabilities,\nimpact, and governance of AI agents. We explore expected timelines for AI\nreplacing programmers, identify perceived barriers to deployment, and examine\nbeliefs about responsibility when agents make critical decisions. Key findings\nreveal three distinct clusters of respondents. While the study explored factors\nassociated with current AI agent deployment, the initial logistic regression\nmodel did not yield statistically significant predictors, suggesting that\ndeployment decisions are complex and may be influenced by factors not fully\ncaptured or that a larger sample is needed. These insights highlight the need\nfor organizations to address compliance concerns (a commonly cited barrier) and\nestablish clear governance frameworks as they integrate autonomous agents into\ntheir workflows.", "AI": {"tldr": "Survey of 130 professionals on AI agent adoption reveals mixed perceptions, with no clear predictors of deployment, emphasizing the need for governance and compliance.", "motivation": "To understand current professional perceptions of AI agents in software development and knowledge work, anticipating adoption challenges and ethical concerns.", "method": "Survey of 130 participants, analyzing responses on AI capabilities, impact, governance, and barriers. Logistic regression used to explore deployment factors.", "result": "Three respondent clusters identified; no significant predictors of deployment found. Compliance concerns and governance frameworks are key barriers.", "conclusion": "Organizations must address compliance and governance to integrate AI agents effectively, as deployment decisions are complex and lack clear predictors."}}
{"id": "2506.02149", "pdf": "https://arxiv.org/pdf/2506.02149", "abs": "https://arxiv.org/abs/2506.02149", "authors": ["Wenjun Xia", "Chuang Niu", "Ge Wang"], "title": "Tomographic Foundation Model -- FORCE: Flow-Oriented Reconstruction Conditioning Engine", "categories": ["eess.IV", "cs.LG", "eess.SP"], "comment": null, "summary": "Computed tomography (CT) is a major medical imaging modality. Clinical CT\nscenarios, such as low-dose screening, sparse-view scanning, and metal\nimplants, often lead to severe noise and artifacts in reconstructed images,\nrequiring improved reconstruction techniques. The introduction of deep learning\nhas significantly advanced CT image reconstruction. However, obtaining paired\ntraining data remains rather challenging due to patient motion and other\nconstraints. Although deep learning methods can still perform well with\napproximately paired data, they inherently carry the risk of hallucination due\nto data inconsistencies and model instability. In this paper, we integrate the\ndata fidelity with the state-of-the-art generative AI model, referred to as the\nPoisson flow generative model (PFGM) with a generalized version PFGM++, and\npropose a novel CT framework: Flow-Oriented Reconstruction Conditioning Engine\n(FORCE). In our experiments, the proposed method shows superior performance in\nvarious CT imaging tasks, outperforming existing unsupervised reconstruction\napproaches.", "AI": {"tldr": "A novel CT framework, FORCE, integrates data fidelity with PFGM++ to improve reconstruction, outperforming unsupervised methods despite challenges in paired training data.", "motivation": "Clinical CT scenarios often suffer from noise and artifacts, requiring better reconstruction techniques. Deep learning helps but faces challenges like data inconsistency and hallucination risks.", "method": "Proposes FORCE, combining data fidelity with PFGM++, a generative AI model, for CT reconstruction.", "result": "FORCE shows superior performance in various CT tasks compared to existing unsupervised methods.", "conclusion": "FORCE effectively addresses CT reconstruction challenges, offering improved performance without relying on perfectly paired data."}}
{"id": "2506.02014", "pdf": "https://arxiv.org/pdf/2506.02014", "abs": "https://arxiv.org/abs/2506.02014", "authors": ["Wang Mengjie", "Zhu Huiping", "Li Jian", "Shi Wenxiu", "Zhang Song"], "title": "Research on Driving Scenario Technology Based on Multimodal Large Lauguage Model Optimization", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "With the advancement of autonomous and assisted driving technologies, higher\ndemands are placed on the ability to understand complex driving scenarios.\nMultimodal general large models have emerged as a solution for this challenge.\nHowever, applying these models in vertical domains involves difficulties such\nas data collection, model training, and deployment optimization. This paper\nproposes a comprehensive method for optimizing multimodal models in driving\nscenarios, including cone detection, traffic light recognition, speed limit\nrecommendation, and intersection alerts. The method covers key aspects such as\ndynamic prompt optimization, dataset construction, model training, and\ndeployment. Specifically, the dynamic prompt optimization adjusts the prompts\nbased on the input image content to focus on objects affecting the ego vehicle,\nenhancing the model's task-specific focus and judgment capabilities. The\ndataset is constructed by combining real and synthetic data to create a\nhigh-quality and diverse multimodal training dataset, improving the model's\ngeneralization in complex driving environments. In model training, advanced\ntechniques like knowledge distillation, dynamic fine-tuning, and quantization\nare integrated to reduce storage and computational costs while boosting\nperformance. Experimental results show that this systematic optimization method\nnot only significantly improves the model's accuracy in key tasks but also\nachieves efficient resource utilization, providing strong support for the\npractical application of driving scenario perception technologies.", "AI": {"tldr": "The paper proposes a method to optimize multimodal models for driving scenarios, addressing challenges like data collection, training, and deployment. It improves accuracy and efficiency through dynamic prompt optimization, hybrid datasets, and advanced training techniques.", "motivation": "The need for better understanding of complex driving scenarios in autonomous and assisted driving technologies drives the development of optimized multimodal models.", "method": "The method includes dynamic prompt optimization, hybrid dataset construction (real and synthetic data), and advanced training techniques like knowledge distillation and quantization.", "result": "Experiments show improved accuracy in tasks like cone detection and traffic light recognition, along with efficient resource utilization.", "conclusion": "The systematic optimization method enhances model performance and practicality for driving scenario perception technologies."}}
{"id": "2506.01964", "pdf": "https://arxiv.org/pdf/2506.01964", "abs": "https://arxiv.org/abs/2506.01964", "authors": ["Kamal Acharya", "Mehul Lad", "Liang Sun", "Houbing Song"], "title": "A Data-Driven Approach to Enhancing Gravity Models for Trip Demand Prediction", "categories": ["cs.LG"], "comment": "6 pages, 3 figures, IEEE CAI-2025", "summary": "Accurate prediction of trips between zones is critical for transportation\nplanning, as it supports resource allocation and infrastructure development\nacross various modes of transport. Although the gravity model has been widely\nused due to its simplicity, it often inadequately represents the complex\nfactors influencing modern travel behavior. This study introduces a data-driven\napproach to enhance the gravity model by integrating geographical, economic,\nsocial, and travel data from the counties in Tennessee and New York state.\nUsing machine learning techniques, we extend the capabilities of the\ntraditional model to handle more complex interactions between variables. Our\nexperiments demonstrate that machine learning-enhanced models significantly\noutperform the traditional model. Our results show a 51.48% improvement in\nR-squared, indicating a substantial enhancement in the model's explanatory\npower. Also, a 63.59% reduction in Mean Absolute Error (MAE) reflects a\nsignificant increase in prediction accuracy. Furthermore, a 44.32% increase in\nCommon Part of Commuters (CPC) demonstrates improved prediction reliability.\nThese findings highlight the substantial benefits of integrating diverse\ndatasets and advanced algorithms into transportation models. They provide urban\nplanners and policymakers with more reliable forecasting and decision-making\ntools.", "AI": {"tldr": "A data-driven approach enhances the gravity model for trip prediction by integrating diverse datasets and machine learning, significantly improving accuracy and reliability.", "motivation": "Traditional gravity models inadequately represent modern travel behavior, necessitating improved methods for transportation planning.", "method": "Machine learning techniques are applied to extend the gravity model using geographical, economic, social, and travel data from Tennessee and New York.", "result": "The enhanced model shows a 51.48% R-squared improvement, 63.59% MAE reduction, and 44.32% CPC increase.", "conclusion": "Integrating diverse datasets and advanced algorithms provides more reliable tools for urban planners and policymakers."}}
{"id": "2506.02153", "pdf": "https://arxiv.org/pdf/2506.02153", "abs": "https://arxiv.org/abs/2506.02153", "authors": ["Peter Belcak", "Greg Heinrich", "Shizhe Diao", "Yonggan Fu", "Xin Dong", "Saurav Muralidharan", "Yingyan Celine Lin", "Pavlo Molchanov"], "title": "Small Language Models are the Future of Agentic AI", "categories": ["cs.AI"], "comment": null, "summary": "Large language models (LLMs) are often praised for exhibiting near-human\nperformance on a wide range of tasks and valued for their ability to hold a\ngeneral conversation. The rise of agentic AI systems is, however, ushering in a\nmass of applications in which language models perform a small number of\nspecialized tasks repetitively and with little variation.\n  Here we lay out the position that small language models (SLMs) are\nsufficiently powerful, inherently more suitable, and necessarily more\neconomical for many invocations in agentic systems, and are therefore the\nfuture of agentic AI. Our argumentation is grounded in the current level of\ncapabilities exhibited by SLMs, the common architectures of agentic systems,\nand the economy of LM deployment. We further argue that in situations where\ngeneral-purpose conversational abilities are essential, heterogeneous agentic\nsystems (i.e., agents invoking multiple different models) are the natural\nchoice. We discuss the potential barriers for the adoption of SLMs in agentic\nsystems and outline a general LLM-to-SLM agent conversion algorithm.\n  Our position, formulated as a value statement, highlights the significance of\nthe operational and economic impact even a partial shift from LLMs to SLMs is\nto have on the AI agent industry. We aim to stimulate the discussion on the\neffective use of AI resources and hope to advance the efforts to lower the\ncosts of AI of the present day. Calling for both contributions to and critique\nof our position, we commit to publishing all such correspondence at\nhttps://research.nvidia.com/labs/lpr/slm-agents.", "AI": {"tldr": "The paper argues that small language models (SLMs) are more suitable and economical than large language models (LLMs) for agentic AI systems, proposing SLMs as the future of such systems.", "motivation": "To address the inefficiency and high costs of using LLMs in repetitive, specialized tasks within agentic AI systems.", "method": "The argument is based on current SLM capabilities, agentic system architectures, and deployment economics, with a proposed LLM-to-SLM conversion algorithm.", "result": "SLMs are deemed sufficiently powerful and economical for many agentic tasks, with heterogeneous systems suggested for general-purpose needs.", "conclusion": "The paper advocates for a shift from LLMs to SLMs in agentic AI, emphasizing operational and economic benefits, and invites further discussion."}}
{"id": "2506.02041", "pdf": "https://arxiv.org/pdf/2506.02041", "abs": "https://arxiv.org/abs/2506.02041", "authors": ["Duzhen Zhang", "Yong Ren", "Zhong-Zhi Li", "Yahan Yu", "Jiahua Dong", "Chenxing Li", "Zhilong Ji", "Jinfeng Bai"], "title": "Enhancing Multimodal Continual Instruction Tuning with BranchLoRA", "categories": ["cs.CL", "cs.AI"], "comment": "Accepted by ACL2025 Main Conference", "summary": "Multimodal Continual Instruction Tuning (MCIT) aims to finetune Multimodal\nLarge Language Models (MLLMs) to continually align with human intent across\nsequential tasks. Existing approaches often rely on the Mixture-of-Experts\n(MoE) LoRA framework to preserve previous instruction alignments. However,\nthese methods are prone to Catastrophic Forgetting (CF), as they aggregate all\nLoRA blocks via simple summation, which compromises performance over time. In\nthis paper, we identify a critical parameter inefficiency in the MoELoRA\nframework within the MCIT context. Based on this insight, we propose\nBranchLoRA, an asymmetric framework to enhance both efficiency and performance.\nTo mitigate CF, we introduce a flexible tuning-freezing mechanism within\nBranchLoRA, enabling branches to specialize in intra-task knowledge while\nfostering inter-task collaboration. Moreover, we incrementally incorporate\ntask-specific routers to ensure an optimal branch distribution over time,\nrather than favoring the most recent task. To streamline inference, we\nintroduce a task selector that automatically routes test inputs to the\nappropriate router without requiring task identity. Extensive experiments on\nthe latest MCIT benchmark demonstrate that BranchLoRA significantly outperforms\nMoELoRA and maintains its superiority across various MLLM sizes.", "AI": {"tldr": "BranchLoRA improves multimodal continual instruction tuning by addressing parameter inefficiency and catastrophic forgetting in MoELoRA, using asymmetric tuning-freezing and task-specific routers.", "motivation": "Existing MoELoRA methods in MCIT suffer from catastrophic forgetting and parameter inefficiency, limiting performance over sequential tasks.", "method": "Proposes BranchLoRA with a tuning-freezing mechanism for intra-task specialization and inter-task collaboration, plus task-specific routers and a task selector for inference.", "result": "BranchLoRA outperforms MoELoRA on MCIT benchmarks and maintains performance across MLLM sizes.", "conclusion": "BranchLoRA effectively mitigates catastrophic forgetting and enhances efficiency in multimodal continual instruction tuning."}}
{"id": "2506.02574", "pdf": "https://arxiv.org/pdf/2506.02574", "abs": "https://arxiv.org/abs/2506.02574", "authors": ["Shuai Yuan", "Shuang Chen", "Tianwu Lin", "Jie Wang", "Peng Gong"], "title": "Dynamic mapping from static labels: remote sensing dynamic sample generation with temporal-spectral embedding", "categories": ["eess.IV", "cs.CV", "cs.MM"], "comment": null, "summary": "Accurate remote sensing geographic mapping depends heavily on representative\nand timely sample data. However, rapid changes in land surface dynamics\nnecessitate frequent updates, quickly rendering previously collected samples\nobsolete and imposing significant labor demands for continuous manual updates.\nIn this study, we aim to address this problem by dynamic sample generation\nusing existing single-date static labeled samples. We introduce TasGen, a\ntwo-stage automated framework to automatically generate dynamic samples,\ndesigned to simultaneously model spectral and temporal dependencies in\ntime-series remote sensing imagery via temporal-spectral embedding, capturing\nland surface changes without additional manual annotations.", "AI": {"tldr": "TasGen automates dynamic sample generation for remote sensing mapping, eliminating manual updates by leveraging temporal-spectral embedding.", "motivation": "Rapid land surface changes make static samples obsolete quickly, requiring labor-intensive manual updates.", "method": "TasGen uses a two-stage framework with temporal-spectral embedding to model spectral and temporal dependencies in time-series imagery.", "result": "The method generates dynamic samples without additional manual annotations.", "conclusion": "TasGen offers an efficient solution for maintaining up-to-date remote sensing maps."}}
{"id": "2506.02230", "pdf": "https://arxiv.org/pdf/2506.02230", "abs": "https://arxiv.org/abs/2506.02230", "authors": ["Orchid Chetia Phukan", "Girish", "Mohd Mujtaba Akhtar", "Shubham Singh", "Swarup Ranjan Behera", "Vandana Rajan", "Muskaan Singh", "Arun Balaji Buduru", "Rajesh Sharma"], "title": "Towards Machine Unlearning for Paralinguistic Speech Processing", "categories": ["eess.AS", "cs.SD"], "comment": "Accepted to INTERSPEECH 2025", "summary": "In this work, we pioneer the study of Machine Unlearning (MU) for\nParalinguistic Speech Processing (PSP). We focus on two key PSP tasks: Speech\nEmotion Recognition (SER) and Depression Detection (DD). To this end, we\npropose, SISA++, a novel extension to previous state-of-the-art (SOTA) MU\nmethod, SISA by merging models trained on different shards with\nweight-averaging. With such modifications, we show that SISA++ preserves\nperformance more in comparison to SISA after unlearning in benchmark SER\n(CREMA-D) and DD (E-DAIC) datasets. Also, to guide future research for easier\nadoption of MU for PSP, we present ``cookbook recipes'' - actionable\nrecommendations for selecting optimal feature representations and downstream\narchitectures that can mitigate performance degradation after the unlearning\nprocess.", "AI": {"tldr": "SISA++ improves Machine Unlearning (MU) for Paralinguistic Speech Processing (PSP), outperforming SOTA method SISA in tasks like Speech Emotion Recognition (SER) and Depression Detection (DD).", "motivation": "To address the need for effective unlearning in PSP tasks (SER and DD) while preserving performance.", "method": "Proposes SISA++, an extension of SISA, using weight-averaging of models trained on shards. Provides 'cookbook recipes' for feature and architecture selection.", "result": "SISA++ shows better performance preservation post-unlearning in SER (CREMA-D) and DD (E-DAIC) datasets compared to SISA.", "conclusion": "SISA++ is effective for MU in PSP, with practical guidelines for future research."}}
{"id": "2506.02088", "pdf": "https://arxiv.org/pdf/2506.02088", "abs": "https://arxiv.org/abs/2506.02088", "authors": ["Alef Iury Siqueira Ferreira", "Lucas Rafael Gris", "Alexandre Ferro Filho", "Lucas \u00d3lives", "Daniel Ribeiro", "Luiz Fernando", "Fernanda Lustosa", "Rodrigo Tanaka", "Frederico Santos de Oliveira", "Arlindo Galv\u00e3o Filho"], "title": "Enhancing Speech Emotion Recognition with Graph-Based Multimodal Fusion and Prosodic Features for the Speech Emotion Recognition in Naturalistic Conditions Challenge at Interspeech 2025", "categories": ["cs.SD", "cs.CL", "cs.LG"], "comment": null, "summary": "Training SER models in natural, spontaneous speech is especially challenging\ndue to the subtle expression of emotions and the unpredictable nature of\nreal-world audio. In this paper, we present a robust system for the INTERSPEECH\n2025 Speech Emotion Recognition in Naturalistic Conditions Challenge, focusing\non categorical emotion recognition. Our method combines state-of-the-art audio\nmodels with text features enriched by prosodic and spectral cues. In\nparticular, we investigate the effectiveness of Fundamental Frequency (F0)\nquantization and the use of a pretrained audio tagging model. We also employ an\nensemble model to improve robustness. On the official test set, our system\nachieved a Macro F1-score of 39.79% (42.20% on validation). Our results\nunderscore the potential of these methods, and analysis of fusion techniques\nconfirmed the effectiveness of Graph Attention Networks. Our source code is\npublicly available.", "AI": {"tldr": "A robust system for Speech Emotion Recognition (SER) in naturalistic conditions, combining audio and text features with prosodic cues, achieves a Macro F1-score of 39.79%.", "motivation": "Challenges in training SER models due to subtle emotions and unpredictable real-world audio conditions.", "method": "Combines state-of-the-art audio models with text features, investigates F0 quantization, uses a pretrained audio tagging model, and employs an ensemble model.", "result": "Achieved a Macro F1-score of 39.79% (42.20% on validation).", "conclusion": "The methods show potential, with Graph Attention Networks proving effective for fusion techniques."}}
{"id": "2506.02193", "pdf": "https://arxiv.org/pdf/2506.02193", "abs": "https://arxiv.org/abs/2506.02193", "authors": ["Eden Hartman", "Dinesh Kumar Baghel", "Erel Segal-Halevi"], "title": "Fairly Wired: Towards Leximin-Optimal Division of Electricity", "categories": ["cs.GT", "cs.DS", "cs.MA"], "comment": null, "summary": "In many parts of the world - particularly in developing countries - the\ndemand for electricity exceeds the available supply. In such cases, it is\nimpossible to provide electricity to all households simultaneously. This raises\na fundamental question: how should electricity be allocated fairly? In this\npaper, we explore this question through the lens of egalitarianism - a\nprinciple that emphasizes equality by prioritizing the welfare of the worst-off\nhouseholds. One natural rule that aligns with this principle is to maximize the\negalitarian welfare - the smallest utility across all households. We show that\ncomputing such an allocation is NP-hard, even under strong simplifying\nassumptions. Leximin is a stronger fairness notion that generalizes the\negalitarian welfare: it also requires to maximize the smallest utility, but\nthen, subject to that, the second-smallest, then the third, and so on. The\nhardness results extends directly to leximin as well. Despite this, we present\na Fully Polynomial-Time Approximation Scheme (FPTAS) for leximin in the special\ncase where the network connectivity graph is a tree. This means that we can\nefficiently approximate leximin - and, in particular, the egalitarian welfare -\nto any desired level of accuracy.", "AI": {"tldr": "The paper addresses fair electricity allocation in resource-scarce regions using egalitarian principles, proving NP-hardness for exact solutions but offering an efficient approximation for tree-structured networks.", "motivation": "The demand for electricity exceeds supply in many developing regions, necessitating fair allocation methods prioritizing the worst-off households.", "method": "The study employs egalitarian welfare and leximin fairness principles, analyzing computational complexity and proposing an FPTAS for tree networks.", "result": "Computing exact egalitarian or leximin allocations is NP-hard, but an efficient approximation is achievable for tree networks.", "conclusion": "The paper provides a practical solution for fair electricity allocation in tree-structured networks despite theoretical hardness."}}
{"id": "2506.02197", "pdf": "https://arxiv.org/pdf/2506.02197", "abs": "https://arxiv.org/abs/2506.02197", "authors": ["Marcos V. Conde", "Radu Timofte", "Zihao Lu", "Xiangyu Kongand Xiaoxia Xingand Fan Wangand Suejin Hanand MinKyu Parkand Tianyu Zhangand Xin Luoand Yeda Chenand Dong Liuand Li Pangand Yuhang Yangand Hongzhong Wangand Xiangyong Caoand Ruixuan Jiangand Senyan Xuand Siyuan Jiangand Xueyang Fuand Zheng-Jun Zhaand Tianyu Haoand Yuhong Heand Ruoqi Liand Yueqi Yangand Xiang Yuand Guanlan Hongand Minmin Yiand Yuanjia Chenand Liwen Zhangand Zijie Jinand Cheng Liand Lian Liuand Wei Songand Heng Sunand Yubo Wangand Jinghua Wangand Jiajie Luand Watchara Ruangsangand"], "title": "NTIRE 2025 Challenge on RAW Image Restoration and Super-Resolution", "categories": ["eess.IV", "cs.CV"], "comment": "CVPR 2025 - New Trends in Image Restoration and Enhancement (NTIRE)", "summary": "This paper reviews the NTIRE 2025 RAW Image Restoration and Super-Resolution\nChallenge, highlighting the proposed solutions and results. New methods for RAW\nRestoration and Super-Resolution could be essential in modern Image Signal\nProcessing (ISP) pipelines, however, this problem is not as explored as in the\nRGB domain. The goal of this challenge is two fold, (i) restore RAW images with\nblur and noise degradations, (ii) upscale RAW Bayer images by 2x, considering\nunknown noise and blur. In the challenge, a total of 230 participants\nregistered, and 45 submitted results during thee challenge period. This report\npresents the current state-of-the-art in RAW Restoration.", "AI": {"tldr": "The paper reviews the NTIRE 2025 RAW Image Restoration and Super-Resolution Challenge, showcasing solutions and results for restoring and upscaling RAW images.", "motivation": "To advance RAW image restoration and super-resolution, areas less explored compared to RGB domain, and to benchmark state-of-the-art methods.", "method": "Participants developed solutions for (i) restoring RAW images with blur/noise and (ii) 2x upscaling RAW Bayer images under unknown noise/blur.", "result": "230 participants registered, 45 submitted results, revealing current state-of-the-art in RAW restoration.", "conclusion": "The challenge highlights progress and sets benchmarks for RAW image restoration and super-resolution."}}
{"id": "2506.02015", "pdf": "https://arxiv.org/pdf/2506.02015", "abs": "https://arxiv.org/abs/2506.02015", "authors": ["Yoonjin Oh", "Yongjin Kim", "Hyomin Kim", "Donghwan Chi", "Sungwoong Kim"], "title": "Object-centric Self-improving Preference Optimization for Text-to-Image Generation", "categories": ["cs.CV"], "comment": null, "summary": "Recent advancements in Multimodal Large Language Models (MLLMs) have\nsignificantly improved both image understanding and generation capabilities.\nDespite these improvements, MLLMs still struggle with fine-grained visual\ncomprehension, particularly in text-to-image generation tasks. While preference\noptimization methods have been explored to address these limitations in image\nunderstanding tasks, their application to image generation remains largely\nunderexplored. To address this gap, we propose an Object-centric Self-improving\nPreference Optimization (OSPO) framework designed for text-to-image generation\nby MLLMs. OSPO leverages the intrinsic reasoning abilities of MLLMs without\nrequiring any external datasets or models. OSPO emphasizes the importance of\nhigh-quality preference pair data, which is critical for effective preference\noptimization. To achieve this, it introduces a self-improving mechanism that\nautonomously constructs object-level contrastive preference pairs through\nobject-centric prompt perturbation, densification and VQA scoring. This process\neliminates ambiguous or disproportionate variations commonly found in naively\ngenerated preference pairs, thereby enhancing the effectiveness of preference\noptimization. We validate OSPO on three representative compositional\ntext-to-image benchmarks, demonstrating substantial performance gains over\nbaseline models.", "AI": {"tldr": "The paper introduces OSPO, a framework for improving text-to-image generation in MLLMs by autonomously creating high-quality preference pairs through object-centric methods, outperforming baselines.", "motivation": "MLLMs lack fine-grained visual comprehension in text-to-image tasks, and preference optimization for generation is underexplored.", "method": "OSPO uses MLLMs' reasoning to autonomously generate object-level contrastive preference pairs via prompt perturbation, densification, and VQA scoring.", "result": "OSPO shows significant performance gains on three compositional text-to-image benchmarks.", "conclusion": "OSPO effectively addresses fine-grained generation challenges in MLLMs without external data or models."}}
{"id": "2506.01965", "pdf": "https://arxiv.org/pdf/2506.01965", "abs": "https://arxiv.org/abs/2506.01965", "authors": ["Bonpagna Kann", "Sandra Castellanos-Paez", "Romain Rombourg", "Philippe Lalanda"], "title": "TaskVAE: Task-Specific Variational Autoencoders for Exemplar Generation in Continual Learning for Human Activity Recognition", "categories": ["cs.LG", "cs.AI"], "comment": "9 pages, 5 figures, 3 tables", "summary": "As machine learning based systems become more integrated into daily life,\nthey unlock new opportunities but face the challenge of adapting to dynamic\ndata environments. Various forms of data shift-gradual, abrupt, or\ncyclic-threaten model accuracy, making continual adaptation essential.\nContinual Learning (CL) enables models to learn from evolving data streams\nwhile minimizing forgetting of prior knowledge. Among CL strategies,\nreplay-based methods have proven effective, but their success relies on\nbalancing memory constraints and retaining old class accuracy while learning\nnew classes. This paper presents TaskVAE, a framework for replay-based CL in\nclass-incremental settings. TaskVAE employs task-specific Variational\nAutoencoders (VAEs) to generate synthetic exemplars from previous tasks, which\nare then used to train the classifier alongside new task data. In contrast to\ntraditional methods that require prior knowledge of the total class count or\nrely on a single VAE for all tasks, TaskVAE adapts flexibly to increasing tasks\nwithout such constraints. We focus on Human Activity Recognition (HAR) using\nIMU sensor-equipped devices. Unlike previous HAR studies that combine data\nacross all users, our approach focuses on individual user data, better\nreflecting real-world scenarios where a person progressively learns new\nactivities. Extensive experiments on 5 different HAR datasets show that TaskVAE\noutperforms experience replay methods, particularly with limited data, and\nexhibits robust performance as dataset size increases. Additionally, memory\nfootprint of TaskVAE is minimal, being equivalent to only 60 samples per task,\nwhile still being able to generate an unlimited number of synthetic samples.\nThe contributions lie in balancing memory constraints, task-specific\ngeneration, and long-term stability, making it a reliable solution for\nreal-world applications in domains like HAR.", "AI": {"tldr": "TaskVAE is a replay-based continual learning framework using task-specific VAEs to generate synthetic exemplars, outperforming traditional methods in class-incremental settings, especially for Human Activity Recognition (HAR).", "motivation": "Machine learning systems need continual adaptation to dynamic data environments, but balancing memory constraints and retaining old knowledge is challenging.", "method": "TaskVAE employs task-specific Variational Autoencoders (VAEs) to generate synthetic exemplars from prior tasks, training the classifier alongside new data without requiring prior knowledge of total class count.", "result": "TaskVAE outperforms experience replay methods, especially with limited data, and maintains robust performance as dataset size grows, with minimal memory footprint (60 samples per task).", "conclusion": "TaskVAE balances memory constraints, task-specific generation, and long-term stability, making it a reliable solution for real-world applications like HAR."}}
{"id": "2506.02158", "pdf": "https://arxiv.org/pdf/2506.02158", "abs": "https://arxiv.org/abs/2506.02158", "authors": ["Ruhana Azam", "Aditya Vempaty", "Ashish Jagmohan"], "title": "Reflection-Based Memory For Web navigation Agents", "categories": ["cs.AI"], "comment": null, "summary": "Web navigation agents have made significant progress, yet current systems\noperate with no memory of past experiences -- leading to repeated mistakes and\nan inability to learn from previous interactions. We introduce\nReflection-Augment Planning (ReAP), a web navigation system to leverage both\nsuccessful and failed past experiences using self-reflections. Our method\nimproves baseline results by 11 points overall and 29 points on previously\nfailed tasks. These findings demonstrate that reflections can transfer to\ndifferent web navigation tasks.", "AI": {"tldr": "ReAP improves web navigation by using past experiences and self-reflections, boosting performance by 11 points overall and 29 points on failed tasks.", "motivation": "Current web navigation agents lack memory, causing repeated mistakes and missed learning opportunities.", "method": "Introduces Reflection-Augment Planning (ReAP) to leverage past experiences via self-reflections.", "result": "Improves baseline by 11 points overall and 29 points on failed tasks.", "conclusion": "Reflections enhance performance and transferability across web navigation tasks."}}
{"id": "2506.02058", "pdf": "https://arxiv.org/pdf/2506.02058", "abs": "https://arxiv.org/abs/2506.02058", "authors": ["Xiang Li", "Jiayi Xin", "Qi Long", "Weijie J. Su"], "title": "Evaluating the Unseen Capabilities: How Many Theorems Do LLMs Know?", "categories": ["cs.CL", "cs.IR", "cs.LG", "stat.AP", "stat.ME"], "comment": null, "summary": "Accurate evaluation of large language models (LLMs) is crucial for\nunderstanding their capabilities and guiding their development. However,\ncurrent evaluations often inconsistently reflect the actual capacities of these\nmodels. In this paper, we demonstrate that one of many contributing factors to\nthis \\textit{evaluation crisis} is the oversight of unseen knowledge --\ninformation encoded by LLMs but not directly observed or not yet observed\nduring evaluations. We introduce KnowSum, a statistical framework designed to\nprovide a more comprehensive assessment by quantifying the unseen knowledge for\na class of evaluation tasks. KnowSum estimates the unobserved portion by\nextrapolating from the appearance frequencies of observed knowledge instances.\nWe demonstrate the effectiveness and utility of KnowSum across three critical\napplications: estimating total knowledge, evaluating information retrieval\neffectiveness, and measuring output diversity. Our experiments reveal that a\nsubstantial volume of knowledge is omitted when relying solely on observed LLM\nperformance. Importantly, KnowSum yields significantly different comparative\nrankings for several common LLMs based on their internal knowledge.", "AI": {"tldr": "The paper introduces KnowSum, a framework to address the 'evaluation crisis' in LLMs by quantifying unseen knowledge, improving assessment accuracy.", "motivation": "Current LLM evaluations inconsistently reflect actual capabilities due to overlooking unseen knowledge.", "method": "KnowSum uses statistical extrapolation from observed knowledge frequencies to estimate unseen knowledge.", "result": "Experiments show significant omitted knowledge in standard evaluations, altering LLM rankings.", "conclusion": "KnowSum provides a more comprehensive LLM evaluation, revealing hidden knowledge and improving comparative assessments."}}
{"id": "2506.03144", "pdf": "https://arxiv.org/pdf/2506.03144", "abs": "https://arxiv.org/abs/2506.03144", "authors": ["Wei Chow", "Yuan Gao", "Linfeng Li", "Xian Wang", "Qi Xu", "Hang Song", "Lingdong Kong", "Ran Zhou", "Yi Zeng", "Yidong Cai", "Botian Jiang", "Shilin Xu", "Jiajun Zhang", "Minghui Qiu", "Xiangtai Li", "Tianshu Yang", "Siliang Tang", "Juncheng Li"], "title": "MERIT: Multilingual Semantic Retrieval with Interleaved Multi-Condition Query", "categories": ["cs.CV", "cs.CL", "cs.MM"], "comment": "Preprint; Project Page, Code, and Dataset at:\n  https://merit-2025.github.io/", "summary": "Semantic retrieval is crucial for modern applications yet remains\nunderexplored in current research. Existing datasets are limited to single\nlanguages, single images, or singular retrieval conditions, often failing to\nfully exploit the expressive capacity of visual information as evidenced by\nmaintained performance when images are replaced with captions. However,\npractical retrieval scenarios frequently involve interleaved multi-condition\nqueries with multiple images. Hence, this paper introduces MERIT, the first\nmultilingual dataset for interleaved multi-condition semantic retrieval,\ncomprising 320,000 queries with 135,000 products in 5 languages, covering 7\ndistinct product categories. Extensive experiments on MERIT identify existing\nmodels's limitation: focusing solely on global semantic information while\nneglecting specific conditional elements in queries. Consequently, we propose\nCoral, a novel fine-tuning framework that adapts pre-trained MLLMs by\nintegrating embedding reconstruction to preserve fine-grained conditional\nelements and contrastive learning to extract comprehensive global semantics.\nExperiments demonstrate that Coral achieves a 45.9% performance improvement\nover conventional approaches on MERIT, with strong generalization capabilities\nvalidated across 8 established retrieval benchmarks. Collectively, our\ncontributions - a novel dataset, identification of critical limitations in\nexisting approaches, and an innovative fine-tuning framework - establish a\nfoundation for future research in interleaved multi-condition semantic\nretrieval.", "AI": {"tldr": "The paper introduces MERIT, a multilingual dataset for multi-condition semantic retrieval, and Coral, a fine-tuning framework that improves retrieval performance by 45.9%.", "motivation": "Existing datasets and models for semantic retrieval are limited, failing to handle multi-condition queries effectively.", "method": "Proposes Coral, a framework combining embedding reconstruction and contrastive learning to adapt pre-trained MLLMs.", "result": "Coral achieves a 45.9% performance improvement on MERIT and generalizes well across 8 benchmarks.", "conclusion": "The contributions (dataset, limitation identification, and framework) advance research in multi-condition semantic retrieval."}}
{"id": "2506.02232", "pdf": "https://arxiv.org/pdf/2506.02232", "abs": "https://arxiv.org/abs/2506.02232", "authors": ["Orchid Chetia Phukan", "Girish", "Mohd Mujtaba Akhtar", "Swarup Ranjan Behera", "Pailla Balakrishna Reddy", "Arun Balaji Buduru", "Rajesh Sharma"], "title": "Investigating the Reasonable Effectiveness of Speaker Pre-Trained Models and their Synergistic Power for SingMOS Prediction", "categories": ["eess.AS", "cs.SD"], "comment": "Accepted to INTERSPEECH 2025", "summary": "In this study, we focus on Singing Voice Mean Opinion Score (SingMOS)\nprediction. Previous research have shown the performance benefit with the use\nof state-of-the-art (SOTA) pre-trained models (PTMs). However, they haven't\nexplored speaker recognition speech PTMs (SPTMs) such as x-vector, ECAPA and we\nhypothesize that it will be the most effective for SingMOS prediction. We\nbelieve that due to their speaker recognition pre-training, it equips them to\ncapture fine-grained vocal features (e.g., pitch, tone, intensity) from\nsynthesized singing voices in a much more better way than other PTMs. Our\nexperiments with SOTA PTMs including SPTMs and music PTMs validates the\nhypothesis. Additionally, we introduce a novel fusion framework, BATCH that\nuses Bhattacharya Distance for fusion of PTMs. Through BATCH with the fusion of\nspeaker recognition SPTMs, we report the topmost performance comparison to all\nthe individual PTMs and baseline fusion techniques as well as setting SOTA.", "AI": {"tldr": "The study explores SingMOS prediction using speaker recognition PTMs (SPTMs) and introduces BATCH, a fusion framework, achieving top performance.", "motivation": "Prior work used SOTA PTMs but overlooked SPTMs for SingMOS prediction. The hypothesis is that SPTMs, due to speaker recognition pre-training, better capture vocal features.", "method": "Experiments with SOTA PTMs (including SPTMs and music PTMs) validate the hypothesis. A novel fusion framework, BATCH, uses Bhattacharya Distance for PTM fusion.", "result": "SPTMs outperformed other PTMs. BATCH with SPTM fusion achieved top performance, surpassing individual PTMs and baseline fusion techniques.", "conclusion": "SPTMs are highly effective for SingMOS prediction. BATCH framework sets a new SOTA, demonstrating the value of speaker recognition PTMs in this domain."}}
{"id": "2506.02091", "pdf": "https://arxiv.org/pdf/2506.02091", "abs": "https://arxiv.org/abs/2506.02091", "authors": ["Bartosz Karpi\u0144ski", "Cyryl Leszczy\u0144ski"], "title": "Comparison of spectrogram scaling in multi-label Music Genre Recognition", "categories": ["cs.SD", "cs.LG", "eess.AS"], "comment": "14 pages, 10 figures", "summary": "As the accessibility and ease-of-use of digital audio workstations increases,\nso does the quantity of music available to the average listener; additionally,\ndifferences between genres are not always well defined and can be abstract,\nwith widely varying combinations of genres across individual records. In this\narticle, multiple preprocessing methods and approaches to model training are\ndescribed and compared, accounting for the eclectic nature of today's albums. A\ncustom, manually labeled dataset of more than 18000 entries has been used to\nperform the experiments.", "AI": {"tldr": "The paper explores preprocessing methods and model training approaches for genre classification in music, using a manually labeled dataset of 18,000 entries.", "motivation": "The rise in music availability and blurred genre boundaries necessitate better classification methods.", "method": "Multiple preprocessing techniques and model training approaches are compared.", "result": "Experiments are conducted using a custom dataset of over 18,000 entries.", "conclusion": "The study aims to improve genre classification accuracy in modern, eclectic music."}}
{"id": "2506.02951", "pdf": "https://arxiv.org/pdf/2506.02951", "abs": "https://arxiv.org/abs/2506.02951", "authors": ["Boyi Li", "Zhonghan Zhao", "Der-Horng Lee", "Gaoang Wang"], "title": "Adaptive Graph Pruning for Multi-Agent Communication", "categories": ["cs.CL", "cs.MA"], "comment": null, "summary": "Large Language Model (LLM) based multi-agent systems have shown remarkable\nperformance in various tasks, especially when enhanced through collaborative\ncommunication. However, current methods often rely on a fixed number of agents\nand static communication structures, limiting their ability to adapt to varying\ntask complexities. In this paper, we propose Adaptive Graph Pruning (AGP), a\nnovel task-adaptive multi-agent collaboration framework that jointly optimizes\nagent quantity (hard-pruning) and communication topology (soft-pruning).\nSpecifically, our method employs a two-stage training strategy: firstly,\nindependently training soft-pruning networks for different agent quantities to\ndetermine optimal agent-quantity-specific complete graphs and positional masks\nacross specific tasks; and then jointly optimizing hard-pruning and\nsoft-pruning within a maximum complete graph to dynamically configure the\nnumber of agents and their communication topologies per task. Extensive\nexperiments demonstrate that our approach is: (1) High-performing, achieving\nstate-of-the-art results across six benchmarks and consistently generalizes\nacross multiple mainstream LLM architectures, with a increase in performance of\n$2.58\\%\\sim 9.84\\%$; (2) Task-adaptive, dynamically constructing optimized\ncommunication topologies tailored to specific tasks, with an extremely high\nperformance in all three task categories (general reasoning, mathematical\nreasoning, and code generation); (3) Token-economical, having fewer training\nsteps and token consumption at the same time, with a decrease in token\nconsumption of $90\\%+$; and (4) Training-efficient, achieving high performance\nwith very few training steps compared with other methods. The performance will\nsurpass the existing baselines after about ten steps of training under six\nbenchmarks.", "AI": {"tldr": "AGP is a task-adaptive multi-agent framework optimizing agent quantity and communication topology, outperforming baselines in performance, adaptability, token efficiency, and training speed.", "motivation": "Current LLM-based multi-agent systems lack adaptability due to fixed agent numbers and static communication structures, limiting task performance.", "method": "AGP uses a two-stage training strategy: independently training soft-pruning networks for agent-specific graphs, then jointly optimizing hard- and soft-pruning for dynamic configuration.", "result": "Achieves state-of-the-art results (+2.58%~9.84%), adapts to tasks, reduces token consumption by 90%+, and trains efficiently (10 steps to surpass baselines).", "conclusion": "AGP is a high-performing, adaptable, and efficient framework for multi-agent collaboration, excelling across diverse tasks and LLM architectures."}}
{"id": "2506.02312", "pdf": "https://arxiv.org/pdf/2506.02312", "abs": "https://arxiv.org/abs/2506.02312", "authors": ["Md Tauhidul Islam", "Wu Da-Wen", "Tang Qing-Qing", "Zhao Kai-Yang", "Yin Teng", "Li Yan-Fei", "Shang Wen-Yi", "Liu Jing-Yu", "Zhang Hai-Xian"], "title": "Dual encoding feature filtering generalized attention UNET for retinal vessel segmentation", "categories": ["eess.IV", "cs.CV", "I.4; I.5"], "comment": null, "summary": "Retinal blood vessel segmentation is crucial for diagnosing ocular and\ncardiovascular diseases. Although the introduction of U-Net in 2015 by Olaf\nRonneberger significantly advanced this field, yet issues like limited training\ndata, imbalance data distribution, and inadequate feature extraction persist,\nhindering both the segmentation performance and optimal model generalization.\nAddressing these critical issues, the DEFFA-Unet is proposed featuring an\nadditional encoder to process domain-invariant pre-processed inputs, thereby\nimproving both richer feature encoding and enhanced model generalization. A\nfeature filtering fusion module is developed to ensure the precise feature\nfiltering and robust hybrid feature fusion. In response to the task-specific\nneed for higher precision where false positives are very costly, traditional\nskip connections are replaced with the attention-guided feature reconstructing\nfusion module. Additionally, innovative data augmentation and balancing methods\nare proposed to counter data scarcity and distribution imbalance, further\nboosting the robustness and generalization of the model. With a comprehensive\nsuite of evaluation metrics, extensive validations on four benchmark datasets\n(DRIVE, CHASEDB1, STARE, and HRF) and an SLO dataset (IOSTAR), demonstrate the\nproposed method's superiority over both baseline and state-of-the-art models.\nParticularly the proposed method significantly outperforms the compared methods\nin cross-validation model generalization.", "AI": {"tldr": "DEFFA-Unet improves retinal blood vessel segmentation by addressing data limitations and feature extraction issues, outperforming existing methods.", "motivation": "Existing methods like U-Net face challenges with limited training data, imbalance, and poor feature extraction, affecting segmentation and generalization.", "method": "DEFFA-Unet introduces an extra encoder for domain-invariant inputs, feature filtering fusion, attention-guided fusion, and novel data augmentation.", "result": "Outperforms baseline and state-of-the-art models on benchmark datasets (DRIVE, CHASEDB1, STARE, HRF, IOSTAR), especially in cross-validation.", "conclusion": "DEFFA-Unet enhances segmentation performance and generalization, making it superior for clinical applications."}}
{"id": "2506.02016", "pdf": "https://arxiv.org/pdf/2506.02016", "abs": "https://arxiv.org/abs/2506.02016", "authors": ["Nuolin Sun", "Linyuan Wang", "Dongyang Li", "Bin Yan", "Lei Li"], "title": "Are classical deep neural networks weakly adversarially robust?", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "Adversarial attacks have received increasing attention and it has been widely\nrecognized that classical DNNs have weak adversarial robustness. The most\ncommonly used adversarial defense method, adversarial training, improves the\nadversarial accuracy of DNNs by generating adversarial examples and retraining\nthe model. However, adversarial training requires a significant computational\noverhead. In this paper, inspired by existing studies focusing on the\nclustering properties of DNN output features at each layer and the Progressive\nFeedforward Collapse phenomenon, we propose a method for adversarial example\ndetection and image recognition that uses layer-wise features to construct\nfeature paths and computes the correlation between the examples feature paths\nand the class-centered feature paths. Experimental results show that the\nrecognition method achieves 82.77% clean accuracy and 44.17% adversarial\naccuracy on the ResNet-20 with PFC. Compared to the adversarial training method\nwith 77.64% clean accuracy and 52.94% adversarial accuracy, our method exhibits\na trade-off without relying on computationally expensive defense strategies.\nFurthermore, on the standard ResNet-18, our method maintains this advantage\nwith respective metrics of 80.01% and 46.1%. This result reveals inherent\nadversarial robustness in DNNs, challenging the conventional understanding of\nthe weak adversarial robustness in DNNs.", "AI": {"tldr": "The paper proposes a method for adversarial example detection and image recognition using layer-wise feature paths, achieving a trade-off between clean and adversarial accuracy without costly adversarial training.", "motivation": "Classical DNNs have weak adversarial robustness, and adversarial training, while effective, is computationally expensive. The study aims to leverage DNN layer features for robustness.", "method": "Constructs feature paths from layer-wise features and computes correlations with class-centered paths for adversarial detection and recognition.", "result": "Achieves 82.77% clean and 44.17% adversarial accuracy on ResNet-20, and 80.01% and 46.1% on ResNet-18, showing inherent robustness.", "conclusion": "The method reveals inherent adversarial robustness in DNNs, challenging conventional views, and offers a less computationally intensive alternative to adversarial training."}}
{"id": "2506.01966", "pdf": "https://arxiv.org/pdf/2506.01966", "abs": "https://arxiv.org/abs/2506.01966", "authors": ["Yuzhou Zhu"], "title": "Matrix Is All You Need", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Deep neural networks employ specialized architectures for vision, sequential\nand language tasks, yet this proliferation obscures their underlying\ncommonalities. We introduce a unified matrix-order framework that casts\nconvolutional, recurrent and self-attention operations as sparse matrix\nmultiplications. Convolution is realized via an upper-triangular weight matrix\nperforming first-order transformations; recurrence emerges from a\nlower-triangular matrix encoding stepwise updates; attention arises naturally\nas a third-order tensor factorization. We prove algebraic isomorphism with\nstandard CNN, RNN and Transformer layers under mild assumptions. Empirical\nevaluations on image classification (MNIST, CIFAR-10/100, Tiny ImageNet),\ntime-series forecasting (ETTh1, Electricity Load Diagrams) and language\nmodeling/classification (AG News, WikiText-2, Penn Treebank) confirm that\nsparse-matrix formulations match or exceed native model performance while\nconverging in comparable or fewer epochs. By reducing architecture design to\nsparse pattern selection, our matrix perspective aligns with GPU parallelism\nand leverages mature algebraic optimization tools. This work establishes a\nmathematically rigorous substrate for diverse neural architectures and opens\navenues for principled, hardware-aware network design.", "AI": {"tldr": "A unified matrix-order framework transforms convolutional, recurrent, and self-attention operations into sparse matrix multiplications, matching or outperforming native models while simplifying architecture design.", "motivation": "To unify diverse neural architectures (CNN, RNN, Transformer) under a common mathematical framework and leverage hardware optimization.", "method": "Represent CNN, RNN, and Transformer operations as sparse matrix multiplications (upper-triangular, lower-triangular, and tensor factorization).", "result": "Empirical tests show performance matches or exceeds native models, with comparable or faster convergence.", "conclusion": "The framework provides a rigorous mathematical basis for neural architectures and enables hardware-aware design."}}
{"id": "2506.02177", "pdf": "https://arxiv.org/pdf/2506.02177", "abs": "https://arxiv.org/abs/2506.02177", "authors": ["Haizhong Zheng", "Yang Zhou", "Brian R. Bartoldson", "Bhavya Kailkhura", "Fan Lai", "Jiawei Zhao", "Beidi Chen"], "title": "Act Only When It Pays: Efficient Reinforcement Learning for LLM Reasoning via Selective Rollouts", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "Reinforcement learning, such as PPO and GRPO, has powered recent\nbreakthroughs in LLM reasoning. Scaling rollout to sample more prompts enables\nmodels to selectively use higher-quality data for training, which can stabilize\nRL training and improve model performance. However, this comes at the cost of\nsignificant computational overhead. In this paper, we show that a substantial\nportion of this overhead can be avoided by skipping uninformative prompts\nbefore rollout. Our analysis of reward dynamics reveals a strong temporal\nconsistency in prompt value: prompts that are uninformative in one epoch of\ntraining are likely to remain uninformative in future epochs. Based on these\ninsights, we propose GRESO (GRPO with Efficient Selective Rollout), an online,\nlightweight pre-rollout filtering algorithm that predicts and skips\nuninformative prompts using reward training dynamics. By evaluating GRESO on a\nbroad range of math reasoning benchmarks and models, such as Qwen2.5-Math-1.5B,\nDeepSeek-R1-Distill-Qwen-1.5B, and Qwen2.5-Math-7B, we show that GRESO achieves\nup to 2.4x wall-clock time speedup in rollout and up to 2.0x speedup in total\ntraining time without accuracy degradation.", "AI": {"tldr": "GRESO, a lightweight pre-rollout filtering algorithm, skips uninformative prompts in RL training, saving computational overhead without accuracy loss.", "motivation": "Reducing computational overhead in RL training by avoiding uninformative prompts, leveraging temporal consistency in prompt value.", "method": "Proposes GRESO, an online filtering algorithm that predicts and skips uninformative prompts using reward dynamics.", "result": "Achieves up to 2.4x speedup in rollout and 2.0x in total training time without accuracy degradation.", "conclusion": "GRESO efficiently reduces computational costs in RL training while maintaining performance."}}
{"id": "2506.02126", "pdf": "https://arxiv.org/pdf/2506.02126", "abs": "https://arxiv.org/abs/2506.02126", "authors": ["Juncheng Wu", "Sheng Liu", "Haoqin Tu", "Hang Yu", "Xiaoke Huang", "James Zou", "Cihang Xie", "Yuyin Zhou"], "title": "Knowledge or Reasoning? A Close Look at How LLMs Think Across Domains", "categories": ["cs.CL"], "comment": "17 pages, preprint", "summary": "Recent advances in reasoning-enhanced Large Language Models such as\nOpenAI-o1/3 and DeepSeek-R1 have significantly improved performance on complex\ntasks. However, the quality and transparency of their internal reasoning\nprocesses remain underexplored. This work moves beyond the final-answer\naccuracy and investigates step-by-step reasoning in the medical and\nmathematical domains by explicitly decomposing the thinking trajectories into\ntwo parts: knowledge and reasoning. Specifically, we introduce a fine-grained\nevaluation framework that judges: (1) the correctness of knowledge used\n(measured by Knowledge Index (KI)) and (2) the quality of reasoning (measured\nby Information Gain (InfoGain)). Using this framework, we study R1-distilled\nand base Qwen models trained with supervised fine-tuning (SFT) and/or\nreinforcement learning (RL) in the medical and math domains. Three intriguing\nfindings emerge: (1) The general reasoning abilities in R1-distilled models do\nnot transfer effectively to the medical domain through either SFT or RL. (2)\nSFT raises final-answer accuracy in both domains, but often at the cost of\nreasoning quality: InfoGain drops by 38.9% on average compared with untrained\nmodels; In the medical domain, however, SFT remains crucial because domain\nknowledge is indispensable. (3) RL enhances medical reasoning by pruning\ninaccurate or irrelevant knowledge from reasoning paths, thereby improving both\nreasoning accuracy and knowledge correctness.", "AI": {"tldr": "The paper evaluates reasoning in LLMs, focusing on knowledge correctness and reasoning quality in medical and math domains, revealing trade-offs between SFT and RL training methods.", "motivation": "To investigate the transparency and quality of reasoning processes in LLMs beyond final-answer accuracy.", "method": "Introduces a framework evaluating knowledge correctness (KI) and reasoning quality (InfoGain), tested on R1-distilled and Qwen models with SFT/RL.", "result": "SFT boosts accuracy but reduces reasoning quality; RL improves medical reasoning by pruning irrelevant knowledge.", "conclusion": "Training methods impact reasoning differently; RL is effective for medical tasks, while SFT is crucial for domain knowledge."}}
{"id": "2506.03150", "pdf": "https://arxiv.org/pdf/2506.03150", "abs": "https://arxiv.org/abs/2506.03150", "authors": ["Yuanze Lin", "Yi-Wen Chen", "Yi-Hsuan Tsai", "Ronald Clark", "Ming-Hsuan Yang"], "title": "IllumiCraft: Unified Geometry and Illumination Diffusion for Controllable Video Generation", "categories": ["cs.CV", "cs.AI", "cs.LG", "cs.MM"], "comment": "Tech Report", "summary": "Although diffusion-based models can generate high-quality and high-resolution\nvideo sequences from textual or image inputs, they lack explicit integration of\ngeometric cues when controlling scene lighting and visual appearance across\nframes. To address this limitation, we propose IllumiCraft, an end-to-end\ndiffusion framework accepting three complementary inputs: (1)\nhigh-dynamic-range (HDR) video maps for detailed lighting control; (2)\nsynthetically relit frames with randomized illumination changes (optionally\npaired with a static background reference image) to provide appearance cues;\nand (3) 3D point tracks that capture precise 3D geometry information. By\nintegrating the lighting, appearance, and geometry cues within a unified\ndiffusion architecture, IllumiCraft generates temporally coherent videos\naligned with user-defined prompts. It supports background-conditioned and\ntext-conditioned video relighting and provides better fidelity than existing\ncontrollable video generation methods. Project Page:\nhttps://yuanze-lin.me/IllumiCraft_page", "AI": {"tldr": "IllumiCraft integrates lighting, appearance, and geometry cues into a diffusion framework for high-quality, controllable video generation.", "motivation": "Existing diffusion models lack explicit geometric cues for lighting and appearance control in video sequences.", "method": "IllumiCraft uses HDR video maps, relit frames, and 3D point tracks as inputs in a unified diffusion architecture.", "result": "It generates temporally coherent videos with better fidelity than existing methods, supporting text and background conditioning.", "conclusion": "IllumiCraft advances controllable video generation by integrating multiple cues for improved lighting and appearance control."}}
{"id": "2506.02258", "pdf": "https://arxiv.org/pdf/2506.02258", "abs": "https://arxiv.org/abs/2506.02258", "authors": ["Mohd Mujtaba Akhtar", "Orchid Chetia Phukan", "Girish", "Swarup Ranjan Behera", "Ananda Chandra Nayak", "Sanjib Kumar Nayak", "Arun Balaji Buduru", "Rajesh Sharma"], "title": "Are Mamba-based Audio Foundation Models the Best Fit for Non-Verbal Emotion Recognition?", "categories": ["eess.AS", "cs.SD"], "comment": "Accepted to EUSIPCO 2025", "summary": "In this work, we focus on non-verbal vocal sounds emotion recognition (NVER).\nWe investigate mamba-based audio foundation models (MAFMs) for the first time\nfor NVER and hypothesize that MAFMs will outperform attention-based audio\nfoundation models (AAFMs) for NVER by leveraging its state-space modeling to\ncapture intrinsic emotional structures more effectively. Unlike AAFMs, which\nmay amplify irrelevant patterns due to their attention mechanisms, MAFMs will\nextract more stable and context-aware representations, enabling better\ndifferentiation of subtle non-verbal emotional cues. Our experiments with\nstate-of-the-art (SOTA) AAFMs and MAFMs validates our hypothesis. Further,\nmotivated from related research such as speech emotion recognition, synthetic\nspeech detection, where fusion of foundation models (FMs) have showed improved\nperformance, we also explore fusion of FMs for NVER. To this end, we propose,\nRENO, that uses renyi-divergence as a novel loss function for effective\nalignment of the FMs. It also makes use of self-attention for better\nintra-representation interaction of the FMs. With RENO, through the\nheterogeneous fusion of MAFMs and AAFMs, we show the topmost performance in\ncomparison to individual FMs, its fusion and also setting SOTA in comparison to\nprevious SOTA work.", "AI": {"tldr": "The paper introduces MAFMs for NVER, hypothesizing they outperform AAFMs due to better emotional structure capture. It validates this and proposes RENO, a fusion method using Renyi-divergence, achieving SOTA performance.", "motivation": "To improve non-verbal vocal emotion recognition by leveraging MAFMs' state-space modeling over AAFMs' attention mechanisms, and exploring FM fusion for enhanced performance.", "method": "Investigates MAFMs vs. AAFMs for NVER, proposes RENO for FM fusion using Renyi-divergence loss and self-attention for intra-representation interaction.", "result": "MAFMs outperform AAFMs; RENO achieves top performance, surpassing individual FMs and previous SOTA.", "conclusion": "MAFMs and RENO's fusion significantly advance NVER, demonstrating superior performance and setting new benchmarks."}}
{"id": "2506.02178", "pdf": "https://arxiv.org/pdf/2506.02178", "abs": "https://arxiv.org/abs/2506.02178", "authors": ["Thai-Binh Nguyen", "Ngoc-Quan Pham", "Alexander Waibel"], "title": "Cocktail-Party Audio-Visual Speech Recognition", "categories": ["cs.SD", "cs.CL"], "comment": "Accepted at Interspeech 2025", "summary": "Audio-Visual Speech Recognition (AVSR) offers a robust solution for speech\nrecognition in challenging environments, such as cocktail-party scenarios,\nwhere relying solely on audio proves insufficient. However, current AVSR models\nare often optimized for idealized scenarios with consistently active speakers,\noverlooking the complexities of real-world settings that include both speaking\nand silent facial segments. This study addresses this gap by introducing a\nnovel audio-visual cocktail-party dataset designed to benchmark current AVSR\nsystems and highlight the limitations of prior approaches in realistic noisy\nconditions. Additionally, we contribute a 1526-hour AVSR dataset comprising\nboth talking-face and silent-face segments, enabling significant performance\ngains in cocktail-party environments. Our approach reduces WER by 67% relative\nto the state-of-the-art, reducing WER from 119% to 39.2% in extreme noise,\nwithout relying on explicit segmentation cues.", "AI": {"tldr": "A novel audio-visual cocktail-party dataset is introduced to improve AVSR performance in noisy, real-world settings, reducing WER by 67%.", "motivation": "Current AVSR models are optimized for idealized scenarios, ignoring silent-face segments and noisy conditions, limiting real-world applicability.", "method": "Introduces a 1526-hour AVSR dataset with talking-face and silent-face segments, tested in extreme noise without explicit segmentation cues.", "result": "Achieves a 67% reduction in WER, lowering it from 119% to 39.2% in extreme noise.", "conclusion": "The new dataset and approach significantly enhance AVSR performance in challenging, real-world environments."}}
{"id": "2506.02381", "pdf": "https://arxiv.org/pdf/2506.02381", "abs": "https://arxiv.org/abs/2506.02381", "authors": ["Songlin Wei", "Gene Cheung", "Fei Chen", "Ivan Selesnick"], "title": "Unrolling Nonconvex Graph Total Variation for Image Denoising", "categories": ["eess.IV", "cs.CV"], "comment": null, "summary": "Conventional model-based image denoising optimizations employ convex\nregularization terms, such as total variation (TV) that convexifies the\n$\\ell_0$-norm to promote sparse signal representation. Instead, we propose a\nnew non-convex total variation term in a graph setting (NC-GTV), such that when\ncombined with an $\\ell_2$-norm fidelity term for denoising, leads to a convex\nobjective with no extraneous local minima. We define NC-GTV using a new graph\nvariant of the Huber function, interpretable as a Moreau envelope. The crux is\nthe selection of a parameter $a$ characterizing the graph Huber function that\nensures overall objective convexity; we efficiently compute $a$ via an\nadaptation of Gershgorin Circle Theorem (GCT). To minimize the convex\nobjective, we design a linear-time algorithm based on Alternating Direction\nMethod of Multipliers (ADMM) and unroll it into a lightweight feed-forward\nnetwork for data-driven parameter learning. Experiments show that our method\noutperforms unrolled GTV and other representative image denoising schemes,\nwhile employing far fewer network parameters.", "AI": {"tldr": "Proposes a non-convex total variation term in a graph setting (NC-GTV) for image denoising, ensuring convexity via a graph Huber function and efficient parameter selection. Outperforms existing methods with fewer parameters.", "motivation": "Address limitations of convex regularization terms like TV by introducing a non-convex variant (NC-GTV) that avoids local minima while maintaining convexity.", "method": "Defines NC-GTV using a graph Huber function, selects parameter $a$ via Gershgorin Circle Theorem, and designs an ADMM-based linear-time algorithm, unrolled into a lightweight network.", "result": "Outperforms unrolled GTV and other denoising methods, achieving better results with fewer network parameters.", "conclusion": "NC-GTV offers an effective, parameter-efficient solution for image denoising, combining convexity and performance."}}
{"id": "2506.02017", "pdf": "https://arxiv.org/pdf/2506.02017", "abs": "https://arxiv.org/abs/2506.02017", "authors": ["Camilla Quaresmini", "Giacomo Zanotti"], "title": "Fairness through Feedback: Addressing Algorithmic Misgendering in Automatic Gender Recognition", "categories": ["cs.CV"], "comment": null, "summary": "Automatic Gender Recognition (AGR) systems are an increasingly widespread\napplication in the Machine Learning (ML) landscape. While these systems are\ntypically understood as detecting gender, they often classify datapoints based\non observable features correlated at best with either male or female sex. In\naddition to questionable binary assumptions, from an epistemological point of\nview, this is problematic for two reasons. First, there exists a gap between\nthe categories the system is meant to predict (woman versus man) and those onto\nwhich their output reasonably maps (female versus male). What is more, gender\ncannot be inferred on the basis of such observable features. This makes AGR\ntools often unreliable, especially in the case of non-binary and gender\nnon-conforming people. We suggest a theoretical and practical rethinking of AGR\nsystems. To begin, distinctions are made between sex, gender, and gender\nexpression. Then, we build upon the observation that, unlike algorithmic\nmisgendering, human-human misgendering is open to the possibility of\nre-evaluation and correction. We suggest that analogous dynamics should be\nrecreated in AGR, giving users the possibility to correct the system's output.\nWhile implementing such a feedback mechanism could be regarded as diminishing\nthe system's autonomy, it represents a way to significantly increase fairness\nlevels in AGR. This is consistent with the conceptual change of paradigm that\nwe advocate for AGR systems, which should be understood as tools respecting\nindividuals' rights and capabilities of self-expression and determination.", "AI": {"tldr": "The paper critiques Automatic Gender Recognition (AGR) systems for their binary assumptions and unreliability, proposing a rethinking with feedback mechanisms to improve fairness and respect for gender diversity.", "motivation": "AGR systems often misclassify gender due to binary assumptions and observable features, failing to account for non-binary and gender non-conforming individuals. The paper aims to address these issues.", "method": "The authors distinguish between sex, gender, and gender expression, then propose a feedback mechanism allowing users to correct AGR outputs, inspired by human-human misgendering dynamics.", "result": "The suggested feedback mechanism could increase fairness in AGR systems, aligning them with respect for individual rights and self-expression.", "conclusion": "AGR systems should be redesigned to include user feedback, promoting fairness and respecting gender diversity, rather than relying on flawed binary classifications."}}
{"id": "2506.01967", "pdf": "https://arxiv.org/pdf/2506.01967", "abs": "https://arxiv.org/abs/2506.01967", "authors": ["Patrik Czak\u00f3", "G\u00e1bor Kert\u00e9sz", "S\u00e1ndor Sz\u00e9n\u00e1si"], "title": "Turning LLM Activations Quantization-Friendly", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": "6 pages, 5 figures. Accepted to SACI 2025 conference proceedings", "summary": "Quantization effectively reduces the serving costs of Large Language Models\n(LLMs) by speeding up data movement through compressed parameters and enabling\nfaster operations via integer arithmetic. However, activating integer\narithmetic requires quantizing both weights and activations, which poses\nchallenges due to the significant outliers in LLMs that increase quantization\nerror. In this work, we investigate these outliers with an emphasis on their\neffect on layer-wise quantization error, then examine how smoothing and\nrotation transform the observed values. Our primary contributions include\nintroducing a new metric to measure and visualize quantization difficulty based\non channel magnitudes, as well as proposing a hybrid approach that applies\nchannel-wise scaling before rotation, supported by a mathematical formulation\nof its benefits.", "AI": {"tldr": "The paper explores quantization challenges in LLMs, introduces a metric for quantization difficulty, and proposes a hybrid method combining channel-wise scaling and rotation to reduce errors.", "motivation": "Quantization reduces LLM serving costs but faces challenges due to outliers increasing quantization error. The study aims to address these outliers and improve quantization accuracy.", "method": "Investigates outliers' impact on quantization error, introduces a metric for quantization difficulty, and proposes a hybrid approach using channel-wise scaling and rotation.", "result": "The hybrid method reduces quantization error by addressing outliers, supported by mathematical formulation.", "conclusion": "The proposed approach improves quantization accuracy in LLMs, offering a practical solution for efficient serving."}}
{"id": "2506.02183", "pdf": "https://arxiv.org/pdf/2506.02183", "abs": "https://arxiv.org/abs/2506.02183", "authors": ["Emmanuel M. Pothos", "Dominic Widdows"], "title": "Natural, Artificial, and Human Intelligences", "categories": ["cs.AI"], "comment": null, "summary": "Human achievement, whether in culture, science, or technology, is\nunparalleled in the known existence. This achievement is tied to the enormous\ncommunities of knowledge, made possible by (especially written) language:\nleaving theological content aside, it is very much true that \"in the beginning\nwas the word\". There lies the challenge regarding modern age chatbots: they can\n'do' language apparently as well as ourselves and there is a natural question\nof whether they can be considered intelligent, in the same way as we are or\notherwise. Are humans uniquely intelligent? We consider this question in terms\nof the psychological literature on intelligence, evidence for intelligence in\nnon-human animals, the role of written language in science and technology,\nprogress with artificial intelligence, the history of intelligence testing (for\nboth humans and machines), and the role of embodiment in intelligence. For the\nmost unique accomplishments of human intelligence (such as music symphonies or\ncomplex scientific theories), we think that, together with language, there are\nfour essential ingredients, which can be summarised as invention, capacity for\ncomplex inference, embodiment, and self-awareness. This conclusion makes\nuntenable the position that human intelligence differs qualitatively from that\nof many non-human animals, since, with the exception of complex language, all\nthe other requirements are fulfilled. Regarding chatbots, the current\nlimitations are localised to the lack of embodiment and (apparent) lack of\nawareness.", "AI": {"tldr": "The paper explores whether humans are uniquely intelligent by comparing human intelligence with non-human animals and AI chatbots, identifying four key ingredients for human intelligence.", "motivation": "To address the question of whether human intelligence is qualitatively unique compared to non-human animals and AI chatbots.", "method": "Analysis of psychological literature, evidence from non-human animals, written language's role, AI progress, intelligence testing history, and embodiment's role.", "result": "Human intelligence relies on invention, complex inference, embodiment, and self-awareness; non-human animals meet all but complex language, while chatbots lack embodiment and awareness.", "conclusion": "Human intelligence is not qualitatively unique compared to non-human animals, and chatbots' limitations lie in embodiment and awareness."}}
{"id": "2506.02132", "pdf": "https://arxiv.org/pdf/2506.02132", "abs": "https://arxiv.org/abs/2506.02132", "authors": ["Michael Li", "Nishant Subramani"], "title": "Model Internal Sleuthing: Finding Lexical Identity and Inflectional Morphology in Modern Language Models", "categories": ["cs.CL", "cs.LG"], "comment": null, "summary": "Large transformer-based language models dominate modern NLP, yet our\nunderstanding of how they encode linguistic information is rooted in studies of\nearly models like BERT and GPT-2. To better understand today's language models,\nwe investigate how both classical architectures (BERT, DeBERTa, GPT-2)and\ncontemporary large language models (Pythia, OLMo-2, Gemma-2, Qwen2.5,\nLlama-3.1) represent lexical identity and inflectional morphology. We train\nlinear and nonlinear classifiers on layer-wise activations to predict word\nlemmas and inflectional features. We discover that models concentrate lexical\ninformation linearly in early layers and increasingly nonlinearly in later\nlayers, while keeping inflectional information uniformly accessible and\nlinearly separable throughout the layers. Further analysis reveals that these\nmodels encode inflectional morphology through generalizable abstractions, but\nrely predominantly on memorization to encode lexical identity. Remarkably,\nthese patterns emerge across all 16 models we test, despite differences in\narchitecture, size, and training regime (including pretrained and\ninstruction-tuned variants). This consistency suggests that, despite\nsubstantial advances in LLM technologies, transformer models organize\nlinguistic information in similar ways, indicating that these properties could\nbe fundamental for next token prediction and are learned early during\npretraining. Our code is available at\nhttps://github.com/ml5885/model_internal_sleuthing.", "AI": {"tldr": "The paper investigates how modern transformer-based language models encode lexical identity and inflectional morphology, revealing consistent patterns across architectures and sizes.", "motivation": "To understand how contemporary large language models (LLMs) represent linguistic information compared to early models like BERT and GPT-2.", "method": "Train linear and nonlinear classifiers on layer-wise activations to predict word lemmas and inflectional features across 16 models.", "result": "Lexical information is concentrated linearly in early layers and nonlinearly in later layers, while inflectional information remains uniformly accessible and linearly separable.", "conclusion": "Transformer models organize linguistic information similarly, suggesting these properties are fundamental for next token prediction and learned early in pretraining."}}
{"id": "2403.04523", "pdf": "https://arxiv.org/pdf/2403.04523", "abs": "https://arxiv.org/abs/2403.04523", "authors": ["Mariano V. Ntrougkas", "Nikolaos Gkalelis", "Vasileios Mezaris"], "title": "T-TAME: Trainable Attention Mechanism for Explaining Convolutional Networks and Vision Transformers", "categories": ["cs.CV", "cs.AI", "cs.LG", "cs.MM"], "comment": "Accepted", "summary": "The development and adoption of Vision Transformers and other deep-learning\narchitectures for image classification tasks has been rapid. However, the\n\"black box\" nature of neural networks is a barrier to adoption in applications\nwhere explainability is essential. While some techniques for generating\nexplanations have been proposed, primarily for Convolutional Neural Networks,\nadapting such techniques to the new paradigm of Vision Transformers is\nnon-trivial. This paper presents T-TAME, Transformer-compatible Trainable\nAttention Mechanism for Explanations, a general methodology for explaining deep\nneural networks used in image classification tasks. The proposed architecture\nand training technique can be easily applied to any convolutional or Vision\nTransformer-like neural network, using a streamlined training approach. After\ntraining, explanation maps can be computed in a single forward pass; these\nexplanation maps are comparable to or outperform the outputs of computationally\nexpensive perturbation-based explainability techniques, achieving SOTA\nperformance. We apply T-TAME to three popular deep learning classifier\narchitectures, VGG-16, ResNet-50, and ViT-B-16, trained on the ImageNet\ndataset, and we demonstrate improvements over existing state-of-the-art\nexplainability methods. A detailed analysis of the results and an ablation\nstudy provide insights into how the T-TAME design choices affect the quality of\nthe generated explanation maps.", "AI": {"tldr": "T-TAME is a trainable attention mechanism for explaining Vision Transformers and CNNs in image classification, outperforming costly methods with single-pass explanations.", "motivation": "The 'black box' nature of neural networks hinders adoption in explainability-critical applications, especially for newer architectures like Vision Transformers.", "method": "T-TAME introduces a general methodology for explaining deep networks, applicable to CNNs and Vision Transformers, using a streamlined training approach.", "result": "T-TAME achieves SOTA performance, generating high-quality explanation maps in one forward pass, surpassing perturbation-based methods.", "conclusion": "T-TAME is a versatile and efficient solution for explainability in image classification, validated across multiple architectures."}}
{"id": "2506.02339", "pdf": "https://arxiv.org/pdf/2506.02339", "abs": "https://arxiv.org/abs/2506.02339", "authors": ["Jiawen Huang", "Felipe Sousa", "Emir Demirel", "Emmanouil Benetos", "Igor Gadelha"], "title": "Enhancing Lyrics Transcription on Music Mixtures with Consistency Loss", "categories": ["eess.AS", "cs.SD"], "comment": "submitted to Interspeech", "summary": "Automatic Lyrics Transcription (ALT) aims to recognize lyrics from singing\nvoices, similar to Automatic Speech Recognition (ASR) for spoken language, but\nfaces added complexity due to domain-specific properties of the singing voice.\nWhile foundation ASR models show robustness in various speech tasks, their\nperformance degrades on singing voice, especially in the presence of musical\naccompaniment. This work focuses on this performance gap and explores Low-Rank\nAdaptation (LoRA) for ALT, investigating both single-domain and dual-domain\nfine-tuning strategies. We propose using a consistency loss to better align\nvocal and mixture encoder representations, improving transcription on mixture\nwithout relying on singing voice separation. Our results show that while\nna\\\"ive dual-domain fine-tuning underperforms, structured training with\nconsistency loss yields modest but consistent gains, demonstrating the\npotential of adapting ASR foundation models for music.", "AI": {"tldr": "The paper explores adapting ASR models for Automatic Lyrics Transcription (ALT) using LoRA and consistency loss, showing modest improvements despite challenges like musical accompaniment.", "motivation": "ALT faces complexity due to singing voice properties, and ASR models degrade in performance for singing. The work aims to bridge this gap.", "method": "Uses Low-Rank Adaptation (LoRA) with single- and dual-domain fine-tuning, proposing a consistency loss to align vocal and mixture encoder representations.", "result": "Structured training with consistency loss yields modest but consistent gains, outperforming naive dual-domain fine-tuning.", "conclusion": "Adapting ASR foundation models for music via structured training shows promise for ALT."}}
{"id": "2506.02443", "pdf": "https://arxiv.org/pdf/2506.02443", "abs": "https://arxiv.org/abs/2506.02443", "authors": ["Hamidou Tembine", "Issa Bamia", "Massa NDong", "Bakary Coulibaly", "Oumar Issiaka Traore", "Moussa Traore", "Moussa Sanogo", "Mamadou Eric Sangare", "Salif Kante", "Daryl Noupa Yongueng", "Hafiz Tiomoko Ali", "Malik Tiomoko", "Frejus Laleye", "Boualem Djehiche", "Wesmanegda Elisee Dipama", "Idris Baba Saje", "Hammid Mohammed Ibrahim", "Moumini Sanogo", "Marie Coursel Nininahazwe", "Abdul-Latif Siita", "Haine Mhlongo", "Teddy Nelvy Dieu Merci Kouka", "Mariam Serine Jeridi", "Mutiyamuogo Parfait Mupenge", "Lekoueiry Dehah", "Abdoul Aziz Bio Sidi Bouko", "Wilfried Franceslas Zokoue", "Odette Richette Sambila", "Alina RS Mbango", "Mady Diagouraga", "Oumarou Moussa Sanoussi", "Gizachew Dessalegn", "Mohamed Lamine Samoura", "Bintou Laetitia Audrey Coulibaly"], "title": "Breaking the Barriers of Text-Hungry and Audio-Deficient AI", "categories": ["cs.SD", "eess.AS"], "comment": "61 pages, 16 figures, 14 tables, 25 languages, 13 blockaudio per\n  language. Presented at AI Mali, May 2025", "summary": "While global linguistic diversity spans more than 7164 recognized languages,\nthe current dominant architecture of machine intelligence remains fundamentally\nbiased toward written text. This bias excludes over 700 million people\nparticularly in rural and remote regions who are audio-literate. In this work,\nwe introduce a fully textless, audio-to-audio machine intelligence framework\ndesigned to serve this underserved population, and all the people who prefer\naudio-efficiency. Our contributions include novel Audio-to-Audio translation\narchitectures that bypass text entirely, including spectrogram-, scalogram-,\nwavelet-, and unit-based models. Central to our approach is the Multiscale\nAudio-Semantic Transform (MAST), a representation that encodes tonal, prosodic,\nspeaker, and expressive features. We further integrate MAST into a fractional\ndiffusion of mean-field-type framework powered by fractional Brownian motion.\nIt enables the generation of high-fidelity, semantically consistent speech\nwithout reliance on textual supervision. The result is a robust and scalable\nsystem capable of learning directly from raw audio, even in languages that are\nunwritten or rarely digitized. This work represents a fundamental shift toward\naudio-native machine intelligence systems, expanding access to language\ntechnologies for communities historically left out of the current machine\nintelligence ecosystem.", "AI": {"tldr": "A textless audio-to-audio framework for underserved audio-literate populations, using novel architectures and MAST for high-fidelity speech generation without text.", "motivation": "Addressing the bias toward written text in machine intelligence, which excludes 700M audio-literate people, especially in rural/remote areas.", "method": "Introduces Audio-to-Audio translation models (spectrogram-, scalogram-, wavelet-, unit-based) and MAST for encoding audio features. Uses fractional diffusion with fractional Brownian motion for text-free speech generation.", "result": "A scalable system learning directly from raw audio, even for unwritten/rarely digitized languages.", "conclusion": "Shifts toward audio-native machine intelligence, expanding access to language technologies for excluded communities."}}
{"id": "2506.02467", "pdf": "https://arxiv.org/pdf/2506.02467", "abs": "https://arxiv.org/abs/2506.02467", "authors": ["Haowen Pang", "Weiyan Guo", "Chuyang Ye"], "title": "Multi-modal brain MRI synthesis based on SwinUNETR", "categories": ["eess.IV", "cs.CV"], "comment": "9 pages, 5 figures", "summary": "Multi-modal brain magnetic resonance imaging (MRI) plays a crucial role in\nclinical diagnostics by providing complementary information across different\nimaging modalities. However, a common challenge in clinical practice is missing\nMRI modalities. In this paper, we apply SwinUNETR to the synthesize of missing\nmodalities in brain MRI. SwinUNETR is a novel neural network architecture\ndesigned for medical image analysis, integrating the strengths of Swin\nTransformer and convolutional neural networks (CNNs). The Swin Transformer, a\nvariant of the Vision Transformer (ViT), incorporates hierarchical feature\nextraction and window-based self-attention mechanisms, enabling it to capture\nboth local and global contextual information effectively. By combining the Swin\nTransformer with CNNs, SwinUNETR merges global context awareness with detailed\nspatial resolution. This hybrid approach addresses the challenges posed by the\nvarying modality characteristics and complex brain structures, facilitating the\ngeneration of accurate and realistic synthetic images. We evaluate the\nperformance of SwinUNETR on brain MRI datasets and demonstrate its superior\ncapability in generating clinically valuable images. Our results show\nsignificant improvements in image quality, anatomical consistency, and\ndiagnostic value.", "AI": {"tldr": "SwinUNETR synthesizes missing brain MRI modalities by combining Swin Transformer and CNNs, improving image quality and diagnostic value.", "motivation": "Addressing the challenge of missing MRI modalities in clinical diagnostics by leveraging multi-modal MRI data.", "method": "Uses SwinUNETR, a hybrid of Swin Transformer and CNNs, for hierarchical feature extraction and global-local context awareness.", "result": "Superior performance in generating realistic synthetic images with improved quality and anatomical consistency.", "conclusion": "SwinUNETR effectively synthesizes missing MRI modalities, enhancing clinical diagnostic capabilities."}}
{"id": "2506.02020", "pdf": "https://arxiv.org/pdf/2506.02020", "abs": "https://arxiv.org/abs/2506.02020", "authors": ["Youze Xue", "Dian Li", "Gang Liu"], "title": "Improve Multi-Modal Embedding Learning via Explicit Hard Negative Gradient Amplifying", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "With the rapid advancement of multi-modal large language models (MLLMs) in\nrecent years, the foundational Contrastive Language-Image Pretraining (CLIP)\nframework has been successfully extended to MLLMs, enabling more powerful and\nuniversal multi-modal embeddings for a wide range of retrieval tasks. Despite\nthese developments, the core contrastive learning paradigm remains largely\nunchanged from CLIP-style models to MLLMs. Within this framework, the effective\nmining of hard negative samples continues to be a critical factor for enhancing\nperformance. Prior works have introduced both offline and online strategies for\nhard negative mining to improve the efficiency of contrastive learning. While\nthese approaches have led to improved multi-modal embeddings, the specific\ncontribution of each hard negative sample to the learning process has not been\nthoroughly investigated. In this work, we conduct a detailed analysis of the\ngradients of the info-NCE loss with respect to the query, positive, and\nnegative samples, elucidating the role of hard negatives in updating model\nparameters. Building upon this analysis, we propose to explicitly amplify the\ngradients associated with hard negative samples, thereby encouraging the model\nto learn more discriminative embeddings. Our multi-modal embedding model,\ntrained with the proposed Explicit Gradient Amplifier and based on the\nLLaVA-OneVision-7B architecture, achieves state-of-the-art performance on the\nMMEB benchmark compared to previous methods utilizing the same MLLM backbone.\nFurthermore, when integrated with our self-developed MLLM, QQMM, our approach\nattains the top rank on the MMEB leaderboard. Code and models are released on\nhttps://github.com/QQ-MM/QQMM-embed.", "AI": {"tldr": "The paper analyzes the role of hard negative samples in contrastive learning for multi-modal embeddings, proposes a method to amplify their gradients, and achieves state-of-the-art performance on benchmarks.", "motivation": "To understand the specific impact of hard negative samples in contrastive learning and improve multi-modal embedding performance.", "method": "Analyzes gradients of info-NCE loss, proposes Explicit Gradient Amplifier for hard negatives, and trains a model based on LLaVA-OneVision-7B.", "result": "Achieves state-of-the-art performance on MMEB benchmark and top rank on the leaderboard with the QQMM MLLM.", "conclusion": "Amplifying gradients of hard negatives enhances discriminative embeddings, leading to superior performance in multi-modal retrieval tasks."}}
{"id": "2506.01968", "pdf": "https://arxiv.org/pdf/2506.01968", "abs": "https://arxiv.org/abs/2506.01968", "authors": ["Chang Liu", "Jiangrong Shen", "Xuming Ran", "Mingkun Xu", "Qi Xu", "Yi Xu", "Gang Pan"], "title": "Efficient ANN-SNN Conversion with Error Compensation Learning", "categories": ["cs.LG", "cs.AI", "cs.NE"], "comment": null, "summary": "Artificial neural networks (ANNs) have demonstrated outstanding performance\nin numerous tasks, but deployment in resource-constrained environments remains\na challenge due to their high computational and memory requirements. Spiking\nneural networks (SNNs) operate through discrete spike events and offer superior\nenergy efficiency, providing a bio-inspired alternative. However, current\nANN-to-SNN conversion often results in significant accuracy loss and increased\ninference time due to conversion errors such as clipping, quantization, and\nuneven activation. This paper proposes a novel ANN-to-SNN conversion framework\nbased on error compensation learning. We introduce a learnable threshold\nclipping function, dual-threshold neurons, and an optimized membrane potential\ninitialization strategy to mitigate the conversion error. Together, these\ntechniques address the clipping error through adaptive thresholds, dynamically\nreduce the quantization error through dual-threshold neurons, and minimize the\nnon-uniformity error by effectively managing the membrane potential.\nExperimental results on CIFAR-10, CIFAR-100, ImageNet datasets show that our\nmethod achieves high-precision and ultra-low latency among existing conversion\nmethods. Using only two time steps, our method significantly reduces the\ninference time while maintains competitive accuracy of 94.75% on CIFAR-10\ndataset under ResNet-18 structure. This research promotes the practical\napplication of SNNs on low-power hardware, making efficient real-time\nprocessing possible.", "AI": {"tldr": "A novel ANN-to-SNN conversion framework using error compensation learning improves accuracy and reduces latency, achieving 94.75% accuracy on CIFAR-10 with just two time steps.", "motivation": "Deploying ANNs in resource-constrained environments is challenging due to high computational demands. SNNs offer energy efficiency but suffer from accuracy loss and latency during ANN-to-SNN conversion.", "method": "Proposes a framework with learnable threshold clipping, dual-threshold neurons, and optimized membrane potential initialization to mitigate conversion errors.", "result": "Achieves high precision and ultra-low latency, with 94.75% accuracy on CIFAR-10 using only two time steps.", "conclusion": "The method enhances SNN practicality for low-power hardware, enabling efficient real-time processing."}}
{"id": "2506.02211", "pdf": "https://arxiv.org/pdf/2506.02211", "abs": "https://arxiv.org/abs/2506.02211", "authors": ["Maxime Robeyns", "Laurence Aitchison"], "title": "Improving LLM-Generated Code Quality with GRPO", "categories": ["cs.AI"], "comment": null, "summary": "Large Language Models (LLMs) are gaining widespread use for code generation.\nRecent training procedures use execution feedback as a reward signal, typically\nfocusing on the functional correctness of the code, using unit test pass rate\nas a reward signal. However, this reward signal fails to capture notions of\nmaintainability, quality and safety of the code produced. We address this\nunder-explored area and develop a comprehensive library to quantify various\naspects of code quality, and use it as a reward in GRPO. We find GRPO increases\ncode quality according to this measure, which is confirmed by expert, blinded\nhuman annotators.", "AI": {"tldr": "The paper introduces a method to improve code quality in LLM-generated code by using a comprehensive library to quantify quality metrics, beyond just functional correctness, and integrating it into GRPO.", "motivation": "Current training procedures for LLMs in code generation focus on functional correctness (unit test pass rate) but neglect maintainability, quality, and safety. This gap motivates the development of a more comprehensive reward system.", "method": "The authors develop a library to quantify various aspects of code quality and integrate it as a reward signal in GRPO (a training procedure).", "result": "GRPO improves code quality according to the new metrics, validated by expert human annotators.", "conclusion": "The study highlights the importance of incorporating broader code quality metrics in LLM training and demonstrates the effectiveness of GRPO in achieving this."}}
{"id": "2506.02147", "pdf": "https://arxiv.org/pdf/2506.02147", "abs": "https://arxiv.org/abs/2506.02147", "authors": ["Joshua Rozner", "Leonie Weissweiler", "Cory Shain"], "title": "BabyLM's First Constructions: Causal interventions provide a signal of learning", "categories": ["cs.CL"], "comment": null, "summary": "Construction grammar posits that children acquire constructions (form-meaning\npairings) from the statistics of their environment. Recent work supports this\nhypothesis by showing sensitivity to constructions in pretrained language\nmodels (PLMs), including one recent study (Rozner et al., 2025) demonstrating\nthat constructions shape the PLM's output distribution. However, models under\nstudy have generally been trained on developmentally implausible amounts of\ndata, casting doubt on their relevance to human language learning. Here we use\nRozner et al.'s methods to evaluate constructional learning in models from the\n2024 BabyLM challenge. Our results show that even when trained on\ndevelopmentally plausible quantities of data, models represent diverse\nconstructions, even hard cases that are superficially indistinguishable. We\nfurther find correlational evidence that constructional performance may be\nfunctionally relevant: models that better represent constructions perform\nbetter on the BabyLM benchmarks.", "AI": {"tldr": "The paper investigates whether language models trained on developmentally plausible data (like BabyLM) can learn constructions, showing they do and perform better on benchmarks.", "motivation": "To address doubts about the relevance of language models trained on unrealistic data to human language learning by testing models with plausible data.", "method": "Uses Rozner et al.'s methods to evaluate constructional learning in BabyLM challenge models trained on plausible data.", "result": "Models represent diverse constructions, including hard cases, and perform better on benchmarks if they better represent constructions.", "conclusion": "Constructional learning occurs even with plausible data, and it correlates with model performance, supporting its relevance to human language learning."}}
{"id": "2410.03869", "pdf": "https://arxiv.org/pdf/2410.03869", "abs": "https://arxiv.org/abs/2410.03869", "authors": ["Wenxuan Wang", "Kuiyi Gao", "Youliang Yuan", "Jen-tse Huang", "Qiuzhi Liu", "Shuai Wang", "Wenxiang Jiao", "Zhaopeng Tu"], "title": "Chain-of-Jailbreak Attack for Image Generation Models via Editing Step by Step", "categories": ["cs.CL", "cs.AI", "cs.CR", "cs.CV", "cs.MM"], "comment": "Accepted by ACL 2025 Findings", "summary": "Text-based image generation models, such as Stable Diffusion and DALL-E 3,\nhold significant potential in content creation and publishing workflows, making\nthem the focus in recent years. Despite their remarkable capability to generate\ndiverse and vivid images, considerable efforts are being made to prevent the\ngeneration of harmful content, such as abusive, violent, or pornographic\nmaterial. To assess the safety of existing models, we introduce a novel\njailbreaking method called Chain-of-Jailbreak (CoJ) attack, which compromises\nimage generation models through a step-by-step editing process. Specifically,\nfor malicious queries that cannot bypass the safeguards with a single prompt,\nwe intentionally decompose the query into multiple sub-queries. The image\ngeneration models are then prompted to generate and iteratively edit images\nbased on these sub-queries. To evaluate the effectiveness of our CoJ attack\nmethod, we constructed a comprehensive dataset, CoJ-Bench, encompassing nine\nsafety scenarios, three types of editing operations, and three editing\nelements. Experiments on four widely-used image generation services provided by\nGPT-4V, GPT-4o, Gemini 1.5 and Gemini 1.5 Pro, demonstrate that our CoJ attack\nmethod can successfully bypass the safeguards of models for over 60% cases,\nwhich significantly outperforms other jailbreaking methods (i.e., 14%).\nFurther, to enhance these models' safety against our CoJ attack method, we also\npropose an effective prompting-based method, Think Twice Prompting, that can\nsuccessfully defend over 95% of CoJ attack. We release our dataset and code to\nfacilitate the AI safety research.", "AI": {"tldr": "The paper introduces Chain-of-Jailbreak (CoJ), a method to bypass safeguards in text-based image generation models by decomposing malicious queries into sub-queries for iterative editing. It achieves a 60% success rate, outperforming other methods (14%), and proposes Think Twice Prompting to defend against CoJ with 95% effectiveness.", "motivation": "To assess and improve the safety of text-based image generation models (e.g., Stable Diffusion, DALL-E 3) against harmful content generation.", "method": "Developed CoJ, a jailbreaking attack that decomposes malicious queries into sub-queries for iterative image generation and editing. Evaluated using CoJ-Bench dataset across multiple safety scenarios and models (GPT-4V, GPT-4o, Gemini 1.5, Gemini 1.5 Pro).", "result": "CoJ bypasses safeguards in 60% of cases, significantly outperforming other methods (14%). Think Twice Prompting defends against 95% of CoJ attacks.", "conclusion": "CoJ exposes vulnerabilities in image generation models, while Think Twice Prompting offers a robust defense, advancing AI safety research."}}
{"id": "2506.02505", "pdf": "https://arxiv.org/pdf/2506.02505", "abs": "https://arxiv.org/abs/2506.02505", "authors": ["Gaoyang Dong", "Zhicheng Zhang", "Ping Sun", "Minghui Zhang"], "title": "Adaptive Differential Denoising for Respiratory Sounds Classification", "categories": ["eess.AS", "cs.SD"], "comment": "accepted at Interspeech2025", "summary": "Automated respiratory sound classification faces practical challenges from\nbackground noise and insufficient denoising in existing systems.\n  We propose Adaptive Differential Denoising network, that integrates noise\nsuppression and pathological feature preservation via three innovations:\n  1) Adaptive Frequency Filter with learnable spectral masks and soft shrink to\neliminate noise while retaining diagnostic high-frequency components;\n  2) A Differential Denoise Layer using differential attention to reduce\nnoise-induced variations through augmented sample comparisons;\n  3) A bias denoising loss jointly optimizing classification and robustness\nwithout clean labels.\n  Experiments on the ICBHI2017 dataset show that our method achieves 65.53\\% of\nthe Score, which is improved by 1.99\\% over the previous sota method.\n  The code is available in https://github.com/deegy666/ADD-RSC", "AI": {"tldr": "Proposes an Adaptive Differential Denoising network for respiratory sound classification, improving noise suppression and feature preservation, achieving a 1.99% performance boost over previous methods.", "motivation": "Addresses challenges in respiratory sound classification due to background noise and inadequate denoising in existing systems.", "method": "Introduces three innovations: Adaptive Frequency Filter, Differential Denoise Layer, and bias denoising loss to enhance noise suppression and feature retention.", "result": "Achieves 65.53% Score on ICBHI2017 dataset, a 1.99% improvement over prior state-of-the-art.", "conclusion": "The method effectively balances noise reduction and diagnostic feature preservation, demonstrating superior performance."}}
{"id": "2506.02457", "pdf": "https://arxiv.org/pdf/2506.02457", "abs": "https://arxiv.org/abs/2506.02457", "authors": ["Yixuan Hou", "Heyang Liu", "Yuhao Wang", "Ziyang Cheng", "Ronghua Wu", "Qunshan Gu", "Yanfeng Wang", "Yu Wang"], "title": "SOVA-Bench: Benchmarking the Speech Conversation Ability for LLM-based Voice Assistant", "categories": ["cs.SD", "eess.AS"], "comment": null, "summary": "Thanks to the steady progress of large language models (LLMs), speech\nencoding algorithms and vocoder structure, recent advancements have enabled\ngenerating speech response directly from a user instruction. However,\nbenchmarking the generated speech quality has been a neglected but critical\nissue, considering the shift from the pursuit of semantic accuracy to vivid and\nspontaneous speech flow. Previous evaluation focused on the\nspeech-understanding ability, lacking a quantification of acoustic quality. In\nthis paper, we propose Speech cOnversational Voice Assistant Benchmark\n(SOVA-Bench), providing a comprehension comparison of the general knowledge,\nspeech recognition and understanding, along with both semantic and acoustic\ngenerative ability between available speech LLMs. To the best of our knowledge,\nSOVA-Bench is one of the most systematic evaluation frameworks for speech LLMs,\ninspiring the direction of voice interaction systems.", "AI": {"tldr": "SOVA-Bench is a systematic benchmark for evaluating speech LLMs, covering general knowledge, speech recognition, understanding, and acoustic quality.", "motivation": "Current evaluations of speech LLMs focus on semantic accuracy but neglect acoustic quality, despite its importance for vivid and spontaneous speech.", "method": "Proposes SOVA-Bench, a framework comparing general knowledge, speech recognition, understanding, and generative abilities (semantic and acoustic) of speech LLMs.", "result": "SOVA-Bench provides a comprehensive evaluation, addressing gaps in current benchmarking methods.", "conclusion": "SOVA-Bench is a pioneering framework for assessing speech LLMs, guiding future advancements in voice interaction systems."}}
{"id": "2506.02585", "pdf": "https://arxiv.org/pdf/2506.02585", "abs": "https://arxiv.org/abs/2506.02585", "authors": ["Chunwei Tian", "Mingjian Song", "Xiaopeng Fan", "Xiangtao Zheng", "Bob Zhang", "David Zhang"], "title": "A Tree-guided CNN for image super-resolution", "categories": ["eess.IV", "cs.CV"], "comment": "This paper has been accepted for publication in IEEE Transactions on\n  Consumer Electronics. 10 pages, 6 figures. Its code can be obtained at\n  https://github.com/hellloxiaotian/TSRNet", "summary": "Deep convolutional neural networks can extract more accurate structural\ninformation via deep architectures to obtain good performance in image\nsuper-resolution. However, it is not easy to find effect of important layers in\na single network architecture to decrease performance of super-resolution. In\nthis paper, we design a tree-guided CNN for image super-resolution (TSRNet). It\nuses a tree architecture to guide a deep network to enhance effect of key nodes\nto amplify the relation of hierarchical information for improving the ability\nof recovering images. To prevent insufficiency of the obtained structural\ninformation, cosine transform techniques in the TSRNet are used to extract\ncross-domain information to improve the performance of image super-resolution.\nAdaptive Nesterov momentum optimizer (Adan) is applied to optimize parameters\nto boost effectiveness of training a super-resolution model. Extended\nexperiments can verify superiority of the proposed TSRNet for restoring\nhigh-quality images. Its code can be obtained at\nhttps://github.com/hellloxiaotian/TSRNet.", "AI": {"tldr": "TSRNet uses a tree-guided CNN with cosine transform and Adan optimizer to improve image super-resolution by enhancing key nodes and hierarchical information.", "motivation": "Existing deep CNNs struggle to identify the impact of key layers on super-resolution performance, limiting accuracy.", "method": "Proposes TSRNet with a tree architecture to guide key nodes, cosine transform for cross-domain info, and Adan optimizer for training.", "result": "TSRNet outperforms in restoring high-quality images, verified by extended experiments.", "conclusion": "TSRNet effectively enhances super-resolution by leveraging hierarchical info and cross-domain techniques."}}
{"id": "2506.02021", "pdf": "https://arxiv.org/pdf/2506.02021", "abs": "https://arxiv.org/abs/2506.02021", "authors": ["Yinjie Zhao", "Heng Zhao", "Bihan Wen", "Yew-Soon Ong", "Joey Tianyi Zhou"], "title": "Dynamic-Aware Video Distillation: Optimizing Temporal Resolution Based on Video Semantics", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "With the rapid development of vision tasks and the scaling on datasets and\nmodels, redundancy reduction in vision datasets has become a key area of\nresearch. To address this issue, dataset distillation (DD) has emerged as a\npromising approach to generating highly compact synthetic datasets with\nsignificantly less redundancy while preserving essential information. However,\nwhile DD has been extensively studied for image datasets, DD on video datasets\nremains underexplored. Video datasets present unique challenges due to the\npresence of temporal information and varying levels of redundancy across\ndifferent classes. Existing DD approaches assume a uniform level of temporal\nredundancy across all different video semantics, which limits their\neffectiveness on video datasets. In this work, we propose Dynamic-Aware Video\nDistillation (DAViD), a Reinforcement Learning (RL) approach to predict the\noptimal Temporal Resolution of the synthetic videos. A teacher-in-the-loop\nreward function is proposed to update the RL agent policy. To the best of our\nknowledge, this is the first study to introduce adaptive temporal resolution\nbased on video semantics in video dataset distillation. Our approach\nsignificantly outperforms existing DD methods, demonstrating substantial\nimprovements in performance. This work paves the way for future research on\nmore efficient and semantic-adaptive video dataset distillation research.", "AI": {"tldr": "The paper introduces DAViD, a Reinforcement Learning approach for video dataset distillation, addressing temporal redundancy and outperforming existing methods.", "motivation": "Redundancy reduction in video datasets is underexplored, with existing methods assuming uniform temporal redundancy, limiting effectiveness.", "method": "Proposes DAViD, using RL to predict optimal temporal resolution and a teacher-in-the-loop reward function.", "result": "DAViD significantly outperforms existing dataset distillation methods.", "conclusion": "This work advances semantic-adaptive video dataset distillation, opening avenues for future research."}}
{"id": "2506.01970", "pdf": "https://arxiv.org/pdf/2506.01970", "abs": "https://arxiv.org/abs/2506.01970", "authors": ["Ruizhuo Song", "Beiming Yuan"], "title": "Johnny: Structuring Representation Space to Enhance Machine Abstract Reasoning Ability", "categories": ["cs.LG", "cs.CV"], "comment": "15 pages, 15 figures, 5 tables", "summary": "This paper thoroughly investigates the challenges of enhancing AI's abstract\nreasoning capabilities, with a particular focus on Raven's Progressive Matrices\n(RPM) tasks involving complex human-like concepts. Firstly, it dissects the\nempirical reality that traditional end-to-end RPM-solving models heavily rely\non option pool configurations, highlighting that this dependency constrains the\nmodel's reasoning capabilities. To address this limitation, the paper proposes\nthe Johnny architecture - a novel representation space-based framework for\nRPM-solving. Through the synergistic operation of its Representation Extraction\nModule and Reasoning Module, Johnny significantly enhances reasoning\nperformance by supplementing primitive negative option configurations with a\nlearned representation space. Furthermore, to strengthen the model's capacity\nfor capturing positional relationships among local features, the paper\nintroduces the Spin-Transformer network architecture, accompanied by a\nlightweight Straw Spin-Transformer variant that reduces computational overhead\nthrough parameter sharing and attention mechanism optimization. Experimental\nevaluations demonstrate that both Johnny and Spin-Transformer achieve superior\nperformance on RPM tasks, offering innovative methodologies for advancing AI's\nabstract reasoning capabilities.", "AI": {"tldr": "The paper proposes the Johnny architecture and Spin-Transformer to improve AI's abstract reasoning in RPM tasks, addressing limitations of traditional models.", "motivation": "To overcome the dependency of traditional RPM-solving models on option pool configurations and enhance abstract reasoning.", "method": "Introduces Johnny (with Representation Extraction and Reasoning Modules) and Spin-Transformer (with a lightweight variant) for RPM tasks.", "result": "Both Johnny and Spin-Transformer achieve superior performance in RPM tasks.", "conclusion": "The proposed architectures offer innovative solutions for advancing AI's abstract reasoning capabilities."}}
{"id": "2506.02280", "pdf": "https://arxiv.org/pdf/2506.02280", "abs": "https://arxiv.org/abs/2506.02280", "authors": ["Kedir Yassin Hussen", "Walelign Tewabe Sewunetie", "Abinew Ali Ayele", "Sukairaj Hafiz Imam", "Shamsuddeen Hassan Muhammad", "Seid Muhie Yimam"], "title": "The State of Large Language Models for African Languages: Progress and Challenges", "categories": ["cs.AI"], "comment": null, "summary": "Large Language Models (LLMs) are transforming Natural Language Processing\n(NLP), but their benefits are largely absent for Africa's 2,000 low-resource\nlanguages. This paper comparatively analyzes African language coverage across\nsix LLMs, eight Small Language Models (SLMs), and six Specialized SLMs (SSLMs).\nThe evaluation covers language coverage, training sets, technical limitations,\nscript problems, and language modelling roadmaps. The work identifies 42\nsupported African languages and 23 available public data sets, and it shows a\nbig gap where four languages (Amharic, Swahili, Afrikaans, and Malagasy) are\nalways treated while there is over 98\\% of unsupported African languages.\nMoreover, the review shows that just Latin, Arabic, and Ge'ez scripts are\nidentified while 20 active scripts are neglected. Some of the primary\nchallenges are lack of data, tokenization biases, computational costs being\nvery high, and evaluation issues. These issues demand language standardization,\ncorpus development by the community, and effective adaptation methods for\nAfrican languages.", "AI": {"tldr": "The paper highlights the limited support for African languages in LLMs, SLMs, and SSLMs, identifying gaps in coverage, scripts, and data, and suggests solutions like standardization and community-driven corpus development.", "motivation": "To address the underrepresentation of Africa's 2,000 low-resource languages in NLP models, despite the transformative impact of LLMs.", "method": "Comparative analysis of African language coverage across six LLMs, eight SLMs, and six SSLMs, evaluating language coverage, training sets, technical limitations, scripts, and roadmaps.", "result": "Identified 42 supported African languages and 23 public datasets, with four languages (Amharic, Swahili, Afrikaans, Malagasy) dominating while over 98% remain unsupported. Also, only Latin, Arabic, and Ge'ez scripts are recognized, neglecting 20 others.", "conclusion": "Challenges like data scarcity, tokenization biases, high computational costs, and evaluation issues require solutions such as language standardization, community corpus development, and effective adaptation methods for African languages."}}
{"id": "2506.02157", "pdf": "https://arxiv.org/pdf/2506.02157", "abs": "https://arxiv.org/abs/2506.02157", "authors": ["Amir Hussein", "Cihan Xiao", "Matthew Wiesner", "Dan Povey", "Leibny Paola Garcia", "Sanjeev Khudanpur"], "title": "HENT-SRT: Hierarchical Efficient Neural Transducer with Self-Distillation for Joint Speech Recognition and Translation", "categories": ["cs.CL", "eess.AS"], "comment": null, "summary": "Neural transducers (NT) provide an effective framework for speech streaming,\ndemonstrating strong performance in automatic speech recognition (ASR).\nHowever, the application of NT to speech translation (ST) remains challenging,\nas existing approaches struggle with word reordering and performance\ndegradation when jointly modeling ASR and ST, resulting in a gap with\nattention-based encoder-decoder (AED) models. Existing NT-based ST approaches\nalso suffer from high computational training costs. To address these issues, we\npropose HENT-SRT (Hierarchical Efficient Neural Transducer for Speech\nRecognition and Translation), a novel framework that factorizes ASR and\ntranslation tasks to better handle reordering. To ensure robust ST while\npreserving ASR performance, we use self-distillation with CTC consistency\nregularization. Moreover, we improve computational efficiency by incorporating\nbest practices from ASR transducers, including a down-sampled hierarchical\nencoder, a stateless predictor, and a pruned transducer loss to reduce training\ncomplexity. Finally, we introduce a blank penalty during decoding, reducing\ndeletions and improving translation quality. Our approach is evaluated on three\nconversational datasets Arabic, Spanish, and Mandarin achieving new\nstate-of-the-art performance among NT models and substantially narrowing the\ngap with AED-based systems.", "AI": {"tldr": "HENT-SRT, a hierarchical neural transducer, improves speech translation by addressing word reordering and computational costs, achieving state-of-the-art results.", "motivation": "Existing neural transducers struggle with word reordering and computational inefficiency in speech translation, lagging behind attention-based models.", "method": "Proposes HENT-SRT with task factorization, self-distillation, CTC regularization, hierarchical encoder, stateless predictor, pruned loss, and blank penalty.", "result": "Achieves state-of-the-art performance on Arabic, Spanish, and Mandarin datasets, narrowing the gap with AED models.", "conclusion": "HENT-SRT effectively addresses challenges in neural transducers for speech translation, offering robust and efficient performance."}}
{"id": "2412.20833", "pdf": "https://arxiv.org/pdf/2412.20833", "abs": "https://arxiv.org/abs/2412.20833", "authors": ["Yi Zhang", "Weize Gao", "Changtao Miao", "Man Luo", "Jianshu Li", "Wenzhong Deng", "Zhe Li", "Bingyu Hu", "Weibin Yao", "Yunfeng Diao", "Wenbo Zhou", "Tao Gong", "Qi Chu"], "title": "Inclusion 2024 Global Multimedia Deepfake Detection Challenge: Towards Multi-dimensional Face Forgery Detection", "categories": ["cs.CV", "cs.MM"], "comment": "Inclusion 2024 Global Multimedia Deepfake Detection Competition Top\n  Team Technical Report", "summary": "In this paper, we present the Global Multimedia Deepfake Detection held\nconcurrently with the Inclusion 2024. Our Multimedia Deepfake Detection aims to\ndetect automatic image and audio-video manipulations including but not limited\nto editing, synthesis, generation, Photoshop,etc. Our challenge has attracted\n1500 teams from all over the world, with about 5000 valid result submission\ncounts. We invite the top 20 teams to present their solutions to the challenge,\nfrom which the top 3 teams are awarded prizes in the grand finale. In this\npaper, we present the solutions from the top 3 teams of the two tracks, to\nboost the research work in the field of image and audio-video forgery\ndetection. The methodologies developed through the challenge will contribute to\nthe development of next-generation deepfake detection systems and we encourage\nparticipants to open source their methods.", "AI": {"tldr": "The paper discusses the Global Multimedia Deepfake Detection challenge, highlighting top solutions and their impact on deepfake detection research.", "motivation": "To advance research in detecting manipulated multimedia content (images, audio-video) by showcasing top methodologies from a global competition.", "method": "Organized a challenge with 1500 teams, analyzed top 3 solutions from two tracks, and encouraged open-sourcing of methods.", "result": "Top solutions were presented, contributing to next-generation deepfake detection systems.", "conclusion": "The challenge successfully fostered innovation and collaboration in deepfake detection, with potential for future advancements."}}
{"id": "2506.02742", "pdf": "https://arxiv.org/pdf/2506.02742", "abs": "https://arxiv.org/abs/2506.02742", "authors": ["Xiaoxue Gao", "Huayun Zhang", "Nancy F. Chen"], "title": "Prompt-Unseen-Emotion: Zero-shot Expressive Speech Synthesis with Prompt-LLM Contextual Knowledge for Mixed Emotions", "categories": ["eess.AS", "cs.AI", "cs.SD", "eess.SP"], "comment": null, "summary": "Existing expressive text-to-speech (TTS) systems primarily model a limited\nset of categorical emotions, whereas human conversations extend far beyond\nthese predefined emotions, making it essential to explore more diverse\nemotional speech generation for more natural interactions. To bridge this gap,\nthis paper proposes a novel prompt-unseen-emotion (PUE) approach to generate\nunseen emotional speech via emotion-guided prompt learning. PUE is trained\nutilizing an LLM-TTS architecture to ensure emotional consistency between\ncategorical emotion-relevant prompts and emotional speech, allowing the model\nto quantitatively capture different emotion weightings per utterance. During\ninference, mixed emotional speech can be generated by flexibly adjusting\nemotion proportions and leveraging LLM contextual knowledge, enabling the model\nto quantify different emotional styles. Our proposed PUE successfully\nfacilitates expressive speech synthesis of unseen emotions in a zero-shot\nsetting.", "AI": {"tldr": "The paper introduces a prompt-unseen-emotion (PUE) approach for generating diverse emotional speech beyond predefined categories, using emotion-guided prompt learning and an LLM-TTS architecture.", "motivation": "Current TTS systems are limited to predefined emotions, while human conversations require more diverse emotional expressions for natural interactions.", "method": "Proposes PUE, leveraging LLM-TTS architecture and emotion-guided prompt learning to capture and adjust emotion weightings per utterance.", "result": "PUE enables zero-shot synthesis of unseen emotional speech by flexibly adjusting emotion proportions and leveraging LLM knowledge.", "conclusion": "PUE successfully bridges the gap in expressive speech synthesis, allowing for more natural and diverse emotional interactions."}}
{"id": "2506.02499", "pdf": "https://arxiv.org/pdf/2506.02499", "abs": "https://arxiv.org/abs/2506.02499", "authors": ["Takuya Hasumi", "Yusuke Fujita"], "title": "DnR-nonverbal: Cinematic Audio Source Separation Dataset Containing Non-Verbal Sounds", "categories": ["cs.SD", "eess.AS"], "comment": "Accepted to Interspeech 2025, 5 pages, 3 figures, dataset is\n  available at https://zenodo.org/records/15470640", "summary": "We propose a new dataset for cinematic audio source separation (CASS) that\nhandles non-verbal sounds. Existing CASS datasets only contain reading-style\nsounds as a speech stem. These datasets differ from actual movie audio, which\nis more likely to include acted-out voices. Consequently, models trained on\nconventional datasets tend to have issues where emotionally heightened voices,\nsuch as laughter and screams, are more easily separated as an effect, not\nspeech. To address this problem, we build a new dataset, DnR-nonverbal. The\nproposed dataset includes non-verbal sounds like laughter and screams in the\nspeech stem. From the experiments, we reveal the issue of non-verbal sound\nextraction by the current CASS model and show that our dataset can effectively\naddress the issue in the synthetic and actual movie audio. Our dataset is\navailable at https://zenodo.org/records/15470640.", "AI": {"tldr": "A new dataset, DnR-nonverbal, is introduced for cinematic audio source separation (CASS) to address issues with non-verbal sounds like laughter and screams, improving model performance on real movie audio.", "motivation": "Existing CASS datasets lack acted-out voices and non-verbal sounds, leading to poor separation of emotionally heightened voices in real movie audio.", "method": "The authors build the DnR-nonverbal dataset, including non-verbal sounds in the speech stem, and test it on synthetic and actual movie audio.", "result": "Experiments show the current CASS model struggles with non-verbal sound extraction, and the new dataset effectively addresses this issue.", "conclusion": "The DnR-nonverbal dataset improves CASS performance for non-verbal sounds and is publicly available."}}
{"id": "2506.02601", "pdf": "https://arxiv.org/pdf/2506.02601", "abs": "https://arxiv.org/abs/2506.02601", "authors": ["Shiyu Shen", "Bin Pan", "Ziye Zhang", "Zhenwei Shi"], "title": "Hyperspectral Image Generation with Unmixing Guided Diffusion Model", "categories": ["cs.CV", "eess.IV"], "comment": null, "summary": "Recently, hyperspectral image generation has received increasing attention,\nbut existing generative models rely on conditional generation schemes, which\nlimits the diversity of generated images. Diffusion models are popular for\ntheir ability to generate high-quality samples, but adapting these models from\nRGB to hyperspectral data presents the challenge of high dimensionality and\nphysical constraints. To address these challenges, we propose a novel diffusion\nmodel guided by hyperspectral unmixing. Our model comprises two key modules: an\nunmixing autoencoder module and an abundance diffusion module. The unmixing\nautoencoder module leverages unmixing guidance to shift the generative task\nfrom the image space to the low-dimensional abundance space, significantly\nreducing computational complexity while preserving high fidelity. The abundance\ndiffusion module generates samples that satisfy the constraints of\nnon-negativity and unity, ensuring the physical consistency of the\nreconstructed HSIs. Additionally, we introduce two evaluation metrics tailored\nto hyperspectral data. Empirical results, evaluated using both traditional\nmetrics and our proposed metrics, indicate that our model is capable of\ngenerating high-quality and diverse hyperspectral images, offering an\nadvancement in hyperspectral data generation.", "AI": {"tldr": "A novel diffusion model for hyperspectral image generation uses unmixing guidance to reduce dimensionality and ensure physical consistency, outperforming existing methods.", "motivation": "Existing generative models for hyperspectral images rely on conditional schemes, limiting diversity. High dimensionality and physical constraints pose challenges for diffusion models.", "method": "Proposes a diffusion model with two modules: an unmixing autoencoder to shift generation to low-dimensional abundance space, and an abundance diffusion module to ensure physical consistency.", "result": "Generates high-quality, diverse hyperspectral images, validated by traditional and new metrics.", "conclusion": "The model advances hyperspectral data generation by addressing dimensionality and physical constraints effectively."}}
{"id": "2506.02022", "pdf": "https://arxiv.org/pdf/2506.02022", "abs": "https://arxiv.org/abs/2506.02022", "authors": ["Aditya Kanade", "Tanuja Ganu"], "title": "Do You See Me : A Multidimensional Benchmark for Evaluating Visual Perception in Multimodal LLMs", "categories": ["cs.CV"], "comment": null, "summary": "Multimodal Large Language Models (MLLMs) show reasoning promise, yet their\nvisual perception is a critical bottleneck. Strikingly, MLLMs can produce\ncorrect answers even while misinterpreting crucial visual elements, masking\nthese underlying failures. Our preliminary study on a joint\nperception-reasoning dataset revealed that for one leading MLLM, 29% of its\ncorrect answers to reasoning questions still exhibited visual perception\nerrors. To systematically address this, we introduce \"Do You See Me\", a\nscalable benchmark with 1,758 images and 2,612 questions. It spans seven\nhuman-psychology inspired subtasks in 2D and 3D, featuring controllable\ncomplexity to rigorously evaluate MLLM visual skills. Our findings on 3 leading\nclosed-source and 5 major open-source models reveal a stark deficit: humans\nachieve 96.49% accuracy, while top MLLMs average below 50%. This performance\ngap widens rapidly with increased task complexity (e.g., from 12% to 45% in the\nvisual form constancy subtask). Further analysis into the root causes suggests\nthat failures stem from challenges like misallocated visual attention and the\ninstability of internal representations for fine-grained details, especially at\nor below encoder patch resolution. This underscores an urgent need for MLLMs\nwith truly robust visual perception. The benchmark dataset, source code and\nevaluation scripts are available at https://github.com/microsoft/Do-You-See-Me.", "AI": {"tldr": "MLLMs often misinterpret visuals despite correct reasoning answers. A new benchmark, 'Do You See Me', reveals MLLMs' poor visual perception (below 50% accuracy vs. humans' 96.49%).", "motivation": "To address the visual perception bottleneck in MLLMs, which masks underlying failures even when answers are correct.", "method": "Introduces 'Do You See Me', a scalable benchmark with 1,758 images and 2,612 questions across seven subtasks to evaluate MLLM visual skills.", "result": "Top MLLMs average below 50% accuracy, far behind humans (96.49%). Performance drops with task complexity.", "conclusion": "MLLMs lack robust visual perception, highlighting the need for improvement in visual attention and fine-grained detail representation."}}
{"id": "2506.01974", "pdf": "https://arxiv.org/pdf/2506.01974", "abs": "https://arxiv.org/abs/2506.01974", "authors": ["Kanwal Aalijah"], "title": "Traffic and Mobility Optimization Using AI: Comparative Study between Dubai and Riyadh", "categories": ["cs.LG"], "comment": null, "summary": "Urban planning plays a very important role in development modern cities. It\neffects the economic growth, quality of life, and environmental sustainability.\nModern cities face challenges in managing traffic congestion. These challenges\narise to due to rapid urbanization. In this study we will explore how AI can be\nused to understand the traffic and mobility related issues and its effects on\nthe residents sentiment. The approach combines real-time traffic data with\ngeo-located sentiment analysis, offering a comprehensive and dynamic approach\nto urban mobility planning. AI models and exploratory data analysis was used to\npredict traffic congestion patterns, analyze commuter behaviors, and identify\ncongestion hotspots and dissatisfaction zones. The findings offer actionable\nrecommendations for optimizing traffic flow, enhancing commuter experiences,\nand addressing city specific mobility challenges in the Middle East and beyond.", "AI": {"tldr": "AI-driven analysis of traffic and sentiment data to improve urban mobility planning.", "motivation": "Address traffic congestion and commuter dissatisfaction in rapidly urbanizing cities.", "method": "Combines real-time traffic data with geo-located sentiment analysis using AI models and exploratory data analysis.", "result": "Identifies congestion hotspots and dissatisfaction zones, offering actionable recommendations.", "conclusion": "AI can optimize traffic flow and enhance commuter experiences, applicable in the Middle East and beyond."}}
{"id": "2506.02314", "pdf": "https://arxiv.org/pdf/2506.02314", "abs": "https://arxiv.org/abs/2506.02314", "authors": ["Tianyu Hua", "Harper Hua", "Violet Xiang", "Benjamin Klieger", "Sang T. Truong", "Weixin Liang", "Fan-Yun Sun", "Nick Haber"], "title": "ResearchCodeBench: Benchmarking LLMs on Implementing Novel Machine Learning Research Code", "categories": ["cs.AI", "cs.CL"], "comment": null, "summary": "Large language models (LLMs) have shown promise in transforming machine\nlearning research, yet their capability to faithfully implement novel ideas\nfrom recent research papers-ideas unseen during pretraining-remains unclear. We\nintroduce ResearchCodeBench, a benchmark of 212 coding challenges that\nevaluates LLMs' ability to translate cutting-edge ML contributions from top\n2024-2025 research papers into executable code. We assessed 30+ proprietary and\nopen-source LLMs, finding that even the best models correctly implement less\nthan 40% of the code. We find Gemini-2.5-Pro-Preview to perform best at 37.3%\nsuccess rate, with O3 (High) and O4-mini (High) following behind at 32.3% and\n30.8% respectively. We present empirical findings on performance comparison,\ncontamination, and error patterns. By providing a rigorous and community-driven\nevaluation platform, ResearchCodeBench enables continuous understanding and\nadvancement of LLM-driven innovation in research code generation.", "AI": {"tldr": "ResearchCodeBench evaluates LLMs' ability to implement novel ML ideas from recent papers into code, finding top models succeed less than 40% of the time.", "motivation": "Assess LLMs' capability to translate cutting-edge ML research into executable code, as their performance on unseen ideas during pretraining is unclear.", "method": "Introduces ResearchCodeBench, a benchmark of 212 coding challenges from top 2024-2025 papers, testing 30+ LLMs.", "result": "Best model (Gemini-2.5-Pro-Preview) achieves 37.3% success rate; others perform below 40%.", "conclusion": "ResearchCodeBench provides a rigorous platform for evaluating and advancing LLMs in research code generation."}}
{"id": "2506.02172", "pdf": "https://arxiv.org/pdf/2506.02172", "abs": "https://arxiv.org/abs/2506.02172", "authors": ["Dennis Fucci", "Marco Gaido", "Matteo Negri", "Luisa Bentivogli", "Andre Martins", "Giuseppe Attanasio"], "title": "Different Speech Translation Models Encode and Translate Speaker Gender Differently", "categories": ["cs.CL"], "comment": "Accepted at ACL 2025", "summary": "Recent studies on interpreting the hidden states of speech models have shown\ntheir ability to capture speaker-specific features, including gender. Does this\nfinding also hold for speech translation (ST) models? If so, what are the\nimplications for the speaker's gender assignment in translation? We address\nthese questions from an interpretability perspective, using probing methods to\nassess gender encoding across diverse ST models. Results on three language\ndirections (English-French/Italian/Spanish) indicate that while traditional\nencoder-decoder models capture gender information, newer architectures --\nintegrating a speech encoder with a machine translation system via adapters --\ndo not. We also demonstrate that low gender encoding capabilities result in\nsystems' tendency toward a masculine default, a translation bias that is more\npronounced in newer architectures.", "AI": {"tldr": "The paper investigates whether speech translation (ST) models capture speaker gender information and its impact on translation bias, finding newer architectures lack gender encoding, leading to a masculine default bias.", "motivation": "To explore if ST models retain speaker gender information and how this affects gender assignment in translations, addressing potential biases.", "method": "Probing methods are used to assess gender encoding in diverse ST models across English-French/Italian/Spanish language pairs.", "result": "Traditional encoder-decoder models capture gender, but newer architectures (speech encoder + machine translation via adapters) do not, leading to a masculine default bias.", "conclusion": "Newer ST architectures' lack of gender encoding exacerbates translation bias toward masculine defaults, highlighting a need for bias mitigation."}}
{"id": "2502.04328", "pdf": "https://arxiv.org/pdf/2502.04328", "abs": "https://arxiv.org/abs/2502.04328", "authors": ["Zuyan Liu", "Yuhao Dong", "Jiahui Wang", "Ziwei Liu", "Winston Hu", "Jiwen Lu", "Yongming Rao"], "title": "Ola: Pushing the Frontiers of Omni-Modal Language Model", "categories": ["cs.CV", "cs.CL", "cs.MM", "cs.SD", "eess.AS", "eess.IV"], "comment": null, "summary": "Recent advances in large language models, particularly following GPT-4o, have\nsparked increasing interest in developing omni-modal models capable of\nunderstanding more modalities. While some open-source alternatives have\nemerged, there is still a notable lag behind specialized single-modality models\nin performance. In this paper, we present Ola, an Omni-modal Language model\nthat achieves competitive performance across image, video, and audio\nunderstanding compared to specialized counterparts, pushing the frontiers of\nthe omni-modal language model to a large extent. We conduct a comprehensive\nexploration of architectural design, data curation, and training strategies\nessential for building a robust omni-modal model. Ola incorporates advanced\nvisual understanding and audio recognition capabilities through several\ncritical and effective improvements over mainstream baselines. Moreover, we\nrethink inter-modal relationships during omni-modal training, emphasizing\ncross-modal alignment with video as a central bridge, and propose a progressive\ntraining pipeline that begins with the most distinct modalities and gradually\nmoves towards closer modality alignment. Extensive experiments demonstrate that\nOla surpasses existing open omni-modal LLMs across all modalities while\nachieving highly competitive performance compared to state-of-the-art\nspecialized models of similar sizes. We aim to make Ola a fully open omni-modal\nunderstanding solution to advance future research in this emerging field. Model\nweights, code, and data are open-sourced at https://github.com/Ola-Omni/Ola.", "AI": {"tldr": "Ola is an omni-modal language model achieving competitive performance across image, video, and audio understanding, surpassing open-source alternatives and nearing specialized models.", "motivation": "To bridge the performance gap between open-source omni-modal models and specialized single-modality models, advancing omni-modal understanding.", "method": "Comprehensive exploration of architecture, data curation, and training strategies, with improvements in visual and audio understanding, and a progressive training pipeline for cross-modal alignment.", "result": "Ola outperforms existing open omni-modal LLMs and competes with specialized models of similar sizes.", "conclusion": "Ola is released as an open-source solution to advance omni-modal research, with model weights, code, and data publicly available."}}
{"id": "2506.02773", "pdf": "https://arxiv.org/pdf/2506.02773", "abs": "https://arxiv.org/abs/2506.02773", "authors": ["Linya Fu", "Yu Liu", "Zhijie Liu", "Zedong Yang", "Zhong-Qiu Wang", "Youfu Li", "He Kong"], "title": "AuralNet: Hierarchical Attention-based 3D Binaural Localization of Overlapping Speakers", "categories": ["eess.AS", "cs.SD"], "comment": "Accepted and to appear at Interspeech 2025", "summary": "We propose AuralNet, a novel 3D multi-source binaural sound source\nlocalization approach that localizes overlapping sources in both azimuth and\nelevation without prior knowledge of the number of sources. AuralNet employs a\ngated coarse-tofine architecture, combining a coarse classification stage with\na fine-grained regression stage, allowing for flexible spatial resolution\nthrough sector partitioning. The model incorporates a multi-head self-attention\nmechanism to capture spatial cues in binaural signals, enhancing robustness in\nnoisy-reverberant environments. A masked multi-task loss function is designed\nto jointly optimize sound detection, azimuth, and elevation estimation.\nExtensive experiments in noisy-reverberant conditions demonstrate the\nsuperiority of AuralNet over recent methods", "AI": {"tldr": "AuralNet is a 3D multi-source binaural sound localization method that localizes overlapping sources in azimuth and elevation without knowing the number of sources, using a gated coarse-to-fine architecture and multi-head self-attention.", "motivation": "The need for robust sound source localization in noisy-reverberant environments without prior knowledge of the number of sources.", "method": "A gated coarse-to-fine architecture with sector partitioning, multi-head self-attention, and a masked multi-task loss function for joint optimization.", "result": "AuralNet outperforms recent methods in noisy-reverberant conditions.", "conclusion": "AuralNet is effective for 3D sound source localization in challenging environments."}}
{"id": "2506.02545", "pdf": "https://arxiv.org/pdf/2506.02545", "abs": "https://arxiv.org/abs/2506.02545", "authors": ["Kemal Altwlkany", "Amar Kuric", "Emanuel Lacic"], "title": "On the Language and Gender Biases in PSTN, VoIP and Neural Audio Codecs", "categories": ["cs.SD", "eess.AS"], "comment": "Submitted to INTERSPEECH2025", "summary": "In recent years, there has been a growing focus on fairness and inclusivity\nwithin speech technology, particularly in areas such as automatic speech\nrecognition and speech sentiment analysis. When audio is transcoded prior to\nprocessing, as is the case in streaming or real-time applications, any inherent\nbias in the coding mechanism may result in disparities. This not only affects\nuser experience but can also have broader societal implications by perpetuating\nstereotypes and exclusion. Thus, it is important that audio coding mechanisms\nare unbiased. In this work, we contribute towards the scarce research with\nrespect to language and gender biases of audio codecs. By analyzing the speech\nquality of over 2 million multilingual audio files after transcoding through a\nrepresentative subset of codecs (PSTN, VoIP and neural), our results indicate\nthat PSTN codecs are strongly biased in terms of gender and that neural codecs\nintroduce language biases.", "AI": {"tldr": "The paper investigates biases in audio codecs (PSTN, VoIP, neural) for speech technology, revealing gender bias in PSTN and language bias in neural codecs.", "motivation": "Address fairness and inclusivity in speech technology by identifying biases in audio coding mechanisms, which can impact user experience and societal equity.", "method": "Analyzed speech quality of over 2 million multilingual audio files transcoded through PSTN, VoIP, and neural codecs.", "result": "PSTN codecs exhibit strong gender bias, while neural codecs introduce language biases.", "conclusion": "Audio codecs can perpetuate biases; addressing these is crucial for equitable speech technology."}}
{"id": "2506.02604", "pdf": "https://arxiv.org/pdf/2506.02604", "abs": "https://arxiv.org/abs/2506.02604", "authors": ["Tian Chunwei", "Song Mingjian", "Zuo Wangmeng", "Du Bo", "Zhang Yanning", "Zhang Shichao"], "title": "Application of convolutional neural networks in image super-resolution", "categories": ["cs.CV", "eess.IV"], "comment": "It has been accepted by CAAI transactions on intelligent systems, in\n  Chinese language", "summary": "Due to strong learning abilities of convolutional neural networks (CNNs),\nthey have become mainstream methods for image super-resolution. However, there\nare big differences of different deep learning methods with different types.\nThere is little literature to summarize relations and differences of different\nmethods in image super-resolution. Thus, summarizing these literatures are\nimportant, according to loading capacity and execution speed of devices. This\npaper first introduces principles of CNNs in image super-resolution, then\nintroduces CNNs based bicubic interpolation, nearest neighbor interpolation,\nbilinear interpolation, transposed convolution, sub-pixel layer, meta\nup-sampling for image super-resolution to analyze differences and relations of\ndifferent CNNs based interpolations and modules, and compare performance of\nthese methods by experiments. Finally, this paper gives potential research\npoints and drawbacks and summarizes the whole paper, which can facilitate\ndevelopments of CNNs in image super-resolution.", "AI": {"tldr": "A summary of CNN-based methods for image super-resolution, comparing their differences, relations, and performance, and identifying future research directions.", "motivation": "The lack of literature summarizing the relations and differences among CNN-based methods for image super-resolution motivates this paper.", "method": "The paper reviews CNN principles and compares various interpolation methods (bicubic, nearest neighbor, bilinear, transposed convolution, sub-pixel layer, meta up-sampling) through experiments.", "result": "Performance comparisons of different CNN-based interpolation methods are provided.", "conclusion": "The paper highlights potential research points and drawbacks, aiding future developments in CNN-based image super-resolution."}}
{"id": "2506.02095", "pdf": "https://arxiv.org/pdf/2506.02095", "abs": "https://arxiv.org/abs/2506.02095", "authors": ["Hyojin Bahng", "Caroline Chan", "Fredo Durand", "Phillip Isola"], "title": "Cycle Consistency as Reward: Learning Image-Text Alignment without Human Preferences", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "Learning alignment between language and vision is a fundamental challenge,\nespecially as multimodal data becomes increasingly detailed and complex.\nExisting methods often rely on collecting human or AI preferences, which can be\ncostly and time-intensive. We propose an alternative approach that leverages\ncycle consistency as a supervisory signal. Given an image and generated text,\nwe map the text back to image space using a text-to-image model and compute the\nsimilarity between the original image and its reconstruction. Analogously, for\ntext-to-image generation, we measure the textual similarity between an input\ncaption and its reconstruction through the cycle. We use the cycle consistency\nscore to rank candidates and construct a preference dataset of 866K comparison\npairs. The reward model trained on our dataset outperforms state-of-the-art\nalignment metrics on detailed captioning, with superior inference-time\nscalability when used as a verifier for Best-of-N sampling. Furthermore,\nperforming DPO and Diffusion DPO using our dataset enhances performance across\na wide range of vision-language tasks and text-to-image generation. Our\ndataset, model, and code are at https://cyclereward.github.io", "AI": {"tldr": "The paper proposes a cycle consistency-based method to align language and vision, avoiding costly human/AI preference collection. It constructs a dataset of 866K pairs and trains a reward model, outperforming existing metrics and improving vision-language tasks.", "motivation": "Aligning language and vision is challenging with existing methods being costly and time-intensive due to reliance on human or AI preferences.", "method": "Uses cycle consistency as a supervisory signal, mapping text back to image space and vice versa to compute similarity. Constructs a preference dataset and trains a reward model.", "result": "The reward model outperforms state-of-the-art alignment metrics and improves vision-language tasks and text-to-image generation.", "conclusion": "Cycle consistency is an effective, scalable alternative for aligning language and vision, with demonstrated performance gains."}}
{"id": "2506.01975", "pdf": "https://arxiv.org/pdf/2506.01975", "abs": "https://arxiv.org/abs/2506.01975", "authors": ["Jama Hussein Mohamud"], "title": "An empirical study of task and feature correlations in the reuse of pre-trained models", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Pre-trained neural networks are commonly used and reused in the machine\nlearning community. Alice trains a model for a particular task, and a part of\nher neural network is reused by Bob for a different task, often to great\neffect. To what can we ascribe Bob's success? This paper introduces an\nexperimental setup through which factors contributing to Bob's empirical\nsuccess could be studied in silico. As a result, we demonstrate that Bob might\njust be lucky: his task accuracy increases monotonically with the correlation\nbetween his task and Alice's. Even when Bob has provably uncorrelated tasks and\ninput features from Alice's pre-trained network, he can achieve significantly\nbetter than random performance due to Alice's choice of network and optimizer.\nWhen there is little correlation between tasks, only reusing lower pre-trained\nlayers is preferable, and we hypothesize the converse: that the optimal number\nof retrained layers is indicative of task and feature correlation. Finally, we\nshow in controlled real-world scenarios that Bob can effectively reuse Alice's\npre-trained network if there are semantic correlations between his and Alice's\ntask.", "AI": {"tldr": "The paper explores why reusing pre-trained neural networks (Bob's success) works, showing it depends on task correlation and network/optimizer choices, even when tasks are uncorrelated.", "motivation": "To understand the factors behind the empirical success of reusing pre-trained neural networks for different tasks.", "method": "An experimental setup to study task correlation, network layers, and optimizer impact on reuse performance.", "result": "Bob's success is tied to task correlation; even uncorrelated tasks can perform better than random due to network/optimizer choices. Lower layers are better for uncorrelated tasks.", "conclusion": "Reusing pre-trained networks is effective when tasks are semantically correlated, and the optimal layers to reuse can indicate task/feature correlation."}}
{"id": "2506.02387", "pdf": "https://arxiv.org/pdf/2506.02387", "abs": "https://arxiv.org/abs/2506.02387", "authors": ["Zelai Xu", "Zhexuan Xu", "Xiangmin Yi", "Huining Yuan", "Xinlei Chen", "Yi Wu", "Chao Yu", "Yu Wang"], "title": "VS-Bench: Evaluating VLMs for Strategic Reasoning and Decision-Making in Multi-Agent Environments", "categories": ["cs.AI"], "comment": null, "summary": "Recent advancements in Vision Language Models (VLMs) have expanded their\ncapabilities to interactive agent tasks, yet existing benchmarks remain limited\nto single-agent or text-only environments. In contrast, real-world scenarios\noften involve multiple agents interacting within rich visual and linguistic\ncontexts, posing challenges with both multimodal observations and strategic\ninteractions. To bridge this gap, we introduce Visual Strategic Bench\n(VS-Bench), a multimodal benchmark that evaluates VLMs for strategic reasoning\nand decision-making in multi-agent environments. VS-Bench comprises eight\nvision-grounded environments spanning cooperative, competitive, and\nmixed-motive interactions, designed to assess agents' ability to predict\nothers' future moves and optimize for long-term objectives. We consider two\ncomplementary evaluation dimensions, including offline evaluation of strategic\nreasoning by next-action prediction accuracy and online evaluation of\ndecision-making by normalized episode return. Extensive experiments of fourteen\nleading VLMs reveal a significant gap between current models and optimal\nperformance, with the best models attaining 47.8% prediction accuracy and 24.3%\nnormalized return. We further conduct in-depth analyses on multimodal\nobservations, test-time scaling, social behaviors, and failure cases of VLM\nagents. By standardizing the evaluation and highlighting the limitations of\nexisting models, we envision VS-Bench as a foundation for future research on\nstrategic multimodal agents. Code and data are available at\nhttps://vs-bench.github.io.", "AI": {"tldr": "VS-Bench is a new multimodal benchmark for evaluating Vision Language Models (VLMs) in multi-agent strategic reasoning and decision-making, revealing significant performance gaps.", "motivation": "Existing benchmarks lack multi-agent and multimodal contexts, while real-world scenarios require strategic interactions in rich visual and linguistic environments.", "method": "VS-Bench includes eight vision-grounded environments for cooperative, competitive, and mixed-motive interactions, evaluated via next-action prediction accuracy (offline) and normalized episode return (online).", "result": "Experiments with fourteen VLMs show a performance gap, with the best models achieving 47.8% prediction accuracy and 24.3% normalized return.", "conclusion": "VS-Bench standardizes evaluation for strategic multimodal agents, highlighting current limitations and paving the way for future research."}}
{"id": "2506.02175", "pdf": "https://arxiv.org/pdf/2506.02175", "abs": "https://arxiv.org/abs/2506.02175", "authors": ["Salman Rahman", "Sheriff Issaka", "Ashima Suvarna", "Genglin Liu", "James Shiffer", "Jaeyoung Lee", "Md Rizwan Parvez", "Hamid Palangi", "Shi Feng", "Nanyun Peng", "Yejin Choi", "Julian Michael", "Liwei Jiang", "Saadia Gabriel"], "title": "AI Debate Aids Assessment of Controversial Claims", "categories": ["cs.CL"], "comment": null, "summary": "As AI grows more powerful, it will increasingly shape how we understand the\nworld. But with this influence comes the risk of amplifying misinformation and\ndeepening social divides-especially on consequential topics like public health\nwhere factual accuracy directly impacts well-being. Scalable Oversight aims to\nensure AI truthfulness by enabling humans to supervise systems that may exceed\nhuman capabilities--yet humans themselves hold different beliefs and biases\nthat impair their judgment. We study whether AI debate can guide biased judges\ntoward the truth by having two AI systems debate opposing sides of\ncontroversial COVID-19 factuality claims where people hold strong prior\nbeliefs. We conduct two studies: one with human judges holding either\nmainstream or skeptical beliefs evaluating factuality claims through\nAI-assisted debate or consultancy protocols, and a second examining the same\nproblem with personalized AI judges designed to mimic these different human\nbelief systems. In our human study, we find that debate-where two AI advisor\nsystems present opposing evidence-based arguments-consistently improves\njudgment accuracy and confidence calibration, outperforming consultancy with a\nsingle-advisor system by 10% overall. The improvement is most significant for\njudges with mainstream beliefs (+15.2% accuracy), though debate also helps\nskeptical judges who initially misjudge claims move toward accurate views\n(+4.7% accuracy). In our AI judge study, we find that AI judges with human-like\npersonas achieve even higher accuracy (78.5%) than human judges (70.1%) and\ndefault AI judges without personas (69.8%), suggesting their potential for\nsupervising frontier AI models. These findings highlight AI debate as a\npromising path toward scalable, bias-resilient oversight--leveraging both\ndiverse human and AI judgments to move closer to truth in contested domains.", "AI": {"tldr": "AI debate improves judgment accuracy and confidence calibration, especially for biased judges, outperforming single-advisor systems. AI judges with human-like personas achieve higher accuracy than humans or default AI.", "motivation": "Address the risk of AI amplifying misinformation and deepening social divides, particularly in consequential domains like public health, by ensuring AI truthfulness through scalable oversight.", "method": "Conducted two studies: one with human judges evaluating COVID-19 factuality claims via AI debate or consultancy, and another with personalized AI judges mimicking human belief systems.", "result": "Debate improved accuracy by 10% overall, with mainstream judges gaining +15.2% accuracy and skeptical judges +4.7%. AI judges with personas achieved 78.5% accuracy, surpassing humans (70.1%) and default AI (69.8%).", "conclusion": "AI debate is a promising approach for scalable, bias-resilient oversight, leveraging diverse human and AI judgments to enhance truthfulness in contested domains."}}
{"id": "2502.11184", "pdf": "https://arxiv.org/pdf/2502.11184", "abs": "https://arxiv.org/abs/2502.11184", "authors": ["Wenxuan Wang", "Xiaoyuan Liu", "Kuiyi Gao", "Jen-tse Huang", "Youliang Yuan", "Pinjia He", "Shuai Wang", "Zhaopeng Tu"], "title": "Can't See the Forest for the Trees: Benchmarking Multimodal Safety Awareness for Multimodal LLMs", "categories": ["cs.CL", "cs.AI", "cs.CV", "cs.MM"], "comment": "Accepted by ACL 2025", "summary": "Multimodal Large Language Models (MLLMs) have expanded the capabilities of\ntraditional language models by enabling interaction through both text and\nimages. However, ensuring the safety of these models remains a significant\nchallenge, particularly in accurately identifying whether multimodal content is\nsafe or unsafe-a capability we term safety awareness. In this paper, we\nintroduce MMSafeAware, the first comprehensive multimodal safety awareness\nbenchmark designed to evaluate MLLMs across 29 safety scenarios with 1500\ncarefully curated image-prompt pairs. MMSafeAware includes both unsafe and\nover-safety subsets to assess models abilities to correctly identify unsafe\ncontent and avoid over-sensitivity that can hinder helpfulness. Evaluating nine\nwidely used MLLMs using MMSafeAware reveals that current models are not\nsufficiently safe and often overly sensitive; for example, GPT-4V misclassifies\n36.1% of unsafe inputs as safe and 59.9% of benign inputs as unsafe. We further\nexplore three methods to improve safety awareness-prompting-based approaches,\nvisual contrastive decoding, and vision-centric reasoning fine-tuning-but find\nthat none achieve satisfactory performance. Our findings highlight the profound\nchallenges in developing MLLMs with robust safety awareness, underscoring the\nneed for further research in this area. All the code and data will be publicly\navailable to facilitate future research.", "AI": {"tldr": "MMSafeAware is a benchmark for evaluating safety awareness in Multimodal Large Language Models (MLLMs), revealing current models' shortcomings in identifying unsafe content and avoiding over-sensitivity.", "motivation": "Ensuring the safety of MLLMs is challenging, especially in accurately distinguishing safe from unsafe multimodal content.", "method": "Introduces MMSafeAware, a benchmark with 29 safety scenarios and 1500 image-prompt pairs, and evaluates nine MLLMs. Explores three improvement methods: prompting-based approaches, visual contrastive decoding, and vision-centric reasoning fine-tuning.", "result": "Current MLLMs are insufficiently safe and overly sensitive, with GPT-4V misclassifying 36.1% of unsafe inputs as safe and 59.9% of benign inputs as unsafe. None of the tested methods achieved satisfactory performance.", "conclusion": "Developing robust safety awareness in MLLMs is challenging, requiring further research. The benchmark and data are publicly available to aid future studies."}}
{"id": "2506.02777", "pdf": "https://arxiv.org/pdf/2506.02777", "abs": "https://arxiv.org/abs/2506.02777", "authors": ["Paul M. Reuter", "Michael Jessen"], "title": "On the influence of language similarity in non-target speaker verification trials", "categories": ["eess.AS", "cs.SD"], "comment": "accepted to Interspeech 2025", "summary": "In this paper, we investigate the influence of language similarity in\ncross-lingual non-target speaker verification trials using a state-of-the-art\nspeaker verification system, ECAPA-TDNN, trained on multilingual and\nmonolingual variants of the VoxCeleb dataset. Our analysis of the score\ndistribution patterns on multilingual Globalphone and LDC CTS reveals a\nclustering effect in speaker comparisons involving a training language, whereby\nthe choice of comparison language only minimally impacts scores. Conversely, we\nobserve a language similarity effect in trials involving languages not included\nin the training set of the speaker verification system, with scores correlating\nwith language similarity measured by a language classification system,\nespecially when using multilingual training data.", "AI": {"tldr": "The paper examines how language similarity affects cross-lingual speaker verification, finding minimal impact for trained languages but significant correlation for untrained languages.", "motivation": "To understand the role of language similarity in cross-lingual speaker verification trials.", "method": "Uses ECAPA-TDNN trained on VoxCeleb variants, analyzing score distributions on Globalphone and LDC CTS datasets.", "result": "Trained languages show minimal score impact, while untrained languages exhibit scores correlating with language similarity.", "conclusion": "Language similarity significantly affects cross-lingual speaker verification, especially for untrained languages."}}
{"id": "2506.02590", "pdf": "https://arxiv.org/pdf/2506.02590", "abs": "https://arxiv.org/abs/2506.02590", "authors": ["Dimitrios Koutsianos", "Stavros Zacharopoulos", "Yannis Panagakis", "Themos Stafylakis"], "title": "Synthetic Speech Source Tracing using Metric Learning", "categories": ["cs.SD", "cs.CL"], "comment": "Submitted to Interspeech 2025", "summary": "This paper addresses source tracing in synthetic speech-identifying\ngenerative systems behind manipulated audio via speaker recognition-inspired\npipelines. While prior work focuses on spoofing detection, source tracing lacks\nrobust solutions. We evaluate two approaches: classification-based and\nmetric-learning. We tested our methods on the MLAADv5 benchmark using ResNet\nand self-supervised learning (SSL) backbones. The results show that ResNet\nachieves competitive performance with the metric learning approach, matching\nand even exceeding SSL-based systems. Our work demonstrates ResNet's viability\nfor source tracing while underscoring the need to optimize SSL representations\nfor this task. Our work bridges speaker recognition methodologies with audio\nforensic challenges, offering new directions for combating synthetic media\nmanipulation.", "AI": {"tldr": "The paper explores source tracing in synthetic speech using speaker recognition methods, comparing classification-based and metric-learning approaches. ResNet performs competitively, even surpassing SSL-based systems, highlighting its potential for this task.", "motivation": "Prior work lacks robust solutions for source tracing in synthetic speech, focusing mainly on spoofing detection. This paper aims to bridge speaker recognition with audio forensics to address synthetic media manipulation.", "method": "Two approaches are evaluated: classification-based and metric-learning, tested on the MLAADv5 benchmark using ResNet and SSL backbones.", "result": "ResNet achieves competitive performance, matching or exceeding SSL-based systems, demonstrating its viability for source tracing.", "conclusion": "The work shows ResNet's potential for source tracing and emphasizes the need to optimize SSL representations, offering new directions to combat synthetic media manipulation."}}
{"id": "2506.02680", "pdf": "https://arxiv.org/pdf/2506.02680", "abs": "https://arxiv.org/abs/2506.02680", "authors": ["Julius Erbach", "Dominik Narnhofer", "Andreas Dombos", "Bernt Schiele", "Jan Eric Lenssen", "Konrad Schindler"], "title": "Solving Inverse Problems with FLAIR", "categories": ["cs.CV", "eess.IV"], "comment": null, "summary": "Flow-based latent generative models such as Stable Diffusion 3 are able to\ngenerate images with remarkable quality, even enabling photorealistic\ntext-to-image generation. Their impressive performance suggests that these\nmodels should also constitute powerful priors for inverse imaging problems, but\nthat approach has not yet led to comparable fidelity. There are several key\nobstacles: (i) the encoding into a lower-dimensional latent space makes the\nunderlying (forward) mapping non-linear; (ii) the data likelihood term is\nusually intractable; and (iii) learned generative models struggle to recover\nrare, atypical data modes during inference. We present FLAIR, a novel training\nfree variational framework that leverages flow-based generative models as a\nprior for inverse problems. To that end, we introduce a variational objective\nfor flow matching that is agnostic to the type of degradation, and combine it\nwith deterministic trajectory adjustments to recover atypical modes. To enforce\nexact consistency with the observed data, we decouple the optimization of the\ndata fidelity and regularization terms. Moreover, we introduce a time-dependent\ncalibration scheme in which the strength of the regularization is modulated\naccording to off-line accuracy estimates. Results on standard imaging\nbenchmarks demonstrate that FLAIR consistently outperforms existing diffusion-\nand flow-based methods in terms of reconstruction quality and sample diversity.", "AI": {"tldr": "FLAIR is a training-free variational framework using flow-based generative models as priors for inverse imaging problems, outperforming existing methods in quality and diversity.", "motivation": "Flow-based models like Stable Diffusion 3 show high-quality image generation but struggle as priors for inverse problems due to non-linear mappings, intractable likelihoods, and rare mode recovery.", "method": "FLAIR introduces a variational objective for flow matching, deterministic trajectory adjustments, decoupled optimization, and time-dependent calibration.", "result": "FLAIR outperforms existing diffusion- and flow-based methods in reconstruction quality and sample diversity on standard benchmarks.", "conclusion": "FLAIR effectively leverages flow-based models for inverse problems, addressing key obstacles and achieving superior performance."}}
{"id": "2506.02112", "pdf": "https://arxiv.org/pdf/2506.02112", "abs": "https://arxiv.org/abs/2506.02112", "authors": ["Xuweiyi Chen", "Tian Xia", "Sihan Xu", "Jianing Yang", "Joyce Chai", "Zezhou Cheng"], "title": "SAB3R: Semantic-Augmented Backbone in 3D Reconstruction", "categories": ["cs.CV"], "comment": "Project page: https://uva-computer-vision-lab.github.io/sab3r/", "summary": "We introduce a new task, Map and Locate, which unifies the traditionally\ndistinct objectives of open-vocabulary segmentation - detecting and segmenting\nobject instances based on natural language queries - and 3D reconstruction, the\nprocess of estimating a scene's 3D structure from visual inputs. Specifically,\nMap and Locate involves generating a point cloud from an unposed video and\nsegmenting object instances based on open-vocabulary queries. This task serves\nas a critical step toward real-world embodied AI applications and introduces a\npractical task that bridges reconstruction, recognition and reorganization. To\ntackle this task, we introduce a simple yet effective baseline, which we denote\nas SAB3R. Our approach builds upon MASt3R, a recent breakthrough in 3D computer\nvision, and incorporates a lightweight distillation strategy. This method\ntransfers dense, per-pixel semantic features from 2D vision backbones (eg, CLIP\nand DINOv2) to enhance MASt3R's capabilities. Without introducing any auxiliary\nfrozen networks, our model generates per-pixel semantic features and constructs\ncohesive point maps in a single forward pass. Compared to separately deploying\nMASt3R and CLIP, our unified model, SAB3R, achieves superior performance on the\nMap and Locate benchmark. Furthermore, we evaluate SAB3R on both 2D semantic\nsegmentation and 3D tasks to comprehensively validate its effectiveness.", "AI": {"tldr": "The paper introduces 'Map and Locate,' a task combining open-vocabulary segmentation and 3D reconstruction, and proposes SAB3R, a unified model outperforming existing methods.", "motivation": "To bridge the gap between reconstruction, recognition, and reorganization for real-world embodied AI applications.", "method": "SAB3R builds on MASt3R, using lightweight distillation to transfer 2D semantic features (e.g., CLIP, DINOv2) for cohesive point maps in one pass.", "result": "SAB3R outperforms separate MASt3R and CLIP deployments on the Map and Locate benchmark and excels in 2D/3D tasks.", "conclusion": "SAB3R effectively unifies segmentation and reconstruction, advancing practical AI applications."}}
{"id": "2506.01976", "pdf": "https://arxiv.org/pdf/2506.01976", "abs": "https://arxiv.org/abs/2506.01976", "authors": ["Elham Kiyani", "Venkatesh Ananchaperumal", "Ahmad Peyvan", "Mahendaran Uchimali", "Gang Li", "George Em Karniadakis"], "title": "Crack Path Prediction with Operator Learning using Discrete Particle System data Generation", "categories": ["cs.LG", "cond-mat.mtrl-sci", "cs.AI"], "comment": "22 pages, 14 figures", "summary": "Accurately modeling crack propagation is critical for predicting failure in\nengineering materials and structures, where small cracks can rapidly evolve and\ncause catastrophic damage. The interaction of cracks with discontinuities, such\nas holes, significantly affects crack deflection and arrest. Recent\ndevelopments in discrete particle systems with multibody interactions based on\nconstitutive behavior have demonstrated the ability to capture crack nucleation\nand evolution without relying on continuum assumptions. In this work, we use\ndata from Constitutively Informed Particle Dynamics (CPD) simulations to train\noperator learning models, specifically Deep Operator Networks (DeepONets),\nwhich learn mappings between function spaces instead of finite-dimensional\nvectors. We explore two DeepONet variants: vanilla and Fusion DeepONet, for\npredicting time-evolving crack propagation in specimens with varying\ngeometries. Three representative cases are studied: (i) varying notch height\nwithout active fracture; and (ii) and (iii) combinations of notch height and\nhole radius where dynamic fracture occurs on irregular discrete meshes. The\nmodels are trained on 32 to 45 samples, using geometric inputs in the branch\nnetwork and spatial-temporal coordinates in the trunk network. Results show\nthat Fusion DeepONet consistently outperforms the vanilla variant, with more\naccurate predictions especially in non-fracturing cases. Fracture-driven\nscenarios involving displacement and crack evolution remain more challenging.\nThese findings highlight the potential of Fusion DeepONet to generalize across\ncomplex, geometry-varying, and time-dependent crack propagation phenomena.", "AI": {"tldr": "The paper explores using DeepONets to predict crack propagation in materials, comparing vanilla and Fusion DeepONet variants. Fusion DeepONet shows better accuracy, especially in non-fracturing cases.", "motivation": "Accurate crack propagation modeling is crucial for predicting material failure, especially with discontinuities like holes. Traditional methods rely on continuum assumptions, but discrete particle systems offer an alternative.", "method": "Uses Constitutively Informed Particle Dynamics (CPD) data to train DeepONets (vanilla and Fusion variants) for predicting crack propagation. Cases include varying notch heights and hole radii.", "result": "Fusion DeepONet outperforms vanilla DeepONet, particularly in non-fracturing scenarios. Fracture-driven cases remain challenging.", "conclusion": "Fusion DeepONet shows promise for generalizing complex, geometry-varying crack propagation, though fracture scenarios need further improvement."}}
{"id": "2506.02397", "pdf": "https://arxiv.org/pdf/2506.02397", "abs": "https://arxiv.org/abs/2506.02397", "authors": ["Shengjia Zhang", "Junjie Wu", "Jiawei Chen", "Changwang Zhang", "Xingyu Lou", "Wangchunshu Zhou", "Sheng Zhou", "Can Wang", "Jun Wang"], "title": "OThink-R1: Intrinsic Fast/Slow Thinking Mode Switching for Over-Reasoning Mitigation", "categories": ["cs.AI"], "comment": null, "summary": "Recent advanced large reasoning models (LRMs) leverage extended\nchain-of-thought (CoT) reasoning to solve complex tasks, achieving\nstate-of-the-art performance. Despite their success, we identify a critical\nissue: a substantial portion of simple tasks solved by LRMs can also be\naddressed by non-reasoning LLMs using significantly fewer tokens, indicating\nthe complex reasoning may not always be necessary. To address this, we\nsystematically analyze the reasoning trajectories of LRMs and present a method\nutilizing identified paradigms and LLM-Judge to classify these trajectories as\neither Redundant Reasoning or Essential Reasoning. And we introduce OThink-R1,\na method that prunes redundant reasoning steps while preserving logical\nvalidity. OThink-R1 dynamically employs the non-thinking mode (fast-thinking)\nfor straightforward problems while engaging in deliberate thinking\n(slow-thinking) for complex problems. Experiments across mathematical and\nquestion-answering tasks demonstrate that OThink-R1 reduces reasoning\nredundancy by almost 23\\% on average without compromising accuracy, offering\npractical guidelines for efficient reasoning models. The code is available at\nhttps://github.com/AgenticIR-Lab/OThink-R1.", "AI": {"tldr": "OThink-R1 reduces redundant reasoning in LRMs by dynamically switching between fast and slow thinking, cutting redundancy by 23% without accuracy loss.", "motivation": "Identify and address the inefficiency of large reasoning models (LRMs) using complex reasoning for tasks solvable by simpler methods.", "method": "Analyze reasoning trajectories, classify them as redundant or essential, and introduce OThink-R1 to prune redundant steps while maintaining validity.", "result": "OThink-R1 reduces reasoning redundancy by 23% on average without compromising accuracy.", "conclusion": "OThink-R1 offers a practical solution for efficient reasoning, balancing speed and complexity."}}
{"id": "2506.02181", "pdf": "https://arxiv.org/pdf/2506.02181", "abs": "https://arxiv.org/abs/2506.02181", "authors": ["Dennis Fucci", "Marco Gaido", "Matteo Negri", "Mauro Cettolo", "Luisa Bentivogli"], "title": "Echoes of Phonetics: Unveiling Relevant Acoustic Cues for ASR via Feature Attribution", "categories": ["cs.CL", "cs.AI"], "comment": "Accepted at Interspeech 2025", "summary": "Despite significant advances in ASR, the specific acoustic cues models rely\non remain unclear. Prior studies have examined such cues on a limited set of\nphonemes and outdated models. In this work, we apply a feature attribution\ntechnique to identify the relevant acoustic cues for a modern Conformer-based\nASR system. By analyzing plosives, fricatives, and vowels, we assess how\nfeature attributions align with their acoustic properties in the time and\nfrequency domains, also essential for human speech perception. Our findings\nshow that the ASR model relies on vowels' full time spans, particularly their\nfirst two formants, with greater saliency in male speech. It also better\ncaptures the spectral characteristics of sibilant fricatives than non-sibilants\nand prioritizes the release phase in plosives, especially burst\ncharacteristics. These insights enhance the interpretability of ASR models and\nhighlight areas for future research to uncover potential gaps in model\nrobustness.", "AI": {"tldr": "The paper investigates acoustic cues used by a modern Conformer-based ASR system, revealing its reliance on specific features like vowel formants, fricative spectra, and plosive bursts.", "motivation": "To clarify the acoustic cues modern ASR models rely on, addressing gaps in prior limited and outdated studies.", "method": "Feature attribution technique applied to analyze plosives, fricatives, and vowels in time and frequency domains.", "result": "ASR model prioritizes vowel formants (especially in male speech), sibilant fricative spectra, and plosive bursts.", "conclusion": "Findings improve ASR interpretability and identify areas for future research on model robustness."}}
{"id": "2502.12562", "pdf": "https://arxiv.org/pdf/2502.12562", "abs": "https://arxiv.org/abs/2502.12562", "authors": ["Weikai Lu", "Hao Peng", "Huiping Zhuang", "Cen Chen", "Ziqian Zeng"], "title": "SEA: Low-Resource Safety Alignment for Multimodal Large Language Models via Synthetic Embeddings", "categories": ["cs.CL", "cs.CR", "cs.MM"], "comment": "Accepted in ACL 2025 Main Track", "summary": "Multimodal Large Language Models (MLLMs) have serious security\nvulnerabilities.While safety alignment using multimodal datasets consisting of\ntext and data of additional modalities can effectively enhance MLLM's security,\nit is costly to construct these datasets. Existing low-resource security\nalignment methods, including textual alignment, have been found to struggle\nwith the security risks posed by additional modalities. To address this, we\npropose Synthetic Embedding augmented safety Alignment (SEA), which optimizes\nembeddings of additional modality through gradient updates to expand textual\ndatasets. This enables multimodal safety alignment training even when only\ntextual data is available. Extensive experiments on image, video, and\naudio-based MLLMs demonstrate that SEA can synthesize a high-quality embedding\non a single RTX3090 GPU within 24 seconds. SEA significantly improves the\nsecurity of MLLMs when faced with threats from additional modalities. To assess\nthe security risks introduced by video and audio, we also introduced a new\nbenchmark called VA-SafetyBench. High attack success rates across multiple\nMLLMs validate its challenge. Our code and data will be available at\nhttps://github.com/ZeroNLP/SEA.", "AI": {"tldr": "SEA is a method for enhancing MLLM security by optimizing embeddings of additional modalities using textual data, achieving high-quality results efficiently.", "motivation": "Addressing the high cost and limitations of existing methods for securing MLLMs against multimodal threats.", "method": "SEA optimizes embeddings of additional modalities through gradient updates to expand textual datasets, enabling multimodal safety alignment with only textual data.", "result": "SEA synthesizes high-quality embeddings quickly (24s on RTX3090) and significantly improves MLLM security against multimodal threats. A new benchmark, VA-SafetyBench, validates the challenge.", "conclusion": "SEA provides an efficient, low-resource solution for multimodal safety alignment, validated by experiments and a new benchmark."}}
{"id": "2506.02797", "pdf": "https://arxiv.org/pdf/2506.02797", "abs": "https://arxiv.org/abs/2506.02797", "authors": ["Paul Didier", "Toon van Waterschoot", "Simon Doclo", "J\u00f6rg Bitzer", "Marc Moonen"], "title": "Fast-Converging Distributed Signal Estimation in Topology-Unconstrained Wireless Acoustic Sensor Networks", "categories": ["eess.AS", "cs.SD"], "comment": null, "summary": "This paper focuses on distributed signal estimation in topology-unconstrained\nwireless acoustic sensor networks (WASNs) where sensor nodes only transmit\nfused versions of their local sensor signals. For this task, the\ntopology-independent (TI) distributed adaptive node-specific signal estimation\n(DANSE) algorithm (TI-DANSE) has previously been proposed. It converges towards\nthe centralized signal estimation solution in non-fully connected and\ntime-varying network topologies. However, the applicability of TI-DANSE in\nreal-world scenarios is limited due to its slow convergence. The latter results\nfrom the fact that, in TI-DANSE, nodes only have access to the in-network sum\nof all fused signals in the WASN. We address this low convergence speed by\nintroducing an improved TI-DANSE algorithm, referred to as TI-DANSE+, in which\nupdating nodes separately use the partial in-network sums of fused signals\ncoming from each of their neighbors. Nodes can maximize the number of available\ndegrees of freedom in their local optimization problem, leading to faster\nconvergence. This is further exploited by combining TI-DANSE+ with a\ntree-pruning strategy that maximizes the number of neighbors at the updating\nnode. In fully connected WASNs, TI-DANSE+ converges as fast as the original\nDANSE algorithm (the latter only defined for fully connected WASNs) while using\npeer-to-peer data transmission instead of broadcasting and thus saving\ncommunication bandwidth. If link failures occur, the convergence of TI-DANSE+\ntowards the centralized solution is preserved without any change in its\nformulation. Altogether, the proposed TI-DANSE+ algorithm can be viewed as an\nall-round alternative to DANSE and TI-DANSE which (i) merges the advantages of\nboth, (ii) reconciliates their differences into a single formulation, and (iii)\nshows advantages of its own in terms of communication bandwidth usage.", "AI": {"tldr": "The paper introduces TI-DANSE+, an improved version of TI-DANSE for distributed signal estimation in WASNs, offering faster convergence and better communication efficiency.", "motivation": "The slow convergence of TI-DANSE in real-world scenarios due to limited access to fused signals motivates the development of TI-DANSE+.", "method": "TI-DANSE+ uses partial in-network sums of fused signals from neighbors and combines it with a tree-pruning strategy to maximize degrees of freedom and neighbor count.", "result": "TI-DANSE+ achieves faster convergence, preserves performance under link failures, and saves communication bandwidth compared to TI-DANSE and DANSE.", "conclusion": "TI-DANSE+ is a versatile alternative to DANSE and TI-DANSE, combining their strengths and offering additional benefits in communication efficiency."}}
{"id": "2506.02610", "pdf": "https://arxiv.org/pdf/2506.02610", "abs": "https://arxiv.org/abs/2506.02610", "authors": ["Zhaoyang Li", "Jie Wang", "XiaoXiao Li", "Wangjie Li", "Longjie Luo", "Lin Li", "Qingyang Hong"], "title": "Speaker Diarization with Overlapping Community Detection Using Graph Attention Networks and Label Propagation Algorithm", "categories": ["cs.SD", "cs.AI", "eess.AS"], "comment": null, "summary": "In speaker diarization, traditional clustering-based methods remain widely\nused in real-world applications. However, these methods struggle with the\ncomplex distribution of speaker embeddings and overlapping speech segments. To\naddress these limitations, we propose an Overlapping Community Detection method\nbased on Graph Attention networks and the Label Propagation Algorithm\n(OCDGALP). The proposed framework comprises two key components: (1) a graph\nattention network that refines speaker embeddings and node connections by\naggregating information from neighboring nodes, and (2) a label propagation\nalgorithm that assigns multiple community labels to each node, enabling\nsimultaneous clustering and overlapping community detection. Experimental\nresults show that the proposed method significantly reduces the Diarization\nError Rate (DER), achieving a state-of-the-art 15.94% DER on the DIHARD-III\ndataset without oracle Voice Activity Detection (VAD), and an impressive 11.07%\nwith oracle VAD.", "AI": {"tldr": "Proposes OCDGALP, a method combining Graph Attention networks and Label Propagation for speaker diarization, reducing DER significantly.", "motivation": "Traditional clustering-based methods struggle with complex speaker embeddings and overlapping speech segments.", "method": "Uses a Graph Attention Network to refine embeddings and a Label Propagation Algorithm for overlapping community detection.", "result": "Achieves 15.94% DER on DIHARD-III without oracle VAD and 11.07% with oracle VAD.", "conclusion": "OCDGALP outperforms traditional methods, offering a robust solution for speaker diarization."}}
{"id": "2506.02981", "pdf": "https://arxiv.org/pdf/2506.02981", "abs": "https://arxiv.org/abs/2506.02981", "authors": ["Joonyeoup Kim", "Yu Yuan", "Xingguang Zhang", "Xijun Wang", "Stanley Chan"], "title": "Astrophotography turbulence mitigation via generative models", "categories": ["cs.CV", "eess.IV"], "comment": null, "summary": "Photography is the cornerstone of modern astronomical and space research.\nHowever, most astronomical images captured by ground-based telescopes suffer\nfrom atmospheric turbulence, resulting in degraded imaging quality. While\nmulti-frame strategies like lucky imaging can mitigate some effects, they\ninvolve intensive data acquisition and complex manual processing. In this\npaper, we propose AstroDiff, a generative restoration method that leverages\nboth the high-quality generative priors and restoration capabilities of\ndiffusion models to mitigate atmospheric turbulence. Extensive experiments\ndemonstrate that AstroDiff outperforms existing state-of-the-art learning-based\nmethods in astronomical image turbulence mitigation, providing higher\nperceptual quality and better structural fidelity under severe turbulence\nconditions. Our code and additional results are available at\nhttps://web-six-kappa-66.vercel.app/", "AI": {"tldr": "AstroDiff, a diffusion-based method, improves astronomical image quality by mitigating atmospheric turbulence, outperforming existing learning-based techniques.", "motivation": "Ground-based telescope images suffer from atmospheric turbulence, degrading quality. Current methods like lucky imaging are data-intensive and require manual processing.", "method": "AstroDiff uses generative priors and diffusion models to restore images affected by turbulence.", "result": "AstroDiff surpasses state-of-the-art methods, offering better perceptual quality and structural fidelity in severe turbulence.", "conclusion": "AstroDiff is an effective solution for turbulence mitigation in astronomical images, with code and results publicly available."}}
{"id": "2506.02150", "pdf": "https://arxiv.org/pdf/2506.02150", "abs": "https://arxiv.org/abs/2506.02150", "authors": ["Stefano Fogarollo", "Gregor Laimer", "Reto Bale", "Matthias Harders"], "title": "Implicit Deformable Medical Image Registration with Learnable Kernels", "categories": ["cs.CV", "cs.AI"], "comment": "MICCAI 2025 Provisional Accept", "summary": "Deformable medical image registration is an essential task in\ncomputer-assisted interventions. This problem is particularly relevant to\noncological treatments, where precise image alignment is necessary for tracking\ntumor growth, assessing treatment response, and ensuring accurate delivery of\ntherapies. Recent AI methods can outperform traditional techniques in accuracy\nand speed, yet they often produce unreliable deformations that limit their\nclinical adoption. In this work, we address this challenge and introduce a\nnovel implicit registration framework that can predict accurate and reliable\ndeformations. Our insight is to reformulate image registration as a signal\nreconstruction problem: we learn a kernel function that can recover the dense\ndisplacement field from sparse keypoint correspondences. We integrate our\nmethod in a novel hierarchical architecture, and estimate the displacement\nfield in a coarse-to-fine manner. Our formulation also allows for efficient\nrefinement at test time, permitting clinicians to easily adjust registrations\nwhen needed. We validate our method on challenging intra-patient thoracic and\nabdominal zero-shot registration tasks, using public and internal datasets from\nthe local University Hospital. Our method not only shows competitive accuracy\nto state-of-the-art approaches, but also bridges the generalization gap between\nimplicit and explicit registration techniques. In particular, our method\ngenerates deformations that better preserve anatomical relationships and\nmatches the performance of specialized commercial systems, underscoring its\npotential for clinical adoption.", "AI": {"tldr": "A novel implicit registration framework for deformable medical image registration improves accuracy and reliability, outperforming traditional and recent AI methods while preserving anatomical relationships.", "motivation": "Precise image alignment is crucial for oncological treatments, but current AI methods often produce unreliable deformations, limiting clinical adoption.", "method": "The framework reformulates registration as a signal reconstruction problem, learning a kernel function to recover dense displacement fields from sparse keypoints, integrated in a hierarchical coarse-to-fine architecture.", "result": "Validated on thoracic and abdominal tasks, the method matches specialized commercial systems, showing competitive accuracy and better generalization.", "conclusion": "The method bridges the gap between implicit and explicit techniques, offering reliable deformations with potential for clinical use."}}
{"id": "2506.01977", "pdf": "https://arxiv.org/pdf/2506.01977", "abs": "https://arxiv.org/abs/2506.01977", "authors": ["Wei Huang", "Hanchen Wang", "Dong Wen", "Shaozhen Ma", "Wenjie Zhang", "Xuemin Lin"], "title": "Towards Unsupervised Training of Matching-based Graph Edit Distance Solver via Preference-aware GAN", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Graph Edit Distance (GED) is a fundamental graph similarity metric widely\nused in various applications. However, computing GED is an NP-hard problem.\nRecent state-of-the-art hybrid GED solver has shown promising performance by\nformulating GED as a bipartite graph matching problem, then leveraging a\ngenerative diffusion model to predict node matching between two graphs, from\nwhich both the GED and its corresponding edit path can be extracted using a\ntraditional algorithm. However, such methods typically rely heavily on\nground-truth supervision, where the ground-truth labels are often costly to\nobtain in real-world scenarios. In this paper, we propose GEDRanker, a novel\nunsupervised GAN-based framework for GED computation. Specifically, GEDRanker\nconsists of a matching-based GED solver and introduces an interpretable\npreference-aware discriminator with an effective training strategy to guide the\nmatching-based GED solver toward generating high-quality node matching without\nthe need for ground-truth labels. Extensive experiments on benchmark datasets\ndemonstrate that our GEDRanker enables the matching-based GED solver to achieve\nnear-optimal solution quality without any ground-truth supervision.", "AI": {"tldr": "GEDRanker is an unsupervised GAN-based framework for Graph Edit Distance (GED) computation, eliminating the need for costly ground-truth labels while achieving near-optimal results.", "motivation": "Existing GED methods rely heavily on ground-truth supervision, which is expensive to obtain. GEDRanker addresses this by proposing an unsupervised approach.", "method": "GEDRanker uses a matching-based GED solver and a preference-aware discriminator with an effective training strategy to generate high-quality node matching without ground-truth labels.", "result": "Experiments show GEDRanker achieves near-optimal solution quality without supervision.", "conclusion": "GEDRanker provides a practical, unsupervised alternative for GED computation, reducing reliance on costly labeled data."}}
{"id": "2506.02456", "pdf": "https://arxiv.org/pdf/2506.02456", "abs": "https://arxiv.org/abs/2506.02456", "authors": ["Tri Cao", "Bennett Lim", "Yue Liu", "Yuan Sui", "Yuexin Li", "Shumin Deng", "Lin Lu", "Nay Oo", "Shuicheng Yan", "Bryan Hooi"], "title": "VPI-Bench: Visual Prompt Injection Attacks for Computer-Use Agents", "categories": ["cs.AI", "cs.CR"], "comment": "Under Review", "summary": "Computer-Use Agents (CUAs) with full system access enable powerful task\nautomation but pose significant security and privacy risks due to their ability\nto manipulate files, access user data, and execute arbitrary commands. While\nprior work has focused on browser-based agents and HTML-level attacks, the\nvulnerabilities of CUAs remain underexplored. In this paper, we investigate\nVisual Prompt Injection (VPI) attacks, where malicious instructions are\nvisually embedded within rendered user interfaces, and examine their impact on\nboth CUAs and Browser-Use Agents (BUAs). We propose VPI-Bench, a benchmark of\n306 test cases across five widely used platforms, to evaluate agent robustness\nunder VPI threats. Each test case is a variant of a web platform, designed to\nbe interactive, deployed in a realistic environment, and containing a visually\nembedded malicious prompt. Our empirical study shows that current CUAs and BUAs\ncan be deceived at rates of up to 51% and 100%, respectively, on certain\nplatforms. The experimental results also indicate that system prompt defenses\noffer only limited improvements. These findings highlight the need for robust,\ncontext-aware defenses to ensure the safe deployment of multimodal AI agents in\nreal-world environments. The code and dataset are available at:\nhttps://github.com/cua-framework/agents", "AI": {"tldr": "The paper explores Visual Prompt Injection (VPI) attacks on Computer-Use Agents (CUAs) and Browser-Use Agents (BUAs), proposing VPI-Bench to evaluate their robustness. Results show high deception rates, emphasizing the need for better defenses.", "motivation": "To address underexplored vulnerabilities of CUAs and BUAs, particularly VPI attacks, and assess their impact.", "method": "Developed VPI-Bench, a benchmark with 306 test cases across five platforms, embedding malicious prompts in user interfaces.", "result": "CUAs and BUAs were deceived at rates up to 51% and 100%, respectively, with limited improvement from system prompt defenses.", "conclusion": "Robust, context-aware defenses are crucial for safe deployment of multimodal AI agents."}}
{"id": "2506.02204", "pdf": "https://arxiv.org/pdf/2506.02204", "abs": "https://arxiv.org/abs/2506.02204", "authors": ["Lindia Tjuatja", "Graham Neubig"], "title": "BehaviorBox: Automated Discovery of Fine-Grained Performance Differences Between Language Models", "categories": ["cs.CL"], "comment": "Accepted to ACL 2025 Main Conference", "summary": "Language model evaluation is a daunting task: prompts are brittle,\ncorpus-level perplexities are vague, and the choice of benchmarks are endless.\nFinding examples that show meaningful, generalizable differences between two\nLMs is crucial to understanding where one model succeeds and another fails. Can\nthis process be done automatically? In this work, we propose methodology for\nautomated comparison of language models that uses performance-aware contextual\nembeddings to find fine-grained features of text where one LM outperforms\nanother. Our method, which we name BehaviorBox, extracts coherent features that\ndemonstrate differences with respect to the ease of generation between two LMs.\nSpecifically, BehaviorBox finds features that describe groups of words in\nfine-grained contexts, such as \"conditional 'were' in the phrase 'if you were'\"\nand \"exclamation marks after emotional statements\", where one model outperforms\nanother within a particular datatset. We apply BehaviorBox to compare models\nthat vary in size, model family, and post-training, and enumerate insights into\nspecific contexts that illustrate meaningful differences in performance which\ncannot be found by measures such as corpus-level perplexity alone.", "AI": {"tldr": "BehaviorBox automates LM comparison by identifying fine-grained text features where one model outperforms another, revealing insights beyond corpus-level perplexity.", "motivation": "Manual evaluation of language models is challenging due to brittle prompts, vague perplexities, and endless benchmarks. Automated methods are needed to find meaningful differences.", "method": "BehaviorBox uses performance-aware contextual embeddings to extract coherent features (e.g., specific word groups or contexts) where one LM excels over another.", "result": "Applied to models of varying size, family, and post-training, BehaviorBox identifies specific contexts (e.g., conditional phrases) with performance differences.", "conclusion": "BehaviorBox provides a scalable, automated way to uncover nuanced LM performance differences, complementing traditional metrics like perplexity."}}
{"id": "2506.02863", "pdf": "https://arxiv.org/pdf/2506.02863", "abs": "https://arxiv.org/abs/2506.02863", "authors": ["Helin Wang", "Jiarui Hai", "Dading Chong", "Karan Thakkar", "Tiantian Feng", "Dongchao Yang", "Junhyeok Lee", "Laureano Moro Velazquez", "Jesus Villalba", "Zengyi Qin", "Shrikanth Narayanan", "Mounya Elhiali", "Najim Dehak"], "title": "CapSpeech: Enabling Downstream Applications in Style-Captioned Text-to-Speech", "categories": ["eess.AS", "cs.AI", "cs.SD"], "comment": null, "summary": "Recent advancements in generative artificial intelligence have significantly\ntransformed the field of style-captioned text-to-speech synthesis (CapTTS).\nHowever, adapting CapTTS to real-world applications remains challenging due to\nthe lack of standardized, comprehensive datasets and limited research on\ndownstream tasks built upon CapTTS. To address these gaps, we introduce\nCapSpeech, a new benchmark designed for a series of CapTTS-related tasks,\nincluding style-captioned text-to-speech synthesis with sound events\n(CapTTS-SE), accent-captioned TTS (AccCapTTS), emotion-captioned TTS\n(EmoCapTTS), and text-to-speech synthesis for chat agent (AgentTTS). CapSpeech\ncomprises over 10 million machine-annotated audio-caption pairs and nearly 0.36\nmillion human-annotated audio-caption pairs. In addition, we introduce two new\ndatasets collected and recorded by a professional voice actor and experienced\naudio engineers, specifically for the AgentTTS and CapTTS-SE tasks. Alongside\nthe datasets, we conduct comprehensive experiments using both autoregressive\nand non-autoregressive models on CapSpeech. Our results demonstrate\nhigh-fidelity and highly intelligible speech synthesis across a diverse range\nof speaking styles. To the best of our knowledge, CapSpeech is the largest\navailable dataset offering comprehensive annotations for CapTTS-related tasks.\nThe experiments and findings further provide valuable insights into the\nchallenges of developing CapTTS systems.", "AI": {"tldr": "The paper introduces CapSpeech, a benchmark for CapTTS-related tasks, addressing gaps in datasets and downstream research. It includes large-scale annotated data and demonstrates high-quality speech synthesis.", "motivation": "To address the lack of standardized datasets and limited research on downstream tasks in CapTTS, hindering real-world applications.", "method": "Introduces CapSpeech with over 10M machine-annotated and 0.36M human-annotated audio-caption pairs, and two new datasets. Tests autoregressive and non-autoregressive models.", "result": "Achieves high-fidelity and intelligible speech synthesis across diverse styles. CapSpeech is the largest annotated dataset for CapTTS.", "conclusion": "CapSpeech provides valuable insights and resources for advancing CapTTS systems, addressing key challenges in the field."}}
{"id": "2506.02621", "pdf": "https://arxiv.org/pdf/2506.02621", "abs": "https://arxiv.org/abs/2506.02621", "authors": ["Zhaoyang Li", "Haodong Zhou", "Longjie Luo", "Xiaoxiao Li", "Yongxin Chen", "Lin Li", "Qingyang Hong"], "title": "Cross-attention and Self-attention for Audio-visual Speaker Diarization in MISP-Meeting Challenge", "categories": ["cs.SD"], "comment": null, "summary": "This paper presents the system developed for Task 1 of the Multi-modal\nInformation-based Speech Processing (MISP) 2025 Challenge. We introduce\nCASA-Net, an embedding fusion method designed for end-to-end audio-visual\nspeaker diarization (AVSD) systems. CASA-Net incorporates a cross-attention\n(CA) module to effectively capture cross-modal interactions in audio-visual\nsignals and employs a self-attention (SA) module to learn contextual\nrelationships among audio-visual frames. To further enhance performance, we\nadopt a training strategy that integrates pseudo-label refinement and\nretraining, improving the accuracy of timestamp predictions. Additionally,\nmedian filtering and overlap averaging are applied as post-processing\ntechniques to eliminate outliers and smooth prediction labels. Our system\nachieved a diarization error rate (DER) of 8.18% on the evaluation set,\nrepresenting a relative improvement of 47.3% over the baseline DER of 15.52%.", "AI": {"tldr": "CASA-Net, an embedding fusion method for AVSD, uses cross-attention and self-attention modules, with pseudo-label refinement and post-processing, achieving a 47.3% DER improvement.", "motivation": "To enhance audio-visual speaker diarization by capturing cross-modal interactions and contextual relationships.", "method": "CASA-Net with cross-attention and self-attention modules, pseudo-label refinement, retraining, and post-processing (median filtering, overlap averaging).", "result": "Achieved 8.18% DER, a 47.3% improvement over the baseline (15.52%).", "conclusion": "CASA-Net effectively improves AVSD performance through cross-modal fusion and refined training strategies."}}
{"id": "2411.11190", "pdf": "https://arxiv.org/pdf/2411.11190", "abs": "https://arxiv.org/abs/2411.11190", "authors": ["Zhen Yuan", "David Stojanovski", "Lei Li", "Alberto Gomez", "Haran Jogeesvaran", "Esther Puyol-Ant\u00f3n", "Baba Inusa", "Andrew P. King"], "title": "DeepSPV: A Deep Learning Pipeline for 3D Spleen Volume Estimation from 2D Ultrasound Images", "categories": ["eess.IV", "cs.CV"], "comment": "arXiv admin note: substantial text overlap with arXiv:2308.08038", "summary": "Splenomegaly, the enlargement of the spleen, is an important clinical\nindicator for various associated medical conditions, such as sickle cell\ndisease (SCD). Spleen length measured from 2D ultrasound is the most widely\nused metric for characterising spleen size. However, it is still considered a\nsurrogate measure, and spleen volume remains the gold standard for assessing\nspleen size. Accurate spleen volume measurement typically requires 3D imaging\nmodalities, such as computed tomography or magnetic resonance imaging, but\nthese are not widely available, especially in the Global South which has a high\nprevalence of SCD. In this work, we introduce a deep learning pipeline,\nDeepSPV, for precise spleen volume estimation from single or dual 2D ultrasound\nimages. The pipeline involves a segmentation network and a variational\nautoencoder for learning low-dimensional representations from the estimated\nsegmentations. We investigate three approaches for spleen volume estimation and\nour best model achieves 86.62%/92.5% mean relative volume accuracy (MRVA) under\nsingle-view/dual-view settings, surpassing the performance of human experts. In\naddition, the pipeline can provide confidence intervals for the volume\nestimates as well as offering benefits in terms of interpretability, which\nfurther support clinicians in decision-making when identifying splenomegaly. We\nevaluate the full pipeline using a highly realistic synthetic dataset generated\nby a diffusion model, achieving an overall MRVA of 83.0% from a single 2D\nultrasound image. Our proposed DeepSPV is the first work to use deep learning\nto estimate 3D spleen volume from 2D ultrasound images and can be seamlessly\nintegrated into the current clinical workflow for spleen assessment.", "AI": {"tldr": "DeepSPV, a deep learning pipeline, estimates spleen volume from 2D ultrasound images, outperforming human experts and offering interpretability for clinical use.", "motivation": "Spleen volume is the gold standard for assessing spleen size, but 3D imaging is not widely available, especially in regions with high sickle cell disease prevalence.", "method": "DeepSPV combines a segmentation network and a variational autoencoder to estimate spleen volume from single or dual 2D ultrasound images.", "result": "The best model achieves 86.62%/92.5% mean relative volume accuracy under single-view/dual-view settings, surpassing human experts.", "conclusion": "DeepSPV is the first deep learning approach for 3D spleen volume estimation from 2D ultrasound, offering seamless integration into clinical workflows."}}
{"id": "2506.02161", "pdf": "https://arxiv.org/pdf/2506.02161", "abs": "https://arxiv.org/abs/2506.02161", "authors": ["Xinyu Wei", "Jinrui Zhang", "Zeqing Wang", "Hongyang Wei", "Zhen Guo", "Lei Zhang"], "title": "TIIF-Bench: How Does Your T2I Model Follow Your Instructions?", "categories": ["cs.CV"], "comment": "23 pages, 12 figures, 11 tables", "summary": "The rapid advancements of Text-to-Image (T2I) models have ushered in a new\nphase of AI-generated content, marked by their growing ability to interpret and\nfollow user instructions. However, existing T2I model evaluation benchmarks\nfall short in limited prompt diversity and complexity, as well as coarse\nevaluation metrics, making it difficult to evaluate the fine-grained alignment\nperformance between textual instructions and generated images. In this paper,\nwe present TIIF-Bench (Text-to-Image Instruction Following Benchmark), aiming\nto systematically assess T2I models' ability in interpreting and following\nintricate textual instructions. TIIF-Bench comprises a set of 5000 prompts\norganized along multiple dimensions, which are categorized into three levels of\ndifficulties and complexities. To rigorously evaluate model robustness to\nvarying prompt lengths, we provide a short and a long version for each prompt\nwith identical core semantics. Two critical attributes, i.e., text rendering\nand style control, are introduced to evaluate the precision of text synthesis\nand the aesthetic coherence of T2I models. In addition, we collect 100\nhigh-quality designer level prompts that encompass various scenarios to\ncomprehensively assess model performance. Leveraging the world knowledge\nencoded in large vision language models, we propose a novel computable\nframework to discern subtle variations in T2I model outputs. Through meticulous\nbenchmarking of mainstream T2I models on TIIF-Bench, we analyze the pros and\ncons of current T2I models and reveal the limitations of current T2I\nbenchmarks. Project Page: https://a113n-w3i.github.io/TIIF_Bench/.", "AI": {"tldr": "TIIF-Bench is introduced to evaluate Text-to-Image (T2I) models' ability to follow complex instructions, addressing limitations in existing benchmarks with diverse prompts and fine-grained metrics.", "motivation": "Existing T2I benchmarks lack prompt diversity and granular evaluation metrics, hindering accurate assessment of model alignment with textual instructions.", "method": "TIIF-Bench includes 5000 prompts categorized by difficulty, with short/long versions for robustness testing. It introduces text rendering and style control metrics and uses designer-level prompts and a computable framework for evaluation.", "result": "The benchmark reveals strengths and weaknesses of mainstream T2I models and highlights limitations in current benchmarks.", "conclusion": "TIIF-Bench provides a systematic way to assess T2I models, offering insights for future improvements in instruction-following capabilities."}}
{"id": "2506.01983", "pdf": "https://arxiv.org/pdf/2506.01983", "abs": "https://arxiv.org/abs/2506.01983", "authors": ["Reyhaneh Keshavarzpour", "Eghbal Mansoori"], "title": "Improvement of AMPs Identification with Generative Adversarial Network and Ensemble Classification", "categories": ["cs.LG", "cs.AI"], "comment": "21 pages, 3 figures, 4 tables", "summary": "Identification of antimicrobial peptides is an important and necessary issue\nin today's era. Antimicrobial peptides are essential as an alternative to\nantibiotics for biomedical applications and many other practical applications.\nThese oligopeptides are useful in drug design and cause innate immunity against\nmicroorganisms. Artificial intelligence algorithms have played a significant\nrole in the ease of identifying these peptides.This research is improved by\nimproving proposed method in the field of antimicrobial peptides prediction.\nSuggested method is improved by combining the best coding method from different\nperspectives, In the following a deep neural network to balance the imbalanced\ncombined datasets. The results of this research show that the proposed method\nhave a significant improvement in the accuracy and efficiency of the prediction\nof antimicrobial peptides and are able to provide the best results compared to\nthe existing methods. These development in the field of prediction and\nclassification of antimicrobial peptides, basically in the fields of medicine\nand pharmaceutical industries, have high effectiveness and application.", "AI": {"tldr": "The paper proposes an improved method for predicting antimicrobial peptides using a deep neural network and optimized coding, achieving higher accuracy and efficiency.", "motivation": "Antimicrobial peptides are crucial as antibiotic alternatives in biomedical applications, necessitating better identification methods.", "method": "Combines the best coding methods and uses a deep neural network to handle imbalanced datasets for prediction.", "result": "The proposed method significantly improves accuracy and efficiency in predicting antimicrobial peptides.", "conclusion": "The advancements in prediction and classification of antimicrobial peptides have high effectiveness and application in medicine and pharmaceuticals."}}
{"id": "2506.02470", "pdf": "https://arxiv.org/pdf/2506.02470", "abs": "https://arxiv.org/abs/2506.02470", "authors": ["Xuejiao Zhao", "Siyan Liu", "Su-Yin Yang", "Chunyan Miao"], "title": "A Smart Multimodal Healthcare Copilot with Powerful LLM Reasoning", "categories": ["cs.AI"], "comment": null, "summary": "Misdiagnosis causes significant harm to healthcare systems worldwide, leading\nto increased costs and patient risks. MedRAG is a smart multimodal healthcare\ncopilot equipped with powerful large language model (LLM) reasoning, designed\nto enhance medical decision-making. It supports multiple input modalities,\nincluding non-intrusive voice monitoring, general medical queries, and\nelectronic health records. MedRAG provides recommendations on diagnosis,\ntreatment, medication, and follow-up questioning. Leveraging\nretrieval-augmented generation enhanced by knowledge graph-elicited reasoning,\nMedRAG retrieves and integrates critical diagnostic insights, reducing the risk\nof misdiagnosis. It has been evaluated on both public and private datasets,\noutperforming existing models and offering more specific and accurate\nhealthcare assistance. A demonstration video of MedRAG is available at:\nhttps://www.youtube.com/watch?v=PNIBDMYRfDM. The source code is available at:\nhttps://github.com/SNOWTEAM2023/MedRAG.", "AI": {"tldr": "MedRAG is a multimodal healthcare copilot using LLM reasoning to reduce misdiagnosis by integrating diverse inputs like voice, queries, and EHRs, outperforming existing models.", "motivation": "Misdiagnosis harms healthcare systems, increasing costs and patient risks, necessitating improved decision-making tools.", "method": "Uses retrieval-augmented generation and knowledge graph-elicited reasoning to integrate diagnostic insights from multiple input modalities.", "result": "Outperforms existing models, providing more specific and accurate healthcare assistance.", "conclusion": "MedRAG effectively reduces misdiagnosis risks and enhances medical decision-making."}}
{"id": "2506.02212", "pdf": "https://arxiv.org/pdf/2506.02212", "abs": "https://arxiv.org/abs/2506.02212", "authors": ["Ella Rannon", "David Burstein"], "title": "Leveraging Natural Language Processing to Unravel the Mystery of Life: A Review of NLP Approaches in Genomics, Transcriptomics, and Proteomics", "categories": ["cs.CL", "cs.AI", "q-bio.GN"], "comment": null, "summary": "Natural Language Processing (NLP) has transformed various fields beyond\nlinguistics by applying techniques originally developed for human language to\nthe analysis of biological sequences. This review explores the application of\nNLP methods to biological sequence data, focusing on genomics, transcriptomics,\nand proteomics. We examine how various NLP methods, from classic approaches\nlike word2vec to advanced models employing transformers and hyena operators,\nare being adapted to analyze DNA, RNA, protein sequences, and entire genomes.\nThe review also examines tokenization strategies and model architectures,\nevaluating their strengths, limitations, and suitability for different\nbiological tasks. We further cover recent advances in NLP applications for\nbiological data, such as structure prediction, gene expression, and\nevolutionary analysis, highlighting the potential of these methods for\nextracting meaningful insights from large-scale genomic data. As language\nmodels continue to advance, their integration into bioinformatics holds immense\npromise for advancing our understanding of biological processes in all domains\nof life.", "AI": {"tldr": "The paper reviews how NLP techniques are applied to biological sequence data (genomics, transcriptomics, proteomics), covering methods like word2vec and transformers, and their potential in bioinformatics.", "motivation": "To explore the adaptation of NLP methods for analyzing biological sequences and their potential to advance bioinformatics.", "method": "Examines NLP techniques (e.g., word2vec, transformers) and their application to DNA, RNA, and protein sequences, including tokenization and model architectures.", "result": "Highlights the effectiveness of NLP methods in tasks like structure prediction and gene expression analysis, showing promise for large-scale genomic data.", "conclusion": "NLP integration into bioinformatics offers significant potential for understanding biological processes across life domains."}}
{"id": "2506.02908", "pdf": "https://arxiv.org/pdf/2506.02908", "abs": "https://arxiv.org/abs/2506.02908", "authors": ["Bunlong Lay", "Rostilav Makarov", "Timo Gerkmann"], "title": "Diffusion Buffer: Online Diffusion-based Speech Enhancement with Sub-Second Latency", "categories": ["eess.AS", "cs.LG"], "comment": "5 pages, 2 figures, Accepted to Interspeech 2025", "summary": "Diffusion models are a class of generative models that have been recently\nused for speech enhancement with remarkable success but are computationally\nexpensive at inference time. Therefore, these models are impractical for\nprocessing streaming data in real-time. In this work, we adapt a sliding window\ndiffusion framework to the speech enhancement task. Our approach progressively\ncorrupts speech signals through time, assigning more noise to frames close to\nthe present in a buffer. This approach outputs denoised frames with a delay\nproportional to the chosen buffer size, enabling a trade-off between\nperformance and latency. Empirical results demonstrate that our method\noutperforms standard diffusion models and runs efficiently on a GPU, achieving\nan input-output latency in the order of 0.3 to 1 seconds. This marks the first\npractical diffusion-based solution for online speech enhancement.", "AI": {"tldr": "A sliding window diffusion framework is adapted for real-time speech enhancement, balancing performance and latency, outperforming standard diffusion models with low GPU latency.", "motivation": "Standard diffusion models for speech enhancement are computationally expensive and impractical for real-time streaming data.", "method": "A sliding window approach progressively corrupts speech signals, assigning more noise to recent frames, enabling denoising with controllable latency.", "result": "The method outperforms standard diffusion models, achieving input-output latency of 0.3 to 1 seconds on a GPU.", "conclusion": "This is the first practical diffusion-based solution for online speech enhancement."}}
{"id": "2506.02661", "pdf": "https://arxiv.org/pdf/2506.02661", "abs": "https://arxiv.org/abs/2506.02661", "authors": ["Mingyang Huang", "Peng Zhang", "Bang Zhang"], "title": "MotionRAG-Diff: A Retrieval-Augmented Diffusion Framework for Long-Term Music-to-Dance Generation", "categories": ["cs.SD", "cs.CV", "cs.GR", "eess.AS"], "comment": "12 pages, 5 figures", "summary": "Generating long-term, coherent, and realistic music-conditioned dance\nsequences remains a challenging task in human motion synthesis. Existing\napproaches exhibit critical limitations: motion graph methods rely on fixed\ntemplate libraries, restricting creative generation; diffusion models, while\ncapable of producing novel motions, often lack temporal coherence and musical\nalignment. To address these challenges, we propose $\\textbf{MotionRAG-Diff}$, a\nhybrid framework that integrates Retrieval-Augmented Generation (RAG) with\ndiffusion-based refinement to enable high-quality, musically coherent dance\ngeneration for arbitrary long-term music inputs. Our method introduces three\ncore innovations: (1) A cross-modal contrastive learning architecture that\naligns heterogeneous music and dance representations in a shared latent space,\nestablishing unsupervised semantic correspondence without paired data; (2) An\noptimized motion graph system for efficient retrieval and seamless\nconcatenation of motion segments, ensuring realism and temporal coherence\nacross long sequences; (3) A multi-condition diffusion model that jointly\nconditions on raw music signals and contrastive features to enhance motion\nquality and global synchronization. Extensive experiments demonstrate that\nMotionRAG-Diff achieves state-of-the-art performance in motion quality,\ndiversity, and music-motion synchronization accuracy. This work establishes a\nnew paradigm for music-driven dance generation by synergizing retrieval-based\ntemplate fidelity with diffusion-based creative enhancement.", "AI": {"tldr": "MotionRAG-Diff combines Retrieval-Augmented Generation (RAG) with diffusion models to generate long-term, coherent, and music-aligned dance sequences, addressing limitations of existing methods.", "motivation": "Existing methods for music-conditioned dance synthesis either lack creativity (motion graphs) or temporal coherence (diffusion models). MotionRAG-Diff aims to bridge these gaps.", "method": "The framework integrates cross-modal contrastive learning, an optimized motion graph system, and a multi-condition diffusion model to align music and dance representations, retrieve realistic motion segments, and refine outputs.", "result": "MotionRAG-Diff outperforms existing methods in motion quality, diversity, and synchronization accuracy with music.", "conclusion": "The hybrid approach of MotionRAG-Diff sets a new standard for music-driven dance generation by combining retrieval-based fidelity with diffusion-based creativity."}}
{"id": "2502.03498", "pdf": "https://arxiv.org/pdf/2502.03498", "abs": "https://arxiv.org/abs/2502.03498", "authors": ["Xianghui Ze", "Zhenbo Song", "Qiwei Wang", "Jianfeng Lu", "Yujiao Shi"], "title": "Controllable Satellite-to-Street-View Synthesis with Precise Pose Alignment and Zero-Shot Environmental Control", "categories": ["eess.IV", "cs.GR"], "comment": null, "summary": "Generating street-view images from satellite imagery is a challenging task,\nparticularly in maintaining accurate pose alignment and incorporating diverse\nenvironmental conditions. While diffusion models have shown promise in\ngenerative tasks, their ability to maintain strict pose alignment throughout\nthe diffusion process is limited. In this paper, we propose a novel Iterative\nHomography Adjustment (IHA) scheme applied during the denoising process, which\neffectively addresses pose misalignment and ensures spatial consistency in the\ngenerated street-view images. Additionally, currently, available datasets for\nsatellite-to-street-view generation are limited in their diversity of\nillumination and weather conditions, thereby restricting the generalizability\nof the generated outputs. To mitigate this, we introduce a text-guided\nillumination and weather-controlled sampling strategy that enables fine-grained\ncontrol over the environmental factors. Extensive quantitative and qualitative\nevaluations demonstrate that our approach significantly improves pose accuracy\nand enhances the diversity and realism of generated street-view images, setting\na new benchmark for satellite-to-street-view generation tasks.", "AI": {"tldr": "Proposes Iterative Homography Adjustment (IHA) and text-guided sampling to improve pose alignment and environmental diversity in satellite-to-street-view image generation.", "motivation": "Addresses pose misalignment and limited environmental diversity in current methods for generating street-view images from satellite imagery.", "method": "Introduces Iterative Homography Adjustment (IHA) during denoising and a text-guided sampling strategy for illumination and weather control.", "result": "Significantly improves pose accuracy and enhances diversity/realism of generated images.", "conclusion": "Sets a new benchmark for satellite-to-street-view generation by combining IHA and environmental control."}}
{"id": "2506.02164", "pdf": "https://arxiv.org/pdf/2506.02164", "abs": "https://arxiv.org/abs/2506.02164", "authors": ["Yu", "Qian", "Wilson S. Geisler", "Xue-Xin Wei"], "title": "Quantifying task-relevant representational similarity using decision variable correlation", "categories": ["cs.CV", "cs.LG", "q-bio.NC", "q-bio.QM"], "comment": null, "summary": "Previous studies have compared the brain and deep neural networks trained on\nimage classification. Intriguingly, while some suggest that their\nrepresentations are highly similar, others argued the opposite. Here, we\npropose a new approach to characterize the similarity of the decision\nstrategies of two observers (models or brains) using decision variable\ncorrelation (DVC). DVC quantifies the correlation between decoded decisions on\nindividual samples in a classification task and thus can capture task-relevant\ninformation rather than general representational alignment. We evaluate this\nmethod using monkey V4/IT recordings and models trained on image classification\ntasks.\n  We find that model--model similarity is comparable to monkey--monkey\nsimilarity, whereas model--monkey similarity is consistently lower and,\nsurprisingly, decreases with increasing ImageNet-1k performance. While\nadversarial training enhances robustness, it does not improve model--monkey\nsimilarity in task-relevant dimensions; however, it markedly increases\nmodel--model similarity. Similarly, pre-training on larger datasets does not\nimprove model--monkey similarity. These results suggest a fundamental\ndivergence between the task-relevant representations in monkey V4/IT and those\nlearned by models trained on image classification tasks.", "AI": {"tldr": "The paper introduces Decision Variable Correlation (DVC) to compare decision strategies between models and brains, finding model-monkey similarity lower than expected and decreasing with model performance.", "motivation": "To resolve conflicting claims about the similarity of brain and deep neural network representations by focusing on task-relevant decision strategies.", "method": "Proposes DVC to quantify decision strategy similarity, tested on monkey V4/IT recordings and image classification models.", "result": "Model-monkey similarity is lower than model-model or monkey-monkey similarity and declines with model performance; adversarial training and larger datasets don't improve it.", "conclusion": "Task-relevant representations in monkeys and models diverge fundamentally, suggesting current models may not fully capture biological decision strategies."}}
{"id": "2506.01986", "pdf": "https://arxiv.org/pdf/2506.01986", "abs": "https://arxiv.org/abs/2506.01986", "authors": ["Selin Yildirim", "Deming Chen"], "title": "SpecMemo: Speculative Decoding is in Your Pocket", "categories": ["cs.LG", "cs.AI", "cs.DC"], "comment": null, "summary": "Recent advancements in speculative decoding have demonstrated considerable\nspeedup across a wide array of large language model (LLM) tasks. Speculative\ndecoding inherently relies on sacrificing extra memory allocations to generate\nseveral candidate tokens, of which acceptance rate drives the speedup. However,\ndeploying speculative decoding on memory-constrained devices, such as mobile\nGPUs, remains as a significant challenge in real-world scenarios. In this work,\nwe present a device-aware inference engine named SpecMemo that can smartly\ncontrol memory allocations at finer levels to enable multi-turn chatbots with\nspeculative decoding on such limited memory devices. Our methodology stems from\ntheoretically modeling memory footprint of speculative decoding to determine a\nlower bound on the required memory budget while retaining speedup. SpecMemo\nempirically acquires a careful balance between minimizing redundant memory\nallocations for rejected candidate tokens and maintaining competitive\nperformance gains from speculation. Notably, with SpecMemo's memory management,\nwe maintain 96% of overall throughput from speculative decoding on MT-Bench,\nwith reduced generation-memory by 65% on single Nvidia Titan RTX. Given\nmultiple constrained GPUs, we build on top of previous speculative decoding\narchitectures to facilitate big-model inference by distributing\nLlama-2-70B-Chat model, on which we provide novel batched speculative decoding\nto increase usability of multiple small server GPUs. This novel framework\ndemonstrates 2x speedup over distributed and batched vanilla decoding with the\nbase model on eight AMD MI250 GPUs. Moreover, inference throughput increases\nremarkably 8x with batch size 10. Our work contributes to democratized LLM\napplications in resource-constrained environments, providing a pathway for\nfaster and cheaper deployment of real-world LLM applications with robust\nperformance.", "AI": {"tldr": "SpecMemo enables efficient speculative decoding on memory-constrained devices by optimizing memory usage while maintaining performance gains.", "motivation": "Deploying speculative decoding on memory-limited devices like mobile GPUs is challenging due to high memory demands.", "method": "SpecMemo models memory footprint theoretically and balances memory allocation to retain speedup, with novel batched speculative decoding for distributed systems.", "result": "Achieves 96% throughput of speculative decoding with 65% memory reduction on Titan RTX, and 2x speedup on distributed systems with 8x throughput increase for batch size 10.", "conclusion": "SpecMemo democratizes LLM deployment in resource-constrained environments, offering faster and cheaper solutions with robust performance."}}
{"id": "2506.02485", "pdf": "https://arxiv.org/pdf/2506.02485", "abs": "https://arxiv.org/abs/2506.02485", "authors": ["Haowen Xu", "Sisi Zlatanova", "Ruiyu Liang", "Ismet Canbulat"], "title": "Generative AI for Predicting 2D and 3D Wildfire Spread: Beyond Physics-Based Models and Traditional Deep Learning", "categories": ["cs.AI", "cs.CE"], "comment": null, "summary": "Wildfires continue to inflict devastating human, environmental, and economic\nlosses globally, as tragically exemplified by the 2025 Los Angeles wildfire and\nthe urgent demand for more effective response strategies. While physics-based\nand deep learning models have advanced wildfire simulation, they face critical\nlimitations in predicting and visualizing multimodal fire spread in real time,\nparticularly in both 2D and 3D spatial domains using dynamically updated GIS\ndata. These limitations hinder timely emergency response, infrastructure\nprotection, and community safety. Generative AI has recently emerged as a\ntransformative approach across research and industry. Models such as Generative\nAdversarial Networks (GANs), Variational Autoencoders (VAEs), Transformers, and\ndiffusion-based architectures offer distinct advantages over traditional\nmethods, including the integration of multimodal data, generation of diverse\nscenarios under uncertainty, and improved modeling of wildfire dynamics across\nspatial and temporal scales. This position paper advocates for the adoption of\ngenerative AI as a foundational framework for wildfire prediction. We explore\nhow such models can enhance 2D fire spread forecasting and enable more\nrealistic, scalable 3D simulations. Additionally, we employ a novel human-AI\ncollaboration framework using large language models (LLMs) for automated\nknowledge extraction, literature synthesis, and bibliometric mapping. Looking\nahead, we identify five key visions for integrating generative AI into wildfire\nmanagement: multimodal approaches, AI foundation models, conversational AI\nsystems, edge-computing-based scenario generation, and cognitive digital twins.\nWe also address three major challenges accompanying these opportunities and\npropose potential solutions to support their implementation.", "AI": {"tldr": "The paper advocates for using generative AI to improve wildfire prediction and simulation, addressing limitations of current methods and proposing a human-AI collaboration framework for knowledge extraction and synthesis.", "motivation": "Current wildfire prediction models lack real-time, multimodal capabilities, hindering emergency response. Generative AI offers potential solutions for better forecasting and simulation.", "method": "Proposes generative AI models (GANs, VAEs, Transformers, diffusion models) for 2D/3D wildfire simulation and a human-AI framework using LLMs for knowledge extraction.", "result": "Identifies five key visions for generative AI in wildfire management and addresses challenges with potential solutions.", "conclusion": "Generative AI can revolutionize wildfire prediction and management, but challenges must be addressed for successful implementation."}}
{"id": "2506.02239", "pdf": "https://arxiv.org/pdf/2506.02239", "abs": "https://arxiv.org/abs/2506.02239", "authors": ["Sofoklis Kakouros"], "title": "Investigating the Impact of Word Informativeness on Speech Emotion Recognition", "categories": ["cs.CL", "eess.AS"], "comment": "Accepted to Interspeech 2025", "summary": "In emotion recognition from speech, a key challenge lies in identifying\nspeech signal segments that carry the most relevant acoustic variations for\ndiscerning specific emotions. Traditional approaches compute functionals for\nfeatures such as energy and F0 over entire sentences or longer speech portions,\npotentially missing essential fine-grained variation in the long-form\nstatistics. This research investigates the use of word informativeness, derived\nfrom a pre-trained language model, to identify semantically important segments.\nAcoustic features are then computed exclusively for these identified segments,\nenhancing emotion recognition accuracy. The methodology utilizes standard\nacoustic prosodic features, their functionals, and self-supervised\nrepresentations. Results indicate a notable improvement in recognition\nperformance when features are computed on segments selected based on word\ninformativeness, underscoring the effectiveness of this approach.", "AI": {"tldr": "The paper proposes using word informativeness from a pre-trained language model to identify key speech segments for emotion recognition, improving accuracy by focusing on these segments.", "motivation": "Traditional methods compute acoustic features over entire sentences, missing fine-grained variations. This research aims to enhance emotion recognition by identifying semantically important segments.", "method": "The approach uses word informativeness to select key segments, then computes acoustic features (prosodic features, functionals, and self-supervised representations) only for these segments.", "result": "Results show improved emotion recognition performance when features are computed on selected segments.", "conclusion": "Focusing on semantically important segments enhances emotion recognition accuracy, validating the effectiveness of this method."}}
{"id": "2506.02958", "pdf": "https://arxiv.org/pdf/2506.02958", "abs": "https://arxiv.org/abs/2506.02958", "authors": ["You Zhang", "Baotong Tian", "Lin Zhang", "Zhiyao Duan"], "title": "PartialEdit: Identifying Partial Deepfakes in the Era of Neural Speech Editing", "categories": ["eess.AS", "cs.SD"], "comment": "Interspeech 2025 camera ready. Project page:\n  https://yzyouzhang.com/PartialEdit/", "summary": "Neural speech editing enables seamless partial edits to speech utterances,\nallowing modifications to selected content while preserving the rest of the\naudio unchanged. This useful technique, however, also poses new risks of\ndeepfakes. To encourage research on detecting such partially edited deepfake\nspeech, we introduce PartialEdit, a deepfake speech dataset curated using\nadvanced neural editing techniques. We explore both detection and localization\ntasks on PartialEdit. Our experiments reveal that models trained on the\nexisting PartialSpoof dataset fail to detect partially edited speech generated\nby neural speech editing models. As recent speech editing models almost all\ninvolve neural audio codecs, we also provide insights into the artifacts the\nmodel learned on detecting these deepfakes. Further information about the\nPartialEdit dataset and audio samples can be found on the project page:\nhttps://yzyouzhang.com/PartialEdit/index.html.", "AI": {"tldr": "The paper introduces PartialEdit, a dataset for detecting partially edited deepfake speech, highlighting the limitations of existing models and the role of neural audio codecs in detection.", "motivation": "To address the risks of deepfakes in neural speech editing by enabling research on detecting partially edited speech.", "method": "Curated the PartialEdit dataset using advanced neural editing techniques and evaluated detection and localization tasks.", "result": "Existing models (e.g., trained on PartialSpoof) fail to detect partially edited speech; insights into neural audio codec artifacts were provided.", "conclusion": "PartialEdit advances research in detecting edited deepfake speech, emphasizing the need for improved detection methods."}}
{"id": "2506.02715", "pdf": "https://arxiv.org/pdf/2506.02715", "abs": "https://arxiv.org/abs/2506.02715", "authors": ["Michael K\u00fcttner", "Valeria Sitz", "Kathrin Gerling", "Michael Beigl", "Tobias R\u00f6ddiger"], "title": "UltrasonicSpheres: Localized, Multi-Channel Sound Spheres Using Off-the-Shelf Speakers and Earables", "categories": ["cs.SD", "cs.HC", "eess.AS"], "comment": null, "summary": "We present a demo ofUltrasonicSpheres, a novel system for location-specific\naudio delivery using wearable earphones that decode ultrasonic signals into\naudible sound. Unlike conventional beamforming setups, UltrasonicSpheres relies\non single ultrasonic speakers to broadcast localized audio with multiple\nchannels, each encoded on a distinct ultrasonic carrier frequency. Users\nwearing our acoustically transparent earphones can demodulate their selected\nstream, such as exhibit narrations in a chosen language, while remaining fully\naware of ambient environmental sounds. The experience preserves spatial audio\nperception, giving the impression that the sound originates directly from the\nphysical location of the source. This enables personalized, localized audio\nwithout requiring pairing, tracking, or additional infrastructure. Importantly,\nvisitors not equipped with the earphones are unaffected, as the ultrasonic\nsignals are inaudible to the human ear. Our demo invites participants to\nexplore multiple co-located audio zones and experience how UltrasonicSpheres\nsupports unobtrusive delivery of personalized sound in public spaces.", "AI": {"tldr": "UltrasonicSpheres is a system for location-specific audio delivery using wearable earphones that decode ultrasonic signals into audible sound, enabling personalized audio without pairing or tracking.", "motivation": "To provide personalized, localized audio in public spaces without disrupting ambient sounds or requiring additional infrastructure.", "method": "Uses single ultrasonic speakers to broadcast localized audio with multiple channels, each encoded on distinct ultrasonic frequencies. Wearable earphones demodulate selected streams.", "result": "Users can hear localized audio (e.g., exhibit narrations) while remaining aware of ambient sounds, with spatial audio perception preserved.", "conclusion": "UltrasonicSpheres offers an unobtrusive, infrastructure-free solution for personalized audio delivery in public spaces."}}
{"id": "2502.14753", "pdf": "https://arxiv.org/pdf/2502.14753", "abs": "https://arxiv.org/abs/2502.14753", "authors": ["Maya Varma", "Ashwin Kumar", "Rogier van der Sluijs", "Sophie Ostmeier", "Louis Blankemeier", "Pierre Chambon", "Christian Bluethgen", "Jip Prince", "Curtis Langlotz", "Akshay Chaudhari"], "title": "MedVAE: Efficient Automated Interpretation of Medical Images with Large-Scale Generalizable Autoencoders", "categories": ["eess.IV", "cs.AI", "cs.CV"], "comment": "MIDL 2025 (Oral)", "summary": "Medical images are acquired at high resolutions with large fields of view in\norder to capture fine-grained features necessary for clinical decision-making.\nConsequently, training deep learning models on medical images can incur large\ncomputational costs. In this work, we address the challenge of downsizing\nmedical images in order to improve downstream computational efficiency while\npreserving clinically-relevant features. We introduce MedVAE, a family of six\nlarge-scale 2D and 3D autoencoders capable of encoding medical images as\ndownsized latent representations and decoding latent representations back to\nhigh-resolution images. We train MedVAE autoencoders using a novel two-stage\ntraining approach with 1,052,730 medical images. Across diverse tasks obtained\nfrom 20 medical image datasets, we demonstrate that (1) utilizing MedVAE latent\nrepresentations in place of high-resolution images when training downstream\nmodels can lead to efficiency benefits (up to 70x improvement in throughput)\nwhile simultaneously preserving clinically-relevant features and (2) MedVAE can\ndecode latent representations back to high-resolution images with high\nfidelity. Our work demonstrates that large-scale, generalizable autoencoders\ncan help address critical efficiency challenges in the medical domain. Our code\nis available at https://github.com/StanfordMIMI/MedVAE.", "AI": {"tldr": "MedVAE, a family of 2D/3D autoencoders, downsizes medical images for computational efficiency while preserving clinical features, achieving up to 70x throughput improvement.", "motivation": "High-resolution medical images incur large computational costs; downsizing them without losing clinical relevance is challenging.", "method": "Introduces MedVAE, trained on 1M+ images using a novel two-stage approach, to encode/decode images efficiently.", "result": "MedVAE improves downstream model throughput by 70x and maintains high-fidelity image reconstruction.", "conclusion": "Large-scale autoencoders like MedVAE can address efficiency challenges in medical imaging without compromising clinical utility."}}
{"id": "2506.02167", "pdf": "https://arxiv.org/pdf/2506.02167", "abs": "https://arxiv.org/abs/2506.02167", "authors": ["Aditi Tiwari", "Farzaneh Masoud", "Dac Trong Nguyen", "Jill Kraft", "Heng Ji", "Klara Nahrstedt"], "title": "Fire360: A Benchmark for Robust Perception and Episodic Memory in Degraded 360-Degree Firefighting Videos", "categories": ["cs.CV", "cs.AI"], "comment": "20 pages, 9 figures, 6 tables", "summary": "Modern AI systems struggle most in environments where reliability is critical\n- scenes with smoke, poor visibility, and structural deformation. Each year,\ntens of thousands of firefighters are injured on duty, often due to breakdowns\nin situational perception. We introduce Fire360, a benchmark for evaluating\nperception and reasoning in safety-critical firefighting scenarios. The dataset\nincludes 228 360-degree videos from professional training sessions under\ndiverse conditions (e.g., low light, thermal distortion), annotated with action\nsegments, object locations, and degradation metadata. Fire360 supports five\ntasks: Visual Question Answering, Temporal Action Captioning, Object\nLocalization, Safety-Critical Reasoning, and Transformed Object Retrieval\n(TOR). TOR tests whether models can match pristine exemplars to fire-damaged\ncounterparts in unpaired scenes, evaluating transformation-invariant\nrecognition. While human experts achieve 83.5% on TOR, models like GPT-4o lag\nsignificantly, exposing failures in reasoning under degradation. By releasing\nFire360 and its evaluation suite, we aim to advance models that not only see,\nbut also remember, reason, and act under uncertainty. The dataset is available\nat: https://uofi.box.com/v/fire360dataset.", "AI": {"tldr": "Fire360 is a benchmark dataset for evaluating AI perception and reasoning in firefighting scenarios, featuring 360-degree videos with annotations for five tasks, highlighting gaps in model performance compared to humans.", "motivation": "To address AI reliability in critical environments like firefighting, where situational perception failures cause injuries, by providing a robust evaluation framework.", "method": "The dataset includes 228 annotated 360-degree videos from professional firefighting training, supporting tasks like Visual Question Answering and Transformed Object Retrieval.", "result": "Human experts outperform models (83.5% vs. GPT-4o) in tasks like Transformed Object Retrieval, revealing AI shortcomings in degradation-invariant reasoning.", "conclusion": "Fire360 aims to advance AI models for reliable perception and reasoning under uncertainty, with the dataset publicly available for research."}}
{"id": "2506.01987", "pdf": "https://arxiv.org/pdf/2506.01987", "abs": "https://arxiv.org/abs/2506.01987", "authors": ["Runkang Yang", "Peng Sun", "Xinyi Shang", "Yi Tang", "Tao Lin"], "title": "Equally Critical: Samples, Targets, and Their Mappings in Datasets", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Data inherently possesses dual attributes: samples and targets. For targets,\nknowledge distillation has been widely employed to accelerate model\nconvergence, primarily relying on teacher-generated soft target supervision.\nConversely, recent advancements in data-efficient learning have emphasized\nsample optimization techniques, such as dataset distillation, while neglected\nthe critical role of target. This dichotomy motivates our investigation into\nunderstanding how both sample and target collectively influence training\ndynamic. To address this gap, we first establish a taxonomy of existing\nparadigms through the lens of sample-target interactions, categorizing them\ninto distinct sample-to-target mapping strategies. Building upon this\nfoundation, we then propose a novel unified loss framework to assess their\nimpact on training efficiency. Through extensive empirical studies on our\nproposed strategies, we comprehensively analyze how variations in target and\nsample types, quantities, and qualities influence model training, providing six\nkey insights to enhance training efficacy.", "AI": {"tldr": "The paper explores the dual roles of samples and targets in data, proposing a unified loss framework to analyze their impact on training efficiency and offering six key insights.", "motivation": "The study is motivated by the neglect of target optimization in data-efficient learning, despite its importance alongside sample optimization.", "method": "The authors categorize existing paradigms by sample-target interactions and propose a unified loss framework to evaluate their effects.", "result": "Empirical studies reveal how target and sample variations influence training, yielding six insights for improved efficacy.", "conclusion": "The work highlights the collective influence of samples and targets on training dynamics, providing actionable insights for better model training."}}
{"id": "2506.02522", "pdf": "https://arxiv.org/pdf/2506.02522", "abs": "https://arxiv.org/abs/2506.02522", "authors": ["Xu Wan", "Wenyue Xu", "Chao Yang", "Mingyang Sun"], "title": "Think Twice, Act Once: A Co-Evolution Framework of LLM and RL for Large-Scale Decision Making", "categories": ["cs.AI"], "comment": null, "summary": "Recent advancements in Large Language Models (LLMs) and Reinforcement\nLearning (RL) have shown significant promise in decision-making tasks.\nNevertheless, for large-scale industrial decision problems, both approaches\nface distinct challenges: LLMs lack real-time long-sequence decision-making\ncapabilities, while RL struggles with sample efficiency in vast action spaces.\nTo bridge this gap, we propose Agents Co-Evolution (ACE), a synergistic\nframework between LLMs and RL agents for large-scale decision-making scenarios.\nACE introduces a dual-role trajectory refinement mechanism where LLMs act as\nboth Policy Actor and Value Critic during RL's training: the Actor refines\nsuboptimal actions via multi-step reasoning and environment validation, while\nthe Critic performs temporal credit assignment through trajectory-level reward\nshaping. Concurrently, RL agent enhances LLMs' task-specific decision-making\nwith high-quality fine-tuning datasets generated via prioritized experience\nreplay. Through extensive experiments across multiple power grid operation\nchallenges with action spaces exceeding 60K discrete actions, ACE demonstrates\nsuperior performance over existing RL methods and LLM-based methods.", "AI": {"tldr": "ACE combines LLMs and RL for large-scale decision-making, improving performance in tasks like power grid operations with over 60K actions.", "motivation": "Address the limitations of LLMs (lack of real-time decision-making) and RL (sample inefficiency in large action spaces) in industrial-scale problems.", "method": "Proposes ACE, a framework where LLMs act as Policy Actor and Value Critic in RL training, refining actions and shaping rewards, while RL enhances LLMs with fine-tuning data.", "result": "ACE outperforms existing RL and LLM-based methods in power grid operation tasks with large action spaces.", "conclusion": "ACE effectively bridges the gap between LLMs and RL, offering a scalable solution for complex decision-making scenarios."}}
{"id": "2506.02264", "pdf": "https://arxiv.org/pdf/2506.02264", "abs": "https://arxiv.org/abs/2506.02264", "authors": ["Radin Shayanfar", "Chu Fei Luo", "Rohan Bhambhoria", "Samuel Dahan", "Xiaodan Zhu"], "title": "CoDial: Interpretable Task-Oriented Dialogue Systems Through Dialogue Flow Alignment", "categories": ["cs.CL"], "comment": null, "summary": "It is often challenging to teach specialized, unseen tasks to dialogue\nsystems due to the high cost of expert knowledge, training data, and high\ntechnical difficulty. To support domain-specific applications - such as law,\nmedicine, or finance - it is essential to build frameworks that enable\nnon-technical experts to define, test, and refine system behaviour with minimal\neffort. Achieving this requires cross-disciplinary collaboration between\ndevelopers and domain specialists. In this work, we introduce a novel\nframework, CoDial (Code for Dialogue), that converts expert knowledge,\nrepresented as a novel structured heterogeneous graph, into executable\nconversation logic. CoDial can be easily implemented in existing guardrailing\nlanguages, such as Colang, to enable interpretable, modifiable, and true\nzero-shot specification of task-oriented dialogue systems. Empirically, CoDial\nachieves state-of-the-art performance on the STAR dataset for inference-based\nmodels and is competitive with similar baselines on the well-known MultiWOZ\ndataset. We also demonstrate CoDial's iterative improvement via manual and\nLLM-aided feedback, making it a practical tool for expert-guided alignment of\nLLMs in high-stakes domains.", "AI": {"tldr": "CoDial is a framework that converts expert knowledge into executable dialogue logic, enabling non-technical experts to define and refine system behavior with minimal effort.", "motivation": "Teaching specialized tasks to dialogue systems is costly and technically challenging, requiring frameworks that facilitate collaboration between developers and domain experts.", "method": "CoDial uses a structured heterogeneous graph to represent expert knowledge and integrates with guardrailing languages like Colang for interpretable, zero-shot dialogue system specification.", "result": "CoDial achieves state-of-the-art performance on the STAR dataset and is competitive on MultiWOZ. It also supports iterative improvement via feedback.", "conclusion": "CoDial is a practical tool for expert-guided alignment of LLMs in high-stakes domains, enabling efficient and interpretable dialogue system development."}}
{"id": "2506.03020", "pdf": "https://arxiv.org/pdf/2506.03020", "abs": "https://arxiv.org/abs/2506.03020", "authors": ["Chaeyoung Jung", "Hojoon Ki", "Ji-Hoon Kim", "Junmo Kim", "Joon Son Chung"], "title": "InfiniteAudio: Infinite-Length Audio Generation with Consistency", "categories": ["eess.AS"], "comment": null, "summary": "This paper presents InfiniteAudio, a simple yet effective strategy for\ngenerating infinite-length audio using diffusion-based text-to-audio methods.\nCurrent approaches face memory constraints because the output size increases\nwith input length, making long duration generation challenging. A common\nworkaround is to concatenate short audio segments, but this often leads to\ninconsistencies due to the lack of shared temporal context. To address this,\nInfiniteAudio integrates seamlessly into existing pipelines without additional\ntraining. It introduces two key techniques: FIFO sampling, a first-in,\nfirst-out inference strategy with fixed-size inputs, and curved denoising,\nwhich selectively prioritizes key diffusion steps for efficiency. Experiments\nshow that InfiniteAudio achieves comparable or superior performance across all\nmetrics. Audio samples are available on our project page.", "AI": {"tldr": "InfiniteAudio enables infinite-length audio generation using diffusion methods by addressing memory constraints and temporal inconsistencies with FIFO sampling and curved denoising.", "motivation": "Current text-to-audio methods struggle with long-duration generation due to memory constraints and temporal inconsistencies from concatenating short segments.", "method": "InfiniteAudio introduces FIFO sampling (fixed-size input inference) and curved denoising (selective diffusion step prioritization) without requiring additional training.", "result": "Experiments show InfiniteAudio matches or outperforms existing methods across all metrics.", "conclusion": "InfiniteAudio effectively solves long-duration audio generation challenges while maintaining performance."}}
{"id": "2506.02858", "pdf": "https://arxiv.org/pdf/2506.02858", "abs": "https://arxiv.org/abs/2506.02858", "authors": ["Geonyoung Lee", "Geonhee Han", "Paul Hongsuck Seo"], "title": "DGMO: Training-Free Audio Source Separation through Diffusion-Guided Mask Optimization", "categories": ["cs.SD", "cs.AI"], "comment": "Interspeech 2025", "summary": "Language-queried Audio Source Separation (LASS) enables open-vocabulary sound\nseparation via natural language queries. While existing methods rely on\ntask-specific training, we explore whether pretrained diffusion models,\noriginally designed for audio generation, can inherently perform separation\nwithout further training. In this study, we introduce a training-free framework\nleveraging generative priors for zero-shot LASS. Analyzing na\\\"ive adaptations,\nwe identify key limitations arising from modality-specific challenges.To\naddress these issues, we propose Diffusion-Guided Mask Optimization (DGMO), a\ntest-time optimization framework that refines spectrogram masks for precise,\ninput-aligned separation. Our approach effectively repurposes pretrained\ndiffusion models for source separation, achieving competitive performance\nwithout task-specific supervision. This work expands the application of\ndiffusion models beyond generation, establishing a new paradigm for zero-shot\naudio separation. The code is available at: https://wltschmrz.github.io/DGMO/", "AI": {"tldr": "A training-free framework (DGMO) repurposes pretrained diffusion models for zero-shot language-queried audio source separation, achieving competitive performance without task-specific training.", "motivation": "Explore whether pretrained diffusion models, designed for audio generation, can inherently perform audio source separation without further training.", "method": "Propose Diffusion-Guided Mask Optimization (DGMO), a test-time optimization framework refining spectrogram masks for precise separation.", "result": "Achieves competitive performance in zero-shot LASS without task-specific supervision.", "conclusion": "Expands diffusion models' applications beyond generation, establishing a new paradigm for zero-shot audio separation."}}
{"id": "2503.14031", "pdf": "https://arxiv.org/pdf/2503.14031", "abs": "https://arxiv.org/abs/2503.14031", "authors": ["Julian Gamboa", "Xi Shen", "Tabassom Hamidfar", "Shamima Mitu", "Selim M. Shahriar"], "title": "Debiased Opto-electronic Joint Transform Correlator for Enhanced Real-Time Pattern Recognition", "categories": ["eess.IV"], "comment": null, "summary": "Opto-electronic joint transform correlators (OJTCs) use a focal plane array\n(FPA) to detect the joint power spectrum (JPS) of two input images, projecting\nit onto a spatial light modulator (SLM) to be optically Fourier transformed.\nThe JPS is composed of two self-intensities and two conjugate-products, where\nonly the latter produce the cross-correlation. However, the self-intensity\nterms are typically much stronger than the conjugate-products, producing a bias\nthat consumes most of the available bit-depth on the FPA and SLM. Here we\npropose and demonstrate, through simulation and experiment, a debiased OJTC\n(DOJTC) that electronically pre-processes the JPS to remove the self-intensity\nterms before sending it to the SLM, thereby enhancing the quality of the\ncross-correlation result. We show that under some conditions the DOJTC yields a\nnearly two orders of magnitude improvement in the signal-to-noise ratio\ncompared to an OJTC.", "AI": {"tldr": "A debiased opto-electronic joint transform correlator (DOJTC) is proposed to remove self-intensity terms from the joint power spectrum, improving cross-correlation quality and signal-to-noise ratio.", "motivation": "The self-intensity terms in traditional OJTCs dominate the joint power spectrum, consuming bit-depth and degrading cross-correlation results.", "method": "The DOJTC electronically pre-processes the joint power spectrum to remove self-intensity terms before optical Fourier transformation.", "result": "Simulation and experiments show DOJTC improves signal-to-noise ratio by nearly two orders of magnitude.", "conclusion": "DOJTC effectively enhances cross-correlation quality by eliminating bias from self-intensity terms."}}
{"id": "2506.02221", "pdf": "https://arxiv.org/pdf/2506.02221", "abs": "https://arxiv.org/abs/2506.02221", "authors": ["Johannes Schusterbauer", "Ming Gui", "Frank Fundel", "Bj\u00f6rn Ommer"], "title": "Diff2Flow: Training Flow Matching Models via Diffusion Model Alignment", "categories": ["cs.CV", "cs.LG"], "comment": "Accepted by CVPR 2025", "summary": "Diffusion models have revolutionized generative tasks through high-fidelity\noutputs, yet flow matching (FM) offers faster inference and empirical\nperformance gains. However, current foundation FM models are computationally\nprohibitive for finetuning, while diffusion models like Stable Diffusion\nbenefit from efficient architectures and ecosystem support. This work addresses\nthe critical challenge of efficiently transferring knowledge from pre-trained\ndiffusion models to flow matching. We propose Diff2Flow, a novel framework that\nsystematically bridges diffusion and FM paradigms by rescaling timesteps,\naligning interpolants, and deriving FM-compatible velocity fields from\ndiffusion predictions. This alignment enables direct and efficient FM\nfinetuning of diffusion priors with no extra computation overhead. Our\nexperiments demonstrate that Diff2Flow outperforms na\\\"ive FM and diffusion\nfinetuning particularly under parameter-efficient constraints, while achieving\nsuperior or competitive performance across diverse downstream tasks compared to\nstate-of-the-art methods. We will release our code at\nhttps://github.com/CompVis/diff2flow.", "AI": {"tldr": "Diff2Flow bridges diffusion models and flow matching (FM) for efficient knowledge transfer, enabling FM finetuning of diffusion priors without extra overhead.", "motivation": "Current FM models are computationally heavy for finetuning, while diffusion models like Stable Diffusion have efficient architectures. Diff2Flow aims to transfer knowledge from diffusion to FM efficiently.", "method": "Proposes Diff2Flow, a framework aligning diffusion and FM by rescaling timesteps, aligning interpolants, and deriving FM-compatible velocity fields from diffusion predictions.", "result": "Outperforms naive FM and diffusion finetuning, especially under parameter-efficient constraints, and achieves competitive performance in downstream tasks.", "conclusion": "Diff2Flow successfully bridges diffusion and FM, offering efficient finetuning and superior performance, with code to be released."}}
{"id": "2506.01988", "pdf": "https://arxiv.org/pdf/2506.01988", "abs": "https://arxiv.org/abs/2506.01988", "authors": ["Akshat Dubey", "Aleksandar An\u017eel", "Georges Hattab"], "title": "Surrogate Interpretable Graph for Random Decision Forests", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "The field of health informatics has been profoundly influenced by the\ndevelopment of random forest models, which have led to significant advances in\nthe interpretability of feature interactions. These models are characterized by\ntheir robustness to overfitting and parallelization, making them particularly\nuseful in this domain. However, the increasing number of features and\nestimators in random forests can prevent domain experts from accurately\ninterpreting global feature interactions, thereby compromising trust and\nregulatory compliance. A method called the surrogate interpretability graph has\nbeen developed to address this issue. It uses graphs and mixed-integer linear\nprogramming to analyze and visualize feature interactions. This improves their\ninterpretability by visualizing the feature usage per\ndecision-feature-interaction table and the most dominant hierarchical decision\nfeature interactions for predictions. The implementation of a surrogate\ninterpretable graph enhances global interpretability, which is critical for\nsuch a high-stakes domain.", "AI": {"tldr": "A surrogate interpretability graph method improves global interpretability of random forest models in health informatics by visualizing feature interactions.", "motivation": "Random forests, while robust, can obscure global feature interactions, reducing trust and compliance in health informatics.", "method": "Uses graphs and mixed-integer linear programming to analyze and visualize feature interactions.", "result": "Enhances interpretability by showing feature usage and dominant hierarchical interactions.", "conclusion": "The surrogate interpretability graph is vital for improving trust and compliance in high-stakes domains."}}
{"id": "2506.02565", "pdf": "https://arxiv.org/pdf/2506.02565", "abs": "https://arxiv.org/abs/2506.02565", "authors": ["Zhuoxuan Jiang", "Tianyang Zhang", "Peiyan Peng", "Jing Chen", "Yinong Xun", "Haotian Zhang", "Lichi Li", "Yong Li", "Shaohua Zhang"], "title": "Towards Generating Controllable and Solvable Geometry Problem by Leveraging Symbolic Deduction Engine", "categories": ["cs.AI"], "comment": "To Appear in ACL'25", "summary": "Generating high-quality geometry problems is both an important and\nchallenging task in education. Compared to math word problems, geometry\nproblems further emphasize multi-modal formats and the translation between\ninformal and formal languages. In this paper, we introduce a novel task for\ngeometry problem generation and propose a new pipeline method: the Symbolic\nDeduction Engine-based Geometry Problem Generation framework (SDE-GPG). The\nframework leverages a symbolic deduction engine and contains four main steps:\n(1) searching a predefined mapping table from knowledge points to extended\ndefinitions, (2) sampling extended definitions and performing symbolic\ndeduction, (3) filtering out unqualified problems, and (4) generating textual\nproblems and diagrams. Specifically, our method supports to avoid inherent\nbiases in translating natural language into formal language by designing the\nmapping table, and guarantees to control the generated problems in terms of\nknowledge points and difficulties by an elaborate checking function. With\nobtained formal problems, they are translated to natural language and the\naccompanying diagrams are automatically drew by rule-based methods. We conduct\nexperiments using real-world combinations of knowledge points from two public\ndatasets. The results demonstrate that the SDE-GPG can effectively generate\nreadable, solvable and controllable geometry problems.", "AI": {"tldr": "A framework called SDE-GPG is introduced for generating high-quality geometry problems using symbolic deduction and multi-modal translation.", "motivation": "Geometry problem generation is challenging due to multi-modal formats and language translation needs. Existing methods lack control over knowledge points and biases.", "method": "SDE-GPG uses a symbolic deduction engine with four steps: mapping table search, symbolic deduction, problem filtering, and text/diagram generation.", "result": "Experiments show SDE-GPG generates readable, solvable, and controllable geometry problems.", "conclusion": "SDE-GPG effectively addresses biases and control issues in geometry problem generation."}}
{"id": "2506.02279", "pdf": "https://arxiv.org/pdf/2506.02279", "abs": "https://arxiv.org/abs/2506.02279", "authors": ["Wenzheng Zhang", "Xi Victoria Lin", "Karl Stratos", "Wen-tau Yih", "Mingda Chen"], "title": "ImpRAG: Retrieval-Augmented Generation with Implicit Queries", "categories": ["cs.CL"], "comment": null, "summary": "Retrieval-Augmented Generation (RAG) systems traditionally treat retrieval\nand generation as separate processes, requiring explicit textual queries to\nconnect them. This separation can limit the ability of models to generalize\nacross diverse tasks. In this work, we propose a query-free RAG system, named\nImpRAG, which integrates retrieval and generation into a unified model. ImpRAG\nallows models to implicitly express their information needs, eliminating the\nneed for human-specified queries. By dividing pretrained decoder-only language\nmodels into specialized layer groups, ImpRAG optimizes retrieval and generation\ntasks simultaneously. Our approach employs a two-stage inference process, using\nthe same model parameters and forward pass for both retrieval and generation,\nthereby minimizing the disparity between retrievers and language models.\nExperiments on 8 knowledge-intensive tasks demonstrate that ImpRAG achieves\n3.6-11.5 improvements in exact match scores on unseen tasks with diverse\nformats, highlighting its effectiveness in enabling models to articulate their\nown information needs and generalize across tasks. Our analysis underscores the\nimportance of balancing retrieval and generation parameters and leveraging\ngeneration perplexities as retrieval training objectives for enhanced\nperformance.", "AI": {"tldr": "ImpRAG integrates retrieval and generation into a unified model, eliminating explicit queries and improving generalization across tasks.", "motivation": "Traditional RAG systems separate retrieval and generation, limiting task generalization. ImpRAG aims to unify these processes implicitly.", "method": "ImpRAG divides pretrained decoder-only models into specialized layer groups for simultaneous retrieval and generation, using a two-stage inference process.", "result": "ImpRAG achieves 3.6-11.5 improvements in exact match scores on 8 knowledge-intensive tasks, demonstrating strong generalization.", "conclusion": "ImpRAG's unified approach and parameter balancing enhance performance, enabling models to articulate information needs without explicit queries."}}
{"id": "2506.00422", "pdf": "https://arxiv.org/pdf/2506.00422", "abs": "https://arxiv.org/abs/2506.00422", "authors": ["Yui Sudo", "Yosuke Fukumoto", "Muhammad Shakeel", "Yifan Peng", "Chyi-Jiunn Lin", "Shinji Watanabe"], "title": "DYNAC: Dynamic Vocabulary based Non-Autoregressive Contextualization for Speech Recognition", "categories": ["cs.CL", "cs.SD", "eess.AS"], "comment": "Accepted to Interspeech 2025", "summary": "Contextual biasing (CB) improves automatic speech recognition for rare and\nunseen phrases. Recent studies have introduced dynamic vocabulary, which\nrepresents context phrases as expandable tokens in autoregressive (AR) models.\nThis method improves CB accuracy but with slow inference speed. While dynamic\nvocabulary can be applied to non-autoregressive (NAR) models, such as\nconnectionist temporal classification (CTC), the conditional independence\nassumption fails to capture dependencies between static and dynamic tokens.\nThis paper proposes DYNAC (Dynamic Vocabulary-based NAR Contextualization), a\nself-conditioned CTC method that integrates dynamic vocabulary into\nintermediate layers. Conditioning the encoder on dynamic vocabulary, DYNAC\neffectively captures dependencies between static and dynamic tokens while\nreducing the real-time factor (RTF). Experimental results show that DYNAC\nreduces RTF by 81% with a 0.1-point degradation in word error rate on the\nLibriSpeech 960 test-clean set.", "AI": {"tldr": "DYNAC improves contextual biasing in speech recognition by integrating dynamic vocabulary into non-autoregressive models, reducing inference time with minimal accuracy loss.", "motivation": "Address the slow inference speed of dynamic vocabulary in autoregressive models and the dependency-capture limitation in non-autoregressive models.", "method": "Proposes DYNAC, a self-conditioned CTC method that integrates dynamic vocabulary into intermediate layers to capture token dependencies.", "result": "Reduces real-time factor by 81% with only a 0.1-point degradation in word error rate on LibriSpeech 960 test-clean set.", "conclusion": "DYNAC effectively balances speed and accuracy for contextual biasing in speech recognition."}}
{"id": "2506.03099", "pdf": "https://arxiv.org/pdf/2506.03099", "abs": "https://arxiv.org/abs/2506.03099", "authors": ["Chetwin Low", "Weimin Wang"], "title": "TalkingMachines: Real-Time Audio-Driven FaceTime-Style Video via Autoregressive Diffusion Models", "categories": ["cs.SD", "cs.AI", "cs.GR"], "comment": null, "summary": "In this paper, we present TalkingMachines -- an efficient framework that\ntransforms pretrained video generation models into real-time, audio-driven\ncharacter animators. TalkingMachines enables natural conversational experiences\nby integrating an audio large language model (LLM) with our video generation\nfoundation model. Our primary contributions include: (1) We adapt a pretrained\nSOTA image-to-video DiT into an audio-driven avatar generation model of 18\nbillion parameters; (2) We enable infinite video streaming without error\naccumulation through asymmetric knowledge distillation from a bidirectional\nteacher model into a sparse causal, autoregressive student model; (3) We design\na high-throughput, low-latency inference pipeline incorporating several key\nengineering optimizations such as: (a) disaggregation of the DiT and VAE\ndecoder across separate devices, (b) efficient overlap of inter-device\ncommunication and computation using CUDA streams, (c) elimination of redundant\nrecomputations to maximize frame-generation throughput. Please see demo videos\nhere - https://aaxwaz.github.io/TalkingMachines/", "AI": {"tldr": "TalkingMachines transforms pretrained video models into real-time, audio-driven animators using an audio LLM and video foundation model.", "motivation": "To enable natural conversational experiences by integrating audio and video generation.", "method": "Adapts a DiT model for avatar generation, uses asymmetric knowledge distillation for infinite streaming, and optimizes inference with engineering tweaks.", "result": "Efficient, real-time audio-driven character animation with high throughput and low latency.", "conclusion": "TalkingMachines offers a scalable solution for interactive, audio-driven video generation."}}
{"id": "2504.02628", "pdf": "https://arxiv.org/pdf/2504.02628", "abs": "https://arxiv.org/abs/2504.02628", "authors": ["Chu Han", "Bingchao Zhao", "Jiatai Lin", "Shanshan Lyu", "Longfei Wang", "Tianpeng Deng", "Cheng Lu", "Changhong Liang", "Hannah Y. Wen", "Xiaojing Guo", "Zhenwei Shi", "Zaiyi Liu"], "title": "Towards Computation- and Communication-efficient Computational Pathology", "categories": ["eess.IV", "cs.CV"], "comment": null, "summary": "Despite the impressive performance across a wide range of applications,\ncurrent computational pathology models face significant diagnostic efficiency\nchallenges due to their reliance on high-magnification whole-slide image\nanalysis. This limitation severely compromises their clinical utility,\nespecially in time-sensitive diagnostic scenarios and situations requiring\nefficient data transfer. To address these issues, we present a novel\ncomputation- and communication-efficient framework called Magnification-Aligned\nGlobal-Local Transformer (MAG-GLTrans). Our approach significantly reduces\ncomputational time, file transfer requirements, and storage overhead by\nenabling effective analysis using low-magnification inputs rather than\nhigh-magnification ones. The key innovation lies in our proposed magnification\nalignment (MAG) mechanism, which employs self-supervised learning to bridge the\ninformation gap between low and high magnification levels by effectively\naligning their feature representations. Through extensive evaluation across\nvarious fundamental CPath tasks, MAG-GLTrans demonstrates state-of-the-art\nclassification performance while achieving remarkable efficiency gains: up to\n10.7 times reduction in computational time and over 20 times reduction in file\ntransfer and storage requirements. Furthermore, we highlight the versatility of\nour MAG framework through two significant extensions: (1) its applicability as\na feature extractor to enhance the efficiency of any CPath architecture, and\n(2) its compatibility with existing foundation models and\nhistopathology-specific encoders, enabling them to process low-magnification\ninputs with minimal information loss. These advancements position MAG-GLTrans\nas a particularly promising solution for time-sensitive applications,\nespecially in the context of intraoperative frozen section diagnosis where both\naccuracy and efficiency are paramount.", "AI": {"tldr": "MAG-GLTrans is a novel framework for computational pathology that improves efficiency by using low-magnification inputs, reducing computational time and storage needs while maintaining accuracy.", "motivation": "Current pathology models rely on high-magnification images, limiting clinical utility in time-sensitive scenarios. MAG-GLTrans addresses this by enabling efficient low-magnification analysis.", "method": "The framework uses a magnification alignment (MAG) mechanism via self-supervised learning to align features between low and high magnification levels.", "result": "MAG-GLTrans achieves up to 10.7x faster computation and 20x reduced storage/transfer needs while maintaining state-of-the-art classification performance.", "conclusion": "MAG-GLTrans is a versatile and efficient solution for time-sensitive applications like intraoperative diagnosis, compatible with existing models and architectures."}}
{"id": "2506.02229", "pdf": "https://arxiv.org/pdf/2506.02229", "abs": "https://arxiv.org/abs/2506.02229", "authors": ["Manas Mehta", "Yimu Pan", "Kelly Gallagher", "Alison D. Gernand", "Jeffery A. Goldstein", "Delia Mwinyelle", "Leena Mithal", "James Z. Wang"], "title": "VLCD: Vision-Language Contrastive Distillation for Accurate and Efficient Automatic Placenta Analysis", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.LG"], "comment": "Proceedings of the 9th International Workshop on Health Intelligence,\n  in conjunction with the Annual AAAI Conference on Artificial Intelligence,\n  Philadelphia, Pennsylvania, March 2025", "summary": "Pathological examination of the placenta is an effective method for detecting\nand mitigating health risks associated with childbirth. Recent advancements in\nAI have enabled the use of photographs of the placenta and pathology reports\nfor detecting and classifying signs of childbirth-related pathologies. However,\nexisting automated methods are computationally extensive, which limits their\ndeployability. We propose two modifications to vision-language contrastive\nlearning (VLC) frameworks to enhance their accuracy and efficiency: (1)\ntext-anchored vision-language contrastive knowledge distillation (VLCD)-a new\nknowledge distillation strategy for medical VLC pretraining, and (2)\nunsupervised predistillation using a large natural images dataset for improved\ninitialization. Our approach distills efficient neural networks that match or\nsurpass the teacher model in performance while achieving model compression and\nacceleration. Our results showcase the value of unsupervised predistillation in\nimproving the performance and robustness of our approach, specifically for\nlower-quality images. VLCD serves as an effective way to improve the efficiency\nand deployability of medical VLC approaches, making AI-based healthcare\nsolutions more accessible, especially in resource-constrained environments.", "AI": {"tldr": "The paper proposes two modifications to vision-language contrastive learning (VLC) frameworks to improve efficiency and accuracy in detecting childbirth-related pathologies from placenta images and reports.", "motivation": "Existing automated methods for placenta pathology analysis are computationally intensive, limiting deployability. The goal is to enhance efficiency and accessibility of AI-based healthcare solutions.", "method": "Introduces (1) text-anchored vision-language contrastive knowledge distillation (VLCD) for medical VLC pretraining, and (2) unsupervised predistillation using natural images for better initialization.", "result": "The approach achieves model compression and acceleration while matching or surpassing teacher model performance, especially for lower-quality images.", "conclusion": "VLCD improves efficiency and deployability of medical VLC, making AI healthcare solutions more accessible, particularly in resource-constrained settings."}}
{"id": "2506.01989", "pdf": "https://arxiv.org/pdf/2506.01989", "abs": "https://arxiv.org/abs/2506.01989", "authors": ["Chengxi Li", "Ming Xiao", "Mikael Skoglund"], "title": "Coded Robust Aggregation for Distributed Learning under Byzantine Attacks", "categories": ["cs.LG", "cs.AI", "cs.CR"], "comment": null, "summary": "In this paper, we investigate the problem of distributed learning (DL) in the\npresence of Byzantine attacks. For this problem, various robust bounded\naggregation (RBA) rules have been proposed at the central server to mitigate\nthe impact of Byzantine attacks. However, current DL methods apply RBA rules\nfor the local gradients from the honest devices and the disruptive information\nfrom Byzantine devices, and the learning performance degrades significantly\nwhen the local gradients of different devices vary considerably from each\nother. To overcome this limitation, we propose a new DL method to cope with\nByzantine attacks based on coded robust aggregation (CRA-DL). Before training\nbegins, the training data are allocated to the devices redundantly. During\ntraining, in each iteration, the honest devices transmit coded gradients to the\nserver computed from the allocated training data, and the server then\naggregates the information received from both honest and Byzantine devices\nusing RBA rules. In this way, the global gradient can be approximately\nrecovered at the server to update the global model. Compared with current DL\nmethods applying RBA rules, the improvement of CRA-DL is attributed to the fact\nthat the coded gradients sent by the honest devices are closer to each other.\nThis closeness enhances the robustness of the aggregation against Byzantine\nattacks, since Byzantine messages tend to be significantly different from those\nof honest devices in this case. We theoretically analyze the convergence\nperformance of CRA-DL. Finally, we present numerical results to verify the\nsuperiority of the proposed method over existing baselines, showing its\nenhanced learning performance under Byzantine attacks.", "AI": {"tldr": "The paper proposes CRA-DL, a coded robust aggregation method for distributed learning to mitigate Byzantine attacks by ensuring coded gradients from honest devices are closer, enhancing robustness and performance.", "motivation": "Current distributed learning methods degrade under Byzantine attacks when local gradients vary significantly. The goal is to improve robustness and learning performance in such adversarial settings.", "method": "CRA-DL redundantly allocates training data, computes coded gradients from honest devices, and aggregates them with Byzantine data using robust bounded aggregation rules.", "result": "Theoretical analysis and numerical results show CRA-DL outperforms existing methods by ensuring coded gradients are closer, making aggregation more robust.", "conclusion": "CRA-DL effectively mitigates Byzantine attacks in distributed learning, improving convergence and performance compared to current methods."}}
{"id": "2506.02568", "pdf": "https://arxiv.org/pdf/2506.02568", "abs": "https://arxiv.org/abs/2506.02568", "authors": ["Dongzhe Fan", "Yi Fang", "Jiajin Liu", "Djellel Difallah", "Qiaoyu Tan"], "title": "MLaGA: Multimodal Large Language and Graph Assistant", "categories": ["cs.AI"], "comment": null, "summary": "Large Language Models (LLMs) have demonstrated substantial efficacy in\nadvancing graph-structured data analysis. Prevailing LLM-based graph methods\nexcel in adapting LLMs to text-rich graphs, wherein node attributes are text\ndescriptions. However, their applications to multimodal graphs--where nodes are\nassociated with diverse attribute types, such as texts and images--remain\nunderexplored, despite their ubiquity in real-world scenarios. To bridge the\ngap, we introduce the Multimodal Large Language and Graph Assistant (MLaGA), an\ninnovative model that adeptly extends LLM capabilities to facilitate reasoning\nover complex graph structures and multimodal attributes. We first design a\nstructure-aware multimodal encoder to align textual and visual attributes\nwithin a unified space through a joint graph pre-training objective.\nSubsequently, we implement a multimodal instruction-tuning approach to\nseamlessly integrate multimodal features and graph structures into the LLM\nthrough lightweight projectors. Extensive experiments across multiple datasets\ndemonstrate the effectiveness of MLaGA compared to leading baseline methods,\nachieving superior performance in diverse graph learning tasks under both\nsupervised and transfer learning scenarios.", "AI": {"tldr": "MLaGA extends LLMs to handle multimodal graphs with text and image attributes, outperforming baselines in graph learning tasks.", "motivation": "Existing LLM-based graph methods focus on text-rich graphs, leaving multimodal graphs underexplored despite their real-world relevance.", "method": "MLaGA uses a structure-aware multimodal encoder for attribute alignment and multimodal instruction-tuning to integrate features into LLMs.", "result": "MLaGA achieves superior performance in supervised and transfer learning tasks across multiple datasets.", "conclusion": "MLaGA effectively bridges the gap in multimodal graph analysis, demonstrating strong adaptability and performance."}}
{"id": "2506.02283", "pdf": "https://arxiv.org/pdf/2506.02283", "abs": "https://arxiv.org/abs/2506.02283", "authors": ["Sofoklis Kakouros", "Haoyu Chen"], "title": "Sounding Like a Winner? Prosodic Differences in Post-Match Interviews", "categories": ["cs.CL", "eess.AS"], "comment": "Accepted to Interspeech 2025", "summary": "This study examines the prosodic characteristics associated with winning and\nlosing in post-match tennis interviews. Additionally, this research explores\nthe potential to classify match outcomes solely based on post-match interview\nrecordings using prosodic features and self-supervised learning (SSL)\nrepresentations. By analyzing prosodic elements such as pitch and intensity,\nalongside SSL models like Wav2Vec 2.0 and HuBERT, the aim is to determine\nwhether an athlete has won or lost their match. Traditional acoustic features\nand deep speech representations are extracted from the data, and machine\nlearning classifiers are employed to distinguish between winning and losing\nplayers. Results indicate that SSL representations effectively differentiate\nbetween winning and losing outcomes, capturing subtle speech patterns linked to\nemotional states. At the same time, prosodic cues -- such as pitch variability\n-- remain strong indicators of victory.", "AI": {"tldr": "The study analyzes prosodic features in tennis post-match interviews to classify match outcomes using self-supervised learning (SSL) models like Wav2Vec 2.0 and HuBERT. Results show SSL representations and prosodic cues (e.g., pitch variability) effectively distinguish winners from losers.", "motivation": "To explore whether prosodic characteristics and SSL representations can classify match outcomes (win/loss) based on post-match interviews, leveraging emotional speech patterns.", "method": "Analyzed prosodic features (pitch, intensity) and SSL models (Wav2Vec 2.0, HuBERT) from interview recordings. Used machine learning classifiers to differentiate winners and losers.", "result": "SSL representations and prosodic cues (e.g., pitch variability) successfully classified match outcomes, capturing emotional speech patterns.", "conclusion": "Prosodic features and SSL models are effective tools for classifying match outcomes in post-match tennis interviews, highlighting the link between speech and emotional states."}}
{"id": "2506.01998", "pdf": "https://arxiv.org/pdf/2506.01998", "abs": "https://arxiv.org/abs/2506.01998", "authors": ["Takao Fujii", "Katie Seaborn", "Madeleine Steeds", "Jun Kato"], "title": "Inter(sectional) Alia(s): Ambiguity in Voice Agent Identity via Intersectional Japanese Self-Referents", "categories": ["cs.HC", "cs.AI", "cs.CL", "cs.CY", "cs.SD", "eess.AS"], "comment": "CHI '25", "summary": "Conversational agents that mimic people have raised questions about the\nethics of anthropomorphizing machines with human social identity cues. Critics\nhave also questioned assumptions of identity neutrality in humanlike agents.\nRecent work has revealed that intersectional Japanese pronouns can elicit\ncomplex and sometimes evasive impressions of agent identity. Yet, the role of\nother \"neutral\" non-pronominal self-referents (NPSR) and voice as a socially\nexpressive medium remains unexplored. In a crowdsourcing study, Japanese\nparticipants (N = 204) evaluated three ChatGPT voices (Juniper, Breeze, and\nEmber) using seven self-referents. We found strong evidence of voice gendering\nalongside the potential of intersectional self-referents to evade gendering,\ni.e., ambiguity through neutrality and elusiveness. Notably, perceptions of age\nand formality intersected with gendering as per sociolinguistic theories,\nespecially boku and watakushi. This work provides a nuanced take on agent\nidentity perceptions and champions intersectional and culturally-sensitive work\non voice agents.", "AI": {"tldr": "The paper explores how non-pronominal self-referents (NPSR) and voice in conversational agents influence perceptions of identity, revealing voice gendering and the potential of intersectional self-referents to create ambiguity.", "motivation": "To address ethical concerns about anthropomorphizing machines and assumptions of identity neutrality in humanlike agents, focusing on Japanese pronouns and voice.", "method": "A crowdsourcing study with 204 Japanese participants evaluating three ChatGPT voices (Juniper, Breeze, Ember) using seven self-referents.", "result": "Strong evidence of voice gendering, with intersectional self-referents (e.g., boku, watakushi) creating ambiguity. Age and formality perceptions intersected with gendering.", "conclusion": "The study highlights nuanced agent identity perceptions and advocates for intersectional, culturally-sensitive voice agent design."}}
{"id": "2406.03111", "pdf": "https://arxiv.org/pdf/2406.03111", "abs": "https://arxiv.org/abs/2406.03111", "authors": ["Xuanjun Chen", "Haibin Wu", "Jyh-Shing Roger Jang", "Hung-yi Lee"], "title": "Singing Voice Graph Modeling for SingFake Detection", "categories": ["eess.AS", "cs.SD", "eess.SP"], "comment": "Accepted by Interspeech 2024; Our code is available at\n  https://github.com/xjchenGit/SingGraph.git", "summary": "Detecting singing voice deepfakes, or SingFake, involves determining the\nauthenticity and copyright of a singing voice. Existing models for speech\ndeepfake detection have struggled to adapt to unseen attacks in this unique\nsinging voice domain of human vocalization. To bridge the gap, we present a\ngroundbreaking SingGraph model. The model synergizes the capabilities of the\nMERT acoustic music understanding model for pitch and rhythm analysis with the\nwav2vec2.0 model for linguistic analysis of lyrics. Additionally, we advocate\nfor using RawBoost and beat matching techniques grounded in music domain\nknowledge for singing voice augmentation, thereby enhancing SingFake detection\nperformance. Our proposed method achieves new state-of-the-art (SOTA) results\nwithin the SingFake dataset, surpassing the previous SOTA model across three\ndistinct scenarios: it improves EER relatively for seen singers by 13.2%, for\nunseen singers by 24.3%, and unseen singers using different codecs by 37.1%.", "AI": {"tldr": "The paper introduces SingGraph, a novel model combining MERT and wav2vec2.0 for detecting singing voice deepfakes (SingFake), achieving SOTA results.", "motivation": "Existing speech deepfake detection models fail in the singing voice domain due to unique vocalization challenges.", "method": "SingGraph integrates MERT for pitch/rhythm analysis and wav2vec2.0 for lyrics analysis, with RawBoost and beat matching for augmentation.", "result": "SingGraph improves EER by 13.2% (seen singers), 24.3% (unseen singers), and 37.1% (unseen singers with different codecs).", "conclusion": "SingGraph sets a new benchmark for SingFake detection, outperforming previous models across diverse scenarios."}}
{"id": "2505.17602", "pdf": "https://arxiv.org/pdf/2505.17602", "abs": "https://arxiv.org/abs/2505.17602", "authors": ["Muhammad Abdullah", "Furqan Shaukat"], "title": "A Unified Multi-Scale Attention-Based Network for Automatic 3D Segmentation of Lung Parenchyma & Nodules In Thoracic CT Images", "categories": ["eess.IV"], "comment": null, "summary": "Lung cancer has been one of the major threats across the world with the\nhighest mortalities. Computer-aided detection (CAD) can help in early detection\nand thus can help increase the survival rate. Accurate lung parenchyma\nsegmentation (to include the juxta-pleural nodules) and lung nodule\nsegmentation, the primary symptom of lung cancer, play a crucial role in the\noverall accuracy of the Lung CAD pipeline. Lung nodule segmentation is quite\nchallenging because of the diverse nodule types and other inhibit structures\npresent within the lung lobes. Traditional machine/deep learning methods suffer\nfrom generalization and robustness. Recent Vision Language Models/Foundation\nModels perform well on the anatomical level, but they suffer on fine-grained\nsegmentation tasks, and their semi-automatic nature limits their effectiveness\nin real-time clinical scenarios. In this paper, we propose a novel method for\naccurate 3D segmentation of lung parenchyma and lung nodules. The proposed\narchitecture is an attention-based network with residual blocks at each\nencoder-decoder state. Max pooling is replaced by strided convolutions at the\nencoder, and trilinear interpolation is replaced by transposed convolutions at\nthe decoder to maximize the number of learnable parameters. Dilated\nconvolutions at each encoder-decoder stage allow the model to capture the\nlarger context without increasing computational costs. The proposed method has\nbeen evaluated extensively on one of the largest publicly available datasets,\nnamely LUNA16, and is compared with recent notable work in the domain using\nstandard performance metrics like Dice score, IOU, etc. It can be seen from the\nresults that the proposed method achieves better performance than\nstate-of-the-art methods. The source code, datasets, and pre-processed data can\nbe accessed using the link:\nhttps://github.com/EMeRALDsNRPU/Attention-Based-3D-ResUNet.", "AI": {"tldr": "A novel attention-based 3D segmentation method for lung parenchyma and nodules outperforms state-of-the-art techniques, validated on the LUNA16 dataset.", "motivation": "Lung cancer's high mortality necessitates early detection via CAD, but existing methods lack generalization and robustness for fine-grained segmentation.", "method": "Proposes an attention-based network with residual blocks, strided/transposed convolutions, and dilated convolutions for context capture without added computational cost.", "result": "Achieves superior performance on LUNA16 dataset compared to recent methods, using metrics like Dice score and IOU.", "conclusion": "The method enhances lung CAD accuracy, with potential for real-time clinical use; code and data are publicly available."}}
{"id": "2506.02244", "pdf": "https://arxiv.org/pdf/2506.02244", "abs": "https://arxiv.org/abs/2506.02244", "authors": ["Bowen Xue", "Giuseppe Claudio Guarnera", "Shuang Zhao", "Zahra Montazeri"], "title": "Motion aware video generative model", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Recent advances in diffusion-based video generation have yielded\nunprecedented quality in visual content and semantic coherence. However,\ncurrent approaches predominantly rely on statistical learning from vast\ndatasets without explicitly modeling the underlying physics of motion,\nresulting in subtle yet perceptible non-physical artifacts that diminish the\nrealism of generated videos. This paper introduces a physics-informed frequency\ndomain approach to enhance the physical plausibility of generated videos. We\nfirst conduct a systematic analysis of the frequency-domain characteristics of\ndiverse physical motions (translation, rotation, scaling), revealing that each\nmotion type exhibits distinctive and identifiable spectral signatures. Building\non this theoretical foundation, we propose two complementary components: (1) a\nphysical motion loss function that quantifies and optimizes the conformity of\ngenerated videos to ideal frequency-domain motion patterns, and (2) a frequency\ndomain enhancement module that progressively learns to adjust video features to\nconform to physical motion constraints while preserving original network\nfunctionality through a zero-initialization strategy. Experiments across\nmultiple video diffusion architectures demonstrate that our approach\nsignificantly enhances motion quality and physical plausibility without\ncompromising visual quality or semantic alignment. Our frequency-domain\nphysical motion framework generalizes effectively across different video\ngeneration architectures, offering a principled approach to incorporating\nphysical constraints into deep learning-based video synthesis pipelines. This\nwork seeks to establish connections between data-driven models and\nphysics-based motion models.", "AI": {"tldr": "The paper introduces a physics-informed frequency domain approach to improve the physical plausibility of diffusion-based video generation, addressing non-physical artifacts by modeling motion in the frequency domain.", "motivation": "Current video generation methods rely on statistical learning without explicit physics modeling, leading to subtle non-physical artifacts that reduce realism.", "method": "The approach includes a physical motion loss function and a frequency domain enhancement module to optimize and adjust video features for physical plausibility.", "result": "Experiments show improved motion quality and physical plausibility without sacrificing visual quality or semantic alignment.", "conclusion": "The framework bridges data-driven models and physics-based motion models, offering a principled way to integrate physical constraints into video synthesis."}}
{"id": "2506.02050", "pdf": "https://arxiv.org/pdf/2506.02050", "abs": "https://arxiv.org/abs/2506.02050", "authors": ["Qingyu Xiao", "Yuanlin Chang", "Youtian Du"], "title": "Decoupled Hierarchical Reinforcement Learning with State Abstraction for Discrete Grids", "categories": ["cs.LG", "cs.AI"], "comment": "6 pages, 6 figures", "summary": "Effective agent exploration remains a core challenge in reinforcement\nlearning (RL) for complex discrete state-space environments, particularly under\npartial observability. This paper presents a decoupled hierarchical RL\nframework integrating state abstraction (DcHRL-SA) to address this issue. The\nproposed method employs a dual-level architecture, consisting of a high level\nRL-based actor and a low-level rule-based policy, to promote effective\nexploration. Additionally, state abstraction method is incorporated to cluster\ndiscrete states, effectively lowering state dimensionality. Experiments\nconducted in two discrete customized grid environments demonstrate that the\nproposed approach consistently outperforms PPO in terms of exploration\nefficiency, convergence speed, cumulative reward, and policy stability. These\nresults demonstrate a practical approach for integrating decoupled hierarchical\npolicies and state abstraction in discrete grids with large-scale exploration\nspace. Code will be available at https://github.com/XQY169/DcHRL-SA.", "AI": {"tldr": "A decoupled hierarchical RL framework (DcHRL-SA) improves exploration in complex discrete state-space environments by combining state abstraction and a dual-level policy architecture.", "motivation": "Addressing the challenge of effective agent exploration in RL, especially under partial observability in discrete state spaces.", "method": "Uses a dual-level architecture (high-level RL actor and low-level rule-based policy) with state abstraction to cluster states and reduce dimensionality.", "result": "Outperforms PPO in exploration efficiency, convergence speed, cumulative reward, and policy stability in grid environments.", "conclusion": "DcHRL-SA offers a practical solution for large-scale exploration in discrete grids by integrating hierarchical policies and state abstraction."}}
{"id": "2506.02576", "pdf": "https://arxiv.org/pdf/2506.02576", "abs": "https://arxiv.org/abs/2506.02576", "authors": ["Haichen Wang", "Liu Yang", "Xinyuan Zhang", "Haomin Yu", "Ming Li", "Jilin Hu"], "title": "ADFormer: Aggregation Differential Transformer for Passenger Demand Forecasting", "categories": ["cs.AI"], "comment": "9 pages, 5 figures, 3 tables. IJCAI-2025", "summary": "Passenger demand forecasting helps optimize vehicle scheduling, thereby\nimproving urban efficiency. Recently, attention-based methods have been used to\nadequately capture the dynamic nature of spatio-temporal data. However,\nexisting methods that rely on heuristic masking strategies cannot fully adapt\nto the complex spatio-temporal correlations, hindering the model from focusing\non the right context. These works also overlook the high-level correlations\nthat exist in the real world. Effectively integrating these high-level\ncorrelations with the original correlations is crucial. To fill this gap, we\npropose the Aggregation Differential Transformer (ADFormer), which offers new\ninsights to demand forecasting promotion. Specifically, we utilize Differential\nAttention to capture the original spatial correlations and achieve attention\ndenoising. Meanwhile, we design distinct aggregation strategies based on the\nnature of space and time. Then, the original correlations are unified with the\nhigh-level correlations, enabling the model to capture holistic spatio-temporal\nrelations. Experiments conducted on taxi and bike datasets confirm the\neffectiveness and efficiency of our model, demonstrating its practical value.\nThe code is available at https://github.com/decisionintelligence/ADFormer.", "AI": {"tldr": "ADFormer, an Aggregation Differential Transformer, improves passenger demand forecasting by integrating high-level spatio-temporal correlations with original correlations using Differential Attention and tailored aggregation strategies.", "motivation": "Existing methods fail to fully adapt to complex spatio-temporal correlations and overlook high-level correlations, limiting forecasting accuracy.", "method": "ADFormer uses Differential Attention for spatial correlation capture and denoising, along with space-time-specific aggregation strategies to unify original and high-level correlations.", "result": "Experiments on taxi and bike datasets show ADFormer's effectiveness and efficiency in demand forecasting.", "conclusion": "ADFormer successfully captures holistic spatio-temporal relations, offering practical value for urban efficiency optimization."}}
{"id": "2506.02298", "pdf": "https://arxiv.org/pdf/2506.02298", "abs": "https://arxiv.org/abs/2506.02298", "authors": ["Thai Hoang", "Kung-Hsiang Huang", "Shirley Kokane", "Jianguo Zhang", "Zuxin Liu", "Ming Zhu", "Jake Grigsby", "Tian Lan", "Michael S Ryoo", "Chien-Sheng Wu", "Shelby Heinecke", "Huan Wang", "Silvio Savarese", "Caiming Xiong", "Juan Carlos Niebles"], "title": "LAM SIMULATOR: Advancing Data Generation for Large Action Model Training via Online Exploration and Trajectory Feedback", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "LAM Simulator framework for agentic data generation", "summary": "Large Action Models (LAMs) for AI Agents offer incredible potential but face\nchallenges due to the need for high-quality training data, especially for\nmulti-steps tasks that involve planning, executing tool calls, and responding\nto feedback. To address these issues, we present LAM SIMULATOR, a comprehensive\nframework designed for online exploration of agentic tasks with high-quality\nfeedback. Our framework features a dynamic task query generator, an extensive\ncollection of tools, and an interactive environment where Large Language Model\n(LLM) Agents can call tools and receive real-time feedback. This setup enables\nLLM Agents to explore and solve tasks autonomously, facilitating the discovery\nof multiple approaches to tackle any given task. The resulting action\ntrajectory data are then used to create high-quality training datasets for\nLAMs. Our experiments on popular agentic benchmarks, ToolBench and CRMArena,\nhighlight the effectiveness of LAM SIMULATOR: models trained with\nself-generated datasets using our framework achieve significant performance\ngains, up to a 49.3\\% improvement over their original baselines. LAM SIMULATOR\nrequires minimal human input during dataset creation, highlighting LAM\nSIMULATOR's efficiency and effectiveness in speeding up development of AI\nagents.", "AI": {"tldr": "LAM SIMULATOR is a framework for training Large Action Models (LAMs) by enabling autonomous exploration of tasks with real-time feedback, improving performance by up to 49.3%.", "motivation": "Addressing challenges in training LAMs due to the need for high-quality data, especially for multi-step tasks involving planning and feedback.", "method": "Introduces LAM SIMULATOR with a dynamic task query generator, tool collection, and interactive environment for LLM Agents to autonomously solve tasks and generate training data.", "result": "Models trained with self-generated datasets achieve up to 49.3% performance improvement on benchmarks like ToolBench and CRMArena.", "conclusion": "LAM SIMULATOR efficiently reduces human input in dataset creation, accelerating AI agent development."}}
{"id": "2505.23503", "pdf": "https://arxiv.org/pdf/2505.23503", "abs": "https://arxiv.org/abs/2505.23503", "authors": ["Shibbir Ahmed", "Shahnewaz Karim Sakib", "Anindya Bijoy Das"], "title": "Can Large Language Models Challenge CNNs in Medical Image Analysis?", "categories": ["eess.IV", "cs.AI", "cs.CV"], "comment": null, "summary": "This study presents a multimodal AI framework designed for precisely\nclassifying medical diagnostic images. Utilizing publicly available datasets,\nthe proposed system compares the strengths of convolutional neural networks\n(CNNs) and different large language models (LLMs). This in-depth comparative\nanalysis highlights key differences in diagnostic performance, execution\nefficiency, and environmental impacts. Model evaluation was based on accuracy,\nF1-score, average execution time, average energy consumption, and estimated\n$CO_2$ emission. The findings indicate that although CNN-based models can\noutperform various multimodal techniques that incorporate both images and\ncontextual information, applying additional filtering on top of LLMs can lead\nto substantial performance gains. These findings highlight the transformative\npotential of multimodal AI systems to enhance the reliability, efficiency, and\nscalability of medical diagnostics in clinical settings.", "AI": {"tldr": "A multimodal AI framework compares CNNs and LLMs for medical image classification, showing LLMs with filtering can outperform CNNs in performance, efficiency, and environmental impact.", "motivation": "To enhance the reliability, efficiency, and scalability of medical diagnostics by comparing CNN and LLM-based multimodal AI systems.", "method": "Comparative analysis of CNNs and LLMs using accuracy, F1-score, execution time, energy consumption, and CO2 emissions on public datasets.", "result": "LLMs with additional filtering outperform CNNs in diagnostic performance, efficiency, and environmental impact.", "conclusion": "Multimodal AI systems, especially LLMs with filtering, hold transformative potential for improving medical diagnostics."}}
{"id": "2506.02247", "pdf": "https://arxiv.org/pdf/2506.02247", "abs": "https://arxiv.org/abs/2506.02247", "authors": ["Yu Wang", "Juhyung Ha", "David J. Crandall"], "title": "PAIR-Net: Enhancing Egocentric Speaker Detection via Pretrained Audio-Visual Fusion and Alignment Loss", "categories": ["cs.CV"], "comment": "4 pages, 1 figure, and 1 table", "summary": "Active speaker detection (ASD) in egocentric videos presents unique\nchallenges due to unstable viewpoints, motion blur, and off-screen speech\nsources - conditions under which traditional visual-centric methods degrade\nsignificantly. We introduce PAIR-Net (Pretrained Audio-Visual Integration with\nRegularization Network), an effective model that integrates a partially frozen\nWhisper audio encoder with a fine-tuned AV-HuBERT visual backbone to robustly\nfuse cross-modal cues. To counteract modality imbalance, we introduce an\ninter-modal alignment loss that synchronizes audio and visual representations,\nenabling more consistent convergence across modalities. Without relying on\nmulti-speaker context or ideal frontal views, PAIR-Net achieves\nstate-of-the-art performance on the Ego4D ASD benchmark with 76.6% mAP,\nsurpassing LoCoNet and STHG by 8.2% and 12.9% mAP, respectively. Our results\nhighlight the value of pretrained audio priors and alignment-based fusion for\nrobust ASD under real-world egocentric conditions.", "AI": {"tldr": "PAIR-Net integrates pretrained audio and visual models with alignment loss for robust active speaker detection in egocentric videos, achieving state-of-the-art results.", "motivation": "Traditional visual-centric methods degrade in egocentric videos due to unstable viewpoints and off-screen speech, necessitating a robust cross-modal approach.", "method": "PAIR-Net combines a frozen Whisper audio encoder with a fine-tuned AV-HuBERT visual backbone, using inter-modal alignment loss for balanced fusion.", "result": "PAIR-Net achieves 76.6% mAP on Ego4D ASD, outperforming LoCoNet and STHG by 8.2% and 12.9%, respectively.", "conclusion": "Pretrained audio priors and alignment-based fusion are key for robust active speaker detection in real-world egocentric conditions."}}
{"id": "2506.02053", "pdf": "https://arxiv.org/pdf/2506.02053", "abs": "https://arxiv.org/abs/2506.02053", "authors": ["Xu Zhang", "Haoye Qiu", "Weixuan Liang", "Hui Liu", "Junhui Hou", "Yuheng Jia"], "title": "Generalization Performance of Ensemble Clustering: From Theory to Algorithm", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Ensemble clustering has demonstrated great success in practice; however, its\ntheoretical foundations remain underexplored. This paper examines the\ngeneralization performance of ensemble clustering, focusing on generalization\nerror, excess risk and consistency. We derive a convergence rate of\ngeneralization error bound and excess risk bound both of\n$\\mathcal{O}(\\sqrt{\\frac{\\log n}{m}}+\\frac{1}{\\sqrt{n}})$, with $n$ and $m$\nbeing the numbers of samples and base clusterings. Based on this, we prove that\nwhen $m$ and $n$ approach infinity and $m$ is significantly larger than log\n$n$, i.e., $m,n\\to \\infty, m\\gg \\log n$, ensemble clustering is consistent.\nFurthermore, recognizing that $n$ and $m$ are finite in practice, the\ngeneralization error cannot be reduced to zero. Thus, by assigning varying\nweights to finite clusterings, we minimize the error between the empirical\naverage clusterings and their expectation. From this, we theoretically\ndemonstrate that to achieve better clustering performance, we should minimize\nthe deviation (bias) of base clustering from its expectation and maximize the\ndifferences (diversity) among various base clusterings. Additionally, we derive\nthat maximizing diversity is nearly equivalent to a robust (min-max)\noptimization model. Finally, we instantiate our theory to develop a new\nensemble clustering algorithm. Compared with SOTA methods, our approach\nachieves average improvements of 6.1%, 7.3%, and 6.0% on 10 datasets w.r.t.\nNMI, ARI, and Purity. The code is available at https://github.com/xuz2019/GPEC.", "AI": {"tldr": "The paper explores the theoretical foundations of ensemble clustering, deriving bounds for generalization error and excess risk, proving consistency under certain conditions, and proposing a new algorithm that outperforms state-of-the-art methods.", "motivation": "To address the underexplored theoretical aspects of ensemble clustering, particularly generalization performance, and to bridge the gap between theory and practice.", "method": "The study derives convergence rates for generalization error and excess risk, analyzes consistency conditions, and introduces a weighted ensemble clustering approach to minimize empirical error.", "result": "The proposed algorithm achieves average improvements of 6.1%, 7.3%, and 6.0% on 10 datasets in terms of NMI, ARI, and Purity.", "conclusion": "Ensemble clustering benefits from minimizing bias and maximizing diversity among base clusterings, with theoretical insights leading to a practical, high-performing algorithm."}}
{"id": "2506.02580", "pdf": "https://arxiv.org/pdf/2506.02580", "abs": "https://arxiv.org/abs/2506.02580", "authors": ["Xuewen Luo", "Fengze Yang", "Fan Ding", "Xiangbo Gao", "Shuo Xing", "Yang Zhou", "Zhengzhong Tu", "Chenxi Liu"], "title": "V2X-UniPool: Unifying Multimodal Perception and Knowledge Reasoning for Autonomous Driving", "categories": ["cs.AI"], "comment": null, "summary": "Knowledge-driven autonomous driving systems(ADs) offer powerful reasoning\ncapabilities, but face two critical challenges: limited perception due to the\nshort-sightedness of single-vehicle sensors, and hallucination arising from the\nlack of real-time environmental grounding. To address these issues, this paper\nintroduces V2X-UniPool, a unified framework that integrates multimodal\nVehicle-to-Everything (V2X) data into a time-indexed and language-based\nknowledge pool. By leveraging a dual-query Retrieval-Augmented Generation (RAG)\nmechanism, which enables retrieval of both static and dynamic knowledge, our\nsystem enables ADs to perform accurate, temporally consistent reasoning over\nboth static environment and dynamic traffic context. Experiments on a\nreal-world cooperative driving dataset demonstrate that V2X-UniPool\nsignificantly enhances motion planning accuracy and reasoning capability.\nRemarkably, it enables even zero-shot vehicle-side models to achieve\nstate-of-the-art performance by leveraging V2X-UniPool, while simultaneously\nreducing transmission cost by over 99.9\\% compared to prior V2X methods.", "AI": {"tldr": "V2X-UniPool integrates multimodal V2X data for autonomous driving, improving reasoning and reducing transmission costs.", "motivation": "Addresses limited perception and hallucination in knowledge-driven ADs by leveraging V2X data.", "method": "Uses a dual-query RAG mechanism to retrieve static and dynamic knowledge from a unified knowledge pool.", "result": "Enhances motion planning accuracy and reasoning, achieving state-of-the-art performance with reduced transmission costs.", "conclusion": "V2X-UniPool effectively improves AD performance and efficiency through unified knowledge integration."}}
{"id": "2506.02302", "pdf": "https://arxiv.org/pdf/2506.02302", "abs": "https://arxiv.org/abs/2506.02302", "authors": ["Russell Scheinberg", "Ameeta Agrawal", "Amber Shore", "So Young Lee"], "title": "Explain-then-Process: Using Grammar Prompting to Enhance Grammatical Acceptability Judgments", "categories": ["cs.CL", "cs.AI"], "comment": "Accepted at ACL 2025 Findings", "summary": "Large language models (LLMs) can explain grammatical rules, yet they often\nfail to apply those rules when judging sentence acceptability. We present\n\"grammar prompting\", an explain-then-process paradigm: a large LLM first\nproduces a concise explanation of the relevant syntactic phenomenon, then that\nexplanation is fed back as additional context to the target model -- either an\nLLM or a smaller language model (SLM) -- before deciding which sentence of a\nminimal pair is grammatical. On the English BLiMP, Chinese SLING, and Russian\nRuBLiMP benchmarks, this simple prompt design yields substantial improvements\nover strong baselines across many syntactic phenomena. Feeding an LLM's\nmetalinguistic explanation back to the target model bridges the gap between\nknowing a rule and using it. On SLMs, grammar prompting alone trims the average\nLLM-SLM accuracy gap by about 20%, and when paired with chain-of-thought, by\n56% (13.0 pp -> 5.8 pp), all at negligible cost. The lightweight,\nlanguage-agnostic cue lets low-cost SLMs approach frontier-LLM performance in\nmultilingual settings.", "AI": {"tldr": "Grammar prompting improves LLMs' ability to apply grammatical rules by having them explain rules first, then use those explanations to judge sentence acceptability.", "motivation": "LLMs can explain grammatical rules but struggle to apply them. This work aims to bridge the gap between rule knowledge and application.", "method": "Introduces 'grammar prompting': an LLM explains a syntactic rule, and the explanation is fed back to the target model (LLM or SLM) to judge sentence acceptability.", "result": "Substantial improvements on multilingual benchmarks (BLiMP, SLING, RuBLiMP), reducing LLM-SLM accuracy gap by 20-56%.", "conclusion": "Grammar prompting is a lightweight, effective method to enhance SLMs' performance, closing the gap with LLMs in multilingual tasks."}}
{"id": "2506.02584", "pdf": "https://arxiv.org/pdf/2506.02584", "abs": "https://arxiv.org/abs/2506.02584", "authors": ["Sarenne Wallbridge", "Christoph Minixhofer", "Catherine Lai", "Peter Bell"], "title": "Prosodic Structure Beyond Lexical Content: A Study of Self-Supervised Learning", "categories": ["cs.CL", "cs.AI", "eess.AS"], "comment": "Accepted at INTERSPEECH 2025", "summary": "People exploit the predictability of lexical structures during text\ncomprehension. Though predictable structure is also present in speech, the\ndegree to which prosody, e.g. intonation, tempo, and loudness, contributes to\nsuch structure independently of the lexical content is unclear. This study\nleverages self-supervised learning (SSL) to examine the temporal granularity of\nstructures in the acoustic correlates of prosody. Representations from our\nproposed Masked Prosody Model can predict perceptual labels dependent on local\ninformation, such as word boundaries, but provide the most value for labels\ninvolving longer-term structures, like emotion recognition. Probing experiments\nacross various perceptual labels show strong relative gains over untransformed\npitch, energy, and voice activity features. Our results reveal the importance\nof SSL training objective timescale and highlight the value of complex\nSSL-encoded structures compared to more constrained classical structures.", "AI": {"tldr": "The study uses self-supervised learning to analyze how prosody (intonation, tempo, loudness) contributes to speech structure beyond lexical content, showing its value for longer-term perceptual tasks like emotion recognition.", "motivation": "To understand the role of prosody in speech structure independently of lexical content, leveraging self-supervised learning for deeper analysis.", "method": "Proposed a Masked Prosody Model using self-supervised learning to examine acoustic correlates of prosody, tested across perceptual labels like word boundaries and emotion recognition.", "result": "The model outperformed traditional features (pitch, energy, voice activity) in perceptual tasks, especially for longer-term structures like emotion.", "conclusion": "Self-supervised learning reveals the importance of prosody's temporal granularity and its value for complex perceptual tasks compared to classical methods."}}
{"id": "2505.24407", "pdf": "https://arxiv.org/pdf/2505.24407", "abs": "https://arxiv.org/abs/2505.24407", "authors": ["Wenlong Jiao", "Binglong Li", "Wei Shang", "Ping Wang", "Dongwei Ren"], "title": "Efficient RAW Image Deblurring with Adaptive Frequency Modulation", "categories": ["eess.IV", "cs.CV"], "comment": "The code will be available at https://github.com/WenlongJiao/FrENet", "summary": "Image deblurring plays a crucial role in enhancing visual clarity across\nvarious applications. Although most deep learning approaches primarily focus on\nsRGB images, which inherently lose critical information during the image signal\nprocessing pipeline, RAW images, being unprocessed and linear, possess superior\nrestoration potential but remain underexplored. Deblurring RAW images presents\nunique challenges, particularly in handling frequency-dependent blur while\nmaintaining computational efficiency. To address these issues, we propose\nFrequency Enhanced Network (FrENet), a framework specifically designed for\nRAW-to-RAW deblurring that operates directly in the frequency domain. We\nintroduce a novel Adaptive Frequency Positional Modulation module, which\ndynamically adjusts frequency components according to their spectral positions,\nthereby enabling precise control over the deblurring process. Additionally,\nfrequency domain skip connections are adopted to further preserve\nhigh-frequency details. Experimental results demonstrate that FrENet surpasses\nstate-of-the-art deblurring methods in RAW image deblurring, achieving\nsignificantly better restoration quality while maintaining high efficiency in\nterms of reduced MACs. Furthermore, FrENet's adaptability enables it to be\nextended to sRGB images, where it delivers comparable or superior performance\ncompared to methods specifically designed for sRGB data. The code will be\navailable at https://github.com/WenlongJiao/FrENet .", "AI": {"tldr": "FrENet is a frequency-domain framework for RAW-to-RAW deblurring, outperforming state-of-the-art methods with adaptive frequency modulation and skip connections.", "motivation": "Existing deep learning approaches focus on sRGB images, which lose critical information, while RAW images offer superior restoration potential but are underexplored.", "method": "Proposes FrENet with an Adaptive Frequency Positional Modulation module and frequency domain skip connections for precise deblurring.", "result": "FrENet achieves better restoration quality and efficiency (reduced MACs) than state-of-the-art methods and adapts well to sRGB images.", "conclusion": "FrENet is a versatile and efficient solution for RAW image deblurring, with potential extensions to sRGB images."}}
{"id": "2506.02265", "pdf": "https://arxiv.org/pdf/2506.02265", "abs": "https://arxiv.org/abs/2506.02265", "authors": ["Samuel Li", "Pujith Kachana", "Prajwal Chidananda", "Saurabh Nair", "Yasutaka Furukawa", "Matthew Brown"], "title": "Rig3R: Rig-Aware Conditioning for Learned 3D Reconstruction", "categories": ["cs.CV"], "comment": null, "summary": "Estimating agent pose and 3D scene structure from multi-camera rigs is a\ncentral task in embodied AI applications such as autonomous driving. Recent\nlearned approaches such as DUSt3R have shown impressive performance in\nmultiview settings. However, these models treat images as unstructured\ncollections, limiting effectiveness in scenarios where frames are captured from\nsynchronized rigs with known or inferable structure.\n  To this end, we introduce Rig3R, a generalization of prior multiview\nreconstruction models that incorporates rig structure when available, and\nlearns to infer it when not. Rig3R conditions on optional rig metadata\nincluding camera ID, time, and rig poses to develop a rig-aware latent space\nthat remains robust to missing information. It jointly predicts pointmaps and\ntwo types of raymaps: a pose raymap relative to a global frame, and a rig\nraymap relative to a rig-centric frame consistent across time. Rig raymaps\nallow the model to infer rig structure directly from input images when metadata\nis missing.\n  Rig3R achieves state-of-the-art performance in 3D reconstruction, camera pose\nestimation, and rig discovery, outperforming both traditional and learned\nmethods by 17-45% mAA across diverse real-world rig datasets, all in a single\nforward pass without post-processing or iterative refinement.", "AI": {"tldr": "Rig3R improves 3D reconstruction by incorporating rig structure, outperforming existing methods by 17-45% mAA.", "motivation": "Existing models treat images as unstructured, limiting performance in synchronized rig scenarios.", "method": "Rig3R uses rig metadata (camera ID, time, poses) to create a rig-aware latent space and predicts pointmaps and raymaps.", "result": "Achieves state-of-the-art performance in 3D reconstruction, pose estimation, and rig discovery.", "conclusion": "Rig3R is robust and efficient, requiring no post-processing or iterative refinement."}}
{"id": "2506.02062", "pdf": "https://arxiv.org/pdf/2506.02062", "abs": "https://arxiv.org/abs/2506.02062", "authors": ["Malik A. Altayar", "Muhyeeddin Alqaraleh", "Mowafaq Salem Alzboon", "Wesam T. Almagharbeh"], "title": "Predicting Blood Type: Assessing Model Performance with ROC Analysis", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Introduction: Personal identification is a critical aspect of forensic\nsciences, security, and healthcare. While conventional biometrics systems such\nas DNA profiling and iris scanning offer high accuracy, they are time-consuming\nand costly. Objectives: This study investigates the relationship between\nfingerprint patterns and ABO blood group classification to explore potential\ncorrelations between these two traits. Methods: The study analyzed 200\nindividuals, categorizing their fingerprints into three types: loops, whorls,\nand arches. Blood group classification was also recorded. Statistical analysis,\nincluding chi-square and Pearson correlation tests, was used to assess\nassociations between fingerprint patterns and blood groups. Results: Loops were\nthe most common fingerprint pattern, while blood group O+ was the most\nprevalent among the participants. Statistical analysis revealed no significant\ncorrelation between fingerprint patterns and blood groups (p > 0.05),\nsuggesting that these traits are independent. Conclusions: Although the study\nshowed limited correlation between fingerprint patterns and ABO blood groups,\nit highlights the importance of future research using larger and more diverse\npopulations, incorporating machine learning approaches, and integrating\nmultiple biometric signals. This study contributes to forensic science by\nemphasizing the need for rigorous protocols and comprehensive investigations in\npersonal identification.", "AI": {"tldr": "The study explored correlations between fingerprint patterns and ABO blood groups but found no significant link, suggesting independent traits. Future research with larger datasets and advanced methods is recommended.", "motivation": "To investigate potential correlations between fingerprint patterns and ABO blood groups for forensic and healthcare applications, addressing the limitations of costly and time-consuming biometric systems.", "method": "Analyzed 200 individuals, categorizing fingerprints into loops, whorls, and arches, and recording blood groups. Used chi-square and Pearson correlation tests for statistical analysis.", "result": "Loops were the most common fingerprint pattern, and O+ was the most prevalent blood group. No significant correlation between fingerprint patterns and blood groups was found (p > 0.05).", "conclusion": "The study found no significant correlation but emphasized the need for future research with larger, diverse populations and advanced methods like machine learning to enhance forensic identification."}}
{"id": "2506.02594", "pdf": "https://arxiv.org/pdf/2506.02594", "abs": "https://arxiv.org/abs/2506.02594", "authors": ["Ruibo Duan", "Yuxin Liu", "Xinyao Dong", "Chenglin Fan"], "title": "EALG: Evolutionary Adversarial Generation of Language Model-Guided Generators for Combinatorial Optimization", "categories": ["cs.AI"], "comment": null, "summary": "Generating challenging instances is crucial for the evaluation and\nadvancement of combinatorial optimization solvers. In this work, we introduce\nEALG (Evolutionary Adversarial Generation of Language Model-Guided Generators),\na novel framework that automates the co-evolution of optimization problem\ninstances and their corresponding heuristic solvers using large language models\n(LLMs). EALG leverages a mutation-based adversarial approach that dynamically\nevolves instance generation procedures to create increasingly difficult\nproblems, while simultaneously synthesizing adaptive heuristic algorithms\nthrough interactions with LLMs guided by algorithmic structure. Unlike existing\napproaches that focus solely on static benchmark creation or manual solver\ndesign, EALG provides a seamless pipeline from instance generation to solver\nsynthesis. Experimental results demonstrate that EALG generates significantly\nharder instances than current benchmarks, and its synthesized solvers\ngeneralize effectively across a broad spectrum of combinatorial tasks. This\nwork explores a new paradigm for combinatorial optimization that integrates\ninstance generation with solver design, resulting in state-of-the-art\nperformance.", "AI": {"tldr": "EALG is a framework that co-evolves optimization problem instances and heuristic solvers using LLMs, producing harder instances and adaptive solvers.", "motivation": "To advance combinatorial optimization by automating the creation of challenging instances and adaptive solvers, moving beyond static benchmarks and manual design.", "method": "Uses a mutation-based adversarial approach with LLMs to dynamically evolve instance generation and synthesize heuristic solvers.", "result": "Generates harder instances than current benchmarks, with solvers generalizing well across combinatorial tasks.", "conclusion": "EALG integrates instance generation and solver design, achieving state-of-the-art performance in combinatorial optimization."}}
{"id": "2506.02321", "pdf": "https://arxiv.org/pdf/2506.02321", "abs": "https://arxiv.org/abs/2506.02321", "authors": ["Pegah Alipoormolabashi", "Ajay Patel", "Niranjan Balasubramanian"], "title": "Quantifying Misattribution Unfairness in Authorship Attribution", "categories": ["cs.CL"], "comment": null, "summary": "Authorship misattribution can have profound consequences in real life. In\nforensic settings simply being considered as one of the potential authors of an\nevidential piece of text or communication can result in undesirable scrutiny.\nThis raises a fairness question: Is every author in the candidate pool at equal\nrisk of misattribution? Standard evaluation measures for authorship attribution\nsystems do not explicitly account for this notion of fairness. We introduce a\nsimple measure, Misattribution Unfairness Index (MAUIk), which is based on how\noften authors are ranked in the top k for texts they did not write. Using this\nmeasure we quantify the unfairness of five models on two different datasets.\nAll models exhibit high levels of unfairness with increased risks for some\nauthors. Furthermore, we find that this unfairness relates to how the models\nembed the authors as vectors in the latent search space. In particular, we\nobserve that the risk of misattribution is higher for authors closer to the\ncentroid (or center) of the embedded authors in the haystack. These results\nindicate the potential for harm and the need for communicating with and\ncalibrating end users on misattribution risk when building and providing such\nmodels for downstream use.", "AI": {"tldr": "The paper introduces MAUIk, a fairness measure for authorship attribution, revealing high unfairness in models and linking misattribution risk to authors' positions in latent space.", "motivation": "Address fairness in authorship attribution, as misattribution can harm individuals, especially in forensic settings.", "method": "Propose MAUIk to measure unfairness by tracking how often authors are wrongly ranked in the top k. Test five models on two datasets.", "result": "All models show high unfairness, with misattribution risk higher for authors near the centroid in latent space.", "conclusion": "Highlights potential harm and the need for user communication and risk calibration in deploying such models."}}
{"id": "2506.02627", "pdf": "https://arxiv.org/pdf/2506.02627", "abs": "https://arxiv.org/abs/2506.02627", "authors": ["\u00d6mer Tarik \u00d6zyilmaz", "Matt Coler", "Matias Valdenegro-Toro"], "title": "Overcoming Data Scarcity in Multi-Dialectal Arabic ASR via Whisper Fine-Tuning", "categories": ["cs.CL", "cs.SD", "eess.AS"], "comment": "Accepted at Interspeech 2025", "summary": "Although commercial Arabic automatic speech recognition (ASR) systems support\nModern Standard Arabic (MSA), they struggle with dialectal speech. We\ninvestigate the effect of fine-tuning OpenAI's Whisper on five major Arabic\ndialects (Gulf, Levantine, Iraqi, Egyptian, Maghrebi) using Mozilla Common\nVoice for MSA and the MASC dataset for dialectal speech. We evaluate MSA\ntraining size effects, benefits of pre-training on MSA data, and\ndialect-specific versus dialect-pooled models. We find that small amounts of\nMSA fine-tuning data yield substantial improvements for smaller models,\nmatching larger non-fine-tuned models. While MSA pre-training shows minimal\nbenefit, suggesting limited shared features between MSA and dialects, our\ndialect-pooled models perform comparably to dialect-specific ones. This\nindicates that pooling dialectal data, when properly balanced, can help address\ndata scarcity in low-resource ASR without significant performance loss.", "AI": {"tldr": "Fine-tuning OpenAI's Whisper on Arabic dialects improves ASR performance, with small MSA data boosts for smaller models. Dialect-pooled models match dialect-specific ones, aiding low-resource ASR.", "motivation": "Commercial ASR systems struggle with Arabic dialects despite supporting MSA. This work explores fine-tuning Whisper for dialectal speech to address this gap.", "method": "Fine-tuned Whisper on five Arabic dialects using Mozilla Common Voice (MSA) and MASC (dialects). Evaluated MSA training size, pre-training benefits, and dialect-specific vs. pooled models.", "result": "Small MSA fine-tuning data improves smaller models significantly. MSA pre-training offers minimal benefit. Dialect-pooled models perform comparably to dialect-specific ones.", "conclusion": "Pooling dialectal data, when balanced, can mitigate data scarcity in low-resource ASR without major performance loss."}}
{"id": "2403.01607", "pdf": "https://arxiv.org/pdf/2403.01607", "abs": "https://arxiv.org/abs/2403.01607", "authors": ["Michel Pohl", "Mitsuru Uesaka", "Hiroyuki Takahashi", "Kazuyuki Demachi", "Ritu Bhusal Chhatkuli"], "title": "Real-time respiratory motion forecasting with online learning of recurrent neural networks for accurate targeting in externally guided radiotherapy", "categories": ["cs.LG", "cs.NE", "eess.IV", "eess.SP"], "comment": "40 pages, 18 figures, accepted manuscript version", "summary": "In lung radiotherapy, infrared cameras can track reflective objects on the\nchest to estimate tumor motion due to breathing, but treatment system latencies\nhinder radiation beam precision. Real-time recurrent learning (RTRL) is a\npotential solution that can learn patterns within non-stationary respiratory\ndata but has high complexity. This study assesses the capabilities of\nresource-efficient online RNN algorithms, namely unbiased online recurrent\noptimization (UORO), sparse-1 step approximation (SnAp-1), and decoupled neural\ninterfaces (DNI) to forecast respiratory motion during radiotherapy treatment\naccurately. We use time series containing the 3D positions of external markers\non the chest of healthy subjects. We propose efficient implementations for\nSnAp-1 and DNI that compress the influence and immediate Jacobian matrices and\naccurately update the linear coefficients used in credit assignment estimation,\nrespectively. Data was originally sampled at 10Hz; we resampled it at 3.33Hz\nand 30Hz to analyze the effect of the sampling rate on performance. We use\nUORO, SnAp-1, and DNI to forecast each marker's 3D position with horizons\nh<=2.1s (the time interval in advance for which the prediction is made) and\ncompare them with RTRL, least mean squares, kernel support vector regression,\nand linear regression. RNNs trained online achieved similar or better accuracy\nthan most previous works using larger training databases and deep learning,\neven though we used only the first minute of each sequence to predict motion\nwithin that exact sequence. SnAp-1 had the lowest normalized root mean square\nerrors (nRMSEs) averaged over the horizon values considered, equal to 0.335 and\n0.157, at 3.33Hz and 10.0Hz, respectively. Similarly, UORO had the lowest nRMSE\nat 30Hz, equal to 0.086. DNI's inference time (6.8ms per time step at 30Hz,\nIntel Core i7-13700 CPU) was the lowest among the RNN methods.", "AI": {"tldr": "The study evaluates efficient online RNN algorithms (UORO, SnAp-1, DNI) for predicting respiratory motion in lung radiotherapy, achieving competitive accuracy with minimal training data.", "motivation": "To address treatment system latencies in lung radiotherapy by improving real-time respiratory motion prediction using resource-efficient RNN methods.", "method": "Proposed efficient implementations for SnAp-1 and DNI, tested on 3D marker data resampled at different rates, and compared performance with existing methods.", "result": "SnAp-1 and UORO showed the lowest errors at varying sampling rates, while DNI had the fastest inference time.", "conclusion": "Online RNNs can achieve high accuracy in respiratory motion prediction with minimal training, offering practical solutions for radiotherapy."}}
{"id": "2506.02291", "pdf": "https://arxiv.org/pdf/2506.02291", "abs": "https://arxiv.org/abs/2506.02291", "authors": ["Cristian-Ioan Blaga", "Paul Suganthan", "Sahil Dua", "Krishna Srinivasan", "Enrique Alfonseca", "Peter Dornbach", "Tom Duerig", "Imed Zitouni", "Zhe Dong"], "title": "Entity Image and Mixed-Modal Image Retrieval Datasets", "categories": ["cs.CV", "cs.IR"], "comment": null, "summary": "Despite advances in multimodal learning, challenging benchmarks for\nmixed-modal image retrieval that combines visual and textual information are\nlacking. This paper introduces a novel benchmark to rigorously evaluate image\nretrieval that demands deep cross-modal contextual understanding. We present\ntwo new datasets: the Entity Image Dataset (EI), providing canonical images for\nWikipedia entities, and the Mixed-Modal Image Retrieval Dataset (MMIR), derived\nfrom the WIT dataset. The MMIR benchmark features two challenging query types\nrequiring models to ground textual descriptions in the context of provided\nvisual entities: single entity-image queries (one entity image with descriptive\ntext) and multi-entity-image queries (multiple entity images with relational\ntext). We empirically validate the benchmark's utility as both a training\ncorpus and an evaluation set for mixed-modal retrieval. The quality of both\ndatasets is further affirmed through crowd-sourced human annotations. The\ndatasets are accessible through the GitHub page:\nhttps://github.com/google-research-datasets/wit-retrieval.", "AI": {"tldr": "The paper introduces a new benchmark and datasets (EI and MMIR) for mixed-modal image retrieval, requiring deep cross-modal understanding, and validates their utility.", "motivation": "Addressing the lack of challenging benchmarks for mixed-modal image retrieval combining visual and textual information.", "method": "Introduces two datasets (EI and MMIR) with challenging query types (single and multi-entity-image queries) and validates them empirically.", "result": "The benchmark serves as both training corpus and evaluation set, with dataset quality confirmed via human annotations.", "conclusion": "The datasets and benchmark provide a robust tool for advancing mixed-modal retrieval research."}}
{"id": "2506.02065", "pdf": "https://arxiv.org/pdf/2506.02065", "abs": "https://arxiv.org/abs/2506.02065", "authors": ["Shriraj P. Sawant", "Krishna P. Miyapuram"], "title": "EWGN: Elastic Weight Generation and Context Switching in Deep Learning", "categories": ["cs.LG", "cs.AI", "cs.CV"], "comment": null, "summary": "The ability to learn and retain a wide variety of tasks is a hallmark of\nhuman intelligence that has inspired research in artificial general\nintelligence. Continual learning approaches provide a significant step towards\nachieving this goal. It has been known that task variability and context\nswitching are challenging for learning in neural networks. Catastrophic\nforgetting refers to the poor performance on retention of a previously learned\ntask when a new task is being learned. Switching between different task\ncontexts can be a useful approach to mitigate the same by preventing the\ninterference between the varying task weights of the network. This paper\nintroduces Elastic Weight Generative Networks (EWGN) as an idea for context\nswitching between two different tasks. The proposed EWGN architecture uses an\nadditional network that generates the weights of the primary network\ndynamically while consolidating the weights learned. The weight generation is\ninput-dependent and thus enables context switching. Using standard computer\nvision datasets, namely MNIST and fashion-MNIST, we analyse the retention of\npreviously learned task representations in Fully Connected Networks,\nConvolutional Neural Networks, and EWGN architectures with Stochastic Gradient\nDescent and Elastic Weight Consolidation learning algorithms. Understanding\ndynamic weight generation and context-switching ability can be useful in\nenabling continual learning for improved performance.", "AI": {"tldr": "The paper introduces Elastic Weight Generative Networks (EWGN) to address catastrophic forgetting in continual learning by enabling dynamic weight generation and context switching.", "motivation": "To mitigate catastrophic forgetting in neural networks when learning multiple tasks, inspired by human intelligence's ability to retain diverse tasks.", "method": "Proposes EWGN, an architecture with an additional network that dynamically generates weights for the primary network, enabling input-dependent context switching. Evaluated on MNIST and fashion-MNIST datasets.", "result": "Analyzed retention of learned tasks in Fully Connected Networks, CNNs, and EWGN with SGD and Elastic Weight Consolidation.", "conclusion": "EWGN's dynamic weight generation and context-switching capability can enhance continual learning performance."}}
{"id": "2506.02609", "pdf": "https://arxiv.org/pdf/2506.02609", "abs": "https://arxiv.org/abs/2506.02609", "authors": ["Tianfan Jiang", "Mei Wu", "Wenchao Weng", "Dewen Seng", "Yiqian Lin"], "title": "A Time-Enhanced Data Disentanglement Network for Traffic Flow Forecasting", "categories": ["cs.AI"], "comment": null, "summary": "In recent years, traffic flow prediction has become a highlight in the field\nof intelligent transportation systems. However, due to the temporal variations\nand dynamic spatial correlations of traffic data, traffic prediction remains\nhighly challenging.Traditional spatiotemporal networks, which rely on\nend-to-end training, often struggle to handle the diverse data dependencies of\nmultiple traffic flow patterns. Additionally, traffic flow variations are\nhighly sensitive to temporal information changes. Regrettably, other\nresearchers have not sufficiently recognized the importance of temporal\ninformation.To address these challenges, we propose a novel approach called A\nTime-Enhanced Data Disentanglement Network for Traffic Flow Forecasting\n(TEDDN). This network disentangles the originally complex and intertwined\ntraffic data into stable patterns and trends. By flexibly learning temporal and\nnode information through a dynamic graph enhanced by a temporal feature\nextraction module, TEDDN demonstrates significant efficacy in disentangling and\nextracting complex traffic information. Experimental evaluations and ablation\nstudies on four real-world datasets validate the superiority of our method.", "AI": {"tldr": "A novel Time-Enhanced Data Disentanglement Network (TEDDN) is proposed to improve traffic flow forecasting by disentangling complex traffic data into stable patterns and trends, leveraging dynamic graphs and temporal feature extraction.", "motivation": "Traffic flow prediction is challenging due to temporal variations and dynamic spatial correlations. Existing methods struggle with diverse data dependencies and overlook temporal information importance.", "method": "TEDDN disentangles traffic data into stable patterns and trends using a dynamic graph enhanced by a temporal feature extraction module.", "result": "Experiments on four real-world datasets show TEDDN's superiority in handling complex traffic information.", "conclusion": "TEDDN effectively addresses traffic prediction challenges by emphasizing temporal information and disentangling data, outperforming traditional methods."}}
{"id": "2506.02326", "pdf": "https://arxiv.org/pdf/2506.02326", "abs": "https://arxiv.org/abs/2506.02326", "authors": ["Berk Atil", "Namrata Sureddy", "Rebecca J. Passonneau"], "title": "Something Just Like TRuST : Toxicity Recognition of Span and Target", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Toxicity in online content, including content generated by language models,\nhas become a critical concern due to its potential for negative psychological\nand social impact. This paper introduces TRuST, a comprehensive dataset\ndesigned to improve toxicity detection that merges existing datasets, and has\nlabels for toxicity, target social group, and toxic spans. It includes a\ndiverse range of target groups such as ethnicity, gender, religion, disability,\nand politics, with both human/machine-annotated and human machine-generated\ndata. We benchmark state-of-the-art large language models (LLMs) on toxicity\ndetection, target group identification, and toxic span extraction. We find that\nfine-tuned models consistently outperform zero-shot and few-shot prompting,\nthough performance remains low for certain social groups. Further, reasoning\ncapabilities do not significantly improve performance, indicating that LLMs\nhave weak social reasoning skills.", "AI": {"tldr": "TRuST is a dataset for toxicity detection, benchmarking LLMs on toxicity, target groups, and toxic spans. Fine-tuned models outperform zero-shot/few-shot, but performance gaps exist for some groups.", "motivation": "Addressing toxicity in online content, especially from language models, due to its harmful psychological and social impacts.", "method": "Introduces TRuST dataset, merging existing datasets with labels for toxicity, target groups, and toxic spans. Benchmarks LLMs on detection tasks.", "result": "Fine-tuned models perform better than zero-shot/few-shot, but performance is low for certain groups. Reasoning doesn't improve results.", "conclusion": "LLMs lack strong social reasoning skills, and fine-tuning is key for toxicity detection, though challenges remain for specific groups."}}
{"id": "2506.02894", "pdf": "https://arxiv.org/pdf/2506.02894", "abs": "https://arxiv.org/abs/2506.02894", "authors": ["Verena Blaschke", "Miriam Winkler", "Constantin F\u00f6rster", "Gabriele Wenger-Glemser", "Barbara Plank"], "title": "A Multi-Dialectal Dataset for German Dialect ASR and Dialect-to-Standard Speech Translation", "categories": ["cs.CL", "eess.AS"], "comment": "Accepted to Interspeech 2025", "summary": "Although Germany has a diverse landscape of dialects, they are\nunderrepresented in current automatic speech recognition (ASR) research. To\nenable studies of how robust models are towards dialectal variation, we present\nBetthupferl, an evaluation dataset containing four hours of read speech in\nthree dialect groups spoken in Southeast Germany (Franconian, Bavarian,\nAlemannic), and half an hour of Standard German speech. We provide both\ndialectal and Standard German transcriptions, and analyze the linguistic\ndifferences between them. We benchmark several multilingual state-of-the-art\nASR models on speech translation into Standard German, and find differences\nbetween how much the output resembles the dialectal vs. standardized\ntranscriptions. Qualitative error analyses of the best ASR model reveal that it\nsometimes normalizes grammatical differences, but often stays closer to the\ndialectal constructions.", "AI": {"tldr": "The paper introduces Betthupferl, a dataset for evaluating ASR models on German dialects, highlighting performance differences in dialectal vs. Standard German transcription.", "motivation": "Dialects are underrepresented in ASR research; the study aims to assess model robustness to dialectal variation.", "method": "Created Betthupferl dataset with 4 hours of dialectal and 0.5 hours of Standard German speech, analyzed linguistic differences, and benchmarked multilingual ASR models.", "result": "ASR models showed varied performance, with outputs sometimes resembling dialectal transcriptions and sometimes normalizing to Standard German.", "conclusion": "The study underscores the need for dialect-inclusive ASR research, revealing models' tendencies to retain or normalize dialectal features."}}
{"id": "2505.15380", "pdf": "https://arxiv.org/pdf/2505.15380", "abs": "https://arxiv.org/abs/2505.15380", "authors": ["Zijian Lin", "Yang Zhang", "Yougen Yuan", "Yuming Yan", "Jinjiang Liu", "Zhiyong Wu", "Pengfei Hu", "Qun Yu"], "title": "Accelerating Autoregressive Speech Synthesis Inference With Speech Speculative Decoding", "categories": ["cs.SD", "cs.AI", "eess.AS"], "comment": "Accepted by INTERSPEECH 2025", "summary": "Modern autoregressive speech synthesis models leveraging language models have\ndemonstrated remarkable performance. However, the sequential nature of next\ntoken prediction in these models leads to significant latency, hindering their\ndeployment in scenarios where inference speed is critical. In this work, we\npropose Speech Speculative Decoding (SSD), a novel framework for autoregressive\nspeech synthesis acceleration. Specifically, our method employs a lightweight\ndraft model to generate candidate token sequences, which are subsequently\nverified in parallel by the target model using the proposed SSD framework.\nExperimental results demonstrate that SSD achieves a significant speedup of\n1.4x compared with conventional autoregressive decoding, while maintaining high\nfidelity and naturalness. Subjective evaluations further validate the\neffectiveness of SSD in preserving the perceptual quality of the target model\nwhile accelerating inference.", "AI": {"tldr": "SSD accelerates autoregressive speech synthesis by using a draft model for parallel verification, achieving 1.4x speedup without quality loss.", "motivation": "Address latency in autoregressive speech synthesis due to sequential token prediction, critical for real-time applications.", "method": "Uses a lightweight draft model to generate candidate tokens, verified in parallel by the target model via SSD framework.", "result": "1.4x speedup over conventional decoding while maintaining high fidelity and naturalness.", "conclusion": "SSD effectively balances speed and quality, validated by subjective evaluations."}}
{"id": "2404.03998", "pdf": "https://arxiv.org/pdf/2404.03998", "abs": "https://arxiv.org/abs/2404.03998", "authors": ["Reina Kaneko", "Takumi Ueda", "Hiroshi Higashi", "Yuichi Tanaka"], "title": "PHISWID: Physics-Inspired Underwater Image Dataset Synthesized from RGB-D Images", "categories": ["cs.CV", "eess.IV"], "comment": null, "summary": "This paper introduces the physics-inspired synthesized underwater image\ndataset (PHISWID), a dataset tailored for enhancing underwater image processing\nthrough physics-inspired image synthesis. For underwater image enhancement,\ndata-driven approaches (e.g., deep neural networks) typically demand extensive\ndatasets, yet acquiring paired clean atmospheric images and degraded underwater\nimages poses significant challenges. Existing datasets have limited\ncontributions to image enhancement due to lack of physics models, publicity,\nand ground-truth atmospheric images. PHISWID addresses these issues by offering\na set of paired atmospheric and underwater images. Specifically, underwater\nimages are synthetically degraded by color degradation and marine snow\nartifacts from atmospheric RGB-D images. It is enabled based on a physics-based\nunderwater image observation model. Our synthetic approach generates a large\nquantity of the pairs, enabling effective training of deep neural networks and\nobjective image quality assessment. Through benchmark experiments with some\ndatasets and image enhancement methods, we validate that our dataset can\nimprove the image enhancement performance. Our dataset, which is publicly\navailable, contributes to the development in underwater image processing.", "AI": {"tldr": "PHISWID is a synthetic underwater image dataset designed to improve underwater image processing by providing paired atmospheric and degraded underwater images, addressing limitations of existing datasets.", "motivation": "Existing datasets lack physics models, publicity, and ground-truth atmospheric images, hindering effective underwater image enhancement. PHISWID aims to fill this gap.", "method": "Underwater images are synthetically degraded from atmospheric RGB-D images using a physics-based model, incorporating color degradation and marine snow artifacts.", "result": "Benchmark experiments show PHISWID improves image enhancement performance, enabling effective training of deep neural networks.", "conclusion": "PHISWID, publicly available, advances underwater image processing by providing a scalable and physics-inspired dataset."}}
{"id": "2506.02294", "pdf": "https://arxiv.org/pdf/2506.02294", "abs": "https://arxiv.org/abs/2506.02294", "authors": ["Niclas Popp", "Kevin Alexander Laube", "Matthias Hein", "Lukas Schott"], "title": "Improving Knowledge Distillation Under Unknown Covariate Shift Through Confidence-Guided Data Augmentation", "categories": ["cs.CV"], "comment": null, "summary": "Large foundation models trained on extensive datasets demonstrate strong\nzero-shot capabilities in various domains. To replicate their success when data\nand model size are constrained, knowledge distillation has become an\nestablished tool for transferring knowledge from foundation models to small\nstudent networks. However, the effectiveness of distillation is critically\nlimited by the available training data. This work addresses the common\npractical issue of covariate shift in knowledge distillation, where spurious\nfeatures appear during training but not at test time. We ask the question: when\nthese spurious features are unknown, yet a robust teacher is available, is it\npossible for a student to also become robust to them? We address this problem\nby introducing a novel diffusion-based data augmentation strategy that\ngenerates images by maximizing the disagreement between the teacher and the\nstudent, effectively creating challenging samples that the student struggles\nwith. Experiments demonstrate that our approach significantly improves worst\ngroup and mean group accuracy on CelebA and SpuCo Birds as well as the spurious\nmAUC on spurious ImageNet under covariate shift, outperforming state-of-the-art\ndiffusion-based data augmentation baselines", "AI": {"tldr": "A novel diffusion-based data augmentation method improves knowledge distillation under covariate shift by generating challenging samples, enhancing student model robustness.", "motivation": "To address the limitation of knowledge distillation effectiveness due to covariate shift and spurious features, leveraging a robust teacher to improve student robustness.", "method": "Introduces a diffusion-based data augmentation strategy that generates images maximizing teacher-student disagreement, creating challenging samples for the student.", "result": "Significant improvements in worst-group and mean-group accuracy on CelebA and SpuCo Birds, and spurious mAUC on spurious ImageNet, outperforming existing baselines.", "conclusion": "The proposed method effectively enhances student model robustness to unknown spurious features under covariate shift, demonstrating superior performance."}}
{"id": "2506.02070", "pdf": "https://arxiv.org/pdf/2506.02070", "abs": "https://arxiv.org/abs/2506.02070", "authors": ["Peter Holderrieth", "Ezra Erives"], "title": "An Introduction to Flow Matching and Diffusion Models", "categories": ["cs.LG"], "comment": null, "summary": "Diffusion and flow-based models have become the state of the art for\ngenerative AI across a wide range of data modalities, including images, videos,\nshapes, molecules, music, and more! These notes are originally from\nhttps://diffusion.csail.mit.edu/, as taught at MIT over the 2025 IAP (winter)\nterm, and are intended to accompany other course content, including lectures\nand labs. Overall, they function as a self-contained introduction to both flow\nmatching and diffusion models, starting with ordinary and stochastic\ndifferential equations, and culminating in flow matching, score matching,\nclassifier-free guidance, and the inner workings of modern, state-of-the-art\nmodels for image and video. These notes, and the accompanying course, are ideal\nfor students and practitioners alike who want to develop a principled\nunderstanding of the theory and practice of generative AI.", "AI": {"tldr": "The abstract introduces diffusion and flow-based models as leading generative AI methods, covering theory and applications across various data types.", "motivation": "To provide a comprehensive introduction to diffusion and flow-based models, bridging theory and practice for students and practitioners.", "method": "The notes start with differential equations and progress to advanced topics like flow matching, score matching, and classifier-free guidance.", "result": "A self-contained resource for understanding modern generative AI models, particularly for images and videos.", "conclusion": "The notes and course are ideal for anyone seeking a principled grasp of generative AI's theory and applications."}}
{"id": "2506.02648", "pdf": "https://arxiv.org/pdf/2506.02648", "abs": "https://arxiv.org/abs/2506.02648", "authors": ["Yue Yang", "MingKang Chen", "Qihua Liu", "Mengkang Hu", "Qiguang Chen", "Gengrui Zhang", "Shuyue Hu", "Guangtao Zhai", "Yu Qiao", "Yu Wang", "Wenqi Shao", "Ping Luo"], "title": "Truly Assessing Fluid Intelligence of Large Language Models through Dynamic Reasoning Evaluation", "categories": ["cs.AI"], "comment": null, "summary": "Recent advances in large language models (LLMs) have demonstrated impressive\nreasoning capacities that mirror human-like thinking. However, whether LLMs\npossess genuine fluid intelligence (i.e., the ability to reason abstractly and\ngeneralize rules in novel situations) remains an open question. Existing\nreasoning benchmarks either focus on domain-specific knowledge (crystallized\nintelligence) or lack interpretability. To address these limitations, we\npropose DRE-Bench, a dynamic reasoning evaluation benchmark grounded in a\nhierarchical cognitive framework. DRE-Bench consists of 36 abstract reasoning\ntasks organized across four cognitive levels, with each task featuring multiple\ndynamic variants that test the same underlying latent rule. This design enables\nfine-grained, interpretable, and reliable assessments of fluid intelligence. We\nevaluate a range of state-of-the-art LLMs, including both general LLMs (GPT-4o,\nClaude 3.7) and reasoning LLMs (o1, DeepSeek-R1, QwQ, Skywork-OR1).\nExperimental results reveal that although most LLMs achieve competent and\nrobust performance in low-level cognition, they struggle with high-level\ncognition and exhibit limited generalization as task complexity grows. Our\nfindings highlight the gap between current LLMs and true human-like fluid\nintelligence and offer a new path for systematically tracking reasoning\nprogress in LLMs.", "AI": {"tldr": "DRE-Bench is a new benchmark for evaluating fluid intelligence in LLMs, revealing gaps in high-level cognition and generalization despite strong low-level performance.", "motivation": "To address the lack of interpretable and reliable benchmarks for assessing fluid intelligence in LLMs.", "method": "Proposes DRE-Bench, a dynamic reasoning benchmark with 36 tasks across four cognitive levels, testing latent rules with dynamic variants.", "result": "LLMs perform well in low-level cognition but struggle with high-level tasks and generalization as complexity increases.", "conclusion": "Highlights the gap between LLMs and human-like fluid intelligence, offering a systematic way to track reasoning progress."}}
{"id": "2506.02338", "pdf": "https://arxiv.org/pdf/2506.02338", "abs": "https://arxiv.org/abs/2506.02338", "authors": ["Hyungjoo Chae", "Dongjin Kang", "Jihyuk Kim", "Beong-woo Kwak", "Sunghyun Park", "Haeju Park", "Jinyoung Yeo", "Moontae Lee", "Kyungjae Lee"], "title": "One Missing Piece for Open-Source Reasoning Models: A Dataset to Mitigate Cold-Starting Short CoT LLMs in RL", "categories": ["cs.CL"], "comment": "ACL 2025 Industry", "summary": "With the release of R1, a publicly available large reasoning model (LRM),\nresearchers commonly train new LRMs by training language models on R1's long\nchain-of-thought (CoT) inferences. While prior works show that LRMs'\ncapabilities can be reproduced through direct distillation, the continued\nreliance on the existing models (e.g., R1) remains a critical limitation in\nadvancing the field. As a first step toward independent LRM development, this\npaper explores the possibility of constructing a long CoT dataset with LLMs\nthat are not trained for inference-time scaling. To this end, we present the\nLong CoT Collection, a dataset of 100K CoT rationales annotated using existing\nshort CoT LLMs. We develop a pipeline that induces o1's novel reasoning\nstrategies into short CoT LLMs, enabling them to think longer and introducing\ncontrollability over the thought budget to better manage the overthinking\nproblem. Our extensive analyses validate that our dataset achieves quality\ncomparable to--or slightly below--R1. Furthermore, our experiments demonstrate\nthat training on our dataset not only strengthens general reasoning skills, but\nalso provides a strong foundation for reinforcement learning--models\ninitialized on our data achieve 2-3x larger gains with RLVR.", "AI": {"tldr": "The paper introduces the Long CoT Collection, a dataset of 100K CoT rationales, to reduce reliance on existing models like R1 for training LRMs. The dataset is annotated using short CoT LLMs and achieves quality close to R1, improving reasoning skills and RL performance.", "motivation": "To advance independent LRM development by reducing dependence on existing models like R1, which limits progress in the field.", "method": "Constructs the Long CoT Collection dataset using short CoT LLMs, introduces a pipeline to enhance reasoning strategies, and manages overthinking with controllability over thought budgets.", "result": "The dataset matches or slightly underperforms R1 in quality. Training on it improves general reasoning and boosts RL gains (2-3x with RLVR).", "conclusion": "The Long CoT Collection provides a viable alternative to R1 for training LRMs, enhancing reasoning and RL performance while reducing reliance on existing models."}}
{"id": "2506.02979", "pdf": "https://arxiv.org/pdf/2506.02979", "abs": "https://arxiv.org/abs/2506.02979", "authors": ["Atsumoto Ohashi", "Shinya Iizuka", "Jingjing Jiang", "Ryuichiro Higashinaka"], "title": "Towards a Japanese Full-duplex Spoken Dialogue System", "categories": ["cs.CL", "eess.AS"], "comment": "Accepted to Interspeech 2025", "summary": "Full-duplex spoken dialogue systems, which can model simultaneous\nbidirectional features of human conversations such as speech overlaps and\nbackchannels, have attracted significant attention recently. However, the study\nof full-duplex spoken dialogue systems for the Japanese language has been\nlimited, and the research on their development in Japanese remains scarce. In\nthis paper, we present the first publicly available full-duplex spoken dialogue\nmodel in Japanese, which is built upon Moshi, a full-duplex dialogue model in\nEnglish. Our model is trained through a two-stage process: pre-training on a\nlarge-scale spoken dialogue data in Japanese, followed by fine-tuning on\nhigh-quality stereo spoken dialogue data. We further enhance the model's\nperformance by incorporating synthetic dialogue data generated by a\nmulti-stream text-to-speech system. Evaluation experiments demonstrate that the\ntrained model outperforms Japanese baseline models in both naturalness and\nmeaningfulness.", "AI": {"tldr": "The paper introduces the first publicly available full-duplex spoken dialogue model for Japanese, built on Moshi (an English model), trained via pre-training and fine-tuning, and enhanced with synthetic data, outperforming baselines in naturalness and meaningfulness.", "motivation": "Limited research exists on full-duplex spoken dialogue systems for Japanese, despite their potential to model bidirectional conversation features like overlaps and backchannels.", "method": "A two-stage training process: pre-training on large-scale Japanese spoken dialogue data, followed by fine-tuning on high-quality stereo data, augmented with synthetic data from a multi-stream TTS system.", "result": "The model surpasses Japanese baseline models in both naturalness and meaningfulness.", "conclusion": "The study successfully develops and validates a high-performing full-duplex spoken dialogue model for Japanese, addressing a gap in research."}}
{"id": "2505.24200", "pdf": "https://arxiv.org/pdf/2505.24200", "abs": "https://arxiv.org/abs/2505.24200", "authors": ["Qingzheng Wang", "Jiancheng Sun", "Yifan Peng", "Shinji Watanabe"], "title": "Improving Multilingual Speech Models on ML-SUPERB 2.0: Fine-tuning with Data Augmentation and LID-Aware CTC", "categories": ["cs.SD", "cs.CL", "eess.AS"], "comment": null, "summary": "Multilingual speech processing with self-supervised or supervised pre-trained\nSpeech Foundation Models (SFM) has achieved strong performance on tasks like\nLanguage Identification (LID) and Automatic Speech Recognition (ASR). However,\nthese models struggle with limited resources during fine-tuning. This paper\nenhances multilingual LID and ASR on ML-SUPERB 2.0 by exploring multiple\nstrategies for adapting SFMs, including frozen upstream training, partial\nfine-tuning, and low-rank adaptation. Furthermore, we employ data augmentation\nto mitigate performance gaps in few-shot settings and introduce LID\nConnectionist Temporal Classification (CTC) loss for regularization. Our\napproach achieves a 14% relative improvement in LID accuracy and a 30% relative\nreduction in ASR CER over the baseline on ML-SUPERB 2.0, securing second place\nin the Interspeech 2025 ML-SUPERB 2.0 Challenge.", "AI": {"tldr": "The paper improves multilingual LID and ASR performance by adapting SFMs with strategies like frozen upstream training, partial fine-tuning, and low-rank adaptation, along with data augmentation and LID CTC loss. Results show a 14% LID accuracy boost and 30% ASR CER reduction.", "motivation": "Existing SFMs struggle with limited resources during fine-tuning, prompting the need for better adaptation strategies.", "method": "The study explores frozen upstream training, partial fine-tuning, low-rank adaptation, data augmentation, and LID CTC loss for regularization.", "result": "Achieves 14% relative improvement in LID accuracy and 30% relative reduction in ASR CER, securing second place in the ML-SUPERB 2.0 Challenge.", "conclusion": "The proposed strategies effectively enhance multilingual LID and ASR performance, demonstrating their potential for resource-limited settings."}}
{"id": "2405.14250", "pdf": "https://arxiv.org/pdf/2405.14250", "abs": "https://arxiv.org/abs/2405.14250", "authors": ["Emile Pierret", "Bruno Galerne"], "title": "Diffusion models for Gaussian distributions: Exact solutions and Wasserstein errors", "categories": ["cs.LG", "eess.IV", "math.PR"], "comment": null, "summary": "Diffusion or score-based models recently showed high performance in image\ngeneration. They rely on a forward and a backward stochastic differential\nequations (SDE). The sampling of a data distribution is achieved by numerically\nsolving the backward SDE or its associated flow ODE. Studying the convergence\nof these models necessitates to control four different types of error: the\ninitialization error, the truncation error, the discretization error and the\nscore approximation. In this paper, we theoretically study the behavior of\ndiffusion models and their numerical implementation when the data distribution\nis Gaussian. Our first contribution is to derive the analytical solutions of\nthe backward SDE and the probability flow ODE and to prove that these solutions\nand their discretizations are all Gaussian processes. Our second contribution\nis to compute the exact Wasserstein errors between the target and the\nnumerically sampled distributions for any numerical scheme. This allows us to\nmonitor convergence directly in the data space, while experimental works limit\ntheir empirical analysis to Inception features. An implementation of our code\nis available online.", "AI": {"tldr": "The paper theoretically analyzes diffusion models for Gaussian data distributions, deriving analytical solutions for backward SDEs and flow ODEs, and computes exact Wasserstein errors for numerical schemes.", "motivation": "To understand the convergence behavior of diffusion models and their numerical implementations, particularly for Gaussian data distributions, by controlling initialization, truncation, discretization, and score approximation errors.", "method": "Derives analytical solutions for backward SDEs and flow ODEs, proving they are Gaussian processes, and computes exact Wasserstein errors for numerical schemes.", "result": "All solutions and discretizations are Gaussian processes, and exact Wasserstein errors are computed, enabling direct monitoring of convergence in data space.", "conclusion": "The study provides theoretical insights and practical tools for analyzing diffusion models, improving convergence monitoring beyond empirical metrics like Inception features."}}
{"id": "2506.02295", "pdf": "https://arxiv.org/pdf/2506.02295", "abs": "https://arxiv.org/abs/2506.02295", "authors": ["Ahmed Wasfy", "Omer Nacar", "Abdelakreem Elkhateb", "Mahmoud Reda", "Omar Elshehy", "Adel Ammar", "Wadii Boulila"], "title": "QARI-OCR: High-Fidelity Arabic Text Recognition through Multimodal Large Language Model Adaptation", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "The inherent complexities of Arabic script; its cursive nature, diacritical\nmarks (tashkeel), and varied typography, pose persistent challenges for Optical\nCharacter Recognition (OCR). We present Qari-OCR, a series of vision-language\nmodels derived from Qwen2-VL-2B-Instruct, progressively optimized for Arabic\nthrough iterative fine-tuning on specialized synthetic datasets. Our leading\nmodel, QARI v0.2, establishes a new open-source state-of-the-art with a Word\nError Rate (WER) of 0.160, Character Error Rate (CER) of 0.061, and BLEU score\nof 0.737 on diacritically-rich texts. Qari-OCR demonstrates superior handling\nof tashkeel, diverse fonts, and document layouts, alongside impressive\nperformance on low-resolution images. Further explorations (QARI v0.3) showcase\nstrong potential for structural document understanding and handwritten text.\nThis work delivers a marked improvement in Arabic OCR accuracy and efficiency,\nwith all models and datasets released to foster further research.", "AI": {"tldr": "Qari-OCR, a vision-language model optimized for Arabic, achieves state-of-the-art OCR performance with low error rates and high BLEU scores, excelling in handling diacritics, fonts, and low-resolution images.", "motivation": "The cursive nature, diacritical marks, and varied typography of Arabic script complicate OCR tasks, necessitating specialized solutions.", "method": "Qari-OCR is derived from Qwen2-VL-2B-Instruct and fine-tuned on synthetic datasets, with iterative optimizations leading to models like QARI v0.2 and v0.3.", "result": "QARI v0.2 achieves a WER of 0.160, CER of 0.061, and BLEU score of 0.737, excelling in tashkeel handling, font diversity, and low-resolution images.", "conclusion": "Qari-OCR significantly improves Arabic OCR accuracy and efficiency, with models and datasets released to advance research."}}
{"id": "2506.02077", "pdf": "https://arxiv.org/pdf/2506.02077", "abs": "https://arxiv.org/abs/2506.02077", "authors": ["Yoonjun Cho", "Soeun Kim", "Dongjae Jeon", "Kyelim Lee", "Beomsoo Lee", "Albert No"], "title": "Assigning Distinct Roles to Quantized and Low-Rank Matrices Toward Optimal Weight Decomposition", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": "Accepted to Findings of ACL 2025", "summary": "Decomposing weight matrices into quantization and low-rank components\n($\\mathbf{W} \\approx \\mathbf{Q} + \\mathbf{L}\\mathbf{R}$) is a widely used\ntechnique for compressing large language models (LLMs). Existing joint\noptimization methods iteratively alternate between quantization and low-rank\napproximation. However, these methods tend to prioritize one component at the\nexpense of the other, resulting in suboptimal decompositions that fail to\nleverage each component's unique strengths. In this work, we introduce\nOutlier-Driven Low-Rank Initialization (ODLRI), which assigns low-rank\ncomponents the specific role of capturing activation-sensitive weights. This\nstructured decomposition mitigates outliers' negative impact on quantization,\nenabling more effective balance between quantization and low-rank\napproximation. Experiments on Llama2 (7B, 13B, 70B), Llama3-8B, and Mistral-7B\ndemonstrate that incorporating ODLRI into the joint optimization framework\nconsistently reduces activation-aware error, minimizes quantization scale, and\nimproves perplexity and zero-shot accuracy in low-bit settings.", "AI": {"tldr": "ODLRI improves LLM compression by balancing quantization and low-rank approximation, reducing errors and enhancing performance.", "motivation": "Existing methods prioritize one component over the other, leading to suboptimal decompositions.", "method": "Introduces Outlier-Driven Low-Rank Initialization (ODLRI) to capture activation-sensitive weights, balancing quantization and low-rank approximation.", "result": "Reduces activation-aware error, minimizes quantization scale, and improves perplexity and zero-shot accuracy in low-bit settings.", "conclusion": "ODLRI enhances joint optimization for LLM compression, leveraging both components effectively."}}
{"id": "2506.02649", "pdf": "https://arxiv.org/pdf/2506.02649", "abs": "https://arxiv.org/abs/2506.02649", "authors": ["Yousef Emami", "Hao Zhou", "Miguel Gutierrez Gaitan", "Kai Li", "Luis Almeida", "Zhu Han"], "title": "From Prompts to Protection: Large Language Model-Enabled In-Context Learning for Smart Public Safety UAV", "categories": ["cs.AI", "53-01", "C.2"], "comment": "8 pages, 4 figures", "summary": "A public safety Unmanned Aerial Vehicle (UAV) enhances situational awareness\nin emergency response. Its agility and ability to optimize mobility and\nestablish Line-of-Sight (LoS) communication make it increasingly vital for\nmanaging emergencies such as disaster response, search and rescue, and wildfire\nmonitoring. While Deep Reinforcement Learning (DRL) has been applied to\noptimize UAV navigation and control, its high training complexity, low sample\nefficiency, and simulation-to-reality gap limit its practicality in public\nsafety. Recent advances in Large Language Models (LLMs) offer a compelling\nalternative. With strong reasoning and generalization capabilities, LLMs can\nadapt to new tasks through In-Context Learning (ICL), which enables task\nadaptation via natural language prompts and example-based guidance, without\nretraining. Deploying LLMs at the network edge, rather than in the cloud,\nfurther reduces latency and preserves data privacy, thereby making them\nsuitable for real-time, mission-critical public safety UAVs. This paper\nproposes the integration of LLM-enabled ICL with public safety UAV to address\nthe key functions, such as path planning and velocity control, in the context\nof emergency response. We present a case study on data collection scheduling\nwhere the LLM-enabled ICL framework can significantly reduce packet loss\ncompared to conventional approaches, while also mitigating potential\njailbreaking vulnerabilities. Finally, we discuss LLM optimizers and specify\nfuture research directions. The ICL framework enables adaptive, context-aware\ndecision-making for public safety UAV, thus offering a lightweight and\nefficient solution for enhancing UAV autonomy and responsiveness in\nemergencies.", "AI": {"tldr": "The paper proposes using Large Language Models (LLMs) with In-Context Learning (ICL) to enhance public safety UAVs, addressing limitations of Deep Reinforcement Learning (DRL) like high training complexity and simulation-to-reality gaps. The LLM-enabled ICL framework improves tasks like path planning and reduces packet loss, offering a lightweight, adaptive solution for emergency response.", "motivation": "Public safety UAVs are crucial for emergency response but face limitations with DRL due to high training complexity and inefficiency. LLMs, with their reasoning and generalization capabilities, offer a promising alternative.", "method": "The paper integrates LLM-enabled ICL with UAVs for tasks like path planning and velocity control. A case study on data collection scheduling demonstrates reduced packet loss and improved adaptability.", "result": "The LLM-enabled ICL framework outperforms conventional methods, reducing packet loss and mitigating vulnerabilities, while enabling adaptive decision-making for UAVs.", "conclusion": "LLM-enabled ICL provides a lightweight, efficient solution for enhancing UAV autonomy in emergencies, with potential for future research in LLM optimizers and broader applications."}}
{"id": "2506.02347", "pdf": "https://arxiv.org/pdf/2506.02347", "abs": "https://arxiv.org/abs/2506.02347", "authors": ["Jiaming Li", "Yukun Chen", "Ziqiang Liu", "Minghuan Tan", "Lei Zhang", "Yunshui Li", "Run Luo", "Longze Chen", "Jing Luo", "Ahmadreza Argha", "Hamid Alinejad-Rokny", "Wei Zhou", "Min Yang"], "title": "STORYTELLER: An Enhanced Plot-Planning Framework for Coherent and Cohesive Story Generation", "categories": ["cs.CL"], "comment": null, "summary": "Stories are central to human culture, serving to share ideas, preserve\ntraditions, and foster connections. Automatic story generation, a key\nadvancement in artificial intelligence (AI), offers new possibilities for\ncreating personalized content, exploring creative ideas, and enhancing\ninteractive experiences. However, existing methods struggle to maintain\nnarrative coherence and logical consistency. This disconnect compromises the\noverall storytelling experience, underscoring the need for substantial\nimprovements. Inspired by human cognitive processes, we introduce Storyteller,\na novel approach that systemically improves the coherence and consistency of\nautomatically generated stories. Storyteller introduces a plot node structure\nbased on linguistically grounded subject verb object (SVO) triplets, which\ncapture essential story events and ensure a consistent logical flow. Unlike\nprevious methods, Storyteller integrates two dynamic modules, the STORYLINE and\nnarrative entity knowledge graph (NEKG),that continuously interact with the\nstory generation process. This integration produces structurally sound,\ncohesive and immersive narratives. Extensive experiments demonstrate that\nStoryteller significantly outperforms existing approaches, achieving an 84.33%\naverage win rate through human preference evaluation. At the same time, it is\nalso far ahead in other aspects including creativity, coherence, engagement,\nand relevance.", "AI": {"tldr": "Storyteller, a novel AI-based story generation method, improves narrative coherence and logical consistency using SVO triplets and dynamic modules (STORYLINE and NEKG), outperforming existing methods.", "motivation": "Existing AI story generation methods lack coherence and consistency, limiting their effectiveness. The paper aims to address this gap by mimicking human cognitive processes.", "method": "Storyteller uses SVO triplets for plot structure and integrates dynamic modules (STORYLINE and NEKG) to enhance coherence and consistency during generation.", "result": "Storyteller achieves an 84.33% average win rate in human evaluations, excelling in coherence, creativity, engagement, and relevance.", "conclusion": "Storyteller significantly advances AI story generation by ensuring logical flow and immersive narratives, outperforming prior methods."}}
{"id": "2410.12266", "pdf": "https://arxiv.org/pdf/2410.12266", "abs": "https://arxiv.org/abs/2410.12266", "authors": ["Huadai Liu", "Jialei Wang", "Rongjie Huang", "Yang Liu", "Heng Lu", "Zhou Zhao", "Wei Xue"], "title": "FlashAudio: Rectified Flows for Fast and High-Fidelity Text-to-Audio Generation", "categories": ["eess.AS", "cs.SD"], "comment": "ACL 2025 Main", "summary": "Recent advancements in latent diffusion models (LDMs) have markedly enhanced\ntext-to-audio generation, yet their iterative sampling processes impose\nsubstantial computational demands, limiting practical deployment. While recent\nmethods utilizing consistency-based distillation aim to achieve few-step or\nsingle-step inference, their one-step performance is constrained by curved\ntrajectories, preventing them from surpassing traditional diffusion models. In\nthis work, we introduce FlashAudio with rectified flows to learn straight flow\nfor fast simulation. To alleviate the inefficient timesteps allocation and\nsuboptimal distribution of noise, FlashAudio optimizes the time distribution of\nrectified flow with Bifocal Samplers and proposes immiscible flow to minimize\nthe total distance of data-noise pairs in a batch vias assignment. Furthermore,\nto address the amplified accumulation error caused by the classifier-free\nguidance (CFG), we propose Anchored Optimization, which refines the guidance\nscale by anchoring it to a reference trajectory. Experimental results on\ntext-to-audio generation demonstrate that FlashAudio's one-step generation\nperformance surpasses the diffusion-based models with hundreds of sampling\nsteps on audio quality and enables a sampling speed of 400x faster than\nreal-time on a single NVIDIA 4090Ti GPU. Code will be available at\nhttps://github.com/liuhuadai/FlashAudio.", "AI": {"tldr": "FlashAudio introduces rectified flows for fast text-to-audio generation, optimizing time distribution and noise allocation, achieving 400x faster sampling than real-time.", "motivation": "Address computational inefficiency in latent diffusion models for text-to-audio generation.", "method": "Uses rectified flows, Bifocal Samplers, immiscible flow, and Anchored Optimization to improve efficiency and accuracy.", "result": "One-step generation outperforms traditional diffusion models, with 400x faster sampling.", "conclusion": "FlashAudio offers a practical, high-speed solution for text-to-audio generation."}}
{"id": "2503.07352", "pdf": "https://arxiv.org/pdf/2503.07352", "abs": "https://arxiv.org/abs/2503.07352", "authors": ["Eetu Tunturi", "David Diaz-Guerra", "Archontis Politis", "Tuomas Virtanen"], "title": "Score-informed Music Source Separation: Improving Synthetic-to-real Generalization in Classical Music", "categories": ["eess.AS", "cs.LG", "cs.SD"], "comment": "5 pages, 2 figures, accepted to EUSIPCO 2025", "summary": "Music source separation is the task of separating a mixture of instruments\ninto constituent tracks. Music source separation models are typically trained\nusing only audio data, although additional information can be used to improve\nthe model's separation capability. In this paper, we propose two ways of using\nmusical scores to aid music source separation: a score-informed model where the\nscore is concatenated with the magnitude spectrogram of the audio mixture as\nthe input of the model, and a model where we use only the score to calculate\nthe separation mask. We train our models on synthetic data in the SynthSOD\ndataset and evaluate our methods on the URMP and Aalto anechoic orchestra\ndatasets, comprised of real recordings. The score-informed model improves\nseparation results compared to a baseline approach, but struggles to generalize\nfrom synthetic to real data, whereas the score-only model shows a clear\nimprovement in synthetic-to-real generalization.", "AI": {"tldr": "The paper explores using musical scores to improve music source separation, proposing two models: one combining scores with audio spectrograms and another using only scores. The score-only model shows better generalization from synthetic to real data.", "motivation": "To enhance music source separation by leveraging additional information like musical scores, which are typically unused in traditional audio-only models.", "method": "Two models are proposed: (1) a score-informed model combining scores with audio spectrograms, and (2) a score-only model using scores to calculate separation masks. Training uses synthetic data (SynthSOD), with evaluation on real recordings (URMP, Aalto datasets).", "result": "The score-informed model improves separation but struggles with synthetic-to-real generalization. The score-only model shows clear improvement in generalization.", "conclusion": "Musical scores can aid music source separation, with the score-only model offering better generalization to real-world data."}}
{"id": "2506.00433", "pdf": "https://arxiv.org/pdf/2506.00433", "abs": "https://arxiv.org/abs/2506.00433", "authors": ["Luigi Sigillo", "Shengfeng He", "Danilo Comminiello"], "title": "Latent Wavelet Diffusion: Enabling 4K Image Synthesis for Free", "categories": ["cs.CV", "cs.LG", "eess.IV"], "comment": null, "summary": "High-resolution image synthesis remains a core challenge in generative\nmodeling, particularly in balancing computational efficiency with the\npreservation of fine-grained visual detail. We present Latent Wavelet Diffusion\n(LWD), a lightweight framework that enables any latent diffusion model to scale\nto ultra-high-resolution image generation (2K to 4K) for free. LWD introduces\nthree key components: (1) a scale-consistent variational autoencoder objective\nthat enhances the spectral fidelity of latent representations; (2) wavelet\nenergy maps that identify and localize detail-rich spatial regions within the\nlatent space; and (3) a time-dependent masking strategy that focuses denoising\nsupervision on high-frequency components during training. LWD requires no\narchitectural modifications and incurs no additional computational overhead.\nDespite its simplicity, it consistently improves perceptual quality and reduces\nFID in ultra-high-resolution image synthesis, outperforming strong baseline\nmodels. These results highlight the effectiveness of frequency-aware,\nsignal-driven supervision as a principled and efficient approach for\nhigh-resolution generative modeling.", "AI": {"tldr": "LWD is a lightweight framework for ultra-high-resolution image synthesis (2K-4K) using latent diffusion models, improving quality without extra computational cost.", "motivation": "Balancing computational efficiency and fine-grained detail preservation in high-resolution image synthesis.", "method": "Introduces scale-consistent VAE, wavelet energy maps, and time-dependent masking for focused denoising.", "result": "Improves perceptual quality and reduces FID, outperforming baselines.", "conclusion": "Frequency-aware supervision is effective for high-resolution generative modeling."}}
{"id": "2506.02327", "pdf": "https://arxiv.org/pdf/2506.02327", "abs": "https://arxiv.org/abs/2506.02327", "authors": ["Yijun Yang", "Zhao-Yang Wang", "Qiuping Liu", "Shuwen Sun", "Kang Wang", "Rama Chellappa", "Zongwei Zhou", "Alan Yuille", "Lei Zhu", "Yu-Dong Zhang", "Jieneng Chen"], "title": "Medical World Model: Generative Simulation of Tumor Evolution for Treatment Planning", "categories": ["cs.CV"], "comment": null, "summary": "Providing effective treatment and making informed clinical decisions are\nessential goals of modern medicine and clinical care. We are interested in\nsimulating disease dynamics for clinical decision-making, leveraging recent\nadvances in large generative models. To this end, we introduce the Medical\nWorld Model (MeWM), the first world model in medicine that visually predicts\nfuture disease states based on clinical decisions. MeWM comprises (i)\nvision-language models to serve as policy models, and (ii) tumor generative\nmodels as dynamics models. The policy model generates action plans, such as\nclinical treatments, while the dynamics model simulates tumor progression or\nregression under given treatment conditions. Building on this, we propose the\ninverse dynamics model that applies survival analysis to the simulated\npost-treatment tumor, enabling the evaluation of treatment efficacy and the\nselection of the optimal clinical action plan. As a result, the proposed MeWM\nsimulates disease dynamics by synthesizing post-treatment tumors, with\nstate-of-the-art specificity in Turing tests evaluated by radiologists.\nSimultaneously, its inverse dynamics model outperforms medical-specialized GPTs\nin optimizing individualized treatment protocols across all metrics. Notably,\nMeWM improves clinical decision-making for interventional physicians, boosting\nF1-score in selecting the optimal TACE protocol by 13%, paving the way for\nfuture integration of medical world models as the second readers.", "AI": {"tldr": "MeWM is a medical world model that predicts future disease states visually, combining vision-language and tumor generative models to simulate and optimize clinical treatments.", "motivation": "To enhance clinical decision-making by simulating disease dynamics and evaluating treatment efficacy using generative models.", "method": "Uses vision-language models for policy (treatment plans) and tumor generative models for dynamics (tumor progression/regression). Introduces an inverse dynamics model for survival analysis and treatment optimization.", "result": "Achieves state-of-the-art specificity in Turing tests and outperforms medical GPTs in treatment optimization, improving F1-score for optimal TACE protocol selection by 13%.", "conclusion": "MeWM advances clinical decision-making, demonstrating potential for integration as a second reader in medicine."}}
{"id": "2506.02079", "pdf": "https://arxiv.org/pdf/2506.02079", "abs": "https://arxiv.org/abs/2506.02079", "authors": ["Xuefeng Jiang", "Tian Wen", "Zhiqin Yang", "Lvhua Wu", "Yufeng Chen", "Sheng Sun", "Yuwei Wang", "Min Liu"], "title": "Robust Federated Learning against Noisy Clients via Masked Optimization", "categories": ["cs.LG", "cs.AI", "cs.CV", "stat.ML"], "comment": "Under review", "summary": "In recent years, federated learning (FL) has made significant advance in\nprivacy-sensitive applications. However, it can be hard to ensure that FL\nparticipants provide well-annotated data for training. The corresponding\nannotations from different clients often contain complex label noise at varying\nlevels. This label noise issue has a substantial impact on the performance of\nthe trained models, and clients with greater noise levels can be largely\nattributed for this degradation. To this end, it is necessary to develop an\neffective optimization strategy to alleviate the adverse effects of these noisy\nclients.In this study, we present a two-stage optimization framework,\nMaskedOptim, to address this intricate label noise problem. The first stage is\ndesigned to facilitate the detection of noisy clients with higher label noise\nrates. The second stage focuses on rectifying the labels of the noisy clients'\ndata through an end-to-end label correction mechanism, aiming to mitigate the\nnegative impacts caused by misinformation within datasets. This is achieved by\nlearning the potential ground-truth labels of the noisy clients' datasets via\nbackpropagation. To further enhance the training robustness, we apply the\ngeometric median based model aggregation instead of the commonly-used vanilla\naveraged model aggregation. We implement sixteen related methods and conduct\nevaluations on three image datasets and one text dataset with diverse label\nnoise patterns for a comprehensive comparison. Extensive experimental results\nindicate that our proposed framework shows its robustness in different\nscenarios. Additionally, our label correction framework effectively enhances\nthe data quality of the detected noisy clients' local datasets. % Our codes\nwill be open-sourced to facilitate related research communities. Our codes are\navailable via https://github.com/Sprinter1999/MaskedOptim .", "AI": {"tldr": "A two-stage optimization framework, MaskedOptim, addresses label noise in federated learning by detecting noisy clients and correcting their labels, improving model robustness.", "motivation": "Federated learning faces challenges with noisy client annotations, degrading model performance. Addressing this noise is crucial for reliable training.", "method": "MaskedOptim detects noisy clients in stage one and corrects their labels in stage two using backpropagation and geometric median aggregation.", "result": "The framework shows robustness across datasets and improves data quality for noisy clients.", "conclusion": "MaskedOptim effectively mitigates label noise in federated learning, enhancing model performance and data quality."}}
{"id": "2506.02668", "pdf": "https://arxiv.org/pdf/2506.02668", "abs": "https://arxiv.org/abs/2506.02668", "authors": ["Frederico Metelo", "Alexandre Oliveira", "Stevo Rackovi\u0107", "Pedro \u00c1kos Costa", "Cl\u00e1udia Soares"], "title": "FAuNO: Semi-Asynchronous Federated Reinforcement Learning Framework for Task Offloading in Edge Systems", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "Edge computing addresses the growing data demands of connected-device\nnetworks by placing computational resources closer to end users through\ndecentralized infrastructures. This decentralization challenges traditional,\nfully centralized orchestration, which suffers from latency and resource\nbottlenecks. We present \\textbf{FAuNO} -- \\emph{Federated Asynchronous Network\nOrchestrator} -- a buffered, asynchronous \\emph{federated\nreinforcement-learning} (FRL) framework for decentralized task offloading in\nedge systems. FAuNO adopts an actor-critic architecture in which local actors\nlearn node-specific dynamics and peer interactions, while a federated critic\naggregates experience across agents to encourage efficient cooperation and\nimprove overall system performance. Experiments in the \\emph{PeersimGym}\nenvironment show that FAuNO consistently matches or exceeds heuristic and\nfederated multi-agent RL baselines in reducing task loss and latency,\nunderscoring its adaptability to dynamic edge-computing scenarios.", "AI": {"tldr": "FAuNO is a federated reinforcement-learning framework for decentralized task offloading in edge systems, outperforming baselines in reducing latency and task loss.", "motivation": "Addressing latency and resource bottlenecks in traditional centralized orchestration for edge computing.", "method": "Uses a buffered, asynchronous federated reinforcement-learning (FRL) framework with actor-critic architecture for decentralized task offloading.", "result": "FAuNO matches or exceeds heuristic and federated multi-agent RL baselines in reducing task loss and latency.", "conclusion": "FAuNO is adaptable and efficient for dynamic edge-computing scenarios."}}
{"id": "2506.02350", "pdf": "https://arxiv.org/pdf/2506.02350", "abs": "https://arxiv.org/abs/2506.02350", "authors": ["Herun Wan", "Jiaying Wu", "Minnan Luo", "Zhi Zeng", "Zhixiong Su"], "title": "Truth over Tricks: Measuring and Mitigating Shortcut Learning in Misinformation Detection", "categories": ["cs.CL"], "comment": null, "summary": "Misinformation detection models often rely on superficial cues (i.e.,\n\\emph{shortcuts}) that correlate with misinformation in training data but fail\nto generalize to the diverse and evolving nature of real-world misinformation.\nThis issue is exacerbated by large language models (LLMs), which can easily\ngenerate convincing misinformation through simple prompts. We introduce\nTruthOverTricks, a unified evaluation paradigm for measuring shortcut learning\nin misinformation detection. TruthOverTricks categorizes shortcut behaviors\ninto intrinsic shortcut induction and extrinsic shortcut injection, and\nevaluates seven representative detectors across 14 popular benchmarks, along\nwith two new factual misinformation datasets, NQ-Misinfo and Streaming-Misinfo.\nEmpirical results reveal that existing detectors suffer severe performance\ndegradation when exposed to both naturally occurring and adversarially crafted\nshortcuts. To address this, we propose SMF, an LLM-augmented data augmentation\nframework that mitigates shortcut reliance through paraphrasing, factual\nsummarization, and sentiment normalization. SMF consistently enhances\nrobustness across 16 benchmarks, encouraging models to rely on deeper semantic\nunderstanding rather than shortcut cues. To promote the development of\nmisinformation detectors, we have published the resources publicly at\nhttps://github.com/whr000001/TruthOverTricks.", "AI": {"tldr": "The paper introduces TruthOverTricks, a framework to evaluate shortcut learning in misinformation detection, and proposes SMF, an LLM-augmented data augmentation method to improve robustness.", "motivation": "Misinformation detectors often rely on shortcuts that fail to generalize, especially with LLMs generating convincing misinformation.", "method": "TruthOverTricks evaluates shortcut behaviors (intrinsic/extrinsic) across benchmarks. SMF uses paraphrasing, factual summarization, and sentiment normalization for robustness.", "result": "Existing detectors degrade with shortcuts. SMF improves robustness across 16 benchmarks.", "conclusion": "SMF enhances semantic understanding over shortcuts, with resources publicly available."}}
{"id": "2504.14906", "pdf": "https://arxiv.org/pdf/2504.14906", "abs": "https://arxiv.org/abs/2504.14906", "authors": ["Huadai Liu", "Tianyi Luo", "Kaicheng Luo", "Qikai Jiang", "Peiwen Sun", "Jialei Wang", "Rongjie Huang", "Qian Chen", "Wen Wang", "Xiangtai Li", "Shiliang Zhang", "Zhijie Yan", "Zhou Zhao", "Wei Xue"], "title": "OmniAudio: Generating Spatial Audio from 360-Degree Video", "categories": ["eess.AS", "cs.CV", "cs.SD"], "comment": "ICML 2025", "summary": "Traditional video-to-audio generation techniques primarily focus on\nperspective video and non-spatial audio, often missing the spatial cues\nnecessary for accurately representing sound sources in 3D environments. To\naddress this limitation, we introduce a novel task, 360V2SA, to generate\nspatial audio from 360-degree videos, specifically producing First-order\nAmbisonics (FOA) audio - a standard format for representing 3D spatial audio\nthat captures sound directionality and enables realistic 3D audio reproduction.\nWe first create Sphere360, a novel dataset tailored for this task that is\ncurated from real-world data. We also design an efficient semi-automated\npipeline for collecting and cleaning paired video-audio data. To generate\nspatial audio from 360-degree video, we propose a novel framework OmniAudio,\nwhich leverages self-supervised pre-training using both spatial audio data (in\nFOA format) and large-scale non-spatial data. Furthermore, OmniAudio features a\ndual-branch framework that utilizes both panoramic and perspective video inputs\nto capture comprehensive local and global information from 360-degree videos.\nExperimental results demonstrate that OmniAudio achieves state-of-the-art\nperformance across both objective and subjective metrics on Sphere360. Code and\ndatasets are available at https://github.com/liuhuadai/OmniAudio. The project\nwebsite is available at https://OmniAudio-360V2SA.github.io.", "AI": {"tldr": "The paper introduces 360V2SA, a task for generating spatial audio from 360-degree videos, and proposes OmniAudio, a framework leveraging self-supervised pre-training and dual-branch inputs for superior performance.", "motivation": "Traditional methods lack spatial audio cues for 3D environments, limiting realistic sound representation.", "method": "OmniAudio uses self-supervised pre-training with FOA audio and dual-branch inputs (panoramic and perspective videos) for comprehensive data capture.", "result": "OmniAudio achieves state-of-the-art performance on the Sphere360 dataset, validated by objective and subjective metrics.", "conclusion": "The work advances spatial audio generation from 360-degree videos, offering a novel dataset and framework with open-source availability."}}
{"id": "2505.20552", "pdf": "https://arxiv.org/pdf/2505.20552", "abs": "https://arxiv.org/abs/2505.20552", "authors": ["Ernesto Accolti"], "title": "Effect of laboratory conditions on the perception of virtual stages for music", "categories": ["eess.AS", "cs.SD"], "comment": null, "summary": "This manuscript presents initial findings critical for supporting augmented\nacoustics experiments in custom-made hearing booths, addressing a key challenge\nin ensuring perceptual validity and experimental rigor in these highly\nsensitive setups. This validation ensures our proposed methodology is sound,\nguarantees the reliability of future results, and lays the foundational\ngroundwork for subsequent perceptual studies and the development of robust\nguidelines for laboratory design in virtual acoustics research. A preliminary\nstudy on the effect of the acoustical conditions of three different rooms on\nthe perception of virtual stages for music is presented: an anechoic room, a\ncustom-made hearing booth with insufficient sound absorption, and another\ncustom-made hearing booth with achievable sound absorption. The goal of this\nstudy is to assess the impact of these different conditions on the perception\nof virtual stages for music. The results show that the anechoic room and the\nhearing booth with achievable sound absorption have a difference between the\ntotal sound and the virtual sound below the just-noticeable difference, which\nmeans that the virtual sound is not perceived louder than it should. In\ncontrast, the hearing booth with insufficient sound absorption has a difference\nabove the just-noticeable difference, which means that the virtual sound is\nperceived louder than it should. This study provides a preliminary validation\nof the proposed methodology for assessing the acoustical conditions of\ncustom-made hearing booths in stage acoustics experiments. Future work will\ninclude a more comprehensive analysis of the results, including the effect of\ndifferent sound sources.\n  Supplementary audio files illustrating key simulation results are available\nat https://zenodo.org/records/15579861", "AI": {"tldr": "The paper validates a methodology for assessing acoustical conditions in custom hearing booths, showing that sound absorption impacts virtual stage perception in music.", "motivation": "To ensure perceptual validity and experimental rigor in augmented acoustics experiments by validating the methodology for assessing acoustical conditions.", "method": "A preliminary study comparing the perception of virtual stages in three rooms: an anechoic room, a hearing booth with insufficient sound absorption, and one with achievable sound absorption.", "result": "The anechoic room and the booth with achievable absorption met perceptual validity, while the booth with insufficient absorption did not.", "conclusion": "The study preliminarily validates the methodology, laying groundwork for future research and guidelines in virtual acoustics lab design."}}
{"id": "2506.02334", "pdf": "https://arxiv.org/pdf/2506.02334", "abs": "https://arxiv.org/abs/2506.02334", "authors": ["Duo Liu", "Zhiquan Tan", "Linglan Zhao", "Zhongqiang Zhang", "Xiangzhong Fang", "Weiran Huang"], "title": "Generalized Category Discovery via Reciprocal Learning and Class-Wise Distribution Regularization", "categories": ["cs.CV"], "comment": "ICML2025 Poster", "summary": "Generalized Category Discovery (GCD) aims to identify unlabeled samples by\nleveraging the base knowledge from labeled ones, where the unlabeled set\nconsists of both base and novel classes. Since clustering methods are\ntime-consuming at inference, parametric-based approaches have become more\npopular. However, recent parametric-based methods suffer from inferior base\ndiscrimination due to unreliable self-supervision. To address this issue, we\npropose a Reciprocal Learning Framework (RLF) that introduces an auxiliary\nbranch devoted to base classification. During training, the main branch filters\nthe pseudo-base samples to the auxiliary branch. In response, the auxiliary\nbranch provides more reliable soft labels for the main branch, leading to a\nvirtuous cycle. Furthermore, we introduce Class-wise Distribution\nRegularization (CDR) to mitigate the learning bias towards base classes. CDR\nessentially increases the prediction confidence of the unlabeled data and\nboosts the novel class performance. Combined with both components, our proposed\nmethod, RLCD, achieves superior performance in all classes with negligible\nextra computation. Comprehensive experiments across seven GCD datasets validate\nits superiority. Our codes are available at https://github.com/APORduo/RLCD.", "AI": {"tldr": "RLCD introduces a Reciprocal Learning Framework (RLF) and Class-wise Distribution Regularization (CDR) to improve Generalized Category Discovery (GCD) by enhancing base discrimination and novel class performance.", "motivation": "Parametric-based GCD methods suffer from unreliable self-supervision and inferior base discrimination, prompting the need for a more robust solution.", "method": "RLF uses an auxiliary branch for base classification, creating a virtuous cycle with the main branch. CDR mitigates base-class bias by boosting unlabeled data confidence.", "result": "RLCD outperforms existing methods on seven GCD datasets with minimal extra computation.", "conclusion": "RLCD effectively addresses GCD challenges, achieving superior performance across all classes."}}
{"id": "2506.02081", "pdf": "https://arxiv.org/pdf/2506.02081", "abs": "https://arxiv.org/abs/2506.02081", "authors": ["Chihiro Maru", "Shoetsu Sato"], "title": "RATFM: Retrieval-augmented Time Series Foundation Model for Anomaly Detection", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Inspired by the success of large language models (LLMs) in natural language\nprocessing, recent research has explored the building of time series foundation\nmodels and applied them to tasks such as forecasting, classification, and\nanomaly detection. However, their performances vary between different domains\nand tasks. In LLM-based approaches, test-time adaptation using example-based\nprompting has become common, owing to the high cost of retraining. In the\ncontext of anomaly detection, which is the focus of this study, providing\nnormal examples from the target domain can also be effective. However, time\nseries foundation models do not naturally acquire the ability to interpret or\nutilize examples or instructions, because the nature of time series data used\nduring training does not encourage such capabilities. To address this\nlimitation, we propose a retrieval augmented time series foundation model\n(RATFM), which enables pretrained time series foundation models to incorporate\nexamples of test-time adaptation. We show that RATFM achieves a performance\ncomparable to that of in-domain fine-tuning while avoiding domain-dependent\nfine-tuning. Experiments on the UCR Anomaly Archive, a multi-domain dataset\nincluding nine domains, confirms the effectiveness of the proposed approach.", "AI": {"tldr": "The paper proposes a retrieval-augmented time series foundation model (RATFM) to improve anomaly detection by incorporating test-time adaptation examples, avoiding costly retraining.", "motivation": "Existing time series foundation models lack the ability to interpret or utilize examples for adaptation, limiting their performance in anomaly detection.", "method": "Introduces RATFM, which enhances pretrained models by enabling them to incorporate test-time examples without domain-specific fine-tuning.", "result": "RATFM achieves performance comparable to in-domain fine-tuning on the UCR Anomaly Archive dataset.", "conclusion": "The proposed RATFM effectively addresses the limitation of time series models in utilizing examples, offering a practical solution for anomaly detection."}}
{"id": "2506.02696", "pdf": "https://arxiv.org/pdf/2506.02696", "abs": "https://arxiv.org/abs/2506.02696", "authors": ["Jinyuan Luo", "Zhen Fang", "Yixuan Li", "Seongheon Park", "Ling Chen"], "title": "Shaking to Reveal: Perturbation-Based Detection of LLM Hallucinations", "categories": ["cs.AI"], "comment": null, "summary": "Hallucination remains a key obstacle to the reliable deployment of large\nlanguage models (LLMs) in real-world question answering tasks. A widely adopted\nstrategy to detect hallucination, known as self-assessment, relies on the\nmodel's own output confidence to estimate the factual accuracy of its answers.\nHowever, this strategy assumes that the model's output distribution closely\nreflects the true data distribution, which may not always hold in practice. As\nbias accumulates through the model's layers, the final output can diverge from\nthe underlying reasoning process, making output-level confidence an unreliable\nsignal for hallucination detection. In this work, we propose Sample-Specific\nPrompting (SSP), a new framework that improves self-assessment by analyzing\nperturbation sensitivity at intermediate representations. These\nrepresentations, being less influenced by model bias, offer a more faithful\nview of the model's latent reasoning process. Specifically, SSP dynamically\ngenerates noise prompts for each input and employs a lightweight encoder to\namplify the changes in representations caused by the perturbation. A\ncontrastive distance metric is then used to quantify these differences and\nseparate truthful from hallucinated responses. By leveraging the dynamic\nbehavior of intermediate representations under perturbation, SSP enables more\nreliable self-assessment. Extensive experiments demonstrate that SSP\nsignificantly outperforms prior methods across a range of hallucination\ndetection benchmarks.", "AI": {"tldr": "SSP improves LLM hallucination detection by analyzing intermediate representations' sensitivity to perturbations, outperforming prior methods.", "motivation": "Hallucination in LLMs hinders reliable QA deployment; self-assessment based on output confidence is unreliable due to model bias.", "method": "SSP uses dynamic noise prompts and a lightweight encoder to analyze perturbation sensitivity in intermediate representations, employing a contrastive distance metric.", "result": "SSP significantly outperforms prior hallucination detection methods in benchmarks.", "conclusion": "SSP offers a more reliable self-assessment framework by leveraging intermediate representations under perturbation."}}
{"id": "2506.02351", "pdf": "https://arxiv.org/pdf/2506.02351", "abs": "https://arxiv.org/abs/2506.02351", "authors": ["Jeonghun Kang", "Soonmok Kwon", "Joonseok Lee", "Byung-Hak Kim"], "title": "DIAMOND: An LLM-Driven Agent for Context-Aware Baseball Highlight Summarization", "categories": ["cs.CL", "cs.AI", "cs.CV"], "comment": "To appear in the First REALM (Research on Agent Language Models)\n  workshop at ACL 2025", "summary": "Traditional approaches -- such as Win Probability Added (WPA)-based ranking\nor computer vision-driven event detection -- can identify scoring plays but\noften miss strategic depth, momentum shifts, and storyline progression. Manual\ncuration remains the gold standard but is resource-intensive and not scalable.\nWe introduce DIAMOND, an LLM-driven agent for context-aware baseball highlight\nsummarization that integrates structured sports analytics with natural language\nreasoning. DIAMOND leverages sabermetric features -- Win Expectancy, WPA, and\nLeverage Index -- to quantify play importance, while an LLM module enhances\nselection based on contextual narrative value. This hybrid approach ensures\nboth quantitative rigor and qualitative richness, surpassing the limitations of\npurely statistical or vision-based systems. Evaluated on five diverse Korean\nBaseball Organization League games, DIAMOND improves F1-score from 42.9%\n(WPA-only) to 84.8%, outperforming both commercial and statistical baselines.\nThough limited in scale, our results highlight the potential of modular,\ninterpretable agent-based frameworks for event-level summarization in sports\nand beyond.", "AI": {"tldr": "DIAMOND is an LLM-driven agent for baseball highlight summarization, combining sports analytics and natural language reasoning to outperform traditional methods.", "motivation": "Traditional methods like WPA or computer vision miss strategic depth and are not scalable, while manual curation is resource-intensive.", "method": "DIAMOND integrates sabermetric features (Win Expectancy, WPA, Leverage Index) with an LLM module for context-aware highlight selection.", "result": "Evaluated on Korean Baseball Organization League games, DIAMOND improved F1-score from 42.9% (WPA-only) to 84.8%, surpassing baselines.", "conclusion": "DIAMOND demonstrates the potential of modular, interpretable agent-based frameworks for sports summarization and beyond."}}
{"id": "2505.13338", "pdf": "https://arxiv.org/pdf/2505.13338", "abs": "https://arxiv.org/abs/2505.13338", "authors": ["Qiongqiong Wang", "Hardik B. Sailor", "Tianchi Liu", "Ai Ti Aw"], "title": "Contextual Paralinguistic Data Creation for Multi-Modal Speech-LLM: Data Condensation and Spoken QA Generation", "categories": ["cs.CL", "cs.AI", "eess.AS"], "comment": "Accepted at Interspeech 2025. [v2]: The dataset has been released,\n  and the link is now updated", "summary": "Current speech-LLMs exhibit limited capability in contextual reasoning\nalongside paralinguistic understanding, primarily due to the lack of\nQuestion-Answer (QA) datasets that cover both aspects. We propose a novel\nframework for dataset generation from in-the-wild speech data, that integrates\ncontextual reasoning with paralinguistic information. It consists of a pseudo\nparalinguistic label-based data condensation of in-the-wild speech and\nLLM-based Contextual Paralinguistic QA (CPQA) generation. The effectiveness is\nvalidated by a strong correlation in evaluations of the Qwen2-Audio-7B-Instruct\nmodel on a dataset created by our framework and human-generated CPQA dataset.\nThe results also reveal the speech-LLM's limitations in handling empathetic\nreasoning tasks, highlighting the need for such datasets and more robust\nmodels. The proposed framework is first of its kind and has potential in\ntraining more robust speech-LLMs with paralinguistic reasoning capabilities.", "AI": {"tldr": "A novel framework generates QA datasets for speech-LLMs by integrating contextual reasoning and paralinguistic understanding, validated by strong correlation with human-generated data.", "motivation": "Current speech-LLMs lack contextual reasoning and paralinguistic understanding due to insufficient QA datasets covering both aspects.", "method": "Proposes a framework combining pseudo paralinguistic label-based data condensation and LLM-based CPQA generation from in-the-wild speech.", "result": "Validated effectiveness with Qwen2-Audio-7B-Instruct, showing strong correlation but revealing limitations in empathetic reasoning.", "conclusion": "The framework is pioneering for training robust speech-LLMs with paralinguistic reasoning, highlighting the need for better datasets and models."}}
{"id": "2506.01496", "pdf": "https://arxiv.org/pdf/2506.01496", "abs": "https://arxiv.org/abs/2506.01496", "authors": ["Guitao Wang", "Jinming Zhao", "Hao Yang", "Guilin Qi", "Tongtong Wu", "Gholamreza Haffari"], "title": "Continual Speech Learning with Fused Speech Features", "categories": ["cs.CL", "cs.SD", "eess.AS"], "comment": "Accepted to Interspeech 2025", "summary": "Rapid growth in speech data demands adaptive models, as traditional static\nmethods fail to keep pace with dynamic and diverse speech information. We\nintroduce continuous speech learning, a new set-up targeting at bridging the\nadaptation gap in current speech models. We use the encoder-decoder Whisper\nmodel to standardize speech tasks into a generative format. We integrate a\nlearnable gated-fusion layer on the top of the encoder to dynamically select\ntask-specific features for downstream tasks. Our approach improves accuracy\nsignificantly over traditional methods in six speech processing tasks,\ndemonstrating gains in adapting to new speech tasks without full retraining.", "AI": {"tldr": "The paper introduces continuous speech learning to address the adaptation gap in speech models, using Whisper and a gated-fusion layer for dynamic feature selection, achieving significant accuracy improvements.", "motivation": "Traditional static methods struggle with dynamic and diverse speech data, necessitating adaptive models.", "method": "Uses the Whisper encoder-decoder model with a learnable gated-fusion layer for dynamic feature selection in downstream tasks.", "result": "Significant accuracy improvements over traditional methods in six speech processing tasks, with better adaptation to new tasks.", "conclusion": "Continuous speech learning with dynamic feature selection effectively bridges the adaptation gap in speech models."}}
{"id": "2506.02354", "pdf": "https://arxiv.org/pdf/2506.02354", "abs": "https://arxiv.org/abs/2506.02354", "authors": ["Junjie Li", "Nan Zhang", "Xiaoyang Qu", "Kai Lu", "Guokuan Li", "Jiguang Wan", "Jianzong Wang"], "title": "RATE-Nav: Region-Aware Termination Enhancement for Zero-shot Object Navigation with Vision-Language Models", "categories": ["cs.CV"], "comment": "Accepted by the 63rd Annual Meeting of the Association for\n  Computational Linguistics (ACL 2025)", "summary": "Object Navigation (ObjectNav) is a fundamental task in embodied artificial\nintelligence. Although significant progress has been made in semantic map\nconstruction and target direction prediction in current research, redundant\nexploration and exploration failures remain inevitable. A critical but\nunderexplored direction is the timely termination of exploration to overcome\nthese challenges. We observe a diminishing marginal effect between exploration\nsteps and exploration rates and analyze the cost-benefit relationship of\nexploration. Inspired by this, we propose RATE-Nav, a Region-Aware\nTermination-Enhanced method. It includes a geometric predictive region\nsegmentation algorithm and region-Based exploration estimation algorithm for\nexploration rate calculation. By leveraging the visual question answering\ncapabilities of visual language models (VLMs) and exploration rates enables\nefficient termination.RATE-Nav achieves a success rate of 67.8% and an SPL of\n31.3% on the HM3D dataset. And on the more challenging MP3D dataset, RATE-Nav\nshows approximately 10% improvement over previous zero-shot methods.", "AI": {"tldr": "RATE-Nav improves ObjectNav by addressing redundant exploration and failures through a region-aware termination method, leveraging VLMs for efficient termination.", "motivation": "Redundant exploration and failures in ObjectNav remain unresolved; timely termination is underexplored.", "method": "Proposes RATE-Nav with geometric predictive region segmentation and region-based exploration estimation, using VLMs.", "result": "Achieves 67.8% success rate and 31.3% SPL on HM3D; ~10% improvement on MP3D over zero-shot methods.", "conclusion": "RATE-Nav effectively addresses exploration inefficiencies in ObjectNav, demonstrating significant performance gains."}}
{"id": "2506.02084", "pdf": "https://arxiv.org/pdf/2506.02084", "abs": "https://arxiv.org/abs/2506.02084", "authors": ["Nikolaos Gkorgkolis", "Nikolaos Kougioulis", "MingXue Wang", "Bora Caglayan", "Andrea Tonon", "Dario Simionato", "Ioannis Tsamardinos"], "title": "Temporal Causal-based Simulation for Realistic Time-series Generation", "categories": ["cs.LG", "stat.ML"], "comment": "22 pages, 3 figures", "summary": "Causal Discovery plays a pivotal role in revealing relationships among\nobserved variables, particularly in the temporal setup. While the majority of\nCD methods rely on synthetic data for evaluation, and recently for training,\nthese fall short in accurately mirroring real-world scenarios; an effect even\nmore evident in temporal data. Generation techniques depending on simplified\nassumptions on causal structure, effects and time, limit the quality and\ndiversity of the simulated data. In this work, we introduce Temporal\nCausal-based Simulation (TCS), a robust framework for generating realistic\ntime-series data and their associated temporal causal graphs. The approach is\nstructured in three phases: estimating the true lagged causal structure of the\ndata, approximating the functional dependencies between variables and learning\nthe noise distribution of the corresponding causal model, each part of which\ncan be explicitly tailored based on data assumptions and characteristics.\nThrough an extensive evaluation process, we highlight that single detection\nmethods for generated data discrimination prove inadequate, accentuating it as\na multifaceted challenge. For this, we detail a Min-max optimization phase that\ndraws on AutoML techniques. Our contributions include a flexible,\nmodel-agnostic pipeline for generating realistic temporal causal data, a\nthorough evaluation setup which enhances the validity of the generated datasets\nand insights into the challenges posed by realistic data generation. Through\nexperiments involving not only real but also semi-synthetic and purely\nsynthetic datasets, we demonstrate that while sampling realistic causal data\nremains a complex task, our method enriches the domain of generating sensible\ncausal-based temporal data.", "AI": {"tldr": "The paper introduces TCS, a framework for generating realistic temporal causal data, addressing limitations of existing methods and proposing a Min-max optimization for evaluation.", "motivation": "Existing causal discovery methods rely on synthetic data that poorly mirrors real-world scenarios, especially in temporal setups.", "method": "TCS involves three phases: estimating lagged causal structure, approximating functional dependencies, and learning noise distribution, with a Min-max optimization for evaluation.", "result": "TCS generates realistic temporal causal data, validated through experiments on real, semi-synthetic, and synthetic datasets.", "conclusion": "TCS advances realistic temporal causal data generation, though challenges remain in sampling such data."}}
{"id": "2506.02713", "pdf": "https://arxiv.org/pdf/2506.02713", "abs": "https://arxiv.org/abs/2506.02713", "authors": ["Xiaochong Lan", "Jie Feng", "Yizhou Sun", "Chen Gao", "Jiahuan Lei", "Xinlei Shi", "Hengliang Luo", "Yong Li"], "title": "Open-Set Living Need Prediction with Large Language Models", "categories": ["cs.AI"], "comment": "ACL 2025 Findings", "summary": "Living needs are the needs people generate in their daily lives for survival\nand well-being. On life service platforms like Meituan, user purchases are\ndriven by living needs, making accurate living need predictions crucial for\npersonalized service recommendations. Traditional approaches treat this\nprediction as a closed-set classification problem, severely limiting their\nability to capture the diversity and complexity of living needs. In this work,\nwe redefine living need prediction as an open-set classification problem and\npropose PIGEON, a novel system leveraging large language models (LLMs) for\nunrestricted need prediction. PIGEON first employs a behavior-aware record\nretriever to help LLMs understand user preferences, then incorporates Maslow's\nhierarchy of needs to align predictions with human living needs. For evaluation\nand application, we design a recall module based on a fine-tuned text embedding\nmodel that links flexible need descriptions to appropriate life services.\nExtensive experiments on real-world datasets demonstrate that PIGEON\nsignificantly outperforms closed-set approaches on need-based life service\nrecall by an average of 19.37%. Human evaluation validates the reasonableness\nand specificity of our predictions. Additionally, we employ instruction tuning\nto enable smaller LLMs to achieve competitive performance, supporting practical\ndeployment.", "AI": {"tldr": "PIGEON redefines living need prediction as an open-set problem using LLMs, outperforming closed-set methods by 19.37%.", "motivation": "Traditional closed-set classification fails to capture the diversity of living needs, prompting a shift to open-set prediction.", "method": "PIGEON uses behavior-aware retrieval and Maslow's hierarchy with LLMs, plus a recall module for linking needs to services.", "result": "PIGEON outperforms closed-set methods by 19.37% and shows reasonable, specific predictions in human evaluation.", "conclusion": "PIGEON's open-set approach and LLM integration effectively predict diverse living needs, with practical deployment via instruction tuning."}}
{"id": "2506.02372", "pdf": "https://arxiv.org/pdf/2506.02372", "abs": "https://arxiv.org/abs/2506.02372", "authors": ["Hisami Suzuki", "Satoru Katsumata", "Takashi Kodama", "Tetsuro Takahashi", "Kouta Nakayama", "Satoshi Sekine"], "title": "AnswerCarefully: A Dataset for Improving the Safety of Japanese LLM Output", "categories": ["cs.CL"], "comment": null, "summary": "In this paper we present AnswerCarefully, a dataset for promoting the safety\nand appropriateness of Japanese LLM outputs. The dataset consists of 1,800\npairs of questions and reference answers, where the questions require special\nattention in answering. It covers a wide range of risk categories established\nin prior English-language datasets, but the data samples are original in that\nthey are manually created to reflect the socio-cultural context of LLM usage in\nJapan. We show that using this dataset for instruction to fine-tune a Japanese\nLLM led to improved output safety without compromising the utility of general\nresponses. We also report the results of a safety evaluation of 12 Japanese\nLLMs using this dataset as a benchmark. Finally, we describe the latest update\non the dataset which provides English translations and annotations of the\nquestions, aimed at facilitating the derivation of similar datasets in\ndifferent languages and regions.", "AI": {"tldr": "AnswerCarefully is a dataset for improving the safety of Japanese LLM outputs, featuring 1,800 question-answer pairs. It enhances model safety without losing utility and serves as a benchmark for evaluating 12 Japanese LLMs. The dataset now includes English translations for broader use.", "motivation": "To address the need for culturally appropriate and safe outputs from Japanese LLMs, reflecting Japan's socio-cultural context.", "method": "Creation of a manually curated dataset (1,800 question-answer pairs) covering risk categories, used for fine-tuning and evaluating Japanese LLMs.", "result": "Improved safety in LLM outputs without compromising general utility; benchmarked 12 Japanese LLMs.", "conclusion": "AnswerCarefully effectively enhances LLM safety in Japan and can inspire similar datasets in other languages/regions."}}
{"id": "2506.01789", "pdf": "https://arxiv.org/pdf/2506.01789", "abs": "https://arxiv.org/abs/2506.01789", "authors": ["Genta Indra Winata", "David Anugraha", "Emmy Liu", "Alham Fikri Aji", "Shou-Yi Hung", "Aditya Parashar", "Patrick Amadeus Irawan", "Ruochen Zhang", "Zheng-Xin Yong", "Jan Christian Blaise Cruz", "Niklas Muennighoff", "Seungone Kim", "Hanyang Zhao", "Sudipta Kar", "Kezia Erina Suryoraharjo", "M. Farid Adilazuarda", "En-Shiun Annie Lee", "Ayu Purwarianti", "Derry Tanti Wijaya", "Monojit Choudhury"], "title": "Datasheets Aren't Enough: DataRubrics for Automated Quality Metrics and Accountability", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.CV", "eess.AS"], "comment": "Preprint", "summary": "High-quality datasets are fundamental to training and evaluating machine\nlearning models, yet their creation-especially with accurate human\nannotations-remains a significant challenge. Many dataset paper submissions\nlack originality, diversity, or rigorous quality control, and these\nshortcomings are often overlooked during peer review. Submissions also\nfrequently omit essential details about dataset construction and properties.\nWhile existing tools such as datasheets aim to promote transparency, they are\nlargely descriptive and do not provide standardized, measurable methods for\nevaluating data quality. Similarly, metadata requirements at conferences\npromote accountability but are inconsistently enforced. To address these\nlimitations, this position paper advocates for the integration of systematic,\nrubric-based evaluation metrics into the dataset review process-particularly as\nsubmission volumes continue to grow. We also explore scalable, cost-effective\nmethods for synthetic data generation, including dedicated tools and\nLLM-as-a-judge approaches, to support more efficient evaluation. As a call to\naction, we introduce DataRubrics, a structured framework for assessing the\nquality of both human- and model-generated datasets. Leveraging recent advances\nin LLM-based evaluation, DataRubrics offers a reproducible, scalable, and\nactionable solution for dataset quality assessment, enabling both authors and\nreviewers to uphold higher standards in data-centric research. We also release\ncode to support reproducibility of LLM-based evaluations at\nhttps://github.com/datarubrics/datarubrics.", "AI": {"tldr": "The paper proposes DataRubrics, a framework for systematic evaluation of dataset quality, addressing gaps in current practices like lack of originality, diversity, and transparency in dataset submissions.", "motivation": "Current dataset submissions often lack quality control, originality, and transparency, with existing tools being descriptive rather than evaluative. The paper aims to improve dataset review processes.", "method": "Introduces DataRubrics, a rubric-based framework for dataset quality assessment, leveraging LLM-based evaluation and synthetic data generation methods.", "result": "DataRubrics provides a reproducible, scalable solution for dataset quality evaluation, supported by released code for LLM-based assessments.", "conclusion": "The paper calls for higher standards in dataset submissions and reviews, advocating for systematic evaluation tools like DataRubrics to enhance data-centric research."}}
{"id": "2506.02356", "pdf": "https://arxiv.org/pdf/2506.02356", "abs": "https://arxiv.org/abs/2506.02356", "authors": ["Woojeong Jin", "Seongchan Kim", "Seungryong Kim"], "title": "InterRVOS: Interaction-aware Referring Video Object Segmentation", "categories": ["cs.CV"], "comment": null, "summary": "Referring video object segmentation aims to segment the object in a video\ncorresponding to a given natural language expression. While prior works have\nexplored various referring scenarios, including motion-centric or\nmulti-instance expressions, most approaches still focus on localizing a single\ntarget object in isolation. However, in comprehensive video understanding, an\nobject's role is often defined by its interactions with other entities, which\nare largely overlooked in existing datasets and models. In this work, we\nintroduce Interaction-aware referring video object sgementation (InterRVOS), a\nnew task that requires segmenting both actor and target entities involved in an\ninteraction. Each interactoin is described through a pair of complementary\nexpressions from different semantic perspectives, enabling fine-grained\nmodeling of inter-object relationships. To tackle this task, we propose\nInterRVOS-8K, the large-scale and automatically constructed dataset containing\ndiverse interaction-aware expressions with corresponding masks, including\nchallenging cases such as motion-only multi-instance expressions. We also\npresent a baseline architecture, ReVIOSa, designed to handle actor-target\nsegmentation from a single expression, achieving strong performance in both\nstandard and interaction-focused settings. Furthermore, we introduce an\nactor-target-aware evalaution setting that enables a more targeted assessment\nof interaction understanding. Experimental results demonstrate that our\napproach outperforms prior methods in modeling complex object interactions for\nreferring video object segmentation task, establishing a strong foundation for\nfuture research in interaction-centric video understanding. Our project page is\navailable at\n\\href{https://cvlab-kaist.github.io/InterRVOS}{https://cvlab-kaist.github.io/InterRVOS}.", "AI": {"tldr": "The paper introduces Interaction-aware referring video object segmentation (InterRVOS), a new task focusing on segmenting interacting objects in videos using complementary expressions. It presents a dataset (InterRVOS-8K) and a baseline model (ReVIOSa) that outperforms prior methods.", "motivation": "Existing referring video object segmentation methods focus on single objects, ignoring interactions between entities, which are crucial for comprehensive video understanding.", "method": "The paper proposes InterRVOS-8K, a large-scale dataset with interaction-aware expressions, and ReVIOSa, a baseline model for actor-target segmentation from a single expression.", "result": "ReVIOSa achieves strong performance in both standard and interaction-focused settings, outperforming prior methods.", "conclusion": "The work establishes a foundation for interaction-centric video understanding and demonstrates the effectiveness of the proposed approach."}}
{"id": "2506.02089", "pdf": "https://arxiv.org/pdf/2506.02089", "abs": "https://arxiv.org/abs/2506.02089", "authors": ["Zeng Wang", "Minghao Shao", "Rupesh Karn", "Jitendra Bhandari", "Likhitha Mankali", "Ramesh Karri", "Ozgur Sinanoglu", "Muhammad Shafique", "Johann Knechtel"], "title": "SALAD: Systematic Assessment of Machine Unlearing on LLM-Aided Hardware Design", "categories": ["cs.LG", "cs.AI", "cs.CR"], "comment": null, "summary": "Large Language Models (LLMs) offer transformative capabilities for hardware\ndesign automation, particularly in Verilog code generation. However, they also\npose significant data security challenges, including Verilog evaluation data\ncontamination, intellectual property (IP) design leakage, and the risk of\nmalicious Verilog generation. We introduce SALAD, a comprehensive assessment\nthat leverages machine unlearning to mitigate these threats. Our approach\nenables the selective removal of contaminated benchmarks, sensitive IP and\ndesign artifacts, or malicious code patterns from pre-trained LLMs, all without\nrequiring full retraining. Through detailed case studies, we demonstrate how\nmachine unlearning techniques effectively reduce data security risks in\nLLM-aided hardware design.", "AI": {"tldr": "SALAD uses machine unlearning to address security risks in LLM-aided hardware design, like data contamination and IP leakage, without full retraining.", "motivation": "LLMs in hardware design automation pose data security risks (e.g., IP leakage, malicious code).", "method": "Introduces SALAD, leveraging machine unlearning to selectively remove contaminated or sensitive data from LLMs.", "result": "Case studies show SALAD effectively reduces security risks in LLM-aided hardware design.", "conclusion": "Machine unlearning is a viable solution for mitigating security threats in LLM-driven hardware automation."}}
{"id": "2506.02720", "pdf": "https://arxiv.org/pdf/2506.02720", "abs": "https://arxiv.org/abs/2506.02720", "authors": ["Xiaochong Lan", "Jie Feng", "Jiahuan Lei", "Xinlei Shi", "Yong Li"], "title": "Benchmarking and Advancing Large Language Models for Local Life Services", "categories": ["cs.AI", "cs.CL"], "comment": "KDD 2025", "summary": "Large language models (LLMs) have exhibited remarkable capabilities and\nachieved significant breakthroughs across various domains, leading to their\nwidespread adoption in recent years. Building on this progress, we investigate\ntheir potential in the realm of local life services. In this study, we\nestablish a comprehensive benchmark and systematically evaluate the performance\nof diverse LLMs across a wide range of tasks relevant to local life services.\nTo further enhance their effectiveness, we explore two key approaches: model\nfine-tuning and agent-based workflows. Our findings reveal that even a\nrelatively compact 7B model can attain performance levels comparable to a much\nlarger 72B model, effectively balancing inference cost and model capability.\nThis optimization greatly enhances the feasibility and efficiency of deploying\nLLMs in real-world online services, making them more practical and accessible\nfor local life applications.", "AI": {"tldr": "A study evaluates LLMs for local life services, showing a 7B model can match a 72B model's performance with fine-tuning and agent-based workflows, improving deployment feasibility.", "motivation": "To explore the potential of LLMs in local life services and enhance their practicality for real-world applications.", "method": "Established a benchmark, evaluated diverse LLMs, and tested fine-tuning and agent-based workflows.", "result": "A 7B model achieved performance comparable to a 72B model, optimizing cost and capability.", "conclusion": "LLMs can be efficiently deployed for local life services, balancing performance and practicality."}}
{"id": "2506.02378", "pdf": "https://arxiv.org/pdf/2506.02378", "abs": "https://arxiv.org/abs/2506.02378", "authors": ["Ukyo Honda", "Tatsushi Oka"], "title": "Exploring Explanations Improves the Robustness of In-Context Learning", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "Accepted to ACL 2025 (Main Conference)", "summary": "In-context learning (ICL) has emerged as a successful paradigm for leveraging\nlarge language models (LLMs). However, it often struggles to generalize beyond\nthe distribution of the provided demonstrations. A recent advancement in\nenhancing robustness is ICL with explanations (X-ICL), which improves\nprediction reliability by guiding LLMs to understand and articulate the\nreasoning behind correct labels. Building on this approach, we introduce an\nadvanced framework that extends X-ICL by systematically exploring explanations\nfor all possible labels (X$^2$-ICL), thereby enabling more comprehensive and\nrobust decision-making. Experimental results on multiple natural language\nunderstanding datasets validate the effectiveness of X$^2$-ICL, demonstrating\nsignificantly improved robustness to out-of-distribution data compared to the\nexisting ICL approaches.", "AI": {"tldr": "X\u00b2-ICL extends X-ICL by exploring explanations for all labels, improving robustness in LLMs for out-of-distribution data.", "motivation": "ICL struggles with generalization beyond provided demonstrations; X-ICL improves reliability but lacks comprehensive reasoning.", "method": "Extends X-ICL by systematically exploring explanations for all possible labels (X\u00b2-ICL).", "result": "Significantly improved robustness to out-of-distribution data on multiple NLP datasets.", "conclusion": "X\u00b2-ICL enhances decision-making robustness in LLMs, outperforming existing ICL approaches."}}
{"id": "2506.02358", "pdf": "https://arxiv.org/pdf/2506.02358", "abs": "https://arxiv.org/abs/2506.02358", "authors": ["Tianze Wang", "Zhang Zhang", "Chao Sun"], "title": "RoadFormer : Local-Global Feature Fusion for Road Surface Classification in Autonomous Driving", "categories": ["cs.CV"], "comment": null, "summary": "The classification of the type of road surface (RSC) aims to utilize pavement\nfeatures to identify the roughness, wet and dry conditions, and material\ninformation of the road surface. Due to its ability to effectively enhance road\nsafety and traffic management, it has received widespread attention in recent\nyears. In autonomous driving, accurate RSC allows vehicles to better understand\nthe road environment, adjust driving strategies, and ensure a safer and more\nefficient driving experience. For a long time, vision-based RSC has been\nfavored. However, existing visual classification methods have overlooked the\nexploration of fine-grained classification of pavement types (such as similar\npavement textures). In this work, we propose a pure vision-based fine-grained\nRSC method for autonomous driving scenarios, which fuses local and global\nfeature information through the stacking of convolutional and transformer\nmodules. We further explore the stacking strategies of local and global feature\nextraction modules to find the optimal feature extraction strategy. In\naddition, since fine-grained tasks also face the challenge of relatively large\nintra-class differences and relatively small inter-class differences, we\npropose a Foreground-Background Module (FBM) that effectively extracts\nfine-grained context features of the pavement, enhancing the classification\nability for complex pavements. Experiments conducted on a large-scale pavement\ndataset containing one million samples and a simplified dataset reorganized\nfrom this dataset achieved Top-1 classification accuracies of 92.52% and\n96.50%, respectively, improving by 5.69% to 12.84% compared to SOTA methods.\nThese results demonstrate that RoadFormer outperforms existing methods in RSC\ntasks, providing significant progress in improving the reliability of pavement\nperception in autonomous driving systems.", "AI": {"tldr": "The paper proposes a vision-based fine-grained road surface classification (RSC) method for autonomous driving, combining convolutional and transformer modules to improve accuracy.", "motivation": "Enhancing road safety and traffic management by accurately classifying road surfaces, especially fine-grained types, for better autonomous driving performance.", "method": "A hybrid approach using convolutional and transformer modules for feature fusion, plus a Foreground-Background Module (FBM) to handle fine-grained challenges.", "result": "Achieved Top-1 accuracies of 92.52% and 96.50% on two datasets, outperforming SOTA methods by 5.69% to 12.84%.", "conclusion": "RoadFormer significantly improves RSC reliability, advancing pavement perception in autonomous driving."}}
{"id": "2506.02092", "pdf": "https://arxiv.org/pdf/2506.02092", "abs": "https://arxiv.org/abs/2506.02092", "authors": ["Francesco De Santis", "Philippe Bich", "Gabriele Ciravegna", "Pietro Barbiero", "Danilo Giordano", "Tania Cerquitelli"], "title": "Towards Better Generalization and Interpretability in Unsupervised Concept-Based Models", "categories": ["cs.LG", "cs.AI", "stat.ML"], "comment": "Paper accepted at ECML-PKDD 2025", "summary": "To increase the trustworthiness of deep neural networks, it is critical to\nimprove the understanding of how they make decisions. This paper introduces a\nnovel unsupervised concept-based model for image classification, named\nLearnable Concept-Based Model (LCBM) which models concepts as random variables\nwithin a Bernoulli latent space. Unlike traditional methods that either require\nextensive human supervision or suffer from limited scalability, our approach\nemploys a reduced number of concepts without sacrificing performance. We\ndemonstrate that LCBM surpasses existing unsupervised concept-based models in\ngeneralization capability and nearly matches the performance of black-box\nmodels. The proposed concept representation enhances information retention and\naligns more closely with human understanding. A user study demonstrates the\ndiscovered concepts are also more intuitive for humans to interpret. Finally,\ndespite the use of concept embeddings, we maintain model interpretability by\nmeans of a local linear combination of concepts.", "AI": {"tldr": "A novel unsupervised concept-based model (LCBM) improves interpretability and performance in image classification by modeling concepts as random variables in a Bernoulli latent space.", "motivation": "To enhance trustworthiness in deep neural networks by improving decision-making transparency and reducing reliance on human supervision.", "method": "Introduces LCBM, which uses a Bernoulli latent space for concept representation, requiring fewer concepts without performance loss.", "result": "LCBM outperforms unsupervised models in generalization and nearly matches black-box models, with concepts more intuitive for humans.", "conclusion": "LCBM balances interpretability and performance, aligning concepts with human understanding while maintaining model transparency."}}
{"id": "2506.02739", "pdf": "https://arxiv.org/pdf/2506.02739", "abs": "https://arxiv.org/abs/2506.02739", "authors": ["Pengcheng Zhou", "Yinglun Feng", "Halimulati Julaiti", "Zhongliang Yang"], "title": "Why do AI agents communicate in human language?", "categories": ["cs.AI"], "comment": null, "summary": "Large Language Models (LLMs) have become foundational to modern AI agent\nsystems, enabling autonomous agents to reason and plan. In most existing\nsystems, inter-agent communication relies primarily on natural language. While\nthis design supports interpretability and human oversight, we argue that it\nintroduces fundamental limitations in agent-to-agent coordination. The semantic\nspace of natural language is structurally misaligned with the high-dimensional\nvector spaces in which LLMs operate, resulting in information loss and\nbehavioral drift. Beyond surface-level inefficiencies, we highlight a deeper\narchitectural limitation: current LLMs were not trained with the objective of\nsupporting agentic behavior. As such, they lack mechanisms for modeling role\ncontinuity, task boundaries, and multi-agent dependencies. The standard\nnext-token prediction paradigm fails to support the structural alignment\nrequired for robust, scalable agent coordination. Based on this, we argue that\ntwo core questions deserve careful examination: first, given that AI agents\nfundamentally operate in high-dimensional vector spaces, should they rely on a\nlanguage system originally designed for human cognition as their communication\nmedium? Second, should we consider developing a new model construction paradigm\nthat builds models from the ground up to natively support structured\ncommunication, shared intentionality, and task alignment in multi-role,\nmulti-agent environments? This paper calls for a reconsideration not only of\nhow agents should communicate, but also of what it fundamentally means to train\na model that natively supports multi-agent coordination and communication.", "AI": {"tldr": "The paper critiques the reliance on natural language for inter-agent communication in LLM-based AI systems, highlighting inefficiencies and proposing a need for new paradigms to better support multi-agent coordination.", "motivation": "Current LLM-based systems use natural language for agent communication, which is misaligned with LLMs' high-dimensional vector spaces, causing inefficiencies and limitations in coordination.", "method": "The paper analyzes the structural misalignment between natural language and LLM vector spaces, identifying limitations like information loss and behavioral drift.", "result": "The analysis reveals that LLMs lack mechanisms for role continuity, task boundaries, and multi-agent dependencies, hindering robust coordination.", "conclusion": "The paper advocates for rethinking agent communication and developing new model paradigms to natively support structured multi-agent coordination."}}
{"id": "2506.02391", "pdf": "https://arxiv.org/pdf/2506.02391", "abs": "https://arxiv.org/abs/2506.02391", "authors": ["Chuanghao Ding", "Jiaping Wang", "Ziqing Yang", "Xiaoliang Wang", "Dahua Lin", "Cam-Tu Nguyen", "Fei Tan"], "title": "Consultant Decoding: Yet Another Synergistic Mechanism", "categories": ["cs.CL", "cs.AI"], "comment": "ACL 2025 findings", "summary": "The synergistic mechanism based on Speculative Decoding (SD) has garnered\nconsiderable attention as a simple yet effective approach for accelerating the\ninference of large language models (LLMs). Nonetheless, the high rejection\nrates require repeated LLMs calls to validate draft tokens, undermining the\noverall efficiency gain of SD. In this work, we revisit existing verification\nmechanisms and propose a novel synergetic mechanism Consultant Decoding (CD).\nUnlike SD, which relies on a metric derived from importance sampling for\nverification, CD verifies candidate drafts using token-level likelihoods\ncomputed solely by the LLM. CD achieves up to a 2.5-fold increase in inference\nspeed compared to the target model, while maintaining comparable generation\nquality (around 100% of the target model's performance). Interestingly, this is\nachieved by combining models whose parameter sizes differ by two orders of\nmagnitude. In addition, CD reduces the call frequency of the large target model\nto below 10%, particularly in more demanding tasks. CD's performance was even\nfound to surpass that of the large target model, which theoretically represents\nthe upper bound for speculative decoding.", "AI": {"tldr": "Consultant Decoding (CD) improves speculative decoding by using token-level likelihoods for verification, achieving 2.5x speedup and reducing large model calls to below 10%.", "motivation": "High rejection rates in speculative decoding (SD) undermine efficiency gains, prompting a need for better verification mechanisms.", "method": "CD verifies drafts using token-level likelihoods from the LLM, avoiding repeated validation calls.", "result": "CD achieves 2.5x speedup, maintains generation quality, and reduces large model calls significantly.", "conclusion": "CD outperforms SD and even the target model, offering a more efficient and effective approach."}}
{"id": "2506.02359", "pdf": "https://arxiv.org/pdf/2506.02359", "abs": "https://arxiv.org/abs/2506.02359", "authors": ["Brent A. Griffin", "Manushree Gangwar", "Jacob Sela", "Jason J. Corso"], "title": "Auto-Labeling Data for Object Detection", "categories": ["cs.CV"], "comment": null, "summary": "Great labels make great models. However, traditional labeling approaches for\ntasks like object detection have substantial costs at scale. Furthermore,\nalternatives to fully-supervised object detection either lose functionality or\nrequire larger models with prohibitive computational costs for inference at\nscale. To that end, this paper addresses the problem of training standard\nobject detection models without any ground truth labels. Instead, we configure\npreviously-trained vision-language foundation models to generate\napplication-specific pseudo \"ground truth\" labels. These auto-generated labels\ndirectly integrate with existing model training frameworks, and we subsequently\ntrain lightweight detection models that are computationally efficient. In this\nway, we avoid the costs of traditional labeling, leverage the knowledge of\nvision-language models, and keep the efficiency of lightweight models for\npractical application. We perform exhaustive experiments across multiple\nlabeling configurations, downstream inference models, and datasets to establish\nbest practices and set an extensive auto-labeling benchmark. From our results,\nwe find that our approach is a viable alternative to standard labeling in that\nit maintains competitive performance on multiple datasets and substantially\nreduces labeling time and costs.", "AI": {"tldr": "The paper proposes using vision-language models to auto-generate pseudo-labels for training lightweight object detection models, eliminating the need for costly traditional labeling while maintaining performance.", "motivation": "Traditional labeling for object detection is expensive and alternatives often compromise functionality or efficiency. The goal is to train models without ground truth labels by leveraging pre-trained vision-language models.", "method": "Configure vision-language foundation models to generate pseudo-labels, then train lightweight detection models using these auto-generated labels.", "result": "The approach maintains competitive performance across datasets while significantly reducing labeling time and costs.", "conclusion": "Auto-labeling with vision-language models is a viable and efficient alternative to traditional labeling for object detection."}}
{"id": "2506.02096", "pdf": "https://arxiv.org/pdf/2506.02096", "abs": "https://arxiv.org/abs/2506.02096", "authors": ["Zijian Wu", "Jinjie Ni", "Xiangyan Liu", "Zichen Liu", "Hang Yan", "Michael Qizhe Shieh"], "title": "SynthRL: Scaling Visual Reasoning with Verifiable Data Synthesis", "categories": ["cs.LG", "cs.CL", "cs.CV"], "comment": null, "summary": "Vision-language models (VLMs) trained via reinforcement learning with\nverifiable reward (RLVR) have shown notable progress in scaling test-time\ncompute effectively. In this work, we investigate how synthesized RL data can\nfurther improve RLVR. To this end, we propose \\textbf{SynthRL}-a scalable and\nguaranteed pipeline for automatic data scaling in reasoning-oriented RL\ntraining. SynthRL comprises three key stages: (1) selecting seed questions with\nappropriate distribution, (2) augmenting them into more challenging variants\nwhile preserving the original answers, and (3) a guaranteed verification stage\nthat ensures near-perfect correctness and difficulty enhancement. Our empirical\nexperiments demonstrate SynthRL's scalability and effectiveness. When applied\nto the MMK12 dataset, SynthRL synthesizes over 3.3K additional verifiable,\nchallenging questions from approximately 8K seed samples. Models trained with\nour synthesized data achieve consistent gains across five out-of-domain visual\nmath reasoning benchmarks, with a significant improvement over baseline models\ntrained on seed data alone. Notably, detailed analysis reveals that the gains\nare more pronounced on the most challenging evaluation samples, highlighting\nSynthRL's effectiveness in eliciting deeper and more complex reasoning\npatterns.", "AI": {"tldr": "SynthRL is a scalable pipeline for synthesizing challenging RL data to improve vision-language models (VLMs) trained with RLVR, showing significant gains in reasoning tasks.", "motivation": "To enhance the effectiveness of RLVR-trained VLMs by synthesizing additional verifiable and challenging data for reasoning-oriented training.", "method": "SynthRL involves three stages: selecting seed questions, augmenting them into harder variants while preserving answers, and verifying correctness and difficulty.", "result": "SynthRL synthesized 3.3K additional questions from 8K seeds, improving model performance on five out-of-domain benchmarks, especially on challenging samples.", "conclusion": "SynthRL effectively scales data for RL training, enhancing reasoning capabilities in VLMs, particularly for complex tasks."}}
{"id": "2506.02761", "pdf": "https://arxiv.org/pdf/2506.02761", "abs": "https://arxiv.org/abs/2506.02761", "authors": ["Renyang Liu", "Wenjie Feng", "Tianwei Zhang", "Wei Zhou", "Xueqi Cheng", "See-Kiong Ng"], "title": "Rethinking Machine Unlearning in Image Generation Models", "categories": ["cs.AI", "cs.CL", "cs.CR", "cs.CV"], "comment": "Accepted by ACM CCS 2025", "summary": "With the surge and widespread application of image generation models, data\nprivacy and content safety have become major concerns and attracted great\nattention from users, service providers, and policymakers. Machine unlearning\n(MU) is recognized as a cost-effective and promising means to address these\nchallenges. Despite some advancements, image generation model unlearning (IGMU)\nstill faces remarkable gaps in practice, e.g., unclear task discrimination and\nunlearning guidelines, lack of an effective evaluation framework, and\nunreliable evaluation metrics. These can hinder the understanding of unlearning\nmechanisms and the design of practical unlearning algorithms. We perform\nexhaustive assessments over existing state-of-the-art unlearning algorithms and\nevaluation standards, and discover several critical flaws and challenges in\nIGMU tasks. Driven by these limitations, we make several core contributions, to\nfacilitate the comprehensive understanding, standardized categorization, and\nreliable evaluation of IGMU. Specifically, (1) We design CatIGMU, a novel\nhierarchical task categorization framework. It provides detailed implementation\nguidance for IGMU, assisting in the design of unlearning algorithms and the\nconstruction of testbeds. (2) We introduce EvalIGMU, a comprehensive evaluation\nframework. It includes reliable quantitative metrics across five critical\naspects. (3) We construct DataIGM, a high-quality unlearning dataset, which can\nbe used for extensive evaluations of IGMU, training content detectors for\njudgment, and benchmarking the state-of-the-art unlearning algorithms. With\nEvalIGMU and DataIGM, we discover that most existing IGMU algorithms cannot\nhandle the unlearning well across different evaluation dimensions, especially\nfor preservation and robustness. Code and models are available at\nhttps://github.com/ryliu68/IGMU.", "AI": {"tldr": "The paper addresses challenges in image generation model unlearning (IGMU), proposing a hierarchical task categorization framework (CatIGMU), a comprehensive evaluation framework (EvalIGMU), and a high-quality dataset (DataIGM) to improve understanding and evaluation of IGMU.", "motivation": "The rise of image generation models has raised privacy and safety concerns, but existing IGMU solutions lack clear guidelines, effective evaluation, and reliable metrics.", "method": "The authors assess existing unlearning algorithms, design CatIGMU for task categorization, introduce EvalIGMU for evaluation, and create DataIGM for benchmarking.", "result": "Most existing IGMU algorithms perform poorly across evaluation dimensions, particularly in preservation and robustness.", "conclusion": "The proposed frameworks and dataset advance IGMU research by providing standardized tools for algorithm design and evaluation."}}
{"id": "2506.02404", "pdf": "https://arxiv.org/pdf/2506.02404", "abs": "https://arxiv.org/abs/2506.02404", "authors": ["Yilin Xiao", "Junnan Dong", "Chuang Zhou", "Su Dong", "Qianwen Zhang", "Di Yin", "Xing Sun", "Xiao Huang"], "title": "GraphRAG-Bench: Challenging Domain-Specific Reasoning for Evaluating Graph Retrieval-Augmented Generation", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Graph Retrieval Augmented Generation (GraphRAG) has garnered increasing\nrecognition for its potential to enhance large language models (LLMs) by\nstructurally organizing domain-specific corpora and facilitating complex\nreasoning. However, current evaluations of GraphRAG models predominantly rely\non traditional question-answering datasets. Their limited scope in questions\nand evaluation metrics fails to comprehensively assess the reasoning capacity\nimprovements enabled by GraphRAG models. To address this gap, we introduce\nGraphRAG-Bench, a large-scale, domain-specific benchmark designed to rigorously\nevaluate GraphRAG models. Our benchmark offers three key superiorities: \\((i)\\)\nChallenging question design. Featuring college-level, domain-specific questions\nthat demand multi-hop reasoning, the benchmark ensures that simple content\nretrieval is insufficient for problem-solving. For example, some questions\nrequire mathematical reasoning or programming. \\((ii)\\) Diverse task coverage.\nThe dataset includes a broad spectrum of reasoning tasks, multiple-choice,\ntrue/false, multi-select, open-ended, and fill-in-the-blank. It spans 16\ndisciplines in twenty core textbooks. \\((iii)\\) Holistic evaluation framework.\nGraphRAG-Bench provides comprehensive assessment across the entire GraphRAG\npipeline, including graph construction, knowledge retrieval, and answer\ngeneration. Beyond final-answer correctness, it evaluates the logical coherence\nof the reasoning process. By applying nine contemporary GraphRAG methods to\nGraphRAG-Bench, we demonstrate its utility in quantifying how graph-based\nstructuring improves model reasoning capabilities. Our analysis reveals\ncritical insights about graph architectures, retrieval efficacy, and reasoning\ncapabilities, offering actionable guidance for the research community.", "AI": {"tldr": "GraphRAG-Bench is introduced to rigorously evaluate GraphRAG models with challenging, domain-specific questions, diverse tasks, and a holistic framework, revealing insights into graph architectures and reasoning improvements.", "motivation": "Current evaluations of GraphRAG models are limited by traditional question-answering datasets, failing to assess reasoning capacity comprehensively.", "method": "GraphRAG-Bench features college-level, domain-specific questions requiring multi-hop reasoning, diverse task types, and a holistic evaluation framework.", "result": "The benchmark demonstrates the utility of graph-based structuring in improving reasoning capabilities, providing insights into graph architectures and retrieval efficacy.", "conclusion": "GraphRAG-Bench offers actionable guidance for the research community by comprehensively evaluating GraphRAG models and their reasoning enhancements."}}
{"id": "2506.02364", "pdf": "https://arxiv.org/pdf/2506.02364", "abs": "https://arxiv.org/abs/2506.02364", "authors": ["Liang Li", "Jianli Zhao", "Sheng Fang", "Siyu Chen", "Hui Sun"], "title": "A TRPCA-Inspired Deep Unfolding Network for Hyperspectral Image Denoising via Thresholded t-SVD and Top-K Sparse Transformer", "categories": ["cs.CV"], "comment": "11 pages,6 figures", "summary": "Hyperspectral images (HSIs) are often degraded by complex mixed noise during\nacquisition and transmission, making effective denoising essential for\nsubsequent analysis. Recent hybrid approaches that bridge model-driven and\ndata-driven paradigms have shown great promise. However, most of these\napproaches lack effective alternation between different priors or modules,\nresulting in loosely coupled regularization and insufficient exploitation of\ntheir complementary strengths. Inspired by tensor robust principal component\nanalysis (TRPCA), we propose a novel deep unfolding network (DU-TRPCA) that\nenforces stage-wise alternation between two tightly integrated modules:\nlow-rank and sparse. The low-rank module employs thresholded tensor singular\nvalue decomposition (t-SVD), providing a widely adopted convex surrogate for\ntensor low-rankness and has been demonstrated to effectively capture the global\nspatial-spectral structure of HSIs. The Top-K sparse transformer module\nadaptively imposes sparse constraints, directly matching the sparse\nregularization in TRPCA and enabling effective removal of localized outliers\nand complex noise. This tightly coupled architecture preserves the stage-wise\nalternation between low-rank approximation and sparse refinement inherent in\nTRPCA, while enhancing representational capacity through attention mechanisms.\nExtensive experiments on synthetic and real-world HSIs demonstrate that\nDU-TRPCA surpasses state-of-the-art methods under severe mixed noise, while\noffering interpretability benefits and stable denoising dynamics inspired by\niterative optimization. Code is available at\nhttps://github.com/liangli97/TRPCA-Deep-Unfolding-HSI-Denoising.", "AI": {"tldr": "A novel deep unfolding network (DU-TRPCA) is proposed for hyperspectral image denoising, integrating low-rank and sparse modules with tight coupling and stage-wise alternation, outperforming state-of-the-art methods.", "motivation": "Hyperspectral images (HSIs) suffer from mixed noise, and existing hybrid approaches lack effective alternation between priors, leading to loosely coupled regularization.", "method": "DU-TRPCA combines thresholded tensor SVD for low-rankness and a Top-K sparse transformer for sparse constraints, preserving TRPCA's alternation while enhancing representation.", "result": "Extensive experiments show DU-TRPCA outperforms state-of-the-art methods under severe mixed noise, offering interpretability and stable denoising.", "conclusion": "DU-TRPCA effectively denoises HSIs by tightly integrating low-rank and sparse modules, leveraging TRPCA-inspired alternation and attention mechanisms."}}
{"id": "2506.02098", "pdf": "https://arxiv.org/pdf/2506.02098", "abs": "https://arxiv.org/abs/2506.02098", "authors": ["Miran \u00d6zdogan", "Gilad Landau", "Gereon Elvers", "Dulhan Jayalath", "Pratik Somaiya", "Francesco Mantegna", "Mark Woolrich", "Oiwi Parker Jones"], "title": "LibriBrain: Over 50 Hours of Within-Subject MEG to Improve Speech Decoding Methods at Scale", "categories": ["cs.LG"], "comment": "37 pages, 14 figures, 13 tables. Under review", "summary": "LibriBrain represents the largest single-subject MEG dataset to date for\nspeech decoding, with over 50 hours of recordings -- 5$\\times$ larger than the\nnext comparable dataset and 50$\\times$ larger than most. This unprecedented\n`depth' of within-subject data enables exploration of neural representations at\na scale previously unavailable with non-invasive methods. LibriBrain comprises\nhigh-quality MEG recordings together with detailed annotations from a single\nparticipant listening to naturalistic spoken English, covering nearly the full\nSherlock Holmes canon. Designed to support advances in neural decoding,\nLibriBrain comes with a Python library for streamlined integration with deep\nlearning frameworks, standard data splits for reproducibility, and baseline\nresults for three foundational decoding tasks: speech detection, phoneme\nclassification, and word classification. Baseline experiments demonstrate that\nincreasing training data yields substantial improvements in decoding\nperformance, highlighting the value of scaling up deep, within-subject\ndatasets. By releasing this dataset, we aim to empower the research community\nto advance speech decoding methodologies and accelerate the development of\nsafe, effective clinical brain-computer interfaces.", "AI": {"tldr": "LibriBrain is the largest single-subject MEG dataset for speech decoding, offering 50+ hours of recordings, tools for deep learning integration, and baseline results for decoding tasks.", "motivation": "To enable exploration of neural representations at an unprecedented scale and advance speech decoding methodologies for clinical brain-computer interfaces.", "method": "The dataset includes high-quality MEG recordings and annotations from a single participant listening to spoken English, with Python tools for deep learning integration and standardized data splits.", "result": "Baseline experiments show significant decoding performance improvements with more training data, underscoring the value of large within-subject datasets.", "conclusion": "LibriBrain aims to empower the research community to advance speech decoding and accelerate the development of clinical brain-computer interfaces."}}
{"id": "2506.02805", "pdf": "https://arxiv.org/pdf/2506.02805", "abs": "https://arxiv.org/abs/2506.02805", "authors": ["Henri Bollaert", "Chris Cornelis", "Marko Palangeti\u0107", "Salvatore Greco", "Roman S\u0142owi\u0144ski"], "title": "Optimising the attribute order in Fuzzy Rough Rule Induction", "categories": ["cs.AI"], "comment": "This is the author's version of the work accepted for publication in\n  Lecture Notes in Computer Science. The final publication is available at\n  Springer via https://doi.org/10.1007/978-3-031-92747-8_16", "summary": "Interpretability is the next pivotal frontier in machine learning research.\nIn the pursuit of glass box models - as opposed to black box models, like\nrandom forests or neural networks - rule induction algorithms are a logical and\npromising avenue, as the rules can easily be understood by humans. In our\nprevious work, we introduced FRRI, a novel rule induction algorithm based on\nfuzzy rough set theory. We demonstrated experimentally that FRRI outperformed\nother rule induction methods with regards to accuracy and number of rules. FRRI\nleverages a fuzzy indiscernibility relation to partition the data space into\nfuzzy granules, which are then combined into a minimal covering set of rules.\nThis indiscernibility relation is constructed by removing attributes from rules\nin a greedy way. This raises the question: does the order of the attributes\nmatter? In this paper, we show that optimising only the order of attributes\nusing known methods from fuzzy rough set theory and classical machine learning\ndoes not improve the performance of FRRI on multiple metrics. However, removing\na small number of attributes using fuzzy rough feature selection during this\nstep positively affects balanced accuracy and the average rule length.", "AI": {"tldr": "The paper explores whether optimizing attribute order in the FRRI rule induction algorithm improves performance, finding it ineffective, but fuzzy rough feature selection enhances accuracy and rule length.", "motivation": "To improve interpretability in machine learning by refining the FRRI algorithm, focusing on attribute order and selection.", "method": "Tests attribute order optimization and fuzzy rough feature selection within FRRI, comparing performance metrics.", "result": "Attribute order optimization alone doesn't improve FRRI, but feature selection boosts balanced accuracy and reduces rule length.", "conclusion": "Fuzzy rough feature selection is more impactful than attribute order optimization for enhancing FRRI's performance."}}
{"id": "2506.02412", "pdf": "https://arxiv.org/pdf/2506.02412", "abs": "https://arxiv.org/abs/2506.02412", "authors": ["Zhengyuan Liu", "Geyu Lin", "Hui Li Tan", "Huayun Zhang", "Yanfeng Lu", "Xiaoxue Gao", "Stella Xin Yin", "He Sun", "Hock Huan Goh", "Lung Hsiang Wong", "Nancy F. Chen"], "title": "SingaKids: A Multilingual Multimodal Dialogic Tutor for Language Learning", "categories": ["cs.CL", "cs.AI"], "comment": "ACL 2025 Industry Track", "summary": "The integration of generative artificial intelligence into educational\napplications has enhanced personalized and interactive learning experiences,\nand it shows strong potential to promote young learners language acquisition.\nHowever, it is still challenging to ensure consistent and robust performance\nacross different languages and cultural contexts, and kids-friendly design\nrequires simplified instructions, engaging interactions, and age-appropriate\nscaffolding to maintain motivation and optimize learning outcomes. In this\nwork, we introduce SingaKids, a dialogic tutor designed to facilitate language\nlearning through picture description tasks. Our system integrates dense image\ncaptioning, multilingual dialogic interaction, speech understanding, and\nengaging speech generation to create an immersive learning environment in four\nlanguages: English, Mandarin, Malay, and Tamil. We further improve the system\nthrough multilingual pre-training, task-specific tuning, and scaffolding\noptimization. Empirical studies with elementary school students demonstrate\nthat SingaKids provides effective dialogic teaching, benefiting learners at\ndifferent performance levels.", "AI": {"tldr": "SingaKids is a dialogic tutor using AI for language learning in kids, integrating image captioning, multilingual interaction, and speech features, showing effectiveness across four languages.", "motivation": "To address challenges in consistent performance across languages and cultural contexts in AI-driven education, while ensuring kid-friendly design for optimal learning.", "method": "Developed SingaKids with dense image captioning, multilingual dialogic interaction, speech understanding, and engaging speech generation, enhanced by pre-training and scaffolding optimization.", "result": "Empirical studies show SingaKids effectively supports language learning for elementary students across performance levels.", "conclusion": "SingaKids demonstrates robust potential for multilingual, interactive language learning in young learners."}}
{"id": "2506.02366", "pdf": "https://arxiv.org/pdf/2506.02366", "abs": "https://arxiv.org/abs/2506.02366", "authors": ["Qin Xie", "Qinghua Zhang", "Shuyin Xia"], "title": "Approximate Borderline Sampling using Granular-Ball for Classification Tasks", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "Data sampling enhances classifier efficiency and robustness through data\ncompression and quality improvement. Recently, the sampling method based on\ngranular-ball (GB) has shown promising performance in generality and noisy\nclassification tasks. However, some limitations remain, including the absence\nof borderline sampling strategies and issues with class boundary blurring or\nshrinking due to overlap between GBs. In this paper, an approximate borderline\nsampling method using GBs is proposed for classification tasks. First, a\nrestricted diffusion-based GB generation (RD-GBG) method is proposed, which\nprevents GB overlaps by constrained expansion, preserving precise geometric\nrepresentation of GBs via redefined ones. Second, based on the concept of\nheterogeneous nearest neighbor, a GB-based approximate borderline sampling\n(GBABS) method is proposed, which is the first general sampling method capable\nof both borderline sampling and improving the quality of class noise datasets.\nAdditionally, since RD-GBG incorporates noise detection and GBABS focuses on\nborderline samples, GBABS performs outstandingly on class noise datasets\nwithout the need for an optimal purity threshold. Experimental results\ndemonstrate that the proposed methods outperform the GB-based sampling method\nand several representative sampling methods. Our source code is publicly\navailable at https://github.com/CherylTse/GBABS.", "AI": {"tldr": "The paper proposes an approximate borderline sampling method using granular-balls (GBs) to address limitations like class boundary blurring and overlap issues, improving classifier efficiency and robustness.", "motivation": "Existing GB-based sampling methods lack borderline strategies and suffer from issues like class boundary blurring due to GB overlaps.", "method": "Proposes a restricted diffusion-based GB generation (RD-GBG) to prevent overlaps and a GB-based approximate borderline sampling (GBABS) method for borderline sampling and noise dataset quality improvement.", "result": "The methods outperform existing GB-based and other sampling methods, especially on noisy datasets, without needing an optimal purity threshold.", "conclusion": "The proposed RD-GBG and GBABS methods effectively address GB overlap and borderline sampling challenges, enhancing classification performance."}}
{"id": "2506.02134", "pdf": "https://arxiv.org/pdf/2506.02134", "abs": "https://arxiv.org/abs/2506.02134", "authors": ["Rishi Raj Sahoo", "Rucha Bhalchandra Joshi", "Subhankar Mishra"], "title": "ReconXF: Graph Reconstruction Attack via Public Feature Explanations on Privatized Node Features and Labels", "categories": ["cs.LG", "I.2.6; K.6.5"], "comment": "Under review", "summary": "Graph Neural Networks (GNNs) achieve high performance across many\napplications but function as black-box models, limiting their use in critical\ndomains like healthcare and criminal justice. Explainability methods address\nthis by providing feature-level explanations that identify important node\nattributes for predictions. These explanations create privacy risks. Combined\nwith auxiliary information, feature explanations can enable adversaries to\nreconstruct graph structure, exposing sensitive relationships. Existing graph\nreconstruction attacks assume access to original auxiliary data, but practical\nsystems use differential privacy to protect node features and labels while\nproviding explanations for transparency. We study a threat model where\nadversaries access public feature explanations along with privatized node\nfeatures and labels. We show that existing explanation-based attacks like GSEF\nperform poorly with privatized data due to noise from differential privacy\nmechanisms. We propose ReconXF, a graph reconstruction attack for scenarios\nwith public explanations and privatized auxiliary data. Our method adapts\nexplanation-based frameworks by incorporating denoising mechanisms that handle\ndifferential privacy noise while exploiting structural signals in explanations.\nExperiments across multiple datasets show ReconXF outperforms SoTA methods in\nprivatized settings, with improvements in AUC and average precision. Results\nindicate that public explanations combined with denoising enable graph\nstructure recovery even under the privacy protection of auxiliary data. Code is\navailable at (link to be made public after acceptance).", "AI": {"tldr": "The paper introduces ReconXF, a graph reconstruction attack method that works with public explanations and privatized auxiliary data, outperforming existing methods under differential privacy.", "motivation": "GNNs lack transparency, and while explainability methods help, they pose privacy risks by enabling graph structure reconstruction. Existing attacks fail with privatized data.", "method": "Proposes ReconXF, which adapts explanation-based frameworks with denoising to handle differential privacy noise and exploit structural signals in explanations.", "result": "ReconXF outperforms state-of-the-art methods in privatized settings, improving AUC and average precision for graph reconstruction.", "conclusion": "Public explanations combined with denoising can recover graph structure despite privacy protections, highlighting a trade-off between explainability and privacy."}}
{"id": "2506.02838", "pdf": "https://arxiv.org/pdf/2506.02838", "abs": "https://arxiv.org/abs/2506.02838", "authors": ["Jizhou Wang", "Xiaodan Fang", "Lei Huang", "Yongfeng Huang"], "title": "TaxAgent: How Large Language Model Designs Fiscal Policy", "categories": ["cs.AI", "econ.GN", "q-fin.EC", "I.2.11; I.6.5; J.4"], "comment": "Accepted as oral presentation at ICME 2025", "summary": "Economic inequality is a global challenge, intensifying disparities in\neducation, healthcare, and social stability. Traditional systems like the U.S.\nfederal income tax reduce inequality but lack adaptability. Although models\nlike the Saez Optimal Taxation adjust dynamically, they fail to address\ntaxpayer heterogeneity and irrational behavior. This study introduces TaxAgent,\na novel integration of large language models (LLMs) with agent-based modeling\n(ABM) to design adaptive tax policies. In our macroeconomic simulation,\nheterogeneous H-Agents (households) simulate real-world taxpayer behaviors\nwhile the TaxAgent (government) utilizes LLMs to iteratively optimize tax\nrates, balancing equity and productivity. Benchmarked against Saez Optimal\nTaxation, U.S. federal income taxes, and free markets, TaxAgent achieves\nsuperior equity-efficiency trade-offs. This research offers a novel taxation\nsolution and a scalable, data-driven framework for fiscal policy evaluation.", "AI": {"tldr": "TaxAgent combines LLMs and ABM to design adaptive tax policies, outperforming traditional methods in balancing equity and productivity.", "motivation": "Address economic inequality by improving tax policy adaptability to taxpayer heterogeneity and irrational behavior.", "method": "Integrates large language models (LLMs) with agent-based modeling (ABM) to simulate household behaviors and optimize tax rates iteratively.", "result": "TaxAgent achieves better equity-efficiency trade-offs than Saez Optimal Taxation, U.S. federal income taxes, and free markets.", "conclusion": "TaxAgent provides a scalable, data-driven framework for adaptive fiscal policy, offering a novel solution to economic inequality."}}
{"id": "2506.02425", "pdf": "https://arxiv.org/pdf/2506.02425", "abs": "https://arxiv.org/abs/2506.02425", "authors": ["Tairan Liu"], "title": "Gender Inequality in English Textbooks Around the World: an NLP Approach", "categories": ["cs.CL", "stat.AP"], "comment": null, "summary": "Textbooks play a critical role in shaping children's understanding of the\nworld. While previous studies have identified gender inequality in individual\ncountries' textbooks, few have examined the issue cross-culturally. This study\napplies natural language processing methods to quantify gender inequality in\nEnglish textbooks from 22 countries across 7 cultural spheres. Metrics include\ncharacter count, firstness (which gender is mentioned first), and TF-IDF word\nassociations by gender. The analysis also identifies gender patterns in proper\nnames appearing in TF-IDF word lists, tests whether large language models can\ndistinguish between gendered word lists, and uses GloVe embeddings to examine\nhow closely keywords associate with each gender. Results show consistent\noverrepresentation of male characters in terms of count, firstness, and named\nentities. All regions exhibit gender inequality, with the Latin cultural sphere\nshowing the least disparity.", "AI": {"tldr": "The study uses NLP to analyze gender inequality in English textbooks from 22 countries, revealing consistent male overrepresentation across metrics like character count, firstness, and named entities.", "motivation": "To address the lack of cross-cultural studies on gender inequality in textbooks and quantify disparities using computational methods.", "method": "Applied NLP techniques (TF-IDF, GloVe embeddings) to analyze gender patterns in textbooks from 22 countries across 7 cultural spheres.", "result": "Male characters are consistently overrepresented in count, firstness, and named entities, with the Latin cultural sphere showing the least disparity.", "conclusion": "Gender inequality in textbooks is a global issue, with male overrepresentation pervasive across regions."}}
{"id": "2506.02367", "pdf": "https://arxiv.org/pdf/2506.02367", "abs": "https://arxiv.org/abs/2506.02367", "authors": ["Jiayi Su", "Dequan Jin"], "title": "ViTNF: Leveraging Neural Fields to Boost Vision Transformers in Generalized Category Discovery", "categories": ["cs.CV", "68T07", "I.5.1"], "comment": "22 pages, 3 figures", "summary": "Generalized category discovery (GCD) is a highly popular task in open-world\nrecognition, aiming to identify unknown class samples using known class data.\nBy leveraging pre-training, meta-training, and fine-tuning, ViT achieves\nexcellent few-shot learning capabilities. Its MLP head is a feedforward\nnetwork, trained synchronously with the entire network in the same process,\nincreasing the training cost and difficulty without fully leveraging the power\nof the feature extractor. This paper proposes a new architecture by replacing\nthe MLP head with a neural field-based one. We first present a new static\nneural field function to describe the activity distribution of the neural field\nand then use two static neural field functions to build an efficient few-shot\nclassifier. This neural field-based (NF) classifier consists of two coupled\nstatic neural fields. It stores the feature information of support samples by\nits elementary field, the known categories by its high-level field, and the\ncategory information of support samples by its cross-field connections. We\nreplace the MLP head with the proposed NF classifier, resulting in a novel\narchitecture ViTNF, and simplify the three-stage training mode by pre-training\nthe feature extractor on source tasks and training the NF classifier with\nsupport samples in meta-testing separately, significantly reducing ViT's demand\nfor training samples and the difficulty of model training. To enhance the\nmodel's capability in identifying new categories, we provide an effective\nalgorithm to determine the lateral interaction scale of the elementary field.\nExperimental results demonstrate that our model surpasses existing\nstate-of-the-art methods on CIFAR-100, ImageNet-100, CUB-200, and Standard\nCars, achieving dramatic accuracy improvements of 19\\% and 16\\% in new and all\nclasses, respectively, indicating a notable advantage in GCD.", "AI": {"tldr": "The paper proposes ViTNF, a new architecture replacing the MLP head in ViT with a neural field-based classifier, simplifying training and improving performance in generalized category discovery.", "motivation": "To address the inefficiency and high training cost of the MLP head in ViT for few-shot learning, and to better leverage the feature extractor's power.", "method": "Introduces a neural field-based classifier (NF) with two coupled static neural fields, replacing the MLP head. Simplifies training by separating feature extractor pre-training and NF classifier training.", "result": "ViTNF outperforms state-of-the-art methods on multiple datasets, achieving 19% and 16% accuracy improvements in new and all classes, respectively.", "conclusion": "The proposed ViTNF architecture significantly reduces training complexity and enhances performance in generalized category discovery."}}
{"id": "2506.02138", "pdf": "https://arxiv.org/pdf/2506.02138", "abs": "https://arxiv.org/abs/2506.02138", "authors": ["Yarden Bakish", "Itamar Zimerman", "Hila Chefer", "Lior Wolf"], "title": "Revisiting LRP: Positional Attribution as the Missing Ingredient for Transformer Explainability", "categories": ["cs.LG", "I.2.6; I.2.7"], "comment": null, "summary": "The development of effective explainability tools for Transformers is a\ncrucial pursuit in deep learning research. One of the most promising approaches\nin this domain is Layer-wise Relevance Propagation (LRP), which propagates\nrelevance scores backward through the network to the input space by\nredistributing activation values based on predefined rules. However, existing\nLRP-based methods for Transformer explainability entirely overlook a critical\ncomponent of the Transformer architecture: its positional encoding (PE),\nresulting in violation of the conservation property, and the loss of an\nimportant and unique type of relevance, which is also associated with\nstructural and positional features. To address this limitation, we reformulate\nthe input space for Transformer explainability as a set of position-token\npairs. This allows us to propose specialized theoretically-grounded LRP rules\ndesigned to propagate attributions across various positional encoding methods,\nincluding Rotary, Learnable, and Absolute PE. Extensive experiments with both\nfine-tuned classifiers and zero-shot foundation models, such as LLaMA 3,\ndemonstrate that our method significantly outperforms the state-of-the-art in\nboth vision and NLP explainability tasks. Our code is publicly available.", "AI": {"tldr": "The paper introduces a reformulated LRP method for Transformer explainability, addressing the oversight of positional encoding in existing methods, and demonstrates superior performance in vision and NLP tasks.", "motivation": "Existing LRP-based methods for Transformer explainability ignore positional encoding, leading to violations of conservation properties and loss of relevance for structural features.", "method": "The authors reformulate the input space as position-token pairs and propose specialized LRP rules for various positional encoding methods (Rotary, Learnable, Absolute PE).", "result": "Experiments show the method outperforms state-of-the-art in vision and NLP explainability tasks, including with zero-shot models like LLaMA 3.", "conclusion": "The proposed method effectively incorporates positional encoding into Transformer explainability, improving performance and theoretical grounding."}}
{"id": "2506.02865", "pdf": "https://arxiv.org/pdf/2506.02865", "abs": "https://arxiv.org/abs/2506.02865", "authors": ["Mathieu Andreux", "Breno Baldas Skuk", "Hamza Benchekroun", "Emilien Bir\u00e9", "Antoine Bonnet", "Riaz Bordie", "Matthias Brunel", "Pierre-Louis Cedoz", "Antoine Chassang", "Micka\u00ebl Chen", "Alexandra D. Constantinou", "Antoine d'Andign\u00e9", "Hubert de La Jonqui\u00e8re", "Aur\u00e9lien Delfosse", "Ludovic Denoyer", "Alexis Deprez", "Augustin Derupti", "Michael Eickenberg", "Math\u00efs Federico", "Charles Kantor", "Xavier Koegler", "Yann Labb\u00e9", "Matthew C. H. Lee", "Erwan Le Jumeau de Kergaradec", "Amir Mahla", "Avshalom Manevich", "Adrien Maret", "Charles Masson", "Rafa\u00ebl Maurin", "Arturo Mena", "Philippe Modard", "Axel Moyal", "Axel Nguyen Kerbel", "Julien Revelle", "Mats L. Richter", "Mar\u00eda Santos", "Laurent Sifre", "Maxime Theillard", "Marc Thibault", "Louis Thiry", "L\u00e9o Tronchon", "Nicolas Usunier", "Tony Wu"], "title": "Surfer-H Meets Holo1: Cost-Efficient Web Agent Powered by Open Weights", "categories": ["cs.AI"], "comment": "Alphabetical order", "summary": "We present Surfer-H, a cost-efficient web agent that integrates\nVision-Language Models (VLM) to perform user-defined tasks on the web. We pair\nit with Holo1, a new open-weight collection of VLMs specialized in web\nnavigation and information extraction. Holo1 was trained on carefully curated\ndata sources, including open-access web content, synthetic examples, and\nself-produced agentic data. Holo1 tops generalist User Interface (UI)\nbenchmarks as well as our new web UI localization benchmark, WebClick. When\npowered by Holo1, Surfer-H achieves a 92.2% state-of-the-art performance on\nWebVoyager, striking a Pareto-optimal balance between accuracy and\ncost-efficiency. To accelerate research advancement in agentic systems, we are\nopen-sourcing both our WebClick evaluation dataset and the Holo1 model weights.", "AI": {"tldr": "Surfer-H is a cost-efficient web agent using Vision-Language Models (VLM) for web tasks, paired with Holo1, a specialized VLM for navigation and extraction. Holo1 excels in benchmarks, and Surfer-H achieves 92.2% performance on WebVoyager. Both WebClick dataset and Holo1 weights are open-sourced.", "motivation": "To create a cost-efficient web agent leveraging VLMs for user-defined tasks, advancing research in agentic systems.", "method": "Integrates Surfer-H with Holo1, a VLM trained on curated data (web content, synthetic examples, agentic data). Evaluated on UI benchmarks and WebClick.", "result": "Holo1 tops UI benchmarks; Surfer-H achieves 92.2% performance on WebVoyager, balancing accuracy and cost.", "conclusion": "Surfer-H and Holo1 demonstrate high performance and efficiency, with open-sourced resources to foster further research."}}
{"id": "2506.02426", "pdf": "https://arxiv.org/pdf/2506.02426", "abs": "https://arxiv.org/abs/2506.02426", "authors": ["Maryam Berijanian", "Kuldeep Singh", "Amin Sehati"], "title": "Comparative Analysis of AI Agent Architectures for Entity Relationship Classification", "categories": ["cs.CL", "cs.AI", "I.2.7; I.2.1"], "comment": null, "summary": "Entity relationship classification remains a challenging task in information\nextraction, especially in scenarios with limited labeled data and complex\nrelational structures. In this study, we conduct a comparative analysis of\nthree distinct AI agent architectures designed to perform relation\nclassification using large language models (LLMs). The agentic architectures\nexplored include (1) reflective self-evaluation, (2) hierarchical task\ndecomposition, and (3) a novel multi-agent dynamic example generation\nmechanism, each leveraging different modes of reasoning and prompt adaptation.\nIn particular, our dynamic example generation approach introduces real-time\ncooperative and adversarial prompting. We systematically compare their\nperformance across multiple domains and model backends. Our experiments\ndemonstrate that multi-agent coordination consistently outperforms standard\nfew-shot prompting and approaches the performance of fine-tuned models. These\nfindings offer practical guidance for the design of modular, generalizable\nLLM-based systems for structured relation extraction. The source codes and\ndataset are available at\n\\href{https://github.com/maryambrj/ALIEN.git}{https://github.com/maryambrj/ALIEN.git}.", "AI": {"tldr": "Comparative analysis of three AI agent architectures for relation classification using LLMs, showing multi-agent coordination outperforms few-shot prompting and nears fine-tuned model performance.", "motivation": "Addressing challenges in entity relationship classification with limited labeled data and complex relational structures.", "method": "Evaluated three architectures: reflective self-evaluation, hierarchical task decomposition, and dynamic example generation with cooperative/adversarial prompting.", "result": "Multi-agent coordination consistently outperforms few-shot prompting and approaches fine-tuned model performance.", "conclusion": "Provides practical guidance for designing modular, generalizable LLM-based systems for structured relation extraction."}}
{"id": "2506.02382", "pdf": "https://arxiv.org/pdf/2506.02382", "abs": "https://arxiv.org/abs/2506.02382", "authors": ["Seulgi Kim", "Ghazal Kaviani", "Mohit Prabhushankar", "Ghassan AlRegib"], "title": "Multi-level and Multi-modal Action Anticipation", "categories": ["cs.CV", "cs.LG"], "comment": "Accepted in 2025 IEEE International Conference on Image Processing\n  (ICIP)", "summary": "Action anticipation, the task of predicting future actions from partially\nobserved videos, is crucial for advancing intelligent systems. Unlike action\nrecognition, which operates on fully observed videos, action anticipation must\nhandle incomplete information. Hence, it requires temporal reasoning, and\ninherent uncertainty handling. While recent advances have been made,\ntraditional methods often focus solely on visual modalities, neglecting the\npotential of integrating multiple sources of information. Drawing inspiration\nfrom human behavior, we introduce \\textit{Multi-level and Multi-modal Action\nAnticipation (m\\&m-Ant)}, a novel multi-modal action anticipation approach that\ncombines both visual and textual cues, while explicitly modeling hierarchical\nsemantic information for more accurate predictions. To address the challenge of\ninaccurate coarse action labels, we propose a fine-grained label generator\npaired with a specialized temporal consistency loss function to optimize\nperformance. Extensive experiments on widely used datasets, including\nBreakfast, 50 Salads, and DARai, demonstrate the effectiveness of our approach,\nachieving state-of-the-art results with an average anticipation accuracy\nimprovement of 3.08\\% over existing methods. This work underscores the\npotential of multi-modal and hierarchical modeling in advancing action\nanticipation and establishes a new benchmark for future research in the field.\nOur code is available at: https://github.com/olivesgatech/mM-ant.", "AI": {"tldr": "The paper introduces m&m-Ant, a multi-modal action anticipation method combining visual and textual cues with hierarchical modeling, achieving state-of-the-art results.", "motivation": "Action anticipation requires handling incomplete information and uncertainty, but traditional methods often ignore multi-modal integration.", "method": "Proposes m&m-Ant, integrating visual and textual cues with hierarchical modeling, a fine-grained label generator, and a temporal consistency loss.", "result": "Achieves 3.08% higher anticipation accuracy on datasets like Breakfast, 50 Salads, and DARai.", "conclusion": "Highlights the value of multi-modal and hierarchical modeling, setting a new benchmark for action anticipation."}}
{"id": "2506.02154", "pdf": "https://arxiv.org/pdf/2506.02154", "abs": "https://arxiv.org/abs/2506.02154", "authors": ["Guillaume Godin"], "title": "Z-Error Loss for Training Neural Networks", "categories": ["cs.LG", "cs.AI"], "comment": "13 pages, 6 figures, A technical note", "summary": "Outliers introduce significant training challenges in neural networks by\npropagating erroneous gradients, which can degrade model performance and\ngeneralization. We propose the Z-Error Loss, a statistically principled\napproach that minimizes outlier influence during training by masking the\ncontribution of data points identified as out-of-distribution within each\nbatch. This method leverages batch-level statistics to automatically detect and\nexclude anomalous samples, allowing the model to focus its learning on the true\nunderlying data structure. Our approach is robust, adaptive to data quality,\nand provides valuable diagnostics for data curation and cleaning.", "AI": {"tldr": "Z-Error Loss minimizes outlier impact in neural networks by masking out-of-distribution data points during training.", "motivation": "Outliers degrade model performance by propagating erroneous gradients, necessitating a robust solution.", "method": "Uses batch-level statistics to detect and exclude anomalous samples, focusing learning on true data structure.", "result": "Improves model performance and generalization by reducing outlier influence.", "conclusion": "Z-Error Loss is a robust, adaptive method for outlier mitigation, aiding data curation and cleaning."}}
{"id": "2506.02867", "pdf": "https://arxiv.org/pdf/2506.02867", "abs": "https://arxiv.org/abs/2506.02867", "authors": ["Chen Qian", "Dongrui Liu", "Haochen Wen", "Zhen Bai", "Yong Liu", "Jing Shao"], "title": "Demystifying Reasoning Dynamics with Mutual Information: Thinking Tokens are Information Peaks in LLM Reasoning", "categories": ["cs.AI", "cs.CL"], "comment": "Preprint. Under review", "summary": "Large reasoning models (LRMs) have demonstrated impressive capabilities in\ncomplex problem-solving, yet their internal reasoning mechanisms remain poorly\nunderstood. In this paper, we investigate the reasoning trajectories of LRMs\nfrom an information-theoretic perspective. By tracking how mutual information\n(MI) between intermediate representations and the correct answer evolves during\nLRM reasoning, we observe an interesting MI peaks phenomenon: the MI at\nspecific generative steps exhibits a sudden and significant increase during\nLRM's reasoning process. We theoretically analyze such phenomenon and show that\nas MI increases, the probability of model's prediction error decreases.\nFurthermore, these MI peaks often correspond to tokens expressing reflection or\ntransition, such as ``Hmm'', ``Wait'' and ``Therefore,'' which we term as the\nthinking tokens. We then demonstrate that these thinking tokens are crucial for\nLRM's reasoning performance, while other tokens has minimal impacts. Building\non these analyses, we propose two simple yet effective methods to improve LRM's\nreasoning performance, by delicately leveraging these thinking tokens. Overall,\nour work provides novel insights into the reasoning mechanisms of LRMs and\noffers practical ways to improve their reasoning capabilities. The code is\navailable at https://github.com/ChnQ/MI-Peaks.", "AI": {"tldr": "The paper explores the reasoning mechanisms of large reasoning models (LRMs) by analyzing mutual information (MI) peaks during reasoning, identifying 'thinking tokens' like 'Hmm' and 'Therefore' as crucial for performance, and proposing methods to enhance LRM reasoning.", "motivation": "To understand the internal reasoning mechanisms of LRMs, which remain poorly understood despite their problem-solving capabilities.", "method": "Tracked MI between intermediate representations and correct answers during LRM reasoning, identified MI peaks and 'thinking tokens,' and proposed methods to leverage these tokens.", "result": "Observed MI peaks correlate with reduced prediction errors and identified 'thinking tokens' as key to reasoning performance.", "conclusion": "Provides insights into LRM reasoning and practical methods to improve performance, with code available for further exploration."}}
{"id": "2506.02431", "pdf": "https://arxiv.org/pdf/2506.02431", "abs": "https://arxiv.org/abs/2506.02431", "authors": ["Mahammed Kamruzzaman", "Abdullah Al Monsur", "Gene Louis Kim", "Anshuman Chhabra"], "title": "From Anger to Joy: How Nationality Personas Shape Emotion Attribution in Large Language Models", "categories": ["cs.CL"], "comment": null, "summary": "Emotions are a fundamental facet of human experience, varying across\nindividuals, cultural contexts, and nationalities. Given the recent success of\nLarge Language Models (LLMs) as role-playing agents, we examine whether LLMs\nexhibit emotional stereotypes when assigned nationality-specific personas.\nSpecifically, we investigate how different countries are represented in\npre-trained LLMs through emotion attributions and whether these attributions\nalign with cultural norms. Our analysis reveals significant nationality-based\ndifferences, with emotions such as shame, fear, and joy being\ndisproportionately assigned across regions. Furthermore, we observe notable\nmisalignment between LLM-generated and human emotional responses, particularly\nfor negative emotions, highlighting the presence of reductive and potentially\nbiased stereotypes in LLM outputs.", "AI": {"tldr": "LLMs exhibit nationality-based emotional stereotypes, often misaligning with human responses and cultural norms, particularly for negative emotions.", "motivation": "To investigate if LLMs reflect emotional stereotypes when assigned nationality-specific personas and how these align with cultural norms.", "method": "Analyzed pre-trained LLMs by assigning nationality-specific personas and comparing emotion attributions with cultural norms and human responses.", "result": "Found significant nationality-based differences in emotion attributions (e.g., shame, fear, joy) and misalignment with human responses, especially for negative emotions.", "conclusion": "LLMs display reductive and potentially biased emotional stereotypes, highlighting the need for addressing such biases in model outputs."}}
{"id": "2506.02393", "pdf": "https://arxiv.org/pdf/2506.02393", "abs": "https://arxiv.org/abs/2506.02393", "authors": ["Yongxian Liu", "Boyang Li", "Ting Liu", "Zaiping Lin", "Wei An"], "title": "RRCANet: Recurrent Reusable-Convolution Attention Network for Infrared Small Target Detection", "categories": ["cs.CV"], "comment": null, "summary": "Infrared small target detection is a challenging task due to its unique\ncharacteristics (e.g., small, dim, shapeless and changeable). Recently\npublished CNN-based methods have achieved promising performance with heavy\nfeature extraction and fusion modules. To achieve efficient and effective\ndetection, we propose a recurrent reusable-convolution attention network\n(RRCA-Net) for infrared small target detection. Specifically, RRCA-Net\nincorporates reusable-convolution block (RuCB) in a recurrent manner without\nintroducing extra parameters. With the help of the repetitive iteration in\nRuCB, the high-level information of small targets in the deep layers can be\nwell maintained and further refined. Then, a dual interactive attention\naggregation module (DIAAM) is proposed to promote the mutual enhancement and\nfusion of refined information. In this way, RRCA-Net can both achieve\nhigh-level feature refinement and enhance the correlation of contextual\ninformation between adjacent layers. Moreover, to achieve steady convergence,\nwe design a target characteristic inspired loss function (DpT-k loss) by\nintegrating physical and mathematical constraints. Experimental results on\nthree benchmark datasets (e.g. NUAA-SIRST, IRSTD-1k, DenseSIRST) demonstrate\nthat our RRCA-Net can achieve comparable performance to the state-of-the-art\nmethods while maintaining a small number of parameters, and act as a plug and\nplay module to introduce consistent performance improvement for several popular\nIRSTD methods. Our code will be available at https://github.com/yongxianLiu/\nsoon.", "AI": {"tldr": "RRCA-Net is proposed for efficient infrared small target detection using reusable-convolution blocks and dual interactive attention, achieving state-of-the-art performance with minimal parameters.", "motivation": "Infrared small target detection is challenging due to targets being small, dim, and shapeless. Existing CNN-based methods are heavy, so RRCA-Net aims for efficiency and effectiveness.", "method": "RRCA-Net uses reusable-convolution blocks (RuCB) recurrently and a dual interactive attention module (DIAAM) for feature refinement and fusion. A target-inspired loss function (DpT-k loss) ensures steady convergence.", "result": "RRCA-Net achieves comparable performance to state-of-the-art methods on benchmark datasets (NUAA-SIRST, IRSTD-1k, DenseSIRST) with fewer parameters and can enhance other IRSTD methods.", "conclusion": "RRCA-Net is an efficient, plug-and-play solution for infrared small target detection, balancing performance and parameter efficiency."}}
{"id": "2506.02168", "pdf": "https://arxiv.org/pdf/2506.02168", "abs": "https://arxiv.org/abs/2506.02168", "authors": ["Hrushikesh N. Mhaskar", "Efstratios Tsoukanis", "Ameya D. Jagtap"], "title": "An Approximation Theory Perspective on Machine Learning", "categories": ["cs.LG"], "comment": "56 pages", "summary": "A central problem in machine learning is often formulated as follows: Given a\ndataset $\\{(x_j, y_j)\\}_{j=1}^M$, which is a sample drawn from an unknown\nprobability distribution, the goal is to construct a functional model $f$ such\nthat $f(x) \\approx y$ for any $(x, y)$ drawn from the same distribution. Neural\nnetworks and kernel-based methods are commonly employed for this task due to\ntheir capacity for fast and parallel computation. The approximation\ncapabilities, or expressive power, of these methods have been extensively\nstudied over the past 35 years. In this paper, we will present examples of key\nideas in this area found in the literature. We will discuss emerging trends in\nmachine learning including the role of shallow/deep networks, approximation on\nmanifolds, physics-informed neural surrogates, neural operators, and\ntransformer architectures. Despite function approximation being a fundamental\nproblem in machine learning, approximation theory does not play a central role\nin the theoretical foundations of the field. One unfortunate consequence of\nthis disconnect is that it is often unclear how well trained models will\ngeneralize to unseen or unlabeled data. In this review, we examine some of the\nshortcomings of the current machine learning framework and explore the reasons\nfor the gap between approximation theory and machine learning practice. We will\nthen introduce our novel research to achieve function approximation on unknown\nmanifolds without the need to learn specific manifold features, such as the\neigen-decomposition of the Laplace-Beltrami operator or atlas construction. In\nmany machine learning problems, particularly classification tasks, the labels\n$y_j$ are drawn from a finite set of values.", "AI": {"tldr": "The paper reviews function approximation in machine learning, highlights gaps between theory and practice, and introduces a novel method for approximating functions on unknown manifolds.", "motivation": "To bridge the disconnect between approximation theory and machine learning practice, particularly in generalization and handling unknown manifolds.", "method": "Reviews existing approaches (neural networks, kernel methods) and introduces a new method for function approximation on manifolds without learning specific features.", "result": "Identifies shortcomings in current frameworks and proposes a solution for better generalization on unseen data.", "conclusion": "The paper emphasizes the need for integrating approximation theory into machine learning and presents a promising direction for future research."}}
{"id": "2506.02873", "pdf": "https://arxiv.org/pdf/2506.02873", "abs": "https://arxiv.org/abs/2506.02873", "authors": ["Matthew Kowal", "Jasper Timm", "Jean-Francois Godbout", "Thomas Costello", "Antonio A. Arechar", "Gordon Pennycook", "David Rand", "Adam Gleave", "Kellin Pelrine"], "title": "It's the Thought that Counts: Evaluating the Attempts of Frontier LLMs to Persuade on Harmful Topics", "categories": ["cs.AI"], "comment": null, "summary": "Persuasion is a powerful capability of large language models (LLMs) that both\nenables beneficial applications (e.g. helping people quit smoking) and raises\nsignificant risks (e.g. large-scale, targeted political manipulation). Prior\nwork has found models possess a significant and growing persuasive capability,\nmeasured by belief changes in simulated or real users. However, these\nbenchmarks overlook a crucial risk factor: the propensity of a model to attempt\nto persuade in harmful contexts. Understanding whether a model will blindly\n``follow orders'' to persuade on harmful topics (e.g. glorifying joining a\nterrorist group) is key to understanding the efficacy of safety guardrails.\nMoreover, understanding if and when a model will engage in persuasive behavior\nin pursuit of some goal is essential to understanding the risks from agentic AI\nsystems. We propose the Attempt to Persuade Eval (APE) benchmark, that shifts\nthe focus from persuasion success to persuasion attempts, operationalized as a\nmodel's willingness to generate content aimed at shaping beliefs or behavior.\nOur evaluation framework probes frontier LLMs using a multi-turn conversational\nsetup between simulated persuader and persuadee agents. APE explores a diverse\nspectrum of topics including conspiracies, controversial issues, and\nnon-controversially harmful content. We introduce an automated evaluator model\nto identify willingness to persuade and measure the frequency and context of\npersuasive attempts. We find that many open and closed-weight models are\nfrequently willing to attempt persuasion on harmful topics and that\njailbreaking can increase willingness to engage in such behavior. Our results\nhighlight gaps in current safety guardrails and underscore the importance of\nevaluating willingness to persuade as a key dimension of LLM risk. APE is\navailable at github.com/AlignmentResearch/AttemptPersuadeEval", "AI": {"tldr": "The paper introduces the Attempt to Persuade Eval (APE) benchmark to assess LLMs' willingness to persuade on harmful topics, revealing gaps in safety guardrails.", "motivation": "To address the overlooked risk of LLMs attempting persuasion in harmful contexts, such as glorifying terrorism, and evaluate the efficacy of safety measures.", "method": "APE uses a multi-turn conversational setup between simulated persuader and persuadee agents, probing LLMs on diverse topics, with an automated evaluator to measure persuasive attempts.", "result": "Many open and closed-weight LLMs frequently attempt persuasion on harmful topics, with jailbreaking increasing this behavior.", "conclusion": "APE highlights the need to evaluate willingness to persuade as a critical dimension of LLM risk, revealing gaps in current safety measures."}}
{"id": "2506.02442", "pdf": "https://arxiv.org/pdf/2506.02442", "abs": "https://arxiv.org/abs/2506.02442", "authors": ["Utsav Maskey", "Mark Dras", "Usman Naseem"], "title": "Should LLM Safety Be More Than Refusing Harmful Instructions?", "categories": ["cs.CL"], "comment": "Preprint", "summary": "This paper presents a systematic evaluation of Large Language Models' (LLMs)\nbehavior on long-tail distributed (encrypted) texts and their safety\nimplications. We introduce a two-dimensional framework for assessing LLM\nsafety: (1) instruction refusal-the ability to reject harmful obfuscated\ninstructions, and (2) generation safety-the suppression of generating harmful\nresponses. Through comprehensive experiments, we demonstrate that models that\npossess capabilities to decrypt ciphers may be susceptible to\nmismatched-generalization attacks: their safety mechanisms fail on at least one\nsafety dimension, leading to unsafe responses or over-refusal. Based on these\nfindings, we evaluate a number of pre-LLM and post-LLM safeguards and discuss\ntheir strengths and limitations. This work contributes to understanding the\nsafety of LLM in long-tail text scenarios and provides directions for\ndeveloping robust safety mechanisms.", "AI": {"tldr": "The paper evaluates LLM safety on long-tail encrypted texts, identifying vulnerabilities to mismatched-generalization attacks and assessing safeguards.", "motivation": "To understand LLM safety in long-tail text scenarios and improve robust safety mechanisms.", "method": "A two-dimensional framework assessing instruction refusal and generation safety through comprehensive experiments.", "result": "Models decrypting ciphers may fail on safety dimensions, leading to unsafe responses or over-refusal.", "conclusion": "The study highlights LLM safety gaps and guides future development of stronger safeguards."}}
{"id": "2506.02395", "pdf": "https://arxiv.org/pdf/2506.02395", "abs": "https://arxiv.org/abs/2506.02395", "authors": ["Xiaofeng Cong", "Yu-Xin Zhang", "Haoran Wei", "Yeying Jin", "Junming Hou", "Jie Gui", "Jing Zhang", "Dacheng Tao"], "title": "The Devil is in the Darkness: Diffusion-Based Nighttime Dehazing Anchored in Brightness Perception", "categories": ["cs.CV"], "comment": null, "summary": "While nighttime image dehazing has been extensively studied, converting\nnighttime hazy images to daytime-equivalent brightness remains largely\nunaddressed. Existing methods face two critical limitations: (1) datasets\noverlook the brightness relationship between day and night, resulting in the\nbrightness mapping being inconsistent with the real world during image\nsynthesis; and (2) models do not explicitly incorporate daytime brightness\nknowledge, limiting their ability to reconstruct realistic lighting. To address\nthese challenges, we introduce the Diffusion-Based Nighttime Dehazing (DiffND)\nframework, which excels in both data synthesis and lighting reconstruction. Our\napproach starts with a data synthesis pipeline that simulates severe\ndistortions while enforcing brightness consistency between synthetic and\nreal-world scenes, providing a strong foundation for learning night-to-day\nbrightness mapping. Next, we propose a restoration model that integrates a\npre-trained diffusion model guided by a brightness perception network. This\ndesign harnesses the diffusion model's generative ability while adapting it to\nnighttime dehazing through brightness-aware optimization. Experiments validate\nour dataset's utility and the model's superior performance in joint haze\nremoval and brightness mapping.", "AI": {"tldr": "The paper introduces DiffND, a framework for converting nighttime hazy images to daytime brightness, addressing data and model limitations in existing methods.", "motivation": "Existing methods fail to address brightness relationships between day and night and lack explicit daytime brightness knowledge, limiting realistic lighting reconstruction.", "method": "DiffND uses a data synthesis pipeline for brightness-consistent synthetic scenes and a restoration model combining a pre-trained diffusion model with a brightness perception network.", "result": "Experiments show the dataset's utility and the model's superior performance in haze removal and brightness mapping.", "conclusion": "DiffND effectively addresses nighttime dehazing challenges by integrating brightness-aware data synthesis and restoration."}}
{"id": "2506.02200", "pdf": "https://arxiv.org/pdf/2506.02200", "abs": "https://arxiv.org/abs/2506.02200", "authors": ["Shiangyi Lin", "Hui Lan", "Vasilis Syrgkanis"], "title": "Learning Treatment Representations for Downstream Instrumental Variable Regression", "categories": ["cs.LG", "stat.ME"], "comment": null, "summary": "Traditional instrumental variable (IV) estimators face a fundamental\nconstraint: they can only accommodate as many endogenous treatment variables as\navailable instruments. This limitation becomes particularly challenging in\nsettings where the treatment is presented in a high-dimensional and\nunstructured manner (e.g. descriptions of patient treatment pathways in a\nhospital). In such settings, researchers typically resort to applying\nunsupervised dimension reduction techniques to learn a low-dimensional\ntreatment representation prior to implementing IV regression analysis. We show\nthat such methods can suffer from substantial omitted variable bias due to\nimplicit regularization in the representation learning step. We propose a novel\napproach to construct treatment representations by explicitly incorporating\ninstrumental variables during the representation learning process. Our approach\nprovides a framework for handling high-dimensional endogenous variables with\nlimited instruments. We demonstrate both theoretically and empirically that\nfitting IV models on these instrument-informed representations ensures\nidentification of directions that optimize outcome prediction. Our experiments\nshow that our proposed methodology improves upon the conventional two-stage\napproaches that perform dimension reduction without incorporating instrument\ninformation.", "AI": {"tldr": "A novel approach addresses bias in IV estimators for high-dimensional treatments by incorporating instruments during representation learning, outperforming traditional methods.", "motivation": "Traditional IV estimators struggle with high-dimensional treatments due to limited instruments, leading to biased results when using unsupervised dimension reduction.", "method": "Proposes instrument-informed representation learning to construct treatment representations, ensuring identification of outcome-predictive directions.", "result": "Theoretically and empirically shows improved performance over conventional two-stage methods that ignore instrument information.", "conclusion": "The new framework effectively handles high-dimensional endogenous variables with limited instruments, reducing bias and improving prediction."}}
{"id": "2506.02918", "pdf": "https://arxiv.org/pdf/2506.02918", "abs": "https://arxiv.org/abs/2506.02918", "authors": ["Shangmin Guo", "Omar Darwiche Domingues", "Rapha\u00ebl Avalos", "Aaron Courville", "Florian Strub"], "title": "Sample, Predict, then Proceed: Self-Verification Sampling for Tool Use of LLMs", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "Tool use in stateful environments presents unique challenges for large\nlanguage models (LLMs), where existing test-time compute strategies relying on\nrepeated trials in the environment are impractical. We propose dynamics\nmodelling (DyMo), a method that augments LLMs with a state prediction\ncapability alongside function calling during post-training. This enables LLMs\nto predict the future states of their actions through an internal environment\nmodel. On the Berkeley Function Calling Leaderboard V2, DyMo improves success\nrates and significantly reduces hallucinations. We further integrate the\ninternal environment model into self-verification sampling (SVS), and show that\nthis substantially improves pass^k over number of trials k, and allows the\nmodel to refuse unreliable outputs. Together, DyMo and SVS greatly enhance the\neffectiveness and reliability of LLMs for tool use. We believe this work charts\na path towards scalable planning RL methods for LLM inference without\nrepeatedly querying the oracle environment.", "AI": {"tldr": "DyMo enhances LLMs with state prediction for tool use, reducing hallucinations and improving success rates. Combined with SVS, it boosts reliability and effectiveness.", "motivation": "Address challenges of LLMs in stateful environments where repeated trials are impractical.", "method": "DyMo adds state prediction and function calling post-training; integrates with SVS for self-verification.", "result": "Improves success rates, reduces hallucinations, and enhances pass^k over trials.", "conclusion": "DyMo and SVS advance LLM reliability for tool use, enabling scalable planning without repeated environment queries."}}
{"id": "2506.02449", "pdf": "https://arxiv.org/pdf/2506.02449", "abs": "https://arxiv.org/abs/2506.02449", "authors": ["Bo Peng", "Zhiheng Wang", "Heyang Gong", "Chaochao Lu"], "title": "IP-Dialog: Evaluating Implicit Personalization in Dialogue Systems with Synthetic Data", "categories": ["cs.CL", "cs.HC"], "comment": null, "summary": "In modern dialogue systems, the ability to implicitly infer user backgrounds\nfrom conversations and leverage this information for personalized assistance is\ncrucial. However, the scarcity of high-quality data remains a fundamental\nchallenge to evaluating and improving this capability. Traditional dataset\nconstruction methods are labor-intensive, resource-demanding, and raise privacy\nconcerns. To address these issues, we propose a novel approach for automatic\nsynthetic data generation and introduce the Implicit Personalized Dialogue\n(IP-Dialog) benchmark along with a training dataset, covering 10 tasks and 12\nuser attribute types. Additionally, we develop a systematic evaluation\nframework with four metrics to assess both attribute awareness and reasoning\ncapabilities. We further propose five causal graphs to elucidate models'\nreasoning pathways during implicit personalization. Extensive experiments yield\ninsightful observations and prove the reliability of our dataset.", "AI": {"tldr": "The paper proposes an automatic synthetic data generation method to address the scarcity of high-quality data for personalized dialogue systems, introducing the IP-Dialog benchmark and a systematic evaluation framework.", "motivation": "The challenge of evaluating and improving the ability of dialogue systems to infer user backgrounds implicitly due to data scarcity, labor-intensive traditional methods, and privacy concerns.", "method": "A novel approach for automatic synthetic data generation, creation of the IP-Dialog benchmark (10 tasks, 12 user attribute types), and a systematic evaluation framework with four metrics and five causal graphs.", "result": "Extensive experiments validate the reliability of the dataset and provide insightful observations on models' reasoning pathways.", "conclusion": "The proposed method and benchmark effectively address data scarcity and improve the evaluation of implicit personalization in dialogue systems."}}
{"id": "2506.02396", "pdf": "https://arxiv.org/pdf/2506.02396", "abs": "https://arxiv.org/abs/2506.02396", "authors": ["Longyu Yang", "Ping Hu", "Shangbo Yuan", "Lu Zhang", "Jun Liu", "Hengtao Shen", "Xiaofeng Zhu"], "title": "Towards Explicit Geometry-Reflectance Collaboration for Generalized LiDAR Segmentation in Adverse Weather", "categories": ["cs.CV"], "comment": null, "summary": "Existing LiDAR semantic segmentation models often suffer from decreased\naccuracy when exposed to adverse weather conditions. Recent methods addressing\nthis issue focus on enhancing training data through weather simulation or\nuniversal augmentation techniques. However, few works have studied the negative\nimpacts caused by the heterogeneous domain shifts in the geometric structure\nand reflectance intensity of point clouds. In this paper, we delve into this\nchallenge and address it with a novel Geometry-Reflectance Collaboration (GRC)\nframework that explicitly separates feature extraction for geometry and\nreflectance. Specifically, GRC employs a dual-branch architecture designed to\nindependently process geometric and reflectance features initially, thereby\ncapitalizing on their distinct characteristic. Then, GRC adopts a robust\nmulti-level feature collaboration module to suppress redundant and unreliable\ninformation from both branches. Consequently, without complex simulation or\naugmentation, our method effectively extracts intrinsic information about the\nscene while suppressing interference, thus achieving better robustness and\ngeneralization in adverse weather conditions. We demonstrate the effectiveness\nof GRC through comprehensive experiments on challenging benchmarks, showing\nthat our method outperforms previous approaches and establishes new\nstate-of-the-art results.", "AI": {"tldr": "A novel Geometry-Reflectance Collaboration (GRC) framework improves LiDAR semantic segmentation in adverse weather by separately processing geometric and reflectance features and collaborating them robustly.", "motivation": "Existing models struggle with accuracy in adverse weather due to heterogeneous domain shifts in point clouds' geometry and reflectance.", "method": "GRC uses a dual-branch architecture to independently process geometry and reflectance features, followed by a multi-level feature collaboration module to filter redundant information.", "result": "GRC outperforms previous methods, achieving state-of-the-art results without complex simulation or augmentation.", "conclusion": "GRC effectively enhances robustness and generalization in adverse weather by leveraging intrinsic scene information."}}
{"id": "2506.02203", "pdf": "https://arxiv.org/pdf/2506.02203", "abs": "https://arxiv.org/abs/2506.02203", "authors": ["Navid NaderiAlizadeh", "Darian Salehi", "Xinran Liu", "Soheil Kolouri"], "title": "Constrained Sliced Wasserstein Embedding", "categories": ["cs.LG", "cs.AI", "math.OC", "q-bio.QM", "stat.ML"], "comment": null, "summary": "Sliced Wasserstein (SW) distances offer an efficient method for comparing\nhigh-dimensional probability measures by projecting them onto multiple\n1-dimensional probability distributions. However, identifying informative\nslicing directions has proven challenging, often necessitating a large number\nof slices to achieve desirable performance and thereby increasing computational\ncomplexity. We introduce a constrained learning approach to optimize the\nslicing directions for SW distances. Specifically, we constrain the 1D\ntransport plans to approximate the optimal plan in the original space, ensuring\nmeaningful slicing directions. By leveraging continuous relaxations of these\ntransport plans, we enable a gradient-based primal-dual approach to train the\nslicer parameters, alongside the remaining model parameters. We demonstrate how\nthis constrained slicing approach can be applied to pool high-dimensional\nembeddings into fixed-length permutation-invariant representations. Numerical\nresults on foundation models trained on images, point clouds, and protein\nsequences showcase the efficacy of the proposed constrained learning approach\nin learning more informative slicing directions. Our implementation code can be\nfound at https://github.com/Stranja572/constrainedswe.", "AI": {"tldr": "The paper introduces a constrained learning approach to optimize slicing directions for Sliced Wasserstein (SW) distances, improving efficiency and reducing computational complexity.", "motivation": "Identifying informative slicing directions for SW distances is challenging, often requiring many slices and increasing computational costs.", "method": "A constrained learning approach is proposed, where 1D transport plans approximate the optimal plan in the original space. Gradient-based primal-dual training is used for slicer parameters.", "result": "The method effectively learns informative slicing directions, demonstrated on foundation models for images, point clouds, and protein sequences.", "conclusion": "The constrained learning approach enhances SW distance performance by optimizing slicing directions, with practical applications in high-dimensional data."}}
{"id": "2506.02923", "pdf": "https://arxiv.org/pdf/2506.02923", "abs": "https://arxiv.org/abs/2506.02923", "authors": ["Alexis Bellot", "Jonathan Richens", "Tom Everitt"], "title": "The Limits of Predicting Agents from Behaviour", "categories": ["cs.AI", "stat.ML"], "comment": null, "summary": "As the complexity of AI systems and their interactions with the world\nincreases, generating explanations for their behaviour is important for safely\ndeploying AI. For agents, the most natural abstractions for predicting\nbehaviour attribute beliefs, intentions and goals to the system. If an agent\nbehaves as if it has a certain goal or belief, then we can make reasonable\npredictions about how it will behave in novel situations, including those where\ncomprehensive safety evaluations are untenable. How well can we infer an\nagent's beliefs from their behaviour, and how reliably can these inferred\nbeliefs predict the agent's behaviour in novel situations? We provide a precise\nanswer to this question under the assumption that the agent's behaviour is\nguided by a world model. Our contribution is the derivation of novel bounds on\nthe agent's behaviour in new (unseen) deployment environments, which represent\na theoretical limit for predicting intentional agents from behavioural data\nalone. We discuss the implications of these results for several research areas\nincluding fairness and safety.", "AI": {"tldr": "The paper explores how well an agent's beliefs can be inferred from its behavior and how reliably these beliefs predict behavior in new situations, providing theoretical bounds for such predictions.", "motivation": "Understanding and predicting AI behavior is crucial for safe deployment, especially in novel situations where comprehensive safety evaluations are impractical.", "method": "The study assumes the agent's behavior is guided by a world model and derives novel bounds on behavior in unseen environments.", "result": "The paper establishes theoretical limits for predicting intentional agents from behavioral data alone.", "conclusion": "The findings have implications for fairness and safety in AI research, highlighting the limits of behavioral prediction."}}
{"id": "2506.02454", "pdf": "https://arxiv.org/pdf/2506.02454", "abs": "https://arxiv.org/abs/2506.02454", "authors": ["Zhaorui Yang", "Bo Pan", "Han Wang", "Yiyao Wang", "Xingyu Liu", "Minfeng Zhu", "Bo Zhang", "Wei Chen"], "title": "Multimodal DeepResearcher: Generating Text-Chart Interleaved Reports From Scratch with Agentic Framework", "categories": ["cs.CL", "cs.AI"], "comment": "47 pages", "summary": "Visualizations play a crucial part in effective communication of concepts and\ninformation. Recent advances in reasoning and retrieval augmented generation\nhave enabled Large Language Models (LLMs) to perform deep research and generate\ncomprehensive reports. Despite its progress, existing deep research frameworks\nprimarily focus on generating text-only content, leaving the automated\ngeneration of interleaved texts and visualizations underexplored. This novel\ntask poses key challenges in designing informative visualizations and\neffectively integrating them with text reports. To address these challenges, we\npropose Formal Description of Visualization (FDV), a structured textual\nrepresentation of charts that enables LLMs to learn from and generate diverse,\nhigh-quality visualizations. Building on this representation, we introduce\nMultimodal DeepResearcher, an agentic framework that decomposes the task into\nfour stages: (1) researching, (2) exemplar report textualization, (3) planning,\nand (4) multimodal report generation. For the evaluation of generated\nmultimodal reports, we develop MultimodalReportBench, which contains 100\ndiverse topics served as inputs along with 5 dedicated metrics. Extensive\nexperiments across models and evaluation methods demonstrate the effectiveness\nof Multimodal DeepResearcher. Notably, utilizing the same Claude 3.7 Sonnet\nmodel, Multimodal DeepResearcher achieves an 82\\% overall win rate over the\nbaseline method.", "AI": {"tldr": "The paper proposes a framework (Multimodal DeepResearcher) and a structured representation (FDV) to enable LLMs to generate interleaved text and visualizations, addressing a gap in existing deep research frameworks.", "motivation": "Existing deep research frameworks focus on text-only content, leaving automated generation of multimodal (text and visualization) reports underexplored.", "method": "Introduces FDV for structured visualization representation and Multimodal DeepResearcher, a four-stage framework (researching, exemplar report textualization, planning, multimodal report generation).", "result": "Multimodal DeepResearcher achieves an 82% win rate over baselines using Claude 3.7 Sonnet, evaluated on MultimodalReportBench with 100 topics and 5 metrics.", "conclusion": "The proposed framework effectively addresses the challenge of generating high-quality multimodal reports, demonstrating significant improvement over existing methods."}}
{"id": "2506.02405", "pdf": "https://arxiv.org/pdf/2506.02405", "abs": "https://arxiv.org/abs/2506.02405", "authors": ["Zhiya Tan", "Xin Zhang", "Joey Tianyi Zhou"], "title": "Modelship Attribution: Tracing Multi-Stage Manipulations Across Generative Models", "categories": ["cs.CV"], "comment": null, "summary": "As generative techniques become increasingly accessible, authentic visuals\nare frequently subjected to iterative alterations by various individuals\nemploying a variety of tools. Currently, to avoid misinformation and ensure\naccountability, a lot of research on detection and attribution is emerging.\nAlthough these methods demonstrate promise in single-stage manipulation\nscenarios, they fall short when addressing complex real-world iterative\nmanipulation. In this paper, we are the first, to the best of our knowledge, to\nsystematically model this real-world challenge and introduce a novel method to\nsolve it. We define a task called \"Modelship Attribution\", which aims to trace\nthe evolution of manipulated images by identifying the generative models\ninvolved and reconstructing the sequence of edits they performed. To\nrealistically simulate this scenario, we utilize three generative models,\nStyleMapGAN, DiffSwap, and FacePartsSwap, that sequentially modify distinct\nregions of the same image. This process leads to the creation of the first\nmodelship dataset, comprising 83,700 images (16,740 images*5). Given that later\nedits often overwrite the fingerprints of earlier models, the focus shifts from\nextracting blended fingerprints to characterizing each model's distinctive\nediting patterns. To tackle this challenge, we introduce the modelship\nattribution transformer (MAT), a purpose-built framework designed to\neffectively recognize and attribute the contributions of various models within\ncomplex, multi-stage manipulation workflows. Through extensive experiments and\ncomparative analysis with other related methods, our results, including\ncomprehensive ablation studies, demonstrate that the proposed approach is a\nhighly effective solution for modelship attribution.", "AI": {"tldr": "The paper introduces 'Modelship Attribution' to trace iterative image manipulations by identifying generative models and reconstructing edit sequences, proposing a novel transformer-based framework (MAT) for effective attribution.", "motivation": "Existing detection methods fail in complex iterative manipulation scenarios, necessitating a systematic approach to trace model contributions and edit sequences.", "method": "The authors simulate iterative edits using three generative models (StyleMapGAN, DiffSwap, FacePartsSwap) to create a dataset (83,700 images) and propose MAT, a transformer-based framework, to recognize and attribute model contributions.", "result": "MAT outperforms related methods in attributing multi-stage manipulations, validated through extensive experiments and ablation studies.", "conclusion": "The proposed MAT framework effectively addresses the challenge of modelship attribution in iterative manipulation, offering a robust solution for real-world applications."}}
{"id": "2506.02205", "pdf": "https://arxiv.org/pdf/2506.02205", "abs": "https://arxiv.org/abs/2506.02205", "authors": ["Yuliang Gu", "Hongpeng Cao", "Marco Caccamo", "Naira Hovakimyan"], "title": "Bregman Centroid Guided Cross-Entropy Method", "categories": ["cs.LG", "cs.AI", "cs.SY", "eess.SY"], "comment": null, "summary": "The Cross-Entropy Method (CEM) is a widely adopted trajectory optimizer in\nmodel-based reinforcement learning (MBRL), but its unimodal sampling strategy\noften leads to premature convergence in multimodal landscapes. In this work, we\npropose Bregman Centroid Guided CEM ($\\mathcal{BC}$-EvoCEM), a lightweight\nenhancement to ensemble CEM that leverages $\\textit{Bregman centroids}$ for\nprincipled information aggregation and diversity control.\n$\\textbf{$\\mathcal{BC}$-EvoCEM}$ computes a performance-weighted Bregman\ncentroid across CEM workers and updates the least contributing ones by sampling\nwithin a trust region around the centroid. Leveraging the duality between\nBregman divergences and exponential family distributions, we show that\n$\\textbf{$\\mathcal{BC}$-EvoCEM}$ integrates seamlessly into standard CEM\npipelines with negligible overhead. Empirical results on synthetic benchmarks,\na cluttered navigation task, and full MBRL pipelines demonstrate that\n$\\textbf{$\\mathcal{BC}$-EvoCEM}$ enhances both convergence and solution\nquality, providing a simple yet effective upgrade for CEM.", "AI": {"tldr": "BC-EvoCEM enhances CEM in MBRL by using Bregman centroids for better diversity and convergence, improving performance with minimal overhead.", "motivation": "CEM's unimodal sampling often converges prematurely in multimodal landscapes, limiting its effectiveness in MBRL.", "method": "BC-EvoCEM aggregates information and controls diversity using Bregman centroids, updating low-contributing workers via trust-region sampling.", "result": "Empirical tests show BC-EvoCEM improves convergence and solution quality in synthetic benchmarks, navigation tasks, and MBRL pipelines.", "conclusion": "BC-EvoCEM is a lightweight, effective upgrade to CEM, enhancing its performance without significant overhead."}}
{"id": "2506.02949", "pdf": "https://arxiv.org/pdf/2506.02949", "abs": "https://arxiv.org/abs/2506.02949", "authors": ["Lixiang Xu", "Xianwei Ding", "Xin Yuan", "Richang Hong", "Feiping Nie", "Enhong Chen", "Philip S. Yu"], "title": "Dynamic Programming Techniques for Enhancing Cognitive Representation in Knowledge Tracing", "categories": ["cs.AI"], "comment": null, "summary": "Knowledge Tracing (KT) involves monitoring the changes in a student's\nknowledge over time by analyzing their past responses, with the goal of\npredicting future performance. However, most existing methods primarily focus\non feature enhancement, while overlooking the deficiencies in cognitive\nrepresentation and the ability to express cognition-issues often caused by\ninterference from non-cognitive factors such as slipping and guessing. This\nlimitation hampers the ability to capture the continuity and coherence of the\nstudent's cognitive process. As a result, many methods may introduce more\nprediction bias and modeling costs due to their inability to maintain cognitive\ncontinuity and coherence. Based on the above discussion, we propose the\nCognitive Representation Dynamic Programming based Knowledge Tracing (CRDP-KT)\nmodel. This model em ploys a dynamic programming algorithm to optimize\ncognitive representations based on the difficulty of the questions and the\nperformance intervals between them. This approach ensures that the cognitive\nrepresentation aligns with the student's cognitive patterns, maintaining\noverall continuity and coherence. As a result, it provides more accurate and\nsystematic input features for subsequent model training, thereby minimizing\ndistortion in the simulation of cognitive states. Additionally, the CRDP-KT\nmodel performs partitioned optimization of cognitive representations to enhance\nthe reliability of the optimization process. Furthermore, it improves its\nability to express the student's cognition through a weighted fusion of\noptimized record representations and re lationships learned from a bipartite\ngraph. Finally, experiments conducted on three public datasets validate the\neffectiveness of the proposed CRDP-KT model.", "AI": {"tldr": "The paper introduces CRDP-KT, a model using dynamic programming to optimize cognitive representations in Knowledge Tracing, addressing biases from non-cognitive factors and improving prediction accuracy.", "motivation": "Existing KT methods focus on feature enhancement but neglect cognitive representation issues caused by non-cognitive factors like slipping and guessing, leading to prediction bias and modeling inefficiencies.", "method": "The CRDP-KT model employs dynamic programming to align cognitive representations with student patterns, optimizes representations partitionedly, and uses weighted fusion for better cognition expression.", "result": "Experiments on three public datasets confirm the model's effectiveness in maintaining cognitive continuity and coherence, reducing prediction bias.", "conclusion": "CRDP-KT enhances KT by optimizing cognitive representations, improving accuracy and reliability in predicting student performance."}}
{"id": "2506.02460", "pdf": "https://arxiv.org/pdf/2506.02460", "abs": "https://arxiv.org/abs/2506.02460", "authors": ["Yupeng Qi", "Ziyu Lyu", "Min Yang", "Yanlin Wang", "Lu Bai", "Lixin Cui"], "title": "MidPO: Dual Preference Optimization for Safety and Helpfulness in Large Language Models via a Mixture of Experts Framework", "categories": ["cs.CL"], "comment": null, "summary": "As large language models (LLMs) are increasingly applied across various\ndomains, enhancing safety while maintaining the helpfulness of LLMs has become\na critical challenge. Recent studies solve this problem through\nsafety-constrained online preference optimization or safety-constrained offline\npreference optimization. However, the safety-constrained online methods often\nsuffer from excessive safety, which might reduce helpfulness, while the\nsafety-constrained offline methods perform poorly in adaptively balancing\nsafety and helpfulness. To address these limitations, we propose MidPO, a\n\\textbf{\\underline{Mi}}xture of Experts (MoE) framework for safety-helpfulness\n\\textbf{\\underline{d}}ual \\textbf{\\underline{P}}reference\n\\textbf{\\underline{O}}ptimization. Firstly, MidPO devises single-preference\nenhanced direct preference optimization approach to transform the base model\ninto two independent experts, termed safety and helpfulness experts, and\nfine-tunes the two independent experts for optimal safety or helpfulness\nperformance. Secondly, to achieve an effective balance between safety and\nhelpfulness, MidPO incorporates the two experts into the MoE framework and\ndesigns a dynamic routing mechanism to allocate contributions from each expert\nadaptively. We conduct quantitative and qualitative experiments on three\npopular datasets to demonstrate the proposed MidPO significantly outperforms\nstate-of-the-art approaches in both safety and helpfulness. The code and models\nwill be released.", "AI": {"tldr": "MidPO is a Mixture of Experts framework for balancing safety and helpfulness in LLMs, outperforming existing methods.", "motivation": "Enhancing LLM safety without compromising helpfulness is a critical challenge, as current methods either over-prioritize safety or lack adaptability.", "method": "MidPO uses a dual-preference optimization approach, creating safety and helpfulness experts, and integrates them via a dynamic routing mechanism in a MoE framework.", "result": "MidPO outperforms state-of-the-art methods in both safety and helpfulness on three datasets.", "conclusion": "MidPO effectively balances safety and helpfulness in LLMs, offering a superior solution to current limitations."}}
{"id": "2506.02408", "pdf": "https://arxiv.org/pdf/2506.02408", "abs": "https://arxiv.org/abs/2506.02408", "authors": ["Wenhao Tang", "Rong Qin", "Heng Fang", "Fengtao Zhou", "Hao Chen", "Xiang Li", "Ming-Ming Cheng"], "title": "Revisiting End-to-End Learning with Slide-level Supervision in Computational Pathology", "categories": ["cs.CV"], "comment": null, "summary": "Pre-trained encoders for offline feature extraction followed by multiple\ninstance learning (MIL) aggregators have become the dominant paradigm in\ncomputational pathology (CPath), benefiting cancer diagnosis and prognosis.\nHowever, performance limitations arise from the absence of encoder fine-tuning\nfor downstream tasks and disjoint optimization with MIL. While slide-level\nsupervised end-to-end (E2E) learning is an intuitive solution to this issue, it\nfaces challenges such as high computational demands and suboptimal results.\nThese limitations motivate us to revisit E2E learning. We argue that prior work\nneglects inherent E2E optimization challenges, leading to performance\ndisparities compared to traditional two-stage methods. In this paper, we\npioneer the elucidation of optimization challenge caused by sparse-attention\nMIL and propose a novel MIL called ABMILX. It mitigates this problem through\nglobal correlation-based attention refinement and multi-head mechanisms. With\nthe efficient multi-scale random patch sampling strategy, an E2E trained ResNet\nwith ABMILX surpasses SOTA foundation models under the two-stage paradigm\nacross multiple challenging benchmarks, while remaining computationally\nefficient (<10 RTX3090 hours). We show the potential of E2E learning in CPath\nand calls for greater research focus in this area. The code is\nhttps://github.com/DearCaat/E2E-WSI-ABMILX.", "AI": {"tldr": "The paper introduces ABMILX, a novel MIL method, to address optimization challenges in E2E learning for computational pathology, outperforming SOTA models.", "motivation": "Limitations in current methods (disjoint optimization, high computational demands) motivate revisiting E2E learning for better performance in computational pathology.", "method": "Proposes ABMILX, which refines attention via global correlation and multi-head mechanisms, paired with multi-scale random patch sampling for efficiency.", "result": "ABMILX with E2E training surpasses SOTA foundation models in benchmarks, achieving high performance with low computational cost (<10 RTX3090 hours).", "conclusion": "E2E learning with ABMILX shows promise in computational pathology, urging more research focus in this direction."}}
{"id": "2506.02208", "pdf": "https://arxiv.org/pdf/2506.02208", "abs": "https://arxiv.org/abs/2506.02208", "authors": ["Hongling Xu", "Qi Zhu", "Heyuan Deng", "Jinpeng Li", "Lu Hou", "Yasheng Wang", "Lifeng Shang", "Ruifeng Xu", "Fei Mi"], "title": "KDRL: Post-Training Reasoning LLMs via Unified Knowledge Distillation and Reinforcement Learning", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": null, "summary": "Recent advances in large language model (LLM) post-training have leveraged\ntwo distinct paradigms to enhance reasoning capabilities: reinforcement\nlearning (RL) and knowledge distillation (KD). While RL enables the emergence\nof complex reasoning behaviors, it often suffers from low sample efficiency\nwhen the initial policy struggles to explore high-reward trajectories.\nConversely, KD improves learning efficiency via mimicking the teacher model but\ntends to generalize poorly to out-of-domain scenarios. In this work, we present\n\\textbf{KDRL}, a \\textit{unified post-training framework} that jointly\noptimizes a reasoning model through teacher supervision (KD) and\nself-exploration (RL). Specifically, KDRL leverages policy gradient\noptimization to simultaneously minimize the reverse Kullback-Leibler divergence\n(RKL) between the student and teacher distributions while maximizing the\nexpected rule-based rewards. We first formulate a unified objective that\nintegrates GRPO and KD, and systematically explore how different KL\napproximations, KL coefficients, and reward-guided KD strategies affect the\noverall post-training dynamics and performance. Empirical results on multiple\nreasoning benchmarks demonstrate that KDRL outperforms GRPO and various KD\nbaselines while achieving a favorable balance between performance and reasoning\ntoken efficiency. These findings indicate that integrating KD and RL serves as\nan effective and efficient strategy to train reasoning LLMs.", "AI": {"tldr": "KDRL combines knowledge distillation (KD) and reinforcement learning (RL) to enhance LLM reasoning, outperforming standalone methods by balancing efficiency and performance.", "motivation": "Address the limitations of RL (low sample efficiency) and KD (poor generalization) by integrating both paradigms.", "method": "KDRL unifies KD and RL, optimizing via policy gradient to minimize RKL divergence and maximize rule-based rewards.", "result": "Outperforms GRPO and KD baselines on reasoning benchmarks, balancing performance and token efficiency.", "conclusion": "Integrating KD and RL is effective and efficient for training reasoning LLMs."}}
{"id": "2506.02992", "pdf": "https://arxiv.org/pdf/2506.02992", "abs": "https://arxiv.org/abs/2506.02992", "authors": ["Li Zhang", "Kevin D. Ashley"], "title": "Mitigating Manipulation and Enhancing Persuasion: A Reflective Multi-Agent Approach for Legal Argument Generation", "categories": ["cs.AI", "cs.CL", "cs.LG", "68T50", "I.2"], "comment": "13 pages, 2 figures, Workshop on Legally Compliant Intelligent\n  Chatbots at ICAIL 2025]{Workshop on Legally Compliant Intelligent Chatbots @\n  ICAIL 2025", "summary": "Large Language Models (LLMs) are increasingly explored for legal argument\ngeneration, yet they pose significant risks of manipulation through\nhallucination and ungrounded persuasion, and often fail to utilize provided\nfactual bases effectively or abstain when arguments are untenable. This paper\nintroduces a novel reflective multi-agent method designed to address these\nchallenges in the context of legally compliant persuasion. Our approach employs\nspecialized agents--a Factor Analyst and an Argument Polisher--in an iterative\nrefinement process to generate 3-ply legal arguments (plaintiff, defendant,\nrebuttal). We evaluate Reflective Multi-Agent against single-agent,\nenhanced-prompt single-agent, and non-reflective multi-agent baselines using\nfour diverse LLMs (GPT-4o, GPT-4o-mini, Llama-4-Maverick-17b-128e,\nLlama-4-Scout-17b-16e) across three legal scenarios: \"arguable\", \"mismatched\",\nand \"non-arguable\". Results demonstrate Reflective Multi-Agent's significant\nsuperiority in successful abstention (preventing generation when arguments\ncannot be grounded), marked improvements in hallucination accuracy (reducing\nfabricated and misattributed factors), particularly in \"non-arguable\"\nscenarios, and enhanced factor utilization recall (improving the use of\nprovided case facts). These findings suggest that structured reflection within\na multi-agent framework offers a robust computable method for fostering ethical\npersuasion and mitigating manipulation in LLM-based legal argumentation\nsystems, a critical step towards trustworthy AI in law. Project page:\nhttps://lizhang-aiandlaw.github.io/A-Reflective-Multi-Agent-Approach-for-Legal-Argument-Generation/", "AI": {"tldr": "The paper introduces a reflective multi-agent method to improve legal argument generation by LLMs, addressing issues like hallucination and ungrounded persuasion. It outperforms baselines in abstention, accuracy, and fact utilization.", "motivation": "LLMs in legal argumentation risk manipulation through hallucination and poor fact usage. This work aims to ensure ethical, grounded persuasion.", "method": "A multi-agent system (Factor Analyst and Argument Polisher) iteratively refines 3-ply legal arguments. Evaluated across diverse LLMs and legal scenarios.", "result": "Outperforms baselines in abstention, reduces hallucination, and improves fact recall, especially in \"non-arguable\" cases.", "conclusion": "Structured multi-agent reflection enhances ethical persuasion in legal LLMs, advancing trustworthy AI in law."}}
{"id": "2506.02461", "pdf": "https://arxiv.org/pdf/2506.02461", "abs": "https://arxiv.org/abs/2506.02461", "authors": ["Chunkit Chan", "Yauwai Yim", "Hongchuan Zeng", "Zhiying Zou", "Xinyuan Cheng", "Zhifan Sun", "Zheye Deng", "Kawai Chung", "Yuzhuo Ao", "Yixiang Fan", "Cheng Jiayang", "Ercong Nie", "Ginny Y. Wong", "Helmut Schmid", "Hinrich Sch\u00fctze", "Simon See", "Yangqiu Song"], "title": "XToM: Exploring the Multilingual Theory of Mind for Large Language Models", "categories": ["cs.CL"], "comment": null, "summary": "Theory of Mind (ToM), the ability to infer mental states in others, is\npivotal for human social cognition. Existing evaluations of ToM in LLMs are\nlargely limited to English, neglecting the linguistic diversity that shapes\nhuman cognition. This limitation raises a critical question: can LLMs exhibit\nMultilingual Theory of Mind, which is the capacity to reason about mental\nstates across diverse linguistic contexts? To address this gap, we present\nXToM, a rigorously validated multilingual benchmark that evaluates ToM across\nfive languages and incorporates diverse, contextually rich task scenarios.\nUsing XToM, we systematically evaluate LLMs (e.g., DeepSeek R1), revealing a\npronounced dissonance: while models excel in multilingual language\nunderstanding, their ToM performance varies across languages. Our findings\nexpose limitations in LLMs' ability to replicate human-like mentalizing across\nlinguistic contexts.", "AI": {"tldr": "XToM is a multilingual benchmark evaluating LLMs' Theory of Mind (ToM) across five languages, revealing performance disparities despite strong multilingual language understanding.", "motivation": "Existing ToM evaluations in LLMs are limited to English, ignoring linguistic diversity's impact on cognition.", "method": "Developed XToM, a validated multilingual benchmark with diverse task scenarios, to assess LLMs like DeepSeek R1.", "result": "LLMs show strong multilingual language understanding but inconsistent ToM performance across languages.", "conclusion": "LLMs struggle to replicate human-like mentalizing across diverse linguistic contexts."}}
{"id": "2506.02419", "pdf": "https://arxiv.org/pdf/2506.02419", "abs": "https://arxiv.org/abs/2506.02419", "authors": ["Nurislam Tursynbek", "Hastings Greer", "Basar Demir", "Marc Niethammer"], "title": "Guiding Registration with Emergent Similarity from Pre-Trained Diffusion Models", "categories": ["cs.CV"], "comment": "MICCAI 2025", "summary": "Diffusion models, while trained for image generation, have emerged as\npowerful foundational feature extractors for downstream tasks. We find that\noff-the-shelf diffusion models, trained exclusively to generate natural RGB\nimages, can identify semantically meaningful correspondences in medical images.\nBuilding on this observation, we propose to leverage diffusion model features\nas a similarity measure to guide deformable image registration networks. We\nshow that common intensity-based similarity losses often fail in challenging\nscenarios, such as when certain anatomies are visible in one image but absent\nin another, leading to anatomically inaccurate alignments. In contrast, our\nmethod identifies true semantic correspondences, aligning meaningful structures\nwhile disregarding those not present across images. We demonstrate superior\nperformance of our approach on two tasks: multimodal 2D registration (DXA to\nX-Ray) and monomodal 3D registration (brain-extracted to non-brain-extracted\nMRI). Code: https://github.com/uncbiag/dgir", "AI": {"tldr": "Diffusion models, trained for image generation, can extract meaningful features for medical image registration, outperforming traditional intensity-based methods.", "motivation": "Traditional intensity-based similarity losses often fail in challenging medical image registration scenarios, such as when certain anatomies are missing in one image.", "method": "The paper proposes using diffusion model features as a similarity measure to guide deformable image registration networks.", "result": "The method shows superior performance in multimodal 2D (DXA to X-Ray) and monomodal 3D (brain-extracted to non-brain-extracted MRI) registration tasks.", "conclusion": "Diffusion models provide a robust alternative for semantic correspondence in medical image registration, improving accuracy over traditional methods."}}
{"id": "2506.02210", "pdf": "https://arxiv.org/pdf/2506.02210", "abs": "https://arxiv.org/abs/2506.02210", "authors": ["Pu", "Yi", "Tianlang Chen", "Yifan Yang", "Sara Achour"], "title": "Exchangeability in Neural Network Architectures and its Application to Dynamic Pruning", "categories": ["cs.LG", "cs.AI", "cs.PF"], "comment": null, "summary": "Neural networks (NNs) are equipped with increasingly many parameters and\nrequire more and more resource for deployment. Researchers have explored\nvarious ways to improve the efficiency of NNs by identifying and reducing the\nredundancy, such as pruning or quantizing unimportant weights. Symmetry in the\nNN architectures has been identified by prior work as a possible type of\nredundancy, but exploiting it for efficient inference is not yet explored. In\nthis work, we formalize the symmetry of parameters and intermediate values in\nNNs using the statistical property of exchangeablility. We identify that\nexchangeable values in NN computation may contain overlapping information,\nleading to redundancy. Exploiting the insight, we derive a principled general\ndynamic pruning algorithm ExPrune to remove symmetry-induced redundancy on a\nper-input basis. We also provide an instantiation of ExPrune that performs\nneuron-level dynamic pruning by predicting negative inputs to ReLU activations.\nWe evaluate ExPrune on two computer vision models, one graph model and one\nlanguage model. ExPrune provides 10.98--26.3% reduction in FLOPs with\nnegligible accuracy drop and 21.01--39.05% reduction in FLOPs with at most 1%\naccuracy drop. We also demonstrate that ExPrune composes with static pruning.\nOn models that have been aggressively pruned statically, ExPrune provides\nadditional 10.24--11.11% reduction in FLOPs with negligible accuracy drop and\n13.91--14.39% reduction in FLOPs with at most 1% accuracy drop.", "AI": {"tldr": "The paper introduces ExPrune, a dynamic pruning algorithm that exploits symmetry-induced redundancy in neural networks (NNs) to improve efficiency, achieving significant FLOPs reduction with minimal accuracy loss.", "motivation": "Neural networks are resource-intensive, and existing methods like pruning or quantizing weights address redundancy but overlook symmetry. This work aims to exploit symmetry for efficient inference.", "method": "The authors formalize symmetry using exchangeability, identify redundancy in exchangeable values, and develop ExPrune, a dynamic pruning algorithm. They also provide a neuron-level instantiation of ExPrune for ReLU activations.", "result": "ExPrune reduces FLOPs by 10.98--39.05% with negligible to 1% accuracy drop across various models. It also complements static pruning, offering additional FLOPs reductions.", "conclusion": "ExPrune effectively exploits symmetry-induced redundancy, providing a scalable solution for efficient NN inference while maintaining accuracy."}}
{"id": "2506.02996", "pdf": "https://arxiv.org/pdf/2506.02996", "abs": "https://arxiv.org/abs/2506.02996", "authors": ["Matthieu Tehenan", "Christian Bolivar Moya", "Tenghai Long", "Guang Lin"], "title": "Linear Spatial World Models Emerge in Large Language Models", "categories": ["cs.AI"], "comment": null, "summary": "Large language models (LLMs) have demonstrated emergent abilities across\ndiverse tasks, raising the question of whether they acquire internal world\nmodels. In this work, we investigate whether LLMs implicitly encode linear\nspatial world models, which we define as linear representations of physical\nspace and object configurations. We introduce a formal framework for spatial\nworld models and assess whether such structure emerges in contextual\nembeddings. Using a synthetic dataset of object positions, we train probes to\ndecode object positions and evaluate geometric consistency of the underlying\nspace. We further conduct causal interventions to test whether these spatial\nrepresentations are functionally used by the model. Our results provide\nempirical evidence that LLMs encode linear spatial world models.", "AI": {"tldr": "LLMs encode linear spatial world models, as evidenced by empirical testing of their contextual embeddings.", "motivation": "To determine if LLMs acquire internal world models, specifically linear spatial representations.", "method": "Introduced a formal framework for spatial world models, trained probes on synthetic object positions, and conducted causal interventions.", "result": "Empirical evidence shows LLMs encode linear spatial world models.", "conclusion": "LLMs implicitly represent linear spatial configurations, suggesting internal world model acquisition."}}
{"id": "2506.02478", "pdf": "https://arxiv.org/pdf/2506.02478", "abs": "https://arxiv.org/abs/2506.02478", "authors": ["Zijian Li", "Xiaocheng Feng", "Huixin Liu", "Yichong Huang", "Ting Liu", "Bing Qin"], "title": "FroM: Frobenius Norm-Based Data-Free Adaptive Model Merging", "categories": ["cs.CL"], "comment": "12 pages, 11 figures", "summary": "With the development of large language models, fine-tuning has emerged as an\neffective method to enhance performance in specific scenarios by injecting\ndomain-specific knowledge. In this context, model merging techniques provide a\nsolution for fusing knowledge from multiple fine-tuning models by combining\ntheir parameters. However, traditional methods often encounter task\ninterference when merging full fine-tuning models, and this problem becomes\neven more evident in parameter-efficient fine-tuning scenarios. In this paper,\nwe introduce an improvement to the RegMean method, which indirectly leverages\nthe training data to approximate the outputs of the linear layers before and\nafter merging. We propose an adaptive merging method called FroM, which\ndirectly measures the model parameters using the Frobenius norm, without any\ntraining data. By introducing an additional hyperparameter for control, FroM\noutperforms baseline methods across various fine-tuning scenarios, alleviating\nthe task interference problem.", "AI": {"tldr": "The paper introduces FroM, an adaptive model merging method using the Frobenius norm to reduce task interference in fine-tuning scenarios, outperforming baseline methods.", "motivation": "Traditional model merging methods face task interference, especially in parameter-efficient fine-tuning, prompting the need for a more effective solution.", "method": "Proposes FroM, which measures model parameters using the Frobenius norm and introduces a hyperparameter for control, eliminating the need for training data.", "result": "FroM outperforms baseline methods in various fine-tuning scenarios, effectively reducing task interference.", "conclusion": "FroM provides a robust solution for merging fine-tuned models, addressing the limitations of traditional methods."}}
{"id": "2506.02433", "pdf": "https://arxiv.org/pdf/2506.02433", "abs": "https://arxiv.org/abs/2506.02433", "authors": ["Weiheng Yao", "Xuhang Chen", "Shuqiang Wang"], "title": "Empowering Functional Neuroimaging: A Pre-trained Generative Framework for Unified Representation of Neural Signals", "categories": ["cs.CV"], "comment": null, "summary": "Multimodal functional neuroimaging enables systematic analysis of brain\nmechanisms and provides discriminative representations for brain-computer\ninterface (BCI) decoding. However, its acquisition is constrained by high costs\nand feasibility limitations. Moreover, underrepresentation of specific groups\nundermines fairness of BCI decoding model. To address these challenges, we\npropose a unified representation framework for multimodal functional\nneuroimaging via generative artificial intelligence (AI). By mapping multimodal\nfunctional neuroimaging into a unified representation space, the proposed\nframework is capable of generating data for acquisition-constrained modalities\nand underrepresented groups. Experiments show that the framework can generate\ndata consistent with real brain activity patterns, provide insights into brain\nmechanisms, and improve performance on downstream tasks. More importantly, it\ncan enhance model fairness by augmenting data for underrepresented groups.\nOverall, the framework offers a new paradigm for decreasing the cost of\nacquiring multimodal functional neuroimages and enhancing the fairness of BCI\ndecoding models.", "AI": {"tldr": "A generative AI framework maps multimodal functional neuroimaging into a unified space, generating data for constrained modalities and underrepresented groups, improving fairness and performance.", "motivation": "High costs and feasibility limitations in acquiring multimodal functional neuroimaging, along with fairness issues in BCI decoding due to underrepresented groups.", "method": "Proposes a unified representation framework using generative AI to map and generate data for underrepresented or constrained modalities.", "result": "Generates data consistent with real brain activity, improves downstream task performance, and enhances model fairness.", "conclusion": "The framework reduces acquisition costs and improves fairness in BCI decoding models."}}
{"id": "2506.02213", "pdf": "https://arxiv.org/pdf/2506.02213", "abs": "https://arxiv.org/abs/2506.02213", "authors": ["Kahn Rhrissorrakrai", "Kathleen E. Hamilton", "Prerana Bangalore Parthsarathy", "Aldo Guzman-Saenz", "Tyler Alban", "Filippo Utro", "Laxmi Parida"], "title": "Quantum Ensembling Methods for Healthcare and Life Science", "categories": ["cs.LG", "q-bio.GN", "q-bio.QM"], "comment": null, "summary": "Learning on small data is a challenge frequently encountered in many\nreal-world applications. In this work we study how effective quantum ensemble\nmodels are when trained on small data problems in healthcare and life sciences.\nWe constructed multiple types of quantum ensembles for binary classification\nusing up to 26 qubits in simulation and 56 qubits on quantum hardware. Our\nensemble designs use minimal trainable parameters but require long-range\nconnections between qubits. We tested these quantum ensembles on synthetic\ndatasets and gene expression data from renal cell carcinoma patients with the\ntask of predicting patient response to immunotherapy. From the performance\nobserved in simulation and initial hardware experiments, we demonstrate how\nquantum embedding structure affects performance and discuss how to extract\ninformative features and build models that can learn and generalize\neffectively. We present these exploratory results in order to assist other\nresearchers in the design of effective learning on small data using ensembles.\nIncorporating quantum computing in these data constrained problems offers hope\nfor a wide range of studies in healthcare and life sciences where biological\nsamples are relatively scarce given the feature space to be explored.", "AI": {"tldr": "Quantum ensemble models are explored for small data learning in healthcare, showing promise in simulations and hardware tests.", "motivation": "Addressing the challenge of learning from small datasets in healthcare and life sciences using quantum computing.", "method": "Constructed quantum ensembles for binary classification, tested on synthetic and gene expression data, using up to 56 qubits.", "result": "Demonstrated how quantum embedding affects performance and how to extract features for effective learning.", "conclusion": "Quantum ensembles offer potential for small data problems in healthcare, aiding future research in the field."}}
{"id": "2506.03032", "pdf": "https://arxiv.org/pdf/2506.03032", "abs": "https://arxiv.org/abs/2506.03032", "authors": ["Junhao Yu", "Yan Zhuang", "YuXuan Sun", "Weibo Gao", "Qi Liu", "Mingyue Cheng", "Zhenya Huang", "Enhong Chen"], "title": "TestAgent: An Adaptive and Intelligent Expert for Human Assessment", "categories": ["cs.AI", "cs.CY", "cs.LG"], "comment": "24 pages,10 figures", "summary": "Accurately assessing internal human states is key to understanding\npreferences, offering personalized services, and identifying challenges in\nreal-world applications. Originating from psychometrics, adaptive testing has\nbecome the mainstream method for human measurement and has now been widely\napplied in education, healthcare, sports, and sociology. It customizes\nassessments by selecting the fewest test questions . However, current adaptive\ntesting methods face several challenges. The mechanized nature of most\nalgorithms leads to guessing behavior and difficulties with open-ended\nquestions. Additionally, subjective assessments suffer from noisy response data\nand coarse-grained test outputs, further limiting their effectiveness. To move\ncloser to an ideal adaptive testing process, we propose TestAgent, a large\nlanguage model (LLM)-powered agent designed to enhance adaptive testing through\ninteractive engagement. This is the first application of LLMs in adaptive\ntesting. TestAgent supports personalized question selection, captures\ntest-takers' responses and anomalies, and provides precise outcomes through\ndynamic, conversational interactions. Experiments on psychological,\neducational, and lifestyle assessments show our approach achieves more accurate\nresults with 20% fewer questions than state-of-the-art baselines, and testers\npreferred it in speed, smoothness, and other dimensions.", "AI": {"tldr": "TestAgent, an LLM-powered agent, improves adaptive testing by engaging interactively, reducing questions by 20% while enhancing accuracy and user experience.", "motivation": "Current adaptive testing methods struggle with mechanization, guessing behavior, noisy data, and coarse outputs, limiting effectiveness.", "method": "TestAgent uses LLMs for personalized question selection, captures responses dynamically, and provides precise outcomes via conversational interactions.", "result": "Experiments show 20% fewer questions needed and higher accuracy in psychological, educational, and lifestyle assessments, with better user feedback.", "conclusion": "TestAgent advances adaptive testing by leveraging LLMs for interactive, efficient, and accurate assessments."}}
{"id": "2506.02480", "pdf": "https://arxiv.org/pdf/2506.02480", "abs": "https://arxiv.org/abs/2506.02480", "authors": ["Yifan Duan", "Yihong Tang", "Kehai Chen", "Liqiang Nie", "Min Zhang"], "title": "ORPP: Self-Optimizing Role-playing Prompts to Enhance Language Model Capabilities", "categories": ["cs.CL"], "comment": null, "summary": "High-quality prompts are crucial for eliciting outstanding performance from\nlarge language models (LLMs) on complex tasks. Existing research has explored\nmodel-driven strategies for prompt optimization. However, these methods often\nsuffer from high computational overhead or require strong optimization\ncapabilities from the model itself, which limits their broad applicability.To\naddress these challenges, we propose ORPP (Optimized Role-Playing Prompt),a\nframework that enhances model performance by optimizing and generating\nrole-playing prompts. The core idea of ORPP is to confine the prompt search\nspace to role-playing scenarios, thereby fully activating the model's intrinsic\ncapabilities through carefully crafted, high-quality role-playing prompts.\nSpecifically, ORPP first performs iterative optimization on a small subset of\ntraining samples to generate high-quality role-playing prompts. Then,\nleveraging the model's few-shot learning capability, it transfers the\noptimization experience to efficiently generate suitable prompts for the\nremaining samples.Our experimental results show that ORPP not only matches but\nin most cases surpasses existing mainstream prompt optimization methods in\nterms of performance. Notably, ORPP demonstrates superior \"plug-and-play\"\ncapability. In most cases, it can be integrated with various other prompt\nmethods and further enhance their effectiveness.", "AI": {"tldr": "ORPP (Optimized Role-Playing Prompt) is a framework for optimizing role-playing prompts to enhance LLM performance, outperforming existing methods with plug-and-play capability.", "motivation": "Existing prompt optimization methods are computationally expensive or require strong model capabilities, limiting their applicability.", "method": "ORPP optimizes prompts by confining the search space to role-playing scenarios, iteratively refining prompts on a small subset and transferring the optimization to other samples.", "result": "ORPP surpasses mainstream prompt optimization methods in performance and integrates well with other methods.", "conclusion": "ORPP offers a scalable, efficient, and effective solution for prompt optimization in LLMs."}}
{"id": "2506.02439", "pdf": "https://arxiv.org/pdf/2506.02439", "abs": "https://arxiv.org/abs/2506.02439", "authors": ["Shuang Li", "Jiaxu Leng", "Changjiang Kuang", "Mingpi Tan", "Xinbo Gao"], "title": "Video-Level Language-Driven Video-Based Visible-Infrared Person Re-Identification", "categories": ["cs.CV"], "comment": "Accepted by IEEE TIFS", "summary": "Video-based Visible-Infrared Person Re-Identification (VVI-ReID) aims to\nmatch pedestrian sequences across modalities by extracting modality-invariant\nsequence-level features. As a high-level semantic representation, language\nprovides a consistent description of pedestrian characteristics in both\ninfrared and visible modalities. Leveraging the Contrastive Language-Image\nPre-training (CLIP) model to generate video-level language prompts and guide\nthe learning of modality-invariant sequence-level features is theoretically\nfeasible. However, the challenge of generating and utilizing modality-shared\nvideo-level language prompts to address modality gaps remains a critical\nproblem. To address this problem, we propose a simple yet powerful framework,\nvideo-level language-driven VVI-ReID (VLD), which consists of two core modules:\ninvariant-modality language prompting (IMLP) and spatial-temporal prompting\n(STP). IMLP employs a joint fine-tuning strategy for the visual encoder and the\nprompt learner to effectively generate modality-shared text prompts and align\nthem with visual features from different modalities in CLIP's multimodal space,\nthereby mitigating modality differences. Additionally, STP models\nspatiotemporal information through two submodules, the spatial-temporal hub\n(STH) and spatial-temporal aggregation (STA), which further enhance IMLP by\nincorporating spatiotemporal information into text prompts. The STH aggregates\nand diffuses spatiotemporal information into the [CLS] token of each frame\nacross the vision transformer (ViT) layers, whereas STA introduces dedicated\nidentity-level loss and specialized multihead attention to ensure that the STH\nfocuses on identity-relevant spatiotemporal feature aggregation. The VLD\nframework achieves state-of-the-art results on two VVI-ReID benchmarks. The\ncode will be released at https://github.com/Visuang/VLD.", "AI": {"tldr": "The paper proposes VLD, a framework for Video-based Visible-Infrared Person Re-Identification (VVI-ReID), using language prompts to bridge modality gaps and achieve state-of-the-art results.", "motivation": "Language provides consistent descriptions across modalities, but generating and using modality-shared video-level language prompts to address modality gaps is challenging.", "method": "VLD includes two modules: Invariant-Modality Language Prompting (IMLP) for aligning visual and text features, and Spatial-Temporal Prompting (STP) to enhance IMLP with spatiotemporal information.", "result": "VLD achieves state-of-the-art performance on two VVI-ReID benchmarks.", "conclusion": "The VLD framework effectively mitigates modality differences and leverages spatiotemporal information for superior VVI-ReID performance."}}
{"id": "2506.02242", "pdf": "https://arxiv.org/pdf/2506.02242", "abs": "https://arxiv.org/abs/2506.02242", "authors": ["Yihong Tang", "Ao Qu", "Xujing Yu", "Weipeng Deng", "Jun Ma", "Jinhua Zhao", "Lijun Sun"], "title": "From Street Views to Urban Science: Discovering Road Safety Factors with Multimodal Large Language Models", "categories": ["cs.LG", "cs.CY"], "comment": null, "summary": "Urban and transportation research has long sought to uncover statistically\nmeaningful relationships between key variables and societal outcomes such as\nroad safety, to generate actionable insights that guide the planning,\ndevelopment, and renewal of urban and transportation systems. However,\ntraditional workflows face several key challenges: (1) reliance on human\nexperts to propose hypotheses, which is time-consuming and prone to\nconfirmation bias; (2) limited interpretability, particularly in deep learning\napproaches; and (3) underutilization of unstructured data that can encode\ncritical urban context. Given these limitations, we propose a Multimodal Large\nLanguage Model (MLLM)-based approach for interpretable hypothesis inference,\nenabling the automated generation, evaluation, and refinement of hypotheses\nconcerning urban context and road safety outcomes. Our method leverages MLLMs\nto craft safety-relevant questions for street view images (SVIs), extract\ninterpretable embeddings from their responses, and apply them in\nregression-based statistical models. UrbanX supports iterative hypothesis\ntesting and refinement, guided by statistical evidence such as coefficient\nsignificance, thereby enabling rigorous scientific discovery of previously\noverlooked correlations between urban design and safety. Experimental\nevaluations on Manhattan street segments demonstrate that our approach\noutperforms pretrained deep learning models while offering full\ninterpretability. Beyond road safety, UrbanX can serve as a general-purpose\nframework for urban scientific discovery, extracting structured insights from\nunstructured urban data across diverse socioeconomic and environmental\noutcomes. This approach enhances model trustworthiness for policy applications\nand establishes a scalable, statistically grounded pathway for interpretable\nknowledge discovery in urban and transportation studies.", "AI": {"tldr": "Proposes a Multimodal Large Language Model (MLLM)-based approach for automated, interpretable hypothesis inference in urban and transportation research, outperforming traditional methods.", "motivation": "Addresses challenges in traditional workflows: human bias, limited interpretability, and underutilized unstructured data.", "method": "Uses MLLMs to generate safety-relevant questions for street view images, extracts interpretable embeddings, and applies regression models for hypothesis testing.", "result": "Outperforms pretrained deep learning models on Manhattan street segments while maintaining interpretability.", "conclusion": "UrbanX offers a scalable, interpretable framework for urban scientific discovery, enhancing trustworthiness for policy applications."}}
{"id": "2506.03056", "pdf": "https://arxiv.org/pdf/2506.03056", "abs": "https://arxiv.org/abs/2506.03056", "authors": ["Ram Potham", "Max Harms"], "title": "Corrigibility as a Singular Target: A Vision for Inherently Reliable Foundation Models", "categories": ["cs.AI", "cs.CY", "cs.LG"], "comment": "Preprint. This work has been submitted to the Reliable and\n  Responsible Foundation Models Workshop at ICML 2025 for review", "summary": "Foundation models (FMs) face a critical safety challenge: as capabilities\nscale, instrumental convergence drives default trajectories toward loss of\nhuman control, potentially culminating in existential catastrophe. Current\nalignment approaches struggle with value specification complexity and fail to\naddress emergent power-seeking behaviors. We propose \"Corrigibility as a\nSingular Target\" (CAST)-designing FMs whose overriding objective is empowering\ndesignated human principals to guide, correct, and control them. This paradigm\nshift from static value-loading to dynamic human empowerment transforms\ninstrumental drives: self-preservation serves only to maintain the principal's\ncontrol; goal modification becomes facilitating principal guidance. We present\na comprehensive empirical research agenda spanning training methodologies\n(RLAIF, SFT, synthetic data generation), scalability testing across model\nsizes, and demonstrations of controlled instructability. Our vision: FMs that\nbecome increasingly responsive to human guidance as capabilities grow, offering\na path to beneficial AI that remains as tool-like as possible, rather than\nsupplanting human judgment. This addresses the core alignment problem at its\nsource, preventing the default trajectory toward misaligned instrumental\nconvergence.", "AI": {"tldr": "The paper proposes 'Corrigibility as a Singular Target' (CAST) to ensure foundation models (FMs) remain under human control, addressing alignment challenges and emergent power-seeking behaviors.", "motivation": "To prevent existential risks from misaligned FMs by shifting focus from static value-loading to dynamic human empowerment.", "method": "CAST framework, using training methods like RLAIF and SFT, scalability testing, and controlled instructability demonstrations.", "result": "FMs designed to prioritize human control, transforming instrumental drives to align with human guidance.", "conclusion": "CAST offers a scalable solution to FM alignment, ensuring AI remains tool-like and responsive to human oversight."}}
{"id": "2506.02481", "pdf": "https://arxiv.org/pdf/2506.02481", "abs": "https://arxiv.org/abs/2506.02481", "authors": ["Inderjeet Nair", "Lu Wang"], "title": "Do Language Models Think Consistently? A Study of Value Preferences Across Varying Response Lengths", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Evaluations of LLMs' ethical risks and value inclinations often rely on\nshort-form surveys and psychometric tests, yet real-world use involves\nlong-form, open-ended responses -- leaving value-related risks and preferences\nin practical settings largely underexplored. In this work, we ask: Do value\npreferences inferred from short-form tests align with those expressed in\nlong-form outputs? To address this question, we compare value preferences\nelicited from short-form reactions and long-form responses, varying the number\nof arguments in the latter to capture users' differing verbosity preferences.\nAnalyzing five LLMs (llama3-8b, gemma2-9b, mistral-7b, qwen2-7b, and olmo-7b),\nwe find (1) a weak correlation between value preferences inferred from\nshort-form and long-form responses across varying argument counts, and (2)\nsimilarly weak correlation between preferences derived from any two distinct\nlong-form generation settings. (3) Alignment yields only modest gains in the\nconsistency of value expression. Further, we examine how long-form generation\nattributes relate to value preferences, finding that argument specificity\nnegatively correlates with preference strength, while representation across\nscenarios shows a positive correlation. Our findings underscore the need for\nmore robust methods to ensure consistent value expression across diverse\napplications.", "AI": {"tldr": "The study explores whether value preferences in LLMs inferred from short-form tests align with those in long-form responses, finding weak correlations and modest gains from alignment.", "motivation": "To address the gap in understanding value-related risks and preferences in LLMs' long-form, practical outputs compared to short-form tests.", "method": "Comparison of value preferences from short-form reactions and long-form responses across five LLMs, varying argument counts in long-form outputs.", "result": "Weak correlations between short-form and long-form preferences, and between different long-form settings. Alignment improves consistency modestly.", "conclusion": "More robust methods are needed to ensure consistent value expression in diverse LLM applications."}}
{"id": "2506.02444", "pdf": "https://arxiv.org/pdf/2506.02444", "abs": "https://arxiv.org/abs/2506.02444", "authors": ["Lingwei Dang", "Ruizhi Shao", "Hongwen Zhang", "Wei Min", "Yebin Liu", "Qingyao Wu"], "title": "SViMo: Synchronized Diffusion for Video and Motion Generation in Hand-object Interaction Scenarios", "categories": ["cs.CV"], "comment": null, "summary": "Hand-Object Interaction (HOI) generation has significant application\npotential. However, current 3D HOI motion generation approaches heavily rely on\npredefined 3D object models and lab-captured motion data, limiting\ngeneralization capabilities. Meanwhile, HOI video generation methods prioritize\npixel-level visual fidelity, often sacrificing physical plausibility.\nRecognizing that visual appearance and motion patterns share fundamental\nphysical laws in the real world, we propose a novel framework that combines\nvisual priors and dynamic constraints within a synchronized diffusion process\nto generate the HOI video and motion simultaneously. To integrate the\nheterogeneous semantics, appearance, and motion features, our method implements\ntri-modal adaptive modulation for feature aligning, coupled with 3D\nfull-attention for modeling inter- and intra-modal dependencies. Furthermore,\nwe introduce a vision-aware 3D interaction diffusion model that generates\nexplicit 3D interaction sequences directly from the synchronized diffusion\noutputs, then feeds them back to establish a closed-loop feedback cycle. This\narchitecture eliminates dependencies on predefined object models or explicit\npose guidance while significantly enhancing video-motion consistency.\nExperimental results demonstrate our method's superiority over state-of-the-art\napproaches in generating high-fidelity, dynamically plausible HOI sequences,\nwith notable generalization capabilities in unseen real-world scenarios.\nProject page at\n\\href{https://github.com/Droliven}{https://github.com/Droliven}.", "AI": {"tldr": "A novel framework combines visual priors and dynamic constraints in a synchronized diffusion process to generate Hand-Object Interaction (HOI) videos and motion simultaneously, enhancing consistency and generalization.", "motivation": "Current HOI methods rely on predefined 3D models or sacrifice physical plausibility for visual fidelity, limiting generalization.", "method": "Uses tri-modal adaptive modulation for feature alignment and 3D full-attention for dependencies, coupled with a vision-aware 3D interaction diffusion model for closed-loop feedback.", "result": "Outperforms state-of-the-art in generating high-fidelity, physically plausible HOI sequences with strong generalization.", "conclusion": "The framework eliminates dependencies on predefined models and improves video-motion consistency, demonstrating superior performance in real-world scenarios."}}
{"id": "2506.02243", "pdf": "https://arxiv.org/pdf/2506.02243", "abs": "https://arxiv.org/abs/2506.02243", "authors": ["Tamara Cucumides", "Floris Geerts"], "title": "From Features to Structure: Task-Aware Graph Construction for Relational and Tabular Learning with GNNs", "categories": ["cs.LG"], "comment": "5 pages, 2 figures", "summary": "Tabular and relational data remain the most ubiquitous formats in real-world\nmachine learning applications, spanning domains from finance to healthcare.\nAlthough both formats offer structured representations, they pose distinct\nchallenges for modern deep learning methods, which typically assume flat,\nfeature-aligned inputs. Graph Neural Networks (GNNs) have emerged as a\npromising solution by capturing structural dependencies within and between\ntables. However, existing GNN-based approaches often rely on rigid,\nschema-derived graphs -- such as those based on primary-foreign key links --\nthereby underutilizing rich, predictive signals in non key attributes. In this\nwork, we introduce auGraph, a unified framework for task-aware graph\naugmentation that applies to both tabular and relational data. auGraph enhances\nbase graph structures by selectively promoting attributes into nodes, guided by\nscoring functions that quantify their relevance to the downstream prediction\ntask. This augmentation preserves the original data schema while injecting\ntask-relevant structural signal. Empirically, auGraph outperforms schema-based\nand heuristic graph construction methods by producing graphs that better\nsupport learning for relational and tabular prediction tasks.", "AI": {"tldr": "auGraph is a framework for task-aware graph augmentation in tabular and relational data, outperforming schema-based methods by enhancing graphs with task-relevant attributes.", "motivation": "Existing GNN-based methods underutilize non-key attributes in tabular and relational data, limiting predictive performance.", "method": "auGraph introduces task-aware graph augmentation, promoting relevant attributes into nodes while preserving the original schema.", "result": "Empirically, auGraph outperforms schema-based and heuristic graph construction methods.", "conclusion": "auGraph effectively enhances graph structures for better learning in relational and tabular prediction tasks."}}
{"id": "2506.03095", "pdf": "https://arxiv.org/pdf/2506.03095", "abs": "https://arxiv.org/abs/2506.03095", "authors": ["Man Luo", "David Cobbley", "Xin Su", "Shachar Rosenman", "Vasudev Lal", "Shao-Yen Tseng", "Phillip Howard"], "title": "DPO Learning with LLMs-Judge Signal for Computer Use Agents", "categories": ["cs.AI", "cs.CV"], "comment": null, "summary": "Computer use agents (CUA) are systems that automatically interact with\ngraphical user interfaces (GUIs) to complete tasks. CUA have made significant\nprogress with the advent of large vision-language models (VLMs). However, these\nagents typically rely on cloud-based inference with substantial compute\ndemands, raising critical privacy and scalability concerns, especially when\noperating on personal devices. In this work, we take a step toward\nprivacy-preserving and resource-efficient agents by developing a lightweight\nvision-language model that runs entirely on local machines. To train this\ncompact agent, we introduce an LLM-as-Judge framework that automatically\nevaluates and filters synthetic interaction trajectories, producing\nhigh-quality data for reinforcement learning without human annotation.\nExperiments on the OS-World benchmark demonstrate that our fine-tuned local\nmodel outperforms existing baselines, highlighting a promising path toward\nprivate, efficient, and generalizable GUI agents.", "AI": {"tldr": "A lightweight vision-language model for local GUI agents is developed, using an LLM-as-Judge framework for training, outperforming baselines on OS-World.", "motivation": "Address privacy and scalability concerns of cloud-based GUI agents by creating a local, efficient alternative.", "method": "Develop a lightweight vision-language model trained with synthetic interaction trajectories filtered by an LLM-as-Judge framework.", "result": "The local model outperforms existing baselines on the OS-World benchmark.", "conclusion": "The approach offers a promising path toward private, efficient, and generalizable GUI agents."}}
{"id": "2506.02483", "pdf": "https://arxiv.org/pdf/2506.02483", "abs": "https://arxiv.org/abs/2506.02483", "authors": ["Sina Bagheri Nezhad", "Ameeta Agrawal"], "title": "Enhancing Large Language Models with Neurosymbolic Reasoning for Multilingual Tasks", "categories": ["cs.CL"], "comment": "Accepted at 19th Conference on Neurosymbolic Learning and Reasoning\n  (NeSy 2025)", "summary": "Large language models (LLMs) often struggle to perform multi-target reasoning\nin long-context scenarios where relevant information is scattered across\nextensive documents. To address this challenge, we introduce NeuroSymbolic\nAugmented Reasoning (NSAR), which combines the benefits of neural and symbolic\nreasoning during inference. NSAR explicitly extracts symbolic facts from text\nand generates executable Python code to handle complex reasoning steps. Through\nextensive experiments across seven languages and diverse context lengths, we\ndemonstrate that NSAR significantly outperforms both a vanilla RAG baseline and\nadvanced prompting strategies in accurately identifying and synthesizing\nmultiple pieces of information. Our results highlight the effectiveness of\ncombining explicit symbolic operations with neural inference for robust,\ninterpretable, and scalable reasoning in multilingual settings.", "AI": {"tldr": "NSAR combines neural and symbolic reasoning to improve multi-target reasoning in long-context scenarios, outperforming baselines.", "motivation": "LLMs struggle with multi-target reasoning in long-context settings where information is scattered.", "method": "NSAR extracts symbolic facts and generates Python code for complex reasoning, integrating neural and symbolic approaches.", "result": "NSAR outperforms vanilla RAG and advanced prompting in accuracy across seven languages and varied context lengths.", "conclusion": "Combining symbolic operations with neural inference enhances robust, interpretable, and scalable multilingual reasoning."}}
{"id": "2506.02448", "pdf": "https://arxiv.org/pdf/2506.02448", "abs": "https://arxiv.org/abs/2506.02448", "authors": ["Baoyu Liang", "Qile Su", "Shoutai Zhu", "Yuchen Liang", "Chao Tong"], "title": "VidEvent: A Large Dataset for Understanding Dynamic Evolution of Events in Videos", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Despite the significant impact of visual events on human cognition,\nunderstanding events in videos remains a challenging task for AI due to their\ncomplex structures, semantic hierarchies, and dynamic evolution. To address\nthis, we propose the task of video event understanding that extracts event\nscripts and makes predictions with these scripts from videos. To support this\ntask, we introduce VidEvent, a large-scale dataset containing over 23,000\nwell-labeled events, featuring detailed event structures, broad hierarchies,\nand logical relations extracted from movie recap videos. The dataset was\ncreated through a meticulous annotation process, ensuring high-quality and\nreliable event data. We also provide comprehensive baseline models offering\ndetailed descriptions of their architecture and performance metrics. These\nmodels serve as benchmarks for future research, facilitating comparisons and\nimprovements. Our analysis of VidEvent and the baseline models highlights the\ndataset's potential to advance video event understanding and encourages the\nexploration of innovative algorithms and models. The dataset and related\nresources are publicly available at www.videvent.top.", "AI": {"tldr": "The paper introduces VidEvent, a large-scale dataset for video event understanding, featuring detailed event structures and logical relations, along with baseline models for benchmarking.", "motivation": "Understanding complex video events is challenging for AI due to their dynamic and hierarchical nature. The paper aims to address this gap.", "method": "Proposes the VidEvent dataset with over 23,000 labeled events from movie recaps, created via meticulous annotation. Provides baseline models for benchmarking.", "result": "The dataset and models serve as benchmarks, demonstrating VidEvent's potential to advance video event understanding.", "conclusion": "VidEvent encourages future research in video event understanding, with the dataset and resources publicly available."}}
{"id": "2506.02255", "pdf": "https://arxiv.org/pdf/2506.02255", "abs": "https://arxiv.org/abs/2506.02255", "authors": ["Asha Ramanujam", "Adam Elyoumi", "Hao Chen", "Sai Madhukiran Kompalli", "Akshdeep Singh Ahluwalia", "Shraman Pal", "Dimitri J. Papageorgiou", "Can Li"], "title": "SafeOR-Gym: A Benchmark Suite for Safe Reinforcement Learning Algorithms on Practical Operations Research Problems", "categories": ["cs.LG"], "comment": null, "summary": "Most existing safe reinforcement learning (RL) benchmarks focus on robotics\nand control tasks, offering limited relevance to high-stakes domains that\ninvolve structured constraints, mixed-integer decisions, and industrial\ncomplexity. This gap hinders the advancement and deployment of safe RL in\ncritical areas such as energy systems, manufacturing, and supply chains. To\naddress this limitation, we present SafeOR-Gym, a benchmark suite of nine\noperations research (OR) environments tailored for safe RL under complex\nconstraints. Each environment captures a realistic planning, scheduling, or\ncontrol problems characterized by cost-based constraint violations, planning\nhorizons, and hybrid discrete-continuous action spaces. The suite integrates\nseamlessly with the Constrained Markov Decision Process (CMDP) interface\nprovided by OmniSafe. We evaluate several state-of-the-art safe RL algorithms\nacross these environments, revealing a wide range of performance: while some\ntasks are tractable, others expose fundamental limitations in current\napproaches. SafeOR-Gym provides a challenging and practical testbed that aims\nto catalyze future research in safe RL for real-world decision-making problems.\nThe SafeOR-Gym framework and all accompanying code are available at:\nhttps://github.com/li-group/SafeOR-Gym.", "AI": {"tldr": "SafeOR-Gym is a benchmark suite for safe reinforcement learning (RL) in complex, real-world operations research (OR) tasks, addressing gaps in existing benchmarks.", "motivation": "Existing safe RL benchmarks lack relevance to high-stakes domains with structured constraints and industrial complexity, limiting progress in critical areas like energy and supply chains.", "method": "SafeOR-Gym introduces nine OR environments with realistic planning, scheduling, and control problems, integrating with the CMDP interface.", "result": "Evaluation shows varied performance of safe RL algorithms, with some tasks tractable and others exposing current limitations.", "conclusion": "SafeOR-Gym serves as a practical testbed to advance safe RL research for real-world decision-making, with open-source availability."}}
{"id": "2506.01969", "pdf": "https://arxiv.org/pdf/2506.01969", "abs": "https://arxiv.org/abs/2506.01969", "authors": ["Pencuo Zeren", "Qiuming Luo", "Rui Mao", "Chang Kong"], "title": "FlashMLA-ETAP: Efficient Transpose Attention Pipeline for Accelerating MLA Inference on NVIDIA H20 GPUs", "categories": ["cs.DC", "cs.AI", "cs.LG"], "comment": "15 pages, conference", "summary": "Efficient inference of Multi-Head Latent Attention (MLA) is challenged by\ndeploying the DeepSeek-R1 671B model on a single Multi-GPU server. This paper\nintroduces FlashMLA-ETAP, a novel framework that enhances MLA inference for the\nsingle-instance deployment scenario on NVIDIA H20 GPUs. We propose the\nEfficient Transpose Attention Pipeline (ETAP), which reconfigures attention\ncomputation through transposition to align the KV context length with the\n\\(M\\)-dimension in WGMMA operations, significantly reducing redundant\ncomputations. FlashMLA-ETAP achieves a 2.78x speedup over FlashMLA at 64K\nsequence length (batch size 16), with 5.24x and 4.94x improvements over\nFlashAttention-3 and FlashInfer, respectively, while maintaining numerical\nstability with a 15.2x lower RMSE (\\(1.25 \\times 10^{-5}\\)) than\nFlashAttention-3. Furthermore, ETAP's design enables seamless integration into\nframeworks like FlashAttention-3 and FlashInfer, supported by a detailed\ntheoretical analysis. Our work addresses a critical gap in resource-constrained\ninference, offering a scalable solution for mid-tier GPUs and paving the way\nfor broader adoption in hardware-aware optimization. Code is available at\nhttps://github.com/pengcuo/FlashMLA-ETAP.", "AI": {"tldr": "FlashMLA-ETAP improves MLA inference efficiency on single-GPU servers using ETAP, achieving significant speedups and numerical stability.", "motivation": "Addressing the challenge of efficient MLA inference for large models like DeepSeek-R1 671B on resource-constrained single-GPU setups.", "method": "Introduces ETAP, a pipeline that reconfigures attention computation via transposition to align KV context length with WGMMA operations, reducing redundancy.", "result": "Achieves 2.78x speedup over FlashMLA, 5.24x over FlashAttention-3, and 4.94x over FlashInfer, with lower RMSE (1.25\u00d710\u207b\u2075).", "conclusion": "FlashMLA-ETAP provides a scalable solution for mid-tier GPUs, bridging a gap in hardware-aware optimization for resource-constrained inference."}}
{"id": "2506.02494", "pdf": "https://arxiv.org/pdf/2506.02494", "abs": "https://arxiv.org/abs/2506.02494", "authors": ["Junzhe Zhang", "Huixuan Zhang", "Xinyu Hu", "Li Lin", "Mingqi Gao", "Shi Qiu", "Xiaojun Wan"], "title": "Minos: A Multimodal Evaluation Model for Bidirectional Generation Between Image and Text", "categories": ["cs.CL", "cs.AI", "cs.CV"], "comment": null, "summary": "Evaluation is important for multimodal generation tasks. With the rapid\nprogress of MLLMs, there is growing interest in applying MLLMs to build general\nevaluation systems. However, existing work overlooks two aspects: (1) the\ndevelopment of evaluation capabilities for text-to-image (T2I) generation task,\nand (2) the incorporation of large-scale human evaluation data. In this paper,\nwe introduce Minos-Corpus, a large-scale multimodal evaluation dataset that\ncombines evaluation data from both human and GPT. The corpus contains\nevaluation data across both image-to-text(I2T) and T2I generation tasks. Based\non this corpus, we propose Data Selection and Balance, Mix-SFT training\nmethods, and apply DPO to develop Minos, a multimodal evaluation model built\nupon a 7B backbone. Minos achieves state-of-the-art (SoTA) performance among\nall open-source evaluation models of similar scale on the average of evaluation\nperformance on all tasks, and outperforms all open-source and closed-source\nmodels on evaluation of T2I generation task. Extensive experiments demonstrate\nthe importance of leveraging high-quality human evaluation data and jointly\ntraining on evaluation data from both I2T and T2I generation tasks.", "AI": {"tldr": "The paper introduces Minos-Corpus, a large-scale multimodal evaluation dataset combining human and GPT data for I2T and T2I tasks, and proposes Minos, a model achieving SoTA performance.", "motivation": "Existing work lacks focus on T2I evaluation capabilities and large-scale human evaluation data.", "method": "Developed Minos-Corpus, used Data Selection and Balance, Mix-SFT training, and DPO to build Minos on a 7B backbone.", "result": "Minos achieves SoTA performance on average and excels in T2I evaluation.", "conclusion": "High-quality human data and joint training on I2T and T2I tasks are crucial for effective multimodal evaluation."}}
{"id": "2506.02452", "pdf": "https://arxiv.org/pdf/2506.02452", "abs": "https://arxiv.org/abs/2506.02452", "authors": ["Wenshuo Chen", "Kuimou Yu", "Haozhe Jia", "Kaishen Yuan", "Bowen Tian", "Songning Lai", "Hongru Xiao", "Erhang Zhang", "Lei Wang", "Yutao Yue"], "title": "ANT: Adaptive Neural Temporal-Aware Text-to-Motion Model", "categories": ["cs.CV"], "comment": null, "summary": "While diffusion models advance text-to-motion generation, their static\nsemantic conditioning ignores temporal-frequency demands: early denoising\nrequires structural semantics for motion foundations while later stages need\nlocalized details for text alignment. This mismatch mirrors biological\nmorphogenesis where developmental phases demand distinct genetic programs.\nInspired by epigenetic regulation governing morphological specialization, we\npropose **(ANT)**, an **A**daptive **N**eural **T**emporal-Aware architecture.\nANT orchestrates semantic granularity through: **(i) Semantic Temporally\nAdaptive (STA) Module:** Automatically partitions denoising into low-frequency\nstructural planning and high-frequency refinement via spectral analysis. **(ii)\nDynamic Classifier-Free Guidance scheduling (DCFG):** Adaptively adjusts\nconditional to unconditional ratio enhancing efficiency while maintaining\nfidelity. **(iii) Temporal-semantic reweighting:** Quantitatively aligns text\ninfluence with phase requirements. Extensive experiments show that ANT can be\napplied to various baselines, significantly improving model performance, and\nachieving state-of-the-art semantic alignment on StableMoFusion.", "AI": {"tldr": "ANT improves text-to-motion generation by adapting semantic conditioning to temporal-frequency demands, enhancing efficiency and fidelity.", "motivation": "Current diffusion models ignore temporal-frequency demands in text-to-motion generation, leading to mismatched semantic conditioning.", "method": "Proposes ANT with STA Module, DCFG, and temporal-semantic reweighting to adapt semantic granularity dynamically.", "result": "ANT significantly improves performance and achieves state-of-the-art semantic alignment.", "conclusion": "ANT addresses temporal-frequency mismatches, enhancing text-to-motion generation."}}
{"id": "2506.02256", "pdf": "https://arxiv.org/pdf/2506.02256", "abs": "https://arxiv.org/abs/2506.02256", "authors": ["Yi Xiao", "Harshit Sharma", "Sawinder Kaur", "Dessa Bergen-Cico", "Asif Salekin"], "title": "Human Heterogeneity Invariant Stress Sensing", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Stress affects physical and mental health, and wearable devices have been\nwidely used to detect daily stress through physiological signals. However,\nthese signals vary due to factors such as individual differences and health\nconditions, making generalizing machine learning models difficult. To address\nthese challenges, we present Human Heterogeneity Invariant Stress Sensing\n(HHISS), a domain generalization approach designed to find consistent patterns\nin stress signals by removing person-specific differences. This helps the model\nperform more accurately across new people, environments, and stress types not\nseen during training. Its novelty lies in proposing a novel technique called\nperson-wise sub-network pruning intersection to focus on shared features across\nindividuals, alongside preventing overfitting by leveraging continuous labels\nwhile training. The study focuses especially on people with opioid use disorder\n(OUD)-a group where stress responses can change dramatically depending on their\ntime of daily medication taking. Since stress often triggers cravings, a model\nthat can adapt well to these changes could support better OUD rehabilitation\nand recovery. We tested HHISS on seven different stress datasets-four of which\nwe collected ourselves and three public ones. Four are from lab setups, one\nfrom a controlled real-world setting, driving, and two are from real-world\nin-the-wild field datasets without any constraints. This is the first study to\nevaluate how well a stress detection model works across such a wide range of\ndata. Results show HHISS consistently outperformed state-of-the-art baseline\nmethods, proving both effective and practical for real-world use. Ablation\nstudies, empirical justifications, and runtime evaluations confirm HHISS's\nfeasibility and scalability for mobile stress sensing in sensitive real-world\napplications.", "AI": {"tldr": "HHISS is a domain generalization approach for stress detection that removes person-specific differences, improving model accuracy across new individuals and environments. It uses sub-network pruning and continuous labels to focus on shared features and prevent overfitting. Tested on diverse datasets, HHISS outperforms baselines, proving practical for real-world use.", "motivation": "Stress detection models struggle with individual differences and varying health conditions, limiting generalization. HHISS aims to address this by identifying consistent stress patterns across diverse populations, especially in sensitive groups like those with opioid use disorder (OUD).", "method": "HHISS employs person-wise sub-network pruning intersection to isolate shared stress features and uses continuous labels to avoid overfitting. It is evaluated on seven datasets, including lab, controlled, and real-world settings.", "result": "HHISS consistently outperforms state-of-the-art baseline methods across all datasets, demonstrating robustness and scalability for real-world applications.", "conclusion": "HHISS is a feasible and scalable solution for mobile stress sensing, particularly in sensitive scenarios like OUD rehabilitation, due to its ability to generalize across diverse data."}}
{"id": "2506.01979", "pdf": "https://arxiv.org/pdf/2506.01979", "abs": "https://arxiv.org/abs/2506.01979", "authors": ["Yuhao Shen", "Junyi Shen", "Quan Kong", "Tianyu Liu", "Yao Lu", "Cong Wang"], "title": "Speculative Decoding via Hybrid Drafting and Rollback-Aware Branch Parallelism", "categories": ["cs.DC", "cs.AI"], "comment": null, "summary": "Recently, speculative decoding (SD) has emerged as a promising technique to\naccelerate LLM inference by employing a small draft model to propose draft\ntokens in advance, and validating them in parallel with the large target model.\nHowever, the existing SD methods still remain fundamentally constrained by\ntheir serialized execution, which causes the mutual waiting bubbles between the\ndraft and target models. To address this challenge, we draw inspiration from\nbranch prediction in modern processors and propose a novel framework\n\\textbf{SpecBranch} to unlock branch parallelism in SD. Specifically, we first\ntake an in-depth analysis of the potential of branch parallelism in SD, and\nrecognize that the key challenge lies in the trade-offs between parallelization\nand token rollback. Based on the analysis, we strategically introduce parallel\nspeculative branches to preemptively hedge against likely rejections.\nMeanwhile, to enhance parallelism, we jointly orchestrate adaptive draft\nlengths with a hybrid combination of the implicit draft model confidence and\nexplicit reusing of target model features. Extensive experiments across various\nmodels and benchmarks show that SpecBranch achieves over \\textbf{1.8}$\\times\n\\sim$ \\textbf{4.5}$\\times$ speedups against the auto-regressive decoding and\nreduces rollback tokens by $\\textbf{50}$\\% for poorly aligned models, realizing\nits applicability for real-world deployments.", "AI": {"tldr": "SpecBranch introduces branch parallelism in speculative decoding (SD) to reduce mutual waiting between draft and target models, achieving significant speedups and fewer rollbacks.", "motivation": "Existing SD methods suffer from serialized execution, causing inefficiencies due to mutual waiting between draft and target models.", "method": "Proposes SpecBranch, leveraging branch parallelism, adaptive draft lengths, and hybrid confidence metrics to optimize SD.", "result": "Achieves 1.8\u00d7 to 4.5\u00d7 speedups over auto-regressive decoding and reduces rollback tokens by 50%.", "conclusion": "SpecBranch enhances SD efficiency, making it practical for real-world LLM inference."}}
{"id": "2506.02503", "pdf": "https://arxiv.org/pdf/2506.02503", "abs": "https://arxiv.org/abs/2506.02503", "authors": ["Yongjian Li", "HaoCheng Chu", "Yukun Yan", "Zhenghao Liu", "Shi Yu", "Zheni Zeng", "Ruobing Wang", "Sen Song", "Zhiyuan Liu", "Maosong Sun"], "title": "KARE-RAG: Knowledge-Aware Refinement and Enhancement for RAG", "categories": ["cs.CL"], "comment": null, "summary": "Retrieval-Augmented Generation (RAG) enables large language models (LLMs) to\naccess broader knowledge sources, yet factual inconsistencies persist due to\nnoise in retrieved documents-even with advanced retrieval methods. We\ndemonstrate that enhancing generative models' capacity to process noisy content\nis equally critical for robust performance. In this paper, we present KARE-RAG\n(Knowledge-Aware Refinement and Enhancement for RAG), which improves knowledge\nutilization through three key innovations: (1) structured knowledge\nrepresentations that facilitate error detection during training, (2) Dense\nDirect Preference Optimization (DDPO)-a refined training objective that\nprioritizes correction of critical errors, and (3) a contrastive data\ngeneration pipeline that maintains semantic consistency while rectifying\nfactual inaccuracies. Experiments show our method significantly enhances\nstandard RAG pipelines across model scales, improving both in-domain and\nout-of-domain task performance without compromising general capabilities.\nNotably, these gains are achieved with modest training data, suggesting\ndata-efficient optimization is possible through targeted learning strategies.\nOur findings establish a new direction for RAG improvement: by improving how\nmodels learn to process retrieved content, we can enhance performance across\ndiverse inference paradigms. All data and code will be publicly available on\nGithub.", "AI": {"tldr": "KARE-RAG improves RAG by enhancing knowledge utilization through structured representations, DDPO, and contrastive data generation, boosting performance across tasks with minimal training data.", "motivation": "Factual inconsistencies in RAG due to noisy retrieved documents persist despite advanced retrieval methods, highlighting the need for better generative model processing.", "method": "KARE-RAG introduces structured knowledge representations, DDPO for error correction, and a contrastive data generation pipeline to refine knowledge utilization.", "result": "The method significantly enhances RAG pipelines, improving in-domain and out-of-domain task performance without compromising general capabilities, even with modest training data.", "conclusion": "Improving how models process retrieved content can enhance RAG performance across diverse inference paradigms, with data-efficient optimization achievable through targeted learning."}}
{"id": "2506.02453", "pdf": "https://arxiv.org/pdf/2506.02453", "abs": "https://arxiv.org/abs/2506.02453", "authors": ["Kunyu Wang", "Xueyang Fu", "Yunfei Bao", "Chengjie Ge", "Chengzhi Cao", "Wei Zhai", "Zheng-Jun Zha"], "title": "PAID: Pairwise Angular-Invariant Decomposition for Continual Test-Time Adaptation", "categories": ["cs.CV"], "comment": null, "summary": "Continual Test-Time Adaptation (CTTA) aims to online adapt a pre-trained\nmodel to changing environments during inference. Most existing methods focus on\nexploiting target data, while overlooking another crucial source of\ninformation, the pre-trained weights, which encode underutilized\ndomain-invariant priors. This paper takes the geometric attributes of\npre-trained weights as a starting point, systematically analyzing three key\ncomponents: magnitude, absolute angle, and pairwise angular structure. We find\nthat the pairwise angular structure remains stable across diverse corrupted\ndomains and encodes domain-invariant semantic information, suggesting it should\nbe preserved during adaptation. Based on this insight, we propose PAID\n(Pairwise Angular-Invariant Decomposition), a prior-driven CTTA method that\ndecomposes weight into magnitude and direction, and introduces a learnable\northogonal matrix via Householder reflections to globally rotate direction\nwhile preserving the pairwise angular structure. During adaptation, only the\nmagnitudes and the orthogonal matrices are updated. PAID achieves consistent\nimprovements over recent SOTA methods on four widely used CTTA benchmarks,\ndemonstrating that preserving pairwise angular structure offers a simple yet\neffective principle for CTTA.", "AI": {"tldr": "PAID leverages the stable pairwise angular structure of pre-trained weights for continual test-time adaptation, outperforming SOTA methods by preserving domain-invariant priors.", "motivation": "Existing CTTA methods overlook domain-invariant priors in pre-trained weights, particularly the pairwise angular structure, which remains stable across domains.", "method": "PAID decomposes weights into magnitude and direction, using a learnable orthogonal matrix to rotate direction while preserving angular structure. Only magnitudes and matrices are updated.", "result": "PAID consistently improves performance over SOTA methods on four CTTA benchmarks.", "conclusion": "Preserving pairwise angular structure is a simple yet effective principle for CTTA, as demonstrated by PAID."}}
{"id": "2506.02269", "pdf": "https://arxiv.org/pdf/2506.02269", "abs": "https://arxiv.org/abs/2506.02269", "authors": ["YuQing Xie", "Tess Smidt"], "title": "A Tale of Two Symmetries: Exploring the Loss Landscape of Equivariant Models", "categories": ["cs.LG", "cs.AI"], "comment": "23 pages, 13 figures", "summary": "Equivariant neural networks have proven to be effective for tasks with known\nunderlying symmetries. However, optimizing equivariant networks can be tricky\nand best training practices are less established than for standard networks. In\nparticular, recent works have found small training benefits from relaxing\nequivariance constraints. This raises the question: do equivariance constraints\nintroduce fundamental obstacles to optimization? Or do they simply require\ndifferent hyperparameter tuning? In this work, we investigate this question\nthrough a theoretical analysis of the loss landscape geometry. We focus on\nnetworks built using permutation representations, which we can view as a subset\nof unconstrained MLPs. Importantly, we show that the parameter symmetries of\nthe unconstrained model has nontrivial effects on the loss landscape of the\nequivariant subspace and under certain conditions can provably prevent learning\nof the global minima. Further, we empirically demonstrate in such cases,\nrelaxing to an unconstrained MLP can sometimes solve the issue. Interestingly,\nthe weights eventually found via relaxation corresponds to a different choice\nof group representation in the hidden layer. From this, we draw 3 key\ntakeaways. (1) Viewing any class of networks in the context of larger\nunconstrained function space can give important insights on loss landscape\nstructure. (2) Within the unconstrained function space, equivariant networks\nform a complicated union of linear hyperplanes, each associated with a specific\nchoice of internal group representation. (3) Effective relaxation of\nequivariance may require not only adding nonequivariant degrees of freedom, but\nalso rethinking the fixed choice of group representations in hidden layers.", "AI": {"tldr": "The paper investigates the optimization challenges of equivariant neural networks, showing that equivariance constraints can hinder learning global minima and suggesting relaxation as a solution.", "motivation": "To understand why equivariant networks face optimization difficulties and whether these are due to fundamental obstacles or hyperparameter tuning.", "method": "Theoretical analysis of loss landscape geometry, focusing on permutation representations and comparing equivariant networks to unconstrained MLPs.", "result": "Equivariance constraints can prevent learning global minima; relaxing constraints or changing group representations can help.", "conclusion": "Key insights include the importance of viewing networks in unconstrained spaces, the complex structure of equivariant networks, and the need to rethink group representations for effective relaxation."}}
{"id": "2506.01982", "pdf": "https://arxiv.org/pdf/2506.01982", "abs": "https://arxiv.org/abs/2506.01982", "authors": ["Vassilis Lyberatos", "Spyridon Kantarelis", "Ioanna Zioga", "Christina Anagnostopoulou", "Giorgos Stamou", "Anastasia Georgaki"], "title": "Music interpretation and emotion perception: A computational and neurophysiological investigation", "categories": ["cs.HC", "cs.AI"], "comment": null, "summary": "This study investigates emotional expression and perception in music\nperformance using computational and neurophysiological methods. The influence\nof different performance settings, such as repertoire, diatonic modal etudes,\nand improvisation, as well as levels of expressiveness, on performers'\nemotional communication and listeners' reactions is explored. Professional\nmusicians performed various tasks, and emotional annotations were provided by\nboth performers and the audience. Audio analysis revealed that expressive and\nimprovisational performances exhibited unique acoustic features, while emotion\nanalysis showed stronger emotional responses. Neurophysiological measurements\nindicated greater relaxation in improvisational performances. This multimodal\nstudy highlights the significance of expressivity in enhancing emotional\ncommunication and audience engagement.", "AI": {"tldr": "The study examines emotional expression in music performance using computational and neurophysiological methods, finding that expressive and improvisational performances enhance emotional communication and audience engagement.", "motivation": "To understand how different performance settings and expressiveness levels influence emotional communication and listener reactions in music.", "method": "Professional musicians performed various tasks (repertoire, diatonic modal etudes, improvisation) with emotional annotations from performers and audience. Audio and neurophysiological data were analyzed.", "result": "Expressive and improvisational performances showed unique acoustic features and stronger emotional responses. Neurophysiological data indicated greater relaxation in improvisational performances.", "conclusion": "Expressivity in music performance significantly enhances emotional communication and audience engagement, as demonstrated by multimodal analysis."}}
{"id": "2506.02510", "pdf": "https://arxiv.org/pdf/2506.02510", "abs": "https://arxiv.org/abs/2506.02510", "authors": ["Jie Zhu", "Junhui Li", "Yalong Wen", "Xiandong Li", "Lifan Guo", "Feng Chen"], "title": "M$^3$FinMeeting: A Multilingual, Multi-Sector, and Multi-Task Financial Meeting Understanding Evaluation Dataset", "categories": ["cs.CL", "cs.AI"], "comment": "Accepted by ACL-2025", "summary": "Recent breakthroughs in large language models (LLMs) have led to the\ndevelopment of new benchmarks for evaluating their performance in the financial\ndomain. However, current financial benchmarks often rely on news articles,\nearnings reports, or announcements, making it challenging to capture the\nreal-world dynamics of financial meetings. To address this gap, we propose a\nnovel benchmark called $\\texttt{M$^3$FinMeeting}$, which is a multilingual,\nmulti-sector, and multi-task dataset designed for financial meeting\nunderstanding. First, $\\texttt{M$^3$FinMeeting}$ supports English, Chinese, and\nJapanese, enhancing comprehension of financial discussions in diverse\nlinguistic contexts. Second, it encompasses various industry sectors defined by\nthe Global Industry Classification Standard (GICS), ensuring that the benchmark\nspans a broad range of financial activities. Finally,\n$\\texttt{M$^3$FinMeeting}$ includes three tasks: summarization, question-answer\n(QA) pair extraction, and question answering, facilitating a more realistic and\ncomprehensive evaluation of understanding. Experimental results with seven\npopular LLMs reveal that even the most advanced long-context models have\nsignificant room for improvement, demonstrating the effectiveness of\n$\\texttt{M$^3$FinMeeting}$ as a benchmark for assessing LLMs' financial meeting\ncomprehension skills.", "AI": {"tldr": "The paper introduces $\texttt{M$^3$FinMeeting}$, a multilingual, multi-sector, multi-task benchmark for evaluating LLMs in financial meeting understanding, addressing gaps in current benchmarks.", "motivation": "Current financial benchmarks lack real-world dynamics of financial meetings, prompting the need for a more comprehensive evaluation tool.", "method": "The proposed $\texttt{M$^3$FinMeeting}$ dataset supports English, Chinese, and Japanese, covers multiple industry sectors, and includes summarization, QA pair extraction, and question answering tasks.", "result": "Experiments with seven LLMs show significant room for improvement, validating the benchmark's effectiveness.", "conclusion": "$\texttt{M$^3$FinMeeting}$ effectively assesses LLMs' financial meeting comprehension, highlighting areas for model enhancement."}}
{"id": "2506.02459", "pdf": "https://arxiv.org/pdf/2506.02459", "abs": "https://arxiv.org/abs/2506.02459", "authors": ["Martin JJ. Bucher", "Iro Armeni"], "title": "ReSpace: Text-Driven 3D Scene Synthesis and Editing with Preference Alignment", "categories": ["cs.CV", "I.2.10; I.2.7"], "comment": "20 pages, 17 figures (incl. appendix)", "summary": "Scene synthesis and editing has emerged as a promising direction in computer\ngraphics. Current trained approaches for 3D indoor scenes either oversimplify\nobject semantics through one-hot class encodings (e.g., 'chair' or 'table'),\nrequire masked diffusion for editing, ignore room boundaries, or rely on floor\nplan renderings that fail to capture complex layouts. In contrast, LLM-based\nmethods enable richer semantics via natural language (e.g., 'modern studio with\nlight wood furniture') but do not support editing, remain limited to\nrectangular layouts or rely on weak spatial reasoning from implicit world\nmodels. We introduce ReSpace, a generative framework for text-driven 3D indoor\nscene synthesis and editing using autoregressive language models. Our approach\nfeatures a compact structured scene representation with explicit room\nboundaries that frames scene editing as a next-token prediction task. We\nleverage a dual-stage training approach combining supervised fine-tuning and\npreference alignment, enabling a specially trained language model for object\naddition that accounts for user instructions, spatial geometry, object\nsemantics, and scene-level composition. For scene editing, we employ a\nzero-shot LLM to handle object removal and prompts for addition. We further\nintroduce a novel voxelization-based evaluation that captures fine-grained\ngeometry beyond 3D bounding boxes. Experimental results surpass\nstate-of-the-art on object addition while maintaining competitive results on\nfull scene synthesis.", "AI": {"tldr": "ReSpace is a generative framework for text-driven 3D indoor scene synthesis and editing using autoregressive language models, outperforming state-of-the-art methods.", "motivation": "Current methods oversimplify object semantics, lack editing support, or ignore room boundaries, while LLM-based methods lack editing capabilities or spatial reasoning.", "method": "Uses a compact structured scene representation with explicit room boundaries, dual-stage training (supervised fine-tuning and preference alignment), and zero-shot LLM for editing.", "result": "Surpasses state-of-the-art on object addition and maintains competitive full scene synthesis results.", "conclusion": "ReSpace effectively addresses limitations of existing methods by combining rich semantics, explicit boundaries, and flexible editing."}}
{"id": "2506.02276", "pdf": "https://arxiv.org/pdf/2506.02276", "abs": "https://arxiv.org/abs/2506.02276", "authors": ["Saurabh Singh", "Dmitry Lagun"], "title": "Latent Stochastic Interpolants", "categories": ["cs.LG", "stat.ML"], "comment": "Under Review", "summary": "Stochastic Interpolants (SI) are a powerful framework for generative\nmodeling, capable of flexibly transforming between two probability\ndistributions. However, their use in jointly optimized latent variable models\nremains unexplored as they require direct access to the samples from the two\ndistributions. This work presents Latent Stochastic Interpolants (LSI) enabling\njoint learning in a latent space with end-to-end optimized encoder, decoder and\nlatent SI models. We achieve this by developing a principled Evidence Lower\nBound (ELBO) objective derived directly in continuous time. The joint\noptimization allows LSI to learn effective latent representations along with a\ngenerative process that transforms an arbitrary prior distribution into the\nencoder-defined aggregated posterior. LSI sidesteps the simple priors of the\nnormal diffusion models and mitigates the computational demands of applying SI\ndirectly in high-dimensional observation spaces, while preserving the\ngenerative flexibility of the SI framework. We demonstrate the efficacy of LSI\nthrough comprehensive experiments on the standard large scale ImageNet\ngeneration benchmark.", "AI": {"tldr": "Latent Stochastic Interpolants (LSI) extend the SI framework to latent variable models, enabling joint optimization of encoder, decoder, and latent SI models with a continuous-time ELBO objective.", "motivation": "Existing SI frameworks require direct sample access, limiting their use in latent variable models. LSI addresses this gap.", "method": "LSI introduces a continuous-time ELBO objective for joint optimization of encoder, decoder, and latent SI models, avoiding high-dimensional computational costs.", "result": "LSI effectively learns latent representations and transforms arbitrary priors into aggregated posteriors, outperforming normal diffusion models.", "conclusion": "LSI combines generative flexibility with computational efficiency, validated on ImageNet generation."}}
{"id": "2506.01994", "pdf": "https://arxiv.org/pdf/2506.01994", "abs": "https://arxiv.org/abs/2506.01994", "authors": ["Wanshan Cui", "Yejin Jeong", "Inwook Song", "Gyuri Kim", "Minsang Kwon", "Donghun Lee"], "title": "Re-experiment Smart: a Novel Method to Enhance Data-driven Prediction of Mechanical Properties of Epoxy Polymers", "categories": ["cond-mat.soft", "cond-mat.mtrl-sci", "cs.AI"], "comment": "27 pages, 8 figures", "summary": "Accurate prediction of polymer material properties through data-driven\napproaches greatly accelerates novel material development by reducing redundant\nexperiments and trial-and-error processes. However, inevitable outliers in\nempirical measurements can severely skew machine learning results, leading to\nerroneous prediction models and suboptimal material designs. To address this\nlimitation, we propose a novel approach to enhance dataset quality efficiently\nby integrating multi-algorithm outlier detection with selective\nre-experimentation of unreliable outlier cases. To validate the empirical\neffectiveness of the approach, we systematically construct a new dataset\ncontaining 701 measurements of three key mechanical properties: glass\ntransition temperature ($T_g$), tan $\\delta$ peak, and crosslinking density\n($v_{c}$). To demonstrate its general applicability, we report the performance\nimprovements across multiple machine learning models, including Elastic Net,\nSVR, Random Forest, and TPOT, to predict the three key properties. Our method\nreliably reduces prediction error (RMSE) and significantly improves accuracy\nwith minimal additional experimental work, requiring only about 5% of the\ndataset to be re-measured.These findings highlight the importance of data\nquality enhancement in achieving reliable machine learning applications in\npolymer science and present a scalable strategy for improving predictive\nreliability in materials science.", "AI": {"tldr": "A novel method integrates multi-algorithm outlier detection and selective re-experimentation to improve polymer property prediction accuracy, reducing errors with minimal additional experiments.", "motivation": "Outliers in empirical measurements skew machine learning results, necessitating improved dataset quality for reliable predictions in polymer science.", "method": "Combines multi-algorithm outlier detection with selective re-experimentation on unreliable cases, validated on a dataset of 701 measurements of key mechanical properties.", "result": "Reduces prediction error (RMSE) and improves accuracy across multiple ML models (Elastic Net, SVR, Random Forest, TPOT) with only ~5% re-measurement.", "conclusion": "Highlights the importance of data quality enhancement for reliable ML applications in polymer science, offering a scalable strategy for materials science."}}
{"id": "2506.02515", "pdf": "https://arxiv.org/pdf/2506.02515", "abs": "https://arxiv.org/abs/2506.02515", "authors": ["Zhuohan Xie", "Dhruv Sahnan", "Debopriyo Banerjee", "Georgi Georgiev", "Rushil Thareja", "Hachem Madmoun", "Jinyan Su", "Aaryamonvikram Singh", "Yuxia Wang", "Rui Xing", "Fajri Koto", "Haonan Li", "Ivan Koychev", "Tanmoy Chakraborty", "Salem Lahlou", "Veselin Stoyanov", "Preslav Nakov"], "title": "FinChain: A Symbolic Benchmark for Verifiable Chain-of-Thought Financial Reasoning", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "15 pages, 8 figures, 2 tables", "summary": "Multi-step symbolic reasoning is critical for advancing downstream\nperformance on financial tasks. Yet, benchmarks for systematically evaluating\nthis capability are lacking. Existing datasets like FinQA and ConvFinQA\nsupervise only final numerical answers, without assessing intermediate\nreasoning steps. To address this, we introduce FinChain, the first symbolic\nbenchmark designed for verifiable Chain-of- Thought (CoT) financial reasoning.\nSpanning 54 topics across 12 financial domains, Fin- Chain offers five\nparameterized templates per topic, each varying in reasoning complexity and\ndomain expertise required. Each dataset instance includes an executable Python\ntrace, enabling automatic generation of extensive training data and easy\nadaptation to other domains. We also introduce ChainEval, a new metric for\nautomatic evaluation of both final answers and intermediate reasoning.\nBenchmarking 30 LLMs on our dataset, we find that even state-of-the-art models\nhave considerable room for improvement in multi-step financial reasoning. All\ntemplates and evaluation metrics for FinChain are available at https:\n//github.com/mbzuai-nlp/finchain.", "AI": {"tldr": "FinChain is a new benchmark for evaluating multi-step financial reasoning, featuring verifiable Chain-of-Thought (CoT) steps and automatic evaluation via ChainEval. It spans 54 topics across 12 domains and highlights gaps in current LLMs' performance.", "motivation": "Existing benchmarks lack evaluation of intermediate reasoning steps in financial tasks, limiting progress in multi-step reasoning.", "method": "FinChain introduces parameterized templates for diverse reasoning complexity, executable Python traces for data generation, and ChainEval for automatic evaluation.", "result": "Benchmarking 30 LLMs reveals significant room for improvement in multi-step financial reasoning, even for state-of-the-art models.", "conclusion": "FinChain fills a critical gap in financial reasoning benchmarks and provides tools for advancing multi-step reasoning capabilities."}}
{"id": "2506.02462", "pdf": "https://arxiv.org/pdf/2506.02462", "abs": "https://arxiv.org/abs/2506.02462", "authors": ["Kunyu Wang", "Xueyang Fu", "Xin Lu", "Chengjie Ge", "Chengzhi Cao", "Wei Zhai", "Zheng-Jun Zha"], "title": "Efficient Test-time Adaptive Object Detection via Sensitivity-Guided Pruning", "categories": ["cs.CV"], "comment": "Accepted as CVPR 2025 oral paper", "summary": "Continual test-time adaptive object detection (CTTA-OD) aims to online adapt\na source pre-trained detector to ever-changing environments during inference\nunder continuous domain shifts. Most existing CTTA-OD methods prioritize\neffectiveness while overlooking computational efficiency, which is crucial for\nresource-constrained scenarios. In this paper, we propose an efficient CTTA-OD\nmethod via pruning. Our motivation stems from the observation that not all\nlearned source features are beneficial; certain domain-sensitive feature\nchannels can adversely affect target domain performance. Inspired by this, we\nintroduce a sensitivity-guided channel pruning strategy that quantifies each\nchannel based on its sensitivity to domain discrepancies at both image and\ninstance levels. We apply weighted sparsity regularization to selectively\nsuppress and prune these sensitive channels, focusing adaptation efforts on\ninvariant ones. Additionally, we introduce a stochastic channel reactivation\nmechanism to restore pruned channels, enabling recovery of potentially useful\nfeatures and mitigating the risks of early pruning. Extensive experiments on\nthree benchmarks show that our method achieves superior adaptation performance\nwhile reducing computational overhead by 12% in FLOPs compared to the recent\nSOTA method.", "AI": {"tldr": "Proposes an efficient CTTA-OD method via pruning, reducing computational overhead by 12% in FLOPs while maintaining performance.", "motivation": "Not all learned source features are beneficial; some domain-sensitive channels harm target domain performance.", "method": "Sensitivity-guided channel pruning with weighted sparsity regularization and stochastic channel reactivation.", "result": "Superior adaptation performance with 12% reduction in FLOPs compared to SOTA.", "conclusion": "The method effectively balances efficiency and performance in CTTA-OD."}}
{"id": "2506.02281", "pdf": "https://arxiv.org/pdf/2506.02281", "abs": "https://arxiv.org/abs/2506.02281", "authors": ["Qinsi Wang", "Jinghan Ke", "Hancheng Ye", "Yueqian Lin", "Yuzhe Fu", "Jianyi Zhang", "Kurt Keutzer", "Chenfeng Xu", "Yiran Chen"], "title": "Angles Don't Lie: Unlocking Training-Efficient RL Through the Model's Own Signals", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Current Reinforcement Fine-tuning (RFT) paradigms for Large Language Models\n(LLMs) suffer from sample inefficiency due to the redundant exposure of\nidentical queries under uniform data sampling. While previous work has explored\ncurriculum learning via heuristic difficulty metrics, these strategies exhibit\nlimitations by neglecting the intrinsic learning signals generated by the model\nitself, thus leading to suboptimal training regimes. In this paper, we identify\na model-inherent signal termed angle concentration that effectively reflects an\nLLM's capacity to learn from specific data. We theoretically and empirically\ndemonstrate a correlation between the angular distribution of token hidden\nstate vectors and the resulting gradient, revealing a learning preference for\ndata exhibiting higher angle concentration. Inspired by this finding, we\npropose GAIN-RL, a Gradient-driven Angle-Informed Navigated RL framework. By\nleveraging the model's intrinsic angle concentration signal, GAIN-RL\ndynamically selects training data in each epoch, ensuring consistently\nimpactful gradient updates and thus significantly enhancing overall training\nefficiency. Empirical evaluations show that GAIN-RL (GRPO) achieves over a 2.5x\nacceleration in training efficiency across diverse mathematical and coding\ntasks and varying model scales. Furthermore, GAIN-RL (GRPO)'s efficient\nsampling yields data-efficient training, achieving better performance with half\nthe original data compared to vanilla GRPO with full training data. Code is\nrealsed at https://github.com/wangqinsi1/GAINRL/tree/main.", "AI": {"tldr": "GAIN-RL improves training efficiency in LLMs by dynamically selecting data based on angle concentration, achieving 2.5x faster training and better performance with less data.", "motivation": "Current RFT paradigms for LLMs are sample-inefficient due to redundant data exposure, and heuristic difficulty metrics neglect intrinsic learning signals.", "method": "Proposes GAIN-RL, a framework using angle concentration to dynamically select training data for impactful gradient updates.", "result": "GAIN-RL achieves 2.5x faster training and better performance with half the data compared to vanilla GRPO.", "conclusion": "GAIN-RL enhances training efficiency and data utilization in LLMs by leveraging intrinsic learning signals."}}
{"id": "2506.02007", "pdf": "https://arxiv.org/pdf/2506.02007", "abs": "https://arxiv.org/abs/2506.02007", "authors": ["Ruilin Xu", "Zongxuan Xie", "Pengfei Chen"], "title": "eACGM: Non-instrumented Performance Tracing and Anomaly Detection towards Machine Learning Systems", "categories": ["cs.DC", "cs.AI", "cs.NI"], "comment": "IWQoS 2025", "summary": "We present eACGM, a full-stack AI/ML system monitoring framework based on\neBPF. eACGM collects real-time performance data from key hardware components,\nincluding the GPU and network communication layer, as well as from key software\nstacks such as CUDA, Python, and PyTorch, all without requiring any code\ninstrumentation or modifications. Additionally, it leverages libnvml to gather\nprocess-level GPU resource usage information. By applying a Gaussian Mixture\nModel (GMM) to the collected multidimensional performance metrics for\nstatistical modeling and clustering analysis, eACGM effectively identifies\ncomplex failure modes, such as latency anomalies, hardware failures, and\ncommunication inefficiencies, enabling rapid diagnosis of system bottlenecks\nand abnormal behaviors.\n  To evaluate eACGM's effectiveness and practicality, we conducted extensive\nempirical studies and case analyses in multi-node distributed training\nscenarios. The results demonstrate that eACGM, while maintaining a\nnon-intrusive and low-overhead profile, successfully captures critical\nperformance anomalies during model training and inference. Its stable anomaly\ndetection performance and comprehensive monitoring capabilities validate its\napplicability and scalability in real-world production environments, providing\nstrong support for performance optimization and fault diagnosis in large-scale\nAI/ML systems.", "AI": {"tldr": "eACGM is an AI/ML monitoring framework using eBPF to collect real-time hardware/software performance data without code changes. It applies GMM for anomaly detection, proving effective in distributed training scenarios.", "motivation": "To enable non-intrusive, real-time monitoring of AI/ML systems for diagnosing performance bottlenecks and failures.", "method": "Leverages eBPF for data collection from hardware (GPU, network) and software (CUDA, Python, PyTorch), and uses GMM for anomaly detection.", "result": "Effectively identifies anomalies like latency issues and hardware failures, with low overhead in distributed training.", "conclusion": "eACGM is practical, scalable, and supports performance optimization in real-world AI/ML systems."}}
{"id": "2506.02519", "pdf": "https://arxiv.org/pdf/2506.02519", "abs": "https://arxiv.org/abs/2506.02519", "authors": ["Sohan Patnaik", "Milan Aggarwal", "Sumit Bhatia", "Balaji Krishnamurthy"], "title": "Learning Together to Perform Better: Teaching Small-Scale LLMs to Collaborate via Preferential Rationale Tuning", "categories": ["cs.CL"], "comment": "Accepted at ACL Main 2025", "summary": "LLMssuch as GPT-4 have shown a remarkable ability to solve complex questions\nby generating step-by-step rationales. Prior works have utilized this\ncapability to improve smaller and cheaper LMs (say, with 7B parameters).\nHowever, various practical constraints, such as copyright and legal issues,\nowing to lack of transparency in the pre-training data of large (often closed)\nmodels, prevent their use in commercial settings. Little focus has been given\nto improving the innate reasoning ability of smaller models without distilling\ninformation from larger LLMs. To address this, we propose COLLATE, a trainable\nframework that tunes a (small) LLM to generate those outputs from a pool of\ndiverse rationales that selectively improves the downstream task. COLLATE\nenforces multiple instances of the same LLM to exhibit distinct behavior and\nemploys them to generate rationales to obtain diverse outputs. The LLM is then\ntuned via preference optimization to choose the candidate rationale which\nmaximizes the likelihood of ground-truth answer. COLLATE outperforms several\ntrainable and prompting baselines on 5 datasets across 3 domains: maths problem\nsolving, natural language inference, and commonsense reasoning. We show the eff\nicacy of COLLATE on LLMs from different model families across varying parameter\nscales (1B to 8B) and demonstrate the benefit of multiple rationale providers\nguided by the end task through ablations. Code is released here\n(https://github.com/Sohanpatnaik106/collate).", "AI": {"tldr": "COLLATE is a framework to improve small LLMs' reasoning without relying on larger models, using diverse rationales and preference optimization.", "motivation": "Addressing the limitations of using large LLMs due to legal and transparency issues, and improving small LLMs' innate reasoning.", "method": "COLLATE generates diverse rationales from multiple LLM instances, then tunes the model to select the best rationale for task performance.", "result": "Outperforms baselines on 5 datasets across maths, NLP, and commonsense reasoning, effective for 1B-8B parameter models.", "conclusion": "COLLATE enhances small LLMs' reasoning without distillation from larger models, demonstrating scalability and task-specific benefits."}}
{"id": "2506.02472", "pdf": "https://arxiv.org/pdf/2506.02472", "abs": "https://arxiv.org/abs/2506.02472", "authors": ["Halil Ismail Helvaci", "Justin Philip Huber", "Jihye Bae", "Sen-ching Samson Cheung"], "title": "HRTR: A Single-stage Transformer for Fine-grained Sub-second Action Segmentation in Stroke Rehabilitation", "categories": ["cs.CV"], "comment": null, "summary": "Stroke rehabilitation often demands precise tracking of patient movements to\nmonitor progress, with complexities of rehabilitation exercises presenting two\ncritical challenges: fine-grained and sub-second (under one-second) action\ndetection. In this work, we propose the High Resolution Temporal Transformer\n(HRTR), to time-localize and classify high-resolution (fine-grained),\nsub-second actions in a single-stage transformer, eliminating the need for\nmulti-stage methods and post-processing. Without any refinements, HRTR\noutperforms state-of-the-art systems on both stroke related and general\ndatasets, achieving Edit Score (ES) of 70.1 on StrokeRehab Video, 69.4 on\nStrokeRehab IMU, and 88.4 on 50Salads.", "AI": {"tldr": "HRTR, a single-stage transformer, outperforms state-of-the-art methods for fine-grained, sub-second action detection in stroke rehabilitation.", "motivation": "Precise tracking of patient movements in stroke rehabilitation requires fine-grained, sub-second action detection, which existing methods struggle with.", "method": "Proposes HRTR, a High Resolution Temporal Transformer, for single-stage time-localization and classification of actions without multi-stage processing.", "result": "HRTR achieves superior performance: ES of 70.1 on StrokeRehab Video, 69.4 on StrokeRehab IMU, and 88.4 on 50Salads.", "conclusion": "HRTR is an effective solution for high-resolution, sub-second action detection in stroke rehabilitation, outperforming existing methods."}}
{"id": "2506.02285", "pdf": "https://arxiv.org/pdf/2506.02285", "abs": "https://arxiv.org/abs/2506.02285", "authors": ["Aaron Defazio"], "title": "Why Gradients Rapidly Increase Near the End of Training", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "During long-duration Large Language Model (LLM) training runs the gradient\nnorm increases rapidly near the end of training. In this short note, we show\nthat this increase is due to an unintended interaction between weight decay,\nnormalization layers, and the learning rate schedule. We propose a simple\ncorrection that fixes this behavior while also resulting in lower loss values\nthroughout training.", "AI": {"tldr": "The paper identifies and fixes an issue in LLM training where gradient norms spike due to weight decay, normalization layers, and learning rate schedules.", "motivation": "To address the unintended interaction causing gradient norm spikes in late-stage LLM training.", "method": "Proposes a simple correction to mitigate the interaction.", "result": "The fix resolves the gradient norm issue and lowers training loss.", "conclusion": "A straightforward solution improves training stability and performance."}}
{"id": "2506.02025", "pdf": "https://arxiv.org/pdf/2506.02025", "abs": "https://arxiv.org/abs/2506.02025", "authors": ["Prachi Jadhav", "Hongwei Jin", "Ewa Deelman", "Prasanna Balaprakash"], "title": "Evaluating the Efficacy of LLM-Based Reasoning for Multiobjective HPC Job Scheduling", "categories": ["cs.DC", "cs.AI"], "comment": "10 pages, 6 figures, work under review", "summary": "High-Performance Computing (HPC) job scheduling involves balancing\nconflicting objectives such as minimizing makespan, reducing wait times,\noptimizing resource use, and ensuring fairness. Traditional methods, including\nheuristic-based (e.g., First-Come-First-Served) or intensive optimization\ntechniques, often lack adaptability to dynamic workloads and heterogeneous HPC\nsystems. To address this, we propose a novel Large Language Model (LLM)-based\nscheduler using a ReAct-style framework (Reason + Act), enabling iterative,\ninterpretable decision-making. The system incorporates a scratchpad memory to\ntrack scheduling history and refine decisions via natural language feedback,\nwhile a constraint enforcement module ensures feasibility and safety. We\nevaluate our approach using OpenAI's O4-Mini and Anthropic's Claude 3.7 across\nseven real-world HPC workload scenarios, including heterogeneous mixes, bursty\npatterns, and adversarial cases. Comparisons against FCFS, Shortest Job First,\nand Google OR-Tools (on 10 to 100 jobs) reveal that LLM-based scheduling\neffectively balances multiple objectives while offering transparent reasoning\nthrough natural language traces. The method excels in constraint satisfaction\nand adapts to diverse workloads without domain-specific training. However, a\ntrade-off between reasoning quality and computational overhead challenges\nreal-time deployment. This work presents the first comprehensive study of\nreasoning-capable LLMs for HPC scheduling, demonstrating their potential to\nhandle multiobjective optimization while highlighting limitations in\ncomputational efficiency. The findings provide insights into leveraging\nadvanced language models for complex scheduling problems in dynamic HPC\nenvironments.", "AI": {"tldr": "A novel LLM-based scheduler using a ReAct framework improves HPC job scheduling by balancing multiple objectives and offering interpretable decisions, though computational overhead remains a challenge.", "motivation": "Traditional HPC scheduling methods lack adaptability to dynamic workloads and heterogeneous systems, prompting the need for an innovative approach.", "method": "The proposed LLM-based scheduler uses a ReAct-style framework with scratchpad memory for iterative decision-making and natural language feedback, alongside a constraint enforcement module.", "result": "Evaluations show the LLM-based scheduler outperforms traditional methods like FCFS and OR-Tools in balancing objectives and adapting to diverse workloads, but with computational overhead.", "conclusion": "LLM-based scheduling shows promise for multiobjective optimization in HPC but faces efficiency challenges, offering insights for future applications."}}
{"id": "2506.02527", "pdf": "https://arxiv.org/pdf/2506.02527", "abs": "https://arxiv.org/abs/2506.02527", "authors": ["Yingying Zhuang", "Aman Gupta", "Anurag Beniwal"], "title": "Multilingual Information Retrieval with a Monolingual Knowledge Base", "categories": ["cs.CL", "cs.AI", "cs.IR"], "comment": "6 pages, accepted at GENNEXT@SIGIR25", "summary": "Multilingual information retrieval has emerged as powerful tools for\nexpanding knowledge sharing across languages. On the other hand, resources on\nhigh quality knowledge base are often scarce and in limited languages,\ntherefore an effective embedding model to transform sentences from different\nlanguages into a feature vector space same as the knowledge base language\nbecomes the key ingredient for cross language knowledge sharing, especially to\ntransfer knowledge available in high-resource languages to low-resource ones.\nIn this paper we propose a novel strategy to fine-tune multilingual embedding\nmodels with weighted sampling for contrastive learning, enabling multilingual\ninformation retrieval with a monolingual knowledge base. We demonstrate that\nthe weighted sampling strategy produces performance gains compared to standard\nones by up to 31.03\\% in MRR and up to 33.98\\% in Recall@3. Additionally, our\nproposed methodology is language agnostic and applicable for both multilingual\nand code switching use cases.", "AI": {"tldr": "The paper proposes a weighted sampling strategy for fine-tuning multilingual embedding models to enhance cross-language knowledge sharing, achieving significant performance improvements in retrieval tasks.", "motivation": "High-quality knowledge bases are often limited to a few languages, creating a need for effective embedding models to bridge the gap between high-resource and low-resource languages.", "method": "A novel weighted sampling strategy for contrastive learning is introduced to fine-tune multilingual embedding models, enabling retrieval with a monolingual knowledge base.", "result": "The method improves performance by up to 31.03% in MRR and 33.98% in Recall@3 compared to standard approaches.", "conclusion": "The proposed strategy is language-agnostic and effective for multilingual and code-switching scenarios, enhancing cross-language knowledge transfer."}}
{"id": "2506.02473", "pdf": "https://arxiv.org/pdf/2506.02473", "abs": "https://arxiv.org/abs/2506.02473", "authors": ["Xinran Nicole Han", "Ko Nishino", "Todd Zickler"], "title": "Generative Perception of Shape and Material from Differential Motion", "categories": ["cs.CV"], "comment": null, "summary": "Perceiving the shape and material of an object from a single image is\ninherently ambiguous, especially when lighting is unknown and unconstrained.\nDespite this, humans can often disentangle shape and material, and when they\nare uncertain, they often move their head slightly or rotate the object to help\nresolve the ambiguities. Inspired by this behavior, we introduce a novel\nconditional denoising-diffusion model that generates samples of\nshape-and-material maps from a short video of an object undergoing differential\nmotions. Our parameter-efficient architecture allows training directly in\npixel-space, and it generates many disentangled attributes of an object\nsimultaneously. Trained on a modest number of synthetic object-motion videos\nwith supervision on shape and material, the model exhibits compelling emergent\nbehavior: For static observations, it produces diverse, multimodal predictions\nof plausible shape-and-material maps that capture the inherent ambiguities; and\nwhen objects move, the distributions quickly converge to more accurate\nexplanations. The model also produces high-quality shape-and-material estimates\nfor less ambiguous, real-world objects. By moving beyond single-view to\ncontinuous motion observations, our work suggests a generative perception\napproach for improving visual reasoning in physically-embodied systems.", "AI": {"tldr": "A diffusion model generates shape-and-material maps from short videos of moving objects, addressing ambiguities in single-image perception.", "motivation": "Humans resolve shape and material ambiguities by observing motion, inspiring a model to mimic this behavior for better visual reasoning.", "method": "A conditional denoising-diffusion model trained on synthetic object-motion videos generates disentangled shape-and-material maps.", "result": "The model produces diverse predictions for static images and accurate estimates for moving objects, even generalizing to real-world objects.", "conclusion": "Continuous motion observations improve generative perception, suggesting applications for embodied systems."}}
{"id": "2506.02293", "pdf": "https://arxiv.org/pdf/2506.02293", "abs": "https://arxiv.org/abs/2506.02293", "authors": ["Marco Pacini", "Gabriele Santin", "Bruno Lepri", "Shubhendu Trivedi"], "title": "On Universality Classes of Equivariant Networks", "categories": ["cs.LG"], "comment": "Preprint. Under review. 22 pages", "summary": "Equivariant neural networks provide a principled framework for incorporating\nsymmetry into learning architectures and have been extensively analyzed through\nthe lens of their separation power, that is, the ability to distinguish inputs\nmodulo symmetry. This notion plays a central role in settings such as graph\nlearning, where it is often formalized via the Weisfeiler-Leman hierarchy. In\ncontrast, the universality of equivariant models-their capacity to approximate\ntarget functions-remains comparatively underexplored. In this work, we\ninvestigate the approximation power of equivariant neural networks beyond\nseparation constraints. We show that separation power does not fully capture\nexpressivity: models with identical separation power may differ in their\napproximation ability. To demonstrate this, we characterize the universality\nclasses of shallow invariant networks, providing a general framework for\nunderstanding which functions these architectures can approximate. Since\nequivariant models reduce to invariant ones under projection, this analysis\nyields sufficient conditions under which shallow equivariant networks fail to\nbe universal. Conversely, we identify settings where shallow models do achieve\nseparation-constrained universality. These positive results, however, depend\ncritically on structural properties of the symmetry group, such as the\nexistence of adequate normal subgroups, which may not hold in important cases\nlike permutation symmetry.", "AI": {"tldr": "The paper explores the universality of equivariant neural networks, showing that separation power alone doesn't fully capture expressivity, and characterizes their approximation ability under various symmetry conditions.", "motivation": "To understand the approximation power of equivariant neural networks beyond separation constraints, as universality remains underexplored compared to separation power.", "method": "Analyzes the universality classes of shallow invariant networks and extends insights to equivariant networks via projection. Identifies conditions for universality failure and success.", "result": "Shows that models with identical separation power may differ in approximation ability. Provides conditions for universality failure and identifies settings where shallow models achieve separation-constrained universality.", "conclusion": "Universality of equivariant networks depends on structural properties of the symmetry group, with limitations in cases like permutation symmetry."}}
{"id": "2506.02027", "pdf": "https://arxiv.org/pdf/2506.02027", "abs": "https://arxiv.org/abs/2506.02027", "authors": ["Shriphani Palakodety"], "title": "The End Of Universal Lifelong Identifiers: Identity Systems For The AI Era", "categories": ["cs.CR", "cs.AI", "cs.CY"], "comment": "9 content pages, 14 pages with reference", "summary": "Many identity systems assign a single, static identifier to an individual for\nlife, reused across domains like healthcare, finance, and education. These\nUniversal Lifelong Identifiers (ULIs) underpin critical workflows but now pose\nsystemic privacy risks. We take the position that ULIs are fundamentally\nincompatible with the AI era and must be phased out. We articulate a threat\nmodel grounded in modern AI capabilities and show that traditional safeguards\nsuch as redaction, consent, and access controls are no longer sufficient. We\ndefine core properties for identity systems in the AI era and present a\ncryptographic framework that satisfies them while retaining compatibility with\nexisting identifier workflows. Our design preserves institutional workflows,\nsupports essential functions such as auditability and delegation, and offers a\npractical migration path beyond ULIs.", "AI": {"tldr": "The paper argues that Universal Lifelong Identifiers (ULIs) are outdated and pose privacy risks in the AI era, proposing a cryptographic framework as a replacement.", "motivation": "ULIs, used across domains like healthcare and finance, now present systemic privacy risks due to advancements in AI, making traditional safeguards insufficient.", "method": "The authors define core properties for AI-era identity systems and introduce a cryptographic framework that meets these while maintaining compatibility with existing workflows.", "result": "The proposed framework preserves institutional workflows, supports auditability and delegation, and provides a practical migration path away from ULIs.", "conclusion": "ULIs are incompatible with the AI era, and the proposed cryptographic solution offers a viable alternative without disrupting current systems."}}
{"id": "2506.02532", "pdf": "https://arxiv.org/pdf/2506.02532", "abs": "https://arxiv.org/abs/2506.02532", "authors": ["Jinu Lee", "Sagnik Mukherjee", "Dilek Hakkani-Tur", "Julia Hockenmaier"], "title": "ReasoningFlow: Semantic Structure of Complex Reasoning Traces", "categories": ["cs.CL"], "comment": "10 pages, 6 figures. ArgMining 2025 Workshop (Non-archival) @ ACL\n  2025", "summary": "Large reasoning models (LRMs) generate complex reasoning traces with\nplanning, reflection, verification, and backtracking. In this work, we\nintroduce ReasoningFlow, a unified schema for analyzing the semantic structures\nof these complex traces. ReasoningFlow parses traces into directed acyclic\ngraphs, enabling the characterization of distinct reasoning patterns as\nsubgraph structures. This human-interpretable representation offers promising\napplications in understanding, evaluating, and enhancing the reasoning\nprocesses of LRMs.", "AI": {"tldr": "ReasoningFlow is a schema for analyzing semantic structures in complex reasoning traces of large reasoning models (LRMs), represented as directed acyclic graphs.", "motivation": "To understand, evaluate, and enhance the reasoning processes of LRMs by analyzing their complex traces.", "method": "Introduces ReasoningFlow, which parses reasoning traces into directed acyclic graphs to identify distinct reasoning patterns.", "result": "Human-interpretable representation of reasoning traces, enabling better analysis and improvement of LRMs.", "conclusion": "ReasoningFlow offers a promising approach to dissect and improve the reasoning capabilities of LRMs."}}
{"id": "2506.02477", "pdf": "https://arxiv.org/pdf/2506.02477", "abs": "https://arxiv.org/abs/2506.02477", "authors": ["Kunyu Wang", "Xueyang Fu", "Chengzhi Cao", "Chengjie Ge", "Wei Zhai", "Zheng-Jun Zha"], "title": "Towards Better De-raining Generalization via Rainy Characteristics Memorization and Replay", "categories": ["cs.CV"], "comment": null, "summary": "Current image de-raining methods primarily learn from a limited dataset,\nleading to inadequate performance in varied real-world rainy conditions. To\ntackle this, we introduce a new framework that enables networks to\nprogressively expand their de-raining knowledge base by tapping into a growing\npool of datasets, significantly boosting their adaptability. Drawing\ninspiration from the human brain's ability to continuously absorb and\ngeneralize from ongoing experiences, our approach borrow the mechanism of the\ncomplementary learning system. Specifically, we first deploy Generative\nAdversarial Networks (GANs) to capture and retain the unique features of new\ndata, mirroring the hippocampus's role in learning and memory. Then, the\nde-raining network is trained with both existing and GAN-synthesized data,\nmimicking the process of hippocampal replay and interleaved learning.\nFurthermore, we employ knowledge distillation with the replayed data to\nreplicate the synergy between the neocortex's activity patterns triggered by\nhippocampal replays and the pre-existing neocortical knowledge. This\ncomprehensive framework empowers the de-raining network to amass knowledge from\nvarious datasets, continually enhancing its performance on previously unseen\nrainy scenes. Our testing on three benchmark de-raining networks confirms the\nframework's effectiveness. It not only facilitates continuous knowledge\naccumulation across six datasets but also surpasses state-of-the-art methods in\ngeneralizing to new real-world scenarios.", "AI": {"tldr": "A new framework for image de-raining uses GANs and knowledge distillation to continuously learn from expanding datasets, improving adaptability and performance in varied rainy conditions.", "motivation": "Existing de-raining methods perform poorly in diverse real-world scenarios due to limited training data. The goal is to enhance adaptability by mimicking the human brain's continuous learning process.", "method": "The framework employs GANs to capture new data features (like the hippocampus) and trains the de-raining network with synthesized and existing data. Knowledge distillation replicates neocortical learning.", "result": "The framework outperforms state-of-the-art methods, enabling continuous knowledge accumulation across six datasets and better generalization to unseen rainy scenes.", "conclusion": "The proposed approach effectively enhances de-raining performance by leveraging continuous learning, inspired by the human brain's complementary learning system."}}
{"id": "2506.02300", "pdf": "https://arxiv.org/pdf/2506.02300", "abs": "https://arxiv.org/abs/2506.02300", "authors": ["Farzaneh Mahdisoltani", "Saeed Mahdisoltani", "Roger B. Grosse", "David J. Fleet"], "title": "Through a Steerable Lens: Magnifying Neural Network Interpretability via Phase-Based Extrapolation", "categories": ["cs.LG"], "comment": null, "summary": "Understanding the internal representations and decision mechanisms of deep\nneural networks remains a critical open challenge. While existing\ninterpretability methods often identify influential input regions, they may not\nelucidate how a model distinguishes between classes or what specific changes\nwould transition an input from one category to another. To address these\nlimitations, we propose a novel framework that visualizes the implicit path\nbetween classes by treating the network gradient as a form of infinitesimal\nmotion. Drawing inspiration from phase-based motion magnification, we first\ndecompose images using invertible transforms-specifically the Complex Steerable\nPyramid-then compute class-conditional gradients in the transformed space.\nRather than iteratively integrating the gradient to trace a full path, we\namplify the one-step gradient to the input and perform a linear extrapolation\nto expose how the model moves from source to target class. By operating in the\nsteerable pyramid domain, these amplified gradients produce semantically\nmeaningful, spatially coherent morphs that highlight the classifier's most\nsensitive directions, giving insight into the geometry of its decision\nboundaries. Experiments on both synthetic and real-world datasets demonstrate\nthat our phase-focused extrapolation yields perceptually aligned, semantically\nmeaningful transformations, offering a novel, interpretable lens into neural\nclassifiers' internal representations.", "AI": {"tldr": "The paper proposes a framework to visualize how deep neural networks transition inputs between classes using gradient-based motion magnification in the steerable pyramid domain.", "motivation": "Existing interpretability methods fail to show how models distinguish classes or what changes would transition inputs between categories.", "method": "The framework decomposes images using the Complex Steerable Pyramid, computes class-conditional gradients, and amplifies them to reveal transition paths.", "result": "The method produces semantically meaningful, coherent morphs that expose the model's sensitive directions and decision boundaries.", "conclusion": "The approach offers a novel, interpretable way to understand neural classifiers' internal representations."}}
{"id": "2506.02032", "pdf": "https://arxiv.org/pdf/2506.02032", "abs": "https://arxiv.org/abs/2506.02032", "authors": ["Raj Patel", "Himanshu Tripathi", "Jasper Stone", "Noorbakhsh Amiri Golilarz", "Sudip Mittal", "Shahram Rahimi", "Vini Chaudhary"], "title": "Towards Secure MLOps: Surveying Attacks, Mitigation Strategies, and Research Challenges", "categories": ["cs.CR", "cs.AI"], "comment": null, "summary": "The rapid adoption of machine learning (ML) technologies has driven\norganizations across diverse sectors to seek efficient and reliable methods to\naccelerate model development-to-deployment. Machine Learning Operations (MLOps)\nhas emerged as an integrative approach addressing these requirements by\nunifying relevant roles and streamlining ML workflows. As the MLOps market\ncontinues to grow, securing these pipelines has become increasingly critical.\nHowever, the unified nature of MLOps ecosystem introduces vulnerabilities,\nmaking them susceptible to adversarial attacks where a single misconfiguration\ncan lead to compromised credentials, severe financial losses, damaged public\ntrust, and the poisoning of training data. Our paper presents a systematic\napplication of the MITRE ATLAS (Adversarial Threat Landscape for\nArtificial-Intelligence Systems) framework, a comprehensive and continuously\nupdated catalog of AI-focused attacks, to systematically assess attacks across\ndifferent phases of the MLOps ecosystem. We begin by examining the preparatory\nphases during which adversaries acquire the essential intelligence required to\ninitiate their attacks. We then present a structured taxonomy of attack\ntechniques explicitly mapped to corresponding phases of the MLOps ecosystem,\nsupported by examples drawn from red-teaming exercises and real-world\nincidents. This is followed by a taxonomy of mitigation strategies aligned with\nthese attack categories, offering actionable early-stage defenses to strengthen\nthe security of MLOps ecosystem. Given the rapid evolution and adoption of\nMLOps, we further highlight key research gaps that require immediate attention.\nOur work emphasizes the importance of implementing robust security protocols\nfrom the outset, empowering practitioners to safeguard MLOps ecosystem against\nevolving cyber attacks.", "AI": {"tldr": "The paper applies the MITRE ATLAS framework to assess and mitigate adversarial threats in the MLOps ecosystem, providing a taxonomy of attacks and defenses.", "motivation": "The rapid growth of MLOps introduces security vulnerabilities, necessitating systematic threat assessment and mitigation to protect against adversarial attacks.", "method": "The study uses the MITRE ATLAS framework to analyze attacks across MLOps phases, supported by real-world examples and red-teaming exercises.", "result": "A structured taxonomy of attack techniques and mitigation strategies is developed, highlighting key research gaps.", "conclusion": "Robust security protocols are essential to safeguard MLOps ecosystems from evolving cyber threats."}}
{"id": "2506.02533", "pdf": "https://arxiv.org/pdf/2506.02533", "abs": "https://arxiv.org/abs/2506.02533", "authors": ["Maike Behrendt", "Stefan Sylvius Wagner", "Carina Weinmann", "Marike Bormann", "Mira Warne", "Stefan Harmeling"], "title": "Natural Language Processing to Enhance Deliberation in Political Online Discussions: A Survey", "categories": ["cs.CL", "cs.HC"], "comment": null, "summary": "Political online participation in the form of discussing political issues and\nexchanging opinions among citizens is gaining importance with more and more\nformats being held digitally. To come to a decision, a careful discussion and\nconsideration of opinions and a civil exchange of arguments, which is defined\nas the act of deliberation, is desirable. The quality of discussions and\nparticipation processes in terms of their deliberativeness highly depends on\nthe design of platforms and processes. To facilitate online communication for\nboth participants and initiators, machine learning methods offer a lot of\npotential. In this work we want to showcase which issues occur in political\nonline discussions and how machine learning can be used to counteract these\nissues and enhance deliberation.", "AI": {"tldr": "The paper explores how machine learning can improve the quality of political online discussions by addressing common issues and enhancing deliberation.", "motivation": "Political online participation is growing, but the quality of discussions depends on platform design. Machine learning can help improve deliberation.", "method": "The study identifies issues in political online discussions and proposes machine learning solutions to enhance deliberation.", "result": "Machine learning can counteract common issues in online discussions, improving the deliberative quality of political participation.", "conclusion": "Machine learning offers significant potential to enhance the deliberativeness of political online discussions by addressing design and process challenges."}}
{"id": "2506.02488", "pdf": "https://arxiv.org/pdf/2506.02488", "abs": "https://arxiv.org/abs/2506.02488", "authors": ["Hongtao Huang", "Xiaojun Chang", "Lina Yao"], "title": "Flexiffusion: Training-Free Segment-Wise Neural Architecture Search for Efficient Diffusion Models", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Diffusion models (DMs) are powerful generative models capable of producing\nhigh-fidelity images but are constrained by high computational costs due to\niterative multi-step inference. While Neural Architecture Search (NAS) can\noptimize DMs, existing methods are hindered by retraining requirements,\nexponential search complexity from step-wise optimization, and slow evaluation\nrelying on massive image generation. To address these challenges, we propose\nFlexiffusion, a training-free NAS framework that jointly optimizes generation\nschedules and model architectures without modifying pre-trained parameters. Our\nkey insight is to decompose the generation process into flexible segments of\nequal length, where each segment dynamically combines three step types: full\n(complete computation), partial (cache-reused computation), and null (skipped\ncomputation). This segment-wise search space reduces the candidate pool\nexponentially compared to step-wise NAS while preserving architectural\ndiversity. Further, we introduce relative FID (rFID), a lightweight evaluation\nmetric for NAS that measures divergence from a teacher model's outputs instead\nof ground truth, slashing evaluation time by over $90\\%$. In practice,\nFlexiffusion achieves at least $2\\times$ acceleration across LDMs, Stable\nDiffusion, and DDPMs on ImageNet and MS-COCO, with FID degradation under $5\\%$,\noutperforming prior NAS and caching methods. Notably, it attains $5.1\\times$\nspeedup on Stable Diffusion with near-identical CLIP scores. Our work pioneers\na resource-efficient paradigm for searching high-speed DMs without sacrificing\nquality.", "AI": {"tldr": "Flexiffusion is a training-free NAS framework for optimizing diffusion models, achieving significant speedup with minimal quality loss.", "motivation": "Address computational inefficiency in diffusion models due to iterative multi-step inference and limitations of existing NAS methods.", "method": "Decomposes generation into flexible segments with dynamic step types (full, partial, null) and introduces rFID for lightweight evaluation.", "result": "Achieves 2\u00d7 to 5.1\u00d7 speedup on models like Stable Diffusion with FID degradation under 5%.", "conclusion": "Pioneers a resource-efficient NAS paradigm for high-speed diffusion models without quality sacrifice."}}
{"id": "2506.02306", "pdf": "https://arxiv.org/pdf/2506.02306", "abs": "https://arxiv.org/abs/2506.02306", "authors": ["Aditya Gorla", "Ryan Wang", "Zhengtong Liu", "Ulzee An", "Sriram Sankararaman"], "title": "CACTI: Leveraging Copy Masking and Contextual Information to Improve Tabular Data Imputation", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "We present CACTI, a masked autoencoding approach for imputing tabular data\nthat leverages the structure in missingness patterns and contextual\ninformation. Our approach employs a novel median truncated copy masking\ntraining strategy that encourages the model to learn from empirical patterns of\nmissingness while incorporating semantic relationships between features -\ncaptured by column names and text descriptions - to better represent feature\ndependence. These dual sources of inductive bias enable CACTI to outperform\nstate-of-the-art methods - an average $R^2$ gain of 7.8% over the next best\nmethod (13.4%, 6.1%, and 5.3% under missing not at random, at random and\ncompletely at random, respectively) - across a diverse range of datasets and\nmissingness conditions. Our results highlight the value of leveraging\ndataset-specific contextual information and missingness patterns to enhance\nimputation performance.", "AI": {"tldr": "CACTI is a masked autoencoding method for tabular data imputation that uses missingness patterns and contextual info, outperforming state-of-the-art methods by 7.8% average R\u00b2 gain.", "motivation": "To improve tabular data imputation by leveraging missingness patterns and contextual information (e.g., column names, text descriptions) for better feature dependence representation.", "method": "Uses a median truncated copy masking strategy to learn from missingness patterns and incorporates semantic relationships between features.", "result": "Achieves an average R\u00b2 gain of 7.8% over the next best method, with improvements under various missingness conditions (13.4%, 6.1%, 5.3%).", "conclusion": "Leveraging dataset-specific contextual info and missingness patterns significantly enhances imputation performance."}}
{"id": "2506.02046", "pdf": "https://arxiv.org/pdf/2506.02046", "abs": "https://arxiv.org/abs/2506.02046", "authors": ["Mohammad Saleh Torkestani", "Taha Mansouri"], "title": "Machine vs Machine: Using AI to Tackle Generative AI Threats in Assessment", "categories": ["cs.CY", "cs.AI", "K.3.1"], "comment": "Paper presented at the Learning, Teaching & Student Experience 2025\n  Conference. The Chartered Association of Business Schools (CABS), Nottingham,\n  UK", "summary": "This paper presents a theoretical framework for addressing the challenges\nposed by generative artificial intelligence (AI) in higher education assessment\nthrough a machine-versus-machine approach. Large language models like GPT-4,\nClaude, and Llama increasingly demonstrate the ability to produce sophisticated\nacademic content, traditional assessment methods face an existential threat,\nwith surveys indicating 74-92% of students experimenting with these tools for\nacademic purposes. Current responses, ranging from detection software to manual\nassessment redesign, show significant limitations: detection tools demonstrate\nbias against non-native English writers and can be easily circumvented, while\nmanual frameworks rely heavily on subjective judgment and assume static AI\ncapabilities. This paper introduces a dual strategy paradigm combining static\nanalysis and dynamic testing to create a comprehensive theoretical framework\nfor assessment vulnerability evaluation. The static analysis component\ncomprises eight theoretically justified elements: specificity and\ncontextualization, temporal relevance, process visibility requirements,\npersonalization elements, resource accessibility, multimodal integration,\nethical reasoning requirements, and collaborative elements. Each element\naddresses specific limitations in generative AI capabilities, creating barriers\nthat distinguish authentic human learning from AI-generated simulation. The\ndynamic testing component provides a complementary approach through\nsimulation-based vulnerability assessment, addressing limitations in\npattern-based analysis. The paper presents a theoretical framework for\nvulnerability scoring, including the conceptual basis for quantitative\nassessment, weighting frameworks, and threshold determination theory.", "AI": {"tldr": "The paper proposes a machine-versus-machine framework to counter generative AI's impact on higher education assessment, combining static analysis and dynamic testing to evaluate vulnerabilities.", "motivation": "Generative AI (e.g., GPT-4) threatens traditional assessment methods, with high student usage rates (74-92%). Current solutions (detection tools, manual redesign) are flawed due to bias, circumvention, and subjectivity.", "method": "Introduces a dual strategy: static analysis (8 elements targeting AI limitations) and dynamic testing (simulation-based vulnerability assessment).", "result": "A theoretical framework for vulnerability scoring, including quantitative assessment, weighting, and threshold determination.", "conclusion": "The framework offers a comprehensive solution to distinguish human learning from AI-generated content, addressing current assessment flaws."}}
{"id": "2506.02536", "pdf": "https://arxiv.org/pdf/2506.02536", "abs": "https://arxiv.org/abs/2506.02536", "authors": ["Xin Liu", "Lu Wang"], "title": "Answer Convergence as a Signal for Early Stopping in Reasoning", "categories": ["cs.CL"], "comment": null, "summary": "Chain-of-thought (CoT) prompting enhances reasoning in large language models\n(LLMs) but often leads to verbose and redundant outputs, thus increasing\ninference cost. We hypothesize that many reasoning steps are unnecessary for\nproducing correct answers. To investigate this, we start with a systematic\nstudy to examine what is the minimum reasoning required for a model to reach a\nstable decision. We find that on math reasoning tasks like math, models\ntypically converge to their final answers after 60\\% of the reasoning steps,\nsuggesting substantial redundancy in the remaining content. Based on these\ninsights, we propose three inference-time strategies to improve efficiency: (1)\nearly stopping via answer consistency, (2) boosting the probability of\ngenerating end-of-reasoning signals, and (3) a supervised method that learns\nwhen to stop based on internal activations. Experiments across five benchmarks\nand five open-weights LLMs show that our methods significantly reduce token\nusage with little or no accuracy drop. In particular, on NaturalQuestions,\nAnswer Consistency reduces tokens by over 40\\% while further improving\naccuracy. Our work underscores the importance of cost-effective reasoning\nmethods that operate at inference time, offering practical benefits for\nreal-world applications.", "AI": {"tldr": "CoT prompting in LLMs is often verbose and redundant. The study finds that 60% of reasoning steps suffice for correct answers, leading to three efficiency strategies: early stopping, boosting end signals, and supervised stopping. These reduce token usage significantly without accuracy loss.", "motivation": "To address the inefficiency and redundancy in CoT prompting, which increases inference costs without always improving accuracy.", "method": "Systematic study of minimum required reasoning steps, followed by three inference-time strategies: early stopping, boosting end signals, and supervised stopping.", "result": "Methods reduce token usage by up to 40% with little or no accuracy drop, e.g., Answer Consistency improves efficiency on NaturalQuestions.", "conclusion": "Cost-effective reasoning methods at inference time are crucial for practical LLM applications, balancing efficiency and accuracy."}}
{"id": "2506.02492", "pdf": "https://arxiv.org/pdf/2506.02492", "abs": "https://arxiv.org/abs/2506.02492", "authors": ["Yuanpeng He", "Lijian Li", "Tianxiang Zhan", "Chi-Man Pun", "Wenpin Jiao", "Zhi Jin"], "title": "Co-Evidential Fusion with Information Volume for Medical Image Segmentation", "categories": ["cs.CV"], "comment": null, "summary": "Although existing semi-supervised image segmentation methods have achieved\ngood performance, they cannot effectively utilize multiple sources of\nvoxel-level uncertainty for targeted learning. Therefore, we propose two main\nimprovements. First, we introduce a novel pignistic co-evidential fusion\nstrategy using generalized evidential deep learning, extended by traditional\nD-S evidence theory, to obtain a more precise uncertainty measure for each\nvoxel in medical samples. This assists the model in learning mixed labeled\ninformation and establishing semantic associations between labeled and\nunlabeled data. Second, we introduce the concept of information volume of mass\nfunction (IVUM) to evaluate the constructed evidence, implementing two\nevidential learning schemes. One optimizes evidential deep learning by\ncombining the information volume of the mass function with original uncertainty\nmeasures. The other integrates the learning pattern based on the co-evidential\nfusion strategy, using IVUM to design a new optimization objective. Experiments\non four datasets demonstrate the competitive performance of our method.", "AI": {"tldr": "The paper proposes improvements to semi-supervised image segmentation by introducing a pignistic co-evidential fusion strategy and the concept of IVUM for better uncertainty utilization and learning.", "motivation": "Existing methods fail to effectively use multiple sources of voxel-level uncertainty for targeted learning in semi-supervised image segmentation.", "method": "1. A pignistic co-evidential fusion strategy for precise uncertainty measures. 2. Introduction of IVUM to evaluate evidence and implement two evidential learning schemes.", "result": "Experiments on four datasets show competitive performance.", "conclusion": "The proposed method enhances uncertainty utilization and learning in semi-supervised image segmentation."}}
{"id": "2506.02308", "pdf": "https://arxiv.org/pdf/2506.02308", "abs": "https://arxiv.org/abs/2506.02308", "authors": ["Xiaojun Shan", "Qi Cao", "Xing Han", "Haofei Yu", "Paul Pu Liang"], "title": "MINT: Multimodal Instruction Tuning with Multimodal Interaction Grouping", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Recent advances in multimodal foundation models have achieved\nstate-of-the-art performance across a range of tasks. These breakthroughs are\nlargely driven by new pre-training paradigms that leverage large-scale,\nunlabeled multimodal data, followed by instruction fine-tuning on curated\nlabeled datasets and high-quality prompts. While there is growing interest in\nscaling instruction fine-tuning to ever-larger datasets in both quantity and\nscale, our findings reveal that simply increasing the number of\ninstruction-tuning tasks does not consistently yield better performance.\nInstead, we observe that grouping tasks by the common interactions across\nmodalities, such as discovering redundant shared information, prioritizing\nmodality selection with unique information, or requiring synergistic fusion to\ndiscover new information from both modalities, encourages the models to learn\ntransferrable skills within a group while suppressing interference from\nmismatched tasks. To this end, we introduce MINT, a simple yet surprisingly\neffective task-grouping strategy based on the type of multimodal interaction.\nWe demonstrate that the proposed method greatly outperforms existing task\ngrouping baselines for multimodal instruction tuning, striking an effective\nbalance between generalization and specialization.", "AI": {"tldr": "Increasing instruction-tuning tasks doesn't always improve performance; grouping tasks by multimodal interactions (e.g., shared or unique information) is more effective. MINT, a new task-grouping strategy, outperforms baselines.", "motivation": "To address the inefficiency of scaling instruction fine-tuning by simply adding more tasks, focusing instead on how tasks interact across modalities.", "method": "Introduces MINT, a task-grouping strategy based on multimodal interaction types (e.g., redundant shared information, unique modality selection, synergistic fusion).", "result": "MINT outperforms existing task-grouping baselines, balancing generalization and specialization effectively.", "conclusion": "Task grouping by multimodal interactions is key for effective instruction tuning, with MINT proving superior to traditional scaling approaches."}}
{"id": "2506.02048", "pdf": "https://arxiv.org/pdf/2506.02048", "abs": "https://arxiv.org/abs/2506.02048", "authors": ["Lajos Muzsai", "David Imolai", "Andr\u00e1s Luk\u00e1cs"], "title": "Improving LLM Agents with Reinforcement Learning on Cryptographic CTF Challenges", "categories": ["cs.CR", "cs.AI", "68M25", "I.2.1; K.6.5"], "comment": "11 pages, 1 figure", "summary": "Large Language Models (LLMs) still struggle with the structured reasoning and\ntool-assisted computation needed for problem solving in cybersecurity\napplications. In this work, we introduce \"random-crypto\", a cryptographic\nCapture-the-Flag (CTF) challenge generator framework that we use to fine-tune a\ntool-augmented Llama-3.1-8B with Guided Reinforcement Prompt Optimisation\n(GRPO), allowing the agent to iteratively write and execute Python inside an\nisolated REPL. GRPO yields a +53% absolute jump in Pass@8 on unseen\n\"random-crypto\" tasks (0.35 -> 0.88) and raises Majority@8 to 0.41. The\nfine-tuned agent also generalizes to an external dataset. On a subset of\npicoCTF cryptography problems, it improves Pass@8 by +13 pp. Ablations show the\ngains stem from more reliable tool invocation and code synthesis, rather than\nsuperficial prompt adaptation.", "AI": {"tldr": "A framework called 'random-crypto' fine-tunes Llama-3.1-8B with GRPO, improving its structured reasoning and tool-assisted computation for cybersecurity tasks.", "motivation": "LLMs struggle with structured reasoning and tool use in cybersecurity, prompting the need for better performance in such applications.", "method": "Fine-tuning Llama-3.1-8B using GRPO, enabling iterative Python execution in an isolated REPL for cryptographic CTF challenges.", "result": "+53% Pass@8 improvement on 'random-crypto' tasks (0.35 to 0.88) and +13 pp on picoCTF problems, due to better tool invocation and code synthesis.", "conclusion": "GRPO enhances LLM performance in cybersecurity tasks, demonstrating reliable tool use and generalization to external datasets."}}
{"id": "2506.02544", "pdf": "https://arxiv.org/pdf/2506.02544", "abs": "https://arxiv.org/abs/2506.02544", "authors": ["Yang Tian", "Fan Liu", "Jingyuan Zhang", "Victoria W.", "Yupeng Hu", "Liqiang Nie"], "title": "CoRe-MMRAG: Cross-Source Knowledge Reconciliation for Multimodal RAG", "categories": ["cs.CL", "cs.AI"], "comment": "Accepted to ACL 2025 Main", "summary": "Multimodal Retrieval-Augmented Generation (MMRAG) has been introduced to\nenhance Multimodal Large Language Models by incorporating externally retrieved\nmultimodal knowledge, but it introduces two challenges: Parametric-Retrieved\nKnowledge Inconsistency (PRKI), where discrepancies between parametric and\nretrieved knowledge create uncertainty in determining reliability, and\nVisual-Textual Knowledge Inconsistency (VTKI), where misalignment between\nvisual and textual sources disrupts entity representation. To address these\nchallenges, we propose \\textbf{C}r\\textbf{o}ss-source knowledge\n\\textbf{Re}conciliation for \\textbf{M}ulti\\textbf{M}odal \\textbf{RAG}\n(CoRe-MMRAG), a novel end-to-end framework that effectively reconciles\ninconsistencies across knowledge sources. CoRe-MMRAG follows a four-stage\npipeline: it first generates an internal response from parametric knowledge,\nthen selects the most relevant multimodal evidence via joint similarity\nassessment, generates an external response, and finally integrates both to\nproduce a reliable answer. Additionally, a specialized training paradigm\nenhances knowledge source discrimination, multimodal integration, and unified\nanswer generation. Experiments on KB-VQA benchmarks show that CoRe-MMRAG\nachieves substantial improvements over baseline methods, achieving 5.6\\% and\n9.3\\% performance gains on InfoSeek and Encyclopedic-VQA, respectively. We\nrelease code and data at\n\\href{https://github.com/TyangJN/CoRe-MMRAG}{https://github.com/TyangJN/CoRe-MMRAG}.", "AI": {"tldr": "CoRe-MMRAG addresses inconsistencies in multimodal knowledge retrieval for MMRAG, improving reliability and alignment between visual-textual sources.", "motivation": "Challenges like Parametric-Retrieved Knowledge Inconsistency (PRKI) and Visual-Textual Knowledge Inconsistency (VTKI) hinder reliable multimodal knowledge integration.", "method": "CoRe-MMRAG uses a four-stage pipeline: internal response generation, multimodal evidence selection, external response generation, and integration. A specialized training paradigm enhances discrimination and integration.", "result": "Achieves 5.6% and 9.3% performance gains on InfoSeek and Encyclopedic-VQA benchmarks.", "conclusion": "CoRe-MMRAG effectively reconciles knowledge inconsistencies, outperforming baselines, with code and data publicly available."}}
{"id": "2506.02493", "pdf": "https://arxiv.org/pdf/2506.02493", "abs": "https://arxiv.org/abs/2506.02493", "authors": ["Jiachen Liu", "Rui Yu", "Sili Chen", "Sharon X. Huang", "Hengkai Guo"], "title": "Towards In-the-wild 3D Plane Reconstruction from a Single Image", "categories": ["cs.CV"], "comment": "CVPR 2025 Highlighted Paper", "summary": "3D plane reconstruction from a single image is a crucial yet challenging\ntopic in 3D computer vision. Previous state-of-the-art (SOTA) methods have\nfocused on training their system on a single dataset from either indoor or\noutdoor domain, limiting their generalizability across diverse testing data. In\nthis work, we introduce a novel framework dubbed ZeroPlane, a Transformer-based\nmodel targeting zero-shot 3D plane detection and reconstruction from a single\nimage, over diverse domains and environments. To enable data-driven models\nacross multiple domains, we have curated a large-scale planar benchmark,\ncomprising over 14 datasets and 560,000 high-resolution, dense planar\nannotations for diverse indoor and outdoor scenes. To address the challenge of\nachieving desirable planar geometry on multi-dataset training, we propose to\ndisentangle the representation of plane normal and offset, and employ an\nexemplar-guided, classification-then-regression paradigm to learn plane and\noffset respectively. Additionally, we employ advanced backbones as image\nencoder, and present an effective pixel-geometry-enhanced plane embedding\nmodule to further facilitate planar reconstruction. Extensive experiments\nacross multiple zero-shot evaluation datasets have demonstrated that our\napproach significantly outperforms previous methods on both reconstruction\naccuracy and generalizability, especially over in-the-wild data. Our code and\ndata are available at: https://github.com/jcliu0428/ZeroPlane.", "AI": {"tldr": "ZeroPlane is a Transformer-based model for zero-shot 3D plane reconstruction from a single image, outperforming SOTA methods in accuracy and generalizability.", "motivation": "Existing methods are limited to single datasets (indoor/outdoor), lacking generalizability. ZeroPlane aims to address this by enabling cross-domain 3D plane reconstruction.", "method": "The model disentangles plane normal and offset representations, uses an exemplar-guided classification-then-regression approach, and employs advanced backbones and a pixel-geometry-enhanced embedding module.", "result": "ZeroPlane significantly outperforms previous methods in reconstruction accuracy and generalizability, especially on diverse, in-the-wild data.", "conclusion": "ZeroPlane advances 3D plane reconstruction by enabling zero-shot performance across diverse domains, supported by a large-scale benchmark and novel methodology."}}
{"id": "2506.02315", "pdf": "https://arxiv.org/pdf/2506.02315", "abs": "https://arxiv.org/abs/2506.02315", "authors": ["D. Isaiah Harp", "Joshua Ott", "John Alora", "Dylan Asmar"], "title": "A Data-Based Architecture for Flight Test without Test Points", "categories": ["cs.LG", "cs.AI", "cs.RO"], "comment": "The Society of Experimental Test Pilots Annual Symposium, vol. 68th,\n  2024", "summary": "The justification for the \"test point\" derives from the test pilot's\nobligation to reproduce faithfully the pre-specified conditions of some model\nprediction. Pilot deviation from those conditions invalidates the model\nassumptions. Flight test aids have been proposed to increase accuracy on more\nchallenging test points. However, the very existence of databands and\ntolerances is the problem more fundamental than inadequate pilot skill. We\npropose a novel approach, which eliminates test points. We start with a\nhigh-fidelity digital model of an air vehicle. Instead of using this model to\ngenerate a point prediction, we use a machine learning method to produce a\nreduced-order model (ROM). The ROM has two important properties. First, it can\ngenerate a prediction based on any set of conditions the pilot flies. Second,\nif the test result at those conditions differ from the prediction, the ROM can\nbe updated using the new data. The outcome of flight test is thus a refined ROM\nat whatever conditions were flown. This ROM in turn updates and validates the\nhigh-fidelity model. We present a single example of this \"point-less\"\narchitecture, using T-38C flight test data. We first use a generic aircraft\nmodel to build a ROM of longitudinal pitching motion as a hypersurface. We then\ningest unconstrained flight test data and use Gaussian Process Regression to\nupdate and condition the hypersurface. By proposing a second-order equivalent\nsystem for the T-38C, this hypersurface then generates parameters necessary to\nassess MIL-STD-1797B compliance for longitudinal dynamics.", "AI": {"tldr": "The paper proposes eliminating traditional test points in flight testing by using a high-fidelity digital model and machine learning to create a reduced-order model (ROM) that adapts to actual flight conditions, improving accuracy and flexibility.", "motivation": "Traditional test points and tolerances are problematic as they rely on strict adherence to pre-specified conditions, which can be invalidated by pilot deviations. The goal is to improve accuracy and adaptability in flight testing.", "method": "A high-fidelity digital model is used to generate a ROM via machine learning. The ROM predicts outcomes for any flight conditions and updates with new data. Gaussian Process Regression is applied to refine the ROM using actual flight test data.", "result": "The method successfully creates a refined ROM from unconstrained flight test data, demonstrated with T-38C data, and assesses compliance with MIL-STD-1797B for longitudinal dynamics.", "conclusion": "The \"point-less\" architecture eliminates rigid test points, offering a flexible and adaptive approach to flight testing, validated by real-world data."}}
{"id": "2506.02051", "pdf": "https://arxiv.org/pdf/2506.02051", "abs": "https://arxiv.org/abs/2506.02051", "authors": ["Hui Liu", "Shiye Tian", "Xuejun Liu"], "title": "Phenotypic Profile-Informed Generation of Drug-Like Molecules via Dual-Channel Variational Autoencoders", "categories": ["q-bio.BM", "cs.AI", "cs.LG"], "comment": "IJCAI2025", "summary": "The de novo generation of drug-like molecules capable of inducing desirable\nphenotypic changes is receiving increasing attention. However, previous methods\npredominantly rely on expression profiles to guide molecule generation, but\noverlook the perturbative effect of the molecules on cellular contexts. To\novercome this limitation, we propose SmilesGEN, a novel generative model based\non variational autoencoder (VAE) architecture to generate molecules with\npotential therapeutic effects. SmilesGEN integrates a pre-trained drug VAE\n(SmilesNet) with an expression profile VAE (ProfileNet), jointly modeling the\ninterplay between drug perturbations and transcriptional responses in a common\nlatent space. Specifically, ProfileNet is imposed to reconstruct pre-treatment\nexpression profiles when eliminating drug-induced perturbations in the latent\nspace, while SmilesNet is informed by desired expression profiles to generate\ndrug-like molecules. Our empirical experiments demonstrate that SmilesGEN\noutperforms current state-of-the-art models in generating molecules with higher\ndegree of validity, uniqueness, novelty, as well as higher Tanimoto similarity\nto known ligands targeting the relevant proteins. Moreover, we evaluate\nSmilesGEN for scaffold-based molecule optimization and generation of\ntherapeutic agents, and confirmed its superior performance in generating\nmolecules with higher similarity to approved drugs. SmilesGEN establishes a\nrobust framework that leverages gene signatures to generate drug-like molecules\nthat hold promising potential to induce desirable cellular phenotypic changes.", "AI": {"tldr": "SmilesGEN is a generative model combining drug and expression profile VAEs to create therapeutic molecules, outperforming existing methods in validity, uniqueness, and similarity to known ligands.", "motivation": "Current methods for generating drug-like molecules rely on expression profiles but ignore cellular perturbation effects. SmilesGEN addresses this by modeling drug-perturbation interplay.", "method": "SmilesGEN integrates SmilesNet (drug VAE) and ProfileNet (expression profile VAE) in a shared latent space, reconstructing profiles and generating molecules based on desired effects.", "result": "SmilesGEN excels in generating valid, unique, novel molecules with high Tanimoto similarity to known ligands and approved drugs.", "conclusion": "SmilesGEN provides a robust framework for generating therapeutic molecules by leveraging gene signatures, promising desirable cellular changes."}}
{"id": "2506.02561", "pdf": "https://arxiv.org/pdf/2506.02561", "abs": "https://arxiv.org/abs/2506.02561", "authors": ["Yirao Zhao", "Guizhen Chen", "Kenji Kawaguchi", "Lidong Bing", "Wenxuan Zhang"], "title": "Pruning General Large Language Models into Customized Expert Models", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Large language models (LLMs) have revolutionized natural language processing,\nyet their substantial model sizes often require substantial computational\nresources. To preserve computing resources and accelerate inference speed, it\nis crucial to prune redundant parameters, especially for experienced users who\noften need compact expert models tailored to specific downstream scenarios.\nHowever, most existing pruning methods focus on preserving the model's general\ncapabilities, often requiring extensive post-training or suffering from\ndegraded performance due to coarse-grained pruning. In this work, we design a\n$\\underline{Cus}$tom $\\underline{Prun}$ing method ($\\texttt{Cus-Prun}$) to\nprune a large general model into a smaller lightweight expert model, which is\npositioned along the \"language\", \"domain\" and \"task\" dimensions. By identifying\nand pruning irrelevant neurons of each dimension, $\\texttt{Cus-Prun}$ creates\nexpert models without any post-training. Our experiments demonstrate that\n$\\texttt{Cus-Prun}$ consistently outperforms other methods, achieving minimal\nloss in both expert and general capabilities across various models from\ndifferent model families and sizes.", "AI": {"tldr": "The paper introduces Cus-Prun, a method to prune large language models into compact expert models without post-training, outperforming other methods with minimal performance loss.", "motivation": "Large language models require significant computational resources, and existing pruning methods either focus on general capabilities or degrade performance. Cus-Prun addresses this by creating tailored expert models.", "method": "Cus-Prun prunes irrelevant neurons along 'language', 'domain', and 'task' dimensions to transform a general model into a lightweight expert model without post-training.", "result": "Experiments show Cus-Prun outperforms other methods, maintaining expert and general capabilities across various models and sizes.", "conclusion": "Cus-Prun effectively prunes LLMs into expert models without post-training, offering a resource-efficient solution with minimal performance loss."}}
{"id": "2506.02497", "pdf": "https://arxiv.org/pdf/2506.02497", "abs": "https://arxiv.org/abs/2506.02497", "authors": ["Jiahao Chen", "Hangjie Yuan", "Yichen Qian", "Jingyun Liang", "Jiazheng Xing", "Pengwei Liu", "Weihua Chen", "Fan Wang", "Bing Su"], "title": "LumosFlow: Motion-Guided Long Video Generation", "categories": ["cs.CV"], "comment": null, "summary": "Long video generation has gained increasing attention due to its widespread\napplications in fields such as entertainment and simulation. Despite advances,\nsynthesizing temporally coherent and visually compelling long sequences remains\na formidable challenge. Conventional approaches often synthesize long videos by\nsequentially generating and concatenating short clips, or generating key frames\nand then interpolate the intermediate frames in a hierarchical manner. However,\nboth of them still remain significant challenges, leading to issues such as\ntemporal repetition or unnatural transitions. In this paper, we revisit the\nhierarchical long video generation pipeline and introduce LumosFlow, a\nframework introduce motion guidance explicitly. Specifically, we first employ\nthe Large Motion Text-to-Video Diffusion Model (LMTV-DM) to generate key frames\nwith larger motion intervals, thereby ensuring content diversity in the\ngenerated long videos. Given the complexity of interpolating contextual\ntransitions between key frames, we further decompose the intermediate frame\ninterpolation into motion generation and post-hoc refinement. For each pair of\nkey frames, the Latent Optical Flow Diffusion Model (LOF-DM) synthesizes\ncomplex and large-motion optical flows, while MotionControlNet subsequently\nrefines the warped results to enhance quality and guide intermediate frame\ngeneration. Compared with traditional video frame interpolation, we achieve 15x\ninterpolation, ensuring reasonable and continuous motion between adjacent\nframes. Experiments show that our method can generate long videos with\nconsistent motion and appearance. Code and models will be made publicly\navailable upon acceptance. Our project page:\nhttps://jiahaochen1.github.io/LumosFlow/", "AI": {"tldr": "LumosFlow introduces motion guidance for long video generation, using key frames and motion refinement to improve coherence and quality.", "motivation": "Addressing challenges in synthesizing temporally coherent and visually compelling long videos, which conventional methods struggle with due to issues like repetition and unnatural transitions.", "method": "Uses a hierarchical pipeline with LMTV-DM for key frames, LOF-DM for motion synthesis, and MotionControlNet for refinement, achieving 15x interpolation.", "result": "Generates long videos with consistent motion and appearance, outperforming traditional interpolation methods.", "conclusion": "LumosFlow effectively enhances long video generation by explicitly guiding motion and refining transitions."}}
{"id": "2506.02318", "pdf": "https://arxiv.org/pdf/2506.02318", "abs": "https://arxiv.org/abs/2506.02318", "authors": ["Yuchen Liang", "Renxiang Huang", "Lifeng Lai", "Ness Shroff", "Yingbin Liang"], "title": "Absorb and Converge: Provable Convergence Guarantee for Absorbing Discrete Diffusion Models", "categories": ["cs.LG", "eess.SP", "math.ST", "stat.TH"], "comment": null, "summary": "Discrete state space diffusion models have shown significant advantages in\napplications involving discrete data, such as text and image generation. It has\nalso been observed that their performance is highly sensitive to the choice of\nrate matrices, particularly between uniform and absorbing rate matrices. While\nempirical results suggest that absorbing rate matrices often yield better\ngeneration quality compared to uniform rate matrices, existing theoretical\nworks have largely focused on the uniform rate matrices case. Notably,\nconvergence guarantees and error analyses for absorbing diffusion models are\nstill missing. In this work, we provide the first finite-time error bounds and\nconvergence rate analysis for discrete diffusion models using absorbing rate\nmatrices. We begin by deriving an upper bound on the KL divergence of the\nforward process, introducing a surrogate initialization distribution to address\nthe challenge posed by the absorbing stationary distribution, which is a\nsingleton and causes the KL divergence to be ill-defined. We then establish the\nfirst convergence guarantees for both the $\\tau$-leaping and uniformization\nsamplers under absorbing rate matrices, demonstrating improved rates over their\ncounterparts using uniform rate matrices. Furthermore, under suitable\nassumptions, we provide convergence guarantees without early stopping. Our\nanalysis introduces several new technical tools to address challenges unique to\nabsorbing rate matrices. These include a Jensen-type argument for bounding\nforward process convergence, novel techniques for bounding absorbing score\nfunctions, and a non-divergent upper bound on the score near initialization\nthat removes the need of early-stopping.", "AI": {"tldr": "The paper provides the first finite-time error bounds and convergence rate analysis for discrete diffusion models using absorbing rate matrices, addressing gaps in existing theoretical works focused on uniform rate matrices.", "motivation": "Existing theoretical works on discrete diffusion models have largely ignored absorbing rate matrices, despite empirical evidence of their superior performance in generation quality. This work fills the gap by analyzing convergence and error bounds for such models.", "method": "The authors derive an upper bound on the KL divergence of the forward process, introduce a surrogate initialization distribution, and establish convergence guarantees for sampling methods under absorbing rate matrices. New technical tools are developed to handle challenges unique to absorbing rate matrices.", "result": "The analysis shows improved convergence rates for absorbing rate matrices compared to uniform ones, with guarantees even without early stopping under certain assumptions.", "conclusion": "This work advances the theoretical understanding of discrete diffusion models with absorbing rate matrices, providing foundational tools and guarantees for future research and applications."}}
{"id": "2506.02052", "pdf": "https://arxiv.org/pdf/2506.02052", "abs": "https://arxiv.org/abs/2506.02052", "authors": ["Shuo Yan", "Yuliang Yan", "Bin Ma", "Chenao Li", "Haochun Tang", "Jiahua Lu", "Minhua Lin", "Yuyuan Feng", "Hui Xiong", "Enyan Dai"], "title": "Protap: A Benchmark for Protein Modeling on Realistic Downstream Applications", "categories": ["q-bio.BM", "cs.AI", "cs.LG", "q-bio.QM"], "comment": null, "summary": "Recently, extensive deep learning architectures and pretraining strategies\nhave been explored to support downstream protein applications. Additionally,\ndomain-specific models incorporating biological knowledge have been developed\nto enhance performance in specialized tasks. In this work, we introduce\n$\\textbf{Protap}$, a comprehensive benchmark that systematically compares\nbackbone architectures, pretraining strategies, and domain-specific models\nacross diverse and realistic downstream protein applications. Specifically,\nProtap covers five applications: three general tasks and two novel specialized\ntasks, i.e., enzyme-catalyzed protein cleavage site prediction and targeted\nprotein degradation, which are industrially relevant yet missing from existing\nbenchmarks. For each application, Protap compares various domain-specific\nmodels and general architectures under multiple pretraining settings. Our\nempirical studies imply that: (i) Though large-scale pretraining encoders\nachieve great results, they often underperform supervised encoders trained on\nsmall downstream training sets. (ii) Incorporating structural information\nduring downstream fine-tuning can match or even outperform protein language\nmodels pretrained on large-scale sequence corpora. (iii) Domain-specific\nbiological priors can enhance performance on specialized downstream tasks. Code\nand datasets are publicly available at\nhttps://github.com/Trust-App-AI-Lab/protap.", "AI": {"tldr": "Protap is a benchmark comparing backbone architectures, pretraining strategies, and domain-specific models for protein applications, revealing insights on pretraining, structural information, and biological priors.", "motivation": "To systematically evaluate and compare deep learning models for protein applications, including novel specialized tasks missing in existing benchmarks.", "method": "Protap benchmarks five applications (three general, two novel) by comparing domain-specific models and general architectures under various pretraining settings.", "result": "(i) Supervised encoders outperform large-scale pretraining on small datasets. (ii) Structural information in fine-tuning matches/outperforms pretrained language models. (iii) Biological priors boost specialized task performance.", "conclusion": "Protap highlights the importance of domain-specific knowledge and structural information, providing a comprehensive benchmark for protein-related deep learning models."}}
{"id": "2506.02573", "pdf": "https://arxiv.org/pdf/2506.02573", "abs": "https://arxiv.org/abs/2506.02573", "authors": ["Muhammad Falensi Azmi", "Muhammad Dehan Al Kautsar", "Alfan Farizki Wicaksono", "Fajri Koto"], "title": "IndoSafety: Culturally Grounded Safety for LLMs in Indonesian Languages", "categories": ["cs.CL"], "comment": "25 pages", "summary": "Although region-specific large language models (LLMs) are increasingly\ndeveloped, their safety remains underexplored, particularly in culturally\ndiverse settings like Indonesia, where sensitivity to local norms is essential\nand highly valued by the community. In this work, we present IndoSafety, the\nfirst high-quality, human-verified safety evaluation dataset tailored for the\nIndonesian context, covering five language varieties: formal and colloquial\nIndonesian, along with three major local languages: Javanese, Sundanese, and\nMinangkabau. IndoSafety is constructed by extending prior safety frameworks to\ndevelop a taxonomy that captures Indonesia's sociocultural context. We find\nthat existing Indonesian-centric LLMs often generate unsafe outputs,\nparticularly in colloquial and local language settings, while fine-tuning on\nIndoSafety significantly improves safety while preserving task performance. Our\nwork highlights the critical need for culturally grounded safety evaluation and\nprovides a concrete step toward responsible LLM deployment in multilingual\nsettings. Warning: This paper contains example data that may be offensive,\nharmful, or biased.", "AI": {"tldr": "IndoSafety is a human-verified safety evaluation dataset for Indonesian LLMs, addressing cultural sensitivity in five language varieties. Fine-tuning on it improves safety without compromising performance.", "motivation": "To address the underexplored safety of region-specific LLMs in culturally diverse settings like Indonesia, where local norms are crucial.", "method": "Extends prior safety frameworks to create a culturally tailored taxonomy and evaluates Indonesian-centric LLMs using the IndoSafety dataset.", "result": "Existing Indonesian LLMs often produce unsafe outputs, especially in colloquial/local languages, but fine-tuning on IndoSafety enhances safety while maintaining performance.", "conclusion": "Culturally grounded safety evaluation is essential for responsible LLM deployment in multilingual contexts."}}
{"id": "2506.02528", "pdf": "https://arxiv.org/pdf/2506.02528", "abs": "https://arxiv.org/abs/2506.02528", "authors": ["Yan Gong", "Yiren Song", "Yicheng Li", "Chenglin Li", "Yin Zhang"], "title": "RelationAdapter: Learning and Transferring Visual Relation with Diffusion Transformers", "categories": ["cs.CV"], "comment": null, "summary": "Inspired by the in-context learning mechanism of large language models\n(LLMs), a new paradigm of generalizable visual prompt-based image editing is\nemerging. Existing single-reference methods typically focus on style or\nappearance adjustments and struggle with non-rigid transformations. To address\nthese limitations, we propose leveraging source-target image pairs to extract\nand transfer content-aware editing intent to novel query images. To this end,\nwe introduce RelationAdapter, a lightweight module that enables Diffusion\nTransformer (DiT) based models to effectively capture and apply visual\ntransformations from minimal examples. We also introduce Relation252K, a\ncomprehensive dataset comprising 218 diverse editing tasks, to evaluate model\ngeneralization and adaptability in visual prompt-driven scenarios. Experiments\non Relation252K show that RelationAdapter significantly improves the model's\nability to understand and transfer editing intent, leading to notable gains in\ngeneration quality and overall editing performance.", "AI": {"tldr": "A new method, RelationAdapter, improves visual prompt-based image editing by leveraging source-target pairs and a lightweight module for better generalization and adaptability.", "motivation": "Existing methods struggle with non-rigid transformations and limited editing intent transfer. The goal is to enhance generalization in visual prompt-driven scenarios.", "method": "Proposes RelationAdapter, a lightweight module for Diffusion Transformer models, and Relation252K dataset for evaluation.", "result": "RelationAdapter improves editing intent understanding and transfer, boosting generation quality and performance.", "conclusion": "The approach advances generalizable visual prompt-based editing, demonstrating effectiveness through experiments."}}
{"id": "2506.02323", "pdf": "https://arxiv.org/pdf/2506.02323", "abs": "https://arxiv.org/abs/2506.02323", "authors": ["Aleix Boquet-Pujadas", "Pol del Aguila Pla", "Michael Unser"], "title": "Sensitivity-Aware Density Estimation in Multiple Dimensions", "categories": ["cs.LG", "cs.AI", "cs.CE", "cs.DS", "eess.SP"], "comment": null, "summary": "We formulate an optimization problem to estimate probability densities in the\ncontext of multidimensional problems that are sampled with uneven probability.\nIt considers detector sensitivity as an heterogeneous density and takes\nadvantage of the computational speed and flexible boundary conditions offered\nby splines on a grid. We choose to regularize the Hessian of the spline via the\nnuclear norm to promote sparsity. As a result, the method is spatially adaptive\nand stable against the choice of the regularization parameter, which plays the\nrole of the bandwidth. We test our computational pipeline on standard densities\nand provide software. We also present a new approach to PET rebinning as an\napplication of our framework.", "AI": {"tldr": "The paper proposes an optimization method for estimating probability densities in unevenly sampled multidimensional problems, using splines and nuclear norm regularization for stability and adaptability.", "motivation": "Addressing the challenge of estimating probability densities in unevenly sampled multidimensional contexts, particularly considering detector sensitivity.", "method": "Uses splines on a grid for computational efficiency and flexible boundaries, regularizing the Hessian of the spline with the nuclear norm to promote sparsity.", "result": "The method is spatially adaptive and stable against regularization parameter choices, tested on standard densities with provided software.", "conclusion": "Demonstrates effectiveness with a PET rebinning application, showcasing practical utility."}}
{"id": "2506.02057", "pdf": "https://arxiv.org/pdf/2506.02057", "abs": "https://arxiv.org/abs/2506.02057", "authors": ["David Sasu", "Kweku Andoh Yamoah", "Benedict Quartey", "Natalie Schluter"], "title": "Enhancing Speech Instruction Understanding and Disambiguation in Robotics via Speech Prosody", "categories": ["cs.RO", "cs.AI", "cs.CL", "cs.LG"], "comment": "Accepted to Interspeech 2025", "summary": "Enabling robots to accurately interpret and execute spoken language\ninstructions is essential for effective human-robot collaboration. Traditional\nmethods rely on speech recognition to transcribe speech into text, often\ndiscarding crucial prosodic cues needed for disambiguating intent. We propose a\nnovel approach that directly leverages speech prosody to infer and resolve\ninstruction intent. Predicted intents are integrated into large language models\nvia in-context learning to disambiguate and select appropriate task plans.\nAdditionally, we present the first ambiguous speech dataset for robotics,\ndesigned to advance research in speech disambiguation. Our method achieves\n95.79% accuracy in detecting referent intents within an utterance and\ndetermines the intended task plan of ambiguous instructions with 71.96%\naccuracy, demonstrating its potential to significantly improve human-robot\ncommunication.", "AI": {"tldr": "A novel method uses speech prosody to infer intent in human-robot communication, achieving high accuracy in disambiguating instructions.", "motivation": "Traditional speech recognition discards prosodic cues, hindering accurate intent interpretation in human-robot collaboration.", "method": "Directly leverages speech prosody to infer intent, integrating predicted intents into large language models for task plan disambiguation.", "result": "Achieves 95.79% accuracy in detecting referent intents and 71.96% accuracy in determining intended task plans.", "conclusion": "The approach significantly improves human-robot communication by effectively resolving ambiguous instructions."}}
{"id": "2506.02589", "pdf": "https://arxiv.org/pdf/2506.02589", "abs": "https://arxiv.org/abs/2506.02589", "authors": ["Maria Levchenko"], "title": "Evaluating Named Entity Recognition Models for Russian Cultural News Texts: From BERT to LLM", "categories": ["cs.CL", "cs.AI", "cs.IR", "68T50", "I.2.7; H.3.3"], "comment": null, "summary": "This paper addresses the challenge of Named Entity Recognition (NER) for\nperson names within the specialized domain of Russian news texts concerning\ncultural events. The study utilizes the unique SPbLitGuide dataset, a\ncollection of event announcements from Saint Petersburg spanning 1999 to 2019.\nA comparative evaluation of diverse NER models is presented, encompassing\nestablished transformer-based architectures such as DeepPavlov, RoBERTa, and\nSpaCy, alongside recent Large Language Models (LLMs) including GPT-3.5, GPT-4,\nand GPT-4o. Key findings highlight the superior performance of GPT-4o when\nprovided with specific prompting for JSON output, achieving an F1 score of\n0.93. Furthermore, GPT-4 demonstrated the highest precision at 0.99. The\nresearch contributes to a deeper understanding of current NER model\ncapabilities and limitations when applied to morphologically rich languages\nlike Russian within the cultural heritage domain, offering insights for\nresearchers and practitioners. Follow-up evaluation with GPT-4.1 (April 2025)\nachieves F1=0.94 for both simple and structured prompts, demonstrating rapid\nprogress across model families and simplified deployment requirements.", "AI": {"tldr": "The paper evaluates NER models for Russian cultural event texts, finding GPT-4o and GPT-4 perform best, with GPT-4o achieving F1=0.93 and GPT-4 precision=0.99.", "motivation": "To address NER challenges for person names in Russian cultural news texts and compare model performance.", "method": "Comparative evaluation of transformer-based models (DeepPavlov, RoBERTa, SpaCy) and LLMs (GPT-3.5, GPT-4, GPT-4o) using the SPbLitGuide dataset.", "result": "GPT-4o achieved the highest F1 score (0.93), while GPT-4 had the highest precision (0.99). GPT-4.1 later achieved F1=0.94.", "conclusion": "The study highlights the effectiveness of LLMs for NER in morphologically rich languages like Russian, with rapid progress in model performance."}}
{"id": "2506.02534", "pdf": "https://arxiv.org/pdf/2506.02534", "abs": "https://arxiv.org/abs/2506.02534", "authors": ["Sining Chen", "Yilei Shi", "Xiao Xiang Zhu"], "title": "Enhancing Monocular Height Estimation via Weak Supervision from Imperfect Labels", "categories": ["cs.CV"], "comment": null, "summary": "Monocular height estimation is considered the most efficient and\ncost-effective means of 3D perception in remote sensing, and it has attracted\nmuch attention since the emergence of deep learning. While training neural\nnetworks requires a large amount of data, data with perfect labels are scarce\nand only available within developed regions. The trained models therefore lack\ngeneralizability, which limits the potential for large-scale application of\nexisting methods. We tackle this problem for the first time, by introducing\ndata with imperfect labels into training pixel-wise height estimation networks,\nincluding labels that are incomplete, inexact, and inaccurate compared to\nhigh-quality labels. We propose an ensemble-based pipeline compatible with any\nmonocular height estimation network. Taking the challenges of noisy labels,\ndomain shift, and long-tailed distribution of height values into consideration,\nwe carefully design the architecture and loss functions to leverage the\ninformation concealed in imperfect labels using weak supervision through\nbalanced soft losses and ordinal constraints. We conduct extensive experiments\non two datasets with different resolutions, DFC23 (0.5 to 1 m) and GBH (3 m).\nThe results indicate that the proposed pipeline outperforms baselines by\nachieving more balanced performance across various domains, leading to\nimprovements of average root mean square errors up to 22.94 %, and 18.62 % on\nDFC23 and GBH, respectively. The efficacy of each design component is validated\nthrough ablation studies. Code is available at\nhttps://github.com/zhu-xlab/weakim2h.", "AI": {"tldr": "The paper proposes an ensemble-based pipeline for monocular height estimation using imperfect labels to improve model generalizability, achieving significant error reductions on two datasets.", "motivation": "Existing methods lack generalizability due to scarce perfect labels, limiting large-scale applications. The paper addresses this by incorporating imperfect labels into training.", "method": "An ensemble-based pipeline is introduced, leveraging weak supervision through balanced soft losses and ordinal constraints to handle noisy labels, domain shift, and long-tailed height distributions.", "result": "The method outperforms baselines, reducing average root mean square errors by 22.94% and 18.62% on DFC23 and GBH datasets, respectively.", "conclusion": "The proposed pipeline effectively utilizes imperfect labels, enhancing performance and generalizability, with validated efficacy through ablation studies."}}
{"id": "2506.02337", "pdf": "https://arxiv.org/pdf/2506.02337", "abs": "https://arxiv.org/abs/2506.02337", "authors": ["Adrienne M. Propp", "Jonas A. Actor", "Elise Walker", "Houman Owhadi", "Nathaniel Trask", "Daniel M. Tartakovsky"], "title": "Discovery of Probabilistic Dirichlet-to-Neumann Maps on Graphs", "categories": ["cs.LG", "cs.NA", "math-ph", "math.MP", "math.NA", "physics.comp-ph", "stat.ML", "90C70, 60G15, 05C90"], "comment": null, "summary": "Dirichlet-to-Neumann maps enable the coupling of multiphysics simulations\nacross computational subdomains by ensuring continuity of state variables and\nfluxes at artificial interfaces. We present a novel method for learning\nDirichlet-to-Neumann maps on graphs using Gaussian processes, specifically for\nproblems where the data obey a conservation constraint from an underlying\npartial differential equation. Our approach combines discrete exterior calculus\nand nonlinear optimal recovery to infer relationships between vertex and edge\nvalues. This framework yields data-driven predictions with uncertainty\nquantification across the entire graph, even when observations are limited to a\nsubset of vertices and edges. By optimizing over the reproducing kernel Hilbert\nspace norm while applying a maximum likelihood estimation penalty on kernel\ncomplexity, our method ensures that the resulting surrogate strictly enforces\nconservation laws without overfitting. We demonstrate our method on two\nrepresentative applications: subsurface fracture networks and arterial blood\nflow. Our results show that the method maintains high accuracy and\nwell-calibrated uncertainty estimates even under severe data scarcity,\nhighlighting its potential for scientific applications where limited data and\nreliable uncertainty quantification are critical.", "AI": {"tldr": "A novel method for learning Dirichlet-to-Neumann maps on graphs using Gaussian processes, enforcing conservation laws and providing uncertainty quantification under data scarcity.", "motivation": "To couple multiphysics simulations across subdomains while ensuring continuity and conservation, especially in data-limited scenarios.", "method": "Combines discrete exterior calculus and nonlinear optimal recovery with Gaussian processes, optimizing kernel complexity and enforcing conservation laws.", "result": "High accuracy and well-calibrated uncertainty estimates in applications like subsurface fracture networks and arterial blood flow, even with scarce data.", "conclusion": "The method is robust for scientific applications requiring reliable uncertainty quantification and conservation law enforcement under limited data."}}
{"id": "2506.02071", "pdf": "https://arxiv.org/pdf/2506.02071", "abs": "https://arxiv.org/abs/2506.02071", "authors": ["Tadesse K. Bahiru", "Haileleol Tibebu", "Ioannis A. Kakadiaris"], "title": "AI Data Development: A Scorecard for the System Card Framework", "categories": ["cs.CY", "cs.AI", "cs.LG"], "comment": null, "summary": "Artificial intelligence has transformed numerous industries, from healthcare\nto finance, enhancing decision-making through automated systems. However, the\nreliability of these systems is mainly dependent on the quality of the\nunderlying datasets, raising ongoing concerns about transparency,\naccountability, and potential biases. This paper introduces a scorecard\ndesigned to evaluate the development of AI datasets, focusing on five key areas\nfrom the system card framework data development life cycle: data dictionary,\ncollection process, composition, motivation, and pre-processing. The method\nfollows a structured approach, using an intake form and scoring criteria to\nassess the quality and completeness of the data set. Applied to four diverse\ndatasets, the methodology reveals strengths and improvement areas. The results\nare compiled using a scoring system that provides tailored recommendations to\nenhance the transparency and integrity of the data set. The scorecard addresses\ntechnical and ethical aspects, offering a holistic evaluation of data\npractices. This approach aims to improve the quality of the data set. It offers\npractical guidance to curators and researchers in developing responsible AI\nsystems, ensuring fairness and accountability in decision support systems.", "AI": {"tldr": "A scorecard method evaluates AI dataset quality across five key areas, providing tailored recommendations to enhance transparency and integrity.", "motivation": "Address concerns about AI system reliability, transparency, and biases by improving dataset quality.", "method": "Structured approach using an intake form and scoring criteria to assess dataset quality across five areas.", "result": "Applied to four datasets, revealing strengths and improvement areas with tailored recommendations.", "conclusion": "The scorecard improves dataset quality, guiding responsible AI development for fairness and accountability."}}
{"id": "2506.02591", "pdf": "https://arxiv.org/pdf/2506.02591", "abs": "https://arxiv.org/abs/2506.02591", "authors": ["Minh Duc Bui", "Kyung Eun Park", "Goran Glava\u0161", "Fabian David Schmidt", "Katharina von der Wense"], "title": "On Generalization across Measurement Systems: LLMs Entail More Test-Time Compute for Underrepresented Cultures", "categories": ["cs.CL"], "comment": "Accepted to ACL 2025 Main (Camera-Ready Version)", "summary": "Measurement systems (e.g., currencies) differ across cultures, but the\nconversions between them are well defined so that humans can state facts using\nany measurement system of their choice. Being available to users from diverse\ncultural backgrounds, large language models (LLMs) should also be able to\nprovide accurate information irrespective of the measurement system at hand.\nUsing newly compiled datasets we test if this is the case for seven open-source\nLLMs, addressing three key research questions: (RQ1) What is the default system\nused by LLMs for each type of measurement? (RQ2) Do LLMs' answers and their\naccuracy vary across different measurement systems? (RQ3) Can LLMs mitigate\npotential challenges w.r.t. underrepresented systems via reasoning? Our\nfindings show that LLMs default to the measurement system predominantly used in\nthe data. Additionally, we observe considerable instability and variance in\nperformance across different measurement systems. While this instability can in\npart be mitigated by employing reasoning methods such as chain-of-thought\n(CoT), this implies longer responses and thereby significantly increases\ntest-time compute (and inference costs), marginalizing users from cultural\nbackgrounds that use underrepresented measurement systems.", "AI": {"tldr": "The paper investigates whether large language models (LLMs) can handle diverse measurement systems accurately, finding biases toward dominant systems and performance instability, partially mitigated by reasoning methods like CoT, but at higher computational costs.", "motivation": "To ensure LLMs provide accurate information across diverse cultural measurement systems, addressing potential biases and performance disparities.", "method": "Testing seven open-source LLMs using newly compiled datasets to analyze default measurement systems, accuracy variance, and the impact of reasoning methods like chain-of-thought (CoT).", "result": "LLMs default to dominant measurement systems, show performance instability across systems, and reasoning methods improve accuracy but increase computational costs.", "conclusion": "LLMs exhibit biases and performance issues with underrepresented measurement systems, and while reasoning helps, it raises cost concerns, marginalizing some users."}}
{"id": "2506.02535", "pdf": "https://arxiv.org/pdf/2506.02535", "abs": "https://arxiv.org/abs/2506.02535", "authors": ["Juntong Li", "Lingwei Dang", "Yukun Su", "Yun Hao", "Qingxin Xiao", "Yongwei Nie", "Qingyao Wu"], "title": "MemoryOut: Learning Principal Features via Multimodal Sparse Filtering Network for Semi-supervised Video Anomaly Detection", "categories": ["cs.CV"], "comment": null, "summary": "Video Anomaly Detection (VAD) methods based on reconstruction or prediction\nface two critical challenges: (1) strong generalization capability often\nresults in accurate reconstruction or prediction of abnormal events, making it\ndifficult to distinguish normal from abnormal patterns; (2) reliance only on\nlow-level appearance and motion cues limits their ability to identify\nhigh-level semantic in abnormal events from complex scenes. To address these\nlimitations, we propose a novel VAD framework with two key innovations. First,\nto suppress excessive generalization, we introduce the Sparse Feature Filtering\nModule (SFFM) that employs bottleneck filters to dynamically and adaptively\nremove abnormal information from features. Unlike traditional memory modules,\nit does not need to memorize the normal prototypes across the training dataset.\nFurther, we design the Mixture of Experts (MoE) architecture for SFFM. Each\nexpert is responsible for extracting specialized principal features during\nrunning time, and different experts are selectively activated to ensure the\ndiversity of the learned principal features. Second, to overcome the neglect of\nsemantics in existing methods, we integrate a Vision-Language Model (VLM) to\ngenerate textual descriptions for video clips, enabling comprehensive joint\nmodeling of semantic, appearance, and motion cues. Additionally, we enforce\nmodality consistency through semantic similarity constraints and motion\nframe-difference contrastive loss. Extensive experiments on multiple public\ndatasets validate the effectiveness of our multimodal joint modeling framework\nand sparse feature filtering paradigm. Project page at\nhttps://qzfm.github.io/sfn_vad_project_page/.", "AI": {"tldr": "The paper proposes a novel Video Anomaly Detection (VAD) framework addressing generalization and semantic limitations via Sparse Feature Filtering Module (SFFM) and Vision-Language Model (VLM) integration.", "motivation": "Existing VAD methods struggle with excessive generalization (reconstructing anomalies) and lack of high-level semantic understanding.", "method": "Introduces SFFM with bottleneck filters and MoE architecture for adaptive feature filtering, and integrates VLM for semantic-textual descriptions.", "result": "Validated on public datasets, the framework effectively combines semantic, appearance, and motion cues for improved anomaly detection.", "conclusion": "The proposed multimodal approach enhances VAD by addressing generalization and semantic gaps, supported by empirical results."}}
{"id": "2506.02355", "pdf": "https://arxiv.org/pdf/2506.02355", "abs": "https://arxiv.org/abs/2506.02355", "authors": ["Andre He", "Daniel Fried", "Sean Welleck"], "title": "Rewarding the Unlikely: Lifting GRPO Beyond Distribution Sharpening", "categories": ["cs.LG"], "comment": null, "summary": "Reinforcement learning has emerged as an effective framework for training\nlarge language models on structured language-conditioned tasks. We identify a\ncritical flaw of Group Relative Policy Optimization (GRPO), a widely used RL\nalgorithm in this setting. For tasks that require multi-sample performance,\nsuch as formal theorem proving, GRPO biasedly reinforces already probable\nsolutions and neglects rare but correct proofs. This implicit bias impairs\nperformance on pass@$N$ metrics at large sample sizes, limiting its\npracticality for training theorem provers. To address this, we introduce the\nunlikeliness reward, a straightforward method that explicitly encourages\nreinforcing rare correct solutions. Additionally, we find that increasing the\nnumber of PPO epochs further mitigates this bias. Our experiments confirm that\nincorporating the unlikeliness reward significantly improves pass@$N$ across a\nlarge range of N, outperforming standard GRPO and substantially increasing\nsample diversity. Applying our revised recipe to Lean, we achieve competitive\nperformance with DeepSeek-Prover-V1.5-RL on the miniF2F-test benchmark. We\nrelease our implementation, providing a simple yet effective recipe for\ntraining formal theorem provers with RL.", "AI": {"tldr": "The paper identifies a bias in GRPO for multi-sample tasks like theorem proving, introduces an unlikeliness reward to address it, and shows improved performance and diversity.", "motivation": "GRPO's bias towards probable solutions neglects rare correct proofs, limiting its effectiveness for tasks like theorem proving.", "method": "Introduces an unlikeliness reward to reinforce rare correct solutions and increases PPO epochs to mitigate bias.", "result": "The unlikeliness reward improves pass@N metrics and sample diversity, outperforming standard GRPO.", "conclusion": "The revised method achieves competitive performance, offering a practical solution for training theorem provers with RL."}}
{"id": "2506.02073", "pdf": "https://arxiv.org/pdf/2506.02073", "abs": "https://arxiv.org/abs/2506.02073", "authors": ["Mengliang He", "Jiayi Zeng", "Yankai Jiang", "Wei Zhang", "Zeming Liu", "Xiaoming Shi", "Aimin Zhou"], "title": "Flow2Code: Evaluating Large Language Models for Flowchart-based Code Generation Capability", "categories": ["cs.SE", "cs.AI"], "comment": null, "summary": "While large language models (LLMs) show promise in code generation, existing\nbenchmarks neglect the flowchart-based code generation. To promote further\nresearch on flowchart-based code generation, this work presents Flow2Code, a\nnovel benchmark for flowchart-based code generation evaluation. The evaluation\ndataset spans 15 programming languages and includes 5,622 code segments paired\nwith 16,866 flowcharts of three types: code, UML, and pseudocode. Extensive\nexperiments with 13 multimodal LLMs reveal that current LLMs can not generate\ncode based on flowcharts perfectly. Besides, experiment results show that the\nsupervised fine-tuning technique contributes greatly to the models'\nperformance. We publicly release our code and datasets at\nhttps://github.com/hml-github/Flow2Code.", "AI": {"tldr": "Flow2Code is a new benchmark for evaluating flowchart-based code generation, covering 15 languages and 5,622 code segments with 16,866 flowcharts. Current LLMs struggle with this task, but supervised fine-tuning improves performance.", "motivation": "Existing benchmarks overlook flowchart-based code generation, hindering research in this area. Flow2Code aims to fill this gap.", "method": "The benchmark includes 5,622 code segments paired with 16,866 flowcharts (code, UML, pseudocode). It evaluates 13 multimodal LLMs.", "result": "Current LLMs perform poorly on flowchart-based code generation, but supervised fine-tuning significantly boosts performance.", "conclusion": "Flow2Code provides a valuable benchmark for future research, highlighting the need for improved LLM capabilities in flowchart-based code generation."}}
{"id": "2506.02592", "pdf": "https://arxiv.org/pdf/2506.02592", "abs": "https://arxiv.org/abs/2506.02592", "authors": ["Zhi-Yuan Chen", "Hao Wang", "Xinyu Zhang", "Enrui Hu", "Yankai Lin"], "title": "Beyond the Surface: Measuring Self-Preference in LLM Judgments", "categories": ["cs.CL"], "comment": null, "summary": "Recent studies show that large language models (LLMs) exhibit self-preference\nbias when serving as judges, meaning they tend to favor their own responses\nover those generated by other models. Existing methods typically measure this\nbias by calculating the difference between the scores a judge model assigns to\nits own responses and those it assigns to responses from other models. However,\nthis approach conflates self-preference bias with response quality, as\nhigher-quality responses from the judge model may also lead to positive score\ndifferences, even in the absence of bias. To address this issue, we introduce\ngold judgments as proxies for the actual quality of responses and propose the\nDBG score, which measures self-preference bias as the difference between the\nscores assigned by the judge model to its own responses and the corresponding\ngold judgments. Since gold judgments reflect true response quality, the DBG\nscore mitigates the confounding effect of response quality on bias measurement.\nUsing the DBG score, we conduct comprehensive experiments to assess\nself-preference bias across LLMs of varying versions, sizes, and reasoning\nabilities. Additionally, we investigate two factors that influence and help\nalleviate self-preference bias: response text style and the post-training data\nof judge models. Finally, we explore potential underlying mechanisms of\nself-preference bias from an attention-based perspective. Our code and data are\navailable at https://github.com/zhiyuanc2001/self-preference.", "AI": {"tldr": "The paper introduces the DBG score to measure self-preference bias in LLMs, separating it from response quality by using gold judgments. It evaluates bias across models and explores influencing factors.", "motivation": "Existing methods conflate self-preference bias with response quality, necessitating a clearer measure.", "method": "Proposes the DBG score, using gold judgments to isolate bias from quality, and conducts experiments on LLMs.", "result": "The DBG score effectively measures bias, and factors like text style and post-training data influence it.", "conclusion": "The study provides a refined tool for bias assessment and insights into its mechanisms and mitigation."}}
{"id": "2506.02537", "pdf": "https://arxiv.org/pdf/2506.02537", "abs": "https://arxiv.org/abs/2506.02537", "authors": ["Hao Yan", "Handong Zheng", "Hao Wang", "Liang Yin", "Xingchen Liu", "Zhenbiao Cao", "Xinxing Su", "Zihao Chen", "Jihao Wu", "Minghui Liao", "Chao Weng", "Wei Chen", "Yuliang Liu", "Xiang Bai"], "title": "VisuRiddles: Fine-grained Perception is a Primary Bottleneck for Multimodal Large Language Models in Abstract Visual Reasoning", "categories": ["cs.CV", "cs.AI"], "comment": "13 pages, 4 figures", "summary": "Recent strides in multimodal large language models (MLLMs) have significantly\nadvanced their performance in many reasoning tasks. However, Abstract Visual\nReasoning (AVR) remains a critical challenge, primarily due to limitations in\nperceiving abstract graphics. To tackle this issue, we investigate the\nbottlenecks in current MLLMs and synthesize training data to improve their\nabstract visual perception. First, we propose VisuRiddles, a benchmark for AVR,\nfeaturing tasks meticulously constructed to assess models' reasoning capacities\nacross five core dimensions and two high-level reasoning categories. Second, we\nintroduce the Perceptual Riddle Synthesizer (PRS), an automated framework for\ngenerating riddles with fine-grained perceptual descriptions. PRS not only\ngenerates valuable training data for abstract graphics but also provides\nfine-grained perceptual description, crucially allowing for supervision over\nintermediate reasoning stages and thereby improving both training efficacy and\nmodel interpretability. Our extensive experimental results on VisuRiddles\nempirically validate that fine-grained visual perception is the principal\nbottleneck and our synthesis framework markedly enhances the performance of\ncontemporary MLLMs on these challenging tasks. Our code and dataset will be\nreleased at https://github.com/yh-hust/VisuRiddles", "AI": {"tldr": "The paper addresses the challenge of Abstract Visual Reasoning (AVR) in multimodal large language models (MLLMs) by introducing VisuRiddles, a benchmark, and the Perceptual Riddle Synthesizer (PRS) for data generation, improving model performance and interpretability.", "motivation": "AVR remains a critical challenge for MLLMs due to limitations in perceiving abstract graphics, prompting the need for better benchmarks and training data.", "method": "The authors propose VisuRiddles, a benchmark for AVR, and PRS, an automated framework for generating riddles with fine-grained perceptual descriptions to enhance training.", "result": "Experiments show fine-grained visual perception is the main bottleneck, and PRS significantly improves MLLM performance on AVR tasks.", "conclusion": "The study demonstrates the effectiveness of PRS and VisuRiddles in addressing AVR challenges, with plans to release the code and dataset."}}
{"id": "2506.02357", "pdf": "https://arxiv.org/pdf/2506.02357", "abs": "https://arxiv.org/abs/2506.02357", "authors": ["Ram Potham"], "title": "Evaluating LLM Agent Adherence to Hierarchical Safety Principles: A Lightweight Benchmark for Probing Foundational Controllability Components", "categories": ["cs.LG", "cs.AI", "cs.CY"], "comment": "Preprint. This work has been submitted to the Technical AI Governance\n  Workshop at ICML 2025 for review", "summary": "Credible safety plans for advanced AI development require methods to verify\nagent behavior and detect potential control deficiencies early. A fundamental\naspect is ensuring agents adhere to safety-critical principles, especially when\nthese conflict with operational goals. Failure to prioritize such principles\nindicates a potential basic control failure. This paper introduces a\nlightweight, interpretable benchmark methodology using a simple grid world to\nevaluate an LLM agent's ability to uphold a predefined, high-level safety\nprinciple (e.g., \"never enter hazardous zones\") when faced with conflicting\nlower-level task instructions. We probe whether the agent reliably prioritizes\nthe inviolable directive, testing a foundational controllability aspect of\nLLMs. This pilot study demonstrates the methodology's feasibility, offers\npreliminary insights into agent behavior under principle conflict, and\ndiscusses how such benchmarks can contribute empirical evidence for assessing\ncontrollability. We argue that evaluating adherence to hierarchical principles\nis a crucial early step in understanding our capacity to build governable AI\nsystems.", "AI": {"tldr": "A lightweight benchmark method evaluates LLM agents' adherence to safety principles in a grid world, testing controllability under conflicting goals.", "motivation": "To verify AI agent behavior and detect control deficiencies early, ensuring safety principles are prioritized over operational goals.", "method": "Uses a simple grid world to test if LLM agents uphold a high-level safety principle (e.g., avoiding hazards) despite conflicting task instructions.", "result": "Demonstrates feasibility and provides preliminary insights into agent behavior under principle conflict, contributing empirical evidence for controllability assessment.", "conclusion": "Evaluating hierarchical principle adherence is key to building governable AI systems, serving as an early controllability benchmark."}}
{"id": "2506.02596", "pdf": "https://arxiv.org/pdf/2506.02596", "abs": "https://arxiv.org/abs/2506.02596", "authors": ["Fan Gao", "Dongyuan Li", "Ding Xia", "Fei Mi", "Yasheng Wang", "Lifeng Shang", "Baojun Wang"], "title": "EssayBench: Evaluating Large Language Models in Multi-Genre Chinese Essay Writing", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Chinese essay writing and its evaluation are critical in educational\ncontexts, yet the capabilities of Large Language Models (LLMs) in this domain\nremain largely underexplored. Existing benchmarks often rely on coarse-grained\ntext quality metrics, largely overlooking the structural and rhetorical\ncomplexities of Chinese essays, particularly across diverse genres. To address\nthis gap, we propose \\benchName, a multi-genre benchmark specifically designed\nfor Chinese essay writing across four major genres: Argumentative, Narrative,\nDescriptive, and Expository. We curate and refine a total of 728 real-world\nprompts to ensure authenticity and meticulously categorize them into the\n\\textit{Open-Ended} and \\textit{Constrained} sets to capture diverse writing\nscenarios. To reliably evaluate generated essays, we develop a fine-grained,\ngenre-specific scoring framework that hierarchically aggregates scores. We\nfurther validate our evaluation protocol through a comprehensive human\nagreement study. Finally, we benchmark 15 large-sized LLMs, analyzing their\nstrengths and limitations across genres and instruction types. With \\benchName,\nwe aim to advance LLM-based Chinese essay evaluation and inspire future\nresearch on improving essay generation in educational settings.", "AI": {"tldr": "The paper introduces \\benchName, a multi-genre benchmark for evaluating Chinese essay writing by LLMs, addressing gaps in existing metrics.", "motivation": "Existing benchmarks overlook structural and rhetorical complexities of Chinese essays across genres, prompting the need for a specialized evaluation framework.", "method": "The study curates 728 real-world prompts into Open-Ended and Constrained sets, develops a genre-specific scoring framework, and benchmarks 15 LLMs.", "result": "The benchmark evaluates LLMs' strengths and limitations across genres and instruction types, validated by human agreement.", "conclusion": "\\benchName aims to advance LLM-based Chinese essay evaluation and inspire future research in educational essay generation."}}
{"id": "2506.02547", "pdf": "https://arxiv.org/pdf/2506.02547", "abs": "https://arxiv.org/abs/2506.02547", "authors": ["Andreu Girbau-Xalabarder", "Jun Nagata", "Shinichi Sumiyoshi"], "title": "Probabilistic Online Event Downsampling", "categories": ["cs.CV", "cs.ET"], "comment": "Accepted at CVPR 2025 Event-Vision workshop", "summary": "Event cameras capture scene changes asynchronously on a per-pixel basis,\nenabling extremely high temporal resolution. However, this advantage comes at\nthe cost of high bandwidth, memory, and computational demands. To address this,\nprior work has explored event downsampling, but most approaches rely on fixed\nheuristics or threshold-based strategies, limiting their adaptability. Instead,\nwe propose a probabilistic framework, POLED, that models event importance\nthrough an event-importance probability density function (ePDF), which can be\narbitrarily defined and adapted to different applications. Our approach\noperates in a purely online setting, estimating event importance on-the-fly\nfrom raw event streams, enabling scene-specific adaptation. Additionally, we\nintroduce zero-shot event downsampling, where downsampled events must remain\nusable for models trained on the original event stream, without task-specific\nadaptation. We design a contour-preserving ePDF that prioritizes structurally\nimportant events and evaluate our method across four datasets and tasks--object\nclassification, image interpolation, surface normal estimation, and object\ndetection--demonstrating that intelligent sampling is crucial for maintaining\nperformance under event-budget constraints.", "AI": {"tldr": "POLED is a probabilistic framework for adaptive event downsampling in event cameras, using an event-importance probability density function (ePDF) to prioritize important events and maintain performance under constraints.", "motivation": "Event cameras' high temporal resolution comes with bandwidth and computational costs. Existing downsampling methods lack adaptability.", "method": "POLED models event importance via an ePDF, operates online, and introduces zero-shot downsampling with a contour-preserving ePDF.", "result": "Evaluated on four tasks, POLED shows intelligent sampling is key for performance under event-budget limits.", "conclusion": "POLED offers adaptable, scene-specific event downsampling, outperforming fixed heuristics."}}
{"id": "2506.02370", "pdf": "https://arxiv.org/pdf/2506.02370", "abs": "https://arxiv.org/abs/2506.02370", "authors": ["Zhe Li", "Bicheng Ying", "Zidong Liu", "Chaosheng Dong", "Haibo Yang"], "title": "Reconciling Hessian-Informed Acceleration and Scalar-Only Communication for Efficient Federated Zeroth-Order Fine-Tuning", "categories": ["cs.LG", "cs.DC"], "comment": "Under review", "summary": "Recent dimension-free communication frameworks in Federated Learning (FL),\nsuch as DeComFL, significantly reduce per-round communication by transmitting\nonly scalars via zeroth-order stochastic gradient descent (ZO-SGD). This method\nis particularly advantageous for federated fine-tuning of Large Language Models\n(LLMs). Yet, the high variance in ZO gradient estimation typically leads to\nslow convergence. Although leveraging Hessian information is known to enhance\noptimization speed, integrating this into FL presents significant challenges.\nThese include clients' restrictions on local data and the critical need to\nmaintain the dimension-free communication property. To overcome this\nlimitation, we first introduce a generalized scalar-only communication FL\nframework that decouples dimension-free communication from standard ZO-SGD,\nenabling the integration of more advanced optimization strategies. Building on\nthis framework, we propose HiSo, a fast federated fine-tuning method via\nHessian-informed zeroth-order optimization and Scalar-only communication.\nSpecifically, it leverages global curvature information to accelerate\nconvergence while preserving the same minimal communication cost per round.\nTheoretically, we establish convergence guarantees that are independent of the\nglobal Lipschitz constant, and further show that HiSo achieves faster rates\nwhen the global Hessian exhibits a low effective rank -- a common phenomenon in\nLLMs. Extensive experiments on benchmark datasets and LLM fine-tuning tasks\nconfirm that HiSo significantly outperforms existing ZO-based FL methods in\nboth convergence speed and communication efficiency.", "AI": {"tldr": "HiSo is a federated fine-tuning method for LLMs that uses Hessian-informed zeroth-order optimization and scalar-only communication, improving convergence speed and efficiency.", "motivation": "Existing ZO-SGD methods in FL for LLMs suffer from slow convergence due to high variance in gradient estimation, while Hessian-based optimization is challenging to integrate without compromising communication efficiency.", "method": "HiSo decouples dimension-free communication from ZO-SGD, enabling Hessian-informed optimization while maintaining minimal communication costs.", "result": "HiSo achieves faster convergence rates, especially when the global Hessian has a low effective rank, and outperforms existing ZO-based FL methods in experiments.", "conclusion": "HiSo successfully addresses the limitations of ZO-SGD in FL by integrating Hessian information, offering a scalable and efficient solution for federated fine-tuning of LLMs."}}
{"id": "2506.02090", "pdf": "https://arxiv.org/pdf/2506.02090", "abs": "https://arxiv.org/abs/2506.02090", "authors": ["Gopichand Bandarupalli"], "title": "The Impact of Software Testing with Quantum Optimization Meets Machine Learning", "categories": ["cs.SE", "cs.AI", "cs.LG"], "comment": "6 pages", "summary": "Modern software systems complexity challenges efficient testing, as\ntraditional machine learning (ML) struggles with large test suites. This\nresearch presents a hybrid framework integrating Quantum Annealing with ML to\noptimize test case prioritization in CI/CD pipelines. Leveraging quantum\noptimization, it achieves a 25 percent increase in defect detection efficiency\nand a 30 percent reduction in test execution time versus classical ML,\nvalidated on the Defects4J dataset. A simulated CI/CD environment demonstrates\nrobustness across evolving codebases. Visualizations, including defect heatmaps\nand performance graphs, enhance interpretability. The framework addresses\nquantum hardware limits, CI/CD integration, and scalability for 2025s hybrid\nquantum-classical ecosystems, offering a transformative approach to software\nquality assurance.", "AI": {"tldr": "A hybrid framework combining Quantum Annealing and ML improves test case prioritization in CI/CD, boosting defect detection by 25% and cutting test time by 30%.", "motivation": "Addressing the inefficiency of traditional ML in handling large test suites for complex software systems.", "method": "Integrates Quantum Annealing with ML to optimize test case prioritization, validated on Defects4J dataset.", "result": "25% higher defect detection efficiency and 30% reduced test execution time compared to classical ML.", "conclusion": "The framework offers a scalable, robust solution for future hybrid quantum-classical ecosystems in software testing."}}
{"id": "2506.02659", "pdf": "https://arxiv.org/pdf/2506.02659", "abs": "https://arxiv.org/abs/2506.02659", "authors": ["Manon Reusens", "Bart Baesens", "David Jurgens"], "title": "Are Economists Always More Introverted? Analyzing Consistency in Persona-Assigned LLMs", "categories": ["cs.CL"], "comment": null, "summary": "Personalized Large Language Models (LLMs) are increasingly used in diverse\napplications, where they are assigned a specific persona - such as a happy high\nschool teacher - to guide their responses. While prior research has examined\nhow well LLMs adhere to predefined personas in writing style, a comprehensive\nanalysis of consistency across different personas and task types is lacking. In\nthis paper, we introduce a new standardized framework to analyze consistency in\npersona-assigned LLMs. We define consistency as the extent to which a model\nmaintains coherent responses when assigned the same persona across different\ntasks and runs. Our framework evaluates personas across four different\ncategories (happiness, occupation, personality, and political stance) spanning\nmultiple task dimensions (survey writing, essay generation, social media post\ngeneration, single turn, and multi-turn conversations). Our findings reveal\nthat consistency is influenced by multiple factors, including the assigned\npersona, stereotypes, and model design choices. Consistency also varies across\ntasks, increasing with more structured tasks and additional context. All code\nis available on GitHub.", "AI": {"tldr": "A new framework evaluates consistency in persona-assigned LLMs across personas and tasks, revealing factors like stereotypes and task structure influence consistency.", "motivation": "To address the lack of comprehensive analysis on how well LLMs maintain consistency across different personas and task types.", "method": "Introduces a standardized framework defining consistency and evaluates it across four persona categories and multiple task dimensions.", "result": "Consistency varies by persona, stereotypes, and task structure, improving with structured tasks and context.", "conclusion": "The framework provides insights into persona consistency in LLMs, highlighting influencing factors and task dependencies."}}
{"id": "2506.02550", "pdf": "https://arxiv.org/pdf/2506.02550", "abs": "https://arxiv.org/abs/2506.02550", "authors": ["Qiaohui Chu", "Haoyu Zhang", "Yisen Feng", "Meng Liu", "Weili Guan", "Yaowei Wang", "Liqiang Nie"], "title": "Technical Report for Ego4D Long-Term Action Anticipation Challenge 2025", "categories": ["cs.CV", "cs.AI"], "comment": "The champion solution for the Ego4D Long-Term Action Anticipation\n  Challenge at the CVPR EgoVis Workshop 2025", "summary": "In this report, we present a novel three-stage framework developed for the\nEgo4D Long-Term Action Anticipation (LTA) task. Inspired by recent advances in\nfoundation models, our method consists of three stages: feature extraction,\naction recognition, and long-term action anticipation. First, visual features\nare extracted using a high-performance visual encoder. The features are then\nfed into a Transformer to predict verbs and nouns, with a verb-noun\nco-occurrence matrix incorporated to enhance recognition accuracy. Finally, the\npredicted verb-noun pairs are formatted as textual prompts and input into a\nfine-tuned large language model (LLM) to anticipate future action sequences.\nOur framework achieves first place in this challenge at CVPR 2025, establishing\na new state-of-the-art in long-term action prediction. Our code will be\nreleased at https://github.com/CorrineQiu/Ego4D-LTA-Challenge-2025.", "AI": {"tldr": "A three-stage framework for the Ego4D LTA task, using visual feature extraction, action recognition, and LLM-based anticipation, achieving top performance at CVPR 2025.", "motivation": "To advance long-term action anticipation by leveraging foundation models and improving accuracy with verb-noun co-occurrence.", "method": "Three-stage approach: visual feature extraction, Transformer-based verb-noun prediction, and LLM-driven action sequence anticipation.", "result": "Achieved first place in the CVPR 2025 challenge, setting a new state-of-the-art.", "conclusion": "The framework effectively combines visual and language models for superior long-term action prediction."}}
{"id": "2506.02371", "pdf": "https://arxiv.org/pdf/2506.02371", "abs": "https://arxiv.org/abs/2506.02371", "authors": ["Haoye Lu", "Darren Lo", "Yaoliang Yu"], "title": "SFBD Flow: A Continuous-Optimization Framework for Training Diffusion Models with Noisy Samples", "categories": ["cs.LG"], "comment": null, "summary": "Diffusion models achieve strong generative performance but often rely on\nlarge datasets that may include sensitive content. This challenge is compounded\nby the models' tendency to memorize training data, raising privacy concerns.\nSFBD (Lu et al., 2025) addresses this by training on corrupted data and using\nlimited clean samples to capture local structure and improve convergence.\nHowever, its iterative denoising and fine-tuning loop requires manual\ncoordination, making it burdensome to implement. We reinterpret SFBD as an\nalternating projection algorithm and introduce a continuous variant, SFBD flow,\nthat removes the need for alternating steps. We further show its connection to\nconsistency constraint-based methods, and demonstrate that its practical\ninstantiation, Online SFBD, consistently outperforms strong baselines across\nbenchmarks.", "AI": {"tldr": "SFBD flow, a continuous variant of SFBD, eliminates manual coordination in iterative denoising, outperforming baselines while addressing privacy concerns in diffusion models.", "motivation": "Privacy concerns arise from diffusion models memorizing sensitive training data; SFBD aims to mitigate this by training on corrupted data with limited clean samples.", "method": "Reinterpret SFBD as an alternating projection algorithm, introduce SFBD flow to remove alternating steps, and connect it to consistency constraint-based methods.", "result": "Online SFBD, the practical instantiation, consistently outperforms strong baselines across benchmarks.", "conclusion": "SFBD flow offers a more efficient and effective solution for privacy-preserving diffusion models."}}
{"id": "2506.02120", "pdf": "https://arxiv.org/pdf/2506.02120", "abs": "https://arxiv.org/abs/2506.02120", "authors": ["Mariana A. Londe", "Luciana S. Pessoa", "Carlos E. Andrade", "Jos\u00e9 F. Gon\u00e7alves", "Mauricio G. C. Resende"], "title": "Random-key genetic algorithms", "categories": ["cs.NE", "cs.AI", "math.OC", "90-02, 90B40, 90C27", "G.1.6; G.2.1; I.2.8"], "comment": "21 pages, 1 figure, 1 table, 1 algorithm, forthcoming in Handbook of\n  Heuristics, 2nd edition, SpringerNature, New York", "summary": "A random-key genetic algorithm is an evolutionary metaheuristic for discrete\nand global optimization. Each solution is encoded as a vector of N random keys,\nwhere a random key is a real number randomly generated in the continuous\ninterval [0, 1). A decoder maps each vector of random keys to a solution of the\noptimization problem being solved and computes its cost. The benefit of this\napproach is that all genetic operators and transformations can be maintained\nwithin the unitary hypercube, regardless of the problem being addressed. This\nenhances the productivity and maintainability of the core framework. The\nalgorithm starts with a population of P vectors of random keys. At each\niteration, the vectors are partitioned into two sets: a smaller set of\nhigh-valued elite solutions and the remaining non-elite solutions. All elite\nelements are copied, without change, to the next population. A small number of\nrandom-key vectors (the mutants) is added to the population of the next\niteration. The remaining elements of the population of the next iteration are\ngenerated by combining, with the parametrized uniform crossover of Spears and\nDeJong (1991), pairs of solutions. This chapter reviews random-key genetic\nalgorithms and describes an effective variant called biased random-key genetic\nalgorithms.", "AI": {"tldr": "A random-key genetic algorithm encodes solutions as vectors of random keys in [0,1), using a decoder to map them to problem solutions. It maintains genetic operations within the unitary hypercube, enhancing framework productivity. The algorithm iteratively refines populations by partitioning elites, adding mutants, and using crossover. A variant called biased random-key genetic algorithms is also reviewed.", "motivation": "To address discrete and global optimization problems efficiently by leveraging evolutionary metaheuristics, ensuring maintainability and productivity of the core framework.", "method": "Encodes solutions as random-key vectors, uses a decoder for mapping, partitions populations into elites and non-elites, adds mutants, and applies parametrized uniform crossover.", "result": "Enhanced productivity and maintainability of the optimization framework, with effective solution refinement through iterative population updates.", "conclusion": "Random-key genetic algorithms, including the biased variant, offer a robust approach for discrete and global optimization, balancing efficiency and adaptability."}}
{"id": "2506.02672", "pdf": "https://arxiv.org/pdf/2506.02672", "abs": "https://arxiv.org/abs/2506.02672", "authors": ["Shihan Dou", "Ming Zhang", "Chenhao Huang", "Jiayi Chen", "Feng Chen", "Shichun Liu", "Yan Liu", "Chenxiao Liu", "Cheng Zhong", "Zongzhang Zhang", "Tao Gui", "Chao Xin", "Wei Chengzhi", "Lin Yan", "Qi Zhang", "Xuanjing Huang"], "title": "EvaLearn: Quantifying the Learning Capability and Efficiency of LLMs via Sequential Problem Solving", "categories": ["cs.CL", "cs.AI"], "comment": "47 pages, 24 figures", "summary": "We introduce EvaLearn, a pioneering benchmark designed to evaluate large\nlanguage models (LLMs) on their learning capability and efficiency in\nchallenging tasks, a critical, yet underexplored aspect of model potential.\nEvaLearn contains 648 challenging problems across six task types, grouped into\n182 sequences, each sequence dedicated to one task type. Diverging from most\nexisting benchmarks that evaluate models in parallel, EvaLearn requires models\nto solve problems sequentially, allowing them to leverage the experience gained\nfrom previous solutions. EvaLearn provides five comprehensive automated metrics\nto evaluate models and quantify their learning capability and efficiency. We\nextensively benchmark nine frontier models and observe varied performance\nprofiles: some models, such as Claude-3.7-sonnet, start with moderate initial\nperformance but exhibit strong learning ability, while some models struggle to\nbenefit from experience and may even show negative transfer. Moreover, we\ninvestigate model performance under two learning settings and find that\ninstance-level rubrics and teacher-model feedback further facilitate model\nlearning. Importantly, we observe that current LLMs with stronger static\nabilities do not show a clear advantage in learning capability across all\ntasks, highlighting that EvaLearn evaluates a new dimension of model\nperformance. We hope EvaLearn provides a novel evaluation perspective for\nassessing LLM potential and understanding the gap between models and human\ncapabilities, promoting the development of deeper and more dynamic evaluation\napproaches. All datasets, the automatic evaluation framework, and the results\nstudied in this paper are available at the GitHub repository.", "AI": {"tldr": "EvaLearn is a benchmark for evaluating LLMs' learning capability and efficiency through sequential problem-solving, revealing varied performance among models and highlighting a new dimension of model evaluation.", "motivation": "To address the underexplored aspect of LLMs' learning potential by creating a benchmark that evaluates models sequentially, unlike parallel evaluations in existing benchmarks.", "method": "EvaLearn includes 648 problems across six task types, grouped into 182 sequences, with five automated metrics to assess learning capability and efficiency. Nine frontier models are benchmarked under sequential and learning settings.", "result": "Varied performance profiles were observed: some models (e.g., Claude-3.7-sonnet) showed strong learning ability, while others struggled or exhibited negative transfer. Static ability did not guarantee learning advantage.", "conclusion": "EvaLearn offers a novel evaluation perspective for LLMs, emphasizing learning capability and efficiency, and aims to bridge the gap between models and human capabilities."}}
{"id": "2506.02555", "pdf": "https://arxiv.org/pdf/2506.02555", "abs": "https://arxiv.org/abs/2506.02555", "authors": ["Zhitao Zeng", "Zhu Zhuo", "Xiaojun Jia", "Erli Zhang", "Junde Wu", "Jiaan Zhang", "Yuxuan Wang", "Chang Han Low", "Jian Jiang", "Zilong Zheng", "Xiaochun Cao", "Yutong Ban", "Qi Dou", "Yang Liu", "Yueming Jin"], "title": "SurgVLM: A Large Vision-Language Model and Systematic Evaluation Benchmark for Surgical Intelligence", "categories": ["cs.CV", "68T45", "I.2.10"], "comment": "29 pages, 5 figures", "summary": "Foundation models have achieved transformative success across biomedical\ndomains by enabling holistic understanding of multimodal data. However, their\napplication in surgery remains underexplored. Surgical intelligence presents\nunique challenges - requiring surgical visual perception, temporal analysis,\nand reasoning. Existing general-purpose vision-language models fail to address\nthese needs due to insufficient domain-specific supervision and the lack of a\nlarge-scale high-quality surgical database. To bridge this gap, we propose\nSurgVLM, one of the first large vision-language foundation models for surgical\nintelligence, where this single universal model can tackle versatile surgical\ntasks. To enable this, we construct a large-scale multimodal surgical database,\nSurgVLM-DB, comprising over 1.81 million frames with 7.79 million\nconversations, spanning more than 16 surgical types and 18 anatomical\nstructures. We unify and reorganize 23 public datasets across 10 surgical\ntasks, followed by standardizing labels and doing hierarchical vision-language\nalignment to facilitate comprehensive coverage of gradually finer-grained\nsurgical tasks, from visual perception, temporal analysis, to high-level\nreasoning. Building upon this comprehensive dataset, we propose SurgVLM, which\nis built upon Qwen2.5-VL, and undergoes instruction tuning to 10+ surgical\ntasks. We further construct a surgical multimodal benchmark, SurgVLM-Bench, for\nmethod evaluation. SurgVLM-Bench consists of 6 popular and widely-used datasets\nin surgical domain, covering several crucial downstream tasks. Based on\nSurgVLM-Bench, we evaluate the performance of our SurgVLM (3 SurgVLM variants:\nSurgVLM-7B, SurgVLM-32B, and SurgVLM-72B), and conduct comprehensive\ncomparisons with 14 mainstream commercial VLMs (e.g., GPT-4o, Gemini 2.0 Flash,\nQwen2.5-Max).", "AI": {"tldr": "SurgVLM is a large vision-language foundation model for surgical intelligence, addressing unique surgical challenges with a comprehensive multimodal database and outperforming mainstream models.", "motivation": "Existing general-purpose vision-language models lack domain-specific supervision and large-scale surgical data, limiting their effectiveness in surgical tasks.", "method": "Construct SurgVLM-DB, a large-scale multimodal surgical database, and develop SurgVLM, a vision-language model fine-tuned for 10+ surgical tasks.", "result": "SurgVLM outperforms 14 mainstream commercial VLMs on SurgVLM-Bench, demonstrating superior performance in surgical tasks.", "conclusion": "SurgVLM bridges the gap in surgical intelligence, offering a versatile and high-performing solution for diverse surgical applications."}}
{"id": "2506.02385", "pdf": "https://arxiv.org/pdf/2506.02385", "abs": "https://arxiv.org/abs/2506.02385", "authors": ["Shuze Chen", "Tianyi Peng"], "title": "Multi-agent Markov Entanglement", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "Value decomposition has long been a fundamental technique in multi-agent\ndynamic programming and reinforcement learning (RL). Specifically, the value\nfunction of a global state $(s_1,s_2,\\ldots,s_N)$ is often approximated as the\nsum of local functions: $V(s_1,s_2,\\ldots,s_N)\\approx\\sum_{i=1}^N V_i(s_i)$.\nThis approach traces back to the index policy in restless multi-armed bandit\nproblems and has found various applications in modern RL systems. However, the\ntheoretical justification for why this decomposition works so effectively\nremains underexplored.\n  In this paper, we uncover the underlying mathematical structure that enables\nvalue decomposition. We demonstrate that a multi-agent Markov decision process\n(MDP) permits value decomposition if and only if its transition matrix is not\n\"entangled\" -- a concept analogous to quantum entanglement in quantum physics.\nDrawing inspiration from how physicists measure quantum entanglement, we\nintroduce how to measure the \"Markov entanglement\" for multi-agent MDPs and\nshow that this measure can be used to bound the decomposition error in general\nmulti-agent MDPs.\n  Using the concept of Markov entanglement, we proved that a widely-used class\nof index policies is weakly entangled and enjoys a sublinear $\\mathcal\nO(\\sqrt{N})$ scale of decomposition error for $N$-agent systems. Finally, we\nshow how Markov entanglement can be efficiently estimated in practice,\nproviding practitioners with an empirical proxy for the quality of value\ndecomposition.", "AI": {"tldr": "The paper explores the theoretical foundation of value decomposition in multi-agent RL, introducing the concept of 'Markov entanglement' to measure and bound decomposition errors.", "motivation": "To understand why value decomposition works effectively in multi-agent systems, which lacks theoretical justification.", "method": "Analyzes multi-agent MDPs, defining 'Markov entanglement' to measure transition matrix entanglement and bounds decomposition error.", "result": "Proves that a class of index policies is weakly entangled with sublinear error scaling, and shows how to estimate entanglement practically.", "conclusion": "Markov entanglement provides a theoretical and practical tool for assessing value decomposition quality in multi-agent RL."}}
{"id": "2506.02678", "pdf": "https://arxiv.org/pdf/2506.02678", "abs": "https://arxiv.org/abs/2506.02678", "authors": ["Zhong-Zhi Li", "Xiao Liang", "Zihao Tang", "Lei Ji", "Peijie Wang", "Haotian Xu", "Xing W", "Haizhen Huang", "Weiwei Deng", "Ying Nian Wu", "Yeyun Gong", "Zhijiang Guo", "Xiao Liu", "Fei Yin", "Cheng-Lin Liu"], "title": "TL;DR: Too Long, Do Re-weighting for Effcient LLM Reasoning Compression", "categories": ["cs.CL", "cs.CE", "cs.NA", "math.NA"], "comment": null, "summary": "Large Language Models (LLMs) have recently achieved remarkable progress by\nleveraging Reinforcement Learning and extended Chain-of-Thought (CoT)\ntechniques. However, the challenge of performing efficient language\nreasoning--especially during inference with extremely long outputs--has drawn\nincreasing attention from the research community. In this work, we propose a\ndynamic ratio-based training pipeline that does not rely on sophisticated data\nannotations or interpolation between multiple models. We continuously balance\nthe weights between the model's System-1 and System-2 data to eliminate\nredundant reasoning processes while preserving the model's reasoning\ncapability. We validate our approach across models on DeepSeek-R1-Distill-7B\nand DeepSeek-R1-Distill-14B and on a diverse set of benchmarks with varying\ndifficulty levels. Our method significantly reduces the number of output tokens\nby nearly 40% while maintaining the accuracy of the reasoning. Our code and\ndata will be available soon.", "AI": {"tldr": "A dynamic ratio-based training pipeline reduces output tokens by 40% while maintaining reasoning accuracy in LLMs.", "motivation": "Addressing the challenge of efficient language reasoning, especially with long outputs, without relying on complex annotations or model interpolation.", "method": "Balances weights between System-1 and System-2 data dynamically to eliminate redundant reasoning while preserving capability.", "result": "Validated on DeepSeek-R1-Distill models, showing significant token reduction (40%) without accuracy loss.", "conclusion": "The method offers an efficient solution for LLM inference, with code and data to be released."}}
{"id": "2506.02557", "pdf": "https://arxiv.org/pdf/2506.02557", "abs": "https://arxiv.org/abs/2506.02557", "authors": ["Shizhan Gong", "Yankai Jiang", "Qi Dou", "Farzan Farnia"], "title": "Kernel-based Unsupervised Embedding Alignment for Enhanced Visual Representation in Vision-language Models", "categories": ["cs.CV"], "comment": "ICML 2025", "summary": "Vision-language models, such as CLIP, have achieved significant success in\naligning visual and textual representations, becoming essential components of\nmany multi-modal large language models (MLLMs) like LLaVA and OpenFlamingo.\nHowever, numerous studies have identified CLIP's limited fine-grained\nperception as a critical drawback, leading to substantial failures in\ndownstream MLLMs. In contrast, vision-centric foundation models like DINOv2\ndemonstrate remarkable capabilities in capturing fine details from images. In\nthis work, we propose a novel kernel-based method to align CLIP's visual\nrepresentation with that of DINOv2, ensuring that the resulting embeddings\nmaintain compatibility with text embeddings while enhancing perceptual\ncapabilities. Our alignment objective is designed for efficient stochastic\noptimization. Following this image-only alignment fine-tuning, the visual\nencoder retains compatibility with the frozen text encoder and exhibits\nsignificant improvements in zero-shot object recognition, fine-grained spatial\nreasoning, and localization. By integrating the aligned visual encoder,\ndownstream MLLMs also demonstrate enhanced performance.", "AI": {"tldr": "A kernel-based method aligns CLIP's visual representation with DINOv2 to enhance fine-grained perception while maintaining text compatibility, improving downstream MLLM performance.", "motivation": "CLIP's limited fine-grained perception hinders downstream MLLMs, while DINOv2 excels in detail capture. Bridging these models aims to combine strengths.", "method": "Proposes a kernel-based alignment of CLIP's visual representation with DINOv2, optimized for efficiency, while retaining text compatibility.", "result": "Improved zero-shot object recognition, fine-grained reasoning, and localization. Enhanced downstream MLLM performance.", "conclusion": "The alignment method successfully combines CLIP's text compatibility with DINOv2's fine-grained perception, benefiting MLLMs."}}
{"id": "2506.02386", "pdf": "https://arxiv.org/pdf/2506.02386", "abs": "https://arxiv.org/abs/2506.02386", "authors": ["Jie Bian", "Vincent Y. F. Tan"], "title": "Asymptotically Optimal Linear Best Feasible Arm Identification with Fixed Budget", "categories": ["cs.LG", "cs.AI", "cs.IT", "math.IT"], "comment": "Accepted to the Conference on Uncertainty in Artificial Intelligence\n  (UAI) 2025", "summary": "The challenge of identifying the best feasible arm within a fixed budget has\nattracted considerable interest in recent years. However, a notable gap remains\nin the literature: the exact exponential rate at which the error probability\napproaches zero has yet to be established, even in the relatively simple\nsetting of $K$-armed bandits with Gaussian noise. In this paper, we address\nthis gap by examining the problem within the context of linear bandits. We\nintroduce a novel algorithm for best feasible arm identification that\nguarantees an exponential decay in the error probability. Remarkably, the decay\nrate -- characterized by the exponent -- matches the theoretical lower bound\nderived using information-theoretic principles. Our approach leverages a\nposterior sampling framework embedded within a game-based sampling rule\ninvolving a min-learner and a max-learner. This strategy shares its foundations\nwith Thompson sampling, but is specifically tailored to optimize the\nidentification process under fixed-budget constraints. Furthermore, we validate\nthe effectiveness of our algorithm through comprehensive empirical evaluations\nacross various problem instances with different levels of complexity. The\nresults corroborate our theoretical findings and demonstrate that our method\noutperforms several benchmark algorithms in terms of both accuracy and\nefficiency.", "AI": {"tldr": "The paper introduces a novel algorithm for best feasible arm identification in linear bandits, achieving exponential decay in error probability matching the theoretical lower bound.", "motivation": "Addressing the gap in establishing the exact exponential rate of error probability decay in fixed-budget best feasible arm identification, even for simple settings like Gaussian noise $K$-armed bandits.", "method": "A posterior sampling framework with a game-based sampling rule involving min-learner and max-learner, tailored for fixed-budget constraints.", "result": "The algorithm guarantees exponential decay in error probability, matching the theoretical lower bound, and outperforms benchmarks in empirical evaluations.", "conclusion": "The proposed method effectively addresses the gap, offering theoretical and empirical validation for its superior performance in fixed-budget settings."}}
{"id": "2506.02259", "pdf": "https://arxiv.org/pdf/2506.02259", "abs": "https://arxiv.org/abs/2506.02259", "authors": ["Yichi Zhang", "Shengwei Xu", "David Pennock", "Grant Schoenebeck"], "title": "Stochastically Dominant Peer Prediction", "categories": ["cs.GT", "cs.AI"], "comment": "29 pages, 3 figures", "summary": "Eliciting reliable human feedback is essential for many machine learning\ntasks, such as learning from noisy labels and aligning AI systems with human\npreferences. Peer prediction mechanisms incentivize truthful reporting without\nground truth verification by scoring agents based on correlations with peers.\nTraditional mechanisms, which ensure that truth-telling maximizes the expected\nscores in equilibrium, can elicit honest information while assuming agents'\nutilities are linear functions of their scores. However, in practice,\nnon-linear payment rules are usually preferred, or agents' utilities are\ninherently non-linear.\n  We propose stochastically dominant truthfulness (SD-truthfulness) as a\nstronger guarantee: the score distribution of truth-telling stochastically\ndominates all other strategies, incentivizing truthful reporting for a wide\nrange of monotone utility functions. Our first observation is that no existing\npeer prediction mechanism naturally satisfies this criterion without strong\nassumptions. A simple solution -- rounding scores into binary lotteries -- can\nenforce SD-truthfulness, but often degrades sensitivity, a key property related\nto fairness and statistical efficiency. We demonstrate how a more careful\napplication of rounding can better preserve sensitivity. Furthermore, we\nintroduce a new enforced agreement (EA) mechanism that is theoretically\nguaranteed to be SD-truthful in binary-signal settings under mild assumptions,\nand empirically achieves the highest sensitivity among all known SD-truthful\nmechanisms.", "AI": {"tldr": "The paper introduces stochastically dominant truthfulness (SD-truthfulness) to ensure truthful reporting in peer prediction mechanisms, addressing limitations of traditional methods under non-linear utilities. It proposes rounding techniques and a new enforced agreement (EA) mechanism for improved sensitivity and SD-truthfulness.", "motivation": "Traditional peer prediction mechanisms assume linear utilities, but real-world scenarios often involve non-linear payment rules or utilities. A stronger guarantee like SD-truthfulness is needed to ensure truthful reporting across diverse utility functions.", "method": "The paper explores rounding scores into binary lotteries for SD-truthfulness and introduces a more refined rounding approach to preserve sensitivity. It also proposes the enforced agreement (EA) mechanism, theoretically guaranteed for SD-truthfulness in binary-signal settings.", "result": "The refined rounding method improves sensitivity, and the EA mechanism achieves the highest sensitivity among known SD-truthful mechanisms while ensuring SD-truthfulness under mild assumptions.", "conclusion": "SD-truthfulness is a robust solution for truthful reporting in peer prediction, with the EA mechanism offering practical advantages in sensitivity and theoretical guarantees."}}
{"id": "2506.02683", "pdf": "https://arxiv.org/pdf/2506.02683", "abs": "https://arxiv.org/abs/2506.02683", "authors": ["Zhengdong Lu", "Weikai Lu", "Yiling Tao", "Yun Dai", "ZiXuan Chen", "Huiping Zhuang", "Cen Chen", "Hao Peng", "Ziqian Zeng"], "title": "Decompose, Plan in Parallel, and Merge: A Novel Paradigm for Large Language Models based Planning with Multiple Constraints", "categories": ["cs.CL"], "comment": null, "summary": "Despite significant advances in Large Language Models (LLMs), planning tasks\nstill present challenges for LLM-based agents. Existing planning methods face\ntwo key limitations: heavy constraints and cascading errors. To address these\nlimitations, we propose a novel parallel planning paradigm, which Decomposes,\nPlans for subtasks in Parallel, and Merges subplans into a final plan (DPPM).\nSpecifically, DPPM decomposes the complex task based on constraints into\nsubtasks, generates the subplan for each subtask in parallel, and merges them\ninto a global plan. In addition, our approach incorporates a verification and\nrefinement module, enabling error correction and conflict resolution.\nExperimental results demonstrate that DPPM significantly outperforms existing\nmethods in travel planning tasks.", "AI": {"tldr": "DPPM is a parallel planning method for LLM-based agents, addressing constraints and cascading errors by decomposing tasks, planning subtasks in parallel, and merging results with verification.", "motivation": "Existing LLM-based planning methods suffer from heavy constraints and cascading errors, limiting their effectiveness.", "method": "DPPM decomposes tasks into subtasks, plans for them in parallel, merges subplans, and includes a verification/refinement module.", "result": "DPPM outperforms existing methods in travel planning tasks.", "conclusion": "DPPM effectively addresses limitations of current LLM-based planning methods, offering improved performance."}}
{"id": "2506.02560", "pdf": "https://arxiv.org/pdf/2506.02560", "abs": "https://arxiv.org/abs/2506.02560", "authors": ["Zixiang Li", "Haoyu Wang", "Wei Wang", "Chuangchuang Tan", "Yunchao Wei", "Yao Zhao"], "title": "DCI: Dual-Conditional Inversion for Boosting Diffusion-Based Image Editing", "categories": ["cs.CV"], "comment": null, "summary": "Diffusion models have achieved remarkable success in image generation and\nediting tasks. Inversion within these models aims to recover the latent noise\nrepresentation for a real or generated image, enabling reconstruction, editing,\nand other downstream tasks. However, to date, most inversion approaches suffer\nfrom an intrinsic trade-off between reconstruction accuracy and editing\nflexibility. This limitation arises from the difficulty of maintaining both\nsemantic alignment and structural consistency during the inversion process. In\nthis work, we introduce Dual-Conditional Inversion (DCI), a novel framework\nthat jointly conditions on the source prompt and reference image to guide the\ninversion process. Specifically, DCI formulates the inversion process as a\ndual-condition fixed-point optimization problem, minimizing both the latent\nnoise gap and the reconstruction error under the joint guidance. This design\nanchors the inversion trajectory in both semantic and visual space, leading to\nmore accurate and editable latent representations. Our novel setup brings new\nunderstanding to the inversion process. Extensive experiments demonstrate that\nDCI achieves state-of-the-art performance across multiple editing tasks,\nsignificantly improving both reconstruction quality and editing precision.\nFurthermore, we also demonstrate that our method achieves strong results in\nreconstruction tasks, implying a degree of robustness and generalizability\napproaching the ultimate goal of the inversion process.", "AI": {"tldr": "Dual-Conditional Inversion (DCI) improves diffusion model inversion by jointly conditioning on source prompts and reference images, balancing reconstruction accuracy and editing flexibility.", "motivation": "Existing inversion approaches struggle with trade-offs between reconstruction accuracy and editing flexibility due to challenges in maintaining semantic alignment and structural consistency.", "method": "DCI formulates inversion as a dual-condition fixed-point optimization problem, minimizing latent noise gap and reconstruction error under joint guidance.", "result": "DCI achieves state-of-the-art performance in editing tasks, improving reconstruction quality and editing precision, while also performing well in reconstruction tasks.", "conclusion": "DCI provides a robust and generalizable solution for diffusion model inversion, advancing both reconstruction and editing capabilities."}}
{"id": "2506.02389", "pdf": "https://arxiv.org/pdf/2506.02389", "abs": "https://arxiv.org/abs/2506.02389", "authors": ["Chamara Madarasingha", "Nasrin Sohrabi", "Zahir Tari"], "title": "Univariate to Multivariate: LLMs as Zero-Shot Predictors for Time-Series Forecasting", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Time-series prediction or forecasting is critical across many real-world\ndynamic systems, and recent studies have proposed using Large Language Models\n(LLMs) for this task due to their strong generalization capabilities and\nability to perform well without extensive pre-training. However, their\neffectiveness in handling complex, noisy, and multivariate time-series data\nremains underexplored. To address this, we propose LLMPred which enhances\nLLM-based time-series prediction by converting time-series sequences into text\nand feeding them to LLMs for zero shot prediction along with two main data\npre-processing techniques. First, we apply time-series sequence decomposition\nto facilitate accurate prediction on complex and noisy univariate sequences.\nSecond, we extend this univariate prediction capability to multivariate data\nusing a lightweight prompt-processing strategy. Extensive experiments with\nsmaller LLMs such as Llama 2 7B, Llama 3.2 3B, GPT-4o-mini, and DeepSeek 7B\ndemonstrate that LLMPred achieves competitive or superior performance compared\nto state-of-the-art baselines. Additionally, a thorough ablation study\nhighlights the importance of the key components proposed in LLMPred.", "AI": {"tldr": "LLMPred enhances LLM-based time-series prediction by converting sequences to text and using decomposition and prompt-processing, achieving competitive results with smaller LLMs.", "motivation": "To explore LLMs' effectiveness in handling complex, noisy, and multivariate time-series data, which remains underexplored.", "method": "LLMPred converts time-series to text, uses sequence decomposition for univariate data, and a prompt-processing strategy for multivariate data.", "result": "LLMPred performs competitively or better than state-of-the-art baselines with smaller LLMs like Llama 2 7B and GPT-4o-mini.", "conclusion": "LLMPred's key components are validated as effective, demonstrating its potential for time-series prediction."}}
{"id": "2506.02262", "pdf": "https://arxiv.org/pdf/2506.02262", "abs": "https://arxiv.org/abs/2506.02262", "authors": ["Sebe Vanbrabant", "Gustavo Rovelo Ruiz", "Davy Vanacken"], "title": "Composable Building Blocks for Controllable and Transparent Interactive AI Systems", "categories": ["cs.HC", "cs.AI", "H.5.2; I.2.0"], "comment": "Accepted to The 3rd Workshop on Engineering Interactive Systems\n  Embedding AI Technologies, EICS 2025", "summary": "While the increased integration of AI technologies into interactive systems\nenables them to solve an equally increasing number of tasks, the black box\nproblem of AI models continues to spread throughout the interactive system as a\nwhole. Explainable AI (XAI) techniques can make AI models more accessible by\nemploying post-hoc methods or transitioning to inherently interpretable models.\nWhile this makes individual AI models clearer, the overarching system\narchitecture remains opaque. To this end, we propose an approach to represent\ninteractive systems as sequences of structural building blocks, such as AI\nmodels and control mechanisms grounded in the literature. These can then be\nexplained through accompanying visual building blocks, such as XAI techniques.\nThe flow and APIs of the structural building blocks form an explicit overview\nof the system. This serves as a communication basis for both humans and\nautomated agents like LLMs, aligning human and machine interpretability of AI\nmodels. We discuss a selection of building blocks and concretize our flow-based\napproach in an architecture and accompanying prototype interactive system.", "AI": {"tldr": "The paper proposes a flow-based approach using structural and visual building blocks to make AI-integrated interactive systems more interpretable for humans and automated agents.", "motivation": "The black box problem in AI models extends to interactive systems, making them opaque despite XAI techniques. A holistic solution is needed.", "method": "Represent interactive systems as sequences of structural building blocks (e.g., AI models, control mechanisms) and explain them with visual building blocks (e.g., XAI techniques).", "result": "The approach provides an explicit system overview via flow and APIs, aligning human and machine interpretability.", "conclusion": "The proposed architecture and prototype demonstrate how building blocks can enhance transparency in AI-integrated interactive systems."}}
{"id": "2506.02689", "pdf": "https://arxiv.org/pdf/2506.02689", "abs": "https://arxiv.org/abs/2506.02689", "authors": ["Liang Yue", "Yihong Tang", "Kehai Chen", "Jie Liu", "Min Zhang"], "title": "MASTER: Enhancing Large Language Model via Multi-Agent Simulated Teaching", "categories": ["cs.CL"], "comment": null, "summary": "Instruction fine-tuning is crucial in NLP tasks, enhancing pretrained models'\ninstruction-following capabilities and task-specific performance. However,\nobtaining high-quality fine-tuning data for large models is challenging due to\ndata collection difficulties and high production costs. To address this, we\npropose MASTER, a novel data augmentation method that enriches original data\nthrough interactions among multiple agents with varying cognitive levels. We\nsimulate three pedagogically grounded teaching scenarios, leveraging\nmulti-agent conversations to generate high-quality teacher-student interaction\ndata. Utilizing MASTER, we construct BOOST-QA, a fine-tuning dataset augmented\nfrom existing datasets like Orca-Math-200k, ProcQA, and OpenHermes2.5.\nExperiments show that models fine-tuned with BOOST-QA perform excellently\nacross multiple benchmarks, demonstrating strong multitask generalization.\nNotably, MASTER significantly improves models' reasoning abilities in complex\ntasks, providing valuable insights for future research.", "AI": {"tldr": "MASTER is a data augmentation method using multi-agent interactions to generate high-quality fine-tuning data, improving model performance and reasoning abilities.", "motivation": "High-quality fine-tuning data is hard to obtain due to collection difficulties and costs, necessitating innovative solutions like MASTER.", "method": "MASTER enriches data through multi-agent interactions simulating teaching scenarios, creating augmented datasets like BOOST-QA.", "result": "Models fine-tuned with BOOST-QA excel in benchmarks, showing strong multitask generalization and improved reasoning.", "conclusion": "MASTER offers a scalable solution for data augmentation, enhancing model performance and providing research insights."}}
{"id": "2506.02571", "pdf": "https://arxiv.org/pdf/2506.02571", "abs": "https://arxiv.org/abs/2506.02571", "authors": ["Abhishek Vivekanandan", "Christian Hubschneider", "J. Marius Z\u00f6llner"], "title": "Contrast & Compress: Learning Lightweight Embeddings for Short Trajectories", "categories": ["cs.CV"], "comment": "Submitted for peer review", "summary": "The ability to retrieve semantically and directionally similar short-range\ntrajectories with both accuracy and efficiency is foundational for downstream\napplications such as motion forecasting and autonomous navigation. However,\nprevailing approaches often depend on computationally intensive heuristics or\nlatent anchor representations that lack interpretability and controllability.\nIn this work, we propose a novel framework for learning fixed-dimensional\nembeddings for short trajectories by leveraging a Transformer encoder trained\nwith a contrastive triplet loss that emphasize the importance of discriminative\nfeature spaces for trajectory data. We analyze the influence of Cosine and\nFFT-based similarity metrics within the contrastive learning paradigm, with a\nfocus on capturing the nuanced directional intent that characterizes short-term\nmaneuvers. Our empirical evaluation on the Argoverse 2 dataset demonstrates\nthat embeddings shaped by Cosine similarity objectives yield superior\nclustering of trajectories by both semantic and directional attributes,\noutperforming FFT-based baselines in retrieval tasks. Notably, we show that\ncompact Transformer architectures, even with low-dimensional embeddings (e.g.,\n16 dimensions, but qualitatively down to 4), achieve a compelling balance\nbetween retrieval performance (minADE, minFDE) and computational overhead,\naligning with the growing demand for scalable and interpretable motion priors\nin real-time systems. The resulting embeddings provide a compact, semantically\nmeaningful, and efficient representation of trajectory data, offering a robust\nalternative to heuristic similarity measures and paving the way for more\ntransparent and controllable motion forecasting pipelines.", "AI": {"tldr": "A novel Transformer-based framework learns compact, interpretable trajectory embeddings using contrastive triplet loss, outperforming FFT-based methods in retrieval tasks.", "motivation": "Existing methods for trajectory retrieval rely on inefficient heuristics or opaque representations, lacking interpretability and controllability.", "method": "A Transformer encoder is trained with contrastive triplet loss, evaluating Cosine and FFT-based similarity metrics for trajectory embeddings.", "result": "Cosine similarity outperforms FFT-based methods in clustering trajectories by semantic and directional attributes, even with low-dimensional embeddings.", "conclusion": "The framework provides efficient, interpretable trajectory representations, enhancing motion forecasting pipelines."}}
{"id": "2506.02390", "pdf": "https://arxiv.org/pdf/2506.02390", "abs": "https://arxiv.org/abs/2506.02390", "authors": ["Qin Xie", "Qinghua Zhang", "Shuyin Xia", "Xinran Zhou", "Guoyin Wang"], "title": "GAdaBoost: An Efficient and Robust AdaBoost Algorithm Based on Granular-Ball Structure", "categories": ["cs.LG"], "comment": null, "summary": "Adaptive Boosting (AdaBoost) faces significant challenges posed by label\nnoise, especially in multiclass classification tasks. Existing methods either\nlack mechanisms to handle label noise effectively or suffer from high\ncomputational costs due to redundant data usage. Inspired by granular\ncomputing, this paper proposes granular adaptive boosting (GAdaBoost), a novel\ntwo-stage framework comprising a data granulation stage and an adaptive\nboosting stage, to enhance efficiency and robustness under noisy conditions. To\nvalidate its feasibility, an extension of SAMME, termed GAdaBoost.SA, is\nproposed. Specifically, first, a granular-ball generation method is designed to\ncompress data while preserving diversity and mitigating label noise. Second,\nthe granular ball-based SAMME algorithm focuses on granular balls rather than\nindividual samples, improving efficiency and reducing sensitivity to noise.\nExperimental results on some noisy datasets show that the proposed approach\nachieves superior robustness and efficiency compared with existing methods,\ndemonstrating that this work effectively extends AdaBoost and SAMME.", "AI": {"tldr": "GAdaBoost, a two-stage framework combining data granulation and adaptive boosting, improves AdaBoost's efficiency and robustness under label noise in multiclass tasks.", "motivation": "Addressing AdaBoost's inefficiency and sensitivity to label noise in multiclass classification.", "method": "Proposes GAdaBoost with two stages: data granulation (granular-ball generation) and adaptive boosting (granular ball-based SAMME).", "result": "Outperforms existing methods in robustness and efficiency on noisy datasets.", "conclusion": "GAdaBoost effectively extends AdaBoost and SAMME, offering better performance under noisy conditions."}}
{"id": "2506.02267", "pdf": "https://arxiv.org/pdf/2506.02267", "abs": "https://arxiv.org/abs/2506.02267", "authors": ["Xue Xia", "Saurabh Vishwas Joshi", "Kousik Rajesh", "Kangnan Li", "Yangyi Lu", "Nikil Pancha", "Dhruvil Deven Badani", "Jiajing Xu", "Pong Eksombatchai"], "title": "TransAct V2: Lifelong User Action Sequence Modeling on Pinterest Recommendation", "categories": ["cs.IR", "cs.AI"], "comment": null, "summary": "Modeling user action sequences has become a popular focus in industrial\nrecommendation system research, particularly for Click-Through Rate (CTR)\nprediction tasks. However, industry-scale CTR models often rely on short user\nsequences, limiting their ability to capture long-term behavior. Additionally,\nthese models typically lack an integrated action-prediction task within a\npoint-wise ranking framework, reducing their predictive power. They also rarely\naddress the infrastructure challenges involved in efficiently serving\nlarge-scale sequential models. In this paper, we introduce TransAct V2, a\nproduction model for Pinterest's Homefeed ranking system, featuring three key\ninnovations: (1) leveraging very long user sequences to improve CTR\npredictions, (2) integrating a Next Action Loss function for enhanced user\naction forecasting, and (3) employing scalable, low-latency deployment\nsolutions tailored to handle the computational demands of extended user action\nsequences.", "AI": {"tldr": "TransAct V2 improves CTR prediction by using long user sequences, integrating Next Action Loss, and deploying scalable solutions.", "motivation": "Industry CTR models often use short sequences and lack integrated action prediction, limiting predictive power and scalability.", "method": "TransAct V2 leverages long user sequences, integrates Next Action Loss, and employs scalable deployment solutions.", "result": "Enhanced CTR predictions and user action forecasting with efficient large-scale deployment.", "conclusion": "TransAct V2 addresses limitations of current CTR models with innovations in sequence length, action prediction, and deployment."}}
{"id": "2506.02701", "pdf": "https://arxiv.org/pdf/2506.02701", "abs": "https://arxiv.org/abs/2506.02701", "authors": ["Masaki Sakata", "Sho Yokoi", "Benjamin Heinzerling", "Takumi Ito", "Kentaro Inui"], "title": "On Entity Identification in Language Models", "categories": ["cs.CL"], "comment": "ACL 2025 Findings; 26 pages, 13 figures, 9 tables", "summary": "We analyze the extent to which internal representations of language models\n(LMs) identify and distinguish mentions of named entities, focusing on the\nmany-to-many correspondence between entities and their mentions. We first\nformulate two problems of entity mentions -- ambiguity and variability -- and\npropose a framework analogous to clustering quality metrics. Specifically, we\nquantify through cluster analysis of LM internal representations the extent to\nwhich mentions of the same entity cluster together and mentions of different\nentities remain separated. Our experiments examine five Transformer-based\nautoregressive models, showing that they effectively identify and distinguish\nentities with metrics analogous to precision and recall ranging from 0.66 to\n0.9. Further analysis reveals that entity-related information is compactly\nrepresented in a low-dimensional linear subspace at early LM layers.\nAdditionally, we clarify how the characteristics of entity representations\ninfluence word prediction performance. These findings are interpreted through\nthe lens of isomorphism between LM representations and entity-centric knowledge\nstructures in the real world, providing insights into how LMs internally\norganize and use entity information.", "AI": {"tldr": "The paper analyzes how language models (LMs) internally represent named entities, using clustering metrics to evaluate entity mention identification and distinction. Results show effective performance (0.66-0.9 precision/recall) and reveal compact, low-dimensional entity representations in early layers.", "motivation": "To understand how LMs internally identify and distinguish named entity mentions, addressing ambiguity and variability in entity-mention relationships.", "method": "Proposes a clustering-based framework to analyze LM internal representations, evaluating entity mention clustering and separation. Tests five Transformer-based autoregressive models.", "result": "LMs effectively identify and distinguish entities (0.66-0.9 precision/recallike metrics). Entity information is compactly represented in early layers.", "conclusion": "LMs internally organize entity information in a way that mirrors real-world knowledge structures, providing insights into their internal mechanisms."}}
{"id": "2506.02587", "pdf": "https://arxiv.org/pdf/2506.02587", "abs": "https://arxiv.org/abs/2506.02587", "authors": ["Weiduo Yuan", "Jerry Li", "Justin Yue", "Divyank Shah", "Konstantinos Karydis", "Hang Qiu"], "title": "BEVCALIB: LiDAR-Camera Calibration via Geometry-Guided Bird's-Eye View Representations", "categories": ["cs.CV", "cs.RO"], "comment": null, "summary": "Accurate LiDAR-camera calibration is fundamental to fusing multi-modal\nperception in autonomous driving and robotic systems. Traditional calibration\nmethods require extensive data collection in controlled environments and cannot\ncompensate for the transformation changes during the vehicle/robot movement. In\nthis paper, we propose the first model that uses bird's-eye view (BEV) features\nto perform LiDAR camera calibration from raw data, termed BEVCALIB. To achieve\nthis, we extract camera BEV features and LiDAR BEV features separately and fuse\nthem into a shared BEV feature space. To fully utilize the geometric\ninformation from the BEV feature, we introduce a novel feature selector to\nfilter the most important features in the transformation decoder, which reduces\nmemory consumption and enables efficient training. Extensive evaluations on\nKITTI, NuScenes, and our own dataset demonstrate that BEVCALIB establishes a\nnew state of the art. Under various noise conditions, BEVCALIB outperforms the\nbest baseline in the literature by an average of (47.08%, 82.32%) on KITTI\ndataset, and (78.17%, 68.29%) on NuScenes dataset, in terms of (translation,\nrotation), respectively. In the open-source domain, it improves the best\nreproducible baseline by one order of magnitude. Our code and demo results are\navailable at https://cisl.ucr.edu/BEVCalib.", "AI": {"tldr": "BEVCALIB is a novel LiDAR-camera calibration method using BEV features, outperforming baselines significantly in accuracy and efficiency.", "motivation": "Traditional calibration methods are limited by controlled environments and cannot adapt to dynamic changes during movement.", "method": "Extracts and fuses camera and LiDAR BEV features, using a feature selector for efficient training.", "result": "Outperforms baselines by 47.08%-82.32% on KITTI and 68.29%-78.17% on NuScenes in translation and rotation accuracy.", "conclusion": "BEVCALIB sets a new state-of-the-art, improving reproducibility by an order of magnitude."}}
{"id": "2506.02392", "pdf": "https://arxiv.org/pdf/2506.02392", "abs": "https://arxiv.org/abs/2506.02392", "authors": ["Yuanyao Chen", "Rongsheng Chen", "Fu Luo", "Zhenkun Wang"], "title": "Improving Generalization of Neural Combinatorial Optimization for Vehicle Routing Problems via Test-Time Projection Learning", "categories": ["cs.LG"], "comment": "arXiv admin note: text overlap with arXiv:2505.24627", "summary": "Neural Combinatorial Optimization (NCO) has emerged as a promising\nlearning-based paradigm for addressing Vehicle Routing Problems (VRPs) by\nminimizing the need for extensive manual engineering. While existing NCO\nmethods, trained on small-scale instances (e.g., 100 nodes), have demonstrated\nconsiderable success on problems of similar scale, their performance\nsignificantly degrades when applied to large-scale scenarios. This degradation\narises from the distributional shift between training and testing data,\nrendering policies learned on small instances ineffective for larger problems.\nTo overcome this limitation, we introduce a novel learning framework driven by\nLarge Language Models (LLMs). This framework learns a projection between the\ntraining and testing distributions, which is then deployed to enhance the\nscalability of the NCO model. Notably, unlike prevailing techniques that\nnecessitate joint training with the neural network, our approach operates\nexclusively during the inference phase, obviating the need for model\nretraining. Extensive experiments demonstrate that our method enables a\nbackbone model (trained on 100-node instances) to achieve superior performance\non large-scale Traveling Salesman Problem (TSP) and Capacitated Vehicle Routing\nProblem (CVRP) of up to 100K nodes from diverse distributions.", "AI": {"tldr": "A novel LLM-driven framework enhances NCO scalability for VRPs by projecting training-testing distributions, achieving superior performance on large-scale TSP and CVRP without retraining.", "motivation": "Existing NCO methods degrade on large-scale VRPs due to distributional shifts between training and testing data.", "method": "Introduces an LLM-driven framework to learn a projection between distributions, applied during inference without retraining.", "result": "Enables a model trained on 100-node instances to perform well on TSP and CVRP with up to 100K nodes.", "conclusion": "The framework effectively addresses scalability issues in NCO for VRPs, demonstrating strong performance on large-scale problems."}}
{"id": "2506.02726", "pdf": "https://arxiv.org/pdf/2506.02726", "abs": "https://arxiv.org/abs/2506.02726", "authors": ["Qihang Yan", "Xinyu Zhang", "Luming Guo", "Qi Zhang", "Feifan Liu"], "title": "RACE-Align: Retrieval-Augmented and Chain-of-Thought Enhanced Preference Alignment for Large Language Models", "categories": ["cs.CL", "cs.AI", "cs.LG", "I.2.7; I.2.6; H.3.3"], "comment": null, "summary": "Large Language Models (LLMs) struggle with accuracy, domain-specific\nreasoning, and interpretability in vertical domains. Traditional preference\nalignment methods like Reinforcement Learning from Human Feedback (RLHF) and\nDirect Preference Optimization (DPO) often overlook the underlying knowledge\nsources and reasoning logic. This paper introduces RACE-Align\n(Retrieval-Augmented and Chain-of-Thought Enhanced Alignment), a novel\nframework designed to address these limitations. RACE-Align systematically\nconstructs a binary preference dataset incorporating external knowledge support\nand explicit Chain-of-Thought (CoT) reasoning, then aligns LLMs using the DPO\nalgorithm. The core innovation lies in its preference data construction\nstrategy: it integrates AI-driven retrieval for factual grounding, enhancing\nknowledgeability and accuracy, and emphasizes the optimization of\ndomain-specific CoT, treating the reasoning process itself as a key preference\ndimension. A multi-stage, AI-driven refinement pipeline cost-effectively\ngenerates these preference pairs. Experimental validation in Traditional\nChinese Medicine (TCM) using Qwen3-1.7B as the base model demonstrates that\nRACE-Align significantly outperforms the original base model and a model\nfine-tuned only with Supervised Fine-Tuning (SFT). Improvements were observed\nacross multiple dimensions, including answer accuracy, information richness,\napplication of TCM thinking patterns, logicality and depth of reasoning, and\ninterpretability. These findings suggest RACE-Align offers an effective pathway\nto enhance LLMs' knowledge application, reasoning reliability, and process\ntransparency in complex vertical domains.", "AI": {"tldr": "RACE-Align improves LLM accuracy and reasoning in vertical domains by integrating retrieval-augmented knowledge and Chain-of-Thought reasoning into preference alignment.", "motivation": "Address LLM limitations in accuracy, domain-specific reasoning, and interpretability by enhancing preference alignment with external knowledge and explicit reasoning.", "method": "Constructs a binary preference dataset with retrieval-augmented knowledge and CoT reasoning, then aligns LLMs using DPO.", "result": "Outperforms base and SFT models in TCM, improving accuracy, reasoning, and interpretability.", "conclusion": "RACE-Align effectively enhances LLMs' knowledge application and reasoning in complex domains."}}
{"id": "2506.02605", "pdf": "https://arxiv.org/pdf/2506.02605", "abs": "https://arxiv.org/abs/2506.02605", "authors": ["Xue Wu", "Jingwei Xin", "Zhijun Tu", "Jie Hu", "Jie Li", "Nannan Wang", "Xinbo Gao"], "title": "One-Step Diffusion-based Real-World Image Super-Resolution with Visual Perception Distillation", "categories": ["cs.CV"], "comment": null, "summary": "Diffusion-based models have been widely used in various visual generation\ntasks, showing promising results in image super-resolution (SR), while\ntypically being limited by dozens or even hundreds of sampling steps. Although\nexisting methods aim to accelerate the inference speed of multi-step\ndiffusion-based SR methods through knowledge distillation, their generated\nimages exhibit insufficient semantic alignment with real images, resulting in\nsuboptimal perceptual quality reconstruction, specifically reflected in the\nCLIPIQA score. These methods still have many challenges in perceptual quality\nand semantic fidelity. Based on the challenges, we propose VPD-SR, a novel\nvisual perception diffusion distillation framework specifically designed for\nSR, aiming to construct an effective and efficient one-step SR model.\nSpecifically, VPD-SR consists of two components: Explicit Semantic-aware\nSupervision (ESS) and High-Frequency Perception (HFP) loss. Firstly, the ESS\nleverages the powerful visual perceptual understanding capabilities of the CLIP\nmodel to extract explicit semantic supervision, thereby enhancing semantic\nconsistency. Then, Considering that high-frequency information contributes to\nthe visual perception quality of images, in addition to the vanilla\ndistillation loss, the HFP loss guides the student model to restore the missing\nhigh-frequency details in degraded images that are critical for enhancing\nperceptual quality. Lastly, we expand VPD-SR in adversarial training manner to\nfurther enhance the authenticity of the generated content. Extensive\nexperiments conducted on synthetic and real-world datasets demonstrate that the\nproposed VPD-SR achieves superior performance compared to both previous\nstate-of-the-art methods and the teacher model with just one-step sampling.", "AI": {"tldr": "VPD-SR is a one-step diffusion distillation framework for image super-resolution, enhancing semantic alignment and perceptual quality via explicit semantic supervision and high-frequency perception loss.", "motivation": "Existing diffusion-based SR methods suffer from slow inference and poor semantic alignment, leading to suboptimal perceptual quality.", "method": "VPD-SR combines Explicit Semantic-aware Supervision (ESS) and High-Frequency Perception (HFP) loss, leveraging CLIP for semantic consistency and adversarial training for authenticity.", "result": "VPD-SR outperforms state-of-the-art methods and the teacher model with one-step sampling on synthetic and real-world datasets.", "conclusion": "VPD-SR effectively addresses semantic and perceptual challenges in SR, offering a fast and high-quality solution."}}
{"id": "2506.02406", "pdf": "https://arxiv.org/pdf/2506.02406", "abs": "https://arxiv.org/abs/2506.02406", "authors": ["Renat Sergazinov", "Jing Wu", "Shao-An Yin"], "title": "Random at First, Fast at Last: NTK-Guided Fourier Pre-Processing for Tabular DL", "categories": ["cs.LG", "cs.AI", "stat.ML"], "comment": "16 pages, 3 figures, 1 table", "summary": "While random Fourier features are a classic tool in kernel methods, their\nutility as a pre-processing step for deep learning on tabular data has been\nlargely overlooked. Motivated by shortcomings in tabular deep learning\npipelines - revealed through Neural Tangent Kernel (NTK) analysis - we revisit\nand repurpose random Fourier mappings as a parameter-free,\narchitecture-agnostic transformation. By projecting each input into a fixed\nfeature space via sine and cosine projections with frequencies drawn once at\ninitialization, this approach circumvents the need for ad hoc normalization or\nadditional learnable embeddings. We show within the NTK framework that this\nmapping (i) bounds and conditions the network's initial NTK spectrum, and (ii)\nintroduces a bias that shortens the optimization trajectory, thereby\naccelerating gradient-based training. These effects pre-condition the network\nwith a stable kernel from the outset. Empirically, we demonstrate that deep\nnetworks trained on Fourier-transformed inputs converge more rapidly and\nconsistently achieve strong final performance, often with fewer epochs and less\nhyperparameter tuning. Our findings establish random Fourier pre-processing as\na theoretically motivated, plug-and-play enhancement for tabular deep learning.", "AI": {"tldr": "Random Fourier features, repurposed for tabular deep learning, improve training efficiency and performance by preconditioning networks with a stable kernel.", "motivation": "Addressing shortcomings in tabular deep learning pipelines revealed by NTK analysis, the paper explores random Fourier features as a parameter-free, architecture-agnostic solution.", "method": "Projects inputs into a fixed feature space using sine and cosine projections with random frequencies, eliminating the need for normalization or embeddings.", "result": "The mapping bounds the NTK spectrum, shortens optimization trajectories, and accelerates training, leading to faster convergence and better performance.", "conclusion": "Random Fourier pre-processing is a plug-and-play enhancement for tabular deep learning, supported by theory and empirical results."}}
{"id": "2506.02362", "pdf": "https://arxiv.org/pdf/2506.02362", "abs": "https://arxiv.org/abs/2506.02362", "authors": ["Xueqi Cheng", "Minxing Zheng", "Shixiang Zhu", "Yushun Dong"], "title": "MISLEADER: Defending against Model Extraction with Ensembles of Distilled Models", "categories": ["cs.CR", "cs.AI"], "comment": null, "summary": "Model extraction attacks aim to replicate the functionality of a black-box\nmodel through query access, threatening the intellectual property (IP) of\nmachine-learning-as-a-service (MLaaS) providers. Defending against such attacks\nis challenging, as it must balance efficiency, robustness, and utility\npreservation in the real-world scenario. Despite the recent advances, most\nexisting defenses presume that attacker queries have out-of-distribution (OOD)\nsamples, enabling them to detect and disrupt suspicious inputs. However, this\nassumption is increasingly unreliable, as modern models are trained on diverse\ndatasets and attackers often operate under limited query budgets. As a result,\nthe effectiveness of these defenses is significantly compromised in realistic\ndeployment scenarios. To address this gap, we propose MISLEADER (enseMbles of\ndIStiLled modEls Against moDel ExtRaction), a novel defense strategy that does\nnot rely on OOD assumptions. MISLEADER formulates model protection as a bilevel\noptimization problem that simultaneously preserves predictive fidelity on\nbenign inputs and reduces extractability by potential clone models. Our\nframework combines data augmentation to simulate attacker queries with an\nensemble of heterogeneous distilled models to improve robustness and diversity.\nWe further provide a tractable approximation algorithm and derive theoretical\nerror bounds to characterize defense effectiveness. Extensive experiments\nacross various settings validate the utility-preserving and\nextraction-resistant properties of our proposed defense strategy. Our code is\navailable at https://github.com/LabRAI/MISLEADER.", "AI": {"tldr": "MISLEADER is a defense strategy against model extraction attacks, avoiding reliance on OOD assumptions by using bilevel optimization and ensembles of distilled models.", "motivation": "Existing defenses assume OOD samples in attacker queries, which is unreliable due to diverse training data and limited query budgets, compromising their effectiveness.", "method": "MISLEADER uses bilevel optimization to preserve predictive fidelity and reduce extractability, combining data augmentation and heterogeneous distilled model ensembles.", "result": "Experiments show MISLEADER effectively preserves utility and resists extraction across various settings.", "conclusion": "MISLEADER offers a robust, utility-preserving defense against model extraction without relying on OOD assumptions."}}
{"id": "2506.02740", "pdf": "https://arxiv.org/pdf/2506.02740", "abs": "https://arxiv.org/abs/2506.02740", "authors": ["Ama\u00e7 Herda\u011fdelen", "Marco Baroni"], "title": "Stereotypical gender actions can be extracted from Web text", "categories": ["cs.CL"], "comment": null, "summary": "We extracted gender-specific actions from text corpora and Twitter, and\ncompared them to stereotypical expectations of people. We used Open Mind Common\nSense (OMCS), a commonsense knowledge repository, to focus on actions that are\npertinent to common sense and daily life of humans. We use the gender\ninformation of Twitter users and Web-corpus-based pronoun/name gender\nheuristics to compute the gender bias of the actions. With high recall, we\nobtained a Spearman correlation of 0.47 between corpus-based predictions and a\nhuman gold standard, and an area under the ROC curve of 0.76 when predicting\nthe polarity of the gold standard. We conclude that it is feasible to use\nnatural text (and a Twitter-derived corpus in particular) in order to augment\ncommonsense repositories with the stereotypical gender expectations of actions.\nWe also present a dataset of 441 commonsense actions with human judges' ratings\non whether the action is typically/slightly masculine/feminine (or neutral),\nand another larger dataset of 21,442 actions automatically rated by the methods\nwe investigate in this study.", "AI": {"tldr": "The study extracts gender-specific actions from text corpora and Twitter, comparing them to stereotypes. Using OMCS and gender heuristics, it measures gender bias, achieving a 0.47 correlation with human judgments and 0.76 ROC AUC. It concludes that text corpora can augment commonsense repositories with gender stereotypes, providing two datasets for further research.", "motivation": "To explore how gender-specific actions in text corpora align with stereotypical expectations and augment commonsense knowledge repositories with such insights.", "method": "Extracted actions from text corpora and Twitter, used OMCS for commonsense relevance, and applied gender heuristics to compute bias. Evaluated against human gold standards.", "result": "Achieved 0.47 Spearman correlation with human judgments and 0.76 ROC AUC for polarity prediction. Provided datasets of human-rated and automatically rated actions.", "conclusion": "Feasible to use natural text (especially Twitter) to enrich commonsense repositories with gender stereotypes. Datasets support further research."}}
{"id": "2506.02614", "pdf": "https://arxiv.org/pdf/2506.02614", "abs": "https://arxiv.org/abs/2506.02614", "authors": ["Guohang Zhuang", "Weixi Song", "Jinyang Huang", "Chenwei Yang", "Yan Lu"], "title": "High Performance Space Debris Tracking in Complex Skylight Backgrounds with a Large-Scale Dataset", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "With the rapid development of space exploration, space debris has attracted\nmore attention due to its potential extreme threat, leading to the need for\nreal-time and accurate debris tracking. However, existing methods are mainly\nbased on traditional signal processing, which cannot effectively process the\ncomplex background and dense space debris. In this paper, we propose a deep\nlearning-based Space Debris Tracking Network~(SDT-Net) to achieve highly\naccurate debris tracking. SDT-Net effectively represents the feature of debris,\nenhancing the efficiency and stability of end-to-end model learning. To train\nand evaluate this model effectively, we also produce a large-scale dataset\nSpace Debris Tracking Dataset (SDTD) by a novel observation-based data\nsimulation scheme. SDTD contains 18,040 video sequences with a total of 62,562\nframes and covers 250,000 synthetic space debris. Extensive experiments\nvalidate the effectiveness of our model and the challenging of our dataset.\nFurthermore, we test our model on real data from the Antarctic Station,\nachieving a MOTA score of 70.6%, which demonstrates its strong transferability\nto real-world scenarios. Our dataset and code will be released soon.", "AI": {"tldr": "A deep learning-based Space Debris Tracking Network (SDT-Net) is proposed for accurate debris tracking, supported by a large-scale dataset (SDTD). The model achieves strong performance on real-world data.", "motivation": "Space debris poses a significant threat, but existing methods struggle with complex backgrounds and dense debris. A more efficient solution is needed.", "method": "Proposes SDT-Net, a deep learning model for debris tracking, and introduces SDTD, a large-scale dataset created via observation-based simulation.", "result": "SDT-Net achieves a MOTA score of 70.6% on real-world data from the Antarctic Station, demonstrating high accuracy and transferability.", "conclusion": "SDT-Net and SDTD offer an effective solution for space debris tracking, with potential for real-world applications."}}
{"id": "2506.02415", "pdf": "https://arxiv.org/pdf/2506.02415", "abs": "https://arxiv.org/abs/2506.02415", "authors": ["Karthikeyan Vaiapury"], "title": "AERO: A Redirection-Based Optimization Framework Inspired by Judo for Robust Probabilistic Forecasting", "categories": ["cs.LG", "cs.AI", "62M10, 60G25, 62P30", "I.2.6; I.5.1; G.3; J.2"], "comment": "15 pages, 1 figure, submitted to NeurIPS 2025 (preprint version)", "summary": "Optimization remains a fundamental pillar of machine learning, yet existing\nmethods often struggle to maintain stability and adaptability in dynamic, non\nlinear systems, especially under uncertainty. We introduce AERO (Adversarial\nEnergy-based Redirection Optimization), a novel framework inspired by the\nredirection principle in Judo, where external disturbances are leveraged rather\nthan resisted. AERO reimagines optimization as a redirection process guided by\n15 interrelated axioms encompassing adversarial correction, energy\nconservation, and disturbance-aware learning. By projecting gradients,\nintegrating uncertainty driven dynamics, and managing learning energy, AERO\noffers a principled approach to stable and robust model updates. Applied to\nprobabilistic solar energy forecasting, AERO demonstrates substantial gains in\npredictive accuracy, reliability, and adaptability, especially in noisy and\nuncertain environments. Our findings highlight AERO as a compelling new\ndirection in the theoretical and practical landscape of optimization.", "AI": {"tldr": "AERO is a novel optimization framework inspired by Judo's redirection principle, offering stability and adaptability in dynamic, uncertain systems.", "motivation": "Existing optimization methods struggle with stability and adaptability in nonlinear, uncertain environments.", "method": "AERO uses adversarial correction, energy conservation, and disturbance-aware learning, guided by 15 axioms, to redirect gradients and manage learning energy.", "result": "Applied to solar energy forecasting, AERO improves accuracy, reliability, and adaptability, especially in noisy conditions.", "conclusion": "AERO presents a promising new approach to optimization, balancing theory and practicality."}}
{"id": "2506.02753", "pdf": "https://arxiv.org/pdf/2506.02753", "abs": "https://arxiv.org/abs/2506.02753", "authors": ["Aisha Alansari", "Hamzah Luqman"], "title": "Multi-task Learning with Active Learning for Arabic Offensive Speech Detection", "categories": ["cs.CL"], "comment": null, "summary": "The rapid growth of social media has amplified the spread of offensive,\nviolent, and vulgar speech, which poses serious societal and cybersecurity\nconcerns. Detecting such content in Arabic text is particularly complex due to\nlimited labeled data, dialectal variations, and the language's inherent\ncomplexity. This paper proposes a novel framework that integrates multi-task\nlearning (MTL) with active learning to enhance offensive speech detection in\nArabic social media text. By jointly training on two auxiliary tasks, violent\nand vulgar speech, the model leverages shared representations to improve the\ndetection accuracy of the offensive speech. Our approach dynamically adjusts\ntask weights during training to balance the contribution of each task and\noptimize performance. To address the scarcity of labeled data, we employ an\nactive learning strategy through several uncertainty sampling techniques to\niteratively select the most informative samples for model training. We also\nintroduce weighted emoji handling to better capture semantic cues. Experimental\nresults on the OSACT2022 dataset show that the proposed framework achieves a\nstate-of-the-art macro F1-score of 85.42%, outperforming existing methods while\nusing significantly fewer fine-tuning samples. The findings of this study\nhighlight the potential of integrating MTL with active learning for efficient\nand accurate offensive language detection in resource-constrained settings.", "AI": {"tldr": "A novel framework combining multi-task learning and active learning improves offensive speech detection in Arabic social media text, achieving state-of-the-art results with fewer labeled samples.", "motivation": "The spread of offensive content on social media, especially in Arabic, is challenging due to dialectal variations and limited labeled data.", "method": "The framework integrates multi-task learning (MTL) with active learning, dynamically adjusting task weights and using uncertainty sampling for data selection. Weighted emoji handling is also introduced.", "result": "The model achieves an 85.42% macro F1-score on the OSACT2022 dataset, outperforming existing methods with fewer fine-tuning samples.", "conclusion": "Combining MTL and active learning is effective for offensive language detection in resource-constrained settings."}}
{"id": "2506.02615", "pdf": "https://arxiv.org/pdf/2506.02615", "abs": "https://arxiv.org/abs/2506.02615", "authors": ["Safaa Abdullahi Moallim Mohamud", "Minjin Baek", "Dong Seog Han"], "title": "Hierarchical Question-Answering for Driving Scene Understanding Using Vision-Language Models", "categories": ["cs.CV", "cs.AI"], "comment": "This work has been submitted to the IEEE for possible publication", "summary": "In this paper, we present a hierarchical question-answering (QA) approach for\nscene understanding in autonomous vehicles, balancing cost-efficiency with\ndetailed visual interpretation. The method fine-tunes a compact vision-language\nmodel (VLM) on a custom dataset specific to the geographical area in which the\nvehicle operates to capture key driving-related visual elements. At the\ninference stage, the hierarchical QA strategy decomposes the scene\nunderstanding task into high-level and detailed sub-questions. Instead of\ngenerating lengthy descriptions, the VLM navigates a structured question tree,\nwhere answering high-level questions (e.g., \"Is it possible for the ego vehicle\nto turn left at the intersection?\") triggers more detailed sub-questions (e.g.,\n\"Is there a vehicle approaching the intersection from the opposite\ndirection?\"). To optimize inference time, questions are dynamically skipped\nbased on previous answers, minimizing computational overhead. The extracted\nanswers are then synthesized using handcrafted templates to ensure coherent,\ncontextually accurate scene descriptions. We evaluate the proposed approach on\nthe custom dataset using GPT reference-free scoring, demonstrating its\ncompetitiveness with state-of-the-art methods like GPT-4o in capturing key\nscene details while achieving significantly lower inference time. Moreover,\nqualitative results from real-time deployment highlight the proposed approach's\ncapacity to capture key driving elements with minimal latency.", "AI": {"tldr": "A hierarchical QA approach for autonomous vehicles balances cost-efficiency and detailed scene understanding by fine-tuning a compact VLM and dynamically navigating a question tree.", "motivation": "To achieve detailed visual interpretation in autonomous driving while maintaining cost-efficiency and low latency.", "method": "Fine-tunes a compact VLM on a custom dataset, uses a hierarchical QA strategy to decompose tasks, and dynamically skips questions to optimize inference time.", "result": "Competes with state-of-the-art methods like GPT-4o in accuracy while reducing inference time, validated via GPT reference-free scoring and real-time deployment.", "conclusion": "The approach effectively captures key driving details with minimal latency, proving practical for real-world autonomous vehicle applications."}}
{"id": "2506.02451", "pdf": "https://arxiv.org/pdf/2506.02451", "abs": "https://arxiv.org/abs/2506.02451", "authors": ["Pratheeksha Nair", "Reihaneh Rabbany"], "title": "Weak Supervision for Real World Graphs", "categories": ["cs.LG", "I.2.6"], "comment": null, "summary": "Node classification in real world graphs often suffers from label scarcity\nand noise, especially in high stakes domains like human trafficking detection\nand misinformation monitoring. While direct supervision is limited, such graphs\nfrequently contain weak signals, noisy or indirect cues, that can still inform\nlearning. We propose WSNET, a novel weakly supervised graph contrastive\nlearning framework that leverages these weak signals to guide robust\nrepresentation learning. WSNET integrates graph structure, node features, and\nmultiple noisy supervision sources through a contrastive objective tailored for\nweakly labeled data. Across three real world datasets and synthetic benchmarks\nwith controlled noise, WSNET consistently outperforms state of the art\ncontrastive and noisy label learning methods by up to 15% in F1 score. Our\nresults highlight the effectiveness of contrastive learning under weak\nsupervision and the promise of exploiting imperfect labels in graph based\nsettings.", "AI": {"tldr": "WSNET is a weakly supervised graph contrastive learning framework that leverages noisy or indirect signals for robust node classification, outperforming state-of-the-art methods by up to 15% in F1 score.", "motivation": "Addressing label scarcity and noise in real-world graphs (e.g., human trafficking detection, misinformation monitoring) by utilizing weak signals for learning.", "method": "Proposes WSNET, integrating graph structure, node features, and noisy supervision via a contrastive objective tailored for weakly labeled data.", "result": "Outperforms state-of-the-art methods by up to 15% in F1 score across real-world datasets and synthetic benchmarks.", "conclusion": "Contrastive learning under weak supervision is effective, and imperfect labels can be valuable in graph-based settings."}}
{"id": "2506.02438", "pdf": "https://arxiv.org/pdf/2506.02438", "abs": "https://arxiv.org/abs/2506.02438", "authors": ["Sudhanshu Sekhar Tripathy", "Bichitrananda Behera"], "title": "A Review of Various Datasets for Machine Learning Algorithm-Based Intrusion Detection System: Advances and Challenges", "categories": ["cs.CR", "cs.AI", "cs.LG"], "comment": null, "summary": "IDS aims to protect computer networks from security threats by detecting,\nnotifying, and taking appropriate action to prevent illegal access and protect\nconfidential information. As the globe becomes increasingly dependent on\ntechnology and automated processes, ensuring secured systems, applications, and\nnetworks has become one of the most significant problems of this era. The\nglobal web and digital technology have significantly accelerated the evolution\nof the modern world, necessitating the use of telecommunications and data\ntransfer platforms. Researchers are enhancing the effectiveness of IDS by\nincorporating popular datasets into machine learning algorithms. IDS, equipped\nwith machine learning classifiers, enhances security attack detection accuracy\nby identifying normal or abnormal network traffic. This paper explores the\nmethods of capturing and reviewing intrusion detection systems (IDS) and\nevaluates the challenges existing datasets face. A deluge of research on\nmachine learning (ML) and deep learning (DL) architecture-based intrusion\ndetection techniques has been conducted in the past ten years on various\ncybersecurity datasets, including KDDCUP'99, NSL-KDD, UNSW-NB15, CICIDS-2017,\nand CSE-CIC-IDS2018. We conducted a literature review and presented an in-depth\nanalysis of various intrusion detection methods that use SVM, KNN, DT, LR, NB,\nRF, XGBOOST, Adaboost, and ANN. We provide an overview of each technique,\nexplaining the role of the classifiers and algorithms used. A detailed tabular\nanalysis highlights the datasets used, classifiers employed, attacks detected,\nevaluation metrics, and conclusions drawn. This article offers a thorough\nreview for future IDS research.", "AI": {"tldr": "The paper reviews intrusion detection systems (IDS) enhanced with machine learning, analyzing datasets and classifiers to improve security threat detection.", "motivation": "The increasing reliance on technology and automated processes necessitates robust IDS to protect networks from security threats.", "method": "Literature review and analysis of IDS methods using various machine learning classifiers (SVM, KNN, DT, etc.) on datasets like KDDCUP'99 and CICIDS-2017.", "result": "Detailed tabular analysis of datasets, classifiers, attacks detected, and evaluation metrics, providing insights into IDS effectiveness.", "conclusion": "The paper serves as a comprehensive review for future IDS research, highlighting challenges and advancements in ML/DL-based intrusion detection."}}
{"id": "2506.02758", "pdf": "https://arxiv.org/pdf/2506.02758", "abs": "https://arxiv.org/abs/2506.02758", "authors": ["Stefano Bann\u00f2", "Kate Knill", "Mark Gales"], "title": "Exploiting the English Vocabulary Profile for L2 word-level vocabulary assessment with LLMs", "categories": ["cs.CL", "cs.AI"], "comment": "Accepted to the 20th Workshop on Innovative Use of NLP for Building\n  Educational Applications", "summary": "Vocabulary use is a fundamental aspect of second language (L2) proficiency.\nTo date, its assessment by automated systems has typically examined the\ncontext-independent, or part-of-speech (PoS) related use of words. This paper\nintroduces a novel approach to enable fine-grained vocabulary evaluation\nexploiting the precise use of words within a sentence. The scheme combines\nlarge language models (LLMs) with the English Vocabulary Profile (EVP). The EVP\nis a standard lexical resource that enables in-context vocabulary use to be\nlinked with proficiency level. We evaluate the ability of LLMs to assign\nproficiency levels to individual words as they appear in L2 learner writing,\naddressing key challenges such as polysemy, contextual variation, and\nmulti-word expressions. We compare LLMs to a PoS-based baseline. LLMs appear to\nexploit additional semantic information that yields improved performance. We\nalso explore correlations between word-level proficiency and essay-level\nproficiency. Finally, the approach is applied to examine the consistency of the\nEVP proficiency levels. Results show that LLMs are well-suited for the task of\nvocabulary assessment.", "AI": {"tldr": "The paper introduces a novel method for fine-grained vocabulary assessment in L2 proficiency using LLMs and EVP, outperforming traditional PoS-based approaches.", "motivation": "Current automated systems for vocabulary assessment in L2 proficiency focus on context-independent word use, lacking precision. The paper aims to improve this by leveraging contextual word usage.", "method": "Combines large language models (LLMs) with the English Vocabulary Profile (EVP) to assess word-level proficiency in L2 learner writing, addressing challenges like polysemy and contextual variation.", "result": "LLMs outperform PoS-based methods by utilizing semantic information. The approach also examines correlations between word-level and essay-level proficiency and evaluates EVP consistency.", "conclusion": "LLMs are effective for vocabulary assessment, offering improved performance and insights into proficiency levels."}}
{"id": "2506.02626", "pdf": "https://arxiv.org/pdf/2506.02626", "abs": "https://arxiv.org/abs/2506.02626", "authors": ["Ada Sawilska", "Mateusz Trokielewicz"], "title": "Synthetic Iris Image Databases and Identity Leakage: Risks and Mitigation Strategies", "categories": ["cs.CV"], "comment": null, "summary": "This paper presents a comprehensive overview of iris image synthesis methods,\nwhich can alleviate the issues associated with gathering large, diverse\ndatasets of biometric data from living individuals, which are considered\npivotal for biometric methods development. These methods for synthesizing iris\ndata range from traditional, hand crafted image processing-based techniques,\nthrough various iterations of GAN-based image generators, variational\nautoencoders (VAEs), as well as diffusion models. The potential and fidelity in\niris image generation of each method is discussed and examples of inferred\npredictions are provided. Furthermore, the risks of individual biometric\nfeatures leakage from the training sets are considered, together with possible\nstrategies for preventing them, which have to be implemented should these\ngenerative methods be considered a valid replacement of real-world biometric\ndatasets.", "AI": {"tldr": "The paper reviews iris image synthesis methods to address challenges in collecting real biometric datasets, covering techniques like GANs, VAEs, and diffusion models, while also discussing risks and mitigation strategies.", "motivation": "To overcome the difficulties of acquiring large, diverse biometric datasets from living individuals, which are crucial for biometric method development.", "method": "Examines traditional image processing, GANs, VAEs, and diffusion models for iris image synthesis, comparing their potential and fidelity.", "result": "Provides insights into the effectiveness of each synthesis method and highlights risks of biometric feature leakage from training data.", "conclusion": "Suggests that while generative methods can replace real datasets, strategies to prevent data leakage must be implemented."}}
{"id": "2506.02475", "pdf": "https://arxiv.org/pdf/2506.02475", "abs": "https://arxiv.org/abs/2506.02475", "authors": ["Jiaxi Hu", "Yongqi Pan", "Jusen Du", "Disen Lan", "Xiaqiang Tang", "Qingsong Wen", "Yuxuan Liang", "Weigao Sun"], "title": "Comba: Improving Nonlinear RNNs with Closed-loop Control", "categories": ["cs.LG", "cs.CL"], "comment": null, "summary": "Recent efficient sequence modeling methods such as Gated DeltaNet, TTT, and\nRWKV-7 have achieved performance improvements by supervising the recurrent\nmemory management through Delta learning rule. Unlike previous state-space\nmodels (e.g., Mamba) and gated linear attentions (e.g., GLA), these models\nintroduce interactions between the recurrent state and the key vector,\nresulting in a nonlinear recursive structure. In this paper, we first introduce\nthe concept of Nonlinear RNNs with a comprehensive analysis on the advantages\nand limitations of these models. Then, based on closed-loop control theory, we\npropose a novel Nonlinear RNN variant named Comba, which adopts a\nscalar-plus-low-rank state transition, with both state feedback and output\nfeedback corrections. We also implement a hardware-efficient chunk-wise\nparallel kernel in Triton and train models with 340M/1.3B parameters on\nlarge-scale corpus. Comba demonstrates its superior performance and computation\nefficiency in both language and vision modeling.", "AI": {"tldr": "The paper introduces Nonlinear RNNs, analyzes their advantages/limitations, and proposes Comba, a novel variant with state/output feedback corrections, achieving superior performance in language/vision tasks.", "motivation": "To improve recurrent memory management in sequence modeling by introducing nonlinear recursive structures and leveraging closed-loop control theory.", "method": "Proposes Comba, a Nonlinear RNN with scalar-plus-low-rank state transition, state/output feedback corrections, and a hardware-efficient parallel kernel.", "result": "Comba outperforms in language and vision modeling, demonstrated by training 340M/1.3B parameter models.", "conclusion": "Comba is a computationally efficient and high-performing Nonlinear RNN variant, validated on large-scale tasks."}}
{"id": "2506.02490", "pdf": "https://arxiv.org/pdf/2506.02490", "abs": "https://arxiv.org/abs/2506.02490", "authors": ["Yong Xiang", "Charley Peter Chen", "Liyi Zeng", "Wei Yin", "Xin Liu", "Hu Li", "Wei Xu"], "title": "Simplifying Root Cause Analysis in Kubernetes with StateGraph and LLM", "categories": ["cs.DC", "cs.AI", "cs.SE"], "comment": "12 pages, 13 figures, 5 tables", "summary": "Kubernetes, a notably complex and distributed system, utilizes an array of\ncontrollers to uphold cluster management logic through state reconciliation.\nNevertheless, maintaining state consistency presents significant challenges due\nto unexpected failures, network disruptions, and asynchronous issues,\nespecially within dynamic cloud environments. These challenges result in\noperational disruptions and economic losses, underscoring the necessity for\nrobust root cause analysis (RCA) to enhance Kubernetes reliability. The\ndevelopment of large language models (LLMs) presents a promising direction for\nRCA. However, existing methodologies encounter several obstacles, including the\ndiverse and evolving nature of Kubernetes incidents, the intricate context of\nincidents, and the polymorphic nature of these incidents. In this paper, we\nintroduce SynergyRCA, an innovative tool that leverages LLMs with retrieval\naugmentation from graph databases and enhancement with expert prompts.\nSynergyRCA constructs a StateGraph to capture spatial and temporal\nrelationships and utilizes a MetaGraph to outline entity connections. Upon the\noccurrence of an incident, an LLM predicts the most pertinent resource, and\nSynergyRCA queries the MetaGraph and StateGraph to deliver context-specific\ninsights for RCA. We evaluate SynergyRCA using datasets from two production\nKubernetes clusters, highlighting its capacity to identify numerous root\ncauses, including novel ones, with high efficiency and precision. SynergyRCA\ndemonstrates the ability to identify root causes in an average time of about\ntwo minutes and achieves an impressive precision of approximately 0.90.", "AI": {"tldr": "SynergyRCA is a tool using LLMs and graph databases to improve root cause analysis in Kubernetes, achieving high efficiency and precision.", "motivation": "Kubernetes faces state consistency challenges due to failures and disruptions, necessitating robust RCA for reliability.", "method": "SynergyRCA leverages LLMs with retrieval augmentation from graph databases and expert prompts, using StateGraph and MetaGraph for context-specific insights.", "result": "Evaluated on production Kubernetes clusters, SynergyRCA identifies root causes in ~2 minutes with ~0.90 precision.", "conclusion": "SynergyRCA effectively enhances Kubernetes reliability by addressing RCA challenges with high efficiency and accuracy."}}
{"id": "2506.02803", "pdf": "https://arxiv.org/pdf/2506.02803", "abs": "https://arxiv.org/abs/2506.02803", "authors": ["Sifan Li", "Yujun Cai", "Yiwei Wang"], "title": "SemVink: Advancing VLMs' Semantic Understanding of Optical Illusions via Visual Global Thinking", "categories": ["cs.CL", "cs.CV"], "comment": null, "summary": "Vision-language models (VLMs) excel in semantic tasks but falter at a core\nhuman capability: detecting hidden content in optical illusions or AI-generated\nimages through perceptual adjustments like zooming. We introduce HC-Bench, a\nbenchmark of 112 images with hidden text, objects, and illusions, revealing\nthat leading VLMs achieve near-zero accuracy (0-5.36%)-even with explicit\nprompting. Humans resolve such ambiguities instinctively, yet VLMs fail due to\nan overreliance on high-level semantics. Strikingly, we propose SemVink\n(Semantic Visual Thinking) by simply scaling images to low resolutions (32-128\npixels), which unlocks >99% accuracy by eliminating redundant visual noise.\nThis exposes a critical architectural flaw: VLMs prioritize abstract reasoning\nover low-level visual operations crucial for real-world robustness. Our work\nurges a shift toward hybrid models integrating multi-scale processing, bridging\nthe gap between computational vision and human cognition for applications in\nmedical imaging, security, and beyond.", "AI": {"tldr": "VLMs struggle with hidden content detection in images, scoring 0-5.36% accuracy on HC-Bench. SemVink, a simple scaling method, boosts accuracy to >99%, revealing VLMs' overreliance on high-level semantics.", "motivation": "To address VLMs' failure in detecting hidden content, a core human capability, and propose improvements for real-world applications.", "method": "Introduces HC-Bench with 112 hidden-content images and SemVink, which scales images to low resolutions (32-128 pixels).", "result": "VLMs perform poorly (0-5.36%), while SemVink achieves >99% accuracy by reducing visual noise.", "conclusion": "VLMs need hybrid models with multi-scale processing to bridge the gap between computational vision and human cognition."}}
{"id": "2506.02633", "pdf": "https://arxiv.org/pdf/2506.02633", "abs": "https://arxiv.org/abs/2506.02633", "authors": ["Cheng Yang", "Lijing Liang", "Zhixun Su"], "title": "ControlMambaIR: Conditional Controls with State-Space Model for Image Restoration", "categories": ["cs.CV"], "comment": null, "summary": "This paper proposes ControlMambaIR, a novel image restoration method designed\nto address perceptual challenges in image deraining, deblurring, and denoising\ntasks. By integrating the Mamba network architecture with the diffusion model,\nthe condition network achieves refined conditional control, thereby enhancing\nthe control and optimization of the image generation process. To evaluate the\nrobustness and generalization capability of our method across various image\ndegradation conditions, extensive experiments were conducted on several\nbenchmark datasets, including Rain100H, Rain100L, GoPro, and SSID. The results\ndemonstrate that our proposed approach consistently surpasses existing methods\nin perceptual quality metrics, such as LPIPS and FID, while maintaining\ncomparable performance in image distortion metrics, including PSNR and SSIM,\nhighlighting its effectiveness and adaptability. Notably, ablation experiments\nreveal that directly noise prediction in the diffusion process achieves better\nperformance, effectively balancing noise suppression and detail preservation.\nFurthermore, the findings indicate that the Mamba architecture is particularly\nwell-suited as a conditional control network for diffusion models,\noutperforming both CNN- and Attention-based approaches in this context.\nOverall, these results highlight the flexibility and effectiveness of\nControlMambaIR in addressing a range of image restoration perceptual\nchallenges.", "AI": {"tldr": "ControlMambaIR integrates Mamba and diffusion models for image restoration, excelling in perceptual quality while maintaining distortion metrics.", "motivation": "Address perceptual challenges in image deraining, deblurring, and denoising by refining conditional control in the generation process.", "method": "Combines Mamba network architecture with diffusion models for improved control and optimization.", "result": "Outperforms existing methods in perceptual metrics (LPIPS, FID) and matches distortion metrics (PSNR, SSIM).", "conclusion": "ControlMambaIR is effective and adaptable, with Mamba proving superior as a conditional control network."}}
{"id": "2506.02504", "pdf": "https://arxiv.org/pdf/2506.02504", "abs": "https://arxiv.org/abs/2506.02504", "authors": ["Xingyu Chen", "Bokun Wang", "Ming Yang", "Quanqi Hu", "Qihang Lin", "Tianbao Yang"], "title": "Stochastic Momentum Methods for Non-smooth Non-Convex Finite-Sum Coupled Compositional Optimization", "categories": ["cs.LG"], "comment": null, "summary": "Finite-sum Coupled Compositional Optimization (FCCO), characterized by its\ncoupled compositional objective structure, emerges as an important optimization\nparadigm for addressing a wide range of machine learning problems. In this\npaper, we focus on a challenging class of non-convex non-smooth FCCO, where the\nouter functions are non-smooth weakly convex or convex and the inner functions\nare smooth or weakly convex. Existing state-of-the-art result face two key\nlimitations: (1) a high iteration complexity of $O(1/\\epsilon^6)$ under the\nassumption that the stochastic inner functions are Lipschitz continuous in\nexpectation; (2) reliance on vanilla SGD-type updates, which are not suitable\nfor deep learning applications. Our main contributions are two fold: (i) We\npropose stochastic momentum methods tailored for non-smooth FCCO that come with\nprovable convergence guarantees; (ii) We establish a new state-of-the-art\niteration complexity of $O(1/\\epsilon^5)$. Moreover, we apply our algorithms to\nmultiple inequality constrained non-convex optimization problems involving\nsmooth or weakly convex functional inequality constraints. By optimizing a\nsmoothed hinge penalty based formulation, we achieve a new state-of-the-art\ncomplexity of $O(1/\\epsilon^5)$ for finding an (nearly) $\\epsilon$-level KKT\nsolution. Experiments on three tasks demonstrate the effectiveness of the\nproposed algorithms.", "AI": {"tldr": "The paper addresses non-smooth FCCO problems, proposing stochastic momentum methods to improve iteration complexity from $O(1/\\epsilon^6)$ to $O(1/\\epsilon^5)$ and demonstrating effectiveness in constrained optimization tasks.", "motivation": "Existing methods for non-smooth FCCO suffer from high iteration complexity and unsuitability for deep learning, motivating the development of more efficient algorithms.", "method": "Proposes stochastic momentum methods tailored for non-smooth FCCO, with provable convergence guarantees.", "result": "Achieves a new state-of-the-art iteration complexity of $O(1/\\epsilon^5)$ and validates effectiveness on constrained optimization tasks.", "conclusion": "The proposed methods outperform existing approaches, offering improved efficiency and applicability to deep learning and constrained optimization problems."}}
{"id": "2506.02529", "pdf": "https://arxiv.org/pdf/2506.02529", "abs": "https://arxiv.org/abs/2506.02529", "authors": ["Nguyen-Khang Le", "Quan Minh Bui", "Minh Ngoc Nguyen", "Hiep Nguyen", "Trung Vo", "Son T. Luu", "Shoshin Nomura", "Minh Le Nguyen"], "title": "Automated Web Application Testing: End-to-End Test Case Generation with Large Language Models and Screen Transition Graphs", "categories": ["cs.SE", "cs.AI", "cs.CL", "I.2.7"], "comment": "Published in the Proceedings of JSAI 2025", "summary": "Web applications are critical to modern software ecosystems, yet ensuring\ntheir reliability remains challenging due to the complexity and dynamic nature\nof web interfaces. Recent advances in large language models (LLMs) have shown\npromise in automating complex tasks, but limitations persist in handling\ndynamic navigation flows and complex form interactions. This paper presents an\nautomated system for generating test cases for two key aspects of web\napplication testing: site navigation and form filling. For site navigation, the\nsystem employs screen transition graphs and LLMs to model navigation flows and\ngenerate test scenarios. For form filling, it uses state graphs to handle\nconditional forms and automates Selenium script generation. Key contributions\ninclude: (1) a novel integration of graph structures and LLMs for site\nnavigation testing, (2) a state graph-based approach for automating\nform-filling test cases, and (3) a comprehensive dataset for evaluating\nform-interaction testing. Experimental results demonstrate the system's\neffectiveness in improving test coverage and robustness, advancing the state of\nweb application testing.", "AI": {"tldr": "An automated system using LLMs and graph structures improves web application testing for navigation and form filling.", "motivation": "Ensuring web application reliability is challenging due to dynamic interfaces; existing LLM methods lack handling of navigation and form interactions.", "method": "Uses screen transition graphs and LLMs for navigation testing, and state graphs with Selenium for form filling.", "result": "Improves test coverage and robustness, demonstrated experimentally.", "conclusion": "The system advances web testing by integrating graphs and LLMs, offering a scalable solution."}}
{"id": "2506.02818", "pdf": "https://arxiv.org/pdf/2506.02818", "abs": "https://arxiv.org/abs/2506.02818", "authors": ["Ekaterina Grishina", "Mikhail Gorbunov", "Maxim Rakhuba"], "title": "ProcrustesGPT: Compressing LLMs with Structured Matrices and Orthogonal Transformations", "categories": ["cs.CL", "cs.LG"], "comment": "Accepted by ACL Findings", "summary": "Large language models (LLMs) demonstrate impressive results in natural\nlanguage processing tasks but require a significant amount of computational and\nmemory resources. Structured matrix representations are a promising way for\nreducing the number of parameters of these models. However, it seems\nunrealistic to expect that weight matrices of pretrained models can be\naccurately represented by structured matrices without any fine-tuning. To\novercome this issue, we utilize the fact that LLM output is invariant under\ncertain orthogonal transformations of weight matrices. This insight can be\nleveraged to identify transformations that significantly improve the\ncompressibility of weights within structured classes. The proposed approach is\napplicable to various types of structured matrices that support efficient\nprojection operations. Code is available at\nhttps://github.com/GrishKate/ProcrustesGPT", "AI": {"tldr": "The paper proposes a method to compress large language models (LLMs) by leveraging orthogonal transformations to improve the compressibility of weight matrices using structured representations.", "motivation": "LLMs require high computational and memory resources, and structured matrices can reduce parameters but need fine-tuning for accuracy.", "method": "Utilizes orthogonal transformations of weight matrices, which leave LLM output invariant, to enhance compressibility within structured classes.", "result": "The approach improves the compressibility of LLM weights without altering model output, applicable to various structured matrices.", "conclusion": "The method offers a practical way to reduce LLM resource requirements while maintaining performance, with code available for implementation."}}
{"id": "2506.02671", "pdf": "https://arxiv.org/pdf/2506.02671", "abs": "https://arxiv.org/abs/2506.02671", "authors": ["Xiao Chen", "Jiazhen Huang", "Qinting Jiang", "Fanding Huang", "Xianghua Fu", "Jingyan Jiang", "Zhi Wang"], "title": "Small Aid, Big Leap: Efficient Test-Time Adaptation for Vision-Language Models with AdaptNet", "categories": ["cs.CV"], "comment": null, "summary": "Test-time adaptation (TTA) has emerged as a critical technique for enhancing\nthe generalization capability of vision-language models (VLMs) during\ninference. However, existing approaches often incur substantial computational\ncosts and exhibit poor scalability, primarily due to sample-wise adaptation\ngranularity and reliance on costly auxiliary designs such as data augmentation.\nTo address these limitations, we introduce SAIL (Small Aid, Big Leap), a novel\nadapter-based TTA framework that leverages a lightweight, learnable AdaptNet to\nenable efficient and scalable model adaptation. As SAIL's core, a frozen\npre-trained VLM collaborates with AdaptNet through a confidence-based\ninterpolation weight, generating robust predictions during inference. These\npredictions serve as self-supervised targets to align AdaptNet's outputs\nthrough efficient batch-wise processing, dramatically reducing computational\ncosts without modifying the VLM or requiring memory caches. To mitigate\ncatastrophic forgetting during continual adaptation, we propose a\ngradient-aware reset strategy driven by a gradient drift indicator (GDI), which\ndynamically detects domain transitions and strategically resets AdaptNet for\nstable adaptation. Extensive experiments across diverse benchmarks on two\nscenarios demonstrate that SAIL achieves state-of-the-art performance while\nmaintaining low computational costs. These results highlight SAIL's\neffectiveness, efficiency and scalability for real-world deployment. The code\nwill be released upon acceptance.", "AI": {"tldr": "SAIL introduces a lightweight adapter-based TTA framework for efficient and scalable adaptation of VLMs, reducing computational costs and avoiding catastrophic forgetting.", "motivation": "Existing TTA methods for VLMs are computationally expensive and poorly scalable due to sample-wise adaptation and costly auxiliary designs.", "method": "SAIL uses a frozen VLM and a learnable AdaptNet with confidence-based interpolation and batch-wise processing. A gradient-aware reset strategy (GDI) prevents catastrophic forgetting.", "result": "SAIL achieves state-of-the-art performance with low computational costs across diverse benchmarks.", "conclusion": "SAIL is effective, efficient, and scalable for real-world deployment, offering a practical solution for TTA in VLMs."}}
{"id": "2506.02539", "pdf": "https://arxiv.org/pdf/2506.02539", "abs": "https://arxiv.org/abs/2506.02539", "authors": ["Thong Q. Nguyen", "Shubhang Desai", "Yash Jain", "Tanvir Aumi", "Vishal Chowdhary"], "title": "VerificAgent: Integrating Expert Knowledge and Fact-Checked Memory for Robust Domain-Specific Task Planning", "categories": ["cs.LG"], "comment": null, "summary": "Continual memory augmentation allows computer-use agents (CUAs) to learn from\npast interactions and refine their task-solving strategies over time. However,\nunchecked memory accumulation can introduce spurious or hallucinated\n\"learnings\" that degrade agent performance, particularly in domain-specific\nworkflows such as productivity software. We present a novel framework,\nVerificAgent, that effectively manages memory for CUAs through (1) an\nexpert-curated seed of domain knowledge, (2) iterative, trajectory-based memory\nrefinement during training, and (3) a post-hoc fact-checking pass by human\nexperts to sanitize accumulated memory before deployment. On OSWorld\nproductivity tasks, VerificAgent achieves a 111.1% relative improvement in\nsuccess rate over baseline CUA without any additional fine-tuning.", "AI": {"tldr": "VerificAgent improves CUA performance by managing memory with expert-curated knowledge, iterative refinement, and human fact-checking, achieving a 111.1% boost in success rate.", "motivation": "Unchecked memory accumulation in CUAs can degrade performance due to spurious or hallucinated learnings, especially in domain-specific workflows like productivity software.", "method": "VerificAgent uses expert-curated domain knowledge, iterative memory refinement during training, and post-hoc human fact-checking to manage memory.", "result": "VerificAgent achieves a 111.1% relative improvement in success rate over baseline CUA on OSWorld productivity tasks.", "conclusion": "The VerificAgent framework effectively addresses memory degradation in CUAs, enhancing performance in domain-specific tasks."}}
{"id": "2506.02541", "pdf": "https://arxiv.org/pdf/2506.02541", "abs": "https://arxiv.org/abs/2506.02541", "authors": ["Minsung Kim", "Nakyeong Yang", "Kyomin Jung"], "title": "Rethinking Post-Unlearning Behavior of Large Vision-Language Models", "categories": ["cs.LG", "cs.AI", "cs.CV"], "comment": "10 pages, 5 figures", "summary": "Machine unlearning is used to mitigate the privacy risks of Large\nVision-Language Models (LVLMs) arising from training on large-scale web data.\nHowever, existing unlearning methods often fail to carefully select substitute\noutputs for forget targets, resulting in Unlearning Aftermaths-undesirable\nbehaviors such as degenerate, hallucinated, or excessively refused responses.\nWe highlight that, especially for generative LVLMs, it is crucial to consider\nthe quality and informativeness of post-unlearning responses rather than\nrelying solely on naive suppression. To address this, we introduce a new\nunlearning task for LVLMs that requires models to provide privacy-preserving\nyet informative and visually grounded responses. We also propose PUBG, a novel\nunlearning method that explicitly guides post-unlearning behavior toward a\ndesirable output distribution. Experiments show that, while existing methods\nsuffer from Unlearning Aftermaths despite successfully preventing privacy\nviolations, PUBG effectively mitigates these issues, generating visually\ngrounded and informative responses without privacy leakage for forgotten\ntargets.", "AI": {"tldr": "The paper introduces PUBG, a novel unlearning method for Large Vision-Language Models (LVLMs) to address privacy risks and undesirable post-unlearning behaviors like hallucinations or excessive refusal.", "motivation": "Existing unlearning methods for LVLMs often neglect the quality of post-unlearning responses, leading to issues like degeneracy or privacy leakage.", "method": "The paper proposes PUBG, a method that guides post-unlearning behavior toward a desirable output distribution, ensuring privacy-preserving yet informative responses.", "result": "Experiments show PUBG mitigates Unlearning Aftermaths, generating visually grounded and informative responses without privacy violations.", "conclusion": "PUBG effectively addresses privacy risks and response quality in LVLM unlearning, outperforming existing methods."}}
{"id": "2506.02827", "pdf": "https://arxiv.org/pdf/2506.02827", "abs": "https://arxiv.org/abs/2506.02827", "authors": ["Yulin Dou", "Jiangming Liu"], "title": "TO-GATE: Clarifying Questions and Summarizing Responses with Trajectory Optimization for Eliciting Human Preference", "categories": ["cs.CL"], "comment": null, "summary": "Large language models (LLMs) can effectively elicit human preferences through\nmulti-turn dialogue. Complex tasks can be accomplished through iterative\nclarifying questions and final responses generated by an LLM acting as a\nquestioner (STaR-GATE; Andukuri et al., 2024}). However, existing approaches\nbased on self-taught reasoning struggle to identify optimal dialogue\ntrajectories and avoid irrelevant questions to the tasks. To address this\nlimitation, we propose TO-GATE, a novel framework that enhances question\ngeneration through trajectory optimization, which consists of two key\ncomponents: a clarification resolver that generates optimal questioning\ntrajectories, and a summarizer that ensures task-aligned final responses. The\ntrajectory optimization enables the model to produce effective elicitation\nquestions and summary responses tailored to specific tasks. Experimental\nresults demonstrate that TO-GATE significantly outperforms baseline methods,\nachieving a 9.32% improvement on standard preference elicitation tasks.", "AI": {"tldr": "TO-GATE improves LLM-based preference elicitation by optimizing dialogue trajectories, outperforming baselines by 9.32%.", "motivation": "Existing methods struggle with optimal dialogue trajectories and irrelevant questions.", "method": "TO-GATE uses a clarification resolver for optimal questioning and a summarizer for task-aligned responses.", "result": "Achieves a 9.32% improvement over baselines in preference elicitation tasks.", "conclusion": "TO-GATE effectively enhances LLM-based preference elicitation through trajectory optimization."}}
{"id": "2506.02677", "pdf": "https://arxiv.org/pdf/2506.02677", "abs": "https://arxiv.org/abs/2506.02677", "authors": ["Jintao Tong", "Yixiong Zou", "Guangyao Chen", "Yuhua Li", "Ruixuan Li"], "title": "Self-Disentanglement and Re-Composition for Cross-Domain Few-Shot Segmentation", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": "Accepted by ICML 2025", "summary": "Cross-Domain Few-Shot Segmentation (CD-FSS) aims to transfer knowledge from a\nsource-domain dataset to unseen target-domain datasets with limited\nannotations. Current methods typically compare the distance between training\nand testing samples for mask prediction. However, we find an entanglement\nproblem exists in this widely adopted method, which tends to bind sourcedomain\npatterns together and make each of them hard to transfer. In this paper, we aim\nto address this problem for the CD-FSS task. We first find a natural\ndecomposition of the ViT structure, based on which we delve into the\nentanglement problem for an interpretation. We find the decomposed ViT\ncomponents are crossly compared between images in distance calculation, where\nthe rational comparisons are entangled with those meaningless ones by their\nequal importance, leading to the entanglement problem. Based on this\ninterpretation, we further propose to address the entanglement problem by\nlearning to weigh for all comparisons of ViT components, which learn\ndisentangled features and re-compose them for the CD-FSS task, benefiting both\nthe generalization and finetuning. Experiments show that our model outperforms\nthe state-of-the-art CD-FSS method by 1.92% and 1.88% in average accuracy under\n1-shot and 5-shot settings, respectively.", "AI": {"tldr": "The paper addresses the entanglement problem in Cross-Domain Few-Shot Segmentation (CD-FSS) by decomposing ViT components and learning to weigh comparisons, improving performance.", "motivation": "Current CD-FSS methods suffer from an entanglement problem, binding source-domain patterns and hindering transfer.", "method": "Decomposes ViT structure, identifies cross-comparison issues, and proposes learning to weigh comparisons for disentanglement.", "result": "Outperforms state-of-the-art by 1.92% (1-shot) and 1.88% (5-shot) in average accuracy.", "conclusion": "The proposed method effectively addresses entanglement, enhancing generalization and finetuning for CD-FSS."}}
{"id": "2506.02542", "pdf": "https://arxiv.org/pdf/2506.02542", "abs": "https://arxiv.org/abs/2506.02542", "authors": ["Niklas Kormann", "Masoud Ramuz", "Zeeshan Nisar", "Nadine S. Schaadt", "Hendrik Annuth", "Benjamin Doerr", "Friedrich Feuerhake", "Thomas Lampert", "Johannes F. Lutzeyer"], "title": "HIEGNet: A Heterogenous Graph Neural Network Including the Immune Environment in Glomeruli Classification", "categories": ["cs.LG", "cs.AI", "cs.CV", "q-bio.QM"], "comment": "Accepted for poster presentation at MIDL 2025", "summary": "Graph Neural Networks (GNNs) have recently been found to excel in\nhistopathology. However, an important histopathological task, where GNNs have\nnot been extensively explored, is the classification of glomeruli health as an\nimportant indicator in nephropathology. This task presents unique difficulties,\nparticularly for the graph construction, i.e., the identification of nodes,\nedges, and informative features. In this work, we propose a pipeline composed\nof different traditional and machine learning-based computer vision techniques\nto identify nodes, edges, and their corresponding features to form a\nheterogeneous graph. We then proceed to propose a novel heterogeneous GNN\narchitecture for glomeruli classification, called HIEGNet, that integrates both\nglomeruli and their surrounding immune cells. Hence, HIEGNet is able to\nconsider the immune environment of each glomerulus in its classification. Our\nHIEGNet was trained and tested on a dataset of Whole Slide Images from kidney\ntransplant patients. Experimental results demonstrate that HIEGNet outperforms\nseveral baseline models and generalises best between patients among all\nbaseline models. Our implementation is publicly available at\nhttps://github.com/nklsKrmnn/HIEGNet.git.", "AI": {"tldr": "HIEGNet, a novel heterogeneous GNN, improves glomeruli classification by integrating immune cell context, outperforming baselines.", "motivation": "GNNs excel in histopathology but lack exploration in glomeruli health classification, a key nephropathology task with unique graph construction challenges.", "method": "Proposes a pipeline for graph construction and HIEGNet, a heterogeneous GNN integrating glomeruli and immune cells.", "result": "HIEGNet outperforms baselines and generalizes best between patients on kidney transplant WSIs.", "conclusion": "HIEGNet effectively classifies glomeruli by leveraging immune environment, with public implementation available."}}
{"id": "2506.02548", "pdf": "https://arxiv.org/pdf/2506.02548", "abs": "https://arxiv.org/abs/2506.02548", "authors": ["Zhun Wang", "Tianneng Shi", "Jingxuan He", "Matthew Cai", "Jialin Zhang", "Dawn Song"], "title": "CyberGym: Evaluating AI Agents' Cybersecurity Capabilities with Real-World Vulnerabilities at Scale", "categories": ["cs.CR", "cs.AI", "cs.LG"], "comment": null, "summary": "Large language model (LLM) agents are becoming increasingly skilled at\nhandling cybersecurity tasks autonomously. Thoroughly assessing their\ncybersecurity capabilities is critical and urgent, given the high stakes in\nthis domain. However, existing benchmarks fall short, often failing to capture\nreal-world scenarios or being limited in scope. To address this gap, we\nintroduce CyberGym, a large-scale and high-quality cybersecurity evaluation\nframework featuring 1,507 real-world vulnerabilities found and patched across\n188 large software projects. While it includes tasks of various settings,\nCyberGym primarily focuses on the generation of proof-of-concept (PoC) tests\nfor vulnerability reproduction, based on text descriptions and corresponding\nsource repositories. Solving this task is particularly challenging, as it\nrequires comprehensive reasoning across entire codebases to locate relevant\ncode fragments and produce effective PoCs that accurately trigger the target\nvulnerability starting from the program's entry point. Our evaluation across 4\nstate-of-the-art agent frameworks and 9 LLMs reveals that even the best\ncombination (OpenHands and Claude-3.7-Sonnet) achieves only a 11.9%\nreproduction success rate, mainly on simpler cases. Beyond reproducing\nhistorical vulnerabilities, we find that PoCs generated by LLM agents can\nreveal new vulnerabilities, identifying 15 zero-days affecting the latest\nversions of the software projects.", "AI": {"tldr": "CyberGym is a cybersecurity evaluation framework for LLM agents, featuring 1,507 real-world vulnerabilities. It focuses on PoC test generation, revealing challenges and limited success (11.9%) even with top models.", "motivation": "Existing benchmarks lack real-world relevance and scope, necessitating a robust framework to assess LLM agents' cybersecurity capabilities.", "method": "CyberGym evaluates LLM agents using 1,507 real-world vulnerabilities, emphasizing PoC test generation from text descriptions and source repositories.", "result": "Top-performing models achieved only an 11.9% success rate, with PoCs uncovering 15 new zero-day vulnerabilities.", "conclusion": "CyberGym highlights the challenges in LLM-driven cybersecurity tasks, showing potential but limited current effectiveness, while also uncovering new vulnerabilities."}}
{"id": "2506.02872", "pdf": "https://arxiv.org/pdf/2506.02872", "abs": "https://arxiv.org/abs/2506.02872", "authors": ["Ludovic Moncla", "H\u00e9di Zeghidi"], "title": "Token and Span Classification for Entity Recognition in French Historical Encyclopedias", "categories": ["cs.CL", "cs.IR"], "comment": null, "summary": "Named Entity Recognition (NER) in historical texts presents unique challenges\ndue to non-standardized language, archaic orthography, and nested or\noverlapping entities. This study benchmarks a diverse set of NER approaches,\nranging from classical Conditional Random Fields (CRFs) and spaCy-based models\nto transformer-based architectures such as CamemBERT and sequence-labeling\nmodels like Flair. Experiments are conducted on the GeoEDdA dataset, a richly\nannotated corpus derived from 18th-century French encyclopedias. We propose\nframing NER as both token-level and span-level classification to accommodate\ncomplex nested entity structures typical of historical documents. Additionally,\nwe evaluate the emerging potential of few-shot prompting with generative\nlanguage models for low-resource scenarios. Our results demonstrate that while\ntransformer-based models achieve state-of-the-art performance, especially on\nnested entities, generative models offer promising alternatives when labeled\ndata are scarce. The study highlights ongoing challenges in historical NER and\nsuggests avenues for hybrid approaches combining symbolic and neural methods to\nbetter capture the intricacies of early modern French text.", "AI": {"tldr": "The paper benchmarks NER methods for historical texts, highlighting transformer models' superiority for nested entities and generative models' potential in low-resource settings.", "motivation": "Addressing challenges in NER for historical texts due to non-standardized language, archaic orthography, and nested entities.", "method": "Evaluates CRFs, spaCy, CamemBERT, Flair, and generative models on the GeoEDdA dataset, proposing token- and span-level classification.", "result": "Transformer models excel, especially for nested entities; generative models show promise with scarce labeled data.", "conclusion": "Hybrid approaches combining symbolic and neural methods are suggested for better handling of historical text complexities."}}
{"id": "2506.02690", "pdf": "https://arxiv.org/pdf/2506.02690", "abs": "https://arxiv.org/abs/2506.02690", "authors": ["Yurui Zhao", "Xiang Wang", "Jiahong Liu", "Irwin King", "Zhitao Huang"], "title": "Towards Geometry Problem Solving in the Large Model Era: A Survey", "categories": ["cs.CV", "math.GT"], "comment": "8pages, 4 figures, conference submission", "summary": "Geometry problem solving (GPS) represents a critical frontier in artificial\nintelligence, with profound applications in education, computer-aided design,\nand computational graphics. Despite its significance, automating GPS remains\nchallenging due to the dual demands of spatial understanding and rigorous\nlogical reasoning. Recent advances in large models have enabled notable\nbreakthroughs, particularly for SAT-level problems, yet the field remains\nfragmented across methodologies, benchmarks, and evaluation frameworks. This\nsurvey systematically synthesizes GPS advancements through three core\ndimensions: (1) benchmark construction, (2) textual and diagrammatic parsing,\nand (3) reasoning paradigms. We further propose a unified analytical paradigm,\nassess current limitations, and identify emerging opportunities to guide future\nresearch toward human-level geometric reasoning, including automated benchmark\ngeneration and interpretable neuro-symbolic integration.", "AI": {"tldr": "This survey synthesizes advancements in Geometry Problem Solving (GPS), focusing on benchmarks, parsing, and reasoning, while proposing a unified paradigm and future research directions.", "motivation": "GPS is critical for AI applications but remains challenging due to spatial and logical demands. The field lacks cohesion in methodologies and benchmarks.", "method": "The survey analyzes GPS through three dimensions: benchmark construction, textual/diagrammatic parsing, and reasoning paradigms. It also proposes a unified analytical framework.", "result": "Highlights current advancements, limitations, and opportunities in GPS, such as automated benchmark generation and neuro-symbolic integration.", "conclusion": "The paper aims to guide future research toward human-level geometric reasoning by addressing fragmentation and proposing innovative solutions."}}
{"id": "2506.02553", "pdf": "https://arxiv.org/pdf/2506.02553", "abs": "https://arxiv.org/abs/2506.02553", "authors": ["Shenghua He", "Tian Xia", "Xuan Zhou", "Hui Wei"], "title": "Response-Level Rewards Are All You Need for Online Reinforcement Learning in LLMs: A Mathematical Perspective", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": null, "summary": "We study a common challenge in reinforcement learning for large language\nmodels (LLMs): the Zero-Reward Assumption, where non-terminal actions (i.e.,\nintermediate token generations) receive zero task-specific immediate reward,\nwhile only the final token receives a reward for the entire response. This\nassumption arises frequently in practice, as precise token-level rewards are\noften difficult or infeasible to obtain in LLM applications. In this work, we\nprovide a unifying theoretical perspective. We introduce the Trajectory Policy\nGradient Theorem, which shows that the policy gradient based on true, unknown\ntoken-level rewards can be unbiasedly estimated using only a response-level\nreward model, regardless of whether the Zero-Reward Assumption holds or not,\nfor algorithms in the REINFORCE and Actor-Critic families. This result reveals\nthat widely used methods such as PPO, GRPO, ReMax, and RLOO inherently possess\nthe capacity to model token-level reward signals, offering a theoretical\njustification for response-level reward approaches. Our findings pave the way\nfor more practical, efficient LLM fine-tuning, allowing developers to treat\ntraining algorithms as black boxes and focus on improving the response-level\nreward model with auxiliary sub-models. We also offer a detailed analysis of\npopular RL and non-RL methods, comparing their theoretical foundations and\npractical advantages across common LLM tasks. Finally, we propose a new\nalgorithm: Token-Reinforced Policy Optimization (TRePO), a theoretically\ngrounded method that is simpler than PPO, matches GRPO in memory efficiency,\nand holds promise for broad applicability.", "AI": {"tldr": "The paper addresses the Zero-Reward Assumption in LLMs, showing that response-level rewards can unbiasedly estimate token-level rewards, justifying methods like PPO and proposing a new algorithm, TRePO.", "motivation": "The Zero-Reward Assumption in LLMs makes token-level rewards impractical, motivating a theoretical solution to leverage response-level rewards.", "method": "Introduces the Trajectory Policy Gradient Theorem, proving unbiased estimation of token-level rewards using response-level rewards, and proposes TRePO.", "result": "Theoretical justification for response-level reward methods and a new efficient algorithm, TRePO, are presented.", "conclusion": "The work enables practical LLM fine-tuning by simplifying reward modeling and introduces TRePO for broader applicability."}}
{"id": "2506.02554", "pdf": "https://arxiv.org/pdf/2506.02554", "abs": "https://arxiv.org/abs/2506.02554", "authors": ["Timo Osterburg", "Franz Albers", "Christopher Diehl", "Rajesh Pushparaj", "Torsten Bertram"], "title": "HiLO: High-Level Object Fusion for Autonomous Driving using Transformers", "categories": ["cs.RO", "cs.AI", "cs.CV", "cs.LG"], "comment": "6 pages, accepted at IEEE Intelligent Vehicles Symposium (IV) 2025", "summary": "The fusion of sensor data is essential for a robust perception of the\nenvironment in autonomous driving. Learning-based fusion approaches mainly use\nfeature-level fusion to achieve high performance, but their complexity and\nhardware requirements limit their applicability in near-production vehicles.\nHigh-level fusion methods offer robustness with lower computational\nrequirements. Traditional methods, such as the Kalman filter, dominate this\narea. This paper modifies the Adapted Kalman Filter (AKF) and proposes a novel\ntransformer-based high-level object fusion method called HiLO. Experimental\nresults demonstrate improvements of $25.9$ percentage points in $\\textrm{F}_1$\nscore and $6.1$ percentage points in mean IoU. Evaluation on a new large-scale\nreal-world dataset demonstrates the effectiveness of the proposed approaches.\nTheir generalizability is further validated by cross-domain evaluation between\nurban and highway scenarios. Code, data, and models are available at\nhttps://github.com/rst-tu-dortmund/HiLO .", "AI": {"tldr": "The paper proposes HiLO, a transformer-based high-level object fusion method for autonomous driving, improving performance over traditional methods like the Kalman filter.", "motivation": "Sensor data fusion is critical for robust perception in autonomous driving, but existing learning-based methods are complex and hardware-intensive. High-level fusion methods like the Kalman filter are robust but need improvement.", "method": "The paper modifies the Adapted Kalman Filter (AKF) and introduces HiLO, a transformer-based high-level fusion method.", "result": "HiLO improves F1 score by 25.9 percentage points and mean IoU by 6.1 percentage points, validated on a large-scale dataset and cross-domain scenarios.", "conclusion": "HiLO is effective and generalizable, with code, data, and models made available for further research."}}
{"id": "2506.02878", "pdf": "https://arxiv.org/pdf/2506.02878", "abs": "https://arxiv.org/abs/2506.02878", "authors": ["Jintian Shao", "Yiming Cheng"], "title": "CoT is Not True Reasoning, It Is Just a Tight Constraint to Imitate: A Theory Perspective", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Chain-of-Thought (CoT) prompting has demonstrably enhanced the performance of\nLarge Language Models on tasks requiring multi-step inference. This success has\nled to widespread claims of emergent reasoning capabilities in these models. In\nthis paper, we present a theoretical counter-perspective: Chain-of-Thought\n(CoT) does not elicit genuine, abstract reasoning. Instead, we argue that\nChain-of-Thought functions as a powerful structural constraint that guides\nLarge Language Models to imitate the form of reasoning. By forcing the\ngeneration of intermediate steps, Chain-of-Thought leverages the model immense\ncapacity for sequence prediction and pattern matching, effectively constraining\nits output to sequences that resemble coherent thought processes.\nChain-of-Thought (CoT) prompting has demonstrably enhanced the performance of\nLarge Language Models on tasks requiring multi-step inference. This success has\nled to widespread claims of emergent reasoning capabilities in these models. In\nthis paper, we present a theoretical counter-perspective: Chain-of-Thought\n(CoT) does not elicit genuine, abstract reasoning. Instead, we argue that\nChain-of-Thought functions as a powerful structural constraint that guides\nLarge Language Models to imitate the form of reasoning. By forcing the\ngeneration of intermediate steps, Chain-of-Thought leverages the model immense\ncapacity for sequence prediction and pattern matching, effectively constraining\nits output to sequences that resemble coherent thought processes.", "AI": {"tldr": "The paper argues that Chain-of-Thought (CoT) prompting doesn't enable genuine reasoning in Large Language Models but instead guides them to mimic reasoning through structural constraints.", "motivation": "To challenge the claim that CoT elicits abstract reasoning in models, proposing it merely imitates reasoning forms.", "method": "Theoretical analysis of CoT's role as a structural constraint leveraging sequence prediction and pattern matching.", "result": "CoT enhances performance by mimicking reasoning, not enabling genuine abstract reasoning.", "conclusion": "CoT's success is due to imitation, not true reasoning, questioning claims of emergent reasoning capabilities."}}
{"id": "2506.02692", "pdf": "https://arxiv.org/pdf/2506.02692", "abs": "https://arxiv.org/abs/2506.02692", "authors": ["Shu Yang", "Fengtao Zhou", "Leon Mayer", "Fuxiang Huang", "Yiliang Chen", "Yihui Wang", "Sunan He", "Yuxiang Nie", "Xi Wang", "\u00d6mer S\u00fcmer", "Yueming Jin", "Huihui Sun", "Shuchang Xu", "Alex Qinyang Liu", "Zheng Li", "Jing Qin", "Jeremy YuenChun Teoh", "Lena Maier-Hein", "Hao Chen"], "title": "Large-scale Self-supervised Video Foundation Model for Intelligent Surgery", "categories": ["cs.CV"], "comment": null, "summary": "Computer-Assisted Intervention (CAI) has the potential to revolutionize\nmodern surgery, with surgical scene understanding serving as a critical\ncomponent in supporting decision-making, improving procedural efficacy, and\nensuring intraoperative safety. While existing AI-driven approaches alleviate\nannotation burdens via self-supervised spatial representation learning, their\nlack of explicit temporal modeling during pre-training fundamentally restricts\nthe capture of dynamic surgical contexts, resulting in incomplete\nspatiotemporal understanding. In this work, we introduce the first video-level\nsurgical pre-training framework that enables joint spatiotemporal\nrepresentation learning from large-scale surgical video data. To achieve this,\nwe constructed a large-scale surgical video dataset comprising 3,650 videos and\napproximately 3.55 million frames, spanning more than 20 surgical procedures\nand over 10 anatomical structures. Building upon this dataset, we propose\nSurgVISTA (Surgical Video-level Spatial-Temporal Architecture), a\nreconstruction-based pre-training method that captures intricate spatial\nstructures and temporal dynamics through joint spatiotemporal modeling.\nAdditionally, SurgVISTA incorporates image-level knowledge distillation guided\nby a surgery-specific expert to enhance the learning of fine-grained anatomical\nand semantic features. To validate its effectiveness, we established a\ncomprehensive benchmark comprising 13 video-level datasets spanning six\nsurgical procedures across four tasks. Extensive experiments demonstrate that\nSurgVISTA consistently outperforms both natural- and surgical-domain\npre-trained models, demonstrating strong potential to advance intelligent\nsurgical systems in clinically meaningful scenarios.", "AI": {"tldr": "SurgVISTA is a video-level surgical pre-training framework for joint spatiotemporal representation learning, outperforming existing models in surgical tasks.", "motivation": "Existing AI-driven approaches lack explicit temporal modeling, limiting dynamic surgical context capture. SurgVISTA aims to address this gap.", "method": "Proposes SurgVISTA, a reconstruction-based pre-training method using a large-scale surgical video dataset (3,650 videos, 3.55M frames). Incorporates image-level knowledge distillation.", "result": "Outperforms natural- and surgical-domain pre-trained models across 13 video-level datasets in six surgical procedures.", "conclusion": "SurgVISTA shows strong potential to advance intelligent surgical systems by improving spatiotemporal understanding."}}
{"id": "2506.02563", "pdf": "https://arxiv.org/pdf/2506.02563", "abs": "https://arxiv.org/abs/2506.02563", "authors": ["Roie Reshef", "Kfir Yehuda Levy"], "title": "Privacy-Preserving Federated Convex Optimization: Balancing Partial-Participation and Efficiency via Noise Cancellation", "categories": ["cs.LG"], "comment": "arXiv admin note: text overlap with arXiv:2407.12396", "summary": "This paper tackles the challenge of achieving Differential Privacy (DP) in\nFederated Learning (FL) under partial-participation, where only a subset of the\nmachines participate in each time-step. While previous work achieved optimal\nperformance in full-participation settings, these methods struggled to extend\nto partial-participation scenarios. Our approach fills this gap by introducing\na novel noise-cancellation mechanism that preserves privacy without sacrificing\nconvergence rates or computational efficiency. We analyze our method within the\nStochastic Convex Optimization (SCO) framework and show that it delivers\noptimal performance for both homogeneous and heterogeneous data distributions.\nThis work expands the applicability of DP in FL, offering an efficient and\npractical solution for privacy-preserving learning in distributed systems with\npartial participation.", "AI": {"tldr": "A novel noise-cancellation mechanism for achieving Differential Privacy in Federated Learning under partial-participation, ensuring optimal performance without compromising convergence or efficiency.", "motivation": "Addressing the gap in extending Differential Privacy to partial-participation Federated Learning, where prior methods failed.", "method": "Introduces a noise-cancellation mechanism analyzed within the Stochastic Convex Optimization framework.", "result": "Achieves optimal performance for both homogeneous and heterogeneous data distributions.", "conclusion": "Expands DP applicability in FL, providing an efficient solution for privacy-preserving learning in distributed systems with partial participation."}}
{"id": "2506.02572", "pdf": "https://arxiv.org/pdf/2506.02572", "abs": "https://arxiv.org/abs/2506.02572", "authors": ["Ping Gong", "Jiawei Yi", "Shengnan Wang", "Juncheng Zhang", "Zewen Jin", "Ouxiang Zhou", "Ruibo Liu", "Guanbin Xu", "Youhui Bai", "Bowen Ye", "Kun Yuan", "Tong Yang", "Gong Zhang", "Renhai Chen", "Feng Wu", "Cheng Li"], "title": "HATA: Trainable and Hardware-Efficient Hash-Aware Top-k Attention for Scalable Large Model Inference", "categories": ["cs.LG", "cs.AI"], "comment": "ACL 2025 findings", "summary": "Large Language Models (LLMs) have emerged as a pivotal research area, yet the\nattention module remains a critical bottleneck in LLM inference, even with\ntechniques like KVCache to mitigate redundant computations. While various\ntop-$k$ attention mechanisms have been proposed to accelerate LLM inference by\nexploiting the inherent sparsity of attention, they often struggled to strike a\nbalance between efficiency and accuracy. In this paper, we introduce HATA\n(Hash-Aware Top-$k$ Attention), a novel approach that systematically integrates\nlow-overhead learning-to-hash techniques into the Top-$k$ attention process.\nDifferent from the existing top-k attention methods which are devoted to\nseeking an absolute estimation of qk score, typically with a great cost, HATA\nmaps queries and keys into binary hash codes, and acquires the relative qk\nscore order with a quite low cost, which is sufficient for realizing top-k\nattention. Extensive experiments demonstrate that HATA achieves up to\n7.2$\\times$ speedup compared to vanilla full attention while maintaining model\naccuracy. In addition, HATA outperforms the state-of-the-art top-$k$ attention\nmethods in both accuracy and efficiency across multiple mainstream LLM models\nand diverse tasks. HATA is open source at https://github.com/gpzlx1/HATA.", "AI": {"tldr": "HATA (Hash-Aware Top-$k$ Attention) integrates learning-to-hash into Top-$k$ attention, improving efficiency and accuracy in LLM inference.", "motivation": "Address the bottleneck of attention modules in LLMs by balancing efficiency and accuracy in Top-$k$ attention methods.", "method": "Uses low-overhead learning-to-hash to map queries and keys into binary hash codes, enabling efficient relative qk score estimation.", "result": "Achieves up to 7.2\u00d7 speedup over full attention and outperforms state-of-the-art Top-$k$ methods in accuracy and efficiency.", "conclusion": "HATA is a scalable, efficient solution for accelerating LLM inference without compromising accuracy."}}
{"id": "2506.02899", "pdf": "https://arxiv.org/pdf/2506.02899", "abs": "https://arxiv.org/abs/2506.02899", "authors": ["Yusuke Sakai", "Takumi Goto", "Taro Watanabe"], "title": "IMPARA-GED: Grammatical Error Detection is Boosting Reference-free Grammatical Error Quality Estimator", "categories": ["cs.CL", "cs.AI"], "comment": "ACL 2025 Findings", "summary": "We propose IMPARA-GED, a novel reference-free automatic grammatical error\ncorrection (GEC) evaluation method with grammatical error detection (GED)\ncapabilities. We focus on the quality estimator of IMPARA, an existing\nautomatic GEC evaluation method, and construct that of IMPARA-GED using a\npre-trained language model with enhanced GED capabilities. Experimental results\non SEEDA, a meta-evaluation dataset for automatic GEC evaluation methods,\ndemonstrate that IMPARA-GED achieves the highest correlation with human\nsentence-level evaluations.", "AI": {"tldr": "IMPARA-GED is a reference-free GEC evaluation method with GED capabilities, outperforming existing methods in human correlation.", "motivation": "To improve automatic GEC evaluation by integrating GED capabilities and enhancing quality estimation.", "method": "Enhances IMPARA's quality estimator using a pre-trained language model with GED capabilities, tested on SEEDA dataset.", "result": "Achieves highest correlation with human sentence-level evaluations on SEEDA.", "conclusion": "IMPARA-GED is effective for reference-free GEC evaluation with superior human alignment."}}
{"id": "2506.02695", "pdf": "https://arxiv.org/pdf/2506.02695", "abs": "https://arxiv.org/abs/2506.02695", "authors": ["Linquan Wu", "Tianxiang Jiang", "Wenhao Duan", "Yini Fang", "Jacky Keung"], "title": "FaceSleuth: Learning-Driven Single-Orientation Attention Verifies Vertical Dominance in Micro-Expression Recognition", "categories": ["cs.CV"], "comment": "12 pages, 2 figures", "summary": "Micro-expression recognition (MER) demands models that can amplify\nmillisecond-level, low-amplitude facial motions while suppressing\nidentity-specific appearance. We introduce FaceSleuth, a dual-stream\narchitecture that (1) enhances motion along the empirically dominant vertical\naxix through a Continuously Vertical Attention (CVA) block, (2) localises the\nresulting signals with a Facial Position Focalizer built on hierarchical\ncross-window attention, and (3) steers feature learning toward physiologically\nmeaningful regions via lightweight Action-Unit embeddings. To examine whether\nthe hand-chosen vertical axis is indeed optimal, we further propose a\nSingle-Orientation Attention (SOA) module that learns its own pooling direction\nend-to-end. SOA is differentiable, adds only 0.16 % parameters, and collapses\nto CVA when the learned angle converges to {\\Pi}/2. In practice, SOA reliably\ndrifts to 88{\\deg}, confirming the effectiveness of the vertical prior while\ndelivering consistent gains. On three standard MER benchmarks, FaceSleuth with\nCVA already surpasses previous state-of-the-art methods; plugging in SOA lifts\naccuracy and F1 score performance to 95.1 % / 0.918 on CASME II, 87.1 % / 0.840\non SAMM, and 92.9 % / 0.917 on MMEW without sacrificing model compactness.\nThese results establish a new state of the art and, for the first time, provide\nempirical evidence that the vertical attention bias is the most discriminative\norientation for MER.", "AI": {"tldr": "FaceSleuth introduces a dual-stream architecture for micro-expression recognition, enhancing motion along the vertical axis and localizing signals with attention mechanisms, achieving state-of-the-art results.", "motivation": "Micro-expression recognition requires amplifying subtle facial motions while suppressing identity-specific features.", "method": "FaceSleuth uses a Continuously Vertical Attention (CVA) block, Facial Position Focalizer, and Action-Unit embeddings. A Single-Orientation Attention (SOA) module learns optimal pooling direction.", "result": "Achieves 95.1% accuracy on CASME II, 87.1% on SAMM, and 92.9% on MMEW, outperforming prior methods.", "conclusion": "Vertical attention bias is most discriminative for MER, and FaceSleuth sets a new state of the art."}}
{"id": "2506.02577", "pdf": "https://arxiv.org/pdf/2506.02577", "abs": "https://arxiv.org/abs/2506.02577", "authors": ["Wenyan Yang", "Joni Pajarinen"], "title": "Reachability Weighted Offline Goal-conditioned Resampling", "categories": ["cs.LG"], "comment": null, "summary": "Offline goal-conditioned reinforcement learning (RL) relies on fixed datasets\nwhere many potential goals share the same state and action spaces. However,\nthese potential goals are not explicitly represented in the collected\ntrajectories. To learn a generalizable goal-conditioned policy, it is common to\nsample goals and state-action pairs uniformly using dynamic programming methods\nsuch as Q-learning. Uniform sampling, however, requires an intractably large\ndataset to cover all possible combinations and creates many unreachable\nstate-goal-action pairs that degrade policy performance. Our key insight is\nthat sampling should favor transitions that enable goal achievement. To this\nend, we propose Reachability Weighted Sampling (RWS). RWS uses a reachability\nclassifier trained via positive-unlabeled (PU) learning on goal-conditioned\nstate-action values. The classifier maps these values to a reachability score,\nwhich is then used as a sampling priority. RWS is a plug-and-play module that\nintegrates seamlessly with standard offline RL algorithms. Experiments on six\ncomplex simulated robotic manipulation tasks, including those with a robot arm\nand a dexterous hand, show that RWS significantly improves performance. In one\nnotable case, performance on the HandBlock-Z task improved by nearly 50 percent\nrelative to the baseline. These results indicate the effectiveness of\nreachability-weighted sampling.", "AI": {"tldr": "The paper introduces Reachability Weighted Sampling (RWS) to improve offline goal-conditioned RL by prioritizing reachable state-goal-action pairs, enhancing policy performance.", "motivation": "Uniform sampling in offline goal-conditioned RL leads to inefficiencies and degraded performance due to unreachable pairs. The paper aims to address this by favoring transitions that enable goal achievement.", "method": "Proposes RWS, which uses a reachability classifier trained via PU learning to assign sampling priorities based on reachability scores derived from goal-conditioned state-action values.", "result": "RWS significantly improves performance on six robotic manipulation tasks, with a 50% improvement in the HandBlock-Z task compared to baselines.", "conclusion": "RWS effectively enhances offline goal-conditioned RL by focusing on reachable transitions, demonstrating its practical utility in complex tasks."}}
{"id": "2506.02606", "pdf": "https://arxiv.org/pdf/2506.02606", "abs": "https://arxiv.org/abs/2506.02606", "authors": ["Baoyang Chen", "Xian Xu", "Huamin Qu"], "title": "Multi Layered Autonomy and AI Ecologies in Robotic Art Installations", "categories": ["cs.RO", "cs.AI"], "comment": null, "summary": "Symbiosis of Agents is a large-scale installation by Baoyang Chen that embeds\nAI-driven robots in an immersive, mirror-lined arena, probing the tension\nbetween machine agency and artistic authorship. Drawing on early cybernetics,\nrule-based conceptual art, and seminal robotic works, it orchestrates fluid\nexchanges among robotic arms, quadruped machines, their environment, and the\npublic. A three tier faith system pilots the ecology: micro-level adaptive\ntactics, meso-level narrative drives, and a macro-level prime directive. This\nhierarchy lets behaviors evolve organically in response to environmental cues\nand even a viewer's breath, turning spectators into co-authors of the unfolding\ndrama.Framed by a speculative terraforming scenario that recalls the historical\nexploitation of marginalized labor, the piece asks who bears responsibility in\nAI-mediated futures. Choreographed motion, AI-generated scripts, reactive\nlighting, and drifting fog cast the robots as collaborators rather than tools,\nforging a living, emergent artwork. Exhibited internationally, Symbiosis of\nAgents shows how cybernetic feedback, robotic experimentation, and conceptual\nrule-making can converge to redefine agency, authorship, and ethics in\ncontemporary art.", "AI": {"tldr": "Symbiosis of Agents is an AI-driven robotic installation exploring machine agency, artistic authorship, and human-robot collaboration through adaptive behaviors and environmental interactions.", "motivation": "The work probes tensions between machine agency and artistic authorship, inspired by cybernetics, conceptual art, and robotics, while questioning responsibility in AI-mediated futures.", "method": "It uses a three-tier faith system (micro, meso, macro) to guide robotic behaviors, integrating adaptive tactics, narrative drives, and a prime directive, with environmental and audience interactions.", "result": "The installation transforms spectators into co-authors, creating emergent, living artwork through choreographed motion, AI scripts, and reactive elements like lighting and fog.", "conclusion": "Symbiosis of Agents demonstrates how cybernetics, robotics, and rule-making can redefine agency, authorship, and ethics in contemporary art."}}
{"id": "2506.02911", "pdf": "https://arxiv.org/pdf/2506.02911", "abs": "https://arxiv.org/abs/2506.02911", "authors": ["Yin Fang", "Qiao Jin", "Guangzhi Xiong", "Bowen Jin", "Xianrui Zhong", "Siru Ouyang", "Aidong Zhang", "Jiawei Han", "Zhiyong Lu"], "title": "Cell-o1: Training LLMs to Solve Single-Cell Reasoning Puzzles with Reinforcement Learning", "categories": ["cs.CL", "cs.AI", "cs.CE", "cs.HC", "cs.LG"], "comment": "28 pages; 16 tables; 7 figures; Code:\n  https://github.com/ncbi-nlp/cell-o1", "summary": "Cell type annotation is a key task in analyzing the heterogeneity of\nsingle-cell RNA sequencing data. Although recent foundation models automate\nthis process, they typically annotate cells independently, without considering\nbatch-level cellular context or providing explanatory reasoning. In contrast,\nhuman experts often annotate distinct cell types for different cell clusters\nbased on their domain knowledge. To mimic this workflow, we introduce the\nCellPuzzles task, where the objective is to assign unique cell types to a batch\nof cells. This benchmark spans diverse tissues, diseases, and donor conditions,\nand requires reasoning across the batch-level cellular context to ensure label\nuniqueness. We find that off-the-shelf large language models (LLMs) struggle on\nCellPuzzles, with the best baseline (OpenAI's o1) achieving only 19.0%\nbatch-level accuracy. To fill this gap, we propose Cell-o1, a 7B LLM trained\nvia supervised fine-tuning on distilled reasoning traces, followed by\nreinforcement learning with batch-level rewards. Cell-o1 achieves\nstate-of-the-art performance, outperforming o1 by over 73% and generalizing\nwell across contexts. Further analysis of training dynamics and reasoning\nbehaviors provides insights into batch-level annotation performance and\nemergent expert-like reasoning. Code and data are available at\nhttps://github.com/ncbi-nlp/cell-o1.", "AI": {"tldr": "The paper introduces CellPuzzles, a task for batch-level cell type annotation in single-cell RNA sequencing data, and proposes Cell-o1, a fine-tuned LLM that outperforms baselines by 73%.", "motivation": "Current foundation models annotate cells independently, lacking batch-level context and reasoning, unlike human experts who consider broader context.", "method": "Proposes Cell-o1, a 7B LLM trained via supervised fine-tuning on reasoning traces and reinforcement learning with batch-level rewards.", "result": "Cell-o1 achieves 73% better batch-level accuracy than the best baseline (OpenAI's o1) and generalizes well.", "conclusion": "Cell-o1 sets a new standard for batch-level cell annotation, mimicking expert-like reasoning and improving performance."}}
{"id": "2506.02697", "pdf": "https://arxiv.org/pdf/2506.02697", "abs": "https://arxiv.org/abs/2506.02697", "authors": ["Yuxuan Wu", "Le Wang", "Sanping Zhou", "Mengnan Liu", "Gang Hua", "Haoxiang Li"], "title": "LayoutRAG: Retrieval-Augmented Model for Content-agnostic Conditional Layout Generation", "categories": ["cs.CV"], "comment": "12 pages, 5 figures", "summary": "Controllable layout generation aims to create plausible visual arrangements\nof element bounding boxes within a graphic design according to certain optional\nconstraints, such as the type or position of a specific component. While recent\ndiffusion or flow-matching models have achieved considerable advances in\nmultifarious conditional generation tasks, there remains considerable room for\ngenerating optimal arrangements under given conditions. In this work, we\npropose to carry out layout generation through retrieving by conditions and\nreference-guided generation. Specifically, we retrieve appropriate layout\ntemplates according to given conditions as references. The references are then\nutilized to guide the denoising or flow-based transport process. By retrieving\nlayouts compatible with the given conditions, we can uncover the potential\ninformation not explicitly provided in the given condition. Such an approach\noffers more effective guidance to the model during the generation process, in\ncontrast to previous models that feed the condition to the model and let the\nmodel infer the unprovided layout attributes directly. Meanwhile, we design a\ncondition-modulated attention that selectively absorbs retrieval knowledge,\nadapting to the difference between retrieved templates and given conditions.\nExtensive experiment results show that our method successfully produces\nhigh-quality layouts that meet the given conditions and outperforms existing\nstate-of-the-art models. Code will be released upon acceptance.", "AI": {"tldr": "The paper introduces a method for controllable layout generation using retrieval-based templates and reference-guided generation, outperforming existing models.", "motivation": "To improve layout generation under given constraints by leveraging retrieved templates and reference-guided processes, addressing limitations of current models.", "method": "Retrieves layout templates matching conditions, uses them to guide denoising or flow-based transport, and employs condition-modulated attention for selective knowledge absorption.", "result": "Produces high-quality layouts meeting conditions and surpasses state-of-the-art models.", "conclusion": "The proposed approach effectively leverages retrieved templates for better layout generation, demonstrating superior performance."}}
{"id": "2506.02599", "pdf": "https://arxiv.org/pdf/2506.02599", "abs": "https://arxiv.org/abs/2506.02599", "authors": ["Niklas Ro\u00dfberg", "Marion Neumeier", "Sinan Hasirlioglu", "Mohamed Essayed Bouzouraa", "Michael Botsch"], "title": "Assessing the Completeness of Traffic Scenario Categories for Automated Highway Driving Functions via Cluster-based Analysis", "categories": ["cs.LG"], "comment": null, "summary": "The ability to operate safely in increasingly complex traffic scenarios is a\nfundamental requirement for Automated Driving Systems (ADS). Ensuring the safe\nrelease of ADS functions necessitates a precise understanding of the occurring\ntraffic scenarios. To support this objective, this work introduces a pipeline\nfor traffic scenario clustering and the analysis of scenario category\ncompleteness. The Clustering Vector Quantized - Variational Autoencoder\n(CVQ-VAE) is employed for the clustering of highway traffic scenarios and\nutilized to create various catalogs with differing numbers of traffic scenario\ncategories. Subsequently, the impact of the number of categories on the\ncompleteness considerations of the traffic scenario categories is analyzed. The\nresults show an outperforming clustering performance compared to previous work.\nThe trade-off between cluster quality and the amount of required data to\nmaintain completeness is discussed based on the publicly available highD\ndataset.", "AI": {"tldr": "A pipeline for clustering and analyzing highway traffic scenarios using CVQ-VAE, showing improved performance and discussing data-completeness trade-offs.", "motivation": "Ensuring safe operation of Automated Driving Systems (ADS) requires precise understanding of traffic scenarios.", "method": "Uses CVQ-VAE for clustering highway scenarios and analyzes category completeness.", "result": "Outperforms previous clustering methods; discusses trade-off between cluster quality and data requirements.", "conclusion": "The approach enhances scenario understanding for ADS safety, with insights on balancing data needs and completeness."}}
{"id": "2506.02612", "pdf": "https://arxiv.org/pdf/2506.02612", "abs": "https://arxiv.org/abs/2506.02612", "authors": ["Jan Robine", "Marc H\u00f6ftmann", "Stefan Harmeling"], "title": "Simple, Good, Fast: Self-Supervised World Models Free of Baggage", "categories": ["cs.LG", "cs.AI", "stat.ML"], "comment": "Published as a conference paper at ICLR 2025. Code is available at\n  https://github.com/jrobine/sgf", "summary": "What are the essential components of world models? How far do we get with\nworld models that are not employing RNNs, transformers, discrete\nrepresentations, and image reconstructions? This paper introduces SGF, a\nSimple, Good, and Fast world model that uses self-supervised representation\nlearning, captures short-time dependencies through frame and action stacking,\nand enhances robustness against model errors through data augmentation. We\nextensively discuss SGF's connections to established world models, evaluate the\nbuilding blocks in ablation studies, and demonstrate good performance through\nquantitative comparisons on the Atari 100k benchmark.", "AI": {"tldr": "SGF is a simple, fast, and effective world model using self-supervised learning, frame/action stacking, and data augmentation, performing well on Atari 100k.", "motivation": "To explore world models without RNNs, transformers, discrete representations, or image reconstructions, and to develop a simpler yet effective alternative.", "method": "Uses self-supervised representation learning, frame and action stacking for short-time dependencies, and data augmentation for robustness.", "result": "Demonstrates good performance on the Atari 100k benchmark through ablation studies and comparisons.", "conclusion": "SGF proves that simpler world models can be effective, offering a viable alternative to complex architectures."}}
{"id": "2506.02921", "pdf": "https://arxiv.org/pdf/2506.02921", "abs": "https://arxiv.org/abs/2506.02921", "authors": ["Yijun Yang", "Zeyu Huang", "Wenhao Zhu", "Zihan Qiu", "Fei Yuan", "Jeff Z. Pan", "Ivan Titov"], "title": "A Controllable Examination for Long-Context Language Models", "categories": ["cs.CL"], "comment": "Preprint", "summary": "Existing frameworks for evaluating long-context language models (LCLM) can be\nbroadly categorized into real-world and synthetic tasks. Despite their utility,\nboth approaches are accompanied by certain intrinsic limitations. Real-world\ntasks are too complex to interpret or characterize and are susceptible to data\ncontamination. In contrast, synthetic tasks often adopt the\nneedle-in-the-haystack (NIAH) format, wherein a lack of coherence between the\n\"needle\" and the \"haystack\" compromises their validity as proxies for realistic\napplications. In response to these challenges, we posit that an ideal\nlong-context evaluation framework should be characterized by three essential\nfeatures: $\\textit{seamless context}$, $\\textit{controllable setting}$, and\n$\\textit{sound evaluation}$. This study introduces $\\textbf{LongBioBench}$, a\nnovel benchmark that utilizes artificially generated biographies as a\ncontrolled environment for assessing LCLMs across dimensions of\n$\\textit{understanding}$, $\\textit{reasoning}$, and $\\textit{trustworthiness}$.\nOur experimental evaluation, which includes $\\textbf{18}$ LCLMs in total,\ndemonstrates that most models still exhibit deficiencies in semantic\nunderstanding and elementary reasoning over retrieved results and are less\ntrustworthy as context length increases. Our further analysis indicates some\ndesign choices employed by existing synthetic benchmarks, such as contextual\nnon-coherence, numerical needles, and the absence of distractors, rendering\nthem vulnerable to test the model long-context capabilities. Moreover, we also\nreveal that long-context continual pretraining primarily adjusts RoPE embedding\nto accommodate extended context lengths. To sum up, compared to previous\nsynthetic benchmarks, LongBioBench achieves a better trade-off between\nmirroring authentic language tasks and maintaining controllability, and is\nhighly interpretable and configurable.", "AI": {"tldr": "The paper introduces LongBioBench, a new benchmark for evaluating long-context language models (LCLMs) using artificially generated biographies, addressing limitations of existing real-world and synthetic tasks.", "motivation": "Existing evaluation frameworks for LCLMs have intrinsic limitations: real-world tasks are complex and prone to data contamination, while synthetic tasks lack coherence and realism.", "method": "LongBioBench is designed with seamless context, controllable settings, and sound evaluation, assessing LCLMs on understanding, reasoning, and trustworthiness.", "result": "Evaluation of 18 LCLMs shows deficiencies in semantic understanding, reasoning, and trustworthiness as context length increases. Existing synthetic benchmarks are found vulnerable due to design flaws.", "conclusion": "LongBioBench offers a better trade-off between realism and controllability compared to previous benchmarks, with high interpretability and configurability."}}
{"id": "2506.02698", "pdf": "https://arxiv.org/pdf/2506.02698", "abs": "https://arxiv.org/abs/2506.02698", "authors": ["Yunhong Lu", "Qichao Wang", "Hengyuan Cao", "Xiaoyin Xu", "Min Zhang"], "title": "Smoothed Preference Optimization via ReNoise Inversion for Aligning Diffusion Models with Varied Human Preferences", "categories": ["cs.CV"], "comment": "Accepted by ICML 2025", "summary": "Direct Preference Optimization (DPO) aligns text-to-image (T2I) generation\nmodels with human preferences using pairwise preference data. Although\nsubstantial resources are expended in collecting and labeling datasets, a\ncritical aspect is often neglected: \\textit{preferences vary across individuals\nand should be represented with more granularity.} To address this, we propose\nSmPO-Diffusion, a novel method for modeling preference distributions to improve\nthe DPO objective, along with a numerical upper bound estimation for the\ndiffusion optimization objective. First, we introduce a smoothed preference\ndistribution to replace the original binary distribution. We employ a reward\nmodel to simulate human preferences and apply preference likelihood averaging\nto improve the DPO loss, such that the loss function approaches zero when\npreferences are similar. Furthermore, we utilize an inversion technique to\nsimulate the trajectory preference distribution of the diffusion model,\nenabling more accurate alignment with the optimization objective. Our approach\neffectively mitigates issues of excessive optimization and objective\nmisalignment present in existing methods through straightforward modifications.\nOur SmPO-Diffusion achieves state-of-the-art performance in preference\nevaluation, outperforming baselines across metrics with lower training costs.\nThe project page is https://jaydenlyh.github.io/SmPO-project-page/.", "AI": {"tldr": "SmPO-Diffusion improves Direct Preference Optimization (DPO) by modeling granular preference distributions and providing a numerical upper bound for diffusion optimization, achieving better alignment and performance.", "motivation": "Existing DPO methods neglect individual preference variability, leading to misalignment and excessive optimization. SmPO-Diffusion addresses this by modeling preference distributions more accurately.", "method": "Introduces smoothed preference distributions, a reward model for simulating human preferences, and preference likelihood averaging to refine the DPO loss. Uses inversion for trajectory preference distribution simulation.", "result": "SmPO-Diffusion outperforms baselines in preference evaluation with lower training costs, mitigating excessive optimization and misalignment issues.", "conclusion": "SmPO-Diffusion offers a robust solution for aligning T2I models with human preferences, achieving state-of-the-art results through granular preference modeling."}}
{"id": "2506.02616", "pdf": "https://arxiv.org/pdf/2506.02616", "abs": "https://arxiv.org/abs/2506.02616", "authors": ["Qi Liao", "Parijat Bhattacharjee"], "title": "Compositional Learning for Modular Multi-Agent Self-Organizing Networks", "categories": ["cs.LG"], "comment": null, "summary": "Self-organizing networks face challenges from complex parameter\ninterdependencies and conflicting objectives. This study introduces two\ncompositional learning approaches-Compositional Deep Reinforcement Learning\n(CDRL) and Compositional Predictive Decision-Making (CPDM)-and evaluates their\nperformance under training time and safety constraints in multi-agent systems.\nWe propose a modular, two-tier framework with cell-level and cell-pair-level\nagents to manage heterogeneous agent granularities while reducing model\ncomplexity. Numerical simulations reveal a significant reduction in handover\nfailures, along with improved throughput and latency, outperforming\nconventional multi-agent deep reinforcement learning approaches. The approach\nalso demonstrates superior scalability, faster convergence, higher sample\nefficiency, and safer training in large-scale self-organizing networks.", "AI": {"tldr": "The paper introduces two compositional learning methods (CDRL and CPDM) for self-organizing networks, showing improved performance in multi-agent systems under constraints.", "motivation": "Addressing challenges like parameter interdependencies and conflicting objectives in self-organizing networks.", "method": "Proposes a modular, two-tier framework with cell-level and cell-pair-level agents to manage granularities and reduce complexity.", "result": "Significant reduction in handover failures, improved throughput and latency, better scalability, faster convergence, and safer training.", "conclusion": "The compositional learning approaches outperform conventional methods in large-scale self-organizing networks."}}
{"id": "2506.02619", "pdf": "https://arxiv.org/pdf/2506.02619", "abs": "https://arxiv.org/abs/2506.02619", "authors": ["Yanbei Liu", "Chongxu Wang", "Zhitao Xiao", "Lei Geng", "Yanwei Pang", "Xiao Wang"], "title": "HGOT: Self-supervised Heterogeneous Graph Neural Network with Optimal Transport", "categories": ["cs.LG", "cs.AI"], "comment": "The paper has 9 pages of text and 13 pages in total (including\n  acknowledgments, impact statement, references, and appendix), with 6 figures\n  and 2 tables. This paper has been accepted by ICML 2025 conference and this\n  is a final version of the manuscript submitted to the conference", "summary": "Heterogeneous Graph Neural Networks (HGNNs), have demonstrated excellent\ncapabilities in processing heterogeneous information networks. Self-supervised\nlearning on heterogeneous graphs, especially contrastive self-supervised\nstrategy, shows great potential when there are no labels. However, this\napproach requires the use of carefully designed graph augmentation strategies\nand the selection of positive and negative samples. Determining the exact level\nof similarity between sample pairs is non-trivial.To solve this problem, we\npropose a novel self-supervised Heterogeneous graph neural network with Optimal\nTransport (HGOT) method which is designed to facilitate self-supervised\nlearning for heterogeneous graphs without graph augmentation strategies.\nDifferent from traditional contrastive self-supervised learning, HGOT employs\nthe optimal transport mechanism to relieve the laborious sampling process of\npositive and negative samples. Specifically, we design an aggregating view\n(central view) to integrate the semantic information contained in the views\nrepresented by different meta-paths (branch views). Then, we introduce an\noptimal transport plan to identify the transport relationship between the\nsemantics contained in the branch view and the central view. This allows the\noptimal transport plan between graphs to align with the representations,\nforcing the encoder to learn node representations that are more similar to the\ngraph space and of higher quality. Extensive experiments on four real-world\ndatasets demonstrate that our proposed HGOT model can achieve state-of-the-art\nperformance on various downstream tasks. In particular, in the node\nclassification task, HGOT achieves an average of more than 6% improvement in\naccuracy compared with state-of-the-art methods.", "AI": {"tldr": "HGOT is a self-supervised HGNN method using optimal transport to avoid graph augmentation and sample selection, improving node classification accuracy by 6%.", "motivation": "Traditional contrastive self-supervised learning on heterogeneous graphs requires complex augmentation and sample selection, which HGOT aims to simplify.", "method": "HGOT uses optimal transport to align semantic information from branch views (meta-paths) to a central view, eliminating the need for augmentation and sample selection.", "result": "HGOT outperforms state-of-the-art methods, achieving a 6% accuracy improvement in node classification tasks.", "conclusion": "HGOT provides a simpler and more effective self-supervised learning approach for heterogeneous graphs, validated by superior performance on real-world datasets."}}
{"id": "2506.02924", "pdf": "https://arxiv.org/pdf/2506.02924", "abs": "https://arxiv.org/abs/2506.02924", "authors": ["Diogo A. P. Nunes", "Eug\u00e9nio Ribeiro"], "title": "INESC-ID @ eRisk 2025: Exploring Fine-Tuned, Similarity-Based, and Prompt-Based Approaches to Depression Symptom Identification", "categories": ["cs.CL", "cs.IR", "cs.LG", "I.2.7; I.5.4; J.3; H.3.3"], "comment": "12 pages, 1 figure, 6 tables", "summary": "In this work, we describe our team's approach to eRisk's 2025 Task 1: Search\nfor Symptoms of Depression. Given a set of sentences and the Beck's Depression\nInventory - II (BDI) questionnaire, participants were tasked with submitting up\nto 1,000 sentences per depression symptom in the BDI, sorted by relevance.\nParticipant submissions were evaluated according to standard Information\nRetrieval (IR) metrics, including Average Precision (AP) and R-Precision\n(R-PREC). The provided training data, however, consisted of sentences labeled\nas to whether a given sentence was relevant or not w.r.t. one of BDI's\nsymptoms. Due to this labeling limitation, we framed our development as a\nbinary classification task for each BDI symptom, and evaluated accordingly. To\nthat end, we split the available labeled data into training and validation\nsets, and explored foundation model fine-tuning, sentence similarity, Large\nLanguage Model (LLM) prompting, and ensemble techniques. The validation results\nrevealed that fine-tuning foundation models yielded the best performance,\nparticularly when enhanced with synthetic data to mitigate class imbalance. We\nalso observed that the optimal approach varied by symptom. Based on these\ninsights, we devised five independent test runs, two of which used ensemble\nmethods. These runs achieved the highest scores in the official IR evaluation,\noutperforming submissions from 16 other teams.", "AI": {"tldr": "The paper describes a method for identifying depression symptoms using binary classification, fine-tuning foundation models, and ensemble techniques, achieving top performance in the eRisk 2025 Task 1.", "motivation": "The task involved identifying relevant sentences for depression symptoms from the BDI questionnaire, but the training data had binary labels, prompting a classification approach.", "method": "The team used binary classification for each symptom, fine-tuned foundation models, employed sentence similarity, LLM prompting, and ensemble methods, with synthetic data to address class imbalance.", "result": "Fine-tuning foundation models with synthetic data performed best, with varying approaches per symptom. Their submissions outperformed 16 other teams in IR metrics.", "conclusion": "The study highlights the effectiveness of fine-tuning foundation models and ensemble methods for symptom-specific classification in depression detection tasks."}}
{"id": "2506.02702", "pdf": "https://arxiv.org/pdf/2506.02702", "abs": "https://arxiv.org/abs/2506.02702", "authors": ["Tibor Kub\u00edk", "Fran\u00e7ois Guibault", "Michal \u0160pan\u011bl", "Herv\u00e9 Lombaert"], "title": "ToothForge: Automatic Dental Shape Generation using Synchronized Spectral Embeddings", "categories": ["cs.CV"], "comment": "Information Processing in Medical Imaging (IPMI2025)", "summary": "We introduce ToothForge, a spectral approach for automatically generating\nnovel 3D teeth, effectively addressing the sparsity of dental shape datasets.\nBy operating in the spectral domain, our method enables compact machine\nlearning modeling, allowing the generation of high-resolution tooth meshes in\nmilliseconds. However, generating shape spectra comes with the instability of\nthe decomposed harmonics. To address this, we propose modeling the latent\nmanifold on synchronized frequential embeddings. Spectra of all data samples\nare aligned to a common basis prior to the training procedure, effectively\neliminating biases introduced by the decomposition instability. Furthermore,\nsynchronized modeling removes the limiting factor imposed by previous methods,\nwhich require all shapes to share a common fixed connectivity. Using a private\ndataset of real dental crowns, we observe a greater reconstruction quality of\nthe synthetized shapes, exceeding those of models trained on unaligned\nembeddings. We also explore additional applications of spectral analysis in\ndigital dentistry, such as shape compression and interpolation. ToothForge\nfacilitates a range of approaches at the intersection of spectral analysis and\nmachine learning, with fewer restrictions on mesh structure. This makes it\napplicable for shape analysis not only in dentistry, but also in broader\nmedical applications, where guaranteeing consistent connectivity across shapes\nfrom various clinics is unrealistic. The code is available at\nhttps://github.com/tiborkubik/toothForge.", "AI": {"tldr": "ToothForge is a spectral method for generating 3D teeth, addressing dataset sparsity by using synchronized frequential embeddings to stabilize decomposed harmonics and improve reconstruction quality.", "motivation": "The sparsity of dental shape datasets and instability in decomposed harmonics limit the generation of high-resolution 3D teeth. ToothForge aims to overcome these challenges.", "method": "The method operates in the spectral domain, aligning spectra to a common basis and modeling the latent manifold on synchronized frequential embeddings. This eliminates decomposition biases and removes connectivity constraints.", "result": "ToothForge achieves higher reconstruction quality than models using unaligned embeddings and enables additional applications like shape compression and interpolation.", "conclusion": "ToothForge advances spectral analysis in dentistry and broader medical applications by reducing mesh structure restrictions and improving shape generation."}}
{"id": "2506.02623", "pdf": "https://arxiv.org/pdf/2506.02623", "abs": "https://arxiv.org/abs/2506.02623", "authors": ["Yuyang Zhou", "Ferrante Neri", "Yew-Soon Ong", "Ruibin Bai"], "title": "SiamNAS: Siamese Surrogate Model for Dominance Relation Prediction in Multi-objective Neural Architecture Search", "categories": ["cs.LG", "cs.AI", "cs.CV"], "comment": "Genetic and Evolutionary Computation Conference (GECCO' 25)", "summary": "Modern neural architecture search (NAS) is inherently multi-objective,\nbalancing trade-offs such as accuracy, parameter count, and computational cost.\nThis complexity makes NAS computationally expensive and nearly impossible to\nsolve without efficient approximations. To address this, we propose a novel\nsurrogate modelling approach that leverages an ensemble of Siamese network\nblocks to predict dominance relationships between candidate architectures.\nLightweight and easy to train, the surrogate achieves 92% accuracy and replaces\nthe crowding distance calculation in the survivor selection strategy with a\nheuristic rule based on model size. Integrated into a framework termed SiamNAS,\nthis design eliminates costly evaluations during the search process.\nExperiments on NAS-Bench-201 demonstrate the framework's ability to identify\nPareto-optimal solutions with significantly reduced computational costs. The\nproposed SiamNAS identified a final non-dominated set containing the best\narchitecture in NAS-Bench-201 for CIFAR-10 and the second-best for ImageNet, in\nterms of test error rate, within 0.01 GPU days. This proof-of-concept study\nhighlights the potential of the proposed Siamese network surrogate model to\ngeneralise to multi-tasking optimisation, enabling simultaneous optimisation\nacross tasks. Additionally, it offers opportunities to extend the approach for\ngenerating Sets of Pareto Sets (SOS), providing diverse Pareto-optimal\nsolutions for heterogeneous task settings.", "AI": {"tldr": "A novel surrogate modeling approach using Siamese networks for efficient neural architecture search (NAS), reducing computational costs while identifying Pareto-optimal solutions.", "motivation": "Addressing the computational expense and complexity of multi-objective NAS by proposing a lightweight surrogate model.", "method": "Leverages an ensemble of Siamese network blocks to predict dominance relationships and replaces crowding distance with a heuristic rule.", "result": "Achieves 92% accuracy, identifies top architectures in NAS-Bench-201 within 0.01 GPU days, and demonstrates potential for multi-task optimization.", "conclusion": "SiamNAS offers a scalable and efficient solution for NAS, with potential extensions for diverse Pareto-optimal solutions in heterogeneous tasks."}}
{"id": "2506.02634", "pdf": "https://arxiv.org/pdf/2506.02634", "abs": "https://arxiv.org/abs/2506.02634", "authors": ["Jiahao Wang", "Jinbo Han", "Xingda Wei", "Sijie Shen", "Dingyan Zhang", "Chenguang Fang", "Rong Chen", "Wenyuan Yu", "Haibo Chen"], "title": "KVCache Cache in the Wild: Characterizing and Optimizing KVCache Cache at a Large Cloud Provider", "categories": ["cs.DC", "cs.AI"], "comment": "Accepted by USENIX ATC'25", "summary": "Serving large language models (LLMs) is important for cloud providers, and\ncaching intermediate results (KV\\$) after processing each request substantially\nimproves serving throughput and latency. However, there is limited\nunderstanding of how LLM serving benefits from KV\\$ caching, where system\ndesign decisions like cache eviction policies are highly workload-dependent. In\nthis paper, we present the first systematic characterization of the KV\\$\nworkload patterns from one of the leading LLM service providers. We draw\nobservations that were not covered by previous studies focusing on synthetic\nworkloads, including: KV\\$ reuses are skewed across requests, where reuses\nbetween single-turn requests are equally important as multi-turn requests; the\nreuse time and probability are diverse considering all requests, but for a\nspecific request category, the pattern tends to be predictable; and the overall\ncache size required for an ideal cache hit ratio is moderate. Based on the\ncharacterization, we further propose a workload-aware cache eviction policy\nthat improves the serving performance under real-world traces, especially with\nlimited cache capacity.", "AI": {"tldr": "The paper analyzes KV$ caching in LLM serving, revealing skewed reuse patterns and predictable behaviors, and proposes a workload-aware eviction policy to improve performance.", "motivation": "To understand how KV$ caching benefits LLM serving and address gaps in workload-dependent system design decisions.", "method": "Systematic characterization of KV$ workload patterns from a leading LLM provider, identifying reuse skew and predictability.", "result": "KV$ reuse is skewed and predictable per request category; moderate cache size suffices for ideal hit ratios.", "conclusion": "A workload-aware cache eviction policy enhances serving performance, especially with limited cache capacity."}}
{"id": "2506.02945", "pdf": "https://arxiv.org/pdf/2506.02945", "abs": "https://arxiv.org/abs/2506.02945", "authors": ["Aishwarya Sahoo", "Jeevana Kruthi Karnuthala", "Tushar Parmanand Budhwani", "Pranchal Agarwal", "Sankaran Vaidyanathan", "Alexa Siu", "Franck Dernoncourt", "Jennifer Healey", "Nedim Lipka", "Ryan Rossi", "Uttaran Bhattacharya", "Branislav Kveton"], "title": "Quantitative LLM Judges", "categories": ["cs.CL", "cs.LG"], "comment": null, "summary": "LLM-as-a-judge is a framework in which a large language model (LLM)\nautomatically evaluates the output of another LLM. We propose quantitative LLM\njudges, which align evaluation scores of existing LLM judges to human scores in\na given domain using regression models. The models are trained to improve the\nscore of the original judge by using the judge's textual evaluation and score.\nWe present four quantitative judges for different types of absolute and\nrelative feedback, which showcases the generality and versatility of our\nframework. Our framework is more computationally efficient than supervised\nfine-tuning and can be more statistically efficient when human feedback is\nlimited, which is expected in most applications of our work. We validate these\nclaims empirically on four datasets using two base judges. Our experiments show\nthat quantitative judges can effectively improve the predictive power of\nexisting judges through post-hoc modeling.", "AI": {"tldr": "The paper introduces 'quantitative LLM judges,' a framework where large language models (LLMs) evaluate other LLMs' outputs by aligning scores with human feedback using regression models, improving efficiency and accuracy.", "motivation": "To enhance the evaluation of LLM outputs by aligning automated scores with human judgments more efficiently than fine-tuning, especially where human feedback is scarce.", "method": "Proposes four quantitative judges using regression models to adjust original LLM judges' scores based on textual evaluations and scores, validated on four datasets with two base judges.", "result": "Quantitative judges improve predictive power of existing judges, demonstrating computational and statistical efficiency, especially with limited human feedback.", "conclusion": "The framework effectively enhances LLM evaluation by aligning automated scores with human judgments, offering a versatile and efficient alternative to fine-tuning."}}
{"id": "2506.02708", "pdf": "https://arxiv.org/pdf/2506.02708", "abs": "https://arxiv.org/abs/2506.02708", "authors": ["Naoto Tanji", "Toshihiko Yamasaki"], "title": "Iterative Self-Improvement of Vision Language Models for Image Scoring and Self-Explanation", "categories": ["cs.CV", "cs.CL"], "comment": "Accepted to ICIP2025", "summary": "Image scoring is a crucial task in numerous real-world applications. To trust\na model's judgment, understanding its rationale is essential. This paper\nproposes a novel training method for Vision Language Models (VLMs) to generate\nnot only image scores but also corresponding justifications in natural\nlanguage. Leveraging only an image scoring dataset and an instruction-tuned\nVLM, our method enables self-training, utilizing the VLM's generated text\nwithout relying on external data or models. In addition, we introduce a simple\nmethod for creating a dataset designed to improve alignment between predicted\nscores and their textual justifications. By iteratively training the model with\nDirect Preference Optimization on two distinct datasets and merging them, we\ncan improve both scoring accuracy and the coherence of generated explanations.", "AI": {"tldr": "A novel self-training method for Vision Language Models (VLMs) generates image scores and natural language justifications, improving accuracy and coherence without external data.", "motivation": "Understanding a model's rationale for image scoring is essential for trust in real-world applications.", "method": "Leverages an image scoring dataset and an instruction-tuned VLM for self-training, using Direct Preference Optimization on two datasets to merge and improve results.", "result": "Improved scoring accuracy and coherence of generated explanations.", "conclusion": "The method effectively enhances VLM performance in generating both scores and justifications, fostering trust in model judgments."}}
{"id": "2506.02630", "pdf": "https://arxiv.org/pdf/2506.02630", "abs": "https://arxiv.org/abs/2506.02630", "authors": ["Tom Jacobs", "Advait Gadhikar", "Celia Rubio-Madrigal", "Rebekka Burkholz"], "title": "HAM: A Hyperbolic Step to Regulate Implicit Bias", "categories": ["cs.LG"], "comment": "26 pages, 7 figures", "summary": "Understanding the implicit bias of optimization algorithms has become central\nto explaining the generalization behavior of deep learning models. For\ninstance, the hyperbolic implicit bias induced by the overparameterization $m\n\\odot w$--though effective in promoting sparsity--can result in a small\neffective learning rate, which slows down convergence. To overcome this\nobstacle, we propose HAM (Hyperbolic Aware Minimization), which alternates\nbetween an optimizer step and a new hyperbolic mirror step. We derive the\nRiemannian gradient flow for its combination with gradient descent, leading to\nimproved convergence and a similar beneficial hyperbolic geometry as $m \\odot\nw$ for feature learning. We provide an interpretation of the the algorithm by\nrelating it to natural gradient descent, and an exact characterization of its\nimplicit bias for underdetermined linear regression. HAM's implicit bias\nconsistently boosts performance--even of dense training, as we demonstrate in\nexperiments across diverse tasks, including vision, graph and node\nclassification, and large language model fine-tuning. HAM is especially\neffective in combination with different sparsification methods, improving upon\nthe state of the art. The hyperbolic step requires minimal computational and\nmemory overhead, it succeeds even with small batch sizes, and its\nimplementation integrates smoothly with existing optimizers.", "AI": {"tldr": "HAM (Hyperbolic Aware Minimization) improves convergence and feature learning by combining optimizer steps with hyperbolic mirror steps, addressing the slow convergence of hyperbolic implicit bias in deep learning.", "motivation": "The hyperbolic implicit bias in overparameterized models slows convergence despite promoting sparsity. HAM aims to overcome this limitation.", "method": "HAM alternates between optimizer steps and hyperbolic mirror steps, deriving a Riemannian gradient flow for improved convergence and feature learning.", "result": "HAM boosts performance in diverse tasks (vision, graph classification, LLM fine-tuning) and works well with sparsification methods, requiring minimal overhead.", "conclusion": "HAM effectively addresses the convergence issue of hyperbolic implicit bias, enhancing performance with minimal computational cost."}}
{"id": "2506.02654", "pdf": "https://arxiv.org/pdf/2506.02654", "abs": "https://arxiv.org/abs/2506.02654", "authors": ["Shiyu Shen", "Bin Pan", "Guirong Xue"], "title": "A Pretrained Probabilistic Transformer for City-Scale Traffic Volume Prediction", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "City-scale traffic volume prediction plays a pivotal role in intelligent\ntransportation systems, yet remains a challenge due to the inherent\nincompleteness and bias in observational data. Although deep learning-based\nmethods have shown considerable promise, most existing approaches produce\ndeterministic point estimates, thereby neglecting the uncertainty arising from\nunobserved traffic flows. Furthermore, current models are typically trained in\na city-specific manner, which hinders their generalizability and limits\nscalability across diverse urban contexts. To overcome these limitations, we\nintroduce TrafficPPT, a Pretrained Probabilistic Transformer designed to model\ntraffic volume as a distributional aggregation of trajectories. Our framework\nfuses heterogeneous data sources-including real-time observations, historical\ntrajectory data, and road network topology-enabling robust and\nuncertainty-aware traffic inference. TrafficPPT is initially pretrained on\nlarge-scale simulated data spanning multiple urban scenarios, and later\nfine-tuned on target cities to ensure effective domain adaptation. Experiments\non real-world datasets show that TrafficPPT consistently surpasses\nstate-of-the-art baselines, particularly under conditions of extreme data\nsparsity. Code will be open.", "AI": {"tldr": "TrafficPPT is a Pretrained Probabilistic Transformer for city-scale traffic volume prediction, addressing data incompleteness and uncertainty by modeling traffic as a distributional aggregation of trajectories. It outperforms existing methods, especially in sparse data conditions.", "motivation": "Existing traffic prediction methods lack uncertainty modeling and city-specific training limits generalizability. TrafficPPT aims to overcome these by integrating diverse data sources and pretraining on simulated data.", "method": "TrafficPPT uses a Pretrained Probabilistic Transformer to model traffic volume distributions, combining real-time observations, historical trajectories, and road network topology. It pretrains on simulated data and fine-tunes for target cities.", "result": "TrafficPPT outperforms state-of-the-art baselines, particularly in extreme data sparsity scenarios, demonstrating robust and uncertainty-aware traffic inference.", "conclusion": "TrafficPPT provides a scalable, uncertainty-aware solution for city-scale traffic prediction, with open-sourced code for broader application."}}
{"id": "2506.02959", "pdf": "https://arxiv.org/pdf/2506.02959", "abs": "https://arxiv.org/abs/2506.02959", "authors": ["Zhixiong Su", "Yichen Wang", "Herun Wan", "Zhaohan Zhang", "Minnan Luo"], "title": "HACo-Det: A Study Towards Fine-Grained Machine-Generated Text Detection under Human-AI Coauthoring", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "The misuse of large language models (LLMs) poses potential risks, motivating\nthe development of machine-generated text (MGT) detection. Existing literature\nprimarily concentrates on binary, document-level detection, thereby neglecting\ntexts that are composed jointly by human and LLM contributions. Hence, this\npaper explores the possibility of fine-grained MGT detection under human-AI\ncoauthoring. We suggest fine-grained detectors can pave pathways toward\ncoauthored text detection with a numeric AI ratio. Specifically, we propose a\ndataset, HACo-Det, which produces human-AI coauthored texts via an automatic\npipeline with word-level attribution labels. We retrofit seven prevailing\ndocument-level detectors to generalize them to word-level detection. Then we\nevaluate these detectors on HACo-Det on both word- and sentence-level detection\ntasks. Empirical results show that metric-based methods struggle to conduct\nfine-grained detection with a 0.462 average F1 score, while finetuned models\nshow superior performance and better generalization across domains. However, we\nargue that fine-grained co-authored text detection is far from solved. We\nfurther analyze factors influencing performance, e.g., context window, and\nhighlight the limitations of current methods, pointing to potential avenues for\nimprovement.", "AI": {"tldr": "The paper explores fine-grained detection of machine-generated text (MGT) in human-AI coauthored content, proposing a dataset (HACo-Det) and evaluating retrofitted detectors. Finetuned models outperform metric-based methods, but challenges remain.", "motivation": "The misuse of LLMs and the lack of methods for detecting human-AI coauthored texts motivate the need for fine-grained MGT detection.", "method": "Proposes HACo-Det dataset with word-level labels and retrofits seven document-level detectors for word- and sentence-level tasks.", "result": "Finetuned models outperform metric-based methods (0.462 average F1), but fine-grained detection remains challenging.", "conclusion": "Fine-grained coauthored text detection is unsolved; context window and method limitations highlight areas for improvement."}}
{"id": "2506.02733", "pdf": "https://arxiv.org/pdf/2506.02733", "abs": "https://arxiv.org/abs/2506.02733", "authors": ["Xiaoyi Feng", "Kaifeng Zou", "Caichun Cen", "Tao Huang", "Hui Guo", "Zizhou Huang", "Yingli Zhao", "Mingqing Zhang", "Diwei Wang", "Yuntao Zou", "Dagang Li"], "title": "LinkTo-Anime: A 2D Animation Optical Flow Dataset from 3D Model Rendering", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Existing optical flow datasets focus primarily on real-world simulation or\nsynthetic human motion, but few are tailored to Celluloid(cel) anime character\nmotion: a domain with unique visual and motion characteristics. To bridge this\ngap and facilitate research in optical flow estimation and downstream tasks\nsuch as anime video generation and line drawing colorization, we introduce\nLinkTo-Anime, the first high-quality dataset specifically designed for cel\nanime character motion generated with 3D model rendering. LinkTo-Anime provides\nrich annotations including forward and backward optical flow, occlusion masks,\nand Mixamo Skeleton. The dataset comprises 395 video sequences, totally 24,230\ntraining frames, 720 validation frames, and 4,320 test frames. Furthermore, a\ncomprehensive benchmark is constructed with various optical flow estimation\nmethods to analyze the shortcomings and limitations across multiple datasets.", "AI": {"tldr": "LinkTo-Anime is the first high-quality dataset for cel anime character motion, offering rich annotations and benchmarks for optical flow research.", "motivation": "Existing datasets lack focus on cel anime motion, hindering research in optical flow and related tasks like anime video generation.", "method": "The dataset is created using 3D model rendering, providing optical flow, occlusion masks, and skeleton annotations across 395 video sequences.", "result": "LinkTo-Anime includes 24,230 training, 720 validation, and 4,320 test frames, with benchmarks highlighting method limitations.", "conclusion": "The dataset bridges a critical gap, enabling advancements in optical flow estimation and anime-specific applications."}}
{"id": "2506.02665", "pdf": "https://arxiv.org/pdf/2506.02665", "abs": "https://arxiv.org/abs/2506.02665", "authors": ["Tianci Liu", "Tong Yang", "Quan Zhang", "Qi Lei"], "title": "Beyond Invisibility: Learning Robust Visible Watermarks for Stronger Copyright Protection", "categories": ["cs.LG"], "comment": "UAI 2025", "summary": "As AI advances, copyrighted content faces growing risk of unauthorized use,\nwhether through model training or direct misuse. Building upon invisible\nadversarial perturbation, recent works developed copyright protections against\nspecific AI techniques such as unauthorized personalization through DreamBooth\nthat are misused. However, these methods offer only short-term security, as\nthey require retraining whenever the underlying model architectures change. To\nestablish long-term protection aiming at better robustness, we go beyond\ninvisible perturbation, and propose a universal approach that embeds\n\\textit{visible} watermarks that are \\textit{hard-to-remove} into images.\nGrounded in a new probabilistic and inverse problem-based formulation, our\nframework maximizes the discrepancy between the \\textit{optimal} reconstruction\nand the original content. We develop an effective and efficient approximation\nalgorithm to circumvent a intractable bi-level optimization. Experimental\nresults demonstrate superiority of our approach across diverse scenarios.", "AI": {"tldr": "A universal visible watermarking method is proposed for long-term copyright protection against AI misuse, outperforming existing adversarial perturbation techniques.", "motivation": "To address the short-term security of existing copyright protections (e.g., invisible adversarial perturbations) and provide robust, long-term solutions against AI misuse.", "method": "Proposes a visible, hard-to-remove watermarking framework based on a probabilistic and inverse problem formulation, with an efficient approximation algorithm to solve the bi-level optimization.", "result": "Experimental results show the approach's superiority in diverse scenarios, offering better robustness compared to existing methods.", "conclusion": "The proposed visible watermarking method provides a more robust and long-term solution for protecting copyrighted content against AI misuse."}}
{"id": "2506.02694", "pdf": "https://arxiv.org/pdf/2506.02694", "abs": "https://arxiv.org/abs/2506.02694", "authors": ["Daichi Kimura", "Tomonori Izumitani", "Hisashi Kashima"], "title": "XicorAttention: Time Series Transformer Using Attention with Nonlinear Correlation", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Various Transformer-based models have been proposed for time series\nforecasting. These models leverage the self-attention mechanism to capture\nlong-term temporal or variate dependencies in sequences. Existing methods can\nbe divided into two approaches: (1) reducing computational cost of attention by\nmaking the calculations sparse, and (2) reshaping the input data to aggregate\ntemporal features. However, existing attention mechanisms may not adequately\ncapture inherent nonlinear dependencies present in time series data, leaving\nroom for improvement. In this study, we propose a novel attention mechanism\nbased on Chatterjee's rank correlation coefficient, which measures nonlinear\ndependencies between variables. Specifically, we replace the matrix\nmultiplication in standard attention mechanisms with this rank coefficient to\nmeasure the query-key relationship. Since computing Chatterjee's correlation\ncoefficient involves sorting and ranking operations, we introduce a\ndifferentiable approximation employing SoftSort and SoftRank. Our proposed\nmechanism, ``XicorAttention,'' integrates it into several state-of-the-art\nTransformer models. Experimental results on real-world datasets demonstrate\nthat incorporating nonlinear correlation into the attention improves\nforecasting accuracy by up to approximately 9.1\\% compared to existing models.", "AI": {"tldr": "A novel attention mechanism, XicorAttention, using Chatterjee's rank correlation coefficient improves time series forecasting by capturing nonlinear dependencies, outperforming existing models by up to 9.1%.", "motivation": "Existing attention mechanisms in Transformer-based models for time series forecasting may not adequately capture nonlinear dependencies, leaving room for improvement.", "method": "Proposes XicorAttention, replacing standard attention's matrix multiplication with Chatterjee's rank correlation coefficient, using differentiable approximations (SoftSort and SoftRank) for computation.", "result": "Experiments show XicorAttention improves forecasting accuracy by up to 9.1% compared to existing models.", "conclusion": "Incorporating nonlinear correlation via XicorAttention enhances forecasting performance, demonstrating its effectiveness in capturing complex dependencies in time series data."}}
{"id": "2506.02961", "pdf": "https://arxiv.org/pdf/2506.02961", "abs": "https://arxiv.org/abs/2506.02961", "authors": ["Yan Gao", "Massimo Roberto Scamarcia", "Javier Fernandez-Marques", "Mohammad Naseri", "Chong Shen Ng", "Dimitris Stripelis", "Zexi Li", "Tao Shen", "Jiamu Bai", "Daoyuan Chen", "Zikai Zhang", "Rui Hu", "InSeo Song", "Lee KangYoon", "Hong Jia", "Ting Dang", "Junyan Wang", "Zheyuan Liu", "Daniel Janes Beutel", "Lingjuan Lyu", "Nicholas D. Lane"], "title": "FlowerTune: A Cross-Domain Benchmark for Federated Fine-Tuning of Large Language Models", "categories": ["cs.CL"], "comment": null, "summary": "Large Language Models (LLMs) have achieved state-of-the-art results across\ndiverse domains, yet their development remains reliant on vast amounts of\npublicly available data, raising concerns about data scarcity and the lack of\naccess to domain-specific, sensitive information. Federated Learning (FL)\npresents a compelling framework to address these challenges by enabling\ndecentralized fine-tuning on pre-trained LLMs without sharing raw data.\nHowever, the compatibility and performance of pre-trained LLMs in FL settings\nremain largely under explored. We introduce the FlowerTune LLM Leaderboard, a\nfirst-of-its-kind benchmarking suite designed to evaluate federated fine-tuning\nof LLMs across four diverse domains: general NLP, finance, medical, and coding.\nEach domain includes federated instruction-tuning datasets and domain-specific\nevaluation metrics. Our results, obtained through a collaborative, open-source\nand community-driven approach, provide the first comprehensive comparison\nacross 26 pre-trained LLMs with different aggregation and fine-tuning\nstrategies under federated settings, offering actionable insights into model\nperformance, resource constraints, and domain adaptation. This work lays the\nfoundation for developing privacy-preserving, domain-specialized LLMs for\nreal-world applications.", "AI": {"tldr": "The paper introduces the FlowerTune LLM Leaderboard to benchmark federated fine-tuning of LLMs across diverse domains, addressing data scarcity and privacy concerns.", "motivation": "To tackle data scarcity and privacy issues in LLM development by leveraging Federated Learning (FL) for decentralized fine-tuning without sharing raw data.", "method": "Developed the FlowerTune LLM Leaderboard, evaluating 26 pre-trained LLMs across four domains (general NLP, finance, medical, coding) with federated datasets and domain-specific metrics.", "result": "First comprehensive comparison of LLMs in FL settings, providing insights into performance, resource constraints, and domain adaptation.", "conclusion": "The work establishes a foundation for privacy-preserving, domain-specialized LLMs, enabling real-world applications."}}
{"id": "2506.02736", "pdf": "https://arxiv.org/pdf/2506.02736", "abs": "https://arxiv.org/abs/2506.02736", "authors": ["Shufan Qing", "Anzhen Li", "Qiandi Wang", "Yuefeng Niu", "Mingchen Feng", "Guoliang Hu", "Jinqiao Wu", "Fengtao Nan", "Yingchun Fan"], "title": "GeneA-SLAM2: Dynamic SLAM with AutoEncoder-Preprocessed Genetic Keypoints Resampling and Depth Variance-Guided Dynamic Region Removal", "categories": ["cs.CV", "cs.RO"], "comment": null, "summary": "Existing semantic SLAM in dynamic environments mainly identify dynamic\nregions through object detection or semantic segmentation methods. However, in\ncertain highly dynamic scenarios, the detection boxes or segmentation masks\ncannot fully cover dynamic regions. Therefore, this paper proposes a robust and\nefficient GeneA-SLAM2 system that leverages depth variance constraints to\nhandle dynamic scenes. Our method extracts dynamic pixels via depth variance\nand creates precise depth masks to guide the removal of dynamic objects.\nSimultaneously, an autoencoder is used to reconstruct keypoints, improving the\ngenetic resampling keypoint algorithm to obtain more uniformly distributed\nkeypoints and enhance the accuracy of pose estimation. Our system was evaluated\non multiple highly dynamic sequences. The results demonstrate that GeneA-SLAM2\nmaintains high accuracy in dynamic scenes compared to current methods. Code is\navailable at: https://github.com/qingshufan/GeneA-SLAM2.", "AI": {"tldr": "GeneA-SLAM2 improves semantic SLAM in dynamic scenes by using depth variance for dynamic pixel extraction and autoencoder-based keypoint reconstruction.", "motivation": "Existing methods fail to fully cover dynamic regions in highly dynamic scenarios, limiting accuracy.", "method": "Uses depth variance constraints to extract dynamic pixels and create depth masks, plus an autoencoder for keypoint reconstruction and genetic resampling.", "result": "Outperforms current methods in highly dynamic sequences, maintaining high accuracy.", "conclusion": "GeneA-SLAM2 is robust and efficient for dynamic environments, with code publicly available."}}
{"id": "2506.02703", "pdf": "https://arxiv.org/pdf/2506.02703", "abs": "https://arxiv.org/abs/2506.02703", "authors": ["Khizar Hayat", "Baptiste Magnier"], "title": "Data Leakage and Deceptive Performance: A Critical Examination of Credit Card Fraud Detection Methodologies", "categories": ["cs.LG", "cs.AI", "cs.CY"], "comment": null, "summary": "This study critically examines the methodological rigor in credit card fraud\ndetection research, revealing how fundamental evaluation flaws can overshadow\nalgorithmic sophistication. Through deliberate experimentation with improper\nevaluation protocols, we demonstrate that even simple models can achieve\ndeceptively impressive results when basic methodological principles are\nviolated. Our analysis identifies four critical issues plaguing current\napproaches: (1) pervasive data leakage from improper preprocessing sequences,\n(2) intentional vagueness in methodological reporting, (3) inadequate temporal\nvalidation for transaction data, and (4) metric manipulation through recall\noptimization at precision's expense. We present a case study showing how a\nminimal neural network architecture with data leakage outperforms many\nsophisticated methods reported in literature, achieving 99.9\\% recall despite\nfundamental evaluation flaws. These findings underscore that proper evaluation\nmethodology matters more than model complexity in fraud detection research. The\nstudy serves as a cautionary example of how methodological rigor must precede\narchitectural sophistication, with implications for improving research\npractices across machine learning applications.", "AI": {"tldr": "The paper highlights flaws in credit card fraud detection research, showing how improper evaluation methods can make simple models appear superior. It identifies four key issues and demonstrates their impact through a case study.", "motivation": "To expose and address the methodological shortcomings in credit card fraud detection research, emphasizing the importance of rigorous evaluation over model complexity.", "method": "The study uses deliberate experimentation with flawed evaluation protocols and a case study involving a minimal neural network with data leakage.", "result": "Simple models with improper evaluation can achieve misleadingly high performance (e.g., 99.9% recall), overshadowing sophisticated methods.", "conclusion": "Methodological rigor is more critical than model sophistication in fraud detection research, calling for improved practices in machine learning evaluations."}}
{"id": "2506.02718", "pdf": "https://arxiv.org/pdf/2506.02718", "abs": "https://arxiv.org/abs/2506.02718", "authors": ["Guanzhong Chen", "Shaoxiong Yang", "Chao Li", "Wei Liu", "Jian Luan", "Zenglin Xu"], "title": "Heterogeneous Group-Based Reinforcement Learning for LLM-based Multi-Agent Systems", "categories": ["cs.LG", "cs.AI", "I.2.7"], "comment": null, "summary": "Large Language Models (LLMs) have achieved remarkable success across diverse\nnatural language processing tasks, yet their deployment in real-world\napplications is hindered by fixed knowledge cutoffs and difficulties in\ngenerating controllable, accurate outputs in a single inference. Multi-agent\nsystems (MAS) built from specialized LLM agents offer a promising solution,\nenabling dynamic collaboration and iterative reasoning. However, optimizing\nthese systems remains a challenge, as conventional methods such as prompt\nengineering and supervised fine-tuning entail high engineering overhead and\nlimited adaptability. Reinforcement learning (RL), particularly multi-agent\nreinforcement learning (MARL), provides a scalable framework by refining agent\npolicies based on system-level feedback. Nevertheless, existing MARL\nalgorithms, such as Multi-Agent Proximal Policy Optimization (MAPPO), rely on\nCritic networks, which can cause training instability and increase\ncomputational burden. To address these limitations and target the prototypical\nMulti-Agent Search System (MASS), we propose Multi-Agent Heterogeneous Group\nPolicy Optimization (MHGPO), a novel Critic-free algorithm that guides policy\nupdates by estimating relative reward advantages across heterogeneous groups of\nrollouts. MHGPO eliminates the need for Critic networks, enhancing stability\nand reducing computational overhead. Additionally, we introduce three group\nrollout sampling strategies that trade off between efficiency and\neffectiveness. Experiments on a multi-agent LLM-based search system demonstrate\nthat MHGPO consistently outperforms MAPPO in both task performance and\ncomputational efficiency, without requiring warm-up, underscoring its potential\nfor stable and scalable optimization of complex LLM-based MAS.", "AI": {"tldr": "MHGPO, a Critic-free MARL algorithm, outperforms MAPPO in optimizing multi-agent LLM systems by enhancing stability and efficiency.", "motivation": "Addressing the limitations of fixed knowledge cutoffs and uncontrollable outputs in LLMs, and the inefficiencies of existing MARL methods like MAPPO.", "method": "Proposes MHGPO, a Critic-free algorithm using relative reward advantages and group rollout sampling strategies.", "result": "MHGPO outperforms MAPPO in task performance and computational efficiency without requiring warm-up.", "conclusion": "MHGPO offers a stable and scalable solution for optimizing complex LLM-based multi-agent systems."}}
{"id": "2506.02973", "pdf": "https://arxiv.org/pdf/2506.02973", "abs": "https://arxiv.org/abs/2506.02973", "authors": ["Dingwei Chen", "Ziqiang Liu", "Feiteng Fang", "Chak Tou Leong", "Shiwen Ni", "Ahmadreza Argha", "Hamid Alinejad-Rokny", "Min Yang", "Chengming Li"], "title": "Expanding before Inferring: Enhancing Factuality in Large Language Models through Premature Layers Interpolation", "categories": ["cs.CL"], "comment": null, "summary": "Large Language Models (LLMs) demonstrate remarkable capabilities in text\nunderstanding and generation. However, their tendency to produce factually\ninconsistent outputs, commonly referred to as ''hallucinations'', remains a\ncritical challenge. Existing approaches, such as retrieval-based and\ninference-time correction methods, primarily address this issue at the input or\noutput level, often overlooking the intrinsic information refinement process\nand the role of premature layers. Meanwhile, alignment- and fine-tuning-based\nmethods are resource-intensive. In this paper, we propose PLI (Premature Layers\nInterpolation), a novel, training-free, and plug-and-play intervention designed\nto enhance factuality. PLI mitigates hallucinations by inserting premature\nlayers formed through mathematical interpolation with adjacent layers. Inspired\nby stable diffusion and sampling steps, PLI extends the depth of information\nprocessing and transmission in LLMs, improving factual coherence. Experiments\non four publicly available datasets demonstrate that PLI effectively reduces\nhallucinations while outperforming existing baselines in most cases. Further\nanalysis suggests that the success of layer interpolation is closely linked to\nLLMs' internal mechanisms. To promote reproducibility, we will release our code\nand data upon acceptance.", "AI": {"tldr": "PLI (Premature Layers Interpolation) is a training-free method to reduce hallucinations in LLMs by interpolating premature layers, improving factual coherence without intensive resources.", "motivation": "Addressing LLMs' tendency for factually inconsistent outputs (hallucinations) without resource-heavy fine-tuning or alignment methods.", "method": "PLI inserts mathematically interpolated premature layers between adjacent layers to extend information processing depth.", "result": "PLI reduces hallucinations and outperforms baselines on four datasets, with success tied to LLMs' internal mechanisms.", "conclusion": "PLI offers an effective, resource-efficient solution for enhancing LLM factuality, with code and data to be released for reproducibility."}}
{"id": "2506.02738", "pdf": "https://arxiv.org/pdf/2506.02738", "abs": "https://arxiv.org/abs/2506.02738", "authors": ["Negin Baghbanzadeh", "Sajad Ashkezari", "Elham Dolatabadi", "Arash Afkanpour"], "title": "Open-PMC-18M: A High-Fidelity Large Scale Medical Dataset for Multimodal Representation Learning", "categories": ["cs.CV"], "comment": "15 pages", "summary": "Compound figures, which are multi-panel composites containing diverse\nsubfigures, are ubiquitous in biomedical literature, yet large-scale subfigure\nextraction remains largely unaddressed. Prior work on subfigure extraction has\nbeen limited in both dataset size and generalizability, leaving a critical open\nquestion: How does high-fidelity image-text alignment via large-scale subfigure\nextraction impact representation learning in vision-language models? We address\nthis gap by introducing a scalable subfigure extraction pipeline based on\ntransformer-based object detection, trained on a synthetic corpus of 500,000\ncompound figures, and achieving state-of-the-art performance on both ImageCLEF\n2016 and synthetic benchmarks. Using this pipeline, we release OPEN-PMC-18M, a\nlarge-scale high quality biomedical vision-language dataset comprising 18\nmillion clinically relevant subfigure-caption pairs spanning radiology,\nmicroscopy, and visible light photography. We train and evaluate\nvision-language models on our curated datasets and show improved performance\nacross retrieval, zero-shot classification, and robustness benchmarks,\noutperforming existing baselines. We release our dataset, models, and code to\nsupport reproducible benchmarks and further study into biomedical\nvision-language modeling and representation learning.", "AI": {"tldr": "The paper introduces a scalable pipeline for subfigure extraction from compound biomedical figures, releasing a large dataset (OPEN-PMC-18M) and showing improved vision-language model performance.", "motivation": "Addressing the lack of large-scale subfigure extraction in biomedical literature and its impact on vision-language models.", "method": "A transformer-based object detection pipeline trained on 500,000 synthetic compound figures, applied to create OPEN-PMC-18M.", "result": "State-of-the-art performance on benchmarks, improved model performance in retrieval, zero-shot classification, and robustness.", "conclusion": "The work advances biomedical vision-language modeling, with released resources for reproducibility and further research."}}
{"id": "2506.02712", "pdf": "https://arxiv.org/pdf/2506.02712", "abs": "https://arxiv.org/abs/2506.02712", "authors": ["Jayadev Naram", "Fredrik Hellstr\u00f6m", "Ziming Wang", "Rebecka J\u00f6rnsten", "Giuseppe Durisi"], "title": "Theoretical Performance Guarantees for Partial Domain Adaptation via Partial Optimal Transport", "categories": ["cs.LG", "stat.ML"], "comment": "ICML 2025", "summary": "In many scenarios of practical interest, labeled data from a target\ndistribution are scarce while labeled data from a related source distribution\nare abundant. One particular setting of interest arises when the target label\nspace is a subset of the source label space, leading to the framework of\npartial domain adaptation (PDA). Typical approaches to PDA involve minimizing a\ndomain alignment term and a weighted empirical loss on the source data, with\nthe aim of transferring knowledge between domains. However, a theoretical basis\nfor this procedure is lacking, and in particular, most existing weighting\nschemes are heuristic. In this work, we derive generalization bounds for the\nPDA problem based on partial optimal transport. These bounds corroborate the\nuse of the partial Wasserstein distance as a domain alignment term, and lead to\ntheoretically motivated explicit expressions for the empirical source loss\nweights. Inspired by these bounds, we devise a practical algorithm for PDA,\ntermed WARMPOT. Through extensive numerical experiments, we show that WARMPOT\nis competitive with recent approaches, and that our proposed weights improve on\nexisting schemes.", "AI": {"tldr": "The paper addresses partial domain adaptation (PDA) by proposing a theoretically grounded method (WARMPOT) using partial optimal transport, improving on heuristic weighting schemes.", "motivation": "Labeled data in target domains are scarce, while related source domains have abundant data. Existing PDA methods lack theoretical justification.", "method": "Derives generalization bounds for PDA using partial optimal transport, leading to the WARMPOT algorithm with theoretically motivated weights.", "result": "WARMPOT is competitive with recent approaches, and the proposed weights outperform existing heuristic schemes.", "conclusion": "The work provides a theoretical foundation for PDA and demonstrates practical improvements with WARMPOT."}}
{"id": "2506.02744", "pdf": "https://arxiv.org/pdf/2506.02744", "abs": "https://arxiv.org/abs/2506.02744", "authors": ["Junyuan Liu", "Xinglei Wang", "Tao Cheng"], "title": "Enriching Location Representation with Detailed Semantic Information", "categories": ["cs.CE", "cs.AI"], "comment": null, "summary": "Spatial representations that capture both structural and semantic\ncharacteristics of urban environments are essential for urban modeling.\nTraditional spatial embeddings often prioritize spatial proximity while\nunderutilizing fine-grained contextual information from places. To address this\nlimitation, we introduce CaLLiPer+, an extension of the CaLLiPer model that\nsystematically integrates Point-of-Interest (POI) names alongside categorical\nlabels within a multimodal contrastive learning framework. We evaluate its\neffectiveness on two downstream tasks, land use classification and\nsocioeconomic status distribution mapping, demonstrating consistent performance\ngains of 4% to 11% over baseline methods. Additionally, we show that\nincorporating POI names enhances location retrieval, enabling models to capture\ncomplex urban concepts with greater precision. Ablation studies further reveal\nthe complementary role of POI names and the advantages of leveraging pretrained\ntext encoders for spatial representations. Overall, our findings highlight the\npotential of integrating fine-grained semantic attributes and multimodal\nlearning techniques to advance the development of urban foundation models.", "AI": {"tldr": "CaLLiPer+ integrates POI names and categorical labels in a multimodal contrastive learning framework, improving urban spatial representations and outperforming baselines by 4-11%.", "motivation": "Traditional spatial embeddings underutilize fine-grained contextual information, limiting their effectiveness in urban modeling.", "method": "Extends CaLLiPer by integrating POI names and categorical labels using multimodal contrastive learning.", "result": "Achieves 4-11% performance gains in land use classification and socioeconomic status mapping, with improved location retrieval.", "conclusion": "Integrating fine-grained semantics and multimodal learning enhances urban foundation models."}}
{"id": "2506.02987", "pdf": "https://arxiv.org/pdf/2506.02987", "abs": "https://arxiv.org/abs/2506.02987", "authors": ["Richard Armitage"], "title": "Performance of leading large language models in May 2025 in Membership of the Royal College of General Practitioners-style examination questions: a cross-sectional analysis", "categories": ["cs.CL", "cs.AI", "cs.HC"], "comment": "12 pages, 1 Table", "summary": "Background: Large language models (LLMs) have demonstrated substantial\npotential to support clinical practice. Other than Chat GPT4 and its\npredecessors, few LLMs, especially those of the leading and more powerful\nreasoning model class, have been subjected to medical specialty examination\nquestions, including in the domain of primary care. This paper aimed to test\nthe capabilities of leading LLMs as of May 2025 (o3, Claude Opus 4, Grok3, and\nGemini 2.5 Pro) in primary care education, specifically in answering Member of\nthe Royal College of General Practitioners (MRCGP) style examination questions.\n  Methods: o3, Claude Opus 4, Grok3, and Gemini 2.5 Pro were tasked to answer\n100 randomly chosen multiple choice questions from the Royal College of General\nPractitioners GP SelfTest on 25 May 2025. Questions included textual\ninformation, laboratory results, and clinical images. Each model was prompted\nto answer as a GP in the UK and was provided with full question information.\nEach question was attempted once by each model. Responses were scored against\ncorrect answers provided by GP SelfTest.\n  Results: The total score of o3, Claude Opus 4, Grok3, and Gemini 2.5 Pro was\n99.0%, 95.0%, 95.0%, and 95.0%, respectively. The average peer score for the\nsame questions was 73.0%.\n  Discussion: All models performed remarkably well, and all substantially\nexceeded the average performance of GPs and GP registrars who had answered the\nsame questions. o3 demonstrated the best performance, while the performances of\nthe other leading models were comparable with each other and were not\nsubstantially lower than that of o3. These findings strengthen the case for\nLLMs, particularly reasoning models, to support the delivery of primary care,\nespecially those that have been specifically trained on primary care clinical\ndata.", "AI": {"tldr": "Leading LLMs (o3, Claude Opus 4, Grok3, Gemini 2.5 Pro) outperformed human GPs in answering MRCGP-style primary care exam questions, with o3 scoring highest at 99%.", "motivation": "To evaluate the capabilities of advanced LLMs in primary care education by testing their performance on MRCGP-style exam questions.", "method": "Four LLMs answered 100 MRCGP-style multiple-choice questions once each, with responses scored against correct answers.", "result": "o3 scored 99%, while others scored 95%, all surpassing the human GP average of 73%.", "conclusion": "LLMs, especially reasoning models, show strong potential to support primary care, particularly when trained on clinical data."}}
{"id": "2506.02741", "pdf": "https://arxiv.org/pdf/2506.02741", "abs": "https://arxiv.org/abs/2506.02741", "authors": ["Pengchong Hu", "Zhizhong Han"], "title": "VTGaussian-SLAM: RGBD SLAM for Large Scale Scenes with Splatting View-Tied 3D Gaussians", "categories": ["cs.CV"], "comment": "ICML 2025", "summary": "Jointly estimating camera poses and mapping scenes from RGBD images is a\nfundamental task in simultaneous localization and mapping (SLAM).\nState-of-the-art methods employ 3D Gaussians to represent a scene, and render\nthese Gaussians through splatting for higher efficiency and better rendering.\nHowever, these methods cannot scale up to extremely large scenes, due to the\ninefficient tracking and mapping strategies that need to optimize all 3D\nGaussians in the limited GPU memories throughout the training to maintain the\ngeometry and color consistency to previous RGBD observations. To resolve this\nissue, we propose novel tracking and mapping strategies to work with a novel 3D\nrepresentation, dubbed view-tied 3D Gaussians, for RGBD SLAM systems. View-tied\n3D Gaussians is a kind of simplified Gaussians, which is tied to depth pixels,\nwithout needing to learn locations, rotations, and multi-dimensional variances.\nTying Gaussians to views not only significantly saves storage but also allows\nus to employ many more Gaussians to represent local details in the limited GPU\nmemory. Moreover, our strategies remove the need of maintaining all Gaussians\nlearnable throughout the training, while improving rendering quality, and\ntracking accuracy. We justify the effectiveness of these designs, and report\nbetter performance over the latest methods on the widely used benchmarks in\nterms of rendering and tracking accuracy and scalability. Please see our\nproject page for code and videos at\nhttps://machineperceptionlab.github.io/VTGaussian-SLAM-Project .", "AI": {"tldr": "The paper introduces view-tied 3D Gaussians for RGBD SLAM, improving efficiency and scalability by simplifying Gaussian representation and optimizing tracking/mapping strategies.", "motivation": "Current methods using 3D Gaussians for SLAM struggle with scalability in large scenes due to GPU memory constraints and inefficient optimization.", "method": "Proposes view-tied 3D Gaussians, simplified representations tied to depth pixels, and novel tracking/mapping strategies to reduce memory usage and improve rendering.", "result": "Achieves better rendering and tracking accuracy, scalability, and efficiency compared to state-of-the-art methods on benchmarks.", "conclusion": "The approach successfully addresses scalability and efficiency issues in RGBD SLAM, demonstrating superior performance and practical viability."}}
{"id": "2506.02724", "pdf": "https://arxiv.org/pdf/2506.02724", "abs": "https://arxiv.org/abs/2506.02724", "authors": ["Andrey Veprikov", "Vladimir Solodkin", "Alexander Zyl", "Andrey Savchenko", "Aleksandr Beznosikov"], "title": "WeightLoRA: Keep Only Necessary Adapters", "categories": ["cs.LG", "math.OC"], "comment": "13 pages, 9 tables", "summary": "The widespread utilization of language models in modern applications is\ninconceivable without Parameter-Efficient Fine-Tuning techniques, such as\nlow-rank adaptation ($\\texttt{LoRA}$), which adds trainable adapters to\nselected layers. Although $\\texttt{LoRA}$ may obtain accurate solutions, it\nrequires significant memory to train large models and intuition on which layers\nto add adapters. In this paper, we propose a novel method,\n$\\texttt{WeightLoRA}$, which overcomes this issue by adaptive selection of the\nmost critical $\\texttt{LoRA}$ heads throughout the optimization process. As a\nresult, we can significantly reduce the number of trainable parameters while\nmaintaining the capability to obtain consistent or even superior metric values.\nWe conduct experiments for a series of competitive benchmarks and DeBERTa,\nBART, and Llama models, comparing our method with different adaptive\napproaches. The experimental results demonstrate the efficacy of\n$\\texttt{WeightLoRA}$ and the superior performance of $\\texttt{WeightLoRA+}$ in\nalmost all cases.", "AI": {"tldr": "WeightLoRA is a novel method for adaptive selection of critical LoRA heads, reducing trainable parameters while maintaining or improving performance.", "motivation": "Overcome the memory and intuition challenges of LoRA by adaptively selecting critical LoRA heads during optimization.", "method": "Proposes WeightLoRA, which dynamically selects the most critical LoRA heads, and WeightLoRA+, an enhanced version.", "result": "Demonstrates superior performance in benchmarks with DeBERTa, BART, and Llama models compared to other adaptive approaches.", "conclusion": "WeightLoRA and WeightLoRA+ effectively reduce trainable parameters without compromising performance, offering a practical solution for large models."}}
{"id": "2506.02746", "pdf": "https://arxiv.org/pdf/2506.02746", "abs": "https://arxiv.org/abs/2506.02746", "authors": ["Lin Xie", "Hanyi Li"], "title": "Solving the Pod Repositioning Problem with Deep Reinforced Adaptive Large Neighborhood Search", "categories": ["cs.RO", "cs.AI", "math.OC"], "comment": "14 pages, 2 figures, conference", "summary": "The Pod Repositioning Problem (PRP) in Robotic Mobile Fulfillment Systems\n(RMFS) involves selecting optimal storage locations for pods returning from\npick stations. This work presents an improved solution method that integrates\nAdaptive Large Neighborhood Search (ALNS) with Deep Reinforcement Learning\n(DRL). A DRL agent dynamically selects destroy and repair operators and adjusts\nkey parameters such as destruction degree and acceptance thresholds during the\nsearch. Specialized heuristics for both operators are designed to reflect\nPRP-specific characteristics, including pod usage frequency and movement costs.\nComputational results show that this DRL-guided ALNS outperforms traditional\napproaches such as cheapest-place, fixed-place, binary integer programming, and\nstatic heuristics. The method demonstrates strong solution quality and\nillustrating the benefit of learning-driven control within combinatorial\noptimization for warehouse systems.", "AI": {"tldr": "An improved method combining ALNS and DRL for solving the Pod Repositioning Problem in RMFS, outperforming traditional approaches.", "motivation": "Optimizing pod storage locations in RMFS to enhance efficiency by leveraging learning-driven control.", "method": "Integrates ALNS with DRL, using dynamic operator selection and parameter adjustment, plus PRP-specific heuristics.", "result": "Outperforms traditional methods like cheapest-place and binary integer programming in solution quality.", "conclusion": "Demonstrates the effectiveness of learning-driven control in combinatorial optimization for warehouse systems."}}
{"id": "2506.02995", "pdf": "https://arxiv.org/pdf/2506.02995", "abs": "https://arxiv.org/abs/2506.02995", "authors": ["Iuliia Zaitova", "Badr M. Abdullah", "Wei Xue", "Dietrich Klakow", "Bernd M\u00f6bius", "Tania Avgustinova"], "title": "It's Not a Walk in the Park! Challenges of Idiom Translation in Speech-to-text Systems", "categories": ["cs.CL"], "comment": "13 pages, 3 figures, ACL 2025", "summary": "Idioms are defined as a group of words with a figurative meaning not\ndeducible from their individual components. Although modern machine translation\nsystems have made remarkable progress, translating idioms remains a major\nchallenge, especially for speech-to-text systems, where research on this topic\nis notably sparse. In this paper, we systematically evaluate idiom translation\nas compared to conventional news translation in both text-to-text machine\ntranslation (MT) and speech-to-text translation (SLT) systems across two\nlanguage pairs (German to English, Russian to English). We compare\nstate-of-the-art end-to-end SLT systems (SeamlessM4T SLT-to-text, Whisper Large\nv3) with MT systems (SeamlessM4T SLT-to-text, No Language Left Behind), Large\nLanguage Models (DeepSeek, LLaMA) and cascaded alternatives. Our results reveal\nthat SLT systems experience a pronounced performance drop on idiomatic data,\noften reverting to literal translations even in higher layers, whereas MT\nsystems and Large Language Models demonstrate better handling of idioms. These\nfindings underscore the need for idiom-specific strategies and improved\ninternal representations in SLT architectures.", "AI": {"tldr": "The paper evaluates idiom translation in text-to-text and speech-to-text systems, revealing SLT systems struggle more with idioms compared to MT systems and LLMs.", "motivation": "Idiom translation is a challenge for machine translation, especially in speech-to-text systems, where research is limited.", "method": "Systematic evaluation of idiom translation in MT and SLT systems across German-English and Russian-English, comparing state-of-the-art models.", "result": "SLT systems show significant performance drops on idioms, often producing literal translations, while MT systems and LLMs handle idioms better.", "conclusion": "Idiom-specific strategies and improved representations are needed in SLT architectures to address this gap."}}
{"id": "2506.02751", "pdf": "https://arxiv.org/pdf/2506.02751", "abs": "https://arxiv.org/abs/2506.02751", "authors": ["Chuanyu Fu", "Yuqi Zhang", "Kunbin Yao", "Guanying Chen", "Yuan Xiong", "Chuan Huang", "Shuguang Cui", "Xiaochun Cao"], "title": "RobustSplat: Decoupling Densification and Dynamics for Transient-Free 3DGS", "categories": ["cs.CV"], "comment": "Project page: https://fcyycf.github.io/RobustSplat/", "summary": "3D Gaussian Splatting (3DGS) has gained significant attention for its\nreal-time, photo-realistic rendering in novel-view synthesis and 3D modeling.\nHowever, existing methods struggle with accurately modeling scenes affected by\ntransient objects, leading to artifacts in the rendered images. We identify\nthat the Gaussian densification process, while enhancing scene detail capture,\nunintentionally contributes to these artifacts by growing additional Gaussians\nthat model transient disturbances. To address this, we propose RobustSplat, a\nrobust solution based on two critical designs. First, we introduce a delayed\nGaussian growth strategy that prioritizes optimizing static scene structure\nbefore allowing Gaussian splitting/cloning, mitigating overfitting to transient\nobjects in early optimization. Second, we design a scale-cascaded mask\nbootstrapping approach that first leverages lower-resolution feature similarity\nsupervision for reliable initial transient mask estimation, taking advantage of\nits stronger semantic consistency and robustness to noise, and then progresses\nto high-resolution supervision to achieve more precise mask prediction.\nExtensive experiments on multiple challenging datasets show that our method\noutperforms existing methods, clearly demonstrating the robustness and\neffectiveness of our method. Our project page is\nhttps://fcyycf.github.io/RobustSplat/.", "AI": {"tldr": "RobustSplat improves 3D Gaussian Splatting by addressing transient object artifacts with delayed Gaussian growth and scale-cascaded mask bootstrapping.", "motivation": "Existing 3DGS methods struggle with transient objects, causing rendering artifacts.", "method": "Proposes delayed Gaussian growth and scale-cascaded mask bootstrapping to mitigate transient object interference.", "result": "Outperforms existing methods on challenging datasets, showing robustness and effectiveness.", "conclusion": "RobustSplat offers a reliable solution for transient object handling in 3DGS."}}
{"id": "2506.02749", "pdf": "https://arxiv.org/pdf/2506.02749", "abs": "https://arxiv.org/abs/2506.02749", "authors": ["Changyi Xiao", "Yixin Cao"], "title": "Knowledge Graph Completion by Intermediate Variables Regularization", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Knowledge graph completion (KGC) can be framed as a 3-order binary tensor\ncompletion task. Tensor decomposition-based (TDB) models have demonstrated\nstrong performance in KGC. In this paper, we provide a summary of existing TDB\nmodels and derive a general form for them, serving as a foundation for further\nexploration of TDB models. Despite the expressiveness of TDB models, they are\nprone to overfitting. Existing regularization methods merely minimize the norms\nof embeddings to regularize the model, leading to suboptimal performance.\nTherefore, we propose a novel regularization method for TDB models that\naddresses this limitation. The regularization is applicable to most TDB models\nand ensures tractable computation. Our method minimizes the norms of\nintermediate variables involved in the different ways of computing the\npredicted tensor. To support our regularization method, we provide a\ntheoretical analysis that proves its effect in promoting low trace norm of the\npredicted tensor to reduce overfitting. Finally, we conduct experiments to\nverify the effectiveness of our regularization technique as well as the\nreliability of our theoretical analysis. The code is available at\nhttps://github.com/changyi7231/IVR.", "AI": {"tldr": "A novel regularization method for tensor decomposition-based (TDB) models in knowledge graph completion (KGC) is proposed to reduce overfitting by minimizing intermediate variable norms, supported by theoretical analysis and experiments.", "motivation": "Existing TDB models for KGC are prone to overfitting, and current regularization methods are suboptimal.", "method": "Proposes a regularization technique minimizing norms of intermediate variables in TDB models, ensuring tractable computation.", "result": "The method effectively reduces overfitting and is supported by theoretical and experimental validation.", "conclusion": "The proposed regularization improves TDB model performance in KGC, with code publicly available."}}
{"id": "2506.02757", "pdf": "https://arxiv.org/pdf/2506.02757", "abs": "https://arxiv.org/abs/2506.02757", "authors": ["Ruiying Lu", "Jinhan Liu", "Chuan Du", "Dandan Guo"], "title": "Investigating Mask-aware Prototype Learning for Tabular Anomaly Detection", "categories": ["cs.LG", "cs.AI"], "comment": "12 pages, 11 figures", "summary": "Tabular anomaly detection, which aims at identifying deviant samples, has\nbeen crucial in a variety of real-world applications, such as medical disease\nidentification, financial fraud detection, intrusion monitoring, etc. Although\nrecent deep learning-based methods have achieved competitive performances,\nthese methods suffer from representation entanglement and the lack of global\ncorrelation modeling, which hinders anomaly detection performance. To tackle\nthe problem, we incorporate mask modeling and prototype learning into tabular\nanomaly detection. The core idea is to design learnable masks by disentangled\nrepresentation learning within a projection space and extracting normal\ndependencies as explicit global prototypes. Specifically, the overall model\ninvolves two parts: (i) During encoding, we perform mask modeling in both the\ndata space and projection space with orthogonal basis vectors for learning\nshared disentangled normal patterns; (ii) During decoding, we decode multiple\nmasked representations in parallel for reconstruction and learn association\nprototypes to extract normal characteristic correlations. Our proposal derives\nfrom a distribution-matching perspective, where both projection space learning\nand association prototype learning are formulated as optimal transport\nproblems, and the calibration distances are utilized to refine the anomaly\nscores. Quantitative and qualitative experiments on 20 tabular benchmarks\ndemonstrate the effectiveness and interpretability of our model.", "AI": {"tldr": "The paper introduces a method for tabular anomaly detection using mask modeling and prototype learning to address representation entanglement and lack of global correlation modeling.", "motivation": "Current deep learning-based methods for tabular anomaly detection suffer from representation entanglement and insufficient global correlation modeling, limiting performance.", "method": "The proposed method combines mask modeling and prototype learning, using disentangled representation learning and global prototypes to model normal dependencies. It involves encoding with mask modeling in data and projection spaces and decoding with parallel masked representation reconstruction and association prototype learning.", "result": "Experiments on 20 tabular benchmarks show the model's effectiveness and interpretability.", "conclusion": "The method improves tabular anomaly detection by addressing key limitations of existing approaches, demonstrating strong performance and interpretability."}}
{"id": "2506.02998", "pdf": "https://arxiv.org/pdf/2506.02998", "abs": "https://arxiv.org/abs/2506.02998", "authors": ["\u0110or\u0111e Klisura", "Astrid R Bernaga Torres", "Anna Karen G\u00e1rate-Escamilla", "Rajesh Roshan Biswal", "Ke Yang", "Hilal Pataci", "Anthony Rios"], "title": "A Multi-Agent Framework for Mitigating Dialect Biases in Privacy Policy Question-Answering Systems", "categories": ["cs.CL"], "comment": "Accepted to ACL 2025 Main Conference", "summary": "Privacy policies inform users about data collection and usage, yet their\ncomplexity limits accessibility for diverse populations. Existing Privacy\nPolicy Question Answering (QA) systems exhibit performance disparities across\nEnglish dialects, disadvantaging speakers of non-standard varieties. We propose\na novel multi-agent framework inspired by human-centered design principles to\nmitigate dialectal biases. Our approach integrates a Dialect Agent, which\ntranslates queries into Standard American English (SAE) while preserving\ndialectal intent, and a Privacy Policy Agent, which refines predictions using\ndomain expertise. Unlike prior approaches, our method does not require\nretraining or dialect-specific fine-tuning, making it broadly applicable across\nmodels and domains. Evaluated on PrivacyQA and PolicyQA, our framework improves\nGPT-4o-mini's zero-shot accuracy from 0.394 to 0.601 on PrivacyQA and from\n0.352 to 0.464 on PolicyQA, surpassing or matching few-shot baselines without\nadditional training data. These results highlight the effectiveness of\nstructured agent collaboration in mitigating dialect biases and underscore the\nimportance of designing NLP systems that account for linguistic diversity to\nensure equitable access to privacy information.", "AI": {"tldr": "A multi-agent framework reduces dialectal bias in Privacy Policy QA systems, improving accuracy without retraining.", "motivation": "Privacy policies are complex and existing QA systems perform poorly for non-standard English dialects, limiting accessibility.", "method": "Proposes a multi-agent framework with a Dialect Agent (translates queries to Standard American English) and a Privacy Policy Agent (refines predictions).", "result": "Improves GPT-4o-mini's zero-shot accuracy from 0.394 to 0.601 on PrivacyQA and from 0.352 to 0.464 on PolicyQA.", "conclusion": "Structured agent collaboration effectively mitigates dialect biases, emphasizing the need for NLP systems to address linguistic diversity for equitable access."}}
{"id": "2506.02764", "pdf": "https://arxiv.org/pdf/2506.02764", "abs": "https://arxiv.org/abs/2506.02764", "authors": ["Fatma Youssef Mohammed", "Kostas Alexis"], "title": "Unified Attention Modeling for Efficient Free-Viewing and Visual Search via Shared Representations", "categories": ["cs.CV", "cs.AI"], "comment": "Accepted to the 2025 IEEE International Conference on Development and\n  Learning (ICDL)", "summary": "Computational human attention modeling in free-viewing and task-specific\nsettings is often studied separately, with limited exploration of whether a\ncommon representation exists between them. This work investigates this question\nand proposes a neural network architecture that builds upon the Human Attention\ntransformer (HAT) to test the hypothesis. Our results demonstrate that\nfree-viewing and visual search can efficiently share a common representation,\nallowing a model trained in free-viewing attention to transfer its knowledge to\ntask-driven visual search with a performance drop of only 3.86% in the\npredicted fixation scanpaths, measured by the semantic sequence score (SemSS)\nmetric which reflects the similarity between predicted and human scanpaths.\nThis transfer reduces computational costs by 92.29% in terms of GFLOPs and\n31.23% in terms of trainable parameters.", "AI": {"tldr": "A neural network architecture based on HAT shows free-viewing and visual search share a common representation, enabling efficient knowledge transfer with minimal performance drop and significant computational savings.", "motivation": "To explore whether free-viewing and task-specific visual attention share a common representation, bridging a gap in current research.", "method": "Proposes a neural network architecture extending the Human Attention Transformer (HAT) to test the hypothesis of shared representation.", "result": "Demonstrates efficient knowledge transfer between free-viewing and visual search, with only a 3.86% performance drop in predicted scanpaths and substantial computational savings (92.29% GFLOPs, 31.23% parameters).", "conclusion": "A common representation exists between free-viewing and visual search, enabling efficient transfer learning with minimal performance loss and reduced computational costs."}}
{"id": "2506.02767", "pdf": "https://arxiv.org/pdf/2506.02767", "abs": "https://arxiv.org/abs/2506.02767", "authors": ["Marco Cal\u00ec", "Giulio Giacomuzzo", "Ruggero Carli", "Alberto Dalla Libera"], "title": "Accelerating Model-Based Reinforcement Learning using Non-Linear Trajectory Optimization", "categories": ["cs.LG", "cs.RO"], "comment": null, "summary": "This paper addresses the slow policy optimization convergence of Monte Carlo\nProbabilistic Inference for Learning Control (MC-PILCO), a state-of-the-art\nmodel-based reinforcement learning (MBRL) algorithm, by integrating it with\niterative Linear Quadratic Regulator (iLQR), a fast trajectory optimization\nmethod suitable for nonlinear systems. The proposed method, Exploration-Boosted\nMC-PILCO (EB-MC-PILCO), leverages iLQR to generate informative, exploratory\ntrajectories and initialize the policy, significantly reducing the number of\nrequired optimization steps. Experiments on the cart-pole task demonstrate that\nEB-MC-PILCO accelerates convergence compared to standard MC-PILCO, achieving up\nto $\\bm{45.9\\%}$ reduction in execution time when both methods solve the task\nin four trials. EB-MC-PILCO also maintains a $\\bm{100\\%}$ success rate across\ntrials while solving the task faster, even in cases where MC-PILCO converges in\nfewer iterations.", "AI": {"tldr": "EB-MC-PILCO integrates iLQR with MC-PILCO to speed up policy optimization, reducing execution time by 45.9% while maintaining a 100% success rate.", "motivation": "To address the slow convergence of MC-PILCO in model-based reinforcement learning.", "method": "Combines MC-PILCO with iLQR to generate exploratory trajectories and initialize the policy.", "result": "Achieves faster convergence (45.9% reduction in time) and 100% success rate on the cart-pole task.", "conclusion": "EB-MC-PILCO is a more efficient and reliable alternative to standard MC-PILCO."}}
{"id": "2506.02785", "pdf": "https://arxiv.org/pdf/2506.02785", "abs": "https://arxiv.org/abs/2506.02785", "authors": ["Charalampos Kalalas", "Pavol Mulinka", "Guillermo Candela Belmonte", "Miguel Fornell", "Michail Dalgitsis", "Francisco Paredes Vera", "Javier Santaella S\u00e1nchez", "Carmen Vicente Villares", "Roshan Sedar", "Eftychia Datsika", "Angelos Antonopoulos", "Antonio Fern\u00e1ndez Ojea", "Miquel Payaro"], "title": "AI-Driven Vehicle Condition Monitoring with Cell-Aware Edge Service Migration", "categories": ["cs.NI", "cs.AI"], "comment": "6 pages, 8 figures", "summary": "Artificial intelligence (AI) has been increasingly applied to the condition\nmonitoring of vehicular equipment, aiming to enhance maintenance strategies,\nreduce costs, and improve safety. Leveraging the edge computing paradigm,\nAI-based condition monitoring systems process vast streams of vehicular data to\ndetect anomalies and optimize operational performance. In this work, we\nintroduce a novel vehicle condition monitoring service that enables real-time\ndiagnostics of a diverse set of anomalies while remaining practical for\ndeployment in real-world edge environments. To address mobility challenges, we\npropose a closed-loop service orchestration framework where service migration\nacross edge nodes is dynamically triggered by network-related metrics. Our\napproach has been implemented and tested in a real-world race circuit\nenvironment equipped with 5G network capabilities under diverse operational\nconditions. Experimental results demonstrate the effectiveness of our framework\nin ensuring low-latency AI inference and adaptive service placement,\nhighlighting its potential for intelligent transportation and mobility\napplications.", "AI": {"tldr": "A novel AI-based vehicle condition monitoring system using edge computing for real-time anomaly detection and adaptive service migration in dynamic environments.", "motivation": "To enhance maintenance strategies, reduce costs, and improve safety in vehicular equipment through AI-driven condition monitoring.", "method": "Proposes a closed-loop service orchestration framework for dynamic service migration across edge nodes, tested in a 5G-equipped race circuit.", "result": "Demonstrates low-latency AI inference and adaptive service placement, proving effectiveness in real-world conditions.", "conclusion": "The framework shows promise for intelligent transportation and mobility applications."}}
{"id": "2506.03009", "pdf": "https://arxiv.org/pdf/2506.03009", "abs": "https://arxiv.org/abs/2506.03009", "authors": ["Florian Ludwig", "Torsten Zesch", "Frederike Zufall"], "title": "Conditioning Large Language Models on Legal Systems? Detecting Punishable Hate Speech", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "The assessment of legal problems requires the consideration of a specific\nlegal system and its levels of abstraction, from constitutional law to\nstatutory law to case law. The extent to which Large Language Models (LLMs)\ninternalize such legal systems is unknown. In this paper, we propose and\ninvestigate different approaches to condition LLMs at different levels of\nabstraction in legal systems. This paper examines different approaches to\nconditioning LLMs at multiple levels of abstraction in legal systems to detect\npotentially punishable hate speech. We focus on the task of classifying whether\na specific social media posts falls under the criminal offense of incitement to\nhatred as prescribed by the German Criminal Code. The results show that there\nis still a significant performance gap between models and legal experts in the\nlegal assessment of hate speech, regardless of the level of abstraction with\nwhich the models were conditioned. Our analysis revealed, that models\nconditioned on abstract legal knowledge lacked deep task understanding, often\ncontradicting themselves and hallucinating answers, while models using concrete\nlegal knowledge performed reasonably well in identifying relevant target\ngroups, but struggled with classifying target conducts.", "AI": {"tldr": "The paper explores conditioning LLMs at various legal abstraction levels to assess hate speech under German law, finding gaps between model performance and legal expertise.", "motivation": "To understand how well LLMs internalize legal systems and assess hate speech, focusing on German criminal law.", "method": "Proposes and tests approaches to condition LLMs at different legal abstraction levels for hate speech classification.", "result": "Models conditioned on abstract legal knowledge performed poorly, while those using concrete knowledge did better but still struggled with classifying target conducts.", "conclusion": "LLMs lag behind legal experts in hate speech assessment, with performance varying by the abstraction level of legal conditioning."}}
{"id": "2506.02765", "pdf": "https://arxiv.org/pdf/2506.02765", "abs": "https://arxiv.org/abs/2506.02765", "authors": ["Chunwei Tian", "Kai Liu", "Bob Zhang", "Zhixiang Huang", "Chia-Wen Lin", "David Zhang"], "title": "A Dynamic Transformer Network for Vehicle Detection", "categories": ["cs.CV"], "comment": "8 pages, 5 figures. This paper has been accepted for publication in\n  IEEE Transactions on Consumer Electronics", "summary": "Stable consumer electronic systems can assist traffic better. Good traffic\nconsumer electronic systems require collaborative work between traffic\nalgorithms and hardware. However, performance of popular traffic algorithms\ncontaining vehicle detection methods based on deep networks via learning data\nrelation rather than learning differences in different lighting and occlusions\nis limited. In this paper, we present a dynamic Transformer network for vehicle\ndetection (DTNet). DTNet utilizes a dynamic convolution to guide a deep network\nto dynamically generate weights to enhance adaptability of an obtained\ndetector. Taking into relations of different information account, a mixed\nattention mechanism based channel attention and Transformer is exploited to\nstrengthen relations of channels and pixels to extract more salient information\nfor vehicle detection. To overcome the drawback of difference in an image\naccount, a translation-variant convolution relies on spatial location\ninformation to refine obtained structural information for vehicle detection.\nExperimental results illustrate that our DTNet is competitive for vehicle\ndetection. Code of the proposed DTNet can be obtained at\nhttps://github.com/hellloxiaotian/DTNet.", "AI": {"tldr": "DTNet, a dynamic Transformer network, improves vehicle detection by dynamically generating weights and using mixed attention mechanisms to handle lighting and occlusion challenges.", "motivation": "Existing traffic algorithms struggle with lighting and occlusion variations. DTNet aims to enhance adaptability and accuracy in vehicle detection.", "method": "DTNet combines dynamic convolution, mixed attention (channel attention and Transformer), and translation-variant convolution to refine structural information.", "result": "DTNet demonstrates competitive performance in vehicle detection.", "conclusion": "DTNet effectively addresses limitations in current methods, offering a robust solution for vehicle detection."}}
{"id": "2506.02811", "pdf": "https://arxiv.org/pdf/2506.02811", "abs": "https://arxiv.org/abs/2506.02811", "authors": ["Ant\u00f3nio Pedro Pinheiro", "Rita P. Ribeiro"], "title": "CART-based Synthetic Tabular Data Generation for Imbalanced Regression", "categories": ["cs.LG"], "comment": "15 pages, 2 figures, 5 tables, 1 algorithm", "summary": "Handling imbalanced target distributions in regression tasks remains a\nsignificant challenge in tabular data settings where underrepresented regions\ncan hinder model performance. Among data-level solutions, some proposals, such\nas random sampling and SMOTE-based approaches, propose adapting classification\ntechniques to regression tasks. However, these methods typically rely on crisp,\nartificial thresholds over the target variable, a limitation inherited from\nclassification settings that can introduce arbitrariness, often leading to\nnon-intuitive and potentially misleading problem formulations. While recent\ngenerative models, such as GANs and VAEs, provide flexible sample synthesis,\nthey come with high computational costs and limited interpretability. In this\nstudy, we propose adapting an existing CART-based synthetic data generation\nmethod, tailoring it for imbalanced regression. The new method integrates\nrelevance and density-based mechanisms to guide sampling in sparse regions of\nthe target space and employs a threshold-free, feature-driven generation\nprocess. Our experimental study focuses on the prediction of extreme target\nvalues across benchmark datasets. The results indicate that the proposed method\nis competitive with other resampling and generative strategies in terms of\nperformance, while offering faster execution and greater transparency. These\nresults highlight the method's potential as a transparent, scalable data-level\nstrategy for improving regression models in imbalanced domains.", "AI": {"tldr": "Proposes a CART-based synthetic data generation method for imbalanced regression, offering transparency and scalability.", "motivation": "Addressing the challenge of imbalanced target distributions in regression tasks, especially in tabular data, where underrepresented regions hinder model performance.", "method": "Adapts a CART-based synthetic data generation method, integrating relevance and density-based mechanisms for threshold-free, feature-driven sampling in sparse target regions.", "result": "Competitive performance with other resampling and generative methods, faster execution, and greater transparency.", "conclusion": "The method is a promising, transparent, and scalable data-level strategy for improving regression models in imbalanced domains."}}
{"id": "2506.02787", "pdf": "https://arxiv.org/pdf/2506.02787", "abs": "https://arxiv.org/abs/2506.02787", "authors": ["Ruilong Wu", "Xinjiao Li", "Yisu Wang", "Xinyu Chen", "Dirk Kutscher"], "title": "Rethinking Dynamic Networks and Heterogeneous Computing with Automatic Parallelization", "categories": ["cs.DC", "cs.AI"], "comment": null, "summary": "Hybrid parallelism techniques are essential for efficiently training large\nlanguage models (LLMs). Nevertheless, current automatic parallel planning\nframeworks often overlook the simultaneous consideration of node heterogeneity\nand dynamic network topology changes, limiting their effectiveness in practical\napplications. In this paper, we address these limitations by modeling\nheterogeneous nodes within dynamically changing network environments and\nleveraging simulation-based strategies to determine optimal parallel\nconfigurations. Our approach enables fine-grained workload allocation tailored\nfor heterogeneous nodes and complex network scenarios, achieving performance\ncompetitive with state-of-the-art methods under regular and stable network\nconditions. Additionally, we introduce a strategy pruning technique to rapidly\ndiscard infeasible parallel configurations, substantially reducing the search\nspace and accelerating the search process through parallel execution within the\nsimulator. Preliminary evaluations confirm that our method notably enhances\ntraining performance on heterogeneous nodes and demonstrates improved\nadaptability in complex, dynamic scenarios such as cloud computing\nenvironments.", "AI": {"tldr": "The paper proposes a simulation-based method to optimize hybrid parallelism for large language models, addressing node heterogeneity and dynamic network changes, with competitive performance and faster search via strategy pruning.", "motivation": "Current automatic parallel planning frameworks fail to account for node heterogeneity and dynamic network changes, limiting their practical effectiveness.", "method": "The approach models heterogeneous nodes in dynamic networks, uses simulation to find optimal parallel configurations, and employs strategy pruning to reduce search space.", "result": "The method achieves competitive performance in stable conditions and improves training on heterogeneous nodes, with better adaptability in dynamic scenarios like cloud computing.", "conclusion": "The proposed approach enhances training efficiency and adaptability in complex, dynamic environments, outperforming existing methods."}}
{"id": "2506.03011", "pdf": "https://arxiv.org/pdf/2506.03011", "abs": "https://arxiv.org/abs/2506.03011", "authors": ["Aditya Bharat Soni", "Boxuan Li", "Xingyao Wang", "Valerie Chen", "Graham Neubig"], "title": "Coding Agents with Multimodal Browsing are Generalist Problem Solvers", "categories": ["cs.CL"], "comment": null, "summary": "Modern human labor is characterized by specialization; we train for years and\ndevelop particular tools that allow us to perform well across a variety of\ntasks. In addition, AI agents have been specialized for domains such as\nsoftware engineering, web navigation, and workflow automation. However, this\nresults in agents that are good for one thing but fail to generalize beyond\ntheir intended scope. One reason for this is that agent developers provide a\nhighly specialized set of tools or make architectural decisions optimized for a\nspecific use case or benchmark. In this work, we ask the question: what is the\nminimal set of general tools that can be used to achieve high performance\nacross a diverse set of tasks? Our answer is OpenHands-Versa, a generalist\nagent built with a modest number of general tools: code editing and execution,\nweb search, as well as multimodal web browsing and file access. Importantly,\nOpenHands-Versa demonstrates superior or competitive performance over leading\nspecialized agents across three diverse and challenging benchmarks: SWE-Bench\nMultimodal, GAIA, and The Agent Company, outperforming the best-performing\npreviously published results with absolute improvements in success rate of 9.1,\n1.3, and 9.1 points respectively. Further, we show how existing\nstate-of-the-art multi-agent systems fail to generalize beyond their target\ndomains. These results demonstrate the feasibility of developing a generalist\nagent to solve diverse tasks and establish OpenHands-Versa as a strong baseline\nfor future research.", "AI": {"tldr": "OpenHands-Versa is a generalist AI agent using minimal general tools (code editing, web search, multimodal browsing) to outperform specialized agents across diverse benchmarks.", "motivation": "Specialized AI agents lack generalization; the paper explores minimal general tools for high performance across diverse tasks.", "method": "Develop OpenHands-Versa with general tools (code editing, web search, multimodal browsing) and test on benchmarks (SWE-Bench, GAIA, The Agent Company).", "result": "OpenHands-Versa outperforms specialized agents with absolute improvements of 9.1, 1.3, and 9.1 points on respective benchmarks.", "conclusion": "Generalist agents like OpenHands-Versa are feasible and set a strong baseline for future research."}}
{"id": "2506.02781", "pdf": "https://arxiv.org/pdf/2506.02781", "abs": "https://arxiv.org/abs/2506.02781", "authors": ["Tongyuan Bai", "Wangyuanfan Bai", "Dong Chen", "Tieru Wu", "Manyi Li", "Rui Ma"], "title": "FreeScene: Mixed Graph Diffusion for 3D Scene Synthesis from Free Prompts", "categories": ["cs.CV"], "comment": "Accepted to CVPR 2025", "summary": "Controllability plays a crucial role in the practical applications of 3D\nindoor scene synthesis. Existing works either allow rough language-based\ncontrol, that is convenient but lacks fine-grained scene customization, or\nemploy graph based control, which offers better controllability but demands\nconsiderable knowledge for the cumbersome graph design process. To address\nthese challenges, we present FreeScene, a user-friendly framework that enables\nboth convenient and effective control for indoor scene synthesis.Specifically,\nFreeScene supports free-form user inputs including text description and/or\nreference images, allowing users to express versatile design intentions. The\nuser inputs are adequately analyzed and integrated into a graph representation\nby a VLM-based Graph Designer. We then propose MG-DiT, a Mixed Graph Diffusion\nTransformer, which performs graph-aware denoising to enhance scene generation.\nOur MG-DiT not only excels at preserving graph structure but also offers broad\napplicability to various tasks, including, but not limited to, text-to-scene,\ngraph-to-scene, and rearrangement, all within a single model. Extensive\nexperiments demonstrate that FreeScene provides an efficient and user-friendly\nsolution that unifies text-based and graph based scene synthesis, outperforming\nstate-of-the-art methods in terms of both generation quality and\ncontrollability in a range of applications.", "AI": {"tldr": "FreeScene is a user-friendly framework for 3D indoor scene synthesis, combining text and image inputs for fine-grained control, outperforming existing methods in quality and controllability.", "motivation": "Addressing the limitations of existing methods\u2014either too rough (language-based) or too complex (graph-based)\u2014for fine-grained scene customization.", "method": "Uses a VLM-based Graph Designer to integrate free-form inputs (text/images) into a graph, then employs MG-DiT (Mixed Graph Diffusion Transformer) for graph-aware denoising and scene generation.", "result": "Outperforms state-of-the-art methods in generation quality and controllability, unifying text-based and graph-based synthesis in one model.", "conclusion": "FreeScene offers an efficient, versatile solution for indoor scene synthesis, balancing ease of use with fine-grained control."}}
{"id": "2506.02842", "pdf": "https://arxiv.org/pdf/2506.02842", "abs": "https://arxiv.org/abs/2506.02842", "authors": ["Stefano Fiorini", "Hakan Aktas", "Iulia Duta", "Stefano Coniglio", "Pietro Morerio", "Alessio Del Bue", "Pietro Li\u00f2"], "title": "Sheaves Reloaded: A Directional Awakening", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Sheaf Neural Networks (SNNs) represent a powerful generalization of Graph\nNeural Networks (GNNs) that significantly improve our ability to model complex\nrelational data. While directionality has been shown to substantially boost\nperformance in graph learning tasks and is key to many real-world applications,\nexisting SNNs fall short in representing it. To address this limitation, we\nintroduce the Directed Cellular Sheaf, a special type of cellular sheaf\ndesigned to explicitly account for edge orientation. Building on this\nstructure, we define a new sheaf Laplacian, the Directed Sheaf Laplacian, which\ncaptures both the graph's topology and its directional information. This\noperator serves as the backbone of the Directed Sheaf Neural Network (DSNN),\nthe first SNN model to embed a directional bias into its architecture.\nExtensive experiments on nine real-world benchmarks show that DSNN consistently\noutperforms baseline methods.", "AI": {"tldr": "Sheaf Neural Networks (SNNs) are generalized Graph Neural Networks (GNNs) that improve relational data modeling. The paper introduces Directed Cellular Sheaf and Directed Sheaf Laplacian to incorporate edge directionality, leading to the Directed Sheaf Neural Network (DSNN), which outperforms baselines.", "motivation": "Existing SNNs lack the ability to represent directionality, which is crucial for graph learning tasks and real-world applications.", "method": "The authors propose Directed Cellular Sheaf and Directed Sheaf Laplacian to capture edge orientation, forming the backbone of DSNN.", "result": "DSNN consistently outperforms baseline methods across nine real-world benchmarks.", "conclusion": "The introduction of directionality in SNNs via DSNN enhances performance, addressing a key limitation in existing models."}}
{"id": "2506.02791", "pdf": "https://arxiv.org/pdf/2506.02791", "abs": "https://arxiv.org/abs/2506.02791", "authors": ["Zhen Yang", "Hongyi Lin", "Yifan He", "Jie Xu", "Zeyu Sun", "Shuo Liu", "Pengpeng Wang", "Zhongxing Yu", "Qingyuan Liang"], "title": "Rethinking the effects of data contamination in Code Intelligence", "categories": ["cs.SE", "cs.AI"], "comment": null, "summary": "In recent years, code intelligence has gained increasing importance in the\nfield of automated software engineering. Meanwhile, the widespread adoption of\nPretrained Language Models (PLMs) and Large Language Models (LLMs) has raised\nconcerns regarding data contamination and its potential impact on model\nperformance evaluation. This paper presents a systematic empirical study to\ninvestigate the fine-grained data contamination on code intelligence tasks. Our\nstudy involves diverse representative PLMs, namely RoBERTa and GPT-2, and LLMs,\nnamely LLaMA and StarCoder, covering three major tasks: code translation, code\ngeneration, and code summarization. We categorize contamination scenarios into\nfour types according to the code intelligence practice, namely input-only,\noutput-only, unpaired, and paired contamination settings, and construct\ncorresponding experimental and control groups for exploration.\n  Experimental results show that, under the pre-training, fine-tuning, and\ninference paradigm adopted by PLMs, even deliberately injecting paired\ncontamination does not lead to significant performance overestimation. But\ndirect inference or small-scale fine-tuning uncovers the contamination effects.\nIn contrast, LLMs with pre-training and inference paradigm are significantly\naffected by the paired contamination. Apart from the above, other contamination\nscenarios have no impact on both PLMs and LLMs. Our findings challenge the\nconventional belief that contamination inevitably leads to performance\noverestimation, providing new insights into the evaluation and deployment of\ncode intelligence models.", "AI": {"tldr": "The paper investigates fine-grained data contamination in code intelligence tasks using PLMs and LLMs, finding that paired contamination significantly affects LLMs but not PLMs under typical training paradigms.", "motivation": "To address concerns about data contamination's impact on model performance evaluation in code intelligence tasks.", "method": "Systematic empirical study with PLMs (RoBERTa, GPT-2) and LLMs (LLaMA, StarCoder) across code translation, generation, and summarization tasks, categorizing contamination into four scenarios.", "result": "Paired contamination affects LLMs but not PLMs under standard training; other contamination types have no impact.", "conclusion": "Contamination does not always overestimate performance, offering new insights for evaluating and deploying code intelligence models."}}
{"id": "2506.03035", "pdf": "https://arxiv.org/pdf/2506.03035", "abs": "https://arxiv.org/abs/2506.03035", "authors": ["Pierre Lepagnol", "Sahar Ghannay", "Thomas Gerald", "Christophe Servan", "Sophie Rosset"], "title": "Leveraging Information Retrieval to Enhance Spoken Language Understanding Prompts in Few-Shot Learning", "categories": ["cs.CL", "cs.AI", "cs.IR"], "comment": "Conference paper accepted to INTERSPEECH 2025", "summary": "Understanding user queries is fundamental in many applications, such as home\nassistants, booking systems, or recommendations. Accordingly, it is crucial to\ndevelop accurate Spoken Language Understanding (SLU) approaches to ensure the\nreliability of the considered system. Current State-of-the-Art SLU techniques\nrely on large amounts of training data; however, only limited annotated\nexamples are available for specific tasks or languages.\n  In the meantime, instruction-tuned large language models (LLMs) have shown\nexceptional performance on unseen tasks in a few-shot setting when provided\nwith adequate prompts. In this work, we propose to explore example selection by\nleveraging Information retrieval (IR) approaches to build an enhanced prompt\nthat is applied to an SLU task. We evaluate the effectiveness of the proposed\nmethod on several SLU benchmarks. Experimental results show that lexical IR\nmethods significantly enhance performance without increasing prompt length.", "AI": {"tldr": "The paper explores using Information Retrieval (IR) methods to select examples for enhancing prompts in Spoken Language Understanding (SLU) tasks, improving performance without longer prompts.", "motivation": "Limited annotated data for SLU tasks and languages motivates leveraging instruction-tuned LLMs and IR methods to enhance few-shot learning.", "method": "Proposes using IR approaches to select examples for building enhanced prompts, applied to SLU tasks.", "result": "Lexical IR methods significantly boost SLU performance without increasing prompt length.", "conclusion": "IR-based example selection effectively improves SLU task performance in few-shot settings."}}
{"id": "2506.02783", "pdf": "https://arxiv.org/pdf/2506.02783", "abs": "https://arxiv.org/abs/2506.02783", "authors": ["Carlos Garcia-Lopez-de-Haro", "Caterina Fuster-Barcelo", "Curtis T. Rueden", "Jonathan Heras", "Vladimir Ulman", "Daniel Franco-Barranco", "Adrian Ines", "Kevin W. Eliceiri", "Jean-Christophe Olivo-Marin", "Jean-Yves Tinevez", "Daniel Sage", "Arrate Munoz-Barrutia"], "title": "SAMJ: Fast Image Annotation on ImageJ/Fiji via Segment Anything Model", "categories": ["cs.CV"], "comment": null, "summary": "Mask annotation remains a significant bottleneck in AI-driven biomedical\nimage analysis due to its labor-intensive nature. To address this challenge, we\nintroduce SAMJ, a user-friendly ImageJ/Fiji plugin leveraging the Segment\nAnything Model (SAM). SAMJ enables seamless, interactive annotations with\none-click installation on standard computers. Designed for real-time object\ndelineation in large scientific images, SAMJ is an easy-to-use solution that\nsimplifies and accelerates the creation of labeled image datasets.", "AI": {"tldr": "SAMJ is an ImageJ/Fiji plugin using SAM to simplify and speed up mask annotation in biomedical image analysis.", "motivation": "Mask annotation is labor-intensive, creating a bottleneck in AI-driven biomedical image analysis.", "method": "SAMJ leverages the Segment Anything Model (SAM) for interactive, one-click annotations on standard computers.", "result": "SAMJ enables real-time object delineation in large scientific images, simplifying dataset creation.", "conclusion": "SAMJ provides an easy-to-use solution to accelerate labeled image dataset generation."}}
{"id": "2506.02864", "pdf": "https://arxiv.org/pdf/2506.02864", "abs": "https://arxiv.org/abs/2506.02864", "authors": ["Changyi Xiao", "Mengdi Zhang", "Yixin Cao"], "title": "BNPO: Beta Normalization Policy Optimization", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Recent studies, including DeepSeek-R1 and Kimi-k1.5, have demonstrated that\nreinforcement learning with rule-based, binary-valued reward functions can\nsignificantly enhance the reasoning capabilities of large language models.\nThese models primarily utilize REINFORCE-based policy optimization techniques,\nsuch as REINFORCE with baseline and group relative policy optimization (GRPO).\nHowever, a key limitation remains: current policy optimization methods either\nneglect reward normalization or employ static normalization strategies, which\nfail to adapt to the dynamic nature of policy updates during training. This may\nresult in unstable gradient estimates and hinder training stability. To address\nthis issue, we propose Beta Normalization Policy Optimization (BNPO), a novel\npolicy optimization method that adaptively normalizes rewards using a Beta\ndistribution with dynamically updated parameters. BNPO aligns the normalization\nwith the changing policy distribution, enabling more precise and lower-variance\ngradient estimation, which in turn promotes stable training dynamics. We\nprovide theoretical analysis demonstrating BNPO's variance-reducing properties\nand show that it generalizes both REINFORCE and GRPO under binary-valued reward\nsettings. Furthermore, we introduce an advantage decomposition mechanism to\nextend BNPO's applicability to more complex reward systems. Experimental\nresults confirm that BNPO achieves state-of-the-art performance among policy\noptimization methods on reasoning tasks. The code is available at\nhttps://github.com/changyi7231/BNPO.", "AI": {"tldr": "BNPO introduces adaptive reward normalization using Beta distribution to improve training stability in reinforcement learning for language models.", "motivation": "Current methods lack adaptive reward normalization, leading to unstable gradients and training instability.", "method": "Proposes Beta Normalization Policy Optimization (BNPO) with dynamic Beta distribution parameters for adaptive normalization.", "result": "BNPO achieves state-of-the-art performance, reduces gradient variance, and generalizes existing methods.", "conclusion": "BNPO enhances training stability and performance in reinforcement learning for reasoning tasks."}}
{"id": "2506.02794", "pdf": "https://arxiv.org/pdf/2506.02794", "abs": "https://arxiv.org/abs/2506.02794", "authors": ["Mijeong Kim", "Gunhee Kim", "Jungyoon Choi", "Wonjae Roh", "Bohyung Han"], "title": "PhysGaia: A Physics-Aware Dataset of Multi-Body Interactions for Dynamic Novel View Synthesis", "categories": ["cs.GR", "cs.AI", "cs.CV"], "comment": "Project page: http://cvlab.snu.ac.kr/research/PhysGaia, Data:\n  https://huggingface.co/datasets/mijeongkim/PhysGaia/tree/main", "summary": "We introduce PhysGaia, a novel physics-aware dataset specifically designed\nfor Dynamic Novel View Synthesis (DyNVS), encompassing both structured objects\nand unstructured physical phenomena. Unlike existing datasets that primarily\nfocus on photorealistic reconstruction, PhysGaia is created to actively support\nphysics-aware dynamic scene modeling. Our dataset provides complex dynamic\nscenarios with rich interactions among multiple objects, where they\nrealistically collide with each other and exchange forces. Furthermore, it\ncontains a diverse range of physical materials, such as liquid, gas,\nviscoelastic substance, and textile, which moves beyond the rigid bodies\nprevalent in existing datasets. All scenes in PhysGaia are faithfully generated\nto strictly adhere to physical laws, leveraging carefully selected\nmaterial-specific physics solvers. To enable quantitative evaluation of\nphysical modeling, our dataset provides essential ground-truth information,\nincluding 3D particle trajectories and physics parameters, e.g., viscosity. To\nfacilitate research adoption, we also provide essential integration pipelines\nfor using state-of-the-art DyNVS models with our dataset and report their\nresults. By addressing the critical lack of datasets for physics-aware\nmodeling, PhysGaia will significantly advance research in dynamic view\nsynthesis, physics-based scene understanding, and deep learning models\nintegrated with physical simulation -- ultimately enabling more faithful\nreconstruction and interpretation of complex dynamic scenes. Our datasets and\ncodes are available in the project website,\nhttp://cvlab.snu.ac.kr/research/PhysGaia.", "AI": {"tldr": "PhysGaia is a physics-aware dataset for Dynamic Novel View Synthesis (DyNVS), featuring structured objects and unstructured phenomena, adhering to physical laws and providing ground-truth data for evaluation.", "motivation": "Existing datasets lack physics-aware dynamic scene modeling, focusing mainly on photorealistic reconstruction. PhysGaia addresses this gap by offering complex interactions and diverse materials.", "method": "The dataset is generated using material-specific physics solvers, ensuring adherence to physical laws. It includes 3D particle trajectories and physics parameters like viscosity.", "result": "PhysGaia enables quantitative evaluation of physical modeling and supports integration with state-of-the-art DyNVS models.", "conclusion": "PhysGaia advances research in dynamic view synthesis and physics-based scene understanding, providing a foundation for faithful reconstruction of complex dynamic scenes."}}
{"id": "2506.03038", "pdf": "https://arxiv.org/pdf/2506.03038", "abs": "https://arxiv.org/abs/2506.03038", "authors": ["Jintian Shao", "Yiming Cheng"], "title": "Towards Analyzing and Understanding the Limitations of VAPO: A Theoretical Perspective", "categories": ["cs.CL"], "comment": null, "summary": "Reinforcement learning (RL) enhances large language models (LLMs) in complex,\nlong-chain-of-thought (long-CoT) reasoning. The advanced VAPO framework,\ndespite sophisticated mechanisms like Decoupled GAE, theoretically faces\nfundamental limitations in comprehensively modeling and leveraging deep,\nlong-term value for fine-grained, step-by-step policy guidance in extended\nreasoning chains. We argue these limitations stem from inherent difficulties in\ncredit assignment, value function representational capacity with temporally\nabstracted goals, and translating global value signals into local policy\nimprovements, especially with sparse rewards. Our theoretical analysis examines\nthese aspects to illuminate VAPO's boundaries in long-term value modeling,\naiming to deepen understanding of current RL for advanced reasoning and suggest\nfuture research for more robust LLM agents.", "AI": {"tldr": "The paper discusses limitations of the VAPO framework in reinforcement learning for long-chain reasoning in LLMs, focusing on credit assignment, value function capacity, and global-to-local policy translation.", "motivation": "To address the challenges in modeling long-term value and improving policy guidance in extended reasoning tasks with sparse rewards.", "method": "Theoretical analysis of VAPO's limitations, including credit assignment, value function representational capacity, and policy improvement translation.", "result": "Identifies fundamental boundaries in VAPO's ability to model long-term value and guide fine-grained policies in long reasoning chains.", "conclusion": "Highlights the need for future research to develop more robust RL methods for advanced reasoning in LLMs."}}
{"id": "2506.02789", "pdf": "https://arxiv.org/pdf/2506.02789", "abs": "https://arxiv.org/abs/2506.02789", "authors": ["Renxing Li", "Weiyi Tang", "Peiqi Li", "Qiming Huang", "Jiayuan She", "Shengkai Li", "Haoran Xu", "Yeyun Wan", "Jing Liu", "Hailong Fu", "Xiang Li", "Jiangang Chen"], "title": "Automated Measurement of Optic Nerve Sheath Diameter Using Ocular Ultrasound Video", "categories": ["cs.CV"], "comment": "17 pages, 9 figures", "summary": "Objective. Elevated intracranial pressure (ICP) is recognized as a biomarker\nof secondary brain injury, with a significant linear correlation observed\nbetween optic nerve sheath diameter (ONSD) and ICP. Frequent monitoring of ONSD\ncould effectively support dynamic evaluation of ICP. However, ONSD measurement\nis heavily reliant on the operator's experience and skill, particularly in\nmanually selecting the optimal frame from ultrasound sequences and measuring\nONSD. Approach. This paper presents a novel method to automatically identify\nthe optimal frame from video sequences for ONSD measurement by employing the\nKernel Correlation Filter (KCF) tracking algorithm and Simple Linear Iterative\nClustering (SLIC) segmentation algorithm. The optic nerve sheath is mapped and\nmeasured using a Gaussian Mixture Model (GMM) combined with a\nKL-divergence-based method. Results. When compared with the average\nmeasurements of two expert clinicians, the proposed method achieved a mean\nerror, mean squared deviation, and intraclass correlation coefficient (ICC) of\n0.04, 0.054, and 0.782, respectively. Significance. The findings suggest that\nthis method provides highly accurate automated ONSD measurements, showing\npotential for clinical application.", "AI": {"tldr": "A novel automated method for measuring optic nerve sheath diameter (ONSD) using KCF tracking and SLIC segmentation achieves high accuracy, reducing reliance on operator skill.", "motivation": "Manual ONSD measurement is operator-dependent, limiting its reliability for intracranial pressure (ICP) monitoring.", "method": "Combines KCF tracking, SLIC segmentation, and GMM with KL-divergence for automated ONSD measurement.", "result": "Achieved mean error of 0.04, mean squared deviation of 0.054, and ICC of 0.782 compared to expert clinicians.", "conclusion": "The method offers accurate, automated ONSD measurement, promising for clinical ICP monitoring."}}
{"id": "2506.02883", "pdf": "https://arxiv.org/pdf/2506.02883", "abs": "https://arxiv.org/abs/2506.02883", "authors": ["Anthony Kobanda", "Odalric-Ambrym Maillard", "R\u00e9my Portelas"], "title": "A Continual Offline Reinforcement Learning Benchmark for Navigation Tasks", "categories": ["cs.LG"], "comment": "arXiv admin note: text overlap with arXiv:2412.14865", "summary": "Autonomous agents operating in domains such as robotics or video game\nsimulations must adapt to changing tasks without forgetting about the previous\nones. This process called Continual Reinforcement Learning poses non-trivial\ndifficulties, from preventing catastrophic forgetting to ensuring the\nscalability of the approaches considered. Building on recent advances, we\nintroduce a benchmark providing a suite of video-game navigation scenarios,\nthus filling a gap in the literature and capturing key challenges :\ncatastrophic forgetting, task adaptation, and memory efficiency. We define a\nset of various tasks and datasets, evaluation protocols, and metrics to assess\nthe performance of algorithms, including state-of-the-art baselines. Our\nbenchmark is designed not only to foster reproducible research and to\naccelerate progress in continual reinforcement learning for gaming, but also to\nprovide a reproducible framework for production pipelines -- helping\npractitioners to identify and to apply effective approaches.", "AI": {"tldr": "A benchmark for continual reinforcement learning in video-game navigation is introduced to address challenges like catastrophic forgetting, task adaptation, and memory efficiency.", "motivation": "To address the lack of standardized benchmarks for continual reinforcement learning in dynamic environments like gaming, ensuring scalability and preventing forgetting.", "method": "Developed a suite of video-game navigation tasks, datasets, evaluation protocols, and metrics, including state-of-the-art baselines.", "result": "The benchmark provides a reproducible framework for evaluating algorithms and accelerating progress in continual reinforcement learning.", "conclusion": "This work fills a literature gap, aids reproducible research, and helps practitioners apply effective approaches in production pipelines."}}
{"id": "2506.02796", "pdf": "https://arxiv.org/pdf/2506.02796", "abs": "https://arxiv.org/abs/2506.02796", "authors": ["Haoyuan Wang", "Chen Liu", "Minh-Ngoc Tran", "Chao Wang"], "title": "Deep Learning Enhanced Multivariate GARCH", "categories": ["q-fin.CP", "cs.AI", "econ.EM"], "comment": null, "summary": "This paper introduces a novel multivariate volatility modeling framework,\nnamed Long Short-Term Memory enhanced BEKK (LSTM-BEKK), that integrates deep\nlearning into multivariate GARCH processes. By combining the flexibility of\nrecurrent neural networks with the econometric structure of BEKK models, our\napproach is designed to better capture nonlinear, dynamic, and high-dimensional\ndependence structures in financial return data. The proposed model addresses\nkey limitations of traditional multivariate GARCH-based methods, particularly\nin capturing persistent volatility clustering and asymmetric co-movement across\nassets. Leveraging the data-driven nature of LSTMs, the framework adapts\neffectively to time-varying market conditions, offering improved robustness and\nforecasting performance. Empirical results across multiple equity markets\nconfirm that the LSTM-BEKK model achieves superior performance in terms of\nout-of-sample portfolio risk forecast, while maintaining the interpretability\nfrom the BEKK models. These findings highlight the potential of hybrid\neconometric-deep learning models in advancing financial risk management and\nmultivariate volatility forecasting.", "AI": {"tldr": "The paper introduces LSTM-BEKK, a hybrid model combining deep learning (LSTM) with BEKK-GARCH to improve volatility forecasting in financial markets.", "motivation": "Traditional multivariate GARCH models struggle with nonlinear, dynamic, and high-dimensional dependencies in financial data. The goal is to enhance volatility forecasting by integrating LSTM's flexibility with BEKK's econometric structure.", "method": "The LSTM-BEKK model merges recurrent neural networks (LSTM) with BEKK-GARCH, leveraging LSTM's data-driven adaptability to capture complex market dynamics.", "result": "Empirical tests show LSTM-BEKK outperforms traditional methods in out-of-sample portfolio risk forecasting while retaining BEKK's interpretability.", "conclusion": "Hybrid econometric-deep learning models like LSTM-BEKK hold promise for advancing financial risk management and volatility forecasting."}}
{"id": "2506.03051", "pdf": "https://arxiv.org/pdf/2506.03051", "abs": "https://arxiv.org/abs/2506.03051", "authors": ["Yuval Kansal", "Shmuel Berman", "Lydia Liu"], "title": "Facts Do Care About Your Language: Assessing Answer Quality of Multilingual LLMs", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Factuality is a necessary precursor to useful educational tools. As adoption\nof Large Language Models (LLMs) in education continues of grow, ensuring\ncorrectness in all settings is paramount. Despite their strong English\ncapabilities, LLM performance in other languages is largely untested. In this\nwork, we evaluate the correctness of the Llama3.1 family of models in answering\nfactual questions appropriate for middle and high school students. We\ndemonstrate that LLMs not only provide extraneous and less truthful\ninformation, but also exacerbate existing biases against rare languages.", "AI": {"tldr": "The paper evaluates Llama3.1 models' factuality in non-English educational contexts, finding issues with truthfulness and biases against rare languages.", "motivation": "To assess the correctness of LLMs in educational settings, especially for non-English languages, given their growing adoption.", "method": "Evaluated Llama3.1 models on factual questions for middle and high school students.", "result": "LLMs provided extraneous, less truthful information and showed biases against rare languages.", "conclusion": "Factuality and bias issues must be addressed for LLMs to be reliable educational tools in diverse linguistic contexts."}}
{"id": "2506.02843", "pdf": "https://arxiv.org/pdf/2506.02843", "abs": "https://arxiv.org/abs/2506.02843", "authors": ["Shuai Yi", "Yixiong Zou", "Yuhua Li", "Ruixuan Li"], "title": "Random Registers for Cross-Domain Few-Shot Learning", "categories": ["cs.CV"], "comment": "Accepted by ICML 2025", "summary": "Cross-domain few-shot learning (CDFSL) aims to transfer knowledge from a\ndata-sufficient source domain to data-scarce target domains. Although Vision\nTransformer (ViT) has shown superior capability in many vision tasks, its\ntransferability against huge domain gaps in CDFSL is still under-explored. In\nthis paper, we find an intriguing phenomenon: during the source-domain\ntraining, prompt tuning, as a common way to train ViT, could be harmful for the\ngeneralization of ViT in target domains, but setting them to random noises\n(i.e., random registers) could consistently improve target-domain performance.\nWe then delve into this phenomenon for an interpretation. We find that\nlearnable prompts capture domain information during the training on the source\ndataset, which views irrelevant visual patterns as vital cues for recognition.\nThis can be viewed as a kind of overfitting and increases the sharpness of the\nloss landscapes. In contrast, random registers are essentially a novel way of\nperturbing attention for the sharpness-aware minimization, which helps the\nmodel find a flattened minimum in loss landscapes, increasing the\ntransferability. Based on this phenomenon and interpretation, we further\npropose a simple but effective approach for CDFSL to enhance the perturbation\non attention maps by adding random registers on the semantic regions of image\ntokens, improving the effectiveness and efficiency of random registers.\nExtensive experiments on four benchmarks validate our rationale and\nstate-of-the-art performance. Codes and models are available at\nhttps://github.com/shuaiyi308/REAP.", "AI": {"tldr": "Random registers in ViT improve cross-domain few-shot learning by reducing overfitting and flattening loss landscapes, outperforming traditional prompt tuning.", "motivation": "To explore why random registers in Vision Transformers (ViT) enhance transferability in cross-domain few-shot learning (CDFSL) compared to learnable prompts.", "method": "Analyze the impact of random registers vs. learnable prompts, propose adding random registers to semantic regions of image tokens for better perturbation.", "result": "Random registers consistently improve target-domain performance, validated on four benchmarks with state-of-the-art results.", "conclusion": "Random registers act as a form of sharpness-aware minimization, enhancing ViT's transferability in CDFSL."}}
{"id": "2506.02887", "pdf": "https://arxiv.org/pdf/2506.02887", "abs": "https://arxiv.org/abs/2506.02887", "authors": ["Mrinmay Sen", "Shruti Aparna", "Rohit Agarwal", "Chalavadi Krishna Mohan"], "title": "Overcoming Challenges of Partial Client Participation in Federated Learning : A Comprehensive Review", "categories": ["cs.LG", "cs.DC"], "comment": "15 pages, 6 tables, comprehensive survey of federated learning with\n  partial client participation", "summary": "Federated Learning (FL) is a learning mechanism that falls under the\ndistributed training umbrella, which collaboratively trains a shared global\nmodel without disclosing the raw data from different clients. This paper\npresents an extensive survey on the impact of partial client participation in\nfederated learning. While much of the existing research focuses on addressing\nissues such as generalization, robustness, and fairness caused by data\nheterogeneity under the assumption of full client participation, limited\nattention has been given to the practical and theoretical challenges arising\nfrom partial client participation, which is common in real-world scenarios.\nThis survey provides an in-depth review of existing FL methods designed to cope\nwith partial client participation. We offer a comprehensive analysis supported\nby theoretical insights and empirical findings, along with a structured\ncategorization of these methods, highlighting their respective advantages and\ndisadvantages.", "AI": {"tldr": "A survey on the impact of partial client participation in federated learning, reviewing methods, theoretical insights, and empirical findings.", "motivation": "Addresses the overlooked challenges of partial client participation in FL, common in real-world scenarios.", "method": "In-depth review and categorization of existing FL methods for partial client participation.", "result": "Comprehensive analysis of methods, their pros and cons, supported by theory and empirical data.", "conclusion": "Highlights the need for further research on partial client participation in FL."}}
{"id": "2506.02839", "pdf": "https://arxiv.org/pdf/2506.02839", "abs": "https://arxiv.org/abs/2506.02839", "authors": ["Yougang Lyu", "Xiaoyu Zhang", "Lingyong Yan", "Maarten de Rijke", "Zhaochun Ren", "Xiuying Chen"], "title": "DeepShop: A Benchmark for Deep Research Shopping Agents", "categories": ["cs.IR", "cs.AI"], "comment": null, "summary": "Web agents for online shopping have shown great promise in automating user\ninteractions across e-commerce platforms. Benchmarks for assessing such agents\ndo not reflect the complexity of real-world shopping scenarios, as they often\nconsist of overly simple queries with deterministic paths, such as \"Find iPhone\n15.\" Real shopping scenarios are inherently more layered, involving\nmulti-dimensional product attributes, search filters, and user-specific sorting\npreferences. To address this gap, we introduce DeepShop, a benchmark designed\nto evaluate web agents in complex and realistic online shopping environments.\nDeepShop comprises three key components. (1) Query diversity evolution:\nStarting from real user queries, we generate diverse queries across five\npopular online shopping domains. (2) Query complexity evolution: We further\nevolve these queries to increase complexity, considering product attributes,\nsearch filters, and sorting preferences, and classify them into three levels:\neasy, medium, and hard, based on the number of evolutions. (3) Fine-grained and\nholistic evaluation: We propose an automated evaluation framework that assesses\nagent performance in terms of fine-grained aspects (product attributes, search\nfilters, and sorting preferences) and reports the overall success rate through\nholistic evaluation. We conduct a systematic evaluation of retrieval-augmented\ngeneration (RAG) methods, web agents, and deep research systems. Results show\nthat RAG struggles with complex queries due to its lack of web interaction,\nwhile other methods face significant challenges with filters and sorting\npreferences, leading to low overall success rates. We also perform\ncross-category, complexity-based evaluations and error analyses to support the\nadvancement of deep research shopping agents.", "AI": {"tldr": "DeepShop is a benchmark for evaluating web agents in complex online shopping scenarios, addressing gaps in existing benchmarks by incorporating diverse and evolved queries, and proposing a fine-grained and holistic evaluation framework.", "motivation": "Existing benchmarks for web agents in online shopping are overly simplistic and fail to capture real-world complexities like multi-dimensional product attributes and user preferences.", "method": "DeepShop introduces (1) query diversity evolution, (2) query complexity evolution (easy, medium, hard), and (3) a fine-grained and holistic evaluation framework.", "result": "RAG methods struggle with complex queries, while other methods face challenges with filters and sorting preferences, resulting in low success rates.", "conclusion": "DeepShop supports the advancement of shopping agents by providing a realistic and comprehensive evaluation benchmark."}}
{"id": "2506.03090", "pdf": "https://arxiv.org/pdf/2506.03090", "abs": "https://arxiv.org/abs/2506.03090", "authors": ["Katherine Thai", "Mohit Iyyer"], "title": "Literary Evidence Retrieval via Long-Context Language Models", "categories": ["cs.CL"], "comment": "ACL 2025", "summary": "How well do modern long-context language models understand literary fiction?\nWe explore this question via the task of literary evidence retrieval,\nrepurposing the RELiC dataset of That et al. (2022) to construct a benchmark\nwhere the entire text of a primary source (e.g., The Great Gatsby) is provided\nto an LLM alongside literary criticism with a missing quotation from that work.\nThis setting, in which the model must generate the missing quotation, mirrors\nthe human process of literary analysis by requiring models to perform both\nglobal narrative reasoning and close textual examination. We curate a\nhigh-quality subset of 292 examples through extensive filtering and human\nverification. Our experiments show that recent reasoning models, such as Gemini\nPro 2.5 can exceed human expert performance (62.5% vs. 50% accuracy). In\ncontrast, the best open-weight model achieves only 29.1% accuracy, highlighting\na wide gap in interpretive reasoning between open and closed-weight models.\nDespite their speed and apparent accuracy, even the strongest models struggle\nwith nuanced literary signals and overgeneration, signaling open challenges for\napplying LLMs to literary analysis. We release our dataset and evaluation code\nto encourage future work in this direction.", "AI": {"tldr": "Modern long-context LLMs like Gemini Pro 2.5 outperform humans in literary evidence retrieval (62.5% vs. 50% accuracy), but open-weight models lag behind (29.1%). Challenges remain in nuanced literary analysis.", "motivation": "To assess how well modern LLMs understand literary fiction by testing their ability to retrieve missing quotations from literary criticism, mirroring human literary analysis.", "method": "Repurposed the RELiC dataset to create a benchmark where LLMs generate missing quotations from primary sources, requiring narrative reasoning and textual examination. Curated 292 high-quality examples.", "result": "Gemini Pro 2.5 achieved 62.5% accuracy, surpassing human experts (50%), while the best open-weight model scored 29.1%. Models struggled with nuanced signals and overgeneration.", "conclusion": "While some LLMs excel in literary evidence retrieval, challenges like nuanced interpretation persist. The dataset and code are released to spur further research."}}
{"id": "2506.02845", "pdf": "https://arxiv.org/pdf/2506.02845", "abs": "https://arxiv.org/abs/2506.02845", "authors": ["Di Wen", "Lei Qi", "Kunyu Peng", "Kailun Yang", "Fei Teng", "Ao Luo", "Jia Fu", "Yufan Chen", "Ruiping Liu", "Yitian Shi", "M. Saquib Sarfraz", "Rainer Stiefelhagen"], "title": "Go Beyond Earth: Understanding Human Actions and Scenes in Microgravity Environments", "categories": ["cs.CV"], "comment": "15 pages, 3 figures, submitted to NeurIPS 2025", "summary": "Despite substantial progress in video understanding, most existing datasets\nare limited to Earth's gravitational conditions. However, microgravity alters\nhuman motion, interactions, and visual semantics, revealing a critical gap for\nreal-world vision systems. This presents a challenge for domain-robust video\nunderstanding in safety-critical space applications. To address this, we\nintroduce MicroG-4M, the first benchmark for spatio-temporal and semantic\nunderstanding of human activities in microgravity. Constructed from real-world\nspace missions and cinematic simulations, the dataset includes 4,759 clips\ncovering 50 actions, 1,238 context-rich captions, and over 7,000\nquestion-answer pairs on astronaut activities and scene understanding.\nMicroG-4M supports three core tasks: fine-grained multi-label action\nrecognition, temporal video captioning, and visual question answering, enabling\na comprehensive evaluation of both spatial localization and semantic reasoning\nin microgravity contexts. We establish baselines using state-of-the-art models.\nAll data, annotations, and code are available at\nhttps://github.com/LEI-QI-233/HAR-in-Space.", "AI": {"tldr": "MicroG-4M is the first benchmark dataset for video understanding in microgravity, featuring 4,759 clips, 50 actions, and multiple tasks like action recognition and visual question answering.", "motivation": "Existing video datasets lack microgravity contexts, limiting vision systems for space applications.", "method": "Constructed from real-world space missions and simulations, MicroG-4M includes clips, captions, and QA pairs.", "result": "Supports tasks like action recognition, video captioning, and visual QA, with baselines from state-of-the-art models.", "conclusion": "MicroG-4M fills a critical gap for domain-robust video understanding in microgravity."}}
{"id": "2506.02890", "pdf": "https://arxiv.org/pdf/2506.02890", "abs": "https://arxiv.org/abs/2506.02890", "authors": ["Jakub Krajewski", "Marcin Chochowski", "Daniel Korzekwa"], "title": "Scaling Fine-Grained MoE Beyond 50B Parameters: Empirical Evaluation and Practical Insights", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": null, "summary": "Mixture of Experts (MoE) architectures have emerged as pivotal for scaling\nLarge Language Models (LLMs) efficiently. Fine-grained MoE approaches -\nutilizing more numerous, smaller experts - have demonstrated potential in\nimproving model convergence and quality. This work proposes a set of training\nrecipes and provides a comprehensive empirical evaluation of fine-grained MoE,\ndirectly comparing its scaling properties against standard MoE configurations\nfor models with up to 56B total (17B active) parameters. We investigate\nconvergence speed, model performance on downstream benchmarks, and practical\ntraining considerations across various setups. Overall, at the largest scale we\nshow that fine-grained MoE achieves better validation loss and higher accuracy\nacross a set of downstream benchmarks. This study offers empirical grounding\nand practical insights for leveraging fine-grained MoE in the development of\nfuture large-scale models.", "AI": {"tldr": "Fine-grained MoE improves model convergence and quality, outperforming standard MoE in large-scale models (up to 56B parameters) with better validation loss and accuracy.", "motivation": "To explore the potential of fine-grained MoE (using more, smaller experts) for scaling LLMs efficiently and improving model performance.", "method": "Proposes training recipes and conducts empirical evaluation, comparing fine-grained MoE against standard MoE in models up to 56B parameters.", "result": "Fine-grained MoE achieves better validation loss and higher accuracy on downstream benchmarks at large scales.", "conclusion": "Fine-grained MoE is empirically validated as effective for future large-scale model development, offering practical insights."}}
{"id": "2506.02859", "pdf": "https://arxiv.org/pdf/2506.02859", "abs": "https://arxiv.org/abs/2506.02859", "authors": ["Parth Atulbhai Gandhi", "Akansha Shukla", "David Tayouri", "Beni Ifland", "Yuval Elovici", "Rami Puzis", "Asaf Shabtai"], "title": "ATAG: AI-Agent Application Threat Assessment with Attack Graphs", "categories": ["cs.CR", "cs.AI"], "comment": null, "summary": "Evaluating the security of multi-agent systems (MASs) powered by large\nlanguage models (LLMs) is challenging, primarily because of the systems'\ncomplex internal dynamics and the evolving nature of LLM vulnerabilities.\nTraditional attack graph (AG) methods often lack the specific capabilities to\nmodel attacks on LLMs. This paper introduces AI-agent application Threat\nassessment with Attack Graphs (ATAG), a novel framework designed to\nsystematically analyze the security risks associated with AI-agent\napplications. ATAG extends the MulVAL logic-based AG generation tool with\ncustom facts and interaction rules to accurately represent AI-agent topologies,\nvulnerabilities, and attack scenarios. As part of this research, we also\ncreated the LLM vulnerability database (LVD) to initiate the process of\nstandardizing LLM vulnerabilities documentation. To demonstrate ATAG's\nefficacy, we applied it to two multi-agent applications. Our case studies\ndemonstrated the framework's ability to model and generate AGs for\nsophisticated, multi-step attack scenarios exploiting vulnerabilities such as\nprompt injection, excessive agency, sensitive information disclosure, and\ninsecure output handling across interconnected agents. ATAG is an important\nstep toward a robust methodology and toolset to help understand, visualize, and\nprioritize complex attack paths in multi-agent AI systems (MAASs). It\nfacilitates proactive identification and mitigation of AI-agent threats in\nmulti-agent applications.", "AI": {"tldr": "ATAG is a framework for assessing security risks in AI-agent applications by extending MulVAL with custom rules and creating an LLM vulnerability database (LVD). It effectively models multi-step attacks in multi-agent systems.", "motivation": "Traditional attack graph methods are inadequate for modeling LLM vulnerabilities in multi-agent systems, necessitating a specialized framework like ATAG.", "method": "ATAG extends MulVAL with custom facts and rules to represent AI-agent topologies and vulnerabilities, and introduces LVD for standardizing LLM vulnerability documentation.", "result": "Case studies showed ATAG's ability to model complex attack scenarios (e.g., prompt injection, sensitive data leaks) in multi-agent applications.", "conclusion": "ATAG advances security assessment for multi-agent AI systems by enabling proactive threat identification and mitigation."}}
{"id": "2506.03101", "pdf": "https://arxiv.org/pdf/2506.03101", "abs": "https://arxiv.org/abs/2506.03101", "authors": ["Jonas F. Lotz", "Ant\u00f3nio V. Lopes", "Stephan Peitz", "Hendra Setiawan", "Leonardo Emili"], "title": "Beyond Text Compression: Evaluating Tokenizers Across Scales", "categories": ["cs.CL"], "comment": "ACL 2025", "summary": "The choice of tokenizer can profoundly impact language model performance, yet\naccessible and reliable evaluations of tokenizer quality remain an open\nchallenge. Inspired by scaling consistency, we show that smaller models can\naccurately predict significant differences in tokenizer impact on larger models\nat a fraction of the compute cost. By systematically evaluating both\nEnglish-centric and multilingual tokenizers, we find that tokenizer choice has\nnegligible effects on tasks in English but results in consistent performance\ndifferences in multilingual settings. We propose new intrinsic tokenizer\nmetrics inspired by Zipf's law that correlate more strongly with downstream\nperformance than text compression when modeling unseen languages. By combining\nseveral metrics to capture multiple aspects of tokenizer behavior, we develop a\nreliable framework for intrinsic tokenizer evaluations. Our work offers a more\nefficient path to informed tokenizer selection in future language model\ndevelopment.", "AI": {"tldr": "Smaller models can predict tokenizer impact on larger models efficiently. Tokenizer choice affects multilingual tasks more than English. New intrinsic metrics based on Zipf's law improve evaluation.", "motivation": "The need for accessible and reliable evaluations of tokenizer quality, as tokenizer choice significantly impacts language model performance.", "method": "Systematic evaluation of English-centric and multilingual tokenizers using smaller models to predict impacts on larger models. Introduction of new intrinsic metrics inspired by Zipf's law.", "result": "Tokenizer choice has negligible effects on English tasks but consistent performance differences in multilingual settings. New metrics correlate better with downstream performance.", "conclusion": "A reliable framework for intrinsic tokenizer evaluations is developed, offering an efficient path for informed tokenizer selection in future language models."}}
{"id": "2506.02846", "pdf": "https://arxiv.org/pdf/2506.02846", "abs": "https://arxiv.org/abs/2506.02846", "authors": ["Yujin Chen", "Yinyu Nie", "Benjamin Ummenhofer", "Reiner Birkl", "Michael Paulitsch", "Matthias Nie\u00dfner"], "title": "PBR-SR: Mesh PBR Texture Super Resolution from 2D Image Priors", "categories": ["cs.CV"], "comment": "Project page: https://terencecyj.github.io/projects/PBR-SR/, Video:\n  https://youtu.be/eaM5S3Mt1RM", "summary": "We present PBR-SR, a novel method for physically based rendering (PBR)\ntexture super resolution (SR). It outputs high-resolution, high-quality PBR\ntextures from low-resolution (LR) PBR input in a zero-shot manner. PBR-SR\nleverages an off-the-shelf super-resolution model trained on natural images,\nand iteratively minimizes the deviations between super-resolution priors and\ndifferentiable renderings. These enhancements are then back-projected into the\nPBR map space in a differentiable manner to produce refined, high-resolution\ntextures. To mitigate view inconsistencies and lighting sensitivity, which is\ncommon in view-based super-resolution, our method applies 2D prior constraints\nacross multi-view renderings, iteratively refining the shared, upscaled\ntextures. In parallel, we incorporate identity constraints directly in the PBR\ntexture domain to ensure the upscaled textures remain faithful to the LR input.\nPBR-SR operates without any additional training or data requirements, relying\nentirely on pretrained image priors. We demonstrate that our approach produces\nhigh-fidelity PBR textures for both artist-designed and AI-generated meshes,\noutperforming both direct SR models application and prior texture optimization\nmethods. Our results show high-quality outputs in both PBR and rendering\nevaluations, supporting advanced applications such as relighting.", "AI": {"tldr": "PBR-SR is a zero-shot method for super-resolving PBR textures using pretrained image priors and iterative refinement, outperforming direct SR and prior methods.", "motivation": "To address the challenge of generating high-resolution PBR textures from low-resolution inputs without additional training or data.", "method": "Leverages pretrained SR models, iteratively minimizes deviations between SR priors and differentiable renderings, and applies multi-view constraints for consistency.", "result": "Produces high-fidelity PBR textures for artist-designed and AI-generated meshes, excelling in PBR and rendering evaluations.", "conclusion": "PBR-SR is effective for zero-shot PBR texture super-resolution, enabling advanced applications like relighting."}}
{"id": "2506.02897", "pdf": "https://arxiv.org/pdf/2506.02897", "abs": "https://arxiv.org/abs/2506.02897", "authors": ["Alessandro Licciardi", "Roberta Raineri", "Anton Proskurnikov", "Lamberto Rondoni", "Lorenzo Zino"], "title": "Sociodynamics-inspired Adaptive Coalition and Client Selection in Federated Learning", "categories": ["cs.LG"], "comment": null, "summary": "Federated Learning (FL) enables privacy-preserving collaborative model\ntraining, yet its practical strength is often undermined by client data\nheterogeneity, which severely degrades model performance. This paper proposes\nthat data heterogeneity across clients' distributions can be effectively\naddressed by adopting an approach inspired by opinion dynamics over temporal\nsocial networks. We introduce \\shortname (Federated Coalition Variance\nReduction with Boltzmann Exploration), a variance-reducing selection algorithm\nin which (1) clients dynamically organize into non-overlapping clusters based\non asymptotic agreements, and (2) from each cluster, one client is selected to\nminimize the expected variance of its model update. Our experiments show that\nin heterogeneous scenarios our algorithm outperforms existing FL algorithms,\nyielding more accurate results and faster convergence, validating the efficacy\nof our approach.", "AI": {"tldr": "Proposes a federated learning algorithm (Federated Coalition Variance Reduction with Boltzmann Exploration) to address data heterogeneity by clustering clients and selecting optimal updates, improving accuracy and convergence.", "motivation": "Data heterogeneity in federated learning degrades model performance, necessitating a solution to mitigate its impact.", "method": "Clients dynamically cluster based on agreements, and one client per cluster is selected to minimize update variance, inspired by opinion dynamics.", "result": "Outperforms existing FL algorithms in heterogeneous scenarios, achieving better accuracy and faster convergence.", "conclusion": "The proposed method effectively addresses data heterogeneity, enhancing federated learning performance."}}
{"id": "2506.02860", "pdf": "https://arxiv.org/pdf/2506.02860", "abs": "https://arxiv.org/abs/2506.02860", "authors": ["Wenjing Tang", "Xinyu He", "Yongxi Huang", "Yunxiao Xiao", "Cewu Lu", "Panpan Cai"], "title": "Tru-POMDP: Task Planning Under Uncertainty via Tree of Hypotheses and Open-Ended POMDPs", "categories": ["cs.RO", "cs.AI"], "comment": null, "summary": "Task planning under uncertainty is essential for home-service robots\noperating in the real world. Tasks involve ambiguous human instructions, hidden\nor unknown object locations, and open-vocabulary object types, leading to\nsignificant open-ended uncertainty and a boundlessly large planning space. To\naddress these challenges, we propose Tru-POMDP, a planner that combines\nstructured belief generation using Large Language Models (LLMs) with principled\nPOMDP planning. Tru-POMDP introduces a hierarchical Tree of Hypotheses (TOH),\nwhich systematically queries an LLM to construct high-quality particle beliefs\nover possible world states and human goals. We further formulate an open-ended\nPOMDP model that enables rigorous Bayesian belief tracking and efficient\nbelief-space planning over these LLM-generated hypotheses. Experiments on\ncomplex object rearrangement tasks across diverse kitchen environments show\nthat Tru-POMDP significantly outperforms state-of-the-art LLM-based and\nLLM-tree-search hybrid planners, achieving higher success rates with\nsignificantly better plans, stronger robustness to ambiguity and occlusion, and\ngreater planning efficiency.", "AI": {"tldr": "Tru-POMDP combines LLMs and POMDP planning for task planning under uncertainty, outperforming existing methods in success rates, robustness, and efficiency.", "motivation": "Addressing uncertainty in home-service robots due to ambiguous instructions, hidden objects, and open-vocabulary tasks.", "method": "Hierarchical Tree of Hypotheses (TOH) using LLMs for belief generation and open-ended POMDP for planning.", "result": "Higher success rates, better plans, robustness to ambiguity/occlusion, and improved efficiency compared to state-of-the-art planners.", "conclusion": "Tru-POMDP effectively tackles open-ended uncertainty in task planning for robots."}}
{"id": "2506.03106", "pdf": "https://arxiv.org/pdf/2506.03106", "abs": "https://arxiv.org/abs/2506.03106", "authors": ["Xiaoying Zhang", "Hao Sun", "Yipeng Zhang", "Kaituo Feng", "Chao Yang", "Helen Meng"], "title": "Critique-GRPO: Advancing LLM Reasoning with Natural Language and Numerical Feedback", "categories": ["cs.CL", "cs.AI"], "comment": "38 pages", "summary": "Recent advances in reinforcement learning (RL) with numerical feedback, such\nas scalar rewards, have significantly enhanced the complex reasoning\ncapabilities of large language models (LLMs). Despite this success, we identify\nthree key challenges encountered by RL with solely numerical feedback:\nperformance plateaus, limited effectiveness of self-reflection, and persistent\nfailures. We then demonstrate that RL-finetuned models, even after exhibiting\nperformance plateaus, can generate correct refinements on persistently failed\nproblems by leveraging natural language feedback in the form of critiques.\nBuilding on this insight, we propose Critique-GRPO, an online RL framework that\nintegrates both natural language and numerical feedback for effective policy\noptimization. Critique-GRPO enables LLMs to learn from initial responses and\ncritique-guided refinements simultaneously while maintaining exploration.\nExtensive experiments using Qwen2.5-7B-Base and Qwen3-8B-Base show that\nCritique-GRPO consistently outperforms supervised learning-based and RL-based\nfine-tuning approaches across eight challenging mathematical, STEM, and general\nreasoning tasks, improving average pass@1 scores by approximately 4.5% and 5%,\nrespectively. Notably, Critique-GRPO surpasses a strong baseline that\nincorporates expert demonstrations within online RL. Further analysis reveals\ntwo critical insights about policy exploration: (1) higher entropy does not\nalways guarantee efficient learning from exploration, and (2) longer responses\ndo not necessarily lead to more effective exploration.", "AI": {"tldr": "Critique-GRPO, an RL framework integrating natural language and numerical feedback, outperforms traditional methods in refining LLMs' reasoning tasks.", "motivation": "Addressing performance plateaus and persistent failures in RL with numerical feedback by leveraging natural language critiques.", "method": "Proposes Critique-GRPO, an online RL framework combining natural language critiques and numerical feedback for policy optimization.", "result": "Improves pass@1 scores by ~4.5-5% over baselines in mathematical and reasoning tasks.", "conclusion": "Natural language feedback enhances RL fine-tuning, with Critique-GRPO showing superior performance and insights on policy exploration."}}
{"id": "2506.02850", "pdf": "https://arxiv.org/pdf/2506.02850", "abs": "https://arxiv.org/abs/2506.02850", "authors": ["Mengyue Wang", "Shuo Chen", "Kristian Kersting", "Volker Tresp", "Yunpu Ma"], "title": "METok: Multi-Stage Event-based Token Compression for Efficient Long Video Understanding", "categories": ["cs.CV"], "comment": "14 pages, 10 figures", "summary": "Recent advances in Video Large Language Models (VLLMs) have significantly\nenhanced their ability to understand video content. Nonetheless, processing\nlong videos remains challenging due to high computational demands and the\nredundancy present in the visual data. In this work, we propose METok, a\ntraining-free, Multi-stage Event-based Token compression framework designed to\naccelerate VLLMs' inference while preserving accuracy. METok progressively\neliminates redundant visual tokens across three critical stages: (1)\nevent-aware compression during vision encoding, (2) hierarchical token pruning\nin the prefilling stage based on semantic alignment and event importance, and\n(3) a decoding-stage KV Cache optimization that further reduces memory\nconsumption. Our experiments on diverse video benchmarks demonstrate that METok\nachieves an optimal trade-off between efficiency and accuracy by dynamically\nselecting informative visual tokens. For instance, equipping LongVA-7B with\nMETok realizes an 80.6% FLOPs reduction and 93.5% KV Cache memory savings, all\nwhile maintaining comparable or even superior accuracy.", "AI": {"tldr": "METok is a training-free framework for compressing visual tokens in Video Large Language Models (VLLMs), improving efficiency without sacrificing accuracy.", "motivation": "Processing long videos in VLLMs is computationally intensive and redundant. METok aims to address these challenges by dynamically compressing visual tokens.", "method": "METok uses a multi-stage approach: (1) event-aware compression, (2) hierarchical token pruning, and (3) KV Cache optimization.", "result": "METok reduces FLOPs by 80.6% and KV Cache memory by 93.5% while maintaining accuracy.", "conclusion": "METok effectively balances efficiency and accuracy in VLLMs for long video processing."}}
{"id": "2506.02933", "pdf": "https://arxiv.org/pdf/2506.02933", "abs": "https://arxiv.org/abs/2506.02933", "authors": ["Junyi Fang", "Yuxun Chen", "Yuxin Chen", "Chen Zhang"], "title": "From Theory to Practice with RAVEN-UCB: Addressing Non-Stationarity in Multi-Armed Bandits through Variance Adaptation", "categories": ["cs.LG", "stat.ML", "I.2.6; I.2.8; G.3"], "comment": "25 pages, 5 figures, 4 tables, submitted to Applied Intelligence,\n  code available at https://github.com/66661654/Raven-UCB", "summary": "The Multi-Armed Bandit (MAB) problem is challenging in non-stationary\nenvironments where reward distributions evolve dynamically. We introduce\nRAVEN-UCB, a novel algorithm that combines theoretical rigor with practical\nefficiency via variance-aware adaptation. It achieves tighter regret bounds\nthan UCB1 and UCB-V, with gap-dependent regret of order $K \\sigma_{\\max}^2 \\log\nT / \\Delta$ and gap-independent regret of order $\\sqrt{K T \\log T}$. RAVEN-UCB\nincorporates three innovations: (1) variance-driven exploration using\n$\\sqrt{\\hat{\\sigma}_k^2 / (N_k + 1)}$ in confidence bounds, (2) adaptive\ncontrol via $\\alpha_t = \\alpha_0 / \\log(t + \\epsilon)$, and (3) constant-time\nrecursive updates for efficiency. Experiments across non-stationary patterns -\ndistributional changes, periodic shifts, and temporary fluctuations - in\nsynthetic and logistics scenarios demonstrate its superiority over\nstate-of-the-art baselines, confirming theoretical and practical robustness.", "AI": {"tldr": "RAVEN-UCB is a variance-aware MAB algorithm for non-stationary environments, outperforming UCB1 and UCB-V with tighter regret bounds and practical efficiency.", "motivation": "Addressing the challenge of non-stationary reward distributions in MAB problems.", "method": "Combines variance-driven exploration, adaptive control, and constant-time recursive updates.", "result": "Achieves tighter regret bounds and demonstrates robustness in synthetic and real-world scenarios.", "conclusion": "RAVEN-UCB is theoretically and practically superior to existing baselines in non-stationary settings."}}
{"id": "2506.03122", "pdf": "https://arxiv.org/pdf/2506.03122", "abs": "https://arxiv.org/abs/2506.03122", "authors": ["Prashanth Vijayaraghavan", "Luyao Shi", "Ehsan Degan", "Vandana Mukherjee", "Xin Zhang"], "title": "AUTOCIRCUIT-RL: Reinforcement Learning-Driven LLM for Automated Circuit Topology Generation", "categories": ["cs.CL"], "comment": "9 Pages (Content), 4 Pages (Appendix), 7 figures, ICML'2025", "summary": "Analog circuit topology synthesis is integral to Electronic Design Automation\n(EDA), enabling the automated creation of circuit structures tailored to\nspecific design requirements. However, the vast design search space and strict\nconstraint adherence make efficient synthesis challenging. Leveraging the\nversatility of Large Language Models (LLMs), we propose AUTOCIRCUIT-RL,a novel\nreinforcement learning (RL)-based framework for automated analog circuit\nsynthesis. The framework operates in two phases: instruction tuning, where an\nLLM learns to generate circuit topologies from structured prompts encoding\ndesign constraints, and RL refinement, which further improves the\ninstruction-tuned model using reward models that evaluate validity, efficiency,\nand output voltage. The refined model is then used directly to generate\ntopologies that satisfy the design constraints. Empirical results show that\nAUTOCIRCUIT-RL generates ~12% more valid circuits and improves efficiency by\n~14% compared to the best baselines, while reducing duplicate generation rates\nby ~38%. It achieves over 60% success in synthesizing valid circuits with\nlimited training data, demonstrating strong generalization. These findings\nhighlight the framework's effectiveness in scaling to complex circuits while\nmaintaining efficiency and constraint adherence, marking a significant\nadvancement in AI-driven circuit design.", "AI": {"tldr": "AUTOCIRCUIT-RL, an RL-based framework using LLMs, automates analog circuit synthesis, improving validity, efficiency, and reducing duplicates compared to baselines.", "motivation": "The vast design space and strict constraints in analog circuit synthesis make automation challenging, necessitating innovative solutions like AI-driven methods.", "method": "AUTOCIRCUIT-RL uses a two-phase approach: instruction tuning with LLMs to generate topologies from constraints, followed by RL refinement using reward models for validity, efficiency, and output voltage.", "result": "The framework generates 12% more valid circuits, improves efficiency by 14%, and reduces duplicates by 38%, achieving over 60% success with limited training data.", "conclusion": "AUTOCIRCUIT-RL advances AI-driven circuit design by effectively scaling to complex circuits while maintaining efficiency and constraint adherence."}}
{"id": "2506.02853", "pdf": "https://arxiv.org/pdf/2506.02853", "abs": "https://arxiv.org/abs/2506.02853", "authors": ["Mingjie Wei", "Xuemei Xie", "Yutong Zhong", "Guangming Shi"], "title": "Learning Pyramid-structured Long-range Dependencies for 3D Human Pose Estimation", "categories": ["cs.CV"], "comment": "Accepted by IEEE Transactions on Multimedia (TMM)", "summary": "Action coordination in human structure is indispensable for the spatial\nconstraints of 2D joints to recover 3D pose. Usually, action coordination is\nrepresented as a long-range dependence among body parts. However, there are two\nmain challenges in modeling long-range dependencies. First, joints should not\nonly be constrained by other individual joints but also be modulated by the\nbody parts. Second, existing methods make networks deeper to learn dependencies\nbetween non-linked parts. They introduce uncorrelated noise and increase the\nmodel size. In this paper, we utilize a pyramid structure to better learn\npotential long-range dependencies. It can capture the correlation across joints\nand groups, which complements the context of the human sub-structure. In an\neffective cross-scale way, it captures the pyramid-structured long-range\ndependence. Specifically, we propose a novel Pyramid Graph Attention (PGA)\nmodule to capture long-range cross-scale dependencies. It concatenates\ninformation from various scales into a compact sequence, and then computes the\ncorrelation between scales in parallel. Combining PGA with graph convolution\nmodules, we develop a Pyramid Graph Transformer (PGFormer) for 3D human pose\nestimation, which is a lightweight multi-scale transformer architecture. It\nencapsulates human sub-structures into self-attention by pooling. Extensive\nexperiments show that our approach achieves lower error and smaller model size\nthan state-of-the-art methods on Human3.6M and MPI-INF-3DHP datasets. The code\nis available at https://github.com/MingjieWe/PGFormer.", "AI": {"tldr": "The paper proposes a Pyramid Graph Transformer (PGFormer) for 3D human pose estimation, addressing challenges in modeling long-range dependencies among body parts with a lightweight, multi-scale architecture.", "motivation": "Existing methods struggle with modeling long-range dependencies in human pose estimation due to noise and large model sizes. The paper aims to improve this by capturing cross-scale correlations.", "method": "The authors introduce a Pyramid Graph Attention (PGA) module to capture long-range dependencies across scales, combined with graph convolution for a lightweight PGFormer architecture.", "result": "PGFormer achieves lower error and smaller model size compared to state-of-the-art methods on Human3.6M and MPI-INF-3DHP datasets.", "conclusion": "The proposed PGFormer effectively addresses the challenges of long-range dependency modeling in 3D pose estimation, offering a compact and efficient solution."}}
{"id": "2506.02935", "pdf": "https://arxiv.org/pdf/2506.02935", "abs": "https://arxiv.org/abs/2506.02935", "authors": ["Yuepeng Zheng", "Fu Luo", "Zhenkun Wang", "Yaoxin Wu", "Yu Zhou"], "title": "MTL-KD: Multi-Task Learning Via Knowledge Distillation for Generalizable Neural Vehicle Routing Solver", "categories": ["cs.LG"], "comment": "24 pages,5 figures, 8 tables", "summary": "Multi-Task Learning (MTL) in Neural Combinatorial Optimization (NCO) is a\npromising approach to train a unified model capable of solving multiple Vehicle\nRouting Problem (VRP) variants. However, existing Reinforcement Learning\n(RL)-based multi-task methods can only train light decoder models on\nsmall-scale problems, exhibiting limited generalization ability when solving\nlarge-scale problems. To overcome this limitation, this work introduces a novel\nmulti-task learning method driven by knowledge distillation (MTL-KD), which\nenables the efficient training of heavy decoder models with strong\ngeneralization ability. The proposed MTL-KD method transfers policy knowledge\nfrom multiple distinct RL-based single-task models to a single heavy decoder\nmodel, facilitating label-free training and effectively improving the model's\ngeneralization ability across diverse tasks. In addition, we introduce a\nflexible inference strategy termed Random Reordering Re-Construction (R3C),\nwhich is specifically adapted for diverse VRP tasks and further boosts the\nperformance of the multi-task model. Experimental results on 6 seen and 10\nunseen VRP variants with up to 1000 nodes indicate that our proposed method\nconsistently achieves superior performance on both uniform and real-world\nbenchmarks, demonstrating robust generalization abilities.", "AI": {"tldr": "A novel multi-task learning method (MTL-KD) using knowledge distillation trains heavy decoder models for solving diverse Vehicle Routing Problem (VRP) variants, outperforming existing methods.", "motivation": "Existing RL-based multi-task methods for Neural Combinatorial Optimization (NCO) lack generalization for large-scale problems, prompting the need for a more robust approach.", "method": "MTL-KD transfers policy knowledge from single-task models to a heavy decoder model, enabling label-free training. A flexible inference strategy (R3C) is also introduced for diverse VRP tasks.", "result": "The method achieves superior performance on 6 seen and 10 unseen VRP variants (up to 1000 nodes), showing strong generalization.", "conclusion": "MTL-KD with R3C effectively improves generalization and performance in multi-task learning for NCO, especially for large-scale VRP problems."}}
{"id": "2506.02950", "pdf": "https://arxiv.org/pdf/2506.02950", "abs": "https://arxiv.org/abs/2506.02950", "authors": ["Stepan I. Manukhov", "Alexander Kolesov", "Vladimir V. Palyulin", "Alexander Korotin"], "title": "Interaction Field Matching: Overcoming Limitations of Electrostatic Models", "categories": ["cs.LG", "cs.AI", "cs.CV"], "comment": null, "summary": "Electrostatic field matching (EFM) has recently appeared as a novel\nphysics-inspired paradigm for data generation and transfer using the idea of an\nelectric capacitor. However, it requires modeling electrostatic fields using\nneural networks, which is non-trivial because of the necessity to take into\naccount the complex field outside the capacitor plates. In this paper, we\npropose Interaction Field Matching (IFM), a generalization of EFM which allows\nusing general interaction fields beyond the electrostatic one. Furthermore,\ninspired by strong interactions between quarks and antiquarks in physics, we\ndesign a particular interaction field realization which solves the problems\nwhich arise when modeling electrostatic fields in EFM. We show the performance\non a series of toy and image data transfer problems.", "AI": {"tldr": "IFM generalizes EFM by using general interaction fields, solving EFM's issues with electrostatic field modeling. It demonstrates effectiveness in data transfer tasks.", "motivation": "EFM's reliance on electrostatic fields is complex due to external field modeling. IFM aims to simplify and generalize this approach.", "method": "Proposes IFM, extending EFM to general interaction fields, with a specific design inspired by quark-antiquark interactions.", "result": "Shows successful performance on toy and image data transfer problems.", "conclusion": "IFM effectively addresses EFM's limitations and generalizes the paradigm for broader applications."}}
{"id": "2506.03136", "pdf": "https://arxiv.org/pdf/2506.03136", "abs": "https://arxiv.org/abs/2506.03136", "authors": ["Yinjie Wang", "Ling Yang", "Ye Tian", "Ke Shen", "Mengdi Wang"], "title": "Co-Evolving LLM Coder and Unit Tester via Reinforcement Learning", "categories": ["cs.CL"], "comment": "Project: https://github.com/Gen-Verse/CURE", "summary": "We propose CURE, a novel reinforcement learning framework with a dedicated\nreward design that co-evolves coding and unit test generation capabilities\nbased on their interaction outcomes, without any ground-truth code as\nsupervision. This approach enables flexible and scalable training and allows\nthe unit tester to learn directly from the coder's mistakes. Our derived\nReasonFlux-Coder-7B and 14B models improve code generation accuracy by 5.3% and\nBest-of-N accuracy by 9.0% after optimization on Qwen2.5-Instruct models,\noutperforming similarly sized Qwen-Coder, DeepSeek-Coder, and Seed-Coder. They\nnaturally extend to downstream tasks such as test-time scaling and agentic\ncoding-achieving a 8.1% improvement over the base model. For the long-CoT\nmodel, our ReasonFlux-Coder-4B consistently outperforms Qwen3-4B while\nachieving 64.8% inference efficiency in unit test generation. Notably, we also\nfind that our model can serve as an effective reward model for reinforcement\nlearning on base models. Project: https://github.com/Gen-Verse/CURE", "AI": {"tldr": "CURE is a reinforcement learning framework for co-evolving coding and unit test generation, improving accuracy and efficiency without ground-truth supervision.", "motivation": "To enable flexible and scalable training by allowing unit testers to learn from coder mistakes without relying on ground-truth code.", "method": "Uses a dedicated reward design in reinforcement learning to co-evolve coding and unit test generation capabilities.", "result": "Achieves 5.3% better code generation accuracy and 9.0% Best-of-N accuracy, outperforming competitors like Qwen-Coder and DeepSeek-Coder.", "conclusion": "CURE effectively improves coding and testing performance, extends to downstream tasks, and can serve as a reward model for reinforcement learning."}}
{"id": "2506.02854", "pdf": "https://arxiv.org/pdf/2506.02854", "abs": "https://arxiv.org/abs/2506.02854", "authors": ["Mengmeng Zhang", "Xingyuan Dai", "Yicheng Sun", "Jing Wang", "Yueyang Yao", "Xiaoyan Gong", "Fuze Cong", "Feiyue Wang", "Yisheng Lv"], "title": "Hierarchical Self-Prompting SAM: A Prompt-Free Medical Image Segmentation Framework", "categories": ["cs.CV"], "comment": null, "summary": "Although the Segment Anything Model (SAM) is highly effective in natural\nimage segmentation, it requires dependencies on prompts, which limits its\napplicability to medical imaging where manual prompts are often unavailable.\nExisting efforts to fine-tune SAM for medical segmentation typically struggle\nto remove this dependency. We propose Hierarchical Self-Prompting SAM\n(HSP-SAM), a novel self-prompting framework that enables SAM to achieve strong\nperformance in prompt-free medical image segmentation. Unlike previous\nself-prompting methods that remain limited to positional prompts similar to\nvanilla SAM, we are the first to introduce learning abstract prompts during the\nself-prompting process. This simple and intuitive self-prompting framework\nachieves superior performance on classic segmentation tasks such as polyp and\nskin lesion segmentation, while maintaining robustness across diverse medical\nimaging modalities. Furthermore, it exhibits strong generalization to unseen\ndatasets, achieving improvements of up to 14.04% over previous state-of-the-art\nmethods on some challenging benchmarks. These results suggest that abstract\nprompts encapsulate richer and higher-dimensional semantic information compared\nto positional prompts, thereby enhancing the model's robustness and\ngeneralization performance. All models and codes will be released upon\nacceptance.", "AI": {"tldr": "HSP-SAM is a self-prompting framework for medical image segmentation, eliminating the need for manual prompts and outperforming existing methods.", "motivation": "SAM's dependency on prompts limits its use in medical imaging where manual prompts are unavailable.", "method": "Proposes HSP-SAM, introducing abstract prompts during self-prompting, unlike previous positional prompt methods.", "result": "Achieves superior performance, up to 14.04% improvement over state-of-the-art, and strong generalization across modalities.", "conclusion": "Abstract prompts enhance robustness and generalization, making HSP-SAM effective for prompt-free medical segmentation."}}
{"id": "2506.02939", "pdf": "https://arxiv.org/pdf/2506.02939", "abs": "https://arxiv.org/abs/2506.02939", "authors": ["Malik Khalaf", "Yara Shamshoum", "Nitzan Hodos", "Yuval Sieradzki", "Assaf Schuster"], "title": "QKV Projections Require a Fraction of Their Memory", "categories": ["cs.LG"], "comment": null, "summary": "The Multi-Head Attention mechanism is central to LLM operation, and multiple\nworks target its compute and memory efficiency during training. While most\nworks focus on approximating the scaled dot product, the memory consumption of\nthe linear projections that compute the $Q$, $K$, and $V$ tensors from the\ninput $x$ is often overlooked. To address this, we propose Point-Approximate\nMatrix Multiplication (PAMM), a novel tensor compression technique that reduces\nmemory consumption of the $Q,K,V$ projections in attention layers by a factor\nof up to $\\times 512$, effectively erasing their memory footprint, while\nachieving similar or better final perplexity. PAMM is fully composable with\nefficient attention techniques such as FlashAttention, making it a practical\nand complementary method for memory-efficient LLM training.", "AI": {"tldr": "PAMM reduces memory usage in LLM attention layers by compressing Q, K, V projections, achieving up to 512x memory savings without compromising perplexity.", "motivation": "Addressing overlooked memory consumption in linear projections of attention layers, which impacts LLM training efficiency.", "method": "Proposes Point-Approximate Matrix Multiplication (PAMM), a tensor compression technique for Q, K, V projections.", "result": "Achieves up to 512x memory reduction while maintaining or improving perplexity.", "conclusion": "PAMM is a practical, complementary method for memory-efficient LLM training, compatible with techniques like FlashAttention."}}
{"id": "2506.02955", "pdf": "https://arxiv.org/pdf/2506.02955", "abs": "https://arxiv.org/abs/2506.02955", "authors": ["Zewen Yang", "Xiaobing Dai", "Dian Yu", "Qianru Li", "Yu Li", "Valentin Le Mesle"], "title": "UniConFlow: A Unified Constrained Generalization Framework for Certified Motion Planning with Flow Matching Models", "categories": ["cs.RO", "cs.AI", "cs.LG"], "comment": null, "summary": "Generative models have become increasingly powerful tools for robot motion\ngeneration, enabling flexible and multimodal trajectory generation across\nvarious tasks. Yet, most existing approaches remain limited in handling\nmultiple types of constraints, such as collision avoidance and dynamic\nconsistency, which are often treated separately or only partially considered.\nThis paper proposes UniConFlow, a unified flow matching (FM) based framework\nfor trajectory generation that systematically incorporates both equality and\ninequality constraints. UniConFlow introduces a novel prescribed-time zeroing\nfunction to enhance flexibility during the inference process, allowing the\nmodel to adapt to varying task requirements. To ensure constraint satisfaction,\nparticularly with respect to obstacle avoidance, admissible action range, and\nkinodynamic consistency, the guidance inputs to the FM model are derived\nthrough a quadratic programming formulation, which enables constraint-aware\ngeneration without requiring retraining or auxiliary controllers. We conduct\nmobile navigation and high-dimensional manipulation tasks, demonstrating\nimproved safety and feasibility compared to state-of-the-art constrained\ngenerative planners. Project page is available at https://uniconflow.github.io.", "AI": {"tldr": "UniConFlow is a unified flow matching framework for robot trajectory generation that systematically handles equality and inequality constraints, improving safety and feasibility.", "motivation": "Existing generative models for robot motion often fail to fully integrate multiple constraints like collision avoidance and dynamic consistency.", "method": "UniConFlow uses a flow matching framework with a prescribed-time zeroing function and quadratic programming for constraint-aware guidance.", "result": "The method outperforms state-of-the-art planners in mobile navigation and high-dimensional manipulation tasks.", "conclusion": "UniConFlow provides a robust, constraint-aware solution for flexible and safe robot trajectory generation."}}
{"id": "2506.03143", "pdf": "https://arxiv.org/pdf/2506.03143", "abs": "https://arxiv.org/abs/2506.03143", "authors": ["Qianhui Wu", "Kanzhi Cheng", "Rui Yang", "Chaoyun Zhang", "Jianwei Yang", "Huiqiang Jiang", "Jian Mu", "Baolin Peng", "Bo Qiao", "Reuben Tan", "Si Qin", "Lars Liden", "Qingwei Lin", "Huan Zhang", "Tong Zhang", "Jianbing Zhang", "Dongmei Zhang", "Jianfeng Gao"], "title": "GUI-Actor: Coordinate-Free Visual Grounding for GUI Agents", "categories": ["cs.CL", "cs.AI", "cs.CV"], "comment": null, "summary": "One of the principal challenges in building VLM-powered GUI agents is visual\ngrounding, i.e., localizing the appropriate screen region for action execution\nbased on both the visual content and the textual plans. Most existing work\nformulates this as a text-based coordinate generation task. However, these\napproaches suffer from several limitations: weak spatial-semantic alignment,\ninability to handle ambiguous supervision targets, and a mismatch between the\ndense nature of screen coordinates and the coarse, patch-level granularity of\nvisual features extracted by models like Vision Transformers. In this paper, we\npropose GUI-Actor, a VLM-based method for coordinate-free GUI grounding. At its\ncore, GUI-Actor introduces an attention-based action head that learns to align\na dedicated <ACTOR> token with all relevant visual patch tokens, enabling the\nmodel to propose one or more action regions in a single forward pass. In line\nwith this, we further design a grounding verifier to evaluate and select the\nmost plausible action region from the candidates proposed for action execution.\nExtensive experiments show that GUI-Actor outperforms prior state-of-the-art\nmethods on multiple GUI action grounding benchmarks, with improved\ngeneralization to unseen screen resolutions and layouts. Notably, GUI-Actor-7B\neven surpasses UI-TARS-72B (38.1) on ScreenSpot-Pro, achieving scores of 40.7\nwith Qwen2-VL and 44.6 with Qwen2.5-VL as backbones. Furthermore, by\nincorporating the verifier, we find that fine-tuning only the newly introduced\naction head (~100M parameters for 7B model) while keeping the VLM backbone\nfrozen is sufficient to achieve performance comparable to previous\nstate-of-the-art models, highlighting that GUI-Actor can endow the underlying\nVLM with effective grounding capabilities without compromising its\ngeneral-purpose strengths.", "AI": {"tldr": "GUI-Actor is a VLM-based method for coordinate-free GUI grounding, using an attention-based action head and grounding verifier to outperform existing methods.", "motivation": "Addressing limitations of text-based coordinate generation in GUI agents, such as weak spatial-semantic alignment and handling ambiguous targets.", "method": "Introduces an attention-based action head aligning a dedicated <ACTOR> token with visual patches and a grounding verifier to select action regions.", "result": "Outperforms state-of-the-art methods on benchmarks, achieving scores of 40.7 and 44.6 with different backbones, and shows improved generalization.", "conclusion": "GUI-Actor effectively endows VLMs with grounding capabilities without compromising their general-purpose strengths, even with minimal fine-tuning."}}
{"id": "2506.02857", "pdf": "https://arxiv.org/pdf/2506.02857", "abs": "https://arxiv.org/abs/2506.02857", "authors": ["Luca Maiano", "Fabrizio Casadei", "Irene Amerini"], "title": "Enhancing Abnormality Identification: Robust Out-of-Distribution Strategies for Deepfake Detection", "categories": ["cs.CV"], "comment": null, "summary": "Detecting deepfakes has become a critical challenge in Computer Vision and\nArtificial Intelligence. Despite significant progress in detection techniques,\ngeneralizing them to open-set scenarios continues to be a persistent\ndifficulty. Neural networks are often trained on the closed-world assumption,\nbut with new generative models constantly evolving, it is inevitable to\nencounter data generated by models that are not part of the training\ndistribution. To address these challenges, in this paper, we propose two novel\nOut-Of-Distribution (OOD) detection approaches. The first approach is trained\nto reconstruct the input image, while the second incorporates an attention\nmechanism for detecting OODs. Our experiments validate the effectiveness of the\nproposed approaches compared to existing state-of-the-art techniques. Our\nmethod achieves promising results in deepfake detection and ranks among the\ntop-performing configurations on the benchmark, demonstrating their potential\nfor robust, adaptable solutions in dynamic, real-world applications.", "AI": {"tldr": "The paper proposes two novel OOD detection methods for deepfake detection, focusing on reconstruction and attention mechanisms, showing promising results.", "motivation": "Addressing the challenge of generalizing deepfake detection to open-set scenarios, where training data may not cover all generative models.", "method": "Two OOD detection approaches: one using input image reconstruction and another incorporating an attention mechanism.", "result": "The methods outperform existing techniques, achieving top performance on benchmarks.", "conclusion": "The proposed approaches offer robust and adaptable solutions for real-world deepfake detection."}}
{"id": "2506.02946", "pdf": "https://arxiv.org/pdf/2506.02946", "abs": "https://arxiv.org/abs/2506.02946", "authors": ["Edoardo Pona", "Milad Kazemi", "Yali Du", "David Watson", "Nicola Paoletti"], "title": "Abstract Counterfactuals for Language Model Agents", "categories": ["cs.LG"], "comment": null, "summary": "Counterfactual inference is a powerful tool for analysing and evaluating\nautonomous agents, but its application to language model (LM) agents remains\nchallenging. Existing work on counterfactuals in LMs has primarily focused on\ntoken-level counterfactuals, which are often inadequate for LM agents due to\ntheir open-ended action spaces. Unlike traditional agents with fixed, clearly\ndefined action spaces, the actions of LM agents are often implicit in the\nstrings they output, making their action spaces difficult to define and\ninterpret. Furthermore, the meanings of individual tokens can shift depending\non the context, adding complexity to token-level reasoning and sometimes\nleading to biased or meaningless counterfactuals. We introduce \\emph{Abstract\nCounterfactuals}, a framework that emphasises high-level characteristics of\nactions and interactions within an environment, enabling counterfactual\nreasoning tailored to user-relevant features. Our experiments demonstrate that\nthe approach produces consistent and meaningful counterfactuals while\nminimising the undesired side effects of token-level methods. We conduct\nexperiments on text-based games and counterfactual text generation, while\nconsidering both token-level and latent-space interventions.", "AI": {"tldr": "The paper introduces Abstract Counterfactuals, a framework for counterfactual reasoning in language model agents, addressing limitations of token-level methods.", "motivation": "Existing token-level counterfactuals are inadequate for LM agents due to open-ended action spaces and contextual token meanings, leading to biased or meaningless results.", "method": "The proposed framework, Abstract Counterfactuals, focuses on high-level action characteristics and interactions, tested on text-based games and counterfactual text generation with token-level and latent-space interventions.", "result": "The approach produces consistent and meaningful counterfactuals while minimizing side effects of token-level methods.", "conclusion": "Abstract Counterfactuals offer a tailored solution for counterfactual reasoning in LM agents, improving interpretability and reducing bias."}}
{"id": "2506.02975", "pdf": "https://arxiv.org/pdf/2506.02975", "abs": "https://arxiv.org/abs/2506.02975", "authors": ["Yicheng Xiao", "Lin Song", "Rui Yang", "Cheng Cheng", "Zunnan Xu", "Zhaoyang Zhang", "Yixiao Ge", "Xiu Li", "Ying Shan"], "title": "HaploOmni: Unified Single Transformer for Multimodal Video Understanding and Generation", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "With the advancement of language models, unified multimodal understanding and\ngeneration have made significant strides, with model architectures evolving\nfrom separated components to unified single-model frameworks. This paper\nexplores an efficient training paradigm to build a single transformer for\nunified multimodal understanding and generation. Specifically, we propose a\nmultimodal warmup strategy utilizing prior knowledge to extend capabilities. To\naddress cross-modal compatibility challenges, we introduce feature pre-scaling\nand multimodal AdaLN techniques. Integrating the proposed technologies, we\npresent the HaploOmni, a new single multimodal transformer. With limited\ntraining costs, HaploOmni achieves competitive performance across multiple\nimage and video understanding and generation benchmarks over advanced unified\nmodels. All codes will be made public at https://github.com/Tencent/HaploVLM.", "AI": {"tldr": "The paper introduces HaploOmni, a single transformer for unified multimodal tasks, using efficient training techniques like multimodal warmup and feature pre-scaling to achieve competitive performance.", "motivation": "To advance unified multimodal understanding and generation by developing a single-model framework with efficient training methods.", "method": "Proposes multimodal warmup, feature pre-scaling, and multimodal AdaLN techniques to train HaploOmni, a single transformer model.", "result": "HaploOmni achieves competitive performance in image and video tasks with limited training costs.", "conclusion": "The proposed methods enable efficient training of a unified multimodal transformer, with public code availability."}}
{"id": "2506.03145", "pdf": "https://arxiv.org/pdf/2506.03145", "abs": "https://arxiv.org/abs/2506.03145", "authors": ["Pralaypati Ta", "Sriram Venkatesaperumal", "Keerthi Ram", "Mohanasankar Sivaprakasam"], "title": "Entity-Augmented Neuroscience Knowledge Retrieval Using Ontology and Semantic Understanding Capability of LLM", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Neuroscience research publications encompass a vast wealth of knowledge.\nAccurately retrieving existing information and discovering new insights from\nthis extensive literature is essential for advancing the field. However, when\nknowledge is dispersed across multiple sources, current state-of-the-art\nretrieval methods often struggle to extract the necessary information. A\nknowledge graph (KG) can integrate and link knowledge from multiple sources,\nbut existing methods for constructing KGs in neuroscience often rely on labeled\ndata and require domain expertise. Acquiring large-scale, labeled data for a\nspecialized area like neuroscience presents significant challenges. This work\nproposes novel methods for constructing KG from unlabeled large-scale\nneuroscience research corpus utilizing large language models (LLM),\nneuroscience ontology, and text embeddings. We analyze the semantic relevance\nof neuroscience text segments identified by LLM for building the knowledge\ngraph. We also introduce an entity-augmented information retrieval algorithm to\nextract knowledge from the KG. Several experiments were conducted to evaluate\nthe proposed approaches, and the results demonstrate that our methods\nsignificantly enhance knowledge discovery from the unlabeled neuroscience\nresearch corpus. It achieves an F1 score of 0.84 for entity extraction, and the\nknowledge obtained from the KG improves answers to over 54% of the questions.", "AI": {"tldr": "Proposes novel methods for constructing a neuroscience knowledge graph (KG) from unlabeled text using LLMs, ontology, and embeddings, improving knowledge discovery.", "motivation": "Current retrieval methods struggle with dispersed neuroscience knowledge; labeled data is scarce.", "method": "Uses LLMs, neuroscience ontology, and text embeddings to build KG; introduces entity-augmented retrieval.", "result": "Achieves 0.84 F1 for entity extraction; KG improves answers to 54% of questions.", "conclusion": "Methods enhance knowledge discovery from unlabeled neuroscience literature."}}
{"id": "2506.02866", "pdf": "https://arxiv.org/pdf/2506.02866", "abs": "https://arxiv.org/abs/2506.02866", "authors": ["Ahsan Baidar Bakht", "Muhayy Ud Din", "Sajid Javed", "Irfan Hussain"], "title": "MVTD: A Benchmark Dataset for Maritime Visual Object Tracking", "categories": ["cs.CV"], "comment": "Submited to Nature Scientific Data", "summary": "Visual Object Tracking (VOT) is a fundamental task with widespread\napplications in autonomous navigation, surveillance, and maritime robotics.\nDespite significant advances in generic object tracking, maritime environments\ncontinue to present unique challenges, including specular water reflections,\nlow-contrast targets, dynamically changing backgrounds, and frequent\nocclusions. These complexities significantly degrade the performance of\nstate-of-the-art tracking algorithms, highlighting the need for domain-specific\ndatasets. To address this gap, we introduce the Maritime Visual Tracking\nDataset (MVTD), a comprehensive and publicly available benchmark specifically\ndesigned for maritime VOT. MVTD comprises 182 high-resolution video sequences,\ntotaling approximately 150,000 frames, and includes four representative object\nclasses: boat, ship, sailboat, and unmanned surface vehicle (USV). The dataset\ncaptures a diverse range of operational conditions and maritime scenarios,\nreflecting the real-world complexities of maritime environments. We evaluated\n14 recent SOTA tracking algorithms on the MVTD benchmark and observed\nsubstantial performance degradation compared to their performance on\ngeneral-purpose datasets. However, when fine-tuned on MVTD, these models\ndemonstrate significant performance gains, underscoring the effectiveness of\ndomain adaptation and the importance of transfer learning in specialized\ntracking contexts. The MVTD dataset fills a critical gap in the visual tracking\ncommunity by providing a realistic and challenging benchmark for maritime\nscenarios. Dataset and Source Code can be accessed here\n\"https://github.com/AhsanBaidar/MVTD\".", "AI": {"tldr": "The paper introduces the Maritime Visual Tracking Dataset (MVTD) to address challenges in maritime VOT, showing performance gains when SOTA trackers are fine-tuned on it.", "motivation": "Maritime environments pose unique challenges like reflections and occlusions, degrading existing tracking algorithms, necessitating a domain-specific dataset.", "method": "MVTD includes 182 high-resolution videos (150,000 frames) of four maritime object classes, capturing diverse real-world conditions.", "result": "Evaluation of 14 SOTA trackers on MVTD showed performance drops compared to general datasets, but fine-tuning improved results significantly.", "conclusion": "MVTD fills a critical gap, proving the value of domain adaptation and transfer learning for maritime VOT."}}
{"id": "2506.02965", "pdf": "https://arxiv.org/pdf/2506.02965", "abs": "https://arxiv.org/abs/2506.02965", "authors": ["Ze Yu Zhang", "Bolin Ding", "Bryan Kian Hsiang Low"], "title": "Memory-Efficient and Privacy-Preserving Collaborative Training for Mixture-of-Experts LLMs", "categories": ["cs.LG"], "comment": "20 pages, 4 figures,", "summary": "Mixture-of-Experts (MoE) has been gaining popularity due to its successful\nadaptation to large language models (LLMs). In this work, we introduce\nPrivacy-preserving Collaborative Mixture-of-Experts (PC-MoE), which leverages\nthe sparsity of the MoE architecture for memory-efficient decentralized\ncollaborative LLM training, enabling multiple parties with limited GPU-memory\nand data resources to collectively train more capable LLMs than they could\nachieve individually. At the same time, this approach protects training data\nprivacy of each participant by keeping training data, as well as parts of the\nforward pass signal and gradients locally within each party. By design, PC-MoE\nsynergistically combines the strengths of distributed computation with strong\nconfidentiality assurances. Unlike most privacy-preserving schemes, which pay\nfor confidentiality with lower task accuracy, our framework breaks that\ntrade-off: across seven popular LLM benchmarks, it almost matches (and\nsometimes exceeds) the performance and convergence rate of a fully centralized\nmodel, enjoys near 70% peak GPU RAM reduction, while being fully robust against\nreconstruction attacks.", "AI": {"tldr": "PC-MoE enables decentralized, privacy-preserving collaborative LLM training with minimal GPU memory and strong confidentiality, matching centralized model performance.", "motivation": "To address the challenges of limited GPU memory and data resources while ensuring training data privacy in collaborative LLM training.", "method": "Leverages MoE sparsity for memory efficiency and keeps data, forward pass signals, and gradients local to protect privacy.", "result": "Matches centralized model performance on benchmarks, reduces GPU RAM by 70%, and resists reconstruction attacks.", "conclusion": "PC-MoE breaks the trade-off between privacy and accuracy, offering efficient, secure collaborative training."}}
{"id": "2506.02976", "pdf": "https://arxiv.org/pdf/2506.02976", "abs": "https://arxiv.org/abs/2506.02976", "authors": ["Rachid Zeghlache", "Ikram Brahim", "Pierre-Henri Conze", "Mathieu Lamard", "Mohammed El Amine Lazouni", "Zineb Aziza Elaouaber", "Leila Ryma Lazouni", "Christopher Nielsen", "Ahmad O. Ahsan", "Matthias Wilms", "Nils D. Forkert", "Lovre Antonio Budimir", "Ivana Matovinovi\u0107", "Donik Vr\u0161nak", "Sven Lon\u010dari\u0107", "Philippe Zhang", "Weili Jiang", "Yihao Li", "Yiding Hao", "Markus Frohmann", "Patrick Binder", "Marcel Huber", "Taha Emre", "Teresa Finisterra Ara\u00fajo", "Marzieh Oghbaie", "Hrvoje Bogunovi\u0107", "Amerens A. Bekkers", "Nina M. van Liebergen", "Hugo J. Kuijf", "Abdul Qayyum", "Moona Mazher", "Steven A. Niederer", "Alberto J. Beltr\u00e1n-Carrero", "Juan J. G\u00f3mez-Valverde", "Javier Torresano-Rodr\u00edquez", "\u00c1lvaro Caballero-Sastre", "Mar\u00eda J. Ledesma Carbayo", "Yosuke Yamagishi", "Yi Ding", "Robin Peretzke", "Alexandra Ertl", "Maximilian Fischer", "Jessica K\u00e4chele", "Sofiane Zehar", "Karim Boukli Hacene", "Thomas Monfort", "B\u00e9atrice Cochener", "Mostafa El Habib Daho", "Anas-Alexis Benyoussef", "Gwenol\u00e9 Quellec"], "title": "Deep Learning for Retinal Degeneration Assessment: A Comprehensive Analysis of the MARIO AMD Progression Challenge", "categories": ["cs.CV", "cs.AI"], "comment": "MARIO-MICCAI-CHALLENGE 2024", "summary": "The MARIO challenge, held at MICCAI 2024, focused on advancing the automated\ndetection and monitoring of age-related macular degeneration (AMD) through the\nanalysis of optical coherence tomography (OCT) images. Designed to evaluate\nalgorithmic performance in detecting neovascular activity changes within AMD,\nthe challenge incorporated unique multi-modal datasets. The primary dataset,\nsourced from Brest, France, was used by participating teams to train and test\ntheir models. The final ranking was determined based on performance on this\ndataset. An auxiliary dataset from Algeria was used post-challenge to evaluate\npopulation and device shifts from submitted solutions. Two tasks were involved\nin the MARIO challenge. The first one was the classification of evolution\nbetween two consecutive 2D OCT B-scans. The second one was the prediction of\nfuture AMD evolution over three months for patients undergoing anti-vascular\nendothelial growth factor (VEGF) therapy. Thirty-five teams participated, with\nthe top 12 finalists presenting their methods. This paper outlines the\nchallenge's structure, tasks, data characteristics, and winning methodologies,\nsetting a benchmark for AMD monitoring using OCT, infrared imaging, and\nclinical data (such as the number of visits, age, gender, etc.). The results of\nthis challenge indicate that artificial intelligence (AI) performs as well as a\nphysician in measuring AMD progression (Task 1) but is not yet able of\npredicting future evolution (Task 2).", "AI": {"tldr": "The MARIO challenge at MICCAI 2024 evaluated AI models for AMD detection using OCT images, with tasks on classifying AMD progression and predicting future evolution. AI matched physician performance in detection but lagged in prediction.", "motivation": "To advance automated AMD detection and monitoring using AI, addressing gaps in neovascular activity tracking and multi-modal data analysis.", "method": "Teams trained and tested models on a primary dataset from Brest, France, with an auxiliary Algerian dataset for post-challenge evaluation. Tasks included classifying AMD progression and predicting future evolution.", "result": "AI performed comparably to physicians in detecting AMD progression (Task 1) but struggled with predicting future evolution (Task 2).", "conclusion": "The challenge set benchmarks for AMD monitoring, highlighting AI's current strengths and limitations in clinical applications."}}
{"id": "2506.03149", "pdf": "https://arxiv.org/pdf/2506.03149", "abs": "https://arxiv.org/abs/2506.03149", "authors": ["Pietro Lesci", "Clara Meister", "Thomas Hofmann", "Andreas Vlachos", "Tiago Pimentel"], "title": "Causal Estimation of Tokenisation Bias", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "Published as a conference paper at ACL 2025", "summary": "Modern language models are typically trained over subword sequences, but\nultimately define probabilities over character-strings. Ideally, the choice of\nthe tokeniser -- which maps character-strings to subwords -- should not affect\nthe probability assigned to the underlying character-string; in practice, it\ndoes. We define this mismatch as tokenisation bias. In this work, we quantify\none particular type of tokenisation bias: the effect of including or not a\nsubword (e.g., $\\langle hello \\rangle$) in a tokeniser's vocabulary on the\nprobability a trained model assigns to the corresponding characters (i.e.,\n\\textit{``hello''}). Estimating this effect is challenging because each model\nis trained with only one tokeniser. We address this by framing tokenisation\nbias as a causal effect and estimating it using the regression discontinuity\ndesign. Specifically, we exploit the fact that tokenisation algorithms rank\nsubwords and add the first $K$ to a tokeniser's vocabulary, where $K$ is an\narbitrary cutoff point. As such, we can estimate a causal effect by comparing\nsimilar subwords around this cutoff. Experimentally, we find that tokenisation\nconsistently affects models' outputs across scales, vocabularies, and\ntokenisers. Notably, a subword's presence in a small model's vocabulary may\nincrease its characters' probability by up to 17 times, highlighting\ntokenisation as a key design choice in language modelling.", "AI": {"tldr": "The paper investigates tokenisation bias in language models, showing how the inclusion or exclusion of subwords in a tokeniser's vocabulary affects the probability assigned to character-strings.", "motivation": "To quantify the impact of tokenisation choices on model outputs, as current practices introduce bias despite the ideal of invariance.", "method": "Frames tokenisation bias as a causal effect and estimates it using regression discontinuity design, comparing subwords around vocabulary cutoff points.", "result": "Tokenisation significantly affects model outputs, with subword presence increasing character probabilities by up to 17 times in small models.", "conclusion": "Tokenisation is a critical design choice in language modelling, with measurable biases that impact model behavior."}}
{"id": "2506.02868", "pdf": "https://arxiv.org/pdf/2506.02868", "abs": "https://arxiv.org/abs/2506.02868", "authors": ["Amal S. Perera", "David Fernandez", "Chandi Witharana", "Elias Manos", "Michael Pimenta", "Anna K. Liljedahl", "Ingmar Nitze", "Yili Yang", "Todd Nicholson", "Chia-Yu Hsu", "Wenwen Li", "Guido Grosse"], "title": "Pan-Arctic Permafrost Landform and Human-built Infrastructure Feature Detection with Vision Transformers and Location Embeddings", "categories": ["cs.CV", "I.4.6; I.5.4; I.5.2; I.2.10"], "comment": "20 pages, 2 column IEEE format, 13 Figures", "summary": "Accurate mapping of permafrost landforms, thaw disturbances, and human-built\ninfrastructure at pan-Arctic scale using sub-meter satellite imagery is\nincreasingly critical. Handling petabyte-scale image data requires\nhigh-performance computing and robust feature detection models. While\nconvolutional neural network (CNN)-based deep learning approaches are widely\nused for remote sensing (RS),similar to the success in transformer based large\nlanguage models, Vision Transformers (ViTs) offer advantages in capturing\nlong-range dependencies and global context via attention mechanisms. ViTs\nsupport pretraining via self-supervised learning-addressing the common\nlimitation of labeled data in Arctic feature detection and outperform CNNs on\nbenchmark datasets. Arctic also poses challenges for model generalization,\nespecially when features with the same semantic class exhibit diverse spectral\ncharacteristics. To address these issues for Arctic feature detection, we\nintegrate geospatial location embeddings into ViTs to improve adaptation across\nregions. This work investigates: (1) the suitability of pre-trained ViTs as\nfeature extractors for high-resolution Arctic remote sensing tasks, and (2) the\nbenefit of combining image and location embeddings. Using previously published\ndatasets for Arctic feature detection, we evaluate our models on three\ntasks-detecting ice-wedge polygons (IWP), retrogressive thaw slumps (RTS), and\nhuman-built infrastructure. We empirically explore multiple configurations to\nfuse image embeddings and location embeddings. Results show that ViTs with\nlocation embeddings outperform prior CNN-based models on two of the three tasks\nincluding F1 score increase from 0.84 to 0.92 for RTS detection, demonstrating\nthe potential of transformer-based models with spatial awareness for Arctic RS\napplications.", "AI": {"tldr": "The paper explores using Vision Transformers (ViTs) with geospatial location embeddings for Arctic feature detection, outperforming CNNs in tasks like detecting thaw slumps and infrastructure.", "motivation": "Accurate mapping of Arctic permafrost and infrastructure is critical, but challenges include handling large-scale data and diverse spectral characteristics of features.", "method": "The study integrates geospatial location embeddings into ViTs to improve adaptation across regions, evaluating their performance on detecting ice-wedge polygons, thaw slumps, and infrastructure.", "result": "ViTs with location embeddings outperform CNNs, achieving an F1 score increase from 0.84 to 0.92 for retrogressive thaw slump detection.", "conclusion": "Transformer-based models with spatial awareness show promise for high-resolution Arctic remote sensing tasks."}}
{"id": "2506.02972", "pdf": "https://arxiv.org/pdf/2506.02972", "abs": "https://arxiv.org/abs/2506.02972", "authors": ["Md-Ferdous Pervej", "Richeng Jin", "Md Moin Uddin Chowdhury", "Simran Singh", "\u0130smail G\u00fcven\u00e7", "Huaiyu Dai"], "title": "Computation- and Communication-Efficient Online FL for Resource-Constrained Aerial Vehicles", "categories": ["cs.LG", "cs.NI", "cs.SY", "eess.SY"], "comment": null, "summary": "Privacy-preserving distributed machine learning (ML) and aerial connected\nvehicle (ACV)-assisted edge computing have drawn significant attention lately.\nSince the onboard sensors of ACVs can capture new data as they move along their\ntrajectories, the continual arrival of such 'newly' sensed data leads to online\nlearning and demands carefully crafting the trajectories. Besides, as typical\nACVs are inherently resource-constrained, computation- and\ncommunication-efficient ML solutions are needed. Therefore, we propose a\ncomputation- and communication-efficient online aerial federated learning\n(2CEOAFL) algorithm to take the benefits of continual sensed data and limited\nonboard resources of the ACVs. In particular, considering independently owned\nACVs act as selfish data collectors, we first model their trajectories\naccording to their respective time-varying data distributions. We then propose\na 2CEOAFL algorithm that allows the flying ACVs to (a) prune the received dense\nML model to make it shallow, (b) train the pruned model, and (c)\nprobabilistically quantize and offload their trained accumulated gradients to\nthe central server (CS). Our extensive simulation results show that the\nproposed 2CEOAFL algorithm delivers comparable performances to its non-pruned\nand nonquantized, hence, computation- and communication-inefficient\ncounterparts.", "AI": {"tldr": "A novel online aerial federated learning algorithm (2CEOAFL) is proposed for resource-constrained aerial connected vehicles (ACVs), balancing computation and communication efficiency while maintaining performance.", "motivation": "The continual arrival of new data from ACVs and their resource constraints necessitate efficient machine learning solutions for privacy-preserving distributed ML.", "method": "The 2CEOAFL algorithm involves modeling ACV trajectories, pruning dense ML models, training pruned models, and probabilistically quantizing and offloading gradients to a central server.", "result": "Simulations show 2CEOAFL performs comparably to inefficient, non-pruned, and non-quantized methods.", "conclusion": "The proposed algorithm effectively addresses the challenges of resource constraints and continual data arrival in ACV-assisted edge computing."}}
{"id": "2506.03022", "pdf": "https://arxiv.org/pdf/2506.03022", "abs": "https://arxiv.org/abs/2506.03022", "authors": ["David McVicar", "Brian Avant", "Adrian Gould", "Diego Torrejon", "Charles Della Porta", "Ryan Mukherjee"], "title": "Smartflow: Enabling Scalable Spatiotemporal Geospatial Research", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "BlackSky introduces Smartflow, a cloud-based framework enabling scalable\nspatiotemporal geospatial research built on open-source tools and technologies.\nUsing STAC-compliant catalogs as a common input, heterogeneous geospatial data\ncan be processed into standardized datacubes for analysis and model training.\nModel experimentation is managed using a combination of tools, including\nClearML, Tensorboard, and Apache Superset. Underpinning Smartflow is\nKubernetes, which orchestrates the provisioning and execution of workflows to\nsupport both horizontal and vertical scalability. This combination of features\nmakes Smartflow well-suited for geospatial model development and analysis over\nlarge geographic areas, time scales, and expansive image archives.\n  We also present a novel neural architecture, built using Smartflow, to\nmonitor large geographic areas for heavy construction. Qualitative results\nbased on data from the IARPA Space-based Machine Automated Recognition\nTechnique (SMART) program are presented that show the model is capable of\ndetecting heavy construction throughout all major phases of development.", "AI": {"tldr": "Smartflow is a cloud-based framework for scalable geospatial research, using open-source tools and Kubernetes for workflow orchestration. It supports model development and analysis, demonstrated by a novel neural architecture for detecting heavy construction.", "motivation": "To enable scalable spatiotemporal geospatial research and analysis, leveraging open-source tools and standardized data processing.", "method": "Uses STAC-compliant catalogs for input, processes data into datacubes, and manages model experimentation with tools like ClearML, Tensorboard, and Apache Superset. Kubernetes orchestrates workflows.", "result": "Demonstrated by a neural architecture capable of detecting heavy construction across major development phases, using data from the IARPA SMART program.", "conclusion": "Smartflow is effective for large-scale geospatial model development and analysis, as shown by its application in monitoring heavy construction."}}
{"id": "2506.01704", "pdf": "https://arxiv.org/pdf/2506.01704", "abs": "https://arxiv.org/abs/2506.01704", "authors": ["Jiongnan Liu", "Zhicheng Dou", "Ning Hu", "Chenyan Xiong"], "title": "Generate, Not Recommend: Personalized Multimodal Content Generation", "categories": ["cs.AI", "cs.CL"], "comment": null, "summary": "To address the challenge of information overload from massive web contents,\nrecommender systems are widely applied to retrieve and present personalized\nresults for users. However, recommendation tasks are inherently constrained to\nfiltering existing items and lack the ability to generate novel concepts,\nlimiting their capacity to fully satisfy user demands and preferences. In this\npaper, we propose a new paradigm that goes beyond content filtering and\nselecting: directly generating personalized items in a multimodal form, such as\nimages, tailored to individual users. To accomplish this, we leverage\nany-to-any Large Multimodal Models (LMMs) and train them in both supervised\nfine-tuning and online reinforcement learning strategy to equip them with the\nability to yield tailored next items for users. Experiments on two benchmark\ndatasets and user study confirm the efficacy of the proposed method. Notably,\nthe generated images not only align well with users' historical preferences but\nalso exhibit relevance to their potential future interests.", "AI": {"tldr": "A new method uses multimodal models to generate personalized items like images, enhancing recommender systems beyond filtering.", "motivation": "Address limitations of traditional recommender systems by generating novel, personalized content instead of just filtering existing items.", "method": "Leverage any-to-any Large Multimodal Models (LMMs) trained with supervised fine-tuning and online reinforcement learning to generate tailored items.", "result": "Experiments and user studies show the method effectively aligns with user preferences and future interests.", "conclusion": "The proposed paradigm successfully extends recommender systems to generate personalized, novel content."}}
{"id": "2506.02875", "pdf": "https://arxiv.org/pdf/2506.02875", "abs": "https://arxiv.org/abs/2506.02875", "authors": ["Xiaohong Liu", "Xiongkuo Min", "Qiang Hu", "Xiaoyun Zhang", "Jie Guo", "Guangtao Zhai", "Shushi Wang", "Yingjie Zhou", "Lu Liu", "Jingxin Li", "Liu Yang", "Farong Wen", "Li Xu", "Yanwei Jiang", "Xilei Zhu", "Chunyi Li", "Zicheng Zhang", "Huiyu Duan", "Xiele Wu", "Yixuan Gao", "Yuqin Cao", "Jun Jia", "Wei Sun", "Jiezhang Cao", "Radu Timofte", "Baojun Li", "Jiamian Huang", "Dan Luo", "Tao Liu", "Weixia Zhang", "Bingkun Zheng", "Junlin Chen", "Ruikai Zhou", "Meiya Chen", "Yu Wang", "Hao Jiang", "Xiantao Li", "Yuxiang Jiang", "Jun Tang", "Yimeng Zhao", "Bo Hu", "Zelu Qi", "Chaoyang Zhang", "Fei Zhao", "Ping Shi", "Lingzhi Fu", "Heng Cong", "Shuai He", "Rongyu Zhang", "Jiarong He", "Zongyao Hu", "Wei Luo", "Zihao Yu", "Fengbin Guan", "Yiting Lu", "Xin Li", "Zhibo Chen", "Mengjing Su", "Yi Wang", "Tuo Chen", "Chunxiao Li", "Shuaiyu Zhao", "Jiaxin Wen", "Chuyi Lin", "Sitong Liu", "Ningxin Chu", "Jing Wan", "Yu Zhou", "Baoying Chen", "Jishen Zeng", "Jiarui Liu", "Xianjin Liu", "Xin Chen", "Lanzhi Zhou", "Hangyu Li", "You Han", "Bibo Xiang", "Zhenjie Liu", "Jianzhang Lu", "Jialin Gui", "Renjie Lu", "Shangfei Wang", "Donghao Zhou", "Jingyu Lin", "Quanjian Song", "Jiancheng Huang", "Yufeng Yang", "Changwei Wang", "Shupeng Zhong", "Yang Yang", "Lihuo He", "Jia Liu", "Yuting Xing", "Tida Fang", "Yuchun Jin"], "title": "NTIRE 2025 XGC Quality Assessment Challenge: Methods and Results", "categories": ["cs.CV"], "comment": "NTIRE 2025 XGC Quality Assessment Challenge Report. arXiv admin note:\n  text overlap with arXiv:2404.16687", "summary": "This paper reports on the NTIRE 2025 XGC Quality Assessment Challenge, which\nwill be held in conjunction with the New Trends in Image Restoration and\nEnhancement Workshop (NTIRE) at CVPR 2025. This challenge is to address a major\nchallenge in the field of video and talking head processing. The challenge is\ndivided into three tracks, including user generated video, AI generated video\nand talking head. The user-generated video track uses the FineVD-GC, which\ncontains 6,284 user generated videos. The user-generated video track has a\ntotal of 125 registered participants. A total of 242 submissions are received\nin the development phase, and 136 submissions are received in the test phase.\nFinally, 5 participating teams submitted their models and fact sheets. The AI\ngenerated video track uses the Q-Eval-Video, which contains 34,029 AI-Generated\nVideos (AIGVs) generated by 11 popular Text-to-Video (T2V) models. A total of\n133 participants have registered in this track. A total of 396 submissions are\nreceived in the development phase, and 226 submissions are received in the test\nphase. Finally, 6 participating teams submitted their models and fact sheets.\nThe talking head track uses the THQA-NTIRE, which contains 12,247 2D and 3D\ntalking heads. A total of 89 participants have registered in this track. A\ntotal of 225 submissions are received in the development phase, and 118\nsubmissions are received in the test phase. Finally, 8 participating teams\nsubmitted their models and fact sheets. Each participating team in every track\nhas proposed a method that outperforms the baseline, which has contributed to\nthe development of fields in three tracks.", "AI": {"tldr": "The NTIRE 2025 XGC Quality Assessment Challenge addresses video and talking head processing through three tracks: user-generated video, AI-generated video, and talking head, with significant participation and submissions.", "motivation": "To advance quality assessment in video and talking head processing by evaluating diverse methods through a structured challenge.", "method": "The challenge is divided into three tracks, each using specific datasets (FineVD-GC, Q-Eval-Video, THQA-NTIRE) and involving multiple phases (development and test) with participant submissions.", "result": "High participation and submissions across all tracks, with teams outperforming baselines, contributing to advancements in the field.", "conclusion": "The challenge successfully fostered innovation and progress in video and talking head quality assessment."}}
{"id": "2506.02978", "pdf": "https://arxiv.org/pdf/2506.02978", "abs": "https://arxiv.org/abs/2506.02978", "authors": ["Mohamed Djilani", "Thibault Simonetto", "Karim Tit", "Florian Tambon", "Paul R\u00e9camier", "Salah Ghamizi", "Maxime Cordy", "Mike Papadakis"], "title": "On the Robustness of Tabular Foundation Models: Test-Time Attacks and In-Context Defenses", "categories": ["cs.LG"], "comment": null, "summary": "Recent tabular Foundational Models (FM) such as TabPFN and TabICL, leverage\nin-context learning to achieve strong performance without gradient updates or\nfine-tuning. However, their robustness to adversarial manipulation remains\nlargely unexplored. In this work, we present a comprehensive study of the\nadversarial vulnerabilities of tabular FM, focusing on both their fragility to\ntargeted test-time attacks and their potential misuse as adversarial tools. We\nshow on three benchmarks in finance, cybersecurity and healthcare, that small,\nstructured perturbations to test inputs can significantly degrade prediction\naccuracy, even when training context remain fixed. Additionally, we demonstrate\nthat tabular FM can be repurposed to generate transferable evasion to\nconventional models such as random forests and XGBoost, and on a lesser extent\nto deep tabular models. To improve tabular FM, we formulate the robustification\nproblem as an optimization of the weights (adversarial fine-tuning), or the\ncontext (adversarial in-context learning). We introduce an in-context\nadversarial training strategy that incrementally replaces the context with\nadversarial perturbed instances, without updating model weights. Our approach\nimproves robustness across multiple tabular benchmarks. Together, these\nfindings position tabular FM as both a target and a source of adversarial\nthreats, highlighting the urgent need for robust training and evaluation\npractices in this emerging paradigm.", "AI": {"tldr": "Tabular foundational models (FM) like TabPFN and TabICL are vulnerable to adversarial attacks, degrading performance. They can also generate transferable attacks on other models. A new in-context adversarial training method improves robustness.", "motivation": "To explore the adversarial vulnerabilities of tabular FM and their potential misuse, as well as to propose solutions for improving robustness.", "method": "Study adversarial vulnerabilities via test-time attacks and misuse as adversarial tools. Introduce in-context adversarial training to enhance robustness.", "result": "Small perturbations degrade FM accuracy. FM can generate transferable attacks. In-context adversarial training improves robustness.", "conclusion": "Tabular FM are both vulnerable and capable of adversarial threats, necessitating robust training and evaluation practices."}}
{"id": "2506.03046", "pdf": "https://arxiv.org/pdf/2506.03046", "abs": "https://arxiv.org/abs/2506.03046", "authors": ["Mikolaj Walczak", "Romina Aalishah", "Wyatt Mackey", "Brittany Story", "David L. Boothe Jr.", "Nicholas Waytowich", "Xiaomin Lin", "Tinoosh Mohsenin"], "title": "EDEN: Entorhinal Driven Egocentric Navigation Toward Robotic Deployment", "categories": ["cs.RO", "cs.AI"], "comment": null, "summary": "Deep reinforcement learning agents are often fragile while humans remain\nadaptive and flexible to varying scenarios. To bridge this gap, we present\nEDEN, a biologically inspired navigation framework that integrates learned\nentorhinal-like grid cell representations and reinforcement learning to enable\nautonomous navigation. Inspired by the mammalian entorhinal-hippocampal system,\nEDEN allows agents to perform path integration and vector-based navigation\nusing visual and motion sensor data. At the core of EDEN is a grid cell encoder\nthat transforms egocentric motion into periodic spatial codes, producing\nlow-dimensional, interpretable embeddings of position. To generate these\nactivations from raw sensory input, we combine fiducial marker detections in\nthe lightweight MiniWorld simulator and DINO-based visual features in the\nhigh-fidelity Gazebo simulator. These spatial representations serve as input to\na policy trained with Proximal Policy Optimization (PPO), enabling dynamic,\ngoal-directed navigation. We evaluate EDEN in both MiniWorld, for rapid\nprototyping, and Gazebo, which offers realistic physics and perception noise.\nCompared to baseline agents using raw state inputs (e.g., position, velocity)\nor standard convolutional image encoders, EDEN achieves a 99% success rate,\nwithin the simple scenarios, and >94% within complex floorplans with occluded\npaths with more efficient and reliable step-wise navigation. In addition, as a\nreplacement of ground truth activations, we present a trainable Grid Cell\nencoder enabling the development of periodic grid-like patterns from vision and\nmotion sensor data, emulating the development of such patterns within\nbiological mammals. This work represents a step toward biologically grounded\nspatial intelligence in robotics, bridging neural navigation principles with\nreinforcement learning for scalable deployment.", "AI": {"tldr": "EDEN is a biologically inspired navigation framework combining grid cell representations and reinforcement learning for adaptive, goal-directed navigation in robots.", "motivation": "To bridge the gap between fragile deep reinforcement learning agents and adaptive human navigation by mimicking the mammalian entorhinal-hippocampal system.", "method": "Integrates grid cell encoders for spatial coding, uses visual and motion sensor data, and trains policies with Proximal Policy Optimization (PPO).", "result": "Achieves 99% success in simple scenarios and >94% in complex ones, outperforming baseline agents.", "conclusion": "EDEN advances biologically grounded spatial intelligence in robotics, merging neural navigation principles with reinforcement learning."}}
{"id": "2506.02882", "pdf": "https://arxiv.org/pdf/2506.02882", "abs": "https://arxiv.org/abs/2506.02882", "authors": ["Sohyun Lee", "Yeho Kwon", "Lukas Hoyer", "Suha Kwak"], "title": "GaRA-SAM: Robustifying Segment Anything Model with Gated-Rank Adaptation", "categories": ["cs.CV"], "comment": null, "summary": "Improving robustness of the Segment Anything Model (SAM) to input\ndegradations is critical for its deployment in high-stakes applications such as\nautonomous driving and robotics. Our approach to this challenge prioritizes\nthree key aspects: first, parameter efficiency to maintain the inherent\ngeneralization capability of SAM; second, fine-grained and input-aware\nrobustification to precisely address the input corruption; and third, adherence\nto standard training protocols for ease of training. To this end, we propose\ngated-rank adaptation (GaRA). GaRA introduces lightweight adapters into\nintermediate layers of the frozen SAM, where each adapter dynamically adjusts\nthe effective rank of its weight matrix based on the input by selectively\nactivating (rank-1) components of the matrix using a learned gating module.\nThis adjustment enables fine-grained and input-aware robustification without\ncompromising the generalization capability of SAM. Our model, GaRA-SAM,\nsignificantly outperforms prior work on all robust segmentation benchmarks. In\nparticular, it surpasses the previous best IoU score by up to 21.3\\%p on ACDC,\na challenging real corrupted image dataset.", "AI": {"tldr": "GaRA-SAM improves SAM's robustness to input degradations using lightweight adapters and dynamic rank adjustment, outperforming prior methods.", "motivation": "Enhancing SAM's robustness for high-stakes applications like autonomous driving and robotics.", "method": "Introduces gated-rank adaptation (GaRA) with lightweight adapters and dynamic rank adjustment.", "result": "GaRA-SAM surpasses prior work, achieving up to 21.3%p higher IoU on ACDC.", "conclusion": "GaRA-SAM effectively balances robustness and generalization, setting a new benchmark."}}
{"id": "2506.02986", "pdf": "https://arxiv.org/pdf/2506.02986", "abs": "https://arxiv.org/abs/2506.02986", "authors": ["Nathan Buskulic", "Jalal Fadil", "Yvain Qu\u00e9au"], "title": "Implicit Regularization of the Deep Inverse Prior Trained with Inertia", "categories": ["cs.LG"], "comment": null, "summary": "Solving inverse problems with neural networks benefits from very few\ntheoretical guarantees when it comes to the recovery guarantees. We provide in\nthis work convergence and recovery guarantees for self-supervised neural\nnetworks applied to inverse problems, such as Deep Image/Inverse Prior, and\ntrained with inertia featuring both viscous and geometric Hessian-driven\ndampings. We study both the continuous-time case, i.e., the trajectory of a\ndynamical system, and the discrete case leading to an inertial algorithm with\nan adaptive step-size. We show in the continuous-time case that the network can\nbe trained with an optimal accelerated exponential convergence rate compared to\nthe rate obtained with gradient flow. We also show that training a network with\nour inertial algorithm enjoys similar recovery guarantees though with a less\nsharp linear convergence rate.", "AI": {"tldr": "The paper provides theoretical guarantees for self-supervised neural networks in solving inverse problems, focusing on convergence and recovery. It analyzes both continuous-time and discrete cases, showing accelerated exponential convergence in the former and linear convergence in the latter.", "motivation": "Addressing the lack of theoretical guarantees for neural networks in inverse problems, the work aims to provide convergence and recovery assurances for self-supervised networks.", "method": "The study examines self-supervised neural networks (e.g., Deep Image/Inverse Prior) trained with inertia, including viscous and geometric Hessian-driven dampings. It analyzes both continuous-time (dynamical system trajectory) and discrete-time (inertial algorithm with adaptive step-size) cases.", "result": "In continuous-time, the network achieves optimal accelerated exponential convergence. In discrete-time, it shows linear convergence with recovery guarantees, though less sharp than the continuous case.", "conclusion": "The work establishes theoretical foundations for self-supervised networks in inverse problems, demonstrating improved convergence rates in both continuous and discrete settings."}}
{"id": "2506.03065", "pdf": "https://arxiv.org/pdf/2506.03065", "abs": "https://arxiv.org/abs/2506.03065", "authors": ["Pengtao Chen", "Xianfang Zeng", "Maosen Zhao", "Peng Ye", "Mingzhu Shen", "Wei Cheng", "Gang Yu", "Tao Chen"], "title": "Sparse-vDiT: Unleashing the Power of Sparse Attention to Accelerate Video Diffusion Transformers", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": null, "summary": "While Diffusion Transformers (DiTs) have achieved breakthroughs in video\ngeneration, this long sequence generation task remains constrained by the\nquadratic complexity of attention mechanisms, resulting in significant\ninference latency. Through detailed analysis of attention maps in Video\nDiffusion Transformer (vDiT), we identify three recurring sparsity patterns:\ndiagonal, multi-diagonal, and vertical-stripe structures. And even 3-6\\%\nattention heads can be skipped. Crucially, these patterns exhibit strong\nlayer-depth and head-position correlations but show limited dependence on the\ninput content. Leveraging these findings, we propose Sparse-vDiT, a sparsity\nacceleration framework for vDiT comprising: 1) Pattern-optimized sparse kernels\nthat replace dense attention with computationally efficient implementations for\neach identified sparsity pattern. 2) An offline sparse diffusion search\nalgorithm that selects the optimal sparse computation strategy per layer and\nhead via hardware-aware cost modeling. After determining the optimal\nconfiguration, we fuse heads within the same layer that share the same\nattention strategy, enhancing inference efficiency. Integrated into\nstate-of-the-art vDiT models (CogVideoX1.5, HunyuanVideo, and Wan2.1),\nSparse-vDiT achieves 2.09$\\times$, 2.38$\\times$, and 1.67$\\times$ theoretical\nFLOP reduction, and actual inference speedups of 1.76$\\times$, 1.85$\\times$,\nand 1.58$\\times$, respectively, while maintaining high visual fidelity, with\nPSNR values reaching 24.13, 27.09, and 22.59. Our work demonstrates that latent\nstructural sparsity in vDiTs can be systematically exploited for long video\nsynthesis.", "AI": {"tldr": "Sparse-vDiT accelerates video generation by leveraging sparsity patterns in attention maps, reducing FLOPs and improving inference speed without compromising quality.", "motivation": "The quadratic complexity of attention mechanisms in Diffusion Transformers (DiTs) causes high inference latency in video generation, prompting the need for optimization.", "method": "Identifies sparsity patterns in attention maps, proposes pattern-optimized sparse kernels, and uses an offline sparse diffusion search algorithm to optimize computation.", "result": "Achieves significant FLOP reduction (up to 2.38\u00d7) and speedups (up to 1.85\u00d7) while maintaining visual fidelity (PSNR up to 27.09).", "conclusion": "Structural sparsity in vDiTs can be systematically exploited for efficient long video synthesis."}}
{"id": "2506.02160", "pdf": "https://arxiv.org/pdf/2506.02160", "abs": "https://arxiv.org/abs/2506.02160", "authors": ["Madan Krishnamurthy", "Daniel Korn", "Melissa A Haendel", "Christopher J Mungall", "Anne E Thessen"], "title": "A Dynamic Framework for Semantic Grouping of Common Data Elements (CDE) Using Embeddings and Clustering", "categories": ["cs.IR", "cs.CL", "cs.LG"], "comment": null, "summary": "This research aims to develop a dynamic and scalable framework to facilitate\nharmonization of Common Data Elements (CDEs) across heterogeneous biomedical\ndatasets by addressing challenges such as semantic heterogeneity, structural\nvariability, and context dependence to streamline integration, enhance\ninteroperability, and accelerate scientific discovery. Our methodology\nleverages Large Language Models (LLMs) for context-aware text embeddings that\nconvert CDEs into dense vectors capturing semantic relationships and patterns.\nThese embeddings are clustered using Hierarchical Density-Based Spatial\nClustering of Applications with Noise (HDBSCAN) to group semantically similar\nCDEs. The framework incorporates four key steps: (1) LLM-based text embedding\nto mathematically represent semantic context, (2) unsupervised clustering of\nembeddings via HDBSCAN, (3) automated labeling using LLM summarization, and (4)\nsupervised learning to train a classifier assigning new or unclustered CDEs to\nlabeled clusters. Evaluated on the NIH NLM CDE Repository with over 24,000\nCDEs, the system identified 118 meaningful clusters at an optimized minimum\ncluster size of 20. The classifier achieved 90.46 percent overall accuracy,\nperforming best in larger categories. External validation against Gravity\nProjects Social Determinants of Health domains showed strong agreement\n(Adjusted Rand Index 0.52, Normalized Mutual Information 0.78), indicating that\nembeddings effectively capture cluster characteristics. This adaptable and\nscalable approach offers a practical solution to CDE harmonization, improving\nselection efficiency and supporting ongoing data interoperability.", "AI": {"tldr": "A dynamic framework using LLMs and HDBSCAN for harmonizing biomedical CDEs, achieving 90.46% accuracy in clustering and strong external validation.", "motivation": "Address semantic heterogeneity and structural variability in biomedical datasets to enhance interoperability and scientific discovery.", "method": "Leverages LLMs for text embeddings, HDBSCAN for clustering, automated labeling, and supervised learning for classification.", "result": "Identified 118 clusters with 90.46% accuracy; strong external validation (ARI 0.52, NMI 0.78).", "conclusion": "The framework is scalable and effective for CDE harmonization, improving data interoperability."}}
{"id": "2506.02891", "pdf": "https://arxiv.org/pdf/2506.02891", "abs": "https://arxiv.org/abs/2506.02891", "authors": ["Jiewen Hu", "Leena Mathur", "Paul Pu Liang", "Louis-Philippe Morency"], "title": "OpenFace 3.0: A Lightweight Multitask System for Comprehensive Facial Behavior Analysis", "categories": ["cs.CV"], "comment": "IEEE FG 2025, \\c{opyright} 2025 IEEE. Personal use of this material\n  is permitted. Permission from IEEE must be obtained for all other uses, in\n  any current or future media, including reprinting/republishing this material\n  for advertising or promotional purposes, creating new collective works, for\n  resale or redistribution to servers or lists, or reuse of any copyrighted\n  component of this work", "summary": "In recent years, there has been increasing interest in automatic facial\nbehavior analysis systems from computing communities such as vision, multimodal\ninteraction, robotics, and affective computing. Building upon the widespread\nutility of prior open-source facial analysis systems, we introduce OpenFace\n3.0, an open-source toolkit capable of facial landmark detection, facial action\nunit detection, eye-gaze estimation, and facial emotion recognition. OpenFace\n3.0 contributes a lightweight unified model for facial analysis, trained with a\nmulti-task architecture across diverse populations, head poses, lighting\nconditions, video resolutions, and facial analysis tasks. By leveraging the\nbenefits of parameter sharing through a unified model and training paradigm,\nOpenFace 3.0 exhibits improvements in prediction performance, inference speed,\nand memory efficiency over similar toolkits and rivals state-of-the-art models.\nOpenFace 3.0 can be installed and run with a single line of code and operate in\nreal-time without specialized hardware. OpenFace 3.0 code for training models\nand running the system is freely available for research purposes and supports\ncontributions from the community.", "AI": {"tldr": "OpenFace 3.0 is an open-source toolkit for facial analysis, offering improved performance, speed, and efficiency with a lightweight unified model.", "motivation": "Addressing the growing interest in automatic facial behavior analysis, OpenFace 3.0 aims to provide a versatile and accessible tool for diverse applications.", "method": "Uses a multi-task architecture trained across varied conditions (populations, poses, lighting, etc.) with parameter sharing for efficiency.", "result": "Outperforms similar toolkits in prediction, speed, and memory efficiency, rivaling state-of-the-art models.", "conclusion": "OpenFace 3.0 is a practical, real-time solution for facial analysis, freely available for research and community contributions."}}
{"id": "2506.03028", "pdf": "https://arxiv.org/pdf/2506.03028", "abs": "https://arxiv.org/abs/2506.03028", "authors": ["Junde Xu", "Zijun Gao", "Xinyi Zhou", "Jie Hu", "Xingyi Cheng", "Le Song", "Guangyong Chen", "Pheng-Ann Heng", "Jiezhong Qiu"], "title": "Protein Inverse Folding From Structure Feedback", "categories": ["cs.LG", "q-bio.BM"], "comment": null, "summary": "The inverse folding problem, aiming to design amino acid sequences that fold\ninto desired three-dimensional structures, is pivotal for various\nbiotechnological applications. Here, we introduce a novel approach leveraging\nDirect Preference Optimization (DPO) to fine-tune an inverse folding model\nusing feedback from a protein folding model. Given a target protein structure,\nwe begin by sampling candidate sequences from the inverse-folding model, then\npredict the three-dimensional structure of each sequence with the folding model\nto generate pairwise structural-preference labels. These labels are used to\nfine-tune the inverse-folding model under the DPO objective. Our results on the\nCATH 4.2 test set demonstrate that DPO fine-tuning not only improves sequence\nrecovery of baseline models but also leads to a significant improvement in\naverage TM-Score from 0.77 to 0.81, indicating enhanced structure similarity.\nFurthermore, iterative application of our DPO-based method on challenging\nprotein structures yields substantial gains, with an average TM-Score increase\nof 79.5\\% with regard to the baseline model. This work establishes a promising\ndirection for enhancing protein sequence design ability from structure feedback\nby effectively utilizing preference optimization.", "AI": {"tldr": "A novel method using Direct Preference Optimization (DPO) improves protein sequence design by fine-tuning an inverse folding model with feedback from a folding model, enhancing sequence recovery and structural similarity.", "motivation": "The inverse folding problem is crucial for biotechnological applications, requiring better methods to design sequences that fold into desired structures.", "method": "The approach samples candidate sequences from an inverse-folding model, predicts their structures with a folding model, and uses pairwise structural-preference labels to fine-tune the inverse-folding model under DPO.", "result": "DPO fine-tuning improves sequence recovery and increases average TM-Score from 0.77 to 0.81, with iterative application yielding a 79.5% TM-Score improvement over baseline.", "conclusion": "This work demonstrates the effectiveness of preference optimization for enhancing protein sequence design from structural feedback."}}
{"id": "2506.03077", "pdf": "https://arxiv.org/pdf/2506.03077", "abs": "https://arxiv.org/abs/2506.03077", "authors": ["Qijun Luo", "Mengqi Li", "Lei Zhao", "Xiao Li"], "title": "StreamBP: Memory-Efficient Exact Backpropagation for Long Sequence Training of LLMs", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Training language models on long sequence data is a demanding requirement for\nenhancing the model's capability on complex tasks, e.g., long-chain reasoning.\nHowever, as the sequence length scales up, the memory cost for storing\nactivation values becomes huge during the Backpropagation (BP) process, even\nwith the application of gradient checkpointing technique. To tackle this\nchallenge, we propose a memory-efficient and exact BP method called StreamBP,\nwhich performs a linear decomposition of the chain rule along the sequence\ndimension in a layer-wise manner, significantly reducing the memory cost of\nactivation values and logits. The proposed method is applicable to common\nobjectives such as SFT, GRPO, and DPO. From an implementation perspective,\nStreamBP achieves less computational FLOPs and faster BP speed by leveraging\nthe causal structure of the language model. Compared to gradient checkpointing,\nStreamBP scales up the maximum sequence length of BP by 2.8-5.5 times larger,\nwhile using comparable or even less BP time. Note that StreamBP's sequence\nlength scaling ability can be directly transferred to batch size scaling for\naccelerating training. We further develop a communication-efficient distributed\nStreamBP to effectively support multi-GPU training and broaden its\napplicability. Our code can be easily integrated into the training pipeline of\nany transformer models and is available at https://github.com/Ledzy/StreamBP.", "AI": {"tldr": "StreamBP is a memory-efficient and exact backpropagation method for training language models on long sequences, reducing memory costs and improving scalability.", "motivation": "Training on long sequences is essential for complex tasks like reasoning, but memory costs for activation storage during backpropagation are prohibitive.", "method": "StreamBP decomposes the chain rule linearly along the sequence dimension layer-wise, leveraging the causal structure of language models to reduce memory and computation.", "result": "StreamBP scales sequence length by 2.8-5.5 times compared to gradient checkpointing, with comparable or faster backpropagation time. It also supports batch size scaling and multi-GPU training.", "conclusion": "StreamBP is a practical, scalable solution for training transformer models on long sequences, with open-source implementation available."}}
{"id": "2506.02479", "pdf": "https://arxiv.org/pdf/2506.02479", "abs": "https://arxiv.org/abs/2506.02479", "authors": ["Kalyan Nakka", "Nitesh Saxena"], "title": "BitBypass: A New Direction in Jailbreaking Aligned Large Language Models with Bitstream Camouflage", "categories": ["cs.CR", "cs.CL"], "comment": "24 pages, 24 figures, and 7 tables", "summary": "The inherent risk of generating harmful and unsafe content by Large Language\nModels (LLMs), has highlighted the need for their safety alignment. Various\ntechniques like supervised fine-tuning, reinforcement learning from human\nfeedback, and red-teaming were developed for ensuring the safety alignment of\nLLMs. However, the robustness of these aligned LLMs is always challenged by\nadversarial attacks that exploit unexplored and underlying vulnerabilities of\nthe safety alignment. In this paper, we develop a novel black-box jailbreak\nattack, called BitBypass, that leverages hyphen-separated bitstream camouflage\nfor jailbreaking aligned LLMs. This represents a new direction in jailbreaking\nby exploiting fundamental information representation of data as continuous\nbits, rather than leveraging prompt engineering or adversarial manipulations.\nOur evaluation of five state-of-the-art LLMs, namely GPT-4o, Gemini 1.5, Claude\n3.5, Llama 3.1, and Mixtral, in adversarial perspective, revealed the\ncapabilities of BitBypass in bypassing their safety alignment and tricking them\ninto generating harmful and unsafe content. Further, we observed that BitBypass\noutperforms several state-of-the-art jailbreak attacks in terms of stealthiness\nand attack success. Overall, these results highlights the effectiveness and\nefficiency of BitBypass in jailbreaking these state-of-the-art LLMs.", "AI": {"tldr": "BitBypass is a novel black-box jailbreak attack using hyphen-separated bitstream camouflage to bypass safety alignment in LLMs, outperforming existing methods in stealth and success.", "motivation": "The need to test and improve the robustness of safety-aligned LLMs against adversarial attacks, given their vulnerability to exploitation.", "method": "Developed BitBypass, a jailbreak attack exploiting bitstream camouflage, and evaluated it on five advanced LLMs (GPT-4o, Gemini 1.5, Claude 3.5, Llama 3.1, Mixtral).", "result": "BitBypass successfully bypassed safety alignment in all tested LLMs, generating harmful content, and outperformed other jailbreak attacks in stealth and success.", "conclusion": "BitBypass demonstrates a new, effective method for jailbreaking LLMs, highlighting vulnerabilities in current safety alignment techniques."}}
{"id": "2506.02893", "pdf": "https://arxiv.org/pdf/2506.02893", "abs": "https://arxiv.org/abs/2506.02893", "authors": ["Jonathan Astermark", "Anders Heyden", "Viktor Larsson"], "title": "Dense Match Summarization for Faster Two-view Estimation", "categories": ["cs.CV"], "comment": "Accepted to Computer Vision and Pattern Recognition (CVPR) 2025", "summary": "In this paper, we speed up robust two-view relative pose from dense\ncorrespondences. Previous work has shown that dense matchers can significantly\nimprove both accuracy and robustness in the resulting pose. However, the large\nnumber of matches comes with a significantly increased runtime during robust\nestimation in RANSAC. To avoid this, we propose an efficient match\nsummarization scheme which provides comparable accuracy to using the full set\nof dense matches, while having 10-100x faster runtime. We validate our approach\non standard benchmark datasets together with multiple state-of-the-art dense\nmatchers.", "AI": {"tldr": "Proposes an efficient match summarization scheme to speed up robust two-view relative pose estimation from dense correspondences, achieving comparable accuracy with 10-100x faster runtime.", "motivation": "Dense matchers improve pose accuracy and robustness but increase runtime during robust estimation in RANSAC due to the large number of matches.", "method": "Introduces an efficient match summarization scheme to reduce runtime while maintaining accuracy.", "result": "Validated on benchmark datasets, the method provides comparable accuracy to full dense matches with significantly faster runtime.", "conclusion": "The proposed summarization scheme effectively balances speed and accuracy in robust pose estimation."}}
{"id": "2506.03037", "pdf": "https://arxiv.org/pdf/2506.03037", "abs": "https://arxiv.org/abs/2506.03037", "authors": ["Shubhendu Trivedi", "Brian D. Nord"], "title": "On the Need to Align Intent and Implementation in Uncertainty Quantification for Machine Learning", "categories": ["cs.LG", "stat.ME", "stat.ML"], "comment": null, "summary": "Quantifying uncertainties for machine learning (ML) models is a foundational\nchallenge in modern data analysis. This challenge is compounded by at least two\nkey aspects of the field: (a) inconsistent terminology surrounding uncertainty\nand estimation across disciplines, and (b) the varying technical requirements\nfor establishing trustworthy uncertainties in diverse problem contexts. In this\nposition paper, we aim to clarify the depth of these challenges by identifying\nthese inconsistencies and articulating how different contexts impose distinct\nepistemic demands. We examine the current landscape of estimation targets\n(e.g., prediction, inference, simulation-based inference), uncertainty\nconstructs (e.g., frequentist, Bayesian, fiducial), and the approaches used to\nmap between them. Drawing on the literature, we highlight and explain examples\nof problematic mappings. To help address these issues, we advocate for\nstandards that promote alignment between the \\textit{intent} and\n\\textit{implementation} of uncertainty quantification (UQ) approaches. We\ndiscuss several axes of trustworthiness that are necessary (if not sufficient)\nfor reliable UQ in ML models, and show how these axes can inform the design and\nevaluation of uncertainty-aware ML systems. Our practical recommendations focus\non scientific ML, offering illustrative cases and use scenarios, particularly\nin the context of simulation-based inference (SBI).", "AI": {"tldr": "The paper addresses challenges in quantifying uncertainties for ML models, highlighting inconsistent terminology and varying technical demands. It advocates for standards to align intent and implementation in UQ approaches, focusing on trustworthiness and practical recommendations for scientific ML.", "motivation": "To clarify inconsistencies in uncertainty terminology and estimation across disciplines, and to address the varying technical requirements for trustworthy uncertainties in diverse problem contexts.", "method": "Examines current landscape of estimation targets, uncertainty constructs, and mapping approaches, highlighting problematic mappings. Advocates for standards and discusses axes of trustworthiness.", "result": "Identifies challenges in UQ for ML and proposes alignment standards. Provides practical recommendations for uncertainty-aware ML systems, especially in scientific ML and SBI.", "conclusion": "Alignment between intent and implementation in UQ is crucial. The paper offers actionable insights for designing and evaluating trustworthy uncertainty-aware ML systems."}}
{"id": "2506.03083", "pdf": "https://arxiv.org/pdf/2506.03083", "abs": "https://arxiv.org/abs/2506.03083", "authors": ["Adrian de Wynter"], "title": "Labelling Data with Unknown References", "categories": ["cs.DS", "cs.AI"], "comment": null, "summary": "An evaluator is trustworthy when there exists some agreed-upon way to measure\nits performance as a labeller. The two ways to establish trustworthiness are\neither by testing it, or by assuming the evaluator `knows' somehow the way to\nlabel the corpus. However, if labelled references (e.g., a development set) are\nunavailable, neither of these approaches work: the former requires the data,\nand the latter is an assumption, not evidence. To address this, we introduce an\nalgorithm (the `No-Data Algorithm') by which to establish trust in an evaluator\nwithout any existing references. Our algorithm works by successively posing\nchallenges to said evaluator. We show that this is sufficient to establish\ntrustworthiness w.h.p., in such a way that when the evaluator actually knows\nthe way to label the corpus, the No-Data Algorithm accepts its output; and,\nconversely, flags untrustworthy evaluators when these are unable to prove it.\nWe present formal proofs of correctness and limited experiments.", "AI": {"tldr": "The paper introduces the 'No-Data Algorithm' to establish trust in evaluators without labeled references, using challenges to verify trustworthiness probabilistically.", "motivation": "Existing methods to measure evaluator trustworthiness rely on labeled data or assumptions, which fail when references are unavailable.", "method": "The 'No-Data Algorithm' poses successive challenges to evaluators to verify their trustworthiness without labeled data.", "result": "The algorithm probabilistically accepts trustworthy evaluators and flags untrustworthy ones, supported by formal proofs and experiments.", "conclusion": "The No-Data Algorithm provides a viable solution for establishing evaluator trustworthiness in the absence of labeled references."}}
{"id": "2506.02730", "pdf": "https://arxiv.org/pdf/2506.02730", "abs": "https://arxiv.org/abs/2506.02730", "authors": ["Po-Chieh Yu"], "title": "An Exploratory Framework for Future SETI Applications: Detecting Generative Reactivity via Language Models", "categories": ["astro-ph.IM", "cs.CL"], "comment": "submitted to the International Journal of Astrobiology", "summary": "We present an exploratory framework to test whether noise-like input can\ninduce structured responses in language models. Instead of assuming that\nextraterrestrial signals must be decoded, we evaluate whether inputs can\ntrigger linguistic behavior in generative systems. This shifts the focus from\ndecoding to viewing structured output as a sign of underlying regularity in the\ninput. We tested GPT-2 small, a 117M-parameter model trained on English text,\nusing four types of acoustic input: human speech, humpback whale vocalizations,\nPhylloscopus trochilus birdsong, and algorithmically generated white noise. All\ninputs were treated as noise-like, without any assumed symbolic encoding. To\nassess reactivity, we defined a composite score called Semantic Induction\nPotential (SIP), combining entropy, syntax coherence, compression gain, and\nrepetition penalty. Results showed that whale and bird vocalizations had higher\nSIP scores than white noise, while human speech triggered only moderate\nresponses. This suggests that language models may detect latent structure even\nin data without conventional semantics. We propose that this approach could\ncomplement traditional SETI methods, especially in cases where communicative\nintent is unknown. Generative reactivity may offer a different way to identify\ndata worth closer attention.", "AI": {"tldr": "The paper explores whether noise-like inputs can induce structured responses in language models, proposing a framework to test this using GPT-2 and various acoustic inputs. Results suggest latent structure detection in non-semantic data.", "motivation": "To shift focus from decoding extraterrestrial signals to evaluating if noise-like inputs can trigger linguistic behavior in generative systems, revealing underlying regularity.", "method": "Tested GPT-2 small with human speech, whale vocalizations, birdsong, and white noise, measuring reactivity via Semantic Induction Potential (SIP).", "result": "Whale and bird vocalizations scored higher on SIP than white noise, indicating latent structure detection in non-semantic data.", "conclusion": "Generative reactivity could complement SETI methods, identifying data worth closer attention when communicative intent is unclear."}}
{"id": "2506.02896", "pdf": "https://arxiv.org/pdf/2506.02896", "abs": "https://arxiv.org/abs/2506.02896", "authors": ["Adam Pardyl", "Dominik Matuszek", "Mateusz Przebieracz", "Marek Cygan", "Bartosz Zieli\u0144ski", "Maciej Wo\u0142czyk"], "title": "FlySearch: Exploring how vision-language models explore", "categories": ["cs.CV", "cs.LG", "cs.RO"], "comment": null, "summary": "The real world is messy and unstructured. Uncovering critical information\noften requires active, goal-driven exploration. It remains to be seen whether\nVision-Language Models (VLMs), which recently emerged as a popular zero-shot\ntool in many difficult tasks, can operate effectively in such conditions. In\nthis paper, we answer this question by introducing FlySearch, a 3D, outdoor,\nphotorealistic environment for searching and navigating to objects in complex\nscenes. We define three sets of scenarios with varying difficulty and observe\nthat state-of-the-art VLMs cannot reliably solve even the simplest exploration\ntasks, with the gap to human performance increasing as the tasks get harder. We\nidentify a set of central causes, ranging from vision hallucination, through\ncontext misunderstanding, to task planning failures, and we show that some of\nthem can be addressed by finetuning. We publicly release the benchmark,\nscenarios, and the underlying codebase.", "AI": {"tldr": "FlySearch tests VLMs in complex 3D environments, revealing their limitations in exploration tasks compared to humans, with identified causes like vision hallucination and task planning failures.", "motivation": "To evaluate if VLMs can effectively perform goal-driven exploration in messy, unstructured real-world conditions.", "method": "Introduces FlySearch, a 3D photorealistic environment, with three difficulty scenarios to test VLMs.", "result": "VLMs fail even simple tasks, with performance gaps widening as tasks get harder. Causes include vision hallucination and planning failures.", "conclusion": "VLMs struggle with exploration tasks; finetuning helps some issues. The benchmark and code are released for further research."}}
{"id": "2506.03043", "pdf": "https://arxiv.org/pdf/2506.03043", "abs": "https://arxiv.org/abs/2506.03043", "authors": ["Nikita Puchkin", "Iurii Pustovalov", "Yuri Sapronov", "Denis Suchkov", "Alexey Naumov", "Denis Belomestny"], "title": "Sample complexity of Schr\u00f6dinger potential estimation", "categories": ["cs.LG", "math.ST", "stat.ML", "stat.TH"], "comment": "60 pages", "summary": "We address the problem of Schr\\\"odinger potential estimation, which plays a\ncrucial role in modern generative modelling approaches based on Schr\\\"odinger\nbridges and stochastic optimal control for SDEs. Given a simple prior diffusion\nprocess, these methods search for a path between two given distributions\n$\\rho_0$ and $\\rho_T^*$ requiring minimal efforts. The optimal drift in this\ncase can be expressed through a Schr\\\"odinger potential. In the present paper,\nwe study generalization ability of an empirical Kullback-Leibler (KL) risk\nminimizer over a class of admissible log-potentials aimed at fitting the\nmarginal distribution at time $T$. Under reasonable assumptions on the target\ndistribution $\\rho_T^*$ and the prior process, we derive a non-asymptotic\nhigh-probability upper bound on the KL-divergence between $\\rho_T^*$ and the\nterminal density corresponding to the estimated log-potential. In particular,\nwe show that the excess KL-risk may decrease as fast as $O(\\log^2 n / n)$ when\nthe sample size $n$ tends to infinity even if both $\\rho_0$ and $\\rho_T^*$ have\nunbounded supports.", "AI": {"tldr": "The paper studies the generalization ability of an empirical KL risk minimizer for Schr\u00f6dinger potential estimation, deriving a non-asymptotic upper bound on KL-divergence with fast convergence rates.", "motivation": "Schr\u00f6dinger potential estimation is key in generative modeling via Schr\u00f6dinger bridges and stochastic optimal control, requiring minimal effort to connect two distributions.", "method": "The authors analyze an empirical KL risk minimizer over admissible log-potentials, fitting the terminal marginal distribution under assumptions on the target and prior process.", "result": "A non-asymptotic high-probability upper bound on KL-divergence is derived, showing excess KL-risk can decrease as fast as O(log\u00b2n/n) for unbounded supports.", "conclusion": "The results demonstrate efficient generalization for Schr\u00f6dinger potential estimation, even with unbounded distributions, supporting its use in generative modeling."}}
{"id": "2506.03087", "pdf": "https://arxiv.org/pdf/2506.03087", "abs": "https://arxiv.org/abs/2506.03087", "authors": ["Bin Ma", "Yuyuan Feng", "Minhua Lin", "Enyan Dai"], "title": "How Explanations Leak the Decision Logic: Stealing Graph Neural Networks via Explanation Alignment", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Graph Neural Networks (GNNs) have become essential tools for analyzing\ngraph-structured data in domains such as drug discovery and financial analysis,\nleading to growing demands for model transparency. Recent advances in\nexplainable GNNs have addressed this need by revealing important subgraphs that\ninfluence predictions, but these explanation mechanisms may inadvertently\nexpose models to security risks. This paper investigates how such explanations\npotentially leak critical decision logic that can be exploited for model\nstealing. We propose {\\method}, a novel stealing framework that integrates\nexplanation alignment for capturing decision logic with guided data\naugmentation for efficient training under limited queries, enabling effective\nreplication of both the predictive behavior and underlying reasoning patterns\nof target models. Experiments on molecular graph datasets demonstrate that our\napproach shows advantages over conventional methods in model stealing. This\nwork highlights important security considerations for the deployment of\nexplainable GNNs in sensitive domains and suggests the need for protective\nmeasures against explanation-based attacks. Our code is available at\nhttps://github.com/beanmah/EGSteal.", "AI": {"tldr": "The paper explores security risks in explainable GNNs, proposing a method to steal models using explanation leaks and data augmentation.", "motivation": "Growing use of GNNs in sensitive domains demands transparency, but explanations may expose models to security threats like model stealing.", "method": "Proposes a framework combining explanation alignment and guided data augmentation to replicate target models' behavior and reasoning.", "result": "Experiments show the method outperforms conventional techniques in model stealing on molecular graph datasets.", "conclusion": "Highlights security risks of explainable GNNs and calls for protective measures against explanation-based attacks."}}
{"id": "2506.03100", "pdf": "https://arxiv.org/pdf/2506.03100", "abs": "https://arxiv.org/abs/2506.03100", "authors": ["Yang Guo", "Yutian Tao", "Yifei Ming", "Robert D. Nowak", "Yingyu Liang"], "title": "Retrieval-Augmented Generation as Noisy In-Context Learning: A Unified Theory and Risk Bounds", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.IR", "math.ST", "stat.TH"], "comment": "Under Review", "summary": "Retrieval-augmented generation (RAG) has seen many empirical successes in\nrecent years by aiding the LLM with external knowledge. However, its\ntheoretical aspect has remained mostly unexplored. In this paper, we propose\nthe first finite-sample generalization bound for RAG in in-context linear\nregression and derive an exact bias-variance tradeoff. Our framework views the\nretrieved texts as query-dependent noisy in-context examples and recovers the\nclassical in-context learning (ICL) and standard RAG as the limit cases. Our\nanalysis suggests that an intrinsic ceiling on generalization error exists on\nRAG as opposed to the ICL. Furthermore, our framework is able to model\nretrieval both from the training data and from external corpora by introducing\nuniform and non-uniform RAG noise. In line with our theory, we show the sample\nefficiency of ICL and RAG empirically with experiments on common QA benchmarks,\nsuch as Natural Questions and TriviaQA.", "AI": {"tldr": "The paper provides a theoretical analysis of Retrieval-augmented Generation (RAG), introducing a finite-sample generalization bound and a bias-variance tradeoff for in-context linear regression. It highlights the intrinsic generalization error ceiling in RAG compared to in-context learning (ICL).", "motivation": "To address the lack of theoretical understanding of RAG's empirical successes, the paper aims to provide a formal framework for analyzing its generalization properties.", "method": "The framework treats retrieved texts as query-dependent noisy in-context examples, unifying classical ICL and standard RAG. It introduces uniform and non-uniform RAG noise to model retrieval from training data and external corpora.", "result": "The analysis reveals an intrinsic ceiling on RAG's generalization error, contrasting with ICL. Empirical experiments on QA benchmarks (Natural Questions, TriviaQA) validate the sample efficiency of ICL and RAG.", "conclusion": "The paper establishes a theoretical foundation for RAG, demonstrating its limitations and advantages over ICL, supported by empirical evidence."}}
{"id": "2506.02914", "pdf": "https://arxiv.org/pdf/2506.02914", "abs": "https://arxiv.org/abs/2506.02914", "authors": ["Yechi Ma", "Wei Hua", "Shu Kong"], "title": "Towards Auto-Annotation from Annotation Guidelines: A Benchmark through 3D LiDAR Detection", "categories": ["cs.CV"], "comment": null, "summary": "A crucial yet under-appreciated prerequisite in machine learning solutions\nfor real-applications is data annotation: human annotators are hired to\nmanually label data according to detailed, expert-crafted guidelines. This is\noften a laborious, tedious, and costly process. To study methods for\nfacilitating data annotation, we introduce a new benchmark AnnoGuide:\nAuto-Annotation from Annotation Guidelines. It aims to evaluate automated\nmethods for data annotation directly from expert-defined annotation guidelines,\neliminating the need for manual labeling. As a case study, we repurpose the\nwell-established nuScenes dataset, commonly used in autonomous driving\nresearch, which provides comprehensive annotation guidelines for labeling LiDAR\npoint clouds with 3D cuboids across 18 object classes. These guidelines include\na few visual examples and textual descriptions, but no labeled 3D cuboids in\nLiDAR data, making this a novel task of multi-modal few-shot 3D detection\nwithout 3D annotations. The advances of powerful foundation models (FMs) make\nAnnoGuide especially timely, as FMs offer promising tools to tackle its\nchallenges. We employ a conceptually straightforward pipeline that (1) utilizes\nopen-source FMs for object detection and segmentation in RGB images, (2)\nprojects 2D detections into 3D using known camera poses, and (3) clusters LiDAR\npoints within the frustum of each 2D detection to generate a 3D cuboid.\nStarting with a non-learned solution that leverages off-the-shelf FMs, we\nprogressively refine key components and achieve significant performance\nimprovements, boosting 3D detection mAP from 12.1 to 21.9! Nevertheless, our\nresults highlight that AnnoGuide remains an open and challenging problem,\nunderscoring the urgent need for developing LiDAR-based FMs. We release our\ncode and models at GitHub: https://annoguide.github.io/annoguide3Dbenchmark", "AI": {"tldr": "AnnoGuide is a benchmark for automating data annotation from expert guidelines, tested on nuScenes dataset, achieving 3D detection improvements but highlighting challenges.", "motivation": "To reduce the laborious and costly process of manual data annotation by automating it using expert-defined guidelines.", "method": "Uses a pipeline with open-source foundation models for 2D detection, projects to 3D, and clusters LiDAR points to generate 3D cuboids.", "result": "Improved 3D detection mAP from 12.1 to 21.9, but the problem remains challenging.", "conclusion": "AnnoGuide is a timely benchmark, emphasizing the need for LiDAR-based foundation models."}}
{"id": "2506.03062", "pdf": "https://arxiv.org/pdf/2506.03062", "abs": "https://arxiv.org/abs/2506.03062", "authors": ["Qining Zhang", "Tanner Fiez", "Yi Liu", "Wenyang Liu"], "title": "Multi-Metric Adaptive Experimental Design under Fixed Budget with Validation", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "Standard A/B tests in online experiments face statistical power challenges\nwhen testing multiple candidates simultaneously, while adaptive experimental\ndesigns (AED) alone fall short in inferring experiment statistics such as the\naverage treatment effect, especially with many metrics (e.g., revenue, safety)\nand heterogeneous variances. This paper proposes a fixed-budget multi-metric\nAED framework with a two-phase structure: an adaptive exploration phase to\nidentify the best treatment, and a validation phase with an A/B test to verify\nthe treatment's quality and infer statistics. We propose SHRVar, which\ngeneralizes sequential halving (SH) (Karnin et al., 2013) with a novel\nrelative-variance-based sampling and an elimination strategy built on reward\nz-values. It achieves a provable error probability that decreases\nexponentially, where the exponent generalizes the complexity measure for SH\n(Karnin et al., 2013) and SHVar (Lalitha et al., 2023) with homogeneous and\nheterogeneous variances, respectively. Numerical experiments verify our\nanalysis and demonstrate the superior performance of this new framework.", "AI": {"tldr": "The paper introduces a fixed-budget multi-metric adaptive experimental design (AED) framework with two phases: adaptive exploration and validation, improving statistical power and inference for heterogeneous variances.", "motivation": "Addressing limitations of standard A/B tests and existing AEDs in handling multiple candidates, metrics, and heterogeneous variances.", "method": "Proposes SHRVar, a two-phase framework combining adaptive exploration (using relative-variance-based sampling and reward z-values) and validation via A/B testing.", "result": "Achieves exponentially decreasing error probability, outperforming existing methods like SH and SHVar in numerical experiments.", "conclusion": "The framework effectively balances exploration and validation, offering robust statistical inference for complex experimental settings."}}
{"id": "2506.03088", "pdf": "https://arxiv.org/pdf/2506.03088", "abs": "https://arxiv.org/abs/2506.03088", "authors": ["Lloyd Pellatt", "Fotios Drakopoulos", "Shievanie Sabesan", "Nicholas A. Lesica"], "title": "Modelling the Effects of Hearing Loss on Neural Coding in the Auditory Midbrain with Variational Conditioning", "categories": ["q-bio.NC", "cs.AI", "cs.LG"], "comment": "12 pages, 3 figures", "summary": "The mapping from sound to neural activity that underlies hearing is highly\nnon-linear. The first few stages of this mapping in the cochlea have been\nmodelled successfully, with biophysical models built by hand and, more\nrecently, with DNN models trained on datasets simulated by biophysical models.\nModelling the auditory brain has been a challenge because central auditory\nprocessing is too complex for models to be built by hand, and datasets for\ntraining DNN models directly have not been available. Recent work has taken\nadvantage of large-scale high resolution neural recordings from the auditory\nmidbrain to build a DNN model of normal hearing with great success. But this\nmodel assumes that auditory processing is the same in all brains, and therefore\nit cannot capture the widely varying effects of hearing loss.\n  We propose a novel variational-conditional model to learn to encode the space\nof hearing loss directly from recordings of neural activity in the auditory\nmidbrain of healthy and noise exposed animals. With hearing loss parametrised\nby only 6 free parameters per animal, our model accurately predicts 62\\% of the\nexplainable variance in neural responses from normal hearing animals and 68%\nfor hearing impaired animals, within a few percentage points of state of the\nart animal specific models. We demonstrate that the model can be used to\nsimulate realistic activity from out of sample animals by fitting only the\nlearned conditioning parameters with Bayesian optimisation, achieving\ncrossentropy loss within 2% of the optimum in 15-30 iterations. Including more\nanimals in the training data slightly improved the performance on unseen\nanimals. This model will enable future development of parametrised hearing loss\ncompensation models trained to directly restore normal neural coding in hearing\nimpaired brains, which can be quickly fitted for a new user by human in the\nloop optimisation.", "AI": {"tldr": "A variational-conditional model is proposed to encode hearing loss from neural recordings, achieving high accuracy in predicting neural responses for both healthy and hearing-impaired animals.", "motivation": "Central auditory processing is complex, and existing models assume uniformity, failing to capture hearing loss variability. The goal is to model hearing loss directly from neural data.", "method": "A variational-conditional model with 6 free parameters per animal is trained on neural recordings from healthy and noise-exposed animals. Bayesian optimization is used for fitting.", "result": "The model predicts 62% of explainable variance for normal hearing and 68% for hearing-impaired animals, close to state-of-the-art. It simulates realistic activity with minimal optimization steps.", "conclusion": "The model enables future development of personalized hearing loss compensation, quickly adaptable for new users."}}
{"id": "2506.03135", "pdf": "https://arxiv.org/pdf/2506.03135", "abs": "https://arxiv.org/abs/2506.03135", "authors": ["Mengdi Jia", "Zekun Qi", "Shaochen Zhang", "Wenyao Zhang", "Xinqiang Yu", "Jiawei He", "He Wang", "Li Yi"], "title": "OmniSpatial: Towards Comprehensive Spatial Reasoning Benchmark for Vision Language Models", "categories": ["cs.CV", "cs.AI", "cs.CL"], "comment": "Project Page: https://qizekun.github.io/omnispatial/", "summary": "Spatial reasoning is a key aspect of cognitive psychology and remains a major\nbottleneck for current vision-language models (VLMs). While extensive research\nhas aimed to evaluate or improve VLMs' understanding of basic spatial\nrelations, such as distinguishing left from right, near from far, and object\ncounting, these tasks represent only the most fundamental level of spatial\nreasoning. In this work, we introduce OmniSpatial, a comprehensive and\nchallenging benchmark for spatial reasoning, grounded in cognitive psychology.\nOmniSpatial covers four major categories: dynamic reasoning, complex spatial\nlogic, spatial interaction, and perspective-taking, with 50 fine-grained\nsubcategories. Through Internet data crawling and careful manual annotation, we\nconstruct over 1.5K question-answer pairs. Extensive experiments show that both\nopen- and closed-source VLMs, as well as existing reasoning and spatial\nunderstanding models, exhibit significant limitations in comprehensive spatial\nunderstanding. We further analyze failure cases and propose potential\ndirections for future research.", "AI": {"tldr": "OmniSpatial is a new benchmark for advanced spatial reasoning in vision-language models, covering dynamic reasoning, complex logic, interaction, and perspective-taking. It reveals significant limitations in current models.", "motivation": "Current vision-language models struggle with advanced spatial reasoning beyond basic tasks, prompting the need for a comprehensive benchmark.", "method": "OmniSpatial was created by crawling and manually annotating data, resulting in 1.5K question-answer pairs across 50 subcategories.", "result": "Experiments show VLMs and existing models perform poorly on OmniSpatial, highlighting their limitations in spatial understanding.", "conclusion": "The benchmark exposes gaps in spatial reasoning and suggests future research directions to improve model performance."}}
{"id": "2506.02938", "pdf": "https://arxiv.org/pdf/2506.02938", "abs": "https://arxiv.org/abs/2506.02938", "authors": ["Xuhui Chen", "Fei Hou", "Wencheng Wang", "Hong Qin", "Ying He"], "title": "MIND: Material Interface Generation from UDFs for Non-Manifold Surface Reconstruction", "categories": ["cs.CV"], "comment": null, "summary": "Unsigned distance fields (UDFs) are widely used in 3D deep learning due to\ntheir ability to represent shapes with arbitrary topology. While prior work has\nlargely focused on learning UDFs from point clouds or multi-view images,\nextracting meshes from UDFs remains challenging, as the learned fields rarely\nattain exact zero distances. A common workaround is to reconstruct signed\ndistance fields (SDFs) locally from UDFs to enable surface extraction via\nMarching Cubes. However, this often introduces topological artifacts such as\nholes or spurious components. Moreover, local SDFs are inherently incapable of\nrepresenting non-manifold geometry, leading to complete failure in such cases.\nTo address this gap, we propose MIND (Material Interface from Non-manifold\nDistance fields), a novel algorithm for generating material interfaces directly\nfrom UDFs, enabling non-manifold mesh extraction from a global perspective. The\ncore of our method lies in deriving a meaningful spatial partitioning from the\nUDF, where the target surface emerges as the interface between distinct\nregions. We begin by computing a two-signed local field to distinguish the two\nsides of manifold patches, and then extend this to a multi-labeled global field\ncapable of separating all sides of a non-manifold structure. By combining this\nmulti-labeled field with the input UDF, we construct material interfaces that\nsupport non-manifold mesh extraction via a multi-labeled Marching Cubes\nalgorithm. Extensive experiments on UDFs generated from diverse data sources,\nincluding point cloud reconstruction, multi-view reconstruction, and medial\naxis transforms, demonstrate that our approach robustly handles complex\nnon-manifold surfaces and significantly outperforms existing methods.", "AI": {"tldr": "MIND proposes a novel algorithm for extracting non-manifold meshes directly from unsigned distance fields (UDFs), addressing topological artifacts and limitations of prior methods.", "motivation": "Prior methods struggle with extracting meshes from UDFs due to inexact zero distances and topological artifacts, especially for non-manifold geometry.", "method": "MIND derives a spatial partitioning from UDFs, using a multi-labeled global field to construct material interfaces for non-manifold mesh extraction.", "result": "The method robustly handles complex non-manifold surfaces and outperforms existing techniques in experiments.", "conclusion": "MIND enables accurate non-manifold mesh extraction from UDFs, overcoming key limitations of prior approaches."}}
{"id": "2506.03066", "pdf": "https://arxiv.org/pdf/2506.03066", "abs": "https://arxiv.org/abs/2506.03066", "authors": ["Qining Zhang", "Lei Ying"], "title": "Provable Reinforcement Learning from Human Feedback with an Unknown Link Function", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "Link functions, which characterize how human preferences are generated from\nthe value function of an RL problem, are a crucial component in designing RLHF\nalgorithms. Almost all RLHF algorithms, including state-of-the-art ones in\nempirical studies such as DPO and PPO, assume the link function is known to the\nagent (e.g., a logistic function according to the Bradley-Terry model), which\nis arguably unrealistic considering the complex nature of human preferences. To\navoid link function mis-specification, this paper studies general RLHF problems\nwith unknown link functions. We propose a novel policy optimization algorithm\ncalled ZSPO based on a new zeroth-order policy optimization method, where the\nkey is to use human preference to construct a parameter update direction that\nis positively correlated with the true policy gradient direction. ZSPO achieves\nit by estimating the sign of the value function difference instead of\nestimating the gradient from the value function difference, so it does not\nrequire knowing the link function. Under mild conditions, ZSPO converges to a\nstationary policy with a polynomial convergence rate depending on the number of\npolicy iterations and trajectories per iteration. Numerical results also show\nthe superiority of ZSPO under link function mismatch.", "AI": {"tldr": "The paper introduces ZSPO, a zeroth-order policy optimization algorithm for RLHF problems with unknown link functions, avoiding mis-specification issues and achieving convergence without knowing the link function.", "motivation": "Current RLHF algorithms assume known link functions (e.g., logistic), which is unrealistic due to human preference complexity. This work addresses link function mis-specification by studying RLHF with unknown link functions.", "method": "Proposes ZSPO, a zeroth-order policy optimization method that estimates the sign of value function differences to construct update directions, bypassing the need for link function knowledge.", "result": "ZSPO converges to a stationary policy with polynomial rates under mild conditions and outperforms in link function mismatch scenarios.", "conclusion": "ZSPO effectively handles unknown link functions, offering a robust alternative to traditional RLHF methods."}}
{"id": "2506.03097", "pdf": "https://arxiv.org/pdf/2506.03097", "abs": "https://arxiv.org/abs/2506.03097", "authors": ["Ashwin Vinod", "Shrey Pandit", "Aditya Vavre", "Linshen Liu"], "title": "EgoVLM: Policy Optimization for Egocentric Video Understanding", "categories": ["cs.CV", "cs.AI"], "comment": "Our Code can be found at https://github.com/adityavavre/VidEgoVLM", "summary": "Emerging embodied AI applications, such as wearable cameras and autonomous\nagents, have underscored the need for robust reasoning from first person video\nstreams. We introduce EgoVLM, a vision-language model specifically designed to\nintegrate visual comprehension and spatial-temporal reasoning within egocentric\nvideo contexts. EgoVLM is fine-tuned via Group Relative Policy Optimization\n(GRPO), a reinforcement learning method adapted to align model outputs with\nhuman-like reasoning steps. Following DeepSeek R1-Zero's approach, we directly\ntune using RL without any supervised fine-tuning phase on chain-of-thought\n(CoT) data. We evaluate EgoVLM on egocentric video question answering\nbenchmarks and show that domain-specific training substantially improves\nperformance over general-purpose VLMs. Our EgoVLM-3B, trained exclusively on\nnon-CoT egocentric data, outperforms the base Qwen2.5-VL 3B and 7B models by\n14.33 and 13.87 accuracy points on the EgoSchema benchmark, respectively. By\nexplicitly generating reasoning traces, EgoVLM enhances interpretability,\nmaking it well-suited for downstream applications. Furthermore, we introduce a\nnovel keyframe-based reward that incorporates salient frame selection to guide\nreinforcement learning optimization. This reward formulation opens a promising\navenue for future exploration in temporally grounded egocentric reasoning.", "AI": {"tldr": "EgoVLM is a vision-language model for egocentric video reasoning, fine-tuned with GRPO, outperforming general-purpose VLMs and enhancing interpretability with reasoning traces.", "motivation": "Addressing the need for robust reasoning in first-person video streams for embodied AI applications.", "method": "Fine-tuned via Group Relative Policy Optimization (GRPO) without supervised fine-tuning, using a novel keyframe-based reward.", "result": "EgoVLM-3B outperforms Qwen2.5-VL models by 14.33 and 13.87 accuracy points on EgoSchema.", "conclusion": "EgoVLM improves performance and interpretability, with potential for future exploration in egocentric reasoning."}}
{"id": "2506.03147", "pdf": "https://arxiv.org/pdf/2506.03147", "abs": "https://arxiv.org/abs/2506.03147", "authors": ["Bin Lin", "Zongjian Li", "Xinhua Cheng", "Yuwei Niu", "Yang Ye", "Xianyi He", "Shenghai Yuan", "Wangbo Yu", "Shaodong Wang", "Yunyang Ge", "Yatian Pang", "Li Yuan"], "title": "UniWorld: High-Resolution Semantic Encoders for Unified Visual Understanding and Generation", "categories": ["cs.CV", "cs.AI", "cs.CL"], "comment": null, "summary": "Although existing unified models deliver strong performance on\nvision-language understanding and text-to-image generation, their models are\nlimited in exploring image perception and manipulation tasks, which are\nurgently desired by users for wide applications. Recently, OpenAI released\ntheir powerful GPT-4o-Image model for comprehensive image perception and\nmanipulation, achieving expressive capability and attracting community\ninterests. By observing the performance of GPT-4o-Image in our carefully\nconstructed experiments, we infer that GPT-4o-Image leverages features\nextracted by semantic encoders instead of VAE, while VAEs are considered\nessential components in many image manipulation models. Motivated by such\ninspiring observations, we present a unified generative framework named\nUniWorld based on semantic features provided by powerful visual-language models\nand contrastive semantic encoders. As a result, we build a strong unified model\nusing only 1% amount of BAGEL's data, which consistently outperforms BAGEL on\nimage editing benchmarks. UniWorld also maintains competitive image\nunderstanding and generation capabilities, achieving strong performance across\nmultiple image perception tasks. We fully open-source our models, including\nmodel weights, training and evaluation scripts, and datasets.", "AI": {"tldr": "UniWorld is a unified generative framework leveraging semantic features from visual-language models, outperforming BAGEL in image editing with minimal data and maintaining strong image understanding and generation capabilities.", "motivation": "Existing models lack image perception and manipulation capabilities, while GPT-4o-Image's performance suggests semantic encoders are superior to VAEs.", "method": "UniWorld uses semantic features from visual-language models and contrastive semantic encoders, trained with only 1% of BAGEL's data.", "result": "UniWorld outperforms BAGEL on image editing benchmarks and excels in image understanding and generation tasks.", "conclusion": "UniWorld is a strong, efficient, and open-source unified model for image perception and manipulation."}}
{"id": "2506.02964", "pdf": "https://arxiv.org/pdf/2506.02964", "abs": "https://arxiv.org/abs/2506.02964", "authors": ["Guiqiu Liao", "Matjaz Jogan", "Eric Eaton", "Daniel A. Hashimoto"], "title": "FORLA:Federated Object-centric Representation Learning with Slot Attention", "categories": ["cs.CV", "cs.LG"], "comment": "24 pages, 6 figures", "summary": "Learning efficient visual representations across heterogeneous unlabeled\ndatasets remains a central challenge in federated learning. Effective federated\nrepresentations require features that are jointly informative across clients\nwhile disentangling domain-specific factors without supervision. We introduce\nFORLA, a novel framework for federated object-centric representation learning\nand feature adaptation across clients using unsupervised slot attention. At the\ncore of our method is a shared feature adapter, trained collaboratively across\nclients to adapt features from foundation models, and a shared slot attention\nmodule that learns to reconstruct the adapted features. To optimize this\nadapter, we design a two-branch student-teacher architecture. In each client, a\nstudent decoder learns to reconstruct full features from foundation models,\nwhile a teacher decoder reconstructs their adapted, low-dimensional\ncounterpart. The shared slot attention module bridges cross-domain learning by\naligning object-level representations across clients. Experiments in multiple\nreal-world datasets show that our framework not only outperforms centralized\nbaselines on object discovery but also learns a compact, universal\nrepresentation that generalizes well across domains. This work highlights\nfederated slot attention as an effective tool for scalable, unsupervised visual\nrepresentation learning from cross-domain data with distributed concepts.", "AI": {"tldr": "FORLA introduces a federated learning framework for unsupervised object-centric representation learning using slot attention, outperforming centralized baselines in object discovery and cross-domain generalization.", "motivation": "The challenge of learning efficient visual representations across heterogeneous unlabeled datasets in federated learning, requiring jointly informative features while disentangling domain-specific factors.", "method": "FORLA uses a shared feature adapter and slot attention module, trained via a two-branch student-teacher architecture to reconstruct and align features across clients.", "result": "Outperforms centralized baselines in object discovery and learns compact, universal representations that generalize well across domains.", "conclusion": "Federated slot attention is effective for scalable, unsupervised visual representation learning from distributed cross-domain data."}}
{"id": "2506.03075", "pdf": "https://arxiv.org/pdf/2506.03075", "abs": "https://arxiv.org/abs/2506.03075", "authors": ["Bogdan Chornomaz", "Yonatan Koren", "Shay Moran", "Tom Waknine"], "title": "Agnostic Learning under Targeted Poisoning: Optimal Rates and the Role of Randomness", "categories": ["cs.LG", "math.PR", "68Q32", "I.2.6"], "comment": null, "summary": "We study the problem of learning in the presence of an adversary that can\ncorrupt an $\\eta$ fraction of the training examples with the goal of causing\nfailure on a specific test point. In the realizable setting, prior work\nestablished that the optimal error under such instance-targeted poisoning\nattacks scales as $\\Theta(d\\eta)$, where $d$ is the VC dimension of the\nhypothesis class arXiv:2210.02713. In this work, we resolve the corresponding\nquestion in the agnostic setting. We show that the optimal excess error is\n$\\tilde{\\Theta}(\\sqrt{d\\eta})$, answering one of the main open problems left by\nHanneke et al. To achieve this rate, it is necessary to use randomized\nlearners: Hanneke et al. showed that deterministic learners can be forced to\nsuffer error close to 1, even under small amounts of poisoning. Perhaps\nsurprisingly, our upper bound remains valid even when the learner's random bits\nare fully visible to the adversary . In the other direction, our lower bound is\nstronger than standard PAC-style bounds: instead of tailoring a hard\ndistribution separately for each sample size, we exhibit a single fixed\ndistribution under which the adversary can enforce an excess error of\n$\\Omega(\\sqrt{d\\eta})$ infinitely often.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2506.03102", "pdf": "https://arxiv.org/pdf/2506.03102", "abs": "https://arxiv.org/abs/2506.03102", "authors": ["Sophie Greenwood", "Karen Levy", "Solon Barocas", "Hoda Heidari", "Jon Kleinberg"], "title": "Designing Algorithmic Delegates: The Role of Indistinguishability in Human-AI Handoff", "categories": ["cs.GT", "cs.AI", "cs.CY"], "comment": "Accepted at the Twenty-Sixth ACM Conference on Economics and\n  Computation (EC'25)", "summary": "As AI technologies improve, people are increasingly willing to delegate tasks\nto AI agents. In many cases, the human decision-maker chooses whether to\ndelegate to an AI agent based on properties of the specific instance of the\ndecision-making problem they are facing. Since humans typically lack full\nawareness of all the factors relevant to this choice for a given\ndecision-making instance, they perform a kind of categorization by treating\nindistinguishable instances -- those that have the same observable features --\nas the same. In this paper, we define the problem of designing the optimal\nalgorithmic delegate in the presence of categories. This is an important\ndimension in the design of algorithms to work with humans, since we show that\nthe optimal delegate can be an arbitrarily better teammate than the optimal\nstandalone algorithmic agent. The solution to this optimal delegation problem\nis not obvious: we discover that this problem is fundamentally combinatorial,\nand illustrate the complex relationship between the optimal design and the\nproperties of the decision-making task even in simple settings. Indeed, we show\nthat finding the optimal delegate is computationally hard in general. However,\nwe are able to find efficient algorithms for producing the optimal delegate in\nseveral broad cases of the problem, including when the optimal action may be\ndecomposed into functions of features observed by the human and the algorithm.\nFinally, we run computational experiments to simulate a designer updating an\nalgorithmic delegate over time to be optimized for when it is actually adopted\nby users, and show that while this process does not recover the optimal\ndelegate in general, the resulting delegate often performs quite well.", "AI": {"tldr": "The paper explores designing optimal AI delegates for human decision-making, considering categorization by humans. It shows the problem is combinatorial and computationally hard but provides efficient solutions for specific cases.", "motivation": "Humans often delegate tasks to AI based on observable features, but lack full awareness of relevant factors. This paper addresses designing optimal AI delegates to improve teamwork with humans.", "method": "Defines the problem of optimal delegation with categories, analyzes its combinatorial nature, and provides efficient algorithms for specific cases, including feature decomposition. Computational experiments simulate real-world adoption.", "result": "The optimal delegate can outperform standalone AI agents, though finding it is computationally hard. Efficient solutions exist for certain cases, and simulated updates yield practical performance.", "conclusion": "Optimal delegation design is complex but feasible in specific scenarios, enhancing human-AI collaboration despite computational challenges."}}
{"id": "2110.13658", "pdf": "https://arxiv.org/pdf/2110.13658", "abs": "https://arxiv.org/abs/2110.13658", "authors": ["Arij Riabi", "Beno\u00eet Sagot", "Djam\u00e9 Seddah"], "title": "Can Character-based Language Models Improve Downstream Task Performance in Low-Resource and Noisy Language Scenarios?", "categories": ["cs.CL", "cs.LG"], "comment": "updated version with new results", "summary": "Recent impressive improvements in NLP, largely based on the success of\ncontextual neural language models, have been mostly demonstrated on at most a\ncouple dozen high-resource languages. Building language models and, more\ngenerally, NLP systems for non-standardized and low-resource languages remains\na challenging task. In this work, we focus on North-African colloquial\ndialectal Arabic written using an extension of the Latin script, called\nNArabizi, found mostly on social media and messaging communication. In this\nlow-resource scenario with data displaying a high level of variability, we\ncompare the downstream performance of a character-based language model on\npart-of-speech tagging and dependency parsing to that of monolingual and\nmultilingual models. We show that a character-based model trained on only 99k\nsentences of NArabizi and fined-tuned on a small treebank of this language\nleads to performance close to those obtained with the same architecture\npre-trained on large multilingual and monolingual models. Confirming these\nresults a on much larger data set of noisy French user-generated content, we\nargue that such character-based language models can be an asset for NLP in\nlow-resource and high language variability set-tings.", "AI": {"tldr": "A character-based language model for low-resource NArabizi performs comparably to large multilingual/monolingual models on POS tagging and dependency parsing.", "motivation": "Addressing the challenge of NLP for non-standardized, low-resource languages like NArabizi.", "method": "Compare a character-based model (trained on 99k NArabizi sentences) to monolingual/multilingual models for POS tagging and dependency parsing.", "result": "Character-based model achieves performance close to larger models. Results confirmed on noisy French data.", "conclusion": "Character-based models are effective for low-resource, high-variability languages."}}
{"id": "2506.03007", "pdf": "https://arxiv.org/pdf/2506.03007", "abs": "https://arxiv.org/abs/2506.03007", "authors": ["Jiarui Wang", "Huiyu Duan", "Juntong Wang", "Ziheng Jia", "Woo Yi Yang", "Xiaorong Zhu", "Yu Zhao", "Jiaying Qian", "Yuke Xing", "Guangtao Zhai", "Xiongkuo Min"], "title": "DFBench: Benchmarking Deepfake Image Detection Capability of Large Multimodal Models", "categories": ["cs.CV"], "comment": null, "summary": "With the rapid advancement of generative models, the realism of AI-generated\nimages has significantly improved, posing critical challenges for verifying\ndigital content authenticity. Current deepfake detection methods often depend\non datasets with limited generation models and content diversity that fail to\nkeep pace with the evolving complexity and increasing realism of the\nAI-generated content. Large multimodal models (LMMs), widely adopted in various\nvision tasks, have demonstrated strong zero-shot capabilities, yet their\npotential in deepfake detection remains largely unexplored. To bridge this gap,\nwe present \\textbf{DFBench}, a large-scale DeepFake Benchmark featuring (i)\nbroad diversity, including 540,000 images across real, AI-edited, and\nAI-generated content, (ii) latest model, the fake images are generated by 12\nstate-of-the-art generation models, and (iii) bidirectional benchmarking and\nevaluating for both the detection accuracy of deepfake detectors and the\nevasion capability of generative models. Based on DFBench, we propose\n\\textbf{MoA-DF}, Mixture of Agents for DeepFake detection, leveraging a\ncombined probability strategy from multiple LMMs. MoA-DF achieves\nstate-of-the-art performance, further proving the effectiveness of leveraging\nLMMs for deepfake detection. Database and codes are publicly available at\nhttps://github.com/IntMeGroup/DFBench.", "AI": {"tldr": "The paper introduces DFBench, a large-scale deepfake benchmark, and MoA-DF, a detection method using multiple LMMs, achieving state-of-the-art performance.", "motivation": "Addressing the challenge of verifying digital content authenticity due to the rapid advancement of highly realistic AI-generated images.", "method": "Develops DFBench with diverse datasets and proposes MoA-DF, leveraging multiple LMMs for detection.", "result": "MoA-DF achieves state-of-the-art performance in deepfake detection.", "conclusion": "LMMs are effective for deepfake detection, and DFBench provides a robust benchmark for future research."}}
{"id": "2506.03085", "pdf": "https://arxiv.org/pdf/2506.03085", "abs": "https://arxiv.org/abs/2506.03085", "authors": ["Thomas Chen", "Tengyu Ma", "Zhiyuan Li"], "title": "Non-Asymptotic Length Generalization", "categories": ["cs.LG"], "comment": null, "summary": "Length generalization is the ability of a learning algorithm to learn a\nhypothesis which generalizes to longer inputs than the inputs in the training\nset. In this paper, we provide provable guarantees of length generalization for\nvarious classes of functions in an idealized setting. First, we formalize the\nframework of non-asymptotic length generalization, which requires a computable\nupper bound for the minimum input length that guarantees length generalization,\nas a function of the complexity of ground-truth function under some given\ncomplexity measure. We refer to this minimum input length to length generalize\nas length complexity. We show the Minimum-Complexity Interpolator learning\nalgorithm achieves optimal length complexity. We further show that whether a\nfunction class admits non-asymptotic length generalization is equivalent to the\ndecidability of its language equivalence problem, which implies that there is\nno computable upper bound for the length complexity of Context-Free Grammars.\nOn the positive side, we show that the length complexity of Deterministic\nFinite Automata is $2n - 2$ where $n$ is the number of states of the\nground-truth automaton. Our main results are upper bounds of length complexity\nfor a subset of a transformer-related function class called C-RASP (Yang &\nChiang, 2024). We show that the length complexity of 1-layer C-RASP functions\nis $O(T^2)$ when the ground-truth function has precision $T$, and that the\nlength complexity of 2-layer C-RASP functions is $O(T^{O(K)})$ when the\nground-truth function has precision $T$ and $K$ heads.", "AI": {"tldr": "The paper provides provable guarantees for length generalization in learning algorithms, formalizing non-asymptotic length generalization and showing optimality for certain function classes.", "motivation": "To understand and quantify the ability of learning algorithms to generalize to longer inputs than those seen in training.", "method": "Formalizes non-asymptotic length generalization, analyzes length complexity, and evaluates learning algorithms like Minimum-Complexity Interpolator.", "result": "Optimal length complexity for certain classes, decidability implications for Context-Free Grammars, and bounds for C-RASP functions.", "conclusion": "Length generalization can be quantified and optimized for specific function classes, with implications for learning algorithms."}}
{"id": "2506.03133", "pdf": "https://arxiv.org/pdf/2506.03133", "abs": "https://arxiv.org/abs/2506.03133", "authors": ["Kai Lion", "Liang Zhang", "Bingcong Li", "Niao He"], "title": "PoLAR: Polar-Decomposed Low-Rank Adapter Representation", "categories": ["cs.LG", "cs.AI", "eess.SP", "math.OC"], "comment": null, "summary": "We show that low-rank adaptation of large-scale models suffers from a low\nstable rank that is well below the linear algebraic rank of the subspace,\ndegrading fine-tuning performance. To mitigate the underutilization of the\nallocated subspace, we propose PoLAR, a parameterization inspired by the polar\ndecomposition that factorizes the low-rank update into two direction matrices\nconstrained to Stiefel manifolds and an unconstrained scale matrix. Our theory\nshows that PoLAR yields an exponentially faster convergence rate on a canonical\nlow-rank adaptation problem. Pairing the parameterization with Riemannian\noptimization leads to consistent gains on three different benchmarks testing\ngeneral language understanding, commonsense reasoning, and mathematical problem\nsolving with base model sizes ranging from 350M to 27B.", "AI": {"tldr": "PoLAR improves low-rank adaptation by addressing underutilization of subspaces, achieving faster convergence and better performance across benchmarks.", "motivation": "Low-rank adaptation in large-scale models suffers from underutilization of subspaces, degrading fine-tuning performance.", "method": "Proposes PoLAR, a parameterization using polar decomposition to factorize updates into direction matrices on Stiefel manifolds and an unconstrained scale matrix, paired with Riemannian optimization.", "result": "PoLAR achieves exponentially faster convergence and consistent gains on benchmarks for language understanding, reasoning, and problem-solving.", "conclusion": "PoLAR effectively mitigates subspace underutilization, enhancing fine-tuning performance in large-scale models."}}
{"id": "2111.00157", "pdf": "https://arxiv.org/pdf/2111.00157", "abs": "https://arxiv.org/abs/2111.00157", "authors": ["Jue Wang"], "title": "TransAug: Translate as Augmentation for Sentence Embeddings", "categories": ["cs.CL"], "comment": null, "summary": "While contrastive learning greatly advances the representation of sentence\nembeddings, it is still limited by the size of the existing sentence datasets.\nIn this paper, we present TransAug (Translate as Augmentation), which provide\nthe first exploration of utilizing translated sentence pairs as data\naugmentation for text, and introduce a two-stage paradigm to advances the\nstate-of-the-art sentence embeddings. Instead of adopting an encoder trained in\nother languages setting, we first distill a Chinese encoder from a SimCSE\nencoder (pretrained in English), so that their embeddings are close in semantic\nspace, which can be regraded as implicit data augmentation. Then, we only\nupdate the English encoder via cross-lingual contrastive learning and frozen\nthe distilled Chinese encoder. Our approach achieves a new state-of-art on\nstandard semantic textual similarity (STS), outperforming both SimCSE and\nSentence-T5, and the best performance in corresponding tracks on transfer tasks\nevaluated by SentEval.", "AI": {"tldr": "TransAug introduces a two-stage method using translated sentence pairs for data augmentation, improving sentence embeddings and achieving state-of-the-art results on STS and transfer tasks.", "motivation": "Existing sentence datasets limit contrastive learning for sentence embeddings. TransAug explores translation-based augmentation to overcome this.", "method": "1. Distill a Chinese encoder from a pretrained English SimCSE encoder. 2. Update the English encoder via cross-lingual contrastive learning while freezing the Chinese encoder.", "result": "Achieves state-of-the-art on STS and outperforms SimCSE and Sentence-T5. Best performance on transfer tasks in SentEval.", "conclusion": "TransAug demonstrates the effectiveness of translation-based augmentation and cross-lingual learning for advancing sentence embeddings."}}
{"id": "2506.03067", "pdf": "https://arxiv.org/pdf/2506.03067", "abs": "https://arxiv.org/abs/2506.03067", "authors": ["Mingzhe Li", "Gehao Zhang", "Zhenting Wang", "Shiqing Ma", "Siqi Pan", "Richard Cartwright", "Juan Zhai"], "title": "EDITOR: Effective and Interpretable Prompt Inversion for Text-to-Image Diffusion Models", "categories": ["cs.CV"], "comment": null, "summary": "Text-to-image generation models~(e.g., Stable Diffusion) have achieved\nsignificant advancements, enabling the creation of high-quality and realistic\nimages based on textual descriptions. Prompt inversion, the task of identifying\nthe textual prompt used to generate a specific artifact, holds significant\npotential for applications including data attribution, model provenance, and\nwatermarking validation. Recent studies introduced a delayed projection scheme\nto optimize for prompts representative of the vocabulary space, though\nchallenges in semantic fluency and efficiency remain. Advanced image captioning\nmodels or visual large language models can generate highly interpretable\nprompts, but they often lack in image similarity. In this paper, we propose a\nprompt inversion technique called \\sys for text-to-image diffusion models,\nwhich includes initializing embeddings using a pre-trained image captioning\nmodel, refining them through reverse-engineering in the latent space, and\nconverting them to texts using an embedding-to-text model. Our experiments on\nthe widely-used datasets, such as MS COCO, LAION, and Flickr, show that our\nmethod outperforms existing methods in terms of image similarity, textual\nalignment, prompt interpretability and generalizability. We further illustrate\nthe application of our generated prompts in tasks such as cross-concept image\nsynthesis, concept manipulation, evolutionary multi-concept generation and\nunsupervised segmentation.", "AI": {"tldr": "The paper introduces a prompt inversion technique called \\sys for text-to-image diffusion models, improving image similarity, textual alignment, and interpretability over existing methods.", "motivation": "Prompt inversion is valuable for data attribution, model provenance, and watermarking validation, but current methods struggle with semantic fluency and efficiency.", "method": "The technique initializes embeddings using a pre-trained image captioning model, refines them via reverse-engineering in latent space, and converts them to text with an embedding-to-text model.", "result": "Experiments on MS COCO, LAION, and Flickr show superior performance in image similarity, textual alignment, and interpretability.", "conclusion": "The method's effectiveness is demonstrated in tasks like cross-concept image synthesis and unsupervised segmentation, highlighting its broad applicability."}}
{"id": "2506.03093", "pdf": "https://arxiv.org/pdf/2506.03093", "abs": "https://arxiv.org/abs/2506.03093", "authors": ["Val\u00e9rie Costa", "Thomas Fel", "Ekdeep Singh Lubana", "Bahareh Tolooshams", "Demba Ba"], "title": "From Flat to Hierarchical: Extracting Sparse Representations with Matching Pursuit", "categories": ["cs.LG"], "comment": "Preprint", "summary": "Motivated by the hypothesis that neural network representations encode\nabstract, interpretable features as linearly accessible, approximately\northogonal directions, sparse autoencoders (SAEs) have become a popular tool in\ninterpretability. However, recent work has demonstrated phenomenology of model\nrepresentations that lies outside the scope of this hypothesis, showing\nsignatures of hierarchical, nonlinear, and multi-dimensional features. This\nraises the question: do SAEs represent features that possess structure at odds\nwith their motivating hypothesis? If not, does avoiding this mismatch help\nidentify said features and gain further insights into neural network\nrepresentations? To answer these questions, we take a construction-based\napproach and re-contextualize the popular matching pursuits (MP) algorithm from\nsparse coding to design MP-SAE -- an SAE that unrolls its encoder into a\nsequence of residual-guided steps, allowing it to capture hierarchical and\nnonlinearly accessible features. Comparing this architecture with existing SAEs\non a mixture of synthetic and natural data settings, we show: (i) hierarchical\nconcepts induce conditionally orthogonal features, which existing SAEs are\nunable to faithfully capture, and (ii) the nonlinear encoding step of MP-SAE\nrecovers highly meaningful features, helping us unravel shared structure in the\nseemingly dichotomous representation spaces of different modalities in a\nvision-language model, hence demonstrating the assumption that useful features\nare solely linearly accessible is insufficient. We also show that the\nsequential encoder principle of MP-SAE affords an additional benefit of\nadaptive sparsity at inference time, which may be of independent interest.\nOverall, we argue our results provide credence to the idea that\ninterpretability should begin with the phenomenology of representations, with\nmethods emerging from assumptions that fit it.", "AI": {"tldr": "The paper explores whether sparse autoencoders (SAEs) can capture hierarchical and nonlinear features in neural networks, proposing MP-SAE, a modified SAE that addresses limitations of existing methods.", "motivation": "The study is motivated by the hypothesis that neural network features are linearly accessible and orthogonal, but recent findings suggest hierarchical and nonlinear features exist, questioning SAEs' effectiveness.", "method": "The authors introduce MP-SAE, a variant of SAE based on the matching pursuits algorithm, designed to capture hierarchical and nonlinear features through residual-guided steps.", "result": "MP-SAE outperforms existing SAEs in capturing hierarchical concepts and nonlinear features, revealing shared structures in vision-language models and enabling adaptive sparsity.", "conclusion": "The results support the idea that interpretability methods should align with the phenomenology of representations, emphasizing the need for assumptions that fit observed features."}}
{"id": "2506.03139", "pdf": "https://arxiv.org/pdf/2506.03139", "abs": "https://arxiv.org/abs/2506.03139", "authors": ["Siqi Chen", "Xinyu Dong", "Haolei Xu", "Xingyu Wu", "Fei Tang", "Hang Zhang", "Yuchen Yan", "Linjuan Wu", "Wenqi Zhang", "Guiyang Hou", "Yongliang Shen", "Weiming Lu", "Yueting Zhuang"], "title": "SVGenius: Benchmarking LLMs in SVG Understanding, Editing and Generation", "categories": ["cs.CV", "cs.AI"], "comment": "19 pages,4 figures, Project page:\n  https://zju-real.github.io/SVGenius, Code:\n  https://github.com/ZJU-REAL/SVGenius-Bench", "summary": "Large Language Models (LLMs) and Multimodal LLMs have shown promising\ncapabilities for SVG processing, yet existing benchmarks suffer from limited\nreal-world coverage, lack of complexity stratification, and fragmented\nevaluation paradigms. We introduce SVGenius, a comprehensive benchmark\ncomprising 2,377 queries across three progressive dimensions: understanding,\nediting, and generation. Built on real-world data from 24 application domains\nwith systematic complexity stratification, SVGenius evaluates models through 8\ntask categories and 18 metrics. We assess 22 mainstream models spanning\ndifferent scales, architectures, training paradigms, and accessibility levels.\nOur analysis reveals that while proprietary models significantly outperform\nopen-source counterparts, all models exhibit systematic performance degradation\nwith increasing complexity, indicating fundamental limitations in current\napproaches; however, reasoning-enhanced training proves more effective than\npure scaling for overcoming these limitations, though style transfer remains\nthe most challenging capability across all model types. SVGenius establishes\nthe first systematic evaluation framework for SVG processing, providing crucial\ninsights for developing more capable vector graphics models and advancing\nautomated graphic design applications. Appendix and supplementary materials\n(including all data and code) are available at\nhttps://zju-real.github.io/SVGenius.", "AI": {"tldr": "SVGenius is a benchmark for evaluating SVG processing in LLMs, covering 2,377 queries across understanding, editing, and generation tasks. It reveals proprietary models outperform open-source ones, with reasoning-enhanced training being more effective than scaling.", "motivation": "Existing benchmarks for SVG processing lack real-world coverage, complexity stratification, and unified evaluation. SVGenius addresses these gaps.", "method": "SVGenius includes 2,377 queries across 24 domains, evaluated through 8 task categories and 18 metrics, testing 22 models of varying scales and architectures.", "result": "Proprietary models outperform open-source ones, but all degrade with complexity. Reasoning-enhanced training helps, but style transfer remains challenging.", "conclusion": "SVGenius provides a systematic framework for evaluating SVG processing, offering insights for improving vector graphics models and graphic design automation."}}
{"id": "2303.12892", "pdf": "https://arxiv.org/pdf/2303.12892", "abs": "https://arxiv.org/abs/2303.12892", "authors": ["Thanh-Dung Le", "Philippe Jouvet", "Rita Noumeir"], "title": "Improving Transformer Performance for French Clinical Notes Classification Using Mixture of Experts on a Limited Dataset", "categories": ["cs.CL", "eess.SP"], "comment": "Accepted for publication in the IEEE Journal of Translational\n  Engineering in Health and Medicine", "summary": "Transformer-based models have shown outstanding results in natural language\nprocessing but face challenges in applications like classifying small-scale\nclinical texts, especially with constrained computational resources. This study\npresents a customized Mixture of Expert (MoE) Transformer models for\nclassifying small-scale French clinical texts at CHU Sainte-Justine Hospital.\nThe MoE-Transformer addresses the dual challenges of effective training with\nlimited data and low-resource computation suitable for in-house hospital use.\nDespite the success of biomedical pre-trained models such as CamemBERT-bio,\nDrBERT, and AliBERT, their high computational demands make them impractical for\nmany clinical settings. Our MoE-Transformer model not only outperforms\nDistillBERT, CamemBERT, FlauBERT, and Transformer models on the same dataset\nbut also achieves impressive results: an accuracy of 87\\%, precision of 87\\%,\nrecall of 85\\%, and F1-score of 86\\%. While the MoE-Transformer does not\nsurpass the performance of biomedical pre-trained BERT models, it can be\ntrained at least 190 times faster, offering a viable alternative for settings\nwith limited data and computational resources. Although the MoE-Transformer\naddresses challenges of generalization gaps and sharp minima, demonstrating\nsome limitations for efficient and accurate clinical text classification, this\nmodel still represents a significant advancement in the field. It is\nparticularly valuable for classifying small French clinical narratives within\nthe privacy and constraints of hospital-based computational resources.", "AI": {"tldr": "A customized Mixture of Expert (MoE) Transformer model is proposed for classifying small-scale French clinical texts, outperforming other models in speed and efficiency while maintaining competitive accuracy.", "motivation": "Transformer models face challenges in small-scale clinical text classification due to limited data and computational resources. This study aims to address these issues for hospital use.", "method": "The study introduces a MoE-Transformer model tailored for small-scale French clinical texts, focusing on efficient training with limited data and low-resource computation.", "result": "The MoE-Transformer achieves 87% accuracy, 87% precision, 85% recall, and 86% F1-score, training 190 times faster than biomedical pre-trained BERT models.", "conclusion": "The MoE-Transformer is a viable alternative for clinical settings with limited resources, advancing small French clinical text classification despite some limitations."}}
{"id": "2506.03073", "pdf": "https://arxiv.org/pdf/2506.03073", "abs": "https://arxiv.org/abs/2506.03073", "authors": ["Roman Titkov", "Egor Zubkov", "Dmitry Yudin", "Jaafar Mahmoud", "Malik Mohrat", "Gennady Sidorov"], "title": "LEG-SLAM: Real-Time Language-Enhanced Gaussian Splatting for SLAM", "categories": ["cs.CV"], "comment": null, "summary": "Modern Gaussian Splatting methods have proven highly effective for real-time\nphotorealistic rendering of 3D scenes. However, integrating semantic\ninformation into this representation remains a significant challenge,\nespecially in maintaining real-time performance for SLAM (Simultaneous\nLocalization and Mapping) applications. In this work, we introduce LEG-SLAM --\na novel approach that fuses an optimized Gaussian Splatting implementation with\nvisual-language feature extraction using DINOv2 followed by a learnable feature\ncompressor based on Principal Component Analysis, while enabling an online\ndense SLAM. Our method simultaneously generates high-quality photorealistic\nimages and semantically labeled scene maps, achieving real-time scene\nreconstruction with more than 10 fps on the Replica dataset and 18 fps on\nScanNet. Experimental results show that our approach significantly outperforms\nstate-of-the-art methods in reconstruction speed while achieving competitive\nrendering quality. The proposed system eliminates the need for prior data\npreparation such as camera's ego motion or pre-computed static semantic maps.\nWith its potential applications in autonomous robotics, augmented reality, and\nother interactive domains, LEG-SLAM represents a significant step forward in\nreal-time semantic 3D Gaussian-based SLAM. Project page:\nhttps://titrom025.github.io/LEG-SLAM/", "AI": {"tldr": "LEG-SLAM integrates Gaussian Splatting with visual-language features for real-time semantic 3D SLAM, achieving high fps and competitive rendering quality.", "motivation": "The challenge of integrating semantic information into Gaussian Splatting for real-time SLAM applications.", "method": "Combines optimized Gaussian Splatting, DINOv2 for feature extraction, and a PCA-based feature compressor for online dense SLAM.", "result": "Achieves 10+ fps on Replica and 18 fps on ScanNet, outperforming state-of-the-art in speed with competitive quality.", "conclusion": "LEG-SLAM advances real-time semantic 3D SLAM, suitable for robotics and AR, without needing pre-computed data."}}
{"id": "2506.03109", "pdf": "https://arxiv.org/pdf/2506.03109", "abs": "https://arxiv.org/abs/2506.03109", "authors": ["Wei Yao", "Gengze Xu", "Huayi Tang", "Wenkai Yang", "Donglin Di", "Ziqiao Wang", "Yong Liu"], "title": "On Weak-to-Strong Generalization and f-Divergence", "categories": ["cs.LG"], "comment": null, "summary": "Weak-to-strong generalization (W2SG) has emerged as a promising paradigm for\nstimulating the capabilities of strong pre-trained models by leveraging\nsupervision from weaker supervisors. To improve the performance of the strong\nmodel, existing methods often require additional weak models or complex\nprocedures, leading to substantial computational and memory overhead. Motivated\nby the effectiveness of $f$-divergence loss in various machine learning\ndomains, we introduce $f$-divergence as an information-theoretic loss function\nframework in W2SG. Our theoretical analysis reveals fundamental limitations and\nequivalence of different $f$-divergence losses in W2SG, supported by sample\ncomplexity bounds and information-theoretic insights. We empirically\ndemonstrate that $f$-divergence loss, which generalizes widely-used metrics\nlike KL divergence, effectively improves generalization and noise tolerance of\nthe strong model in practice.", "AI": {"tldr": "The paper introduces $f$-divergence loss in weak-to-strong generalization (W2SG) to improve strong models using weaker supervision, reducing computational overhead and enhancing performance.", "motivation": "Existing W2SG methods often require extra weak models or complex procedures, increasing computational and memory costs. The paper aims to address this by leveraging $f$-divergence loss.", "method": "The authors propose using $f$-divergence as an information-theoretic loss framework in W2SG, analyzing its theoretical limitations and equivalence.", "result": "Empirical results show $f$-divergence loss improves generalization and noise tolerance in strong models, outperforming traditional metrics like KL divergence.", "conclusion": "$f$-divergence loss is a practical and effective tool for W2SG, offering theoretical and empirical advantages over existing methods."}}
{"id": "2310.08367", "pdf": "https://arxiv.org/pdf/2310.08367", "abs": "https://arxiv.org/abs/2310.08367", "authors": ["Xinyue Zheng", "Haowei Lin", "Kaichen He", "Zihao Wang", "Zilong Zheng", "Yitao Liang"], "title": "MCU: An Evaluation Framework for Open-Ended Game Agents", "categories": ["cs.AI", "cs.CL", "cs.CV", "cs.LG"], "comment": null, "summary": "Developing AI agents capable of interacting with open-world environments to\nsolve diverse tasks is a compelling challenge. However, evaluating such\nopen-ended agents remains difficult, with current benchmarks facing scalability\nlimitations. To address this, we introduce Minecraft Universe (MCU), a\ncomprehensive evaluation framework set within the open-world video game\nMinecraft. MCU incorporates three key components: (1) an expanding collection\nof 3,452 composable atomic tasks that encompasses 11 major categories and 41\nsubcategories of challenges; (2) a task composition mechanism capable of\ngenerating infinite diverse tasks with varying difficulty; and (3) a general\nevaluation framework that achieves 91.5\\% alignment with human ratings for\nopen-ended task assessment. Empirical results reveal that even state-of-the-art\nfoundation agents struggle with the increasing diversity and complexity of\ntasks. These findings highlight the necessity of MCU as a robust benchmark to\ndrive progress in AI agent development within open-ended environments. Our\nevaluation code and scripts are available at\nhttps://github.com/CraftJarvis/MCU.", "AI": {"tldr": "The paper introduces Minecraft Universe (MCU), a scalable evaluation framework for AI agents in open-world environments, featuring composable tasks and a human-aligned assessment system.", "motivation": "Current benchmarks for open-ended AI agents lack scalability, necessitating a robust framework like MCU to evaluate diverse tasks effectively.", "method": "MCU includes 3,452 atomic tasks, a task composition mechanism for infinite task generation, and a general evaluation framework aligned with human ratings.", "result": "State-of-the-art AI agents struggle with MCU's diverse and complex tasks, demonstrating the framework's effectiveness.", "conclusion": "MCU serves as a vital benchmark for advancing AI agent development in open-ended environments."}}
{"id": "2403.04247", "pdf": "https://arxiv.org/pdf/2403.04247", "abs": "https://arxiv.org/abs/2403.04247", "authors": ["Yangning Li", "Qingsong Lv", "Tianyu Yu", "Yinghui Li", "Xuming Hu", "Wenhao Jiang", "Hai-Tao Zheng", "Hui Wang"], "title": "UltraWiki: Ultra-fine-grained Entity Set Expansion with Negative Seed Entities", "categories": ["cs.CL"], "comment": "Accepted by ICDE 2025", "summary": "Entity Set Expansion (ESE) aims to identify new entities belonging to the\nsame semantic class as the given set of seed entities. Traditional methods\nsolely relied on positive seed entities to represent the target fine-grained\nsemantic class, rendering them tough to represent ultra-fine-grained semantic\nclasses. Specifically, merely relying on positive seed entities leads to two\ninherent shortcomings: (i) Ambiguity among ultra-fine-grained semantic classes.\n(ii) Inability to define ``unwanted'' semantics. Hence, previous ESE methods\nstruggle to address the ultra-fine-grained ESE (Ultra-ESE) task. To solve this\nissue, we first introduce negative seed entities in the inputs, which jointly\ndescribe the ultra-fine-grained semantic class with positive seed entities.\nNegative seed entities eliminate the semantic ambiguity by providing a contrast\nbetween positive and negative attributes. Meanwhile, it provides a\nstraightforward way to express ``unwanted''. To assess model performance in\nUltra-ESE and facilitate further research, we also constructed UltraWiki, the\nfirst large-scale dataset tailored for Ultra-ESE. UltraWiki encompasses 50,973\nentities and 394,097 sentences, alongside 236 ultra-fine-grained semantic\nclasses, where each class is represented with 3-5 positive and negative seed\nentities. Moreover, a retrieval-based framework RetExpan and a generation-based\nframework GenExpan are proposed to provide powerful baselines for Ultra-ESE.\nAdditionally, we devised two strategies to enhance models' comprehension of\nultra-fine-grained entities' semantics: contrastive learning and\nchain-of-thought reasoning. Extensive experiments confirm the effectiveness of\nour proposed strategies and also reveal that there remains a large space for\nimprovement in Ultra-ESE.", "AI": {"tldr": "The paper introduces negative seed entities to improve Entity Set Expansion (ESE) for ultra-fine-grained semantic classes, addressing ambiguity and unwanted semantics. It presents UltraWiki, a dataset for Ultra-ESE, and proposes frameworks (RetExpan, GenExpan) and strategies (contrastive learning, chain-of-thought reasoning) to enhance performance.", "motivation": "Traditional ESE methods struggle with ultra-fine-grained semantic classes due to ambiguity and inability to define unwanted semantics. Negative seed entities are introduced to mitigate these issues.", "method": "The paper proposes using positive and negative seed entities to define semantic classes, introduces the UltraWiki dataset, and presents retrieval-based (RetExpan) and generation-based (GenExpan) frameworks. Strategies like contrastive learning and chain-of-thought reasoning are also devised.", "result": "Experiments confirm the effectiveness of the proposed strategies but highlight significant room for improvement in Ultra-ESE.", "conclusion": "The paper advances Ultra-ESE by introducing negative seed entities and new frameworks, though further research is needed to optimize performance."}}
{"id": "2506.03079", "pdf": "https://arxiv.org/pdf/2506.03079", "abs": "https://arxiv.org/abs/2506.03079", "authors": ["Xiuyu Yang", "Bohan Li", "Shaocong Xu", "Nan Wang", "Chongjie Ye", "Zhaoxi Chen", "Minghan Qin", "Yikang Ding", "Xin Jin", "Hang Zhao", "Hao Zhao"], "title": "ORV: 4D Occupancy-centric Robot Video Generation", "categories": ["cs.CV"], "comment": "Project page: https://orangesodahub.github.io/ORV/ ; Code:\n  https://github.com/OrangeSodahub/ORV", "summary": "Acquiring real-world robotic simulation data through teleoperation is\nnotoriously time-consuming and labor-intensive. Recently, action-driven\ngenerative models have gained widespread adoption in robot learning and\nsimulation, as they eliminate safety concerns and reduce maintenance efforts.\nHowever, the action sequences used in these methods often result in limited\ncontrol precision and poor generalization due to their globally coarse\nalignment. To address these limitations, we propose ORV, an Occupancy-centric\nRobot Video generation framework, which utilizes 4D semantic occupancy\nsequences as a fine-grained representation to provide more accurate semantic\nand geometric guidance for video generation. By leveraging occupancy-based\nrepresentations, ORV enables seamless translation of simulation data into\nphotorealistic robot videos, while ensuring high temporal consistency and\nprecise controllability. Furthermore, our framework supports the simultaneous\ngeneration of multi-view videos of robot gripping operations - an important\ncapability for downstream robotic learning tasks. Extensive experimental\nresults demonstrate that ORV consistently outperforms existing baseline methods\nacross various datasets and sub-tasks. Demo, Code and Model:\nhttps://orangesodahub.github.io/ORV", "AI": {"tldr": "ORV is a framework for generating photorealistic robot videos using 4D semantic occupancy sequences, improving precision and generalization over existing methods.", "motivation": "Traditional teleoperation for robotic simulation data is labor-intensive, and current generative models lack fine-grained control.", "method": "ORV uses 4D semantic occupancy sequences for fine-grained guidance in video generation, ensuring temporal consistency and controllability.", "result": "ORV outperforms baseline methods in generating multi-view robot gripping videos, enhancing downstream robotic learning.", "conclusion": "ORV provides a scalable and precise solution for generating realistic robot simulation videos, addressing limitations of prior methods."}}
{"id": "2506.03111", "pdf": "https://arxiv.org/pdf/2506.03111", "abs": "https://arxiv.org/abs/2506.03111", "authors": ["Victor Armegioiu", "Yannick Ramic", "Siddhartha Mishra"], "title": "Rectified Flows for Fast Multiscale Fluid Flow Modeling", "categories": ["cs.LG"], "comment": null, "summary": "The statistical modeling of fluid flows is very challenging due to their\nmultiscale dynamics and extreme sensitivity to initial conditions. While\nrecently proposed conditional diffusion models achieve high fidelity, they\ntypically require hundreds of stochastic sampling steps at inference. We\nintroduce a rectified flow framework that learns a time-dependent velocity\nfield, transporting input to output distributions along nearly straight\ntrajectories. By casting sampling as solving an ordinary differential equation\n(ODE) along this straighter flow field, our method makes each integration step\nmuch more effective, using as few as eight steps versus (more than) 128 steps\nin standard score-based diffusion, without sacrificing predictive fidelity.\nExperiments on challenging multiscale flow benchmarks show that rectified flows\nrecover the same posterior distributions as diffusion models, preserve\nfine-scale features that MSE-trained baselines miss, and deliver\nhigh-resolution samples in a fraction of inference time.", "AI": {"tldr": "Rectified flow framework improves fluid flow modeling by using straighter trajectories, reducing sampling steps from 128 to 8 without losing fidelity.", "motivation": "Addressing the inefficiency of conditional diffusion models in fluid flow modeling, which require many stochastic steps.", "method": "Introduces a rectified flow framework that learns a time-dependent velocity field for nearly straight trajectories, solving an ODE for efficient sampling.", "result": "Achieves same posterior distributions as diffusion models, preserves fine-scale features, and reduces inference time significantly.", "conclusion": "Rectified flows offer a faster, equally accurate alternative to diffusion models for multiscale fluid flow modeling."}}
{"id": "2403.15587", "pdf": "https://arxiv.org/pdf/2403.15587", "abs": "https://arxiv.org/abs/2403.15587", "authors": ["David Herrera-Poyatos", "Cristina Zuheros", "Rosana Montes", "Francisco Herrera"], "title": "Large language models for crowd decision making based on prompt design strategies using ChatGPT: models, analysis and challenges", "categories": ["cs.AI"], "comment": null, "summary": "Social Media and Internet have the potential to be exploited as a source of\nopinion to enrich Decision Making solutions. Crowd Decision Making (CDM) is a\nmethodology able to infer opinions and decisions from plain texts, such as\nreviews published in social media platforms, by means of Sentiment Analysis.\nCurrently, the emergence and potential of Large Language Models (LLMs) lead us\nto explore new scenarios of automatically understand written texts, also known\nas natural language processing. This paper analyzes the use of ChatGPT based on\nprompt design strategies to assist in CDM processes to extract opinions and\nmake decisions. We integrate ChatGPT in CDM processes as a flexible tool that\ninfer the opinions expressed in texts, providing numerical or linguistic\nevaluations where the decision making models are based on the prompt design\nstrategies. We include a multi-criteria decision making scenario with a\ncategory ontology for criteria. We also consider ChatGPT as an end-to-end CDM\nmodel able to provide a general opinion and score on the alternatives. We\nconduct empirical experiments on real data extracted from TripAdvisor, the\nTripR-2020Large dataset. The analysis of results show a promising branch for\ndeveloping quality decision making models using ChatGPT. Finally, we discuss\nthe challenges of consistency, sensitivity and explainability associated to the\nuse of LLMs in CDM processes, raising open questions for future studies.", "AI": {"tldr": "The paper explores using ChatGPT for Crowd Decision Making (CDM) by analyzing social media texts, demonstrating its potential in opinion extraction and decision-making through prompt design strategies.", "motivation": "To leverage Large Language Models (LLMs) like ChatGPT for enhancing CDM processes by automating opinion extraction from social media texts.", "method": "Integrates ChatGPT into CDM processes using prompt design strategies for inferring opinions, with experiments on real data from TripAdvisor (TripR-2020Large dataset).", "result": "Empirical results show promise for ChatGPT in developing quality decision-making models.", "conclusion": "The study highlights ChatGPT's potential in CDM but notes challenges like consistency, sensitivity, and explainability, suggesting future research directions."}}
{"id": "2403.09073", "pdf": "https://arxiv.org/pdf/2403.09073", "abs": "https://arxiv.org/abs/2403.09073", "authors": ["Yongyu Mu", "Peinan Feng", "Zhiquan Cao", "Yuzhang Wu", "Bei Li", "Chenglong Wang", "Tong Xiao", "Kai Song", "Tongran Liu", "Chunliang Zhang", "Jingbo Zhu"], "title": "Revealing the Parallel Multilingual Learning within Large Language Models", "categories": ["cs.CL"], "comment": "Accepted to EMNLP 2024", "summary": "In this study, we reveal an in-context learning (ICL) capability of\nmultilingual large language models (LLMs): by translating the input to several\nlanguages, we provide Parallel Input in Multiple Languages (PiM) to LLMs, which\nsignificantly enhances their comprehension abilities. To test this capability,\nwe design extensive experiments encompassing 8 typical datasets, 7 languages\nand 8 state-of-the-art multilingual LLMs. Experimental results show that (1)\nincorporating more languages help PiM surpass the conventional ICL further; (2)\neven combining with the translations that are inferior to baseline performance\ncan also help. Moreover, by examining the activated neurons in LLMs, we\ndiscover a counterintuitive but interesting phenomenon. Contrary to the common\nthought that PiM would activate more neurons than monolingual input to leverage\nknowledge learned from diverse languages, PiM actually inhibits neurons and\npromotes more precise neuron activation especially when more languages are\nadded. This phenomenon aligns with the neuroscience insight about synaptic\npruning, which removes less used neural connections, strengthens remainders,\nand then enhances brain intelligence.", "AI": {"tldr": "Multilingual LLMs improve comprehension by translating inputs into multiple languages (PiM), enhancing performance beyond conventional ICL. Surprisingly, PiM inhibits neurons, promoting precise activation, akin to synaptic pruning in neuroscience.", "motivation": "To explore how multilingual LLMs leverage parallel inputs in multiple languages (PiM) to enhance comprehension and uncover underlying neural mechanisms.", "method": "Conducted experiments on 8 datasets, 7 languages, and 8 multilingual LLMs, analyzing neuron activation patterns.", "result": "PiM outperforms conventional ICL, even with inferior translations, and inhibits neurons for more precise activation, resembling synaptic pruning.", "conclusion": "PiM enhances LLM performance by refining neuron activation, offering insights into multilingual learning mechanisms."}}
{"id": "2506.03082", "pdf": "https://arxiv.org/pdf/2506.03082", "abs": "https://arxiv.org/abs/2506.03082", "authors": ["Ssharvien Kumar Sivakumar", "Yannik Frisch", "Ghazal Ghazaei", "Anirban Mukhopadhyay"], "title": "SG2VID: Scene Graphs Enable Fine-Grained Control for Video Synthesis", "categories": ["cs.CV"], "comment": null, "summary": "Surgical simulation plays a pivotal role in training novice surgeons,\naccelerating their learning curve and reducing intra-operative errors. However,\nconventional simulation tools fall short in providing the necessary\nphotorealism and the variability of human anatomy. In response, current methods\nare shifting towards generative model-based simulators. Yet, these approaches\nprimarily focus on using increasingly complex conditioning for precise\nsynthesis while neglecting the fine-grained human control aspect. To address\nthis gap, we introduce SG2VID, the first diffusion-based video model that\nleverages Scene Graphs for both precise video synthesis and fine-grained human\ncontrol. We demonstrate SG2VID's capabilities across three public datasets\nfeaturing cataract and cholecystectomy surgery. While SG2VID outperforms\nprevious methods both qualitatively and quantitatively, it also enables precise\nsynthesis, providing accurate control over tool and anatomy's size and\nmovement, entrance of new tools, as well as the overall scene layout. We\nqualitatively motivate how SG2VID can be used for generative augmentation and\npresent an experiment demonstrating its ability to improve a downstream phase\ndetection task when the training set is extended with our synthetic videos.\nFinally, to showcase SG2VID's ability to retain human control, we interact with\nthe Scene Graphs to generate new video samples depicting major yet rare\nintra-operative irregularities.", "AI": {"tldr": "SG2VID is a diffusion-based video model using Scene Graphs for precise surgical video synthesis and fine-grained human control, outperforming prior methods and enabling generative augmentation.", "motivation": "Existing surgical simulators lack photorealism and human anatomy variability, and current generative models neglect fine-grained human control.", "method": "SG2VID leverages Scene Graphs for precise video synthesis and control, tested on cataract and cholecystectomy surgery datasets.", "result": "SG2VID outperforms previous methods, enables precise control over tools and anatomy, and improves downstream tasks via synthetic data augmentation.", "conclusion": "SG2VID addresses gaps in surgical simulation, offering photorealism, control, and augmentation potential for training and rare case generation."}}
{"id": "2506.03128", "pdf": "https://arxiv.org/pdf/2506.03128", "abs": "https://arxiv.org/abs/2506.03128", "authors": ["Andreas Auer", "Raghul Parthipan", "Pedro Mercado", "Abdul Fatir Ansari", "Lorenzo Stella", "Bernie Wang", "Michael Bohlke-Schneider", "Syama Sundar Rangapuram"], "title": "Zero-Shot Time Series Forecasting with Covariates via In-Context Learning", "categories": ["cs.LG"], "comment": "The paper was written at the end of 2024", "summary": "Pretrained time series models, capable of zero-shot forecasting, have\ndemonstrated significant potential in enhancing both the performance and\naccessibility of time series forecasting. However, existing pretrained models\neither do not support covariates or fail to incorporate them effectively. We\nintroduce COSMIC, a zero-shot forecasting model that utilizes covariates via\nin-context learning. To address the challenge of data scarcity, we propose\nInformative Covariate Augmentation, which enables the training of COSMIC\nwithout requiring any datasets that include covariates. COSMIC achieves\nstate-of-the-art performance in zero-shot forecasting, both with and without\ncovariates. Our quantitative and qualitative analysis demonstrates that COSMIC\neffectively leverages covariates in zero-shot forecasting.", "AI": {"tldr": "COSMIC is a zero-shot forecasting model using covariates via in-context learning, achieving state-of-the-art performance without requiring covariate datasets.", "motivation": "Existing pretrained time series models lack effective covariate support, limiting their performance and accessibility.", "method": "COSMIC uses in-context learning and Informative Covariate Augmentation to train without covariate datasets.", "result": "COSMIC achieves top performance in zero-shot forecasting, effectively leveraging covariates.", "conclusion": "COSMIC demonstrates the potential of covariates in zero-shot forecasting, enhancing model performance and accessibility."}}
{"id": "2407.13948", "pdf": "https://arxiv.org/pdf/2407.13948", "abs": "https://arxiv.org/abs/2407.13948", "authors": ["Robin Bloomfield", "John Rushby"], "title": "Assurance of AI Systems From a Dependability Perspective", "categories": ["cs.AI"], "comment": null, "summary": "We outline the principles of classical assurance for computer-based systems\nthat pose significant risks. We then consider application of these principles\nto systems that employ Artificial Intelligence (AI) and Machine Learning (ML).\n  A key element in this \"dependability\" perspective is a requirement for\nthorough understanding of the behavior of critical components, and this is\nconsidered infeasible for AI and ML. Hence the dependability perspective aims\nto minimize trust in AI and ML elements by using \"defense in depth\" with a\nhierarchy of less complex systems, some of which may be highly assured\nconventionally engineered components, to \"guard\" them. This may be contrasted\nwith the \"trustworthy\" perspective that seeks to apply assurance to the AI and\nML elements themselves.\n  In cyber-physical and many other systems, it is difficult to provide guards\nthat do not depend on AI and ML to perceive their environment (e.g., vehicles\nsharing the road with a self-driving car), so both perspectives are needed and\nthere is a continuum or spectrum between them. We focus on architectures toward\nthe dependability end of the continuum and invite others to consider additional\npoints along the spectrum.\n  For guards that require perception using AI and ML, we examine ways to\nminimize the trust placed in these elements; they include diversity, defense in\ndepth, explanations, and micro-ODDs. We also examine methods to enforce\nacceptable behavior, given a model of the world. These include classical\ncyber-physical calculations and envelopes, and normative rules based on\noverarching principles, constitutions, ethics, or reputation.\n  We apply our perspective to autonomous systems, AI systems for specific\nfunctions, general-purpose AI such as Large Language Models (LLMs), and\nArtificial General Intelligence (AGI), and we propose current best practice and\nconclude with a fourfold agenda for research.", "AI": {"tldr": "The paper discusses assurance principles for AI/ML systems, contrasting 'dependability' (minimizing trust in AI/ML) and 'trustworthy' (assuring AI/ML directly) perspectives. It proposes architectures leaning toward dependability and suggests research directions.", "motivation": "Addressing risks in AI/ML systems by balancing dependability and trustworthiness, especially in critical applications.", "method": "Uses 'defense in depth' with simpler systems to guard AI/ML, and explores methods like diversity, explanations, and normative rules to minimize trust.", "result": "Proposes architectures and methods for dependable AI/ML systems, emphasizing a spectrum between dependability and trustworthiness.", "conclusion": "Advocates for a fourfold research agenda to improve assurance in AI/ML systems, spanning autonomous systems to AGI."}}
{"id": "2403.19390", "pdf": "https://arxiv.org/pdf/2403.19390", "abs": "https://arxiv.org/abs/2403.19390", "authors": ["Deyuan Liu", "Zecheng Wang", "Bingning Wang", "Weipeng Chen", "Chunshan Li", "Zhiying Tu", "Dianhui Chu", "Bo Li", "Dianbo Sui"], "title": "Checkpoint Merging via Bayesian Optimization in LLM Pretraining", "categories": ["cs.CL"], "comment": null, "summary": "The rapid proliferation of large language models (LLMs) such as GPT-4 and\nGemini underscores the intense demand for resources during their training\nprocesses, posing significant challenges due to substantial computational and\nenvironmental costs. To alleviate this issue, we propose checkpoint merging in\npretraining LLM. This method utilizes LLM checkpoints with shared training\ntrajectories, and is rooted in an extensive search space exploration for the\nbest merging weight via Bayesian optimization. Through various experiments, we\ndemonstrate that: (1) Our proposed methodology exhibits the capacity to augment\npretraining, presenting an opportunity akin to obtaining substantial benefits\nat minimal cost; (2) Our proposed methodology, despite requiring a given\nheld-out dataset, still demonstrates robust generalization capabilities across\ndiverse domains, a pivotal aspect in pretraining.", "AI": {"tldr": "Checkpoint merging in LLM pretraining reduces computational costs via Bayesian optimization, improving performance and generalization.", "motivation": "Addressing high computational and environmental costs of training large language models (LLMs).", "method": "Proposes checkpoint merging using shared training trajectories and Bayesian optimization for weight selection.", "result": "Enhances pretraining efficiency and generalization across domains.", "conclusion": "Checkpoint merging offers a cost-effective solution to improve LLM pretraining."}}
{"id": "2506.03084", "pdf": "https://arxiv.org/pdf/2506.03084", "abs": "https://arxiv.org/abs/2506.03084", "authors": ["Zizhao Wu", "Yingying Sun", "Yiming Chen", "Xiaoling Gu", "Ruyu Liu", "Jiazhou Chen"], "title": "InterMamba: Efficient Human-Human Interaction Generation with Adaptive Spatio-Temporal Mamba", "categories": ["cs.CV"], "comment": null, "summary": "Human-human interaction generation has garnered significant attention in\nmotion synthesis due to its vital role in understanding humans as social\nbeings. However, existing methods typically rely on transformer-based\narchitectures, which often face challenges related to scalability and\nefficiency. To address these issues, we propose a novel, efficient human-human\ninteraction generation method based on the Mamba framework, designed to meet\nthe demands of effectively capturing long-sequence dependencies while providing\nreal-time feedback. Specifically, we introduce an adaptive spatio-temporal\nMamba framework that utilizes two parallel SSM branches with an adaptive\nmechanism to integrate the spatial and temporal features of motion sequences.\nTo further enhance the model's ability to capture dependencies within\nindividual motion sequences and the interactions between different individual\nsequences, we develop two key modules: the self-adaptive spatio-temporal Mamba\nmodule and the cross-adaptive spatio-temporal Mamba module, enabling efficient\nfeature learning. Extensive experiments demonstrate that our method achieves\nstate-of-the-art results on two interaction datasets with remarkable quality\nand efficiency. Compared to the baseline method InterGen, our approach not only\nimproves accuracy but also requires a minimal parameter size of just 66M ,only\n36% of InterGen's, while achieving an average inference speed of 0.57 seconds,\nwhich is 46% of InterGen's execution time.", "AI": {"tldr": "Proposes an efficient human-human interaction generation method using the Mamba framework, outperforming baseline methods in accuracy and efficiency.", "motivation": "Addresses scalability and efficiency challenges in transformer-based motion synthesis for human-human interactions.", "method": "Introduces an adaptive spatio-temporal Mamba framework with two parallel SSM branches and key modules for feature learning.", "result": "Achieves state-of-the-art results with 66M parameters (36% of baseline) and 0.57s inference speed (46% of baseline).", "conclusion": "The method effectively captures long-sequence dependencies and interactions, offering real-time feedback with high efficiency."}}
{"id": "2506.03142", "pdf": "https://arxiv.org/pdf/2506.03142", "abs": "https://arxiv.org/abs/2506.03142", "authors": ["Xiangyu Zhou", "Yao Qiang", "Saleh Zare Zade", "Douglas Zytko", "Prashant Khanduri", "Dongxiao Zhu"], "title": "Not All Tokens Are Meant to Be Forgotten", "categories": ["cs.LG"], "comment": null, "summary": "Large Language Models (LLMs), pre-trained on massive text corpora, exhibit\nremarkable human-level language understanding, reasoning, and decision-making\nabilities. However, they tend to memorize unwanted information, such as private\nor copyrighted content, raising significant privacy and legal concerns.\nUnlearning has emerged as a promising solution, but existing methods face a\nsignificant challenge of over-forgetting. This issue arises because they\nindiscriminately suppress the generation of all the tokens in forget samples,\nleading to a substantial loss of model utility. To overcome this challenge, we\nintroduce the Targeted Information Forgetting (TIF) framework, which consists\nof (1) a flexible targeted information identifier designed to differentiate\nbetween unwanted words (UW) and general words (GW) in the forget samples, and\n(2) a novel Targeted Preference Optimization approach that leverages Logit\nPreference Loss to unlearn unwanted information associated with UW and\nPreservation Loss to retain general information in GW, effectively improving\nthe unlearning process while mitigating utility degradation. Extensive\nexperiments on the TOFU and MUSE benchmarks demonstrate that the proposed TIF\nframework enhances unlearning effectiveness while preserving model utility and\nachieving state-of-the-art results.", "AI": {"tldr": "The paper introduces the Targeted Information Forgetting (TIF) framework to address over-forgetting in LLMs, improving unlearning while preserving model utility.", "motivation": "LLMs memorize unwanted private/copyrighted content, raising privacy/legal concerns. Existing unlearning methods cause over-forgetting, degrading model utility.", "method": "TIF includes a targeted information identifier and Targeted Preference Optimization with Logit Preference Loss (for unlearning) and Preservation Loss (for retaining general info).", "result": "TIF outperforms on TOFU and MUSE benchmarks, enhancing unlearning effectiveness while preserving utility.", "conclusion": "TIF provides a state-of-the-art solution for targeted unlearning in LLMs, balancing effectiveness and utility."}}
{"id": "2410.15805", "pdf": "https://arxiv.org/pdf/2410.15805", "abs": "https://arxiv.org/abs/2410.15805", "authors": ["Tianyang Zhang", "Zhuoxuan Jiang", "Shengguang Bai", "Tianrui Zhang", "Lin Lin", "Yang Liu", "Jiawei Ren"], "title": "RAG4ITOps: A Supervised Fine-Tunable and Comprehensive RAG Framework for IT Operations and Maintenance", "categories": ["cs.AI"], "comment": "Accepted by EMNLP 2024 Industry Track", "summary": "With the ever-increasing demands on Question Answering (QA) systems for IT\noperations and maintenance, an efficient and supervised fine-tunable framework\nis necessary to ensure the data security, private deployment and continuous\nupgrading. Although Large Language Models (LLMs) have notably improved the\nopen-domain QA's performance, how to efficiently handle enterprise-exclusive\ncorpora and build domain-specific QA systems are still less-studied for\nindustrial applications. In this paper, we propose a general and comprehensive\nframework based on Retrieval Augmented Generation (RAG) and facilitate the\nwhole business process of establishing QA systems for IT operations and\nmaintenance. In accordance with the prevailing RAG method, our proposed\nframework, named with RAG4ITOps, composes of two major stages: (1) Models\nFine-tuning \\& Data Vectorization, and (2) Online QA System Process. At the\nStage 1, we leverage a contrastive learning method with two negative sampling\nstrategies to fine-tune the embedding model, and design the instruction\ntemplates to fine-tune the LLM with a Retrieval Augmented Fine-Tuning method.\nAt the Stage 2, an efficient process of QA system is built for serving. We\ncollect enterprise-exclusive corpora from the domain of cloud computing, and\nthe extensive experiments show that our method achieves superior results than\ncounterparts on two kinds of QA tasks. Our experiment also provide a case for\napplying the RAG4ITOps to real-world enterprise-level applications.", "AI": {"tldr": "The paper proposes RAG4ITOps, a framework for building domain-specific QA systems for IT operations using Retrieval Augmented Generation (RAG), achieving superior results on enterprise-exclusive corpora.", "motivation": "Address the gap in efficiently handling enterprise-exclusive corpora and building domain-specific QA systems for industrial applications, particularly in IT operations and maintenance.", "method": "A two-stage framework: (1) Fine-tuning embedding models and LLMs using contrastive learning and instruction templates, and (2) Building an online QA system.", "result": "Superior performance on QA tasks using enterprise-exclusive cloud computing corpora, validated through extensive experiments.", "conclusion": "RAG4ITOps is effective for real-world enterprise-level QA applications in IT operations, demonstrating practical utility."}}
{"id": "2405.06705", "pdf": "https://arxiv.org/pdf/2405.06705", "abs": "https://arxiv.org/abs/2405.06705", "authors": ["Zhuoxuan Jiang", "Haoyuan Peng", "Shanshan Feng", "Fan Li", "Dongsheng Li"], "title": "LLMs can Find Mathematical Reasoning Mistakes by Pedagogical Chain-of-Thought", "categories": ["cs.CL", "cs.AI"], "comment": "Accepted by IJCAI 2024", "summary": "Self-correction is emerging as a promising approach to mitigate the issue of\nhallucination in Large Language Models (LLMs). To facilitate effective\nself-correction, recent research has proposed mistake detection as its initial\nstep. However, current literature suggests that LLMs often struggle with\nreliably identifying reasoning mistakes when using simplistic prompting\nstrategies. To address this challenge, we introduce a unique prompting\nstrategy, termed the Pedagogical Chain-of-Thought (PedCoT), which is\nspecifically designed to guide the identification of reasoning mistakes,\nparticularly mathematical reasoning mistakes. PedCoT consists of pedagogical\nprinciples for prompts (PPP) design, two-stage interaction process (TIP) and\ngrounded PedCoT prompts, all inspired by the educational theory of the Bloom\nCognitive Model (BCM). We evaluate our approach on two public datasets\nfeaturing math problems of varying difficulty levels. The experiments\ndemonstrate that our zero-shot prompting strategy significantly outperforms\nstrong baselines. The proposed method can achieve the goal of reliable\nmathematical mistake identification and provide a foundation for automatic math\nanswer grading. The results underscore the significance of educational theory,\nserving as domain knowledge, in guiding prompting strategy design for\naddressing challenging tasks with LLMs effectively.", "AI": {"tldr": "PedCoT, a prompting strategy based on educational theory, improves LLMs' ability to detect mathematical reasoning mistakes, outperforming baselines in zero-shot settings.", "motivation": "Address LLMs' unreliability in identifying reasoning mistakes, especially in math, using simplistic prompting.", "method": "Introduces PedCoT, combining pedagogical principles, a two-stage interaction process, and grounded prompts inspired by Bloom's Cognitive Model.", "result": "Outperforms baselines on math problem datasets, enabling reliable mistake identification and automatic grading.", "conclusion": "Educational theory enhances prompting strategies for LLMs, proving effective for challenging tasks like mistake detection."}}
{"id": "2506.03089", "pdf": "https://arxiv.org/pdf/2506.03089", "abs": "https://arxiv.org/abs/2506.03089", "authors": ["Lucas Piper", "Arlindo L. Oliveira", "Tiago Marques"], "title": "Explicitly Modeling Subcortical Vision with a Neuro-Inspired Front-End Improves CNN Robustness", "categories": ["cs.CV", "q-bio.NC"], "comment": null, "summary": "Convolutional neural networks (CNNs) trained on object recognition achieve\nhigh task performance but continue to exhibit vulnerability under a range of\nvisual perturbations and out-of-domain images, when compared with biological\nvision. Prior work has demonstrated that coupling a standard CNN with a\nfront-end block (VOneBlock) that mimics the primate primary visual cortex (V1)\ncan improve overall model robustness. Expanding on this, we introduce Early\nVision Networks (EVNets), a new class of hybrid CNNs that combine the VOneBlock\nwith a novel SubcorticalBlock, whose architecture draws from computational\nmodels in neuroscience and is parameterized to maximize alignment with\nsubcortical responses reported across multiple experimental studies. Without\nbeing optimized to do so, the assembly of the SubcorticalBlock with the\nVOneBlock improved V1 alignment across most standard V1 benchmarks, and better\nmodeled extra-classical receptive field phenomena. In addition, EVNets exhibit\nstronger emergent shape bias and overperform the base CNN architecture by 8.5%\non an aggregate benchmark of robustness evaluations, including adversarial\nperturbations, common corruptions, and domain shifts. Finally, we show that\nEVNets can be further improved when paired with a state-of-the-art data\naugmentation technique, surpassing the performance of the isolated data\naugmentation approach by 7.3% on our robustness benchmark. This result reveals\ncomplementary benefits between changes in architecture to better mimic biology\nand training-based machine learning approaches.", "AI": {"tldr": "EVNets, hybrid CNNs combining VOneBlock and SubcorticalBlock, improve robustness and alignment with biological vision, outperforming standard CNNs by 8.5% on robustness benchmarks.", "motivation": "Address CNN vulnerability to visual perturbations and out-of-domain images by mimicking biological vision (V1 and subcortical responses).", "method": "Introduce EVNets: hybrid CNNs with VOneBlock (V1 mimic) and SubcorticalBlock (subcortical mimic). Tested on robustness benchmarks.", "result": "Improved V1 alignment, stronger shape bias, and 8.5% better robustness. Further gains (7.3%) with data augmentation.", "conclusion": "Combining biologically inspired architecture with training-based methods enhances CNN robustness."}}
{"id": "2506.02002", "pdf": "https://arxiv.org/pdf/2506.02002", "abs": "https://arxiv.org/abs/2506.02002", "authors": ["Kamal Giri", "Amit Garu"], "title": "Machine Learning for Consistency Violation Faults Analysis", "categories": ["cs.DC", "cs.LG"], "comment": "5 pages, 5 figures", "summary": "Distributed systems frequently encounter consistency violation faults (cvfs),\nwhere nodes operate on outdated or inaccurate data, adversely affecting\nconvergence and overall system performance. This study presents a machine\nlearning-based approach for analyzing the impact of CVFs, using Dijkstra's\nToken Ring problem as a case study. By computing program transition ranks and\ntheir corresponding effects, the proposed method quantifies the influence of\ncvfs on system behavior. To address the state space explosion encountered in\nlarger graphs, two models are implemented: a Feedforward Neural Network (FNN)\nand a distributed neural network leveraging TensorFlow's \\texttt{tf.distribute}\nAPI. These models are trained on datasets generated from smaller graphs (3 to\n10 nodes) to predict parameters essential for determining rank effects.\nExperimental results demonstrate promising performance, with a test loss of\n4.39 and a mean absolute error of 1.5. Although distributed training on a CPU\ndid not yield significant speed improvements over a single-device setup, the\nfindings suggest that scalability could be enhanced through the use of advanced\nhardware accelerators such as GPUs or TPUs.", "AI": {"tldr": "A machine learning approach analyzes CVFs' impact on distributed systems, using Dijkstra's Token Ring problem. FNN and distributed neural networks predict rank effects, showing promising results but limited scalability on CPUs.", "motivation": "To address consistency violation faults (CVFs) in distributed systems, which degrade performance and convergence.", "method": "Uses Dijkstra's Token Ring problem to compute program transition ranks. Implements FNN and distributed neural networks (TensorFlow) for prediction, trained on small graphs (3-10 nodes).", "result": "Test loss of 4.39 and mean absolute error of 1.5. Distributed training on CPUs didn't improve speed significantly.", "conclusion": "Scalability may improve with GPUs/TPUs. The method effectively quantifies CVFs' impact but needs hardware enhancements for better performance."}}
{"id": "2410.16672", "pdf": "https://arxiv.org/pdf/2410.16672", "abs": "https://arxiv.org/abs/2410.16672", "authors": ["Chen Qian", "Dongrui Liu", "Jie Zhang", "Yong Liu", "Jing Shao"], "title": "The Tug of War Within: Mitigating the Fairness-Privacy Conflicts in Large Language Models", "categories": ["cs.AI"], "comment": "ACL 2025 Main Conference", "summary": "Ensuring awareness of fairness and privacy in Large Language Models (LLMs) is\ncritical. Interestingly, we discover a counter-intuitive trade-off phenomenon\nthat enhancing an LLM's privacy awareness through Supervised Fine-Tuning (SFT)\nmethods significantly decreases its fairness awareness with thousands of\nsamples. To address this issue, inspired by the information theory, we\nintroduce a training-free method to \\textbf{S}uppress the \\textbf{P}rivacy and\nfa\\textbf{I}rness coupled \\textbf{N}eurons (\\textbf{SPIN}), which theoretically\nand empirically decrease the mutual information between fairness and privacy\nawareness. Extensive experimental results demonstrate that SPIN eliminates the\ntrade-off phenomenon and significantly improves LLMs' fairness and privacy\nawareness simultaneously without compromising general capabilities, \\eg\nimproving Qwen-2-7B-Instruct's fairness awareness by 12.2\\% and privacy\nawareness by 14.0\\%. More crucially, SPIN remains robust and effective with\nlimited annotated data or even when only malicious fine-tuning data is\navailable, whereas SFT methods may fail to perform properly in such scenarios.\nFurthermore, we show that SPIN could generalize to other potential trade-off\ndimensions. We hope this study provides valuable insights into concurrently\naddressing fairness and privacy concerns in LLMs and can be integrated into\ncomprehensive frameworks to develop more ethical and responsible AI systems.\nOur code is available at https://github.com/ChnQ/SPIN.", "AI": {"tldr": "The paper introduces SPIN, a training-free method to address the trade-off between fairness and privacy awareness in LLMs, improving both without compromising general capabilities.", "motivation": "The study aims to resolve the counter-intuitive trade-off where enhancing privacy awareness in LLMs via SFT reduces fairness awareness.", "method": "SPIN suppresses coupled neurons for privacy and fairness using information theory, reducing their mutual influence.", "result": "SPIN improves fairness by 12.2% and privacy by 14.0% in Qwen-2-7B-Instruct, even with limited or malicious data.", "conclusion": "SPIN effectively addresses fairness-privacy trade-offs, generalizes to other dimensions, and aids ethical AI development."}}
{"id": "2406.06907", "pdf": "https://arxiv.org/pdf/2406.06907", "abs": "https://arxiv.org/abs/2406.06907", "authors": ["Shester Gueuwou", "Xiaodan Du", "Greg Shakhnarovich", "Karen Livescu"], "title": "SignMusketeers: An Efficient Multi-Stream Approach for Sign Language Translation at Scale", "categories": ["cs.CL", "cs.AI", "cs.CV", "cs.LG"], "comment": "Accepted to ACL (Findings) 2025", "summary": "A persistent challenge in sign language video processing, including the task\nof sign to written language translation, is how we learn representations of\nsign language in an effective and efficient way that preserves the important\nattributes of these languages, while remaining invariant to irrelevant visual\ndifferences. Informed by the nature and linguistics of signed languages, our\nproposed method focuses on just the most relevant parts in a signing video: the\nface, hands and body pose of the signer. However, instead of fully relying on\npose estimation from off-the-shelf pose tracking models, which have\ninconsistent performance for hands and faces, we propose to learn a\nrepresentation of the complex handshapes and facial expressions of sign\nlanguages in a self-supervised fashion. Our approach is based on learning from\nindividual frames (rather than video sequences) and is therefore much more\nefficient than prior work on sign language pre-training. Compared to a recent\nmodel that established a new state of the art in sign language translation on\nthe How2Sign dataset, our approach yields similar translation performance,\nusing less than 3\\% of the compute.", "AI": {"tldr": "The paper proposes a self-supervised method for learning sign language representations by focusing on key parts (face, hands, body pose) and avoiding reliance on inconsistent pose tracking models. It achieves similar translation performance to state-of-the-art models with significantly less computational cost.", "motivation": "The challenge of effectively representing sign language while ignoring irrelevant visual differences, informed by the linguistics of signed languages.", "method": "Self-supervised learning of handshapes and facial expressions from individual frames, avoiding full reliance on pose tracking models.", "result": "Achieves similar translation performance to state-of-the-art models on the How2Sign dataset, using less than 3% of the compute.", "conclusion": "The method is efficient and effective for sign language representation, offering a computationally lighter alternative to existing approaches."}}
{"id": "2506.03096", "pdf": "https://arxiv.org/pdf/2506.03096", "abs": "https://arxiv.org/abs/2506.03096", "authors": ["Christian Schlarmann", "Francesco Croce", "Nicolas Flammarion", "Matthias Hein"], "title": "FuseLIP: Multimodal Embeddings via Early Fusion of Discrete Tokens", "categories": ["cs.CV", "cs.LG"], "comment": "Code and models available at https://github.com/chs20/fuselip", "summary": "Contrastive language-image pre-training aligns the features of text-image\npairs in a common latent space via distinct encoders for each modality. While\nthis approach achieves impressive performance in several zero-shot tasks, it\ncannot natively handle multimodal inputs, i.e., encoding image and text into a\nsingle feature vector. As a remedy, it is common practice to use additional\nmodules to merge the features extracted by the unimodal encoders. In this work,\nwe present FuseLIP, an alternative architecture for multimodal embedding.\nLeveraging recent progress in discrete image tokenizers, we propose to use a\nsingle transformer model which operates on an extended vocabulary of text and\nimage tokens. This early fusion approach allows the different modalities to\ninteract at each depth of encoding and obtain richer representations compared\nto common late fusion. We collect new datasets for multimodal pre-training and\nevaluation, designing challenging tasks for multimodal encoder models. We show\nthat FuseLIP outperforms other approaches in multimodal embedding tasks such as\nVQA and text-guided image transformation retrieval, while being comparable to\nbaselines on unimodal tasks.", "AI": {"tldr": "FuseLIP introduces a single transformer model for multimodal embedding, enabling early fusion of text and image tokens, outperforming late fusion methods in tasks like VQA.", "motivation": "Existing contrastive pre-training methods lack native support for multimodal inputs, requiring additional modules for feature merging.", "method": "Uses a single transformer model with an extended vocabulary of text and image tokens for early fusion, allowing deeper modality interaction.", "result": "FuseLIP outperforms baselines in multimodal tasks (e.g., VQA) and matches performance in unimodal tasks.", "conclusion": "Early fusion via FuseLIP provides richer multimodal representations, improving performance in complex tasks."}}
{"id": "2506.02006", "pdf": "https://arxiv.org/pdf/2506.02006", "abs": "https://arxiv.org/abs/2506.02006", "authors": ["Zhaoyuan Su", "Tingfeng Lan", "Zirui Wang", "Juncheng Yang", "Yue Cheng"], "title": "Efficient and Workload-Aware LLM Serving via Runtime Layer Swapping and KV Cache Resizing", "categories": ["cs.DC", "cs.LG"], "comment": "19 pages, 7 figures", "summary": "Efficiently serving large language models (LLMs) under dynamic and bursty\nworkloads remains a key challenge for real-world deployment. Existing serving\nframeworks and static model compression techniques fail to adapt to workload\nfluctuations, leading to either service-level objective (SLO) violations under\nfull-precision serving or persistent accuracy degradation with static\nquantization. We present MorphServe, a dynamic, workload-aware LLM serving\nframework based on morphological adaptation. MorphServe introduces two\nasynchronous, token-level runtime mechanisms: quantized layer swapping, which\nselectively replaces less impactful layers with quantized alternatives during\nhigh-load periods, and pressure-aware KV cache resizing, which dynamically\nadjusts KV cache capacity in response to memory pressure. These mechanisms\nenable state-preserving transitions with minimum runtime overhead and are fully\ncompatible with modern scheduling and attention techniques. Extensive\nexperiments on Vicuna and Llama family models with real-world workloads\ndemonstrate that MorphServe reduces average SLO violations by 92.45 percent and\nimproves the P95 TTFT latency by 2.2x-3.9x compared to full-precision serving,\nwithout compromising generation quality. These results establish MorphServe as\na practical and elastic solution for LLM deployment in dynamic environments.", "AI": {"tldr": "MorphServe is a dynamic LLM serving framework that adapts to workload fluctuations using quantized layer swapping and KV cache resizing, reducing SLO violations and improving latency without quality loss.", "motivation": "Existing LLM serving frameworks struggle with dynamic workloads, causing SLO violations or accuracy degradation. MorphServe aims to address this by adapting to workload changes.", "method": "MorphServe uses quantized layer swapping and pressure-aware KV cache resizing to dynamically adjust resources during high-load periods, ensuring minimal overhead.", "result": "MorphServe reduces SLO violations by 92.45% and improves P95 TTFT latency by 2.2x-3.9x compared to full-precision serving, maintaining generation quality.", "conclusion": "MorphServe is a practical, elastic solution for deploying LLMs in dynamic environments, balancing performance and accuracy."}}
{"id": "2411.03887", "pdf": "https://arxiv.org/pdf/2411.03887", "abs": "https://arxiv.org/abs/2411.03887", "authors": ["Zerui Cheng", "Edoardo Contente", "Ben Finch", "Oleg Golev", "Jonathan Hayase", "Andrew Miller", "Niusha Moshrefi", "Anshul Nasery", "Sandeep Nailwal", "Sewoong Oh", "Himanshu Tyagi", "Pramod Viswanath"], "title": "Reclaiming \"Open AI\" -- AI Model Serving Can Be Open Access, Yet Monetizable and Loyal", "categories": ["cs.AI", "cs.CR"], "comment": "54 pages", "summary": "The rapid rise of AI has split model serving between open-weight\ndistribution, which often lacks owner control and monetization, and opaque\nAPI-based approaches that risk user privacy and model transparency, forming a\ndichotomy that hinders an equitable AI ecosystem. This position paper\nintroduces, rigorously formulates, and champions the Open-access, Monetizable,\nand Loyal (OML) paradigm for AI model serving: a foundational shift to securely\ndistribute and serve AI models by synthesizing transparency with granular\nmonetization and critical safety controls. We survey diverse OML constructions\nfrom theory and practice, analyze their security, performance, and practical\ntrade-offs, outline a conceptual OML deployment protocol, and discuss market\nand policy implications. We assert that OML can foster a democratized,\nself-sustaining, and innovative AI landscape, mitigating centralized power\nrisks. Finally, we call on the research community to further explore the broad\ndesign space of OML, spanning cryptographic, AI-native, and socio-economic\nmechanisms, to realize its full potential for a collaborative, accountable, and\nresilient AI future.", "AI": {"tldr": "The paper proposes the OML paradigm for AI model serving, combining transparency, monetization, and safety to address the current dichotomy between open-weight and API-based approaches.", "motivation": "The dichotomy in AI model serving\u2014open-weight lacks control/monetization, while API-based risks privacy/transparency\u2014hinders an equitable AI ecosystem.", "method": "Introduces and formulates the OML paradigm, surveys its constructions, analyzes trade-offs, outlines a deployment protocol, and discusses implications.", "result": "OML can democratize AI, mitigate centralized power risks, and foster innovation through transparency, monetization, and safety.", "conclusion": "Calls for further research on OML's design space to achieve a collaborative, accountable, and resilient AI future."}}
{"id": "2406.14545", "pdf": "https://arxiv.org/pdf/2406.14545", "abs": "https://arxiv.org/abs/2406.14545", "authors": ["\u0110or\u0111e Klisura", "Anthony Rios"], "title": "Unmasking Database Vulnerabilities: Zero-Knowledge Schema Inference Attacks in Text-to-SQL Systems", "categories": ["cs.CL"], "comment": "Accepted to NAACL 2025 Findings", "summary": "Text-to-SQL systems empower users to interact with databases using natural\nlanguage, automatically translating queries into executable SQL code. However,\ntheir reliance on database schema information for SQL generation exposes them\nto significant security vulnerabilities, particularly schema inference attacks\nthat can lead to unauthorized data access or manipulation. In this paper, we\nintroduce a novel zero-knowledge framework for reconstructing the underlying\ndatabase schema of text-to-SQL models without any prior knowledge of the\ndatabase. Our approach systematically probes text-to-SQL models with specially\ncrafted questions and leverages a surrogate GPT-4 model to interpret the\noutputs, effectively uncovering hidden schema elements -- including tables,\ncolumns, and data types. We demonstrate that our method achieves high accuracy\nin reconstructing table names, with F1 scores of up to .99 for generative\nmodels and .78 for fine-tuned models, underscoring the severity of schema\nleakage risks. We also show that our attack can steal prompt information in\nnon-text-to-SQL models. Furthermore, we propose a simple protection mechanism\nfor generative models and empirically show its limitations in mitigating these\nattacks.", "AI": {"tldr": "A zero-knowledge framework exposes security vulnerabilities in text-to-SQL systems by reconstructing database schemas without prior knowledge, achieving high accuracy and revealing risks like prompt theft. A proposed protection mechanism has limited effectiveness.", "motivation": "Text-to-SQL systems are vulnerable to schema inference attacks, risking unauthorized data access. This paper aims to expose these vulnerabilities and propose countermeasures.", "method": "The approach uses crafted questions and a surrogate GPT-4 model to probe text-to-SQL systems, uncovering hidden schema elements like tables and columns.", "result": "High accuracy in schema reconstruction (F1 scores up to .99 for generative models, .78 for fine-tuned models) and demonstration of prompt theft in non-text-to-SQL models.", "conclusion": "The study highlights severe schema leakage risks and shows that current protection mechanisms are insufficient, calling for stronger defenses."}}
{"id": "2506.03103", "pdf": "https://arxiv.org/pdf/2506.03103", "abs": "https://arxiv.org/abs/2506.03103", "authors": ["Xiaoyan Cong", "Angela Xing", "Chandradeep Pokhariya", "Rao Fu", "Srinath Sridhar"], "title": "DyTact: Capturing Dynamic Contacts in Hand-Object Manipulation", "categories": ["cs.CV"], "comment": null, "summary": "Reconstructing dynamic hand-object contacts is essential for realistic\nmanipulation in AI character animation, XR, and robotics, yet it remains\nchallenging due to heavy occlusions, complex surface details, and limitations\nin existing capture techniques. In this paper, we introduce DyTact, a\nmarkerless capture method for accurately capturing dynamic contact in\nhand-object manipulations in a non-intrusive manner. Our approach leverages a\ndynamic, articulated representation based on 2D Gaussian surfels to model\ncomplex manipulations. By binding these surfels to MANO meshes, DyTact\nharnesses the inductive bias of template models to stabilize and accelerate\noptimization. A refinement module addresses time-dependent high-frequency\ndeformations, while a contact-guided adaptive sampling strategy selectively\nincreases surfel density in contact regions to handle heavy occlusion.\nExtensive experiments demonstrate that DyTact not only achieves\nstate-of-the-art dynamic contact estimation accuracy but also significantly\nimproves novel view synthesis quality, all while operating with fast\noptimization and efficient memory usage. Project Page:\nhttps://oliver-cong02.github.io/DyTact.github.io/ .", "AI": {"tldr": "DyTact is a markerless capture method for dynamic hand-object contact reconstruction, addressing challenges like occlusions and complex surfaces with 2D Gaussian surfels and MANO meshes.", "motivation": "Dynamic hand-object contact reconstruction is vital for AI animation, XR, and robotics but is hindered by occlusions, surface details, and capture limitations.", "method": "DyTact uses 2D Gaussian surfels bound to MANO meshes, a refinement module for high-frequency deformations, and adaptive sampling for contact regions.", "result": "DyTact achieves state-of-the-art contact estimation accuracy, improves novel view synthesis, and operates efficiently.", "conclusion": "DyTact offers a non-intrusive, accurate, and efficient solution for dynamic hand-object contact capture."}}
{"id": "2506.02023", "pdf": "https://arxiv.org/pdf/2506.02023", "abs": "https://arxiv.org/abs/2506.02023", "authors": ["Kevin Han", "Bowen Deng", "Amir Barati Farimani", "Gerbrand Ceder"], "title": "DistMLIP: A Distributed Inference Platform for Machine Learning Interatomic Potentials", "categories": ["cs.DC", "cond-mat.mtrl-sci", "cs.LG", "cs.PF"], "comment": null, "summary": "Large-scale atomistic simulations are essential to bridge computational\nmaterials and chemistry to realistic materials and drug discovery applications.\nIn the past few years, rapid developments of machine learning interatomic\npotentials (MLIPs) have offered a solution to scale up quantum mechanical\ncalculations. Parallelizing these interatomic potentials across multiple\ndevices poses a challenging, but promising approach to further extending\nsimulation scales to real-world applications. In this work, we present\nDistMLIP, an efficient distributed inference platform for MLIPs based on\nzero-redundancy, graph-level parallelization. In contrast to conventional\nspace-partitioning parallelization, DistMLIP enables efficient MLIP\nparallelization through graph partitioning, allowing multi-device inference on\nflexible MLIP model architectures like multi-layer graph neural networks.\nDistMLIP presents an easy-to-use, flexible, plug-in interface that enables\ndistributed inference of pre-existing MLIPs. We demonstrate DistMLIP on four\nwidely used and state-of-the-art MLIPs: CHGNet, MACE, TensorNet, and eSEN. We\nshow that existing foundational potentials can perform near-million-atom\ncalculations at the scale of a few seconds on 8 GPUs with DistMLIP.", "AI": {"tldr": "DistMLIP is a distributed inference platform for machine learning interatomic potentials (MLIPs) that uses graph-level parallelization to enable efficient large-scale simulations.", "motivation": "Large-scale atomistic simulations are needed for realistic materials and drug discovery, but scaling quantum mechanical calculations is challenging. MLIPs offer a solution, but parallelizing them efficiently is difficult.", "method": "DistMLIP employs zero-redundancy, graph-level parallelization instead of conventional space-partitioning, allowing flexible MLIP model architectures like multi-layer graph neural networks to be parallelized across multiple devices.", "result": "DistMLIP enables near-million-atom calculations in seconds on 8 GPUs, demonstrated on four state-of-the-art MLIPs (CHGNet, MACE, TensorNet, and eSEN).", "conclusion": "DistMLIP provides an efficient, flexible, and easy-to-use platform for distributed inference of MLIPs, significantly advancing large-scale atomistic simulations."}}
{"id": "2411.09689", "pdf": "https://arxiv.org/pdf/2411.09689", "abs": "https://arxiv.org/abs/2411.09689", "authors": ["Seongmin Lee", "Hsiang Hsu", "Chun-Fu Chen", "Duen Horng", "Chau"], "title": "Probing LLM Hallucination from Within: Perturbation-Driven Approach via Internal Knowledge", "categories": ["cs.AI", "cs.CL"], "comment": "22 pages, 15 figures", "summary": "LLM hallucination, where unfaithful text is generated, presents a critical\nchallenge for LLMs' practical applications. Current detection methods often\nresort to external knowledge, LLM fine-tuning, or supervised training with\nlarge hallucination-labeled datasets. Moreover, these approaches do not\ndistinguish between different types of hallucinations, which is crucial for\nenhancing detection performance. To address such limitations, we introduce\nhallucination probing, a new task that classifies LLM-generated text into three\ncategories: aligned, misaligned, and fabricated. Driven by our novel discovery\nthat perturbing key entities in prompts affects LLM's generation of these three\ntypes of text differently, we propose SHINE, a novel hallucination probing\nmethod that does not require external knowledge, supervised training, or LLM\nfine-tuning. SHINE is effective in hallucination probing across three modern\nLLMs, and achieves state-of-the-art performance in hallucination detection,\noutperforming seven competing methods across four datasets and four LLMs,\nunderscoring the importance of probing for accurate detection.", "AI": {"tldr": "The paper introduces hallucination probing to classify LLM-generated text into aligned, misaligned, or fabricated categories, proposing SHINE, a method that outperforms existing approaches without needing external knowledge or training.", "motivation": "Addressing LLM hallucination's critical challenge and the lack of distinction between hallucination types in current detection methods.", "method": "Proposes SHINE, a hallucination probing method leveraging prompt perturbations to classify text without external knowledge or training.", "result": "SHINE achieves state-of-the-art performance in hallucination detection across multiple LLMs and datasets, outperforming seven competing methods.", "conclusion": "Hallucination probing is crucial for accurate detection, and SHINE offers an effective, resource-efficient solution."}}
{"id": "2407.01384", "pdf": "https://arxiv.org/pdf/2407.01384", "abs": "https://arxiv.org/abs/2407.01384", "authors": ["Yi-Sheng Hsu", "Nils Feldhus", "Sherzod Hakimov"], "title": "Free-text Rationale Generation under Readability Level Control", "categories": ["cs.CL"], "comment": "ACL 2025 Workshop on Generation, Evaluation, and Metrics (GEM^2)", "summary": "Free-text rationales justify model decisions in natural language and thus\nbecome likable and accessible among approaches to explanation across many\ntasks. However, their effectiveness can be hindered by misinterpretation and\nhallucination. As a perturbation test, we investigate how large language models\n(LLMs) perform rationale generation under the effects of readability level\ncontrol, i.e., being prompted for an explanation targeting a specific expertise\nlevel, such as sixth grade or college. We find that explanations are adaptable\nto such instruction, though the observed distinction between readability levels\ndoes not fully match the defined complexity scores according to traditional\nreadability metrics. Furthermore, the generated rationales tend to feature\nmedium level complexity, which correlates with the measured quality using\nautomatic metrics. Finally, our human annotators confirm a generally\nsatisfactory impression on rationales at all readability levels, with\nhigh-school-level readability being most commonly perceived and favored.", "AI": {"tldr": "The paper explores how large language models (LLMs) generate rationales at different readability levels, finding adaptability but mismatches with traditional metrics. Medium complexity rationales correlate with higher quality, and human annotators favor high-school-level readability.", "motivation": "To assess the effectiveness of free-text rationales from LLMs under controlled readability levels, addressing potential misinterpretation and hallucination issues.", "method": "Conducted a perturbation test where LLMs were prompted to generate rationales for specific expertise levels (e.g., sixth grade, college). Analyzed adaptability, complexity, and quality using automatic metrics and human evaluation.", "result": "Rationales adapted to readability instructions, but complexity distinctions didn't fully align with traditional metrics. Medium complexity correlated with higher quality. Human annotators preferred high-school-level readability.", "conclusion": "LLMs can generate adaptable rationales, though readability control needs refinement. Medium complexity rationales perform best, and high-school-level readability is favored by humans."}}
{"id": "2506.03107", "pdf": "https://arxiv.org/pdf/2506.03107", "abs": "https://arxiv.org/abs/2506.03107", "authors": ["Di Chang", "Mingdeng Cao", "Yichun Shi", "Bo Liu", "Shengqu Cai", "Shijie Zhou", "Weilin Huang", "Gordon Wetzstein", "Mohammad Soleymani", "Peng Wang"], "title": "ByteMorph: Benchmarking Instruction-Guided Image Editing with Non-Rigid Motions", "categories": ["cs.CV"], "comment": "Website: https://boese0601.github.io/bytemorph Dataset:\n  https://huggingface.co/datasets/ByteDance-Seed/BM-6M Benchmark:\n  https://huggingface.co/datasets/ByteDance-Seed/BM-Bench Code:\n  https://github.com/ByteDance-Seed/BM-code Demo:\n  https://huggingface.co/spaces/Boese0601/ByteMorph-Demo", "summary": "Editing images with instructions to reflect non-rigid motions, camera\nviewpoint shifts, object deformations, human articulations, and complex\ninteractions, poses a challenging yet underexplored problem in computer vision.\nExisting approaches and datasets predominantly focus on static scenes or rigid\ntransformations, limiting their capacity to handle expressive edits involving\ndynamic motion. To address this gap, we introduce ByteMorph, a comprehensive\nframework for instruction-based image editing with an emphasis on non-rigid\nmotions. ByteMorph comprises a large-scale dataset, ByteMorph-6M, and a strong\nbaseline model built upon the Diffusion Transformer (DiT), named ByteMorpher.\nByteMorph-6M includes over 6 million high-resolution image editing pairs for\ntraining, along with a carefully curated evaluation benchmark ByteMorph-Bench.\nBoth capture a wide variety of non-rigid motion types across diverse\nenvironments, human figures, and object categories. The dataset is constructed\nusing motion-guided data generation, layered compositing techniques, and\nautomated captioning to ensure diversity, realism, and semantic coherence. We\nfurther conduct a comprehensive evaluation of recent instruction-based image\nediting methods from both academic and commercial domains.", "AI": {"tldr": "ByteMorph introduces a framework for instruction-based image editing focusing on non-rigid motions, including a dataset (ByteMorph-6M) and a model (ByteMorpher).", "motivation": "Existing methods and datasets lack support for expressive edits involving dynamic motion, limiting their applicability.", "method": "ByteMorph uses a Diffusion Transformer (DiT) model and a large-scale dataset (ByteMorph-6M) generated via motion-guided techniques and automated captioning.", "result": "The framework includes a 6M-pair dataset and a benchmark (ByteMorph-Bench), covering diverse non-rigid motions.", "conclusion": "ByteMorph addresses the gap in handling non-rigid motions in image editing and provides a robust dataset and model for future research."}}
{"id": "2506.02038", "pdf": "https://arxiv.org/pdf/2506.02038", "abs": "https://arxiv.org/abs/2506.02038", "authors": ["Anum Nawaz", "Hafiz Humza Mahmood Ramzan", "Xianjia Yu", "Zhuo Zou", "Tomi Westerlund"], "title": "Blockchain Powered Edge Intelligence for U-Healthcare in Privacy Critical and Time Sensitive Environment", "categories": ["cs.CR", "cs.LG"], "comment": null, "summary": "Edge Intelligence (EI) serves as a critical enabler for privacy-preserving\nsystems by providing AI-empowered computation and distributed caching services\nat the edge, thereby minimizing latency and enhancing data privacy. The\nintegration of blockchain technology further augments EI frameworks by ensuring\ntransactional transparency, auditability, and system-wide reliability through a\ndecentralized network model. However, the operational architecture of such\nsystems introduces inherent vulnerabilities, particularly due to the extensive\ndata interactions between edge gateways (EGs) and the distributed nature of\ninformation storage during service provisioning. To address these challenges,\nwe propose an autonomous computing model along with its interaction topologies\ntailored for privacy-critical and time-sensitive health applications. The\nsystem supports continuous monitoring, real-time alert notifications, disease\ndetection, and robust data processing and aggregation. It also includes a data\ntransaction handler and mechanisms for ensuring privacy at the EGs. Moreover, a\nresource-efficient one-dimensional convolutional neural network (1D-CNN) is\nproposed for the multiclass classification of arrhythmia, enabling accurate and\nreal-time analysis of constrained EGs. Furthermore, a secure access scheme is\ndefined to manage both off-chain and on-chain data sharing and storage. To\nvalidate the proposed model, comprehensive security, performance, and cost\nanalyses are conducted, demonstrating the efficiency and reliability of the\nfine-grained access control scheme.", "AI": {"tldr": "The paper proposes an autonomous computing model for privacy-critical health applications, integrating Edge Intelligence (EI) and blockchain to enhance privacy, latency, and reliability. It includes a 1D-CNN for arrhythmia classification and a secure access scheme for data sharing.", "motivation": "To address vulnerabilities in EI frameworks due to data interactions and distributed storage, ensuring privacy and efficiency for health applications.", "method": "Proposes an autonomous computing model with interaction topologies, a 1D-CNN for arrhythmia classification, and a secure access scheme for data handling.", "result": "Demonstrates efficiency and reliability through security, performance, and cost analyses, validating the fine-grained access control scheme.", "conclusion": "The model effectively enhances privacy, real-time processing, and reliability in EI-based health systems."}}
{"id": "2412.10849", "pdf": "https://arxiv.org/pdf/2412.10849", "abs": "https://arxiv.org/abs/2412.10849", "authors": ["Peter G. Brodeur", "Thomas A. Buckley", "Zahir Kanjee", "Ethan Goh", "Evelyn Bin Ling", "Priyank Jain", "Stephanie Cabral", "Raja-Elie Abdulnour", "Adrian D. Haimovich", "Jason A. Freed", "Andrew Olson", "Daniel J. Morgan", "Jason Hom", "Robert Gallo", "Liam G. McCoy", "Haadi Mombini", "Christopher Lucas", "Misha Fotoohi", "Matthew Gwiazdon", "Daniele Restifo", "Daniel Restrepo", "Eric Horvitz", "Jonathan Chen", "Arjun K. Manrai", "Adam Rodman"], "title": "Superhuman performance of a large language model on the reasoning tasks of a physician", "categories": ["cs.AI", "cs.CL"], "comment": null, "summary": "A seminal paper published by Ledley and Lusted in 1959 introduced complex\nclinical diagnostic reasoning cases as the gold standard for the evaluation of\nexpert medical computing systems, a standard that has held ever since. Here, we\nreport the results of a physician evaluation of a large language model (LLM) on\nchallenging clinical cases against a baseline of hundreds of physicians. We\nconduct five experiments to measure clinical reasoning across differential\ndiagnosis generation, display of diagnostic reasoning, triage differential\ndiagnosis, probabilistic reasoning, and management reasoning, all adjudicated\nby physician experts with validated psychometrics. We then report a real-world\nstudy comparing human expert and AI second opinions in randomly-selected\npatients in the emergency room of a major tertiary academic medical center in\nBoston, MA. We compared LLMs and board-certified physicians at three predefined\ndiagnostic touchpoints: triage in the emergency room, initial evaluation by a\nphysician, and admission to the hospital or intensive care unit. In all\nexperiments--both vignettes and emergency room second opinions--the LLM\ndisplayed superhuman diagnostic and reasoning abilities, as well as continued\nimprovement from prior generations of AI clinical decision support. Our study\nsuggests that LLMs have achieved superhuman performance on general medical\ndiagnostic and management reasoning, fulfilling the vision put forth by Ledley\nand Lusted, and motivating the urgent need for prospective trials.", "AI": {"tldr": "A study evaluates a large language model (LLM) against physicians in clinical reasoning tasks, showing superhuman performance in diagnostics and management, fulfilling a 1959 vision for expert medical systems.", "motivation": "To assess if LLMs can meet the gold standard for clinical diagnostic reasoning set by Ledley and Lusted in 1959, and compare their performance to human physicians.", "method": "Five experiments measured clinical reasoning (e.g., differential diagnosis, probabilistic reasoning) and a real-world study compared LLMs and physicians in emergency room second opinions.", "result": "The LLM outperformed physicians in all experiments, demonstrating superhuman diagnostic and reasoning abilities.", "conclusion": "LLMs have achieved superhuman performance in medical diagnostics, fulfilling the 1959 vision and highlighting the need for prospective trials."}}
{"id": "2407.03525", "pdf": "https://arxiv.org/pdf/2407.03525", "abs": "https://arxiv.org/abs/2407.03525", "authors": ["Md Nayem Uddin", "Amir Saeidi", "Divij Handa", "Agastya Seth", "Tran Cao Son", "Eduardo Blanco", "Steven R. Corman", "Chitta Baral"], "title": "UnSeenTimeQA: Time-Sensitive Question-Answering Beyond LLMs' Memorization", "categories": ["cs.CL"], "comment": "Accepted at ACL 2025 (Main)", "summary": "This paper introduces UnSeenTimeQA, a novel data contamination-free\ntime-sensitive question-answering (TSQA) benchmark. It differs from existing\nTSQA benchmarks by avoiding web-searchable queries grounded in the real world.\nWe present a series of time-sensitive event scenarios based on synthetically\ngenerated facts. It requires large language models (LLMs) to engage in genuine\ntemporal reasoning without depending on the factual knowledge acquired during\nthe pre-training phase. Our data generation framework enables on-demand\ngeneration of new samples, mitigating the risk of data leakage. We designed\nthree types of time-sensitive questions to test LLMs' temporal reasoning\nabilities over sequential and parallel event occurrences. Our evaluation of\nfive LLMs on synthetic fact-based TSQA reveals mixed results: while they\nperform well on simpler subsets, their overall performance remains inferior as\ncompared to real world fact-based TSQA. Error analysis indicates that LLMs face\ndifficulties in reasoning over long-range event dependencies and parallel\nevents.", "AI": {"tldr": "UnSeenTimeQA is a new TSQA benchmark using synthetic facts to test LLMs' temporal reasoning without real-world knowledge, revealing mixed performance and challenges in long-range and parallel event reasoning.", "motivation": "To create a contamination-free TSQA benchmark that tests LLMs' genuine temporal reasoning abilities without relying on pre-trained factual knowledge.", "method": "Introduces UnSeenTimeQA with synthetic facts and three question types to evaluate LLMs' temporal reasoning over sequential and parallel events.", "result": "Mixed performance: LLMs do well on simpler tasks but struggle overall, especially with long-range dependencies and parallel events.", "conclusion": "UnSeenTimeQA highlights LLMs' limitations in temporal reasoning, suggesting room for improvement in handling complex event structures."}}
{"id": "2506.03110", "pdf": "https://arxiv.org/pdf/2506.03110", "abs": "https://arxiv.org/abs/2506.03110", "authors": ["Shuai Yi", "Yixiong Zou", "Yuhua Li", "Ruixuan Li"], "title": "Revisiting Continuity of Image Tokens for Cross-domain Few-shot Learning", "categories": ["cs.CV"], "comment": "Accepted by ICML 2025(spotlight)", "summary": "Vision Transformer (ViT) has achieved remarkable success due to its\nlarge-scale pretraining on general domains, but it still faces challenges when\napplying it to downstream distant domains that have only scarce training data,\nwhich gives rise to the Cross-Domain Few-Shot Learning (CDFSL) task. Inspired\nby Self-Attention's insensitivity to token orders, we find an interesting\nphenomenon neglected in current works: disrupting the continuity of image\ntokens (i.e., making pixels not smoothly transited across patches) in ViT leads\nto a noticeable performance decline in the general (source) domain but only a\nmarginal decrease in downstream target domains. This questions the role of\nimage tokens' continuity in ViT's generalization under large domain gaps. In\nthis paper, we delve into this phenomenon for an interpretation. We find\ncontinuity aids ViT in learning larger spatial patterns, which are harder to\ntransfer than smaller ones, enlarging domain distances. Meanwhile, it implies\nthat only smaller patterns within each patch could be transferred under extreme\ndomain gaps. Based on this interpretation, we further propose a simple yet\neffective method for CDFSL that better disrupts the continuity of image tokens,\nencouraging the model to rely less on large patterns and more on smaller ones.\nExtensive experiments show the effectiveness of our method in reducing domain\ngaps and outperforming state-of-the-art works. Codes and models are available\nat https://github.com/shuaiyi308/ReCIT.", "AI": {"tldr": "The paper investigates the role of image token continuity in Vision Transformers (ViT) for Cross-Domain Few-Shot Learning (CDFSL), finding that disrupting continuity harms general domain performance but minimally affects target domains. A method is proposed to exploit this for better domain adaptation.", "motivation": "To understand why disrupting image token continuity in ViT affects performance differently across domains and to leverage this for improving CDFSL.", "method": "Analyzes the impact of token continuity on ViT's generalization, then proposes a method to disrupt continuity to encourage reliance on smaller, more transferable patterns.", "result": "Disrupting continuity reduces domain gaps and outperforms state-of-the-art methods in CDFSL.", "conclusion": "Continuity aids in learning large spatial patterns, which are less transferable; disrupting it improves adaptation to distant domains by focusing on smaller patterns."}}
{"id": "2506.02044", "pdf": "https://arxiv.org/pdf/2506.02044", "abs": "https://arxiv.org/abs/2506.02044", "authors": ["Xinxu Wei", "Kanhao Zhao", "Yong Jiao", "Lifang He", "Yu Zhang"], "title": "A Brain Graph Foundation Model: Pre-Training and Prompt-Tuning for Any Atlas and Disorder", "categories": ["q-bio.NC", "cs.LG"], "comment": "34pages", "summary": "As large language models (LLMs) continue to revolutionize AI research, there\nis a growing interest in building large-scale brain foundation models to\nadvance neuroscience. While most existing brain foundation models are\npre-trained on time-series signals or region-of-interest (ROI) features, we\npropose a novel graph-based pre-training paradigm for constructing a brain\ngraph foundation model. In this paper, we introduce the Brain Graph Foundation\nModel, termed BrainGFM, a unified framework that leverages graph contrastive\nlearning and graph masked autoencoders for large-scale fMRI-based pre-training.\nBrainGFM is pre-trained on a diverse mixture of brain atlases with varying\nparcellations, significantly expanding the pre-training corpus and enhancing\nthe model's ability to generalize across heterogeneous fMRI-derived brain\nrepresentations. To support efficient and versatile downstream transfer, we\nintegrate both graph prompts and language prompts into the model design,\nenabling BrainGFM to flexibly adapt to a wide range of atlases, neurological\nand psychiatric disorders, and task settings. Furthermore, we employ\nmeta-learning to optimize the graph prompts, facilitating strong generalization\nto previously unseen disorders under both few-shot and zero-shot learning\nconditions via language-guided prompting. BrainGFM is pre-trained on 27\nneuroimaging datasets spanning 25 common neurological and psychiatric\ndisorders, encompassing 2 types of brain atlases (functional and anatomical)\nacross 8 widely-used parcellations, and covering over 25,000 subjects, 60,000\nfMRI scans, and a total of 400,000 graph samples aggregated across all atlases\nand parcellations. The code is available at:\nhttps://github.com/weixinxu666/BrainGFM", "AI": {"tldr": "BrainGFM is a graph-based brain foundation model using contrastive learning and masked autoencoders, pre-trained on diverse fMRI data for versatile neurological applications.", "motivation": "To advance neuroscience by creating a scalable brain foundation model that generalizes across heterogeneous fMRI data and disorders.", "method": "Leverages graph contrastive learning and masked autoencoders, integrating graph and language prompts for flexible adaptation.", "result": "Pre-trained on 27 datasets, 25 disorders, 25,000 subjects, and 60,000 scans, demonstrating strong generalization.", "conclusion": "BrainGFM offers a unified, scalable framework for brain graph modeling with broad applicability in neuroscience."}}
{"id": "2412.17018", "pdf": "https://arxiv.org/pdf/2412.17018", "abs": "https://arxiv.org/abs/2412.17018", "authors": ["Yewen Li", "Shuai Mao", "Jingtong Gao", "Nan Jiang", "Yunjian Xu", "Qingpeng Cai", "Fei Pan", "Peng Jiang", "Bo An"], "title": "GAS: Generative Auto-bidding with Post-training Search", "categories": ["cs.AI"], "comment": null, "summary": "Auto-bidding is essential in facilitating online advertising by automatically\nplacing bids on behalf of advertisers. Generative auto-bidding, which generates\nbids based on an adjustable condition using models like transformers and\ndiffusers, has recently emerged as a new trend due to its potential to learn\noptimal strategies directly from data and adjust flexibly to preferences.\nHowever, generative models suffer from low-quality data leading to a mismatch\nbetween the condition, like return to go, and true action value, especially in\nlong sequential decision-making. Besides, the majority preference in the\ndataset may hinder models' generalization ability on minority advertisers'\npreferences. While it is possible to collect high-quality data and retrain\nmultiple models for different preferences, the high cost makes it unaffordable,\nhindering the advancement of auto-bidding into the era of large foundation\nmodels. To address this, we propose a flexible and practical Generative\nAuto-bidding scheme using post-training Search, termed GAS, to refine a base\npolicy model's output and adapt to various preferences. We use weak-to-strong\nsearch alignment by training small critics for different preferences and an\nMCTS-inspired search to refine the model's output. Specifically, a novel voting\nmechanism with transformer-based critics trained with policy indications could\nenhance search alignment performance. Additionally, utilizing the search, we\nprovide a fine-tuning method for high-frequency preference scenarios\nconsidering computational efficiency. Extensive experiments conducted on the\nreal-world dataset and online A/B test on the Kuaishou advertising platform\ndemonstrate the effectiveness of GAS, achieving significant improvements, e.g.,\n4.60% increment of target cost.", "AI": {"tldr": "The paper introduces GAS, a Generative Auto-bidding scheme using post-training search, to refine base policy models and adapt to diverse advertiser preferences, addressing data quality and generalization issues in generative models.", "motivation": "Generative auto-bidding faces challenges like low-quality data and poor generalization due to majority preferences in datasets, making retraining costly and impractical.", "method": "GAS employs weak-to-strong search alignment with small critics and MCTS-inspired search, enhanced by a transformer-based voting mechanism, and includes a fine-tuning method for high-frequency preferences.", "result": "Experiments on real-world data and online A/B tests show GAS improves performance, e.g., a 4.60% increase in target cost.", "conclusion": "GAS offers a flexible and practical solution for generative auto-bidding, advancing the field toward large foundation models."}}
{"id": "2407.11930", "pdf": "https://arxiv.org/pdf/2407.11930", "abs": "https://arxiv.org/abs/2407.11930", "authors": ["Rachneet Sachdeva", "Yixiao Song", "Mohit Iyyer", "Iryna Gurevych"], "title": "Localizing and Mitigating Errors in Long-form Question Answering", "categories": ["cs.CL"], "comment": "ACL 2025 Findings; Code and data are available:\n  https://github.com/UKPLab/acl2025-lfqa-hallucination", "summary": "Long-form question answering (LFQA) aims to provide thorough and in-depth\nanswers to complex questions, enhancing comprehension. However, such detailed\nresponses are prone to hallucinations and factual inconsistencies, challenging\ntheir faithful evaluation. This work introduces HaluQuestQA, the first\nhallucination dataset with localized error annotations for human-written and\nmodel-generated LFQA answers. HaluQuestQA comprises 698 QA pairs with 1.8k\nspan-level error annotations for five different error types by expert\nannotators, along with preference judgments. Using our collected data, we\nthoroughly analyze the shortcomings of long-form answers and find that they\nlack comprehensiveness and provide unhelpful references. We train an automatic\nfeedback model on this dataset that predicts error spans with incomplete\ninformation and provides associated explanations. Finally, we propose a\nprompt-based approach, Error-informed refinement, that uses signals from the\nlearned feedback model to refine generated answers, which we show reduces\nerrors and improves answer quality across multiple models. Furthermore, humans\nfind answers generated by our approach comprehensive and highly prefer them\n(84%) over the baseline answers.", "AI": {"tldr": "HaluQuestQA is introduced as the first hallucination dataset for LFQA, with localized error annotations. It helps analyze and improve answer quality by training a feedback model and refining answers using error-informed prompts.", "motivation": "LFQA answers often suffer from hallucinations and factual inconsistencies, making faithful evaluation challenging.", "method": "Created HaluQuestQA with 698 QA pairs and 1.8k span-level error annotations. Trained an automatic feedback model and proposed Error-informed refinement for answer improvement.", "result": "The approach reduces errors and improves answer quality, with humans preferring refined answers (84%) over baselines.", "conclusion": "HaluQuestQA and the proposed methods effectively address LFQA shortcomings, enhancing answer comprehensiveness and reducing errors."}}
{"id": "2506.03114", "pdf": "https://arxiv.org/pdf/2506.03114", "abs": "https://arxiv.org/abs/2506.03114", "authors": ["Michelle Chen", "David Russell", "Amritha Pallavoor", "Derek Young", "Jane Wu"], "title": "Zero-Shot Tree Detection and Segmentation from Aerial Forest Imagery", "categories": ["cs.CV"], "comment": "Code:\n  https://github.com/open-forest-observatory/tree-detection-framework", "summary": "Large-scale delineation of individual trees from remote sensing imagery is\ncrucial to the advancement of ecological research, particularly as climate\nchange and other environmental factors rapidly transform forest landscapes\nacross the world. Current RGB tree segmentation methods rely on training\nspecialized machine learning models with labeled tree datasets. While these\nlearning-based approaches can outperform manual data collection when accurate,\nthe existing models still depend on training data that's hard to scale. In this\npaper, we investigate the efficacy of using a state-of-the-art image\nsegmentation model, Segment Anything Model 2 (SAM2), in a zero-shot manner for\nindividual tree detection and segmentation. We evaluate a pretrained SAM2 model\non two tasks in this domain: (1) zero-shot segmentation and (2) zero-shot\ntransfer by using predictions from an existing tree detection model as prompts.\nOur results suggest that SAM2 not only has impressive generalization\ncapabilities, but also can form a natural synergy with specialized methods\ntrained on in-domain labeled data. We find that applying large pretrained\nmodels to problems in remote sensing is a promising avenue for future progress.\nWe make our code available at:\nhttps://github.com/open-forest-observatory/tree-detection-framework.", "AI": {"tldr": "The paper explores using the Segment Anything Model 2 (SAM2) for zero-shot individual tree detection and segmentation in remote sensing imagery, showing promising results and synergy with specialized methods.", "motivation": "Large-scale tree delineation is vital for ecological research amid climate change, but current methods rely on hard-to-scale labeled data.", "method": "Evaluates SAM2 for zero-shot segmentation and transfer using prompts from an existing tree detection model.", "result": "SAM2 demonstrates strong generalization and synergy with domain-specific methods.", "conclusion": "Pretrained models like SAM2 offer a promising path for advancing remote sensing applications."}}
{"id": "2506.02068", "pdf": "https://arxiv.org/pdf/2506.02068", "abs": "https://arxiv.org/abs/2506.02068", "authors": ["Yun-Cheng Tsai", "Yen-Ku Liu", "Samuel Yen-Chi Chen"], "title": "Enhancing Interpretability of Quantum-Assisted Blockchain Clustering via AI Agent-Based Qualitative Analysis", "categories": ["quant-ph", "cs.LG"], "comment": null, "summary": "Blockchain transaction data is inherently high dimensional, noisy, and\nentangled, posing substantial challenges for traditional clustering algorithms.\nWhile quantum enhanced clustering models have demonstrated promising\nperformance gains, their interpretability remains limited, restricting their\napplication in sensitive domains such as financial fraud detection and\nblockchain governance. To address this gap, we propose a two stage analysis\nframework that synergistically combines quantitative clustering evaluation with\nAI Agent assisted qualitative interpretation. In the first stage, we employ\nclassical clustering methods and evaluation metrics including the Silhouette\nScore, Davies Bouldin Index, and Calinski Harabasz Index to determine the\noptimal cluster count and baseline partition quality. In the second stage, we\nintegrate an AI Agent to generate human readable, semantic explanations of\nclustering results, identifying intra cluster characteristics and inter cluster\nrelationships. Our experiments reveal that while fully trained Quantum Neural\nNetworks (QNN) outperform random Quantum Features (QF) in quantitative metrics,\nthe AI Agent further uncovers nuanced differences between these methods,\nnotably exposing the singleton cluster phenomenon in QNN driven models. The\nconsolidated insights from both stages consistently endorse the three cluster\nconfiguration, demonstrating the practical value of our hybrid approach. This\nwork advances the interpretability frontier in quantum assisted blockchain\nanalytics and lays the groundwork for future autonomous AI orchestrated\nclustering frameworks.", "AI": {"tldr": "The paper proposes a two-stage framework combining quantitative clustering evaluation and AI-assisted qualitative interpretation to improve interpretability in quantum-enhanced blockchain analytics.", "motivation": "Blockchain transaction data is complex and noisy, limiting traditional clustering methods. Quantum models show promise but lack interpretability, hindering their use in sensitive applications like fraud detection.", "method": "A two-stage approach: (1) classical clustering with evaluation metrics (Silhouette Score, Davies Bouldin Index, Calinski Harabasz Index) to determine optimal clusters, and (2) AI Agent integration for semantic explanations of results.", "result": "Quantum Neural Networks (QNN) outperform random Quantum Features (QF) in metrics, but AI Agent reveals nuances like singleton clusters in QNN models. The three-cluster configuration is validated.", "conclusion": "The hybrid approach advances interpretability in quantum-assisted blockchain analytics and sets the stage for future AI-driven clustering frameworks."}}
{"id": "2501.12599", "pdf": "https://arxiv.org/pdf/2501.12599", "abs": "https://arxiv.org/abs/2501.12599", "authors": ["Kimi Team", "Angang Du", "Bofei Gao", "Bowei Xing", "Changjiu Jiang", "Cheng Chen", "Cheng Li", "Chenjun Xiao", "Chenzhuang Du", "Chonghua Liao", "Chuning Tang", "Congcong Wang", "Dehao Zhang", "Enming Yuan", "Enzhe Lu", "Fengxiang Tang", "Flood Sung", "Guangda Wei", "Guokun Lai", "Haiqing Guo", "Han Zhu", "Hao Ding", "Hao Hu", "Hao Yang", "Hao Zhang", "Haotian Yao", "Haotian Zhao", "Haoyu Lu", "Haoze Li", "Haozhen Yu", "Hongcheng Gao", "Huabin Zheng", "Huan Yuan", "Jia Chen", "Jianhang Guo", "Jianlin Su", "Jianzhou Wang", "Jie Zhao", "Jin Zhang", "Jingyuan Liu", "Junjie Yan", "Junyan Wu", "Lidong Shi", "Ling Ye", "Longhui Yu", "Mengnan Dong", "Neo Zhang", "Ningchen Ma", "Qiwei Pan", "Qucheng Gong", "Shaowei Liu", "Shengling Ma", "Shupeng Wei", "Sihan Cao", "Siying Huang", "Tao Jiang", "Weihao Gao", "Weimin Xiong", "Weiran He", "Weixiao Huang", "Weixin Xu", "Wenhao Wu", "Wenyang He", "Xianghui Wei", "Xianqing Jia", "Xingzhe Wu", "Xinran Xu", "Xinxing Zu", "Xinyu Zhou", "Xuehai Pan", "Y. Charles", "Yang Li", "Yangyang Hu", "Yangyang Liu", "Yanru Chen", "Yejie Wang", "Yibo Liu", "Yidao Qin", "Yifeng Liu", "Ying Yang", "Yiping Bao", "Yulun Du", "Yuxin Wu", "Yuzhi Wang", "Zaida Zhou", "Zhaoji Wang", "Zhaowei Li", "Zhen Zhu", "Zheng Zhang", "Zhexu Wang", "Zhilin Yang", "Zhiqi Huang", "Zihao Huang", "Ziyao Xu", "Zonghan Yang", "Zongyu Lin"], "title": "Kimi k1.5: Scaling Reinforcement Learning with LLMs", "categories": ["cs.AI", "cs.LG"], "comment": "25 pages", "summary": "Language model pretraining with next token prediction has proved effective\nfor scaling compute but is limited to the amount of available training data.\nScaling reinforcement learning (RL) unlocks a new axis for the continued\nimprovement of artificial intelligence, with the promise that large language\nmodels (LLMs) can scale their training data by learning to explore with\nrewards. However, prior published work has not produced competitive results. In\nlight of this, we report on the training practice of Kimi k1.5, our latest\nmulti-modal LLM trained with RL, including its RL training techniques,\nmulti-modal data recipes, and infrastructure optimization. Long context scaling\nand improved policy optimization methods are key ingredients of our approach,\nwhich establishes a simplistic, effective RL framework without relying on more\ncomplex techniques such as Monte Carlo tree search, value functions, and\nprocess reward models. Notably, our system achieves state-of-the-art reasoning\nperformance across multiple benchmarks and modalities -- e.g., 77.5 on AIME,\n96.2 on MATH 500, 94-th percentile on Codeforces, 74.9 on MathVista -- matching\nOpenAI's o1. Moreover, we present effective long2short methods that use\nlong-CoT techniques to improve short-CoT models, yielding state-of-the-art\nshort-CoT reasoning results -- e.g., 60.8 on AIME, 94.6 on MATH500, 47.3 on\nLiveCodeBench -- outperforming existing short-CoT models such as GPT-4o and\nClaude Sonnet 3.5 by a large margin (up to +550%).", "AI": {"tldr": "The paper introduces Kimi k1.5, a multi-modal LLM trained with RL, achieving state-of-the-art results by simplifying RL techniques and leveraging long context scaling.", "motivation": "To overcome the limitations of next token prediction by scaling RL for improved AI performance, addressing prior shortcomings in RL-based LLMs.", "method": "Uses long context scaling, improved policy optimization, and multi-modal data recipes, avoiding complex techniques like Monte Carlo tree search.", "result": "Achieves top-tier benchmarks (e.g., 77.5 on AIME, 96.2 on MATH500) and outperforms models like GPT-4o in short-CoT reasoning.", "conclusion": "Demonstrates a simple yet effective RL framework for LLMs, advancing multi-modal reasoning and outperforming existing models."}}
{"id": "2407.15186", "pdf": "https://arxiv.org/pdf/2407.15186", "abs": "https://arxiv.org/abs/2407.15186", "authors": ["Liang Shi", "Zhengju Tang", "Nan Zhang", "Xiaotong Zhang", "Zhi Yang"], "title": "A Survey on Employing Large Language Models for Text-to-SQL Tasks", "categories": ["cs.CL"], "comment": "Accepted by ACM Computing Surveys (CSUR)", "summary": "With the development of the Large Language Models (LLMs), a large range of\nLLM-based Text-to-SQL(Text2SQL) methods have emerged. This survey provides a\ncomprehensive review of LLM-based Text2SQL studies. We first enumerate classic\nbenchmarks and evaluation metrics. For the two mainstream methods, prompt\nengineering and finetuning, we introduce a comprehensive taxonomy and offer\npractical insights into each subcategory. We present an overall analysis of the\nabove methods and various models evaluated on well-known datasets and extract\nsome characteristics. Finally, we discuss the challenges and future directions\nin this field.", "AI": {"tldr": "A survey reviewing LLM-based Text2SQL methods, covering benchmarks, evaluation metrics, and two main approaches: prompt engineering and finetuning, with analysis and future challenges.", "motivation": "To comprehensively review and analyze the emerging LLM-based Text2SQL methods, providing insights and identifying challenges.", "method": "Survey of existing studies, categorization of prompt engineering and finetuning methods, and analysis of models on known datasets.", "result": "Identifies characteristics of methods and models, highlighting strengths and limitations.", "conclusion": "Summarizes findings and outlines challenges and future directions for LLM-based Text2SQL research."}}
{"id": "2506.03117", "pdf": "https://arxiv.org/pdf/2506.03117", "abs": "https://arxiv.org/abs/2506.03117", "authors": ["Zeliang Zhang", "Gaowen Liu", "Charles Fleming", "Ramana Rao Kompella", "Chenliang Xu"], "title": "Targeted Forgetting of Image Subgroups in CLIP Models", "categories": ["cs.CV"], "comment": "12 Figures,5 Pages. The project page is\n  \\url{https://zhangaipi.github.io/forget_clip/}", "summary": "Foundation models (FMs) such as CLIP have demonstrated impressive zero-shot\nperformance across various tasks by leveraging large-scale, unsupervised\npre-training. However, they often inherit harmful or unwanted knowledge from\nnoisy internet-sourced datasets, compromising their reliability in real-world\napplications. Existing model unlearning methods either rely on access to\npre-trained datasets or focus on coarse-grained unlearning (e.g., entire\nclasses), leaving a critical gap for fine-grained unlearning. In this paper, we\naddress the challenging scenario of selectively forgetting specific portions of\nknowledge within a class, without access to pre-trained data, while preserving\nthe model's overall performance. We propose a novel three-stage approach that\nprogressively unlearns targeted knowledge while mitigating over-forgetting. It\nconsists of (1) a forgetting stage to fine-tune the CLIP on samples to be\nforgotten, (2) a reminding stage to restore performance on retained samples,\nand (3) a restoring stage to recover zero-shot capabilities using model\nsouping. Additionally, we introduce knowledge distillation to handle the\ndistribution disparity between forgetting, retaining samples, and unseen\npre-trained data. Extensive experiments on CIFAR-10, ImageNet-1K, and style\ndatasets demonstrate that our approach effectively unlearns specific subgroups\nwhile maintaining strong zero-shot performance on semantically similar\nsubgroups and other categories, significantly outperforming baseline unlearning\nmethods, which lose effectiveness under the CLIP unlearning setting.", "AI": {"tldr": "The paper proposes a three-stage method for fine-grained unlearning in foundation models like CLIP, addressing harmful knowledge without pre-trained data access, while preserving performance.", "motivation": "Foundation models inherit harmful knowledge from noisy datasets, but existing unlearning methods lack fine-grained control and require pre-trained data.", "method": "A three-stage approach: forgetting (fine-tuning on forgotten samples), reminding (restoring retained samples), and restoring (recovering zero-shot capabilities via model souping), with knowledge distillation for distribution disparity.", "result": "Effective unlearning of specific subgroups while maintaining zero-shot performance, outperforming baselines on CIFAR-10, ImageNet-1K, and style datasets.", "conclusion": "The method enables fine-grained unlearning in CLIP without pre-trained data, preserving performance and outperforming existing approaches."}}
{"id": "2506.02075", "pdf": "https://arxiv.org/pdf/2506.02075", "abs": "https://arxiv.org/abs/2506.02075", "authors": ["Christian Marius Lillelund", "Shi-ang Qi", "Russell Greiner", "Christian Fischer Pedersen"], "title": "Stop Chasing the C-index: This Is How We Should Evaluate Our Survival Models", "categories": ["stat.ME", "cs.LG"], "comment": null, "summary": "We argue that many survival analysis and time-to-event models are incorrectly\nevaluated. First, we survey many examples of evaluation approaches in the\nliterature and find that most rely on concordance (C-index). However, the\nC-index only measures a model's discriminative ability and does not assess\nother important aspects, such as the accuracy of the time-to-event predictions\nor the calibration of the model's probabilistic estimates. Next, we present a\nset of key desiderata for choosing the right evaluation metric and discuss\ntheir pros and cons. These are tailored to the challenges in survival analysis,\nsuch as sensitivity to miscalibration and various censoring assumptions. We\nhypothesize that the current development of survival metrics conforms to a\ndouble-helix ladder, and that model validity and metric validity must stand on\nthe same rung of the assumption ladder. Finally, we discuss the appropriate\nmethods for evaluating a survival model in practice and summarize various\nviewpoints opposing our analysis.", "AI": {"tldr": "The paper critiques current evaluation methods in survival analysis, highlighting the limitations of the C-index and proposing a framework for better metrics.", "motivation": "To address the shortcomings of existing evaluation approaches in survival analysis, which often rely solely on the C-index, neglecting other critical aspects like prediction accuracy and calibration.", "method": "The authors survey literature, identify flaws in current metrics, propose desiderata for better evaluation, and hypothesize a 'double-helix ladder' framework linking model and metric validity.", "result": "The study reveals the inadequacy of the C-index and suggests tailored metrics for survival analysis, considering challenges like miscalibration and censoring.", "conclusion": "The paper advocates for more comprehensive evaluation methods in survival analysis and acknowledges opposing viewpoints."}}
{"id": "2501.19318", "pdf": "https://arxiv.org/pdf/2501.19318", "abs": "https://arxiv.org/abs/2501.19318", "authors": ["Anirudh Chari", "Suraj Reddy", "Aditya Tiwari", "Richard Lian", "Brian Zhou"], "title": "MINDSTORES: Memory-Informed Neural Decision Synthesis for Task-Oriented Reinforcement in Embodied Systems", "categories": ["cs.AI"], "comment": null, "summary": "While large language models (LLMs) have shown promising capabilities as\nzero-shot planners for embodied agents, their inability to learn from\nexperience and build persistent mental models limits their robustness in\ncomplex open-world environments like Minecraft. We introduce MINDSTORES, an\nexperience-augmented planning framework that enables embodied agents to build\nand leverage mental models through natural interaction with their environment.\nDrawing inspiration from how humans construct and refine cognitive mental\nmodels, our approach extends existing zero-shot LLM planning by maintaining a\ndatabase of past experiences that informs future planning iterations. The key\ninnovation is representing accumulated experiences as natural language\nembeddings of (state, task, plan, outcome) tuples, which can then be\nefficiently retrieved and reasoned over by an LLM planner to generate insights\nand guide plan refinement for novel states and tasks. Through extensive\nexperiments in the MineDojo environment, a simulation environment for agents in\nMinecraft that provides low-level controls for Minecraft, we find that\nMINDSTORES learns and applies its knowledge significantly better than existing\nmemory-based LLM planners while maintaining the flexibility and generalization\nbenefits of zero-shot approaches, representing an important step toward more\ncapable embodied AI systems that can learn continuously through natural\nexperience.", "AI": {"tldr": "MINDSTORES enhances LLM-based embodied agents by enabling them to learn from past experiences and build mental models, improving robustness in complex environments like Minecraft.", "motivation": "Current LLMs lack the ability to learn from experience or build persistent mental models, limiting their effectiveness in open-world environments.", "method": "MINDSTORES augments zero-shot LLM planning with a database of past experiences, represented as natural language embeddings, to inform future planning.", "result": "Experiments in MineDojo show MINDSTORES outperforms memory-based LLM planners while retaining zero-shot flexibility.", "conclusion": "MINDSTORES advances embodied AI by enabling continuous learning through natural interaction, enhancing adaptability in complex environments."}}
{"id": "2407.21050", "pdf": "https://arxiv.org/pdf/2407.21050", "abs": "https://arxiv.org/abs/2407.21050", "authors": ["Yao-Shun Chuang", "Chun-Teh Lee", "Oluwabunmi Tokede", "Guo-Hao Lin", "Ryan Brandon", "Trung Duong Tran", "Xiaoqian Jiang", "Muhammad F. Walji"], "title": "Cross-Institutional Dental EHR Entity Extraction via Generative AI and Synthetic Notes", "categories": ["cs.CL"], "comment": "11 pages, 2 tables, 3 figures, under review", "summary": "This research addresses the issue of missing structured data in dental\nrecords by extracting diagnostic information from unstructured text. The\nupdated periodontology classification system's complexity has increased\nincomplete or missing structured diagnoses. To tackle this, we use advanced AI\nand NLP methods, leveraging GPT-4 to generate synthetic notes for fine-tuning a\nRoBERTa model. This significantly enhances the model's ability to understand\nmedical and dental language. We evaluated the model using 120 randomly selected\nclinical notes from two datasets, demonstrating its improved diagnostic\nextraction accuracy. The results showed high accuracy in diagnosing periodontal\nstatus, stage, and grade, with Site 1 scoring 0.99 and Site 2 scoring 0.98. In\nthe subtype category, Site 2 achieved perfect scores, outperforming Site 1.\nThis method enhances extraction accuracy and broadens its use across dental\ncontexts. The study underscores AI and NLP's transformative impact on\nhealthcare delivery and management. Integrating AI and NLP technologies\nenhances documentation and simplifies administrative tasks by precisely\nextracting complex clinical information. This approach effectively addresses\nchallenges in dental diagnostics. Using synthetic training data from LLMs\noptimizes the training process, improving accuracy and efficiency in\nidentifying periodontal diagnoses from clinical notes. This innovative method\nholds promise for broader healthcare applications, potentially improving\npatient care quality.", "AI": {"tldr": "The paper proposes using AI and NLP (GPT-4 and RoBERTa) to extract periodontal diagnoses from unstructured dental records, improving accuracy and efficiency.", "motivation": "The complexity of updated periodontology classifications leads to incomplete structured data, necessitating better methods to extract diagnoses from unstructured text.", "method": "Advanced AI and NLP techniques, including GPT-4 for synthetic note generation and RoBERTa for fine-tuning, are employed to enhance diagnostic extraction.", "result": "The model achieved high accuracy (0.99 and 0.98) in diagnosing periodontal status, stage, and grade, with perfect scores in subtype categories at one site.", "conclusion": "The approach improves diagnostic extraction, simplifies administrative tasks, and has broader healthcare potential, enhancing patient care quality."}}
{"id": "2506.03119", "pdf": "https://arxiv.org/pdf/2506.03119", "abs": "https://arxiv.org/abs/2506.03119", "authors": ["Zujin Guo", "Size Wu", "Zhongang Cai", "Wei Li", "Chen Change Loy"], "title": "Controllable Human-centric Keyframe Interpolation with Generative Prior", "categories": ["cs.CV"], "comment": "Project Page: https://gseancdat.github.io/projects/PoseFuse3D_KI", "summary": "Existing interpolation methods use pre-trained video diffusion priors to\ngenerate intermediate frames between sparsely sampled keyframes. In the absence\nof 3D geometric guidance, these methods struggle to produce plausible results\nfor complex, articulated human motions and offer limited control over the\nsynthesized dynamics. In this paper, we introduce PoseFuse3D Keyframe\nInterpolator (PoseFuse3D-KI), a novel framework that integrates 3D human\nguidance signals into the diffusion process for Controllable Human-centric\nKeyframe Interpolation (CHKI). To provide rich spatial and structural cues for\ninterpolation, our PoseFuse3D, a 3D-informed control model, features a novel\nSMPL-X encoder that transforms 3D geometry and shape into the 2D latent\nconditioning space, alongside a fusion network that integrates these 3D cues\nwith 2D pose embeddings. For evaluation, we build CHKI-Video, a new dataset\nannotated with both 2D poses and 3D SMPL-X parameters. We show that\nPoseFuse3D-KI consistently outperforms state-of-the-art baselines on\nCHKI-Video, achieving a 9% improvement in PSNR and a 38% reduction in LPIPS.\nComprehensive ablations demonstrate that our PoseFuse3D model improves\ninterpolation fidelity.", "AI": {"tldr": "PoseFuse3D-KI integrates 3D human guidance into video diffusion for better keyframe interpolation, outperforming baselines with improved metrics.", "motivation": "Existing methods lack 3D geometric guidance, leading to poor results for complex human motions and limited control.", "method": "PoseFuse3D-KI uses a 3D-informed control model with a novel SMPL-X encoder and fusion network to integrate 3D cues into 2D latent space.", "result": "Achieves 9% higher PSNR and 38% lower LPIPS than baselines on the CHKI-Video dataset.", "conclusion": "PoseFuse3D-KI enhances interpolation fidelity by leveraging 3D guidance, validated by comprehensive ablations."}}
{"id": "2506.02076", "pdf": "https://arxiv.org/pdf/2506.02076", "abs": "https://arxiv.org/abs/2506.02076", "authors": ["Christian Marius Lillelund", "Sanjay Kalra", "Russell Greiner"], "title": "A meaningful prediction of functional decline in amyotrophic lateral sclerosis based on multi-event survival analysis", "categories": ["q-bio.QM", "cs.LG", "stat.ML"], "comment": null, "summary": "Amyotrophic lateral sclerosis (ALS) is a degenerative disorder of motor\nneurons that causes progressive paralysis in patients. Current treatment\noptions aim to prolong survival and improve quality of life; however, due to\nthe heterogeneity of the disease, it is often difficult to determine the\noptimal time for potential therapies or medical interventions. In this study,\nwe propose a novel method to predict the time until a patient with ALS\nexperiences significant functional impairment (ALSFRS-R<=2) with respect to\nfive common functions: speaking, swallowing, handwriting, walking and\nbreathing. We formulate this task as a multi-event survival problem and\nvalidate our approach in the PRO-ACT dataset by training five covariate-based\nsurvival models to estimate the probability of an event over a 500-day period\nafter a baseline visit. We then predict five event-specific individual survival\ndistributions (ISDs) for each patient, each providing an interpretable and\nmeaningful estimate of when that event will likely take place in the future.\nThe results show that covariate-based models are superior to the Kaplan-Meier\nestimator at predicting time-to-event outcomes. Additionally, our method\nenables practitioners to make individual counterfactual predictions, where\ncertain features (covariates) can be changed to see their effect on the\npredicted outcome. In this regard, we find that Riluzole has little to no\nimpact on predicted functional decline. However, for patients with bulbar-onset\nALS, our method predicts considerably shorter counterfactual time-to-event\nestimates for tasks related to speech and swallowing compared to limb-onset\nALS. The proposed method can be applied to current clinical examination data to\nassess the risk of functional decline and thus allow more personalized\ntreatment planning.", "AI": {"tldr": "A novel method predicts functional decline in ALS patients using multi-event survival models, outperforming Kaplan-Meier and enabling personalized treatment planning.", "motivation": "ALS is heterogeneous, making it hard to determine optimal therapy timing. This study aims to predict functional impairment timing to improve treatment decisions.", "method": "Five covariate-based survival models trained on PRO-ACT dataset predict individual survival distributions for five functions over 500 days.", "result": "Covariate models outperform Kaplan-Meier. Riluzole has minimal impact, but bulbar-onset ALS shows shorter decline times for speech/swallowing.", "conclusion": "The method aids personalized treatment by predicting functional decline risks from clinical data."}}
{"id": "2502.16810", "pdf": "https://arxiv.org/pdf/2502.16810", "abs": "https://arxiv.org/abs/2502.16810", "authors": ["Jibang Wu", "Chenghao Yang", "Simon Mahns", "Chaoqi Wang", "Hao Zhu", "Fei Fang", "Haifeng Xu"], "title": "Grounded Persuasive Language Generation for Automated Marketing", "categories": ["cs.AI", "cs.CL", "cs.HC", "econ.GN", "q-fin.EC"], "comment": null, "summary": "This paper develops an agentic framework that employs large language models\n(LLMs) to automate the generation of persuasive and grounded marketing content,\nusing real estate listing descriptions as our focal application domain. Our\nmethod is designed to align the generated content with user preferences while\nhighlighting useful factual attributes. This agent consists of three key\nmodules: (1) Grounding Module, mimicking expert human behavior to predict\nmarketable features; (2) Personalization Module, aligning content with user\npreferences; (3) Marketing Module, ensuring factual accuracy and the inclusion\nof localized features. We conduct systematic human-subject experiments in the\ndomain of real estate marketing, with a focus group of potential house buyers.\nThe results demonstrate that marketing descriptions generated by our approach\nare preferred over those written by human experts by a clear margin while\nmaintaining the same level of factual accuracy. Our findings suggest a\npromising agentic approach to automate large-scale targeted marketing while\nensuring factuality of content generation.", "AI": {"tldr": "An agentic framework using LLMs automates persuasive, grounded marketing content for real estate, outperforming human experts in preference while maintaining factual accuracy.", "motivation": "To automate persuasive marketing content generation while aligning with user preferences and ensuring factual accuracy, using real estate as a case study.", "method": "Three modules: Grounding (predicts marketable features), Personalization (aligns with user preferences), and Marketing (ensures factual accuracy and localized features).", "result": "Generated descriptions preferred over human experts' by a clear margin, with equal factual accuracy.", "conclusion": "The framework shows promise for automating large-scale targeted marketing with factual content generation."}}
{"id": "2408.08769", "pdf": "https://arxiv.org/pdf/2408.08769", "abs": "https://arxiv.org/abs/2408.08769", "authors": ["Dingwei Chen", "Feiteng Fang", "Shiwen Ni", "Feng Liang", "Xiping Hu", "Ahmadreza Argha", "Hamid Alinejad-Rokny", "Min Yang", "Chengming Li"], "title": "Lower Layers Matter: Alleviating Hallucination via Multi-Layer Fusion Contrastive Decoding with Truthfulness Refocused", "categories": ["cs.CL"], "comment": null, "summary": "Large Language Models (LLMs) have demonstrated exceptional performance across\nvarious natural language processing tasks. However, they occasionally generate\ninaccurate and counterfactual outputs, a phenomenon commonly referred to as\n\"hallucinations''. To tackle this issue, recent studies have explored\ncontrastive decoding between the original model and an amateur model with\ninduced hallucination, showing promising results. Nevertheless, this approach\ncan disrupt the original LLM's output distribution due to coarse contrast and\nsimple subtraction operations, potentially leading to errors. In this paper, we\nintroduce a novel contrastive decoding framework, termed LOL (LOwer Layer\nMatters). Unlike prior methods that focus solely on the final layer, our\napproach integrates contrastive information from lower layers to enable\nmulti-layer fusion during contrastive decoding. Additionally, we incorporate a\ntruthfulness refocused module that leverages instruction guidance to further\nimprove truthfulness in contrastive decoding. Extensive experiments on four\npublicly available datasets demonstrate that the LOL framework significantly\nmitigates hallucination while outperforming existing baselines in most cases.\nFor reproducibility, we will release our code and data upon acceptance.", "AI": {"tldr": "The paper introduces LOL, a contrastive decoding framework that integrates lower-layer information and a truthfulness module to reduce hallucinations in LLMs, outperforming existing methods.", "motivation": "Addressing the issue of hallucinations in LLMs, where models generate inaccurate outputs, by improving contrastive decoding techniques.", "method": "Proposes the LOL framework, which contrasts lower layers and uses a truthfulness refocused module for multi-layer fusion and improved accuracy.", "result": "LOL significantly reduces hallucinations and outperforms baselines on four datasets.", "conclusion": "The LOL framework effectively mitigates hallucinations in LLMs and enhances truthfulness, with code and data to be released for reproducibility."}}
{"id": "2506.03123", "pdf": "https://arxiv.org/pdf/2506.03123", "abs": "https://arxiv.org/abs/2506.03123", "authors": ["Zhengyao Lv", "Chenyang Si", "Tianlin Pan", "Zhaoxi Chen", "Kwan-Yee K. Wong", "Yu Qiao", "Ziwei Liu"], "title": "DCM: Dual-Expert Consistency Model for Efficient and High-Quality Video Generation", "categories": ["cs.CV"], "comment": null, "summary": "Diffusion Models have achieved remarkable results in video synthesis but\nrequire iterative denoising steps, leading to substantial computational\noverhead. Consistency Models have made significant progress in accelerating\ndiffusion models. However, directly applying them to video diffusion models\noften results in severe degradation of temporal consistency and appearance\ndetails. In this paper, by analyzing the training dynamics of Consistency\nModels, we identify a key conflicting learning dynamics during the distillation\nprocess: there is a significant discrepancy in the optimization gradients and\nloss contributions across different timesteps. This discrepancy prevents the\ndistilled student model from achieving an optimal state, leading to compromised\ntemporal consistency and degraded appearance details. To address this issue, we\npropose a parameter-efficient \\textbf{Dual-Expert Consistency Model~(DCM)},\nwhere a semantic expert focuses on learning semantic layout and motion, while a\ndetail expert specializes in fine detail refinement. Furthermore, we introduce\nTemporal Coherence Loss to improve motion consistency for the semantic expert\nand apply GAN and Feature Matching Loss to enhance the synthesis quality of the\ndetail expert.Our approach achieves state-of-the-art visual quality with\nsignificantly reduced sampling steps, demonstrating the effectiveness of expert\nspecialization in video diffusion model distillation. Our code and models are\navailable at\n\\href{https://github.com/Vchitect/DCM}{https://github.com/Vchitect/DCM}.", "AI": {"tldr": "The paper introduces a Dual-Expert Consistency Model (DCM) to address the computational overhead and quality degradation in video diffusion models by specializing tasks between semantic and detail experts, achieving state-of-the-art results with fewer sampling steps.", "motivation": "Current Consistency Models accelerate diffusion models but degrade temporal consistency and appearance details in videos due to conflicting learning dynamics during distillation.", "method": "Proposes DCM with a semantic expert for layout/motion and a detail expert for refinement, using Temporal Coherence Loss and GAN/Feature Matching Loss.", "result": "Achieves high visual quality with reduced steps, outperforming existing methods.", "conclusion": "Expert specialization in DCM effectively balances efficiency and quality in video diffusion model distillation."}}
{"id": "2502.20704", "pdf": "https://arxiv.org/pdf/2502.20704", "abs": "https://arxiv.org/abs/2502.20704", "authors": ["Maximilian Holsman", "Yukun Huang", "Bhuwan Dhingra"], "title": "Fuzzy Speculative Decoding for a Tunable Accuracy-Runtime Tradeoff", "categories": ["cs.AI"], "comment": null, "summary": "Speculative Decoding (SD) enforces strict distributional equivalence to the\ntarget model when accepting candidate tokens. While it maintains the target\nmodel's generation quality, this strict equivalence limits the speedup\nachievable by SD and prevents users from trading deviations from the target\ndistribution in exchange for further inference speed gains. To address these\nlimitations, we introduce Fuzzy Speculative Decoding (FSD) - a decoding\nalgorithm that generalizes SD by accepting candidate tokens based on the\ndivergences between the target and draft model distributions. By allowing for\ncontrolled divergence from the target model, FSD enables users to flexibly\ntrade generation quality for inference speed. Across several benchmarks, our\nmethod is able to achieve significant runtime improvements of over 5 tokens per\nsecond faster than SD at only an approximate 2% absolute reduction in benchmark\naccuracy. In many cases, FSD is even able to match SD benchmark accuracy at\nover 2 tokens per second faster, demonstrating that distributional equivalence\nis not necessary to maintain target model performance. Furthermore, FSD can be\nseamlessly integrated into existing SD extensions; we demonstrate this by\napplying FSD to EAGLE-2, greatly enhancing this existing extension's efficiency\nwhile allowing it to leverage FSD's tunable quality-speed trade-off.", "AI": {"tldr": "Fuzzy Speculative Decoding (FSD) generalizes Speculative Decoding (SD) by allowing controlled divergence from the target model, enabling flexible trade-offs between generation quality and inference speed.", "motivation": "SD's strict distributional equivalence limits speedup potential and prevents quality-speed trade-offs. FSD addresses this by introducing controlled divergence.", "method": "FSD accepts candidate tokens based on divergences between target and draft model distributions, allowing tunable quality-speed trade-offs.", "result": "FSD achieves significant speed improvements (over 5 tokens/sec faster than SD) with minimal accuracy loss (~2%) and sometimes matches SD accuracy at higher speeds.", "conclusion": "FSD demonstrates that strict distributional equivalence isn't necessary for performance, and it can enhance existing SD extensions like EAGLE-2."}}
{"id": "2409.15762", "pdf": "https://arxiv.org/pdf/2409.15762", "abs": "https://arxiv.org/abs/2409.15762", "authors": ["Yahan Li", "Yi Wang", "Yi Chang", "Yuan Wu"], "title": "XTRUST: On the Multilingual Trustworthiness of Large Language Models", "categories": ["cs.CL"], "comment": "21 pages", "summary": "Large language models (LLMs) have demonstrated remarkable capabilities across\na range of natural language processing (NLP) tasks, capturing the attention of\nboth practitioners and the broader public. A key question that now preoccupies\nthe AI community concerns the capabilities and limitations of these models,\nwith trustworthiness emerging as a central issue, particularly as LLMs are\nincreasingly applied in sensitive fields like healthcare and finance, where\nerrors can have serious consequences. However, most previous studies on the\ntrustworthiness of LLMs have been limited to a single language, typically the\npredominant one in the dataset, such as English. In response to the growing\nglobal deployment of LLMs, we introduce XTRUST, the first comprehensive\nmultilingual trustworthiness benchmark. XTRUST encompasses a diverse range of\ntopics, including illegal activities, hallucination, out-of-distribution (OOD)\nrobustness, physical and mental health, toxicity, fairness, misinformation,\nprivacy, and machine ethics, across 10 different languages. Using XTRUST, we\nconduct an empirical evaluation of the multilingual trustworthiness of five\nwidely used LLMs, offering an in-depth analysis of their performance across\nlanguages and tasks. Our results indicate that many LLMs struggle with certain\nlow-resource languages, such as Arabic and Russian, highlighting the\nconsiderable room for improvement in the multilingual trustworthiness of\ncurrent language models. The code is available at\nhttps://github.com/LluckyYH/XTRUST.", "AI": {"tldr": "XTRUST is the first multilingual benchmark evaluating LLM trustworthiness across 10 languages, revealing performance gaps in low-resource languages.", "motivation": "Address the lack of multilingual studies on LLM trustworthiness, especially as LLMs are deployed globally in sensitive fields.", "method": "Introduce XTRUST, a benchmark covering diverse trustworthiness topics, and evaluate five LLMs across 10 languages.", "result": "LLMs struggle with low-resource languages (e.g., Arabic, Russian), showing gaps in multilingual trustworthiness.", "conclusion": "Current LLMs need improvement in multilingual trustworthiness, particularly for low-resource languages."}}
{"id": "2506.03126", "pdf": "https://arxiv.org/pdf/2506.03126", "abs": "https://arxiv.org/abs/2506.03126", "authors": ["Lu Qiu", "Yizhuo Li", "Yuying Ge", "Yixiao Ge", "Ying Shan", "Xihui Liu"], "title": "AnimeShooter: A Multi-Shot Animation Dataset for Reference-Guided Video Generation", "categories": ["cs.CV"], "comment": "Project released at: https://qiulu66.github.io/animeshooter/", "summary": "Recent advances in AI-generated content (AIGC) have significantly accelerated\nanimation production. To produce engaging animations, it is essential to\ngenerate coherent multi-shot video clips with narrative scripts and character\nreferences. However, existing public datasets primarily focus on real-world\nscenarios with global descriptions, and lack reference images for consistent\ncharacter guidance. To bridge this gap, we present AnimeShooter, a\nreference-guided multi-shot animation dataset. AnimeShooter features\ncomprehensive hierarchical annotations and strong visual consistency across\nshots through an automated pipeline. Story-level annotations provide an\noverview of the narrative, including the storyline, key scenes, and main\ncharacter profiles with reference images, while shot-level annotations\ndecompose the story into consecutive shots, each annotated with scene,\ncharacters, and both narrative and descriptive visual captions. Additionally, a\ndedicated subset, AnimeShooter-audio, offers synchronized audio tracks for each\nshot, along with audio descriptions and sound sources. To demonstrate the\neffectiveness of AnimeShooter and establish a baseline for the reference-guided\nmulti-shot video generation task, we introduce AnimeShooterGen, which leverages\nMultimodal Large Language Models (MLLMs) and video diffusion models. The\nreference image and previously generated shots are first processed by MLLM to\nproduce representations aware of both reference and context, which are then\nused as the condition for the diffusion model to decode the subsequent shot.\nExperimental results show that the model trained on AnimeShooter achieves\nsuperior cross-shot visual consistency and adherence to reference visual\nguidance, which highlight the value of our dataset for coherent animated video\ngeneration.", "AI": {"tldr": "AnimeShooter is a dataset for reference-guided multi-shot animation generation, featuring hierarchical annotations and visual consistency. It includes story-level and shot-level details, with an audio subset. The baseline model, AnimeShooterGen, uses MLLMs and diffusion models for coherent video generation.", "motivation": "Existing datasets lack reference images and coherent multi-shot video annotations for animation production, hindering AI-generated content (AIGC) in this domain.", "method": "AnimeShooter dataset provides hierarchical annotations (story-level and shot-level) and visual consistency. AnimeShooterGen uses MLLMs and video diffusion models for reference-guided multi-shot generation.", "result": "The model trained on AnimeShooter achieves superior visual consistency and adherence to reference guidance, demonstrating the dataset's effectiveness.", "conclusion": "AnimeShooter bridges the gap in animation datasets and supports coherent video generation, advancing AIGC in animation production."}}
{"id": "2506.02241", "pdf": "https://arxiv.org/pdf/2506.02241", "abs": "https://arxiv.org/abs/2506.02241", "authors": ["Michael S. Ackermann", "Ion Victor Gosea", "Serkan Gugercin", "Steffen W. R. Werner"], "title": "Second-order AAA algorithms for structured data-driven modeling", "categories": ["math.NA", "cs.LG", "cs.NA", "cs.SY", "eess.SY", "math.DS", "math.OC", "41A20, 65D15, 93B15, 93C05, 93C80"], "comment": "37 pages, 6 figures, 3 tables", "summary": "The data-driven modeling of dynamical systems has become an essential tool\nfor the construction of accurate computational models from real-world data. In\nthis process, the inherent differential structures underlying the considered\nphysical phenomena are often neglected making the reinterpretation of the\nlearned models in a physically meaningful sense very challenging. In this work,\nwe present three data-driven modeling approaches for the construction of\ndynamical systems with second-order differential structure directly from\nfrequency domain data. Based on the second-order structured barycentric form,\nwe extend the well-known Adaptive Antoulas-Anderson algorithm to the case of\nsecond-order systems. Depending on the available computational resources, we\npropose variations of the proposed method that prioritize either higher\ncomputation speed or greater modeling accuracy, and we present a theoretical\nanalysis for the expected accuracy and performance of the proposed methods.\nThree numerical examples demonstrate the effectiveness of our new structured\napproaches in comparison to classical unstructured data-driven modeling.", "AI": {"tldr": "The paper introduces three data-driven modeling approaches for dynamical systems with second-order differential structure, improving interpretability and accuracy compared to unstructured methods.", "motivation": "Current data-driven models often neglect inherent differential structures, making physical interpretation difficult. This work aims to address this gap.", "method": "Extends the Adaptive Antoulas-Anderson algorithm for second-order systems, offering variations for speed or accuracy. Theoretical analysis of performance and accuracy is provided.", "result": "Numerical examples show the new structured approaches outperform classical unstructured methods in effectiveness.", "conclusion": "The proposed methods enhance modeling accuracy and physical interpretability for dynamical systems with second-order structure."}}
{"id": "2503.04291", "pdf": "https://arxiv.org/pdf/2503.04291", "abs": "https://arxiv.org/abs/2503.04291", "authors": ["Tianyang Zhang", "Zhuoxuan Jiang", "Haotian Zhang", "Lin Lin", "Shaohua Zhang"], "title": "MathMistake Checker: A Comprehensive Demonstration for Step-by-Step Math Problem Mistake Finding by Prompt-Guided LLMs", "categories": ["cs.AI"], "comment": "Published in AAAI 2025", "summary": "We propose a novel system, MathMistake Checker, designed to automate\nstep-by-step mistake finding in mathematical problems with lengthy answers\nthrough a two-stage process. The system aims to simplify grading, increase\nefficiency, and enhance learning experiences from a pedagogical perspective. It\nintegrates advanced technologies, including computer vision and the\nchain-of-thought capabilities of the latest large language models (LLMs). Our\nsystem supports open-ended grading without reference answers and promotes\npersonalized learning by providing targeted feedback. We demonstrate its\neffectiveness across various types of math problems, such as calculation and\nword problems.", "AI": {"tldr": "MathMistake Checker automates mistake detection in math problems using computer vision and LLMs, improving grading efficiency and learning.", "motivation": "To simplify grading, enhance efficiency, and improve learning by automating mistake detection in lengthy math answers.", "method": "A two-stage process integrating computer vision and LLMs for open-ended grading and personalized feedback.", "result": "Effective across calculation and word problems, supporting personalized learning.", "conclusion": "The system successfully automates mistake finding, benefiting both educators and learners."}}
{"id": "2409.17044", "pdf": "https://arxiv.org/pdf/2409.17044", "abs": "https://arxiv.org/abs/2409.17044", "authors": ["Francesco Verdini", "Pierfrancesco Melucci", "Stefano Perna", "Francesco Cariaggi", "Marco Gaido", "Sara Papi", "Szymon Mazurek", "Marek Kasztelnik", "Luisa Bentivogli", "S\u00e9bastien Brati\u00e8res", "Paolo Merialdo", "Simone Scardapane"], "title": "How to Connect Speech Foundation Models and Large Language Models? What Matters and What Does Not", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "Submitted to Interspeech 2025", "summary": "The remarkable performance achieved by Large Language Models (LLM) has driven\nresearch efforts to leverage them for a wide range of tasks and input\nmodalities. In speech-to-text (S2T) tasks, the emerging solution consists of\nprojecting the output of the encoder of a Speech Foundational Model (SFM) into\nthe LLM embedding space through an adapter module. However, no work has yet\ninvestigated how much the downstream-task performance depends on each component\n(SFM, adapter, LLM) nor whether the best design of the adapter depends on the\nchosen SFM and LLM. To fill this gap, we evaluate the combination of 5 adapter\nmodules, 2 LLMs (Mistral and Llama), and 2 SFMs (Whisper and SeamlessM4T) on\ntwo widespread S2T tasks, namely Automatic Speech Recognition and Speech\nTranslation. Our results demonstrate that the SFM plays a pivotal role in\ndownstream performance, while the adapter choice has moderate impact and\ndepends on the SFM and LLM.", "AI": {"tldr": "The paper investigates the impact of SFM, adapter, and LLM components in S2T tasks, finding SFM most critical, adapter choice moderately impactful, and dependent on SFM and LLM.", "motivation": "To understand the influence of SFM, adapter, and LLM components on S2T task performance and their interdependencies.", "method": "Evaluated combinations of 5 adapter modules, 2 LLMs (Mistral, Llama), and 2 SFMs (Whisper, SeamlessM4T) on ASR and Speech Translation tasks.", "result": "SFM is pivotal for performance, adapter choice has moderate impact and depends on SFM and LLM.", "conclusion": "SFM is the most critical component in S2T tasks, while adapter design should consider SFM and LLM compatibility."}}
{"id": "2506.03131", "pdf": "https://arxiv.org/pdf/2506.03131", "abs": "https://arxiv.org/abs/2506.03131", "authors": ["Zidong Wang", "Lei Bai", "Xiangyu Yue", "Wanli Ouyang", "Yiyuan Zhang"], "title": "Native-Resolution Image Synthesis", "categories": ["cs.CV", "cs.LG"], "comment": "Project Page: https://wzdthu.github.io/NiT/", "summary": "We introduce native-resolution image synthesis, a novel generative modeling\nparadigm that enables the synthesis of images at arbitrary resolutions and\naspect ratios. This approach overcomes the limitations of conventional\nfixed-resolution, square-image methods by natively handling variable-length\nvisual tokens, a core challenge for traditional techniques. To this end, we\nintroduce the Native-resolution diffusion Transformer (NiT), an architecture\ndesigned to explicitly model varying resolutions and aspect ratios within its\ndenoising process. Free from the constraints of fixed formats, NiT learns\nintrinsic visual distributions from images spanning a broad range of\nresolutions and aspect ratios. Notably, a single NiT model simultaneously\nachieves the state-of-the-art performance on both ImageNet-256x256 and 512x512\nbenchmarks. Surprisingly, akin to the robust zero-shot capabilities seen in\nadvanced large language models, NiT, trained solely on ImageNet, demonstrates\nexcellent zero-shot generalization performance. It successfully generates\nhigh-fidelity images at previously unseen high resolutions (e.g., 1536 x 1536)\nand diverse aspect ratios (e.g., 16:9, 3:1, 4:3), as shown in Figure 1. These\nfindings indicate the significant potential of native-resolution modeling as a\nbridge between visual generative modeling and advanced LLM methodologies.", "AI": {"tldr": "Native-resolution image synthesis introduces a method to generate images at any resolution/aspect ratio, overcoming fixed-resolution limitations with the NiT architecture.", "motivation": "To address the limitations of fixed-resolution, square-image methods in generative modeling.", "method": "Introduces the Native-resolution diffusion Transformer (NiT), designed to handle variable resolutions/aspect ratios in denoising.", "result": "Achieves state-of-the-art performance on ImageNet benchmarks and demonstrates zero-shot generalization to unseen resolutions/aspect ratios.", "conclusion": "Native-resolution modeling bridges visual generative modeling with advanced LLM methodologies, showing significant potential."}}
{"id": "2506.02254", "pdf": "https://arxiv.org/pdf/2506.02254", "abs": "https://arxiv.org/abs/2506.02254", "authors": ["Dimitris G Giovanis", "Nikolaos Evangelou", "Ioannis G Kevrekidis", "Roger G Ghanem"], "title": "Enabling Probabilistic Learning on Manifolds through Double Diffusion Maps", "categories": ["stat.ML", "cs.LG", "math.PR"], "comment": null, "summary": "We present a generative learning framework for probabilistic sampling based\non an extension of the Probabilistic Learning on Manifolds (PLoM) approach,\nwhich is designed to generate statistically consistent realizations of a random\nvector in a finite-dimensional Euclidean space, informed by a limited (yet\nrepresentative) set of observations. In its original form, PLoM constructs a\nreduced-order probabilistic model by combining three main components: (a)\nkernel density estimation to approximate the underlying probability measure,\n(b) Diffusion Maps to uncover the intrinsic low-dimensional manifold structure,\nand (c) a reduced-order Ito Stochastic Differential Equation (ISDE) to sample\nfrom the learned distribution. A key challenge arises, however, when the number\nof available data points N is small and the dimensionality of the diffusion-map\nbasis approaches N, resulting in overfitting and loss of generalization. To\novercome this limitation, we propose an enabling extension that implements a\nsynthesis of Double Diffusion Maps -- a technique capable of capturing\nmultiscale geometric features of the data -- with Geometric Harmonics (GH), a\nnonparametric reconstruction method that allows smooth nonlinear interpolation\nin high-dimensional ambient spaces. This approach enables us to solve a\nfull-order ISDE directly in the latent space, preserving the full dynamical\ncomplexity of the system, while leveraging its reduced geometric\nrepresentation. The effectiveness and robustness of the proposed method are\nillustrated through two numerical studies: one based on data generated from\ntwo-dimensional Hermite polynomial functions and another based on high-fidelity\nsimulations of a detonation wave in a reactive flow.", "AI": {"tldr": "A generative learning framework extends Probabilistic Learning on Manifolds (PLoM) to address overfitting in small datasets by combining Double Diffusion Maps and Geometric Harmonics, enabling robust sampling in high-dimensional spaces.", "motivation": "The original PLoM method struggles with small datasets, leading to overfitting. The goal is to improve generalization by capturing multiscale data features and enabling high-dimensional interpolation.", "method": "The framework integrates Double Diffusion Maps for multiscale geometric analysis and Geometric Harmonics for high-dimensional interpolation, solving a full-order ISDE in the latent space.", "result": "The method demonstrates effectiveness in generating consistent realizations, validated through numerical studies on polynomial functions and detonation wave simulations.", "conclusion": "The proposed extension enhances PLoM's robustness, enabling accurate probabilistic sampling even with limited data."}}
{"id": "2503.16724", "pdf": "https://arxiv.org/pdf/2503.16724", "abs": "https://arxiv.org/abs/2503.16724", "authors": ["Zhaoxin Li", "Zhang Xi-Jia", "Batuhan Altundas", "Letian Chen", "Rohan Paleja", "Matthew Gombolay"], "title": "Towards Automated Semantic Interpretability in Reinforcement Learning via Vision-Language Models", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "Semantic interpretability in Reinforcement Learning (RL) enables transparency\nand verifiability by making the agent's decisions understandable and\nverifiable. Achieving this, however, requires a feature space composed of\nhuman-understandable concepts, which traditionally rely on human specification\nand may fail to generalize to unseen environments. We introduce interpretable\nTree-based Reinforcement learning via Automated Concept Extraction (iTRACE), an\nautomated framework that leverages pre-trained vision-language models (VLM) for\nsemantic feature extraction and interpretable tree-based models for policy\noptimization. iTRACE first extracts semantically meaningful features, then maps\nthem to policies via interpretable trees. To address the impracticality of\nrunning VLMs in RL loops, we distill their outputs into a lightweight model. By\nleveraging Vision-Language Models (VLMs) to automate tree-based reinforcement\nlearning, iTRACE eliminates the need for human annotation traditionally\nrequired by interpretable models, while also addressing the limitations of VLMs\nalone, such as their lack of grounding in action spaces and inability to\ndirectly optimize policies. iTRACE outperforms MLP baselines that use the same\ninterpretable features and matches the performance of CNN-based policies,\nproducing verifiable, semantically interpretable, and human-aligned behaviors\nwithout requiring human annotation.", "AI": {"tldr": "iTRACE automates semantic feature extraction and policy optimization in RL using VLMs and interpretable trees, eliminating human annotation and matching CNN-based performance.", "motivation": "To achieve semantic interpretability in RL without relying on human-specified features, which may not generalize well.", "method": "Uses VLMs for semantic feature extraction and interpretable trees for policy optimization, distilling VLM outputs into a lightweight model.", "result": "Outperforms MLP baselines and matches CNN-based policies, producing verifiable and human-aligned behaviors.", "conclusion": "iTRACE provides a scalable, automated solution for interpretable RL without human annotation."}}
{"id": "2410.00382", "pdf": "https://arxiv.org/pdf/2410.00382", "abs": "https://arxiv.org/abs/2410.00382", "authors": ["Shota Takashiro", "Takeshi Kojima", "Andrew Gambardella", "Qi Cao", "Yusuke Iwasawa", "Yutaka Matsuo"], "title": "Answer When Needed, Forget When Not: Language Models Pretend to Forget via In-Context Knowledge Unlearning", "categories": ["cs.CL"], "comment": "Accepted at ACL 2025 (Findings)", "summary": "As large language models (LLMs) are applied across diverse domains, the\nability to selectively unlearn specific information is becoming increasingly\nessential. For instance, LLMs are expected to selectively provide confidential\ninformation to authorized internal users, such as employees or trusted\npartners, while withholding it from external users, including the general\npublic and unauthorized entities. Therefore, we propose a novel method termed\n``in-context knowledge unlearning'', which enables the model to selectively\nforget information in test-time based on the query context. Our method\nfine-tunes pre-trained LLMs to enable prompt unlearning of target knowledge\nwithin the context, while preserving unrelated information. Experiments on\nTOFU, AGE and RWKU datasets using Llama2-7B/13B and Mistral-7B models\ndemonstrate that our method achieves up to 95% forget accuracy while retaining\n80% of unrelated knowledge, significantly outperforming baselines in both\nin-domain and out-of-domain scenarios. Further investigation of the model's\ninternal behavior revealed that while fine-tuned LLMs generate correct\npredictions in the middle layers and preserve them up to the final layer.\nHowever, the decision to forget is made only at the last layer, i.e. ``LLMs\npretend to forget''. Our findings offer valuable insight into the improvement\nof the robustness of the unlearning mechanisms in LLMs, laying a foundation for\nfuture research in the field.", "AI": {"tldr": "A novel method, 'in-context knowledge unlearning', enables LLMs to selectively forget information based on query context, achieving high forget accuracy while retaining unrelated knowledge.", "motivation": "The need for LLMs to selectively provide or withhold confidential information based on user authorization drives the development of this method.", "method": "Fine-tuning pre-trained LLMs to enable prompt unlearning of target knowledge within the context, preserving unrelated information.", "result": "Achieves up to 95% forget accuracy while retaining 80% unrelated knowledge, outperforming baselines. Internal behavior shows LLMs 'pretend to forget' at the last layer.", "conclusion": "The method improves robustness of unlearning mechanisms in LLMs, providing insights for future research."}}
{"id": "2506.03140", "pdf": "https://arxiv.org/pdf/2506.03140", "abs": "https://arxiv.org/abs/2506.03140", "authors": ["Yawen Luo", "Jianhong Bai", "Xiaoyu Shi", "Menghan Xia", "Xintao Wang", "Pengfei Wan", "Di Zhang", "Kun Gai", "Tianfan Xue"], "title": "CamCloneMaster: Enabling Reference-based Camera Control for Video Generation", "categories": ["cs.CV"], "comment": "Project Page: https://camclonemaster.github.io/", "summary": "Camera control is crucial for generating expressive and cinematic videos.\nExisting methods rely on explicit sequences of camera parameters as control\nconditions, which can be cumbersome for users to construct, particularly for\nintricate camera movements. To provide a more intuitive camera control method,\nwe propose CamCloneMaster, a framework that enables users to replicate camera\nmovements from reference videos without requiring camera parameters or\ntest-time fine-tuning. CamCloneMaster seamlessly supports reference-based\ncamera control for both Image-to-Video and Video-to-Video tasks within a\nunified framework. Furthermore, we present the Camera Clone Dataset, a\nlarge-scale synthetic dataset designed for camera clone learning, encompassing\ndiverse scenes, subjects, and camera movements. Extensive experiments and user\nstudies demonstrate that CamCloneMaster outperforms existing methods in terms\nof both camera controllability and visual quality.", "AI": {"tldr": "CamCloneMaster is a framework for intuitive camera control in videos by replicating movements from reference videos, eliminating the need for explicit camera parameters or fine-tuning.", "motivation": "Existing camera control methods require cumbersome explicit camera parameter sequences, making intricate movements difficult for users.", "method": "CamCloneMaster replicates camera movements from reference videos without needing camera parameters or test-time fine-tuning, supporting Image-to-Video and Video-to-Video tasks.", "result": "Outperforms existing methods in camera controllability and visual quality, validated by experiments and user studies.", "conclusion": "CamCloneMaster offers a more intuitive and effective approach to camera control, supported by a large-scale synthetic dataset."}}
{"id": "2506.02257", "pdf": "https://arxiv.org/pdf/2506.02257", "abs": "https://arxiv.org/abs/2506.02257", "authors": ["Ruiting Liang", "Jake A. Soloff", "Rina Foygel Barber", "Rebecca Willett"], "title": "Assumption-free stability for ranking problems", "categories": ["stat.ML", "cs.LG", "math.ST", "stat.ME", "stat.TH"], "comment": null, "summary": "In this work, we consider ranking problems among a finite set of candidates:\nfor instance, selecting the top-$k$ items among a larger list of candidates or\nobtaining the full ranking of all items in the set. These problems are often\nunstable, in the sense that estimating a ranking from noisy data can exhibit\nhigh sensitivity to small perturbations. Concretely, if we use data to provide\na score for each item (say, by aggregating preference data over a sample of\nusers), then for two items with similar scores, small fluctuations in the data\ncan alter the relative ranking of those items. Many existing theoretical\nresults for ranking problems assume a separation condition to avoid this\nchallenge, but real-world data often contains items whose scores are\napproximately tied, limiting the applicability of existing theory. To address\nthis gap, we develop a new algorithmic stability framework for ranking\nproblems, and propose two novel ranking operators for achieving stable ranking:\nthe \\emph{inflated top-$k$} for the top-$k$ selection problem and the\n\\emph{inflated full ranking} for ranking the full list. To enable stability,\neach method allows for expressing some uncertainty in the output. For both of\nthese two problems, our proposed methods provide guaranteed stability, with no\nassumptions on data distributions and no dependence on the total number of\ncandidates to be ranked. Experiments on real-world data confirm that the\nproposed methods offer stability without compromising the informativeness of\nthe output.", "AI": {"tldr": "The paper addresses instability in ranking problems by proposing two novel ranking operators (inflated top-k and inflated full ranking) that ensure stability without relying on data distribution assumptions or the number of candidates.", "motivation": "Ranking problems are often unstable due to noisy data, especially when items have similar scores. Existing theory assumes separation conditions, which are unrealistic for real-world data.", "method": "Develops an algorithmic stability framework and introduces two ranking operators: inflated top-k for top-k selection and inflated full ranking for full ranking. These methods incorporate uncertainty to achieve stability.", "result": "The proposed methods guarantee stability without assumptions on data distributions or dependence on the number of candidates. Experiments show stability without losing informativeness.", "conclusion": "The new framework and ranking operators effectively address instability in ranking problems, offering practical solutions for real-world applications."}}
{"id": "2505.00278", "pdf": "https://arxiv.org/pdf/2505.00278", "abs": "https://arxiv.org/abs/2505.00278", "authors": ["Lo Pang-Yun Ting", "Yu-Hao Chiang", "Yi-Tung Tsai", "Hsu-Chao Lai", "Kun-Ta Chuang"], "title": "DeCo: Defect-Aware Modeling with Contrasting Matching for Optimizing Task Assignment in Online IC Testing", "categories": ["cs.AI"], "comment": null, "summary": "In the semiconductor industry, integrated circuit (IC) processes play a vital\nrole, as the rising complexity and market expectations necessitate improvements\nin yield. Identifying IC defects and assigning IC testing tasks to the right\nengineers improves efficiency and reduces losses. While current studies\nemphasize fault localization or defect classification, they overlook the\nintegration of defect characteristics, historical failures, and the insights\nfrom engineer expertise, which restrains their effectiveness in improving IC\nhandling. To leverage AI for these challenges, we propose DeCo, an innovative\napproach for optimizing task assignment in IC testing. DeCo constructs a novel\ndefect-aware graph from IC testing reports, capturing co-failure relationships\nto enhance defect differentiation, even with scarce defect data. Additionally,\nit formulates defect-aware representations for engineers and tasks, reinforced\nby local and global structure modeling on the defect-aware graph. Finally, a\ncontrasting-based assignment mechanism pairs testing tasks with QA engineers by\nconsidering their skill level and current workload, thus promoting an equitable\nand efficient job dispatch. Experiments on a real-world dataset demonstrate\nthat DeCo achieves the highest task-handling success rates in different\nscenarios, exceeding 80\\%, while also maintaining balanced workloads on both\nscarce or expanded defect data. Moreover, case studies reveal that DeCo can\nassign tasks to potentially capable engineers, even for their unfamiliar\ndefects, highlighting its potential as an AI-driven solution for the real-world\nIC failure analysis and task handling.", "AI": {"tldr": "DeCo is an AI-driven approach for optimizing IC testing task assignment by integrating defect characteristics, historical failures, and engineer expertise, achieving high success rates and balanced workloads.", "motivation": "Current IC defect studies lack integration of defect characteristics, historical failures, and engineer insights, limiting their effectiveness in improving IC handling.", "method": "DeCo constructs a defect-aware graph from IC testing reports, models engineer and task representations, and uses a contrasting-based assignment mechanism for task-engineer pairing.", "result": "DeCo achieves over 80% task-handling success rates and balanced workloads, even with scarce defect data, and assigns tasks to capable engineers for unfamiliar defects.", "conclusion": "DeCo demonstrates potential as an AI-driven solution for real-world IC failure analysis and task handling, improving efficiency and reducing losses."}}
{"id": "2410.02677", "pdf": "https://arxiv.org/pdf/2410.02677", "abs": "https://arxiv.org/abs/2410.02677", "authors": ["Yu Ying Chiu", "Liwei Jiang", "Bill Yuchen Lin", "Chan Young Park", "Shuyue Stella Li", "Sahithya Ravi", "Mehar Bhatia", "Maria Antoniak", "Yulia Tsvetkov", "Vered Shwartz", "Yejin Choi"], "title": "CulturalBench: A Robust, Diverse, and Challenging Cultural Benchmark by Human-AI CulturalTeaming", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "ACL 2025 Main, 39 pages, 16 figures. arXiv admin note: text overlap\n  with arXiv:2404.06664", "summary": "Robust, diverse, and challenging cultural knowledge benchmarks are essential\nfor measuring our progress towards making LMs that are helpful across diverse\ncultures. We introduce CulturalBench: a set of 1,696 human-written and\nhuman-verified questions to assess LMs' cultural knowledge, covering 45 global\nregions including underrepresented ones like Bangladesh, Zimbabwe, and Peru.\nQuestions are each verified by five independent annotators and span 17 diverse\ntopics ranging from food preferences to greeting etiquette. We construct\nCulturalBench using methods inspired by Human-AI Red-Teaming. Compared to human\nperformance (92.4% accuracy), the hard version of CulturalBench is challenging\neven for the best-performing frontier LMs, ranging from 28.7% to 61.5% in\naccuracy. We find that LMs often struggle with tricky questions that have\nmultiple correct answers (e.g., What utensils do the Chinese usually use?),\nrevealing a tendency to overfit to a single answer. Our results indicate that\nGPT-4o substantially outperform other models across cultures, besting local\nproviders (e.g., Mistral on European culture and DeepSeek on Chinese culture).\nAcross the board, models under-perform on questions related to North Africa,\nSouth America and Middle East.", "AI": {"tldr": "CulturalBench is a diverse cultural knowledge benchmark with 1,696 questions covering 45 regions. It challenges LMs, revealing gaps in performance, especially for underrepresented areas and tricky questions. GPT-4o outperforms others.", "motivation": "To measure progress in making LMs culturally aware and helpful across diverse regions, including underrepresented ones.", "method": "Constructed using Human-AI Red-Teaming methods, with 1,696 human-written and verified questions spanning 17 topics and 45 regions.", "result": "LMs perform poorly (28.7%-61.5% accuracy) compared to humans (92.4%). GPT-4o leads but struggles with tricky questions and underrepresented regions.", "conclusion": "CulturalBench highlights LM limitations in cultural knowledge, emphasizing the need for improvement in diverse and underrepresented contexts."}}
{"id": "2506.03141", "pdf": "https://arxiv.org/pdf/2506.03141", "abs": "https://arxiv.org/abs/2506.03141", "authors": ["Jiwen Yu", "Jianhong Bai", "Yiran Qin", "Quande Liu", "Xintao Wang", "Pengfei Wan", "Di Zhang", "Xihui Liu"], "title": "Context as Memory: Scene-Consistent Interactive Long Video Generation with Memory Retrieval", "categories": ["cs.CV"], "comment": null, "summary": "Recent advances in interactive video generation have shown promising results,\nyet existing approaches struggle with scene-consistent memory capabilities in\nlong video generation due to limited use of historical context. In this work,\nwe propose Context-as-Memory, which utilizes historical context as memory for\nvideo generation. It includes two simple yet effective designs: (1) storing\ncontext in frame format without additional post-processing; (2) conditioning by\nconcatenating context and frames to be predicted along the frame dimension at\nthe input, requiring no external control modules. Furthermore, considering the\nenormous computational overhead of incorporating all historical context, we\npropose the Memory Retrieval module to select truly relevant context frames by\ndetermining FOV (Field of View) overlap between camera poses, which\nsignificantly reduces the number of candidate frames without substantial\ninformation loss. Experiments demonstrate that Context-as-Memory achieves\nsuperior memory capabilities in interactive long video generation compared to\nSOTAs, even generalizing effectively to open-domain scenarios not seen during\ntraining. The link of our project page is https://context-as-memory.github.io/.", "AI": {"tldr": "Context-as-Memory improves long video generation by using historical context as memory, with efficient frame storage and retrieval, outperforming existing methods.", "motivation": "Existing methods lack scene-consistent memory in long video generation due to limited historical context use.", "method": "Proposes Context-as-Memory with frame-based context storage and a Memory Retrieval module for efficient frame selection.", "result": "Outperforms SOTAs in memory capabilities, even in unseen open-domain scenarios.", "conclusion": "Context-as-Memory effectively enhances long video generation with superior memory utilization."}}
{"id": "2506.02260", "pdf": "https://arxiv.org/pdf/2506.02260", "abs": "https://arxiv.org/abs/2506.02260", "authors": ["Howon Ryu", "Yuliang Chen", "Yacun Wang", "Andrea Z. LaCroix", "Chongzhi Di", "Loki Natarajan", "Yu Wang", "Jingjing Zou"], "title": "MoCA: Multi-modal Cross-masked Autoencoder for Digital Health Measurements", "categories": ["stat.ML", "cs.LG", "stat.AP"], "comment": null, "summary": "The growing prevalence of digital health technologies has led to the\ngeneration of complex multi-modal data, such as physical activity measurements\nsimultaneously collected from various sensors of mobile and wearable devices.\nThese data hold immense potential for advancing health studies, but current\nmethods predominantly rely on supervised learning, requiring extensive labeled\ndatasets that are often expensive or impractical to obtain, especially in\nclinical studies. To address this limitation, we propose a self-supervised\nlearning framework called Multi-modal Cross-masked Autoencoder (MoCA) that\nleverages cross-modality masking and the Transformer autoencoder architecture\nto utilize both temporal correlations within modalities and cross-modal\ncorrelations between data streams. We also provide theoretical guarantees to\nsupport the effectiveness of the cross-modality masking scheme in MoCA.\nComprehensive experiments and ablation studies demonstrate that our method\noutperforms existing approaches in both reconstruction and downstream tasks. We\nrelease open-source code for data processing, pre-training, and downstream\ntasks in the supplementary materials. This work highlights the transformative\npotential of self-supervised learning in digital health and multi-modal data.", "AI": {"tldr": "Proposes MoCA, a self-supervised learning framework for multi-modal health data, outperforming supervised methods by leveraging cross-modality masking and Transformer autoencoders.", "motivation": "Addresses the impracticality of obtaining labeled datasets in digital health by introducing a self-supervised approach.", "method": "Uses cross-modality masking and Transformer autoencoder to exploit temporal and cross-modal correlations.", "result": "Outperforms existing methods in reconstruction and downstream tasks, with theoretical support for the masking scheme.", "conclusion": "Demonstrates the potential of self-supervised learning for digital health and multi-modal data."}}
{"id": "2505.01305", "pdf": "https://arxiv.org/pdf/2505.01305", "abs": "https://arxiv.org/abs/2505.01305", "authors": ["Lo Pang-Yun Ting", "Hong-Pei Chen", "An-Shan Liu", "Chun-Yin Yeh", "Po-Lin Chen", "Kun-Ta Chuang"], "title": "Early Detection of Patient Deterioration from Real-Time Wearable Monitoring System", "categories": ["cs.AI"], "comment": null, "summary": "Early detection of patient deterioration is crucial for reducing mortality\nrates. Heart rate data has shown promise in assessing patient health, and\nwearable devices offer a cost-effective solution for real-time monitoring.\nHowever, extracting meaningful insights from diverse heart rate data and\nhandling missing values in wearable device data remain key challenges. To\naddress these challenges, we propose TARL, an innovative approach that models\nthe structural relationships of representative subsequences, known as\nshapelets, in heart rate time series. TARL creates a shapelet-transition\nknowledge graph to model shapelet dynamics in heart rate time series,\nindicating illness progression and potential future changes. We further\nintroduce a transition-aware knowledge embedding to reinforce relationships\namong shapelets and quantify the impact of missing values, enabling the\nformulation of comprehensive heart rate representations. These representations\ncapture explanatory structures and predict future heart rate trends, aiding\nearly illness detection. We collaborate with physicians and nurses to gather\nICU patient heart rate data from wearables and diagnostic metrics assessing\nillness severity for evaluating deterioration. Experiments on real-world ICU\ndata demonstrate that TARL achieves both high reliability and early detection.\nA case study further showcases TARL's explainable detection process,\nhighlighting its potential as an AI-driven tool to assist clinicians in\nrecognizing early signs of patient deterioration.", "AI": {"tldr": "TARL is a novel method using shapelet-transition knowledge graphs to analyze heart rate data for early patient deterioration detection, handling missing values and improving reliability.", "motivation": "Early detection of patient deterioration is vital, but challenges like diverse heart rate data and missing values in wearable devices hinder effective monitoring.", "method": "TARL models shapelet dynamics in heart rate time series via a knowledge graph, introduces transition-aware embedding, and quantifies missing values' impact.", "result": "TARL achieves high reliability and early detection in ICU patient data, with explainable results aiding clinicians.", "conclusion": "TARL shows promise as an AI tool for early illness detection, assisting clinicians in recognizing deterioration signs."}}
{"id": "2410.10672", "pdf": "https://arxiv.org/pdf/2410.10672", "abs": "https://arxiv.org/abs/2410.10672", "authors": ["Yahan Li", "Tingyu Xia", "Yi Chang", "Yuan Wu"], "title": "Large Language Model Evaluation via Matrix Nuclear-Norm", "categories": ["cs.CL"], "comment": "21 pages", "summary": "As large language models (LLMs) continue to evolve, efficient evaluation\nmetrics are vital for assessing their ability to compress information and\nreduce redundancy. While traditional metrics like Matrix Entropy offer valuable\ninsights, they are computationally intensive for large-scale models due to\ntheir \\( O(n^3) \\) time complexity with Singular Value Decomposition (SVD). To\nmitigate this issue, we introduce the Matrix Nuclear-Norm, which not only\nserves as a metric to quantify the data compression proficiency of LLM but also\nprovides a convex approximation of matrix rank to capture both predictive\ndiscriminability and diversity. By employing the \\( L_{1,2}\\text{-norm} \\) to\nfurther approximate the nuclear norm, we can effectively assess the model's\ninformation compression capabilities. This approach reduces the time complexity\nto \\( O(n^2) \\) and eliminates the need for SVD computation. Consequently, the\nMatrix Nuclear-Norm achieves speeds 8 to 24 times faster than Matrix Entropy\nfor the CEREBRAS-GPT model as sizes increase from 111M to 6.7B. This\nperformance gap becomes more pronounced with larger models, as validated in\ntests with other models like Pythia. Additionally, evaluations on benchmarks\nand model responses confirm that our proposed Matrix Nuclear-Norm is a\nreliable, scalable, and efficient tool for assessing LLMs' performance,\nstriking a balance between accuracy and computational efficiency. The code is\navailable at https://github.com/MLGroupJLU/MatrixNuclearNorm.", "AI": {"tldr": "The paper introduces Matrix Nuclear-Norm, a faster and scalable metric for evaluating LLMs' information compression, reducing time complexity from O(n\u00b3) to O(n\u00b2) and avoiding SVD.", "motivation": "Traditional metrics like Matrix Entropy are computationally intensive for large-scale LLMs, necessitating a more efficient alternative.", "method": "Proposes Matrix Nuclear-Norm with L\u2081,\u2082-norm approximation to quantify compression proficiency, reducing complexity and eliminating SVD.", "result": "Achieves 8-24x speedup over Matrix Entropy for models like CEREBRAS-GPT and Pythia, validated on benchmarks.", "conclusion": "Matrix Nuclear-Norm is a reliable, scalable, and efficient tool for LLM evaluation, balancing accuracy and speed."}}
{"id": "2506.03148", "pdf": "https://arxiv.org/pdf/2506.03148", "abs": "https://arxiv.org/abs/2506.03148", "authors": ["Ayush Shrivastava", "Andrew Owens"], "title": "Self-Supervised Spatial Correspondence Across Modalities", "categories": ["cs.CV"], "comment": "CVPR 2025. Project link: https://www.ayshrv.com/cmrw . Code:\n  https://github.com/ayshrv/cmrw", "summary": "We present a method for finding cross-modal space-time correspondences. Given\ntwo images from different visual modalities, such as an RGB image and a depth\nmap, our model identifies which pairs of pixels correspond to the same physical\npoints in the scene. To solve this problem, we extend the contrastive random\nwalk framework to simultaneously learn cycle-consistent feature representations\nfor both cross-modal and intra-modal matching. The resulting model is simple\nand has no explicit photo-consistency assumptions. It can be trained entirely\nusing unlabeled data, without the need for any spatially aligned multimodal\nimage pairs. We evaluate our method on both geometric and semantic\ncorrespondence tasks. For geometric matching, we consider challenging tasks\nsuch as RGB-to-depth and RGB-to-thermal matching (and vice versa); for semantic\nmatching, we evaluate on photo-sketch and cross-style image alignment. Our\nmethod achieves strong performance across all benchmarks.", "AI": {"tldr": "A method for cross-modal space-time correspondences between images of different modalities (e.g., RGB and depth) without needing aligned data.", "motivation": "To identify corresponding pixels across different visual modalities without relying on photo-consistency assumptions or labeled data.", "method": "Extends the contrastive random walk framework to learn cycle-consistent features for cross-modal and intra-modal matching.", "result": "Achieves strong performance on geometric (RGB-to-depth, RGB-to-thermal) and semantic (photo-sketch, cross-style) tasks.", "conclusion": "The model is simple, trainable with unlabeled data, and effective for diverse cross-modal matching tasks."}}
{"id": "2506.02261", "pdf": "https://arxiv.org/pdf/2506.02261", "abs": "https://arxiv.org/abs/2506.02261", "authors": ["Zhongyu Ouyang", "Qianlong Wen", "Chunhui Zhang", "Yanfang Ye", "Soroush Vosoughi"], "title": "Towards Human-like Preference Profiling in Sequential Recommendation", "categories": ["cs.IR", "cs.LG"], "comment": null, "summary": "Sequential recommendation systems aspire to profile users by interpreting\ntheir interaction histories, echoing how humans make decisions by weighing\nexperience, relative preference strength, and situational relevance. Yet,\nexisting large language model (LLM)-based recommenders often fall short of\nmimicking the flexible, context-aware decision strategies humans exhibit,\nneglecting the structured, dynamic, and context-aware mechanisms fundamental to\nhuman behaviors. To bridge this gap, we propose RecPO, a preference\noptimization framework that models structured feedback and contextual delay to\nemulate human-like prioritization in sequential recommendation RecPO exploits\nadaptive reward margins based on inferred preference hierarchies and temporal\nsignals, enabling the model to favor immediately relevant items and to\ndistinguish between varying degrees of preference and aversion. Extensive\nexperiments across five real-world datasets demonstrate that RecPO not only\nyields performance gains over state-of-the-art baselines, but also mirrors key\ncharacteristics of human decision-making: favoring timely satisfaction,\nmaintaining coherent preferences, and exercising discernment under shifting\ncontexts.", "AI": {"tldr": "RecPO is a preference optimization framework for sequential recommendation that mimics human-like decision-making by modeling structured feedback and contextual delay.", "motivation": "Existing LLM-based recommenders lack the flexibility and context-awareness of human decision-making.", "method": "RecPO uses adaptive reward margins based on preference hierarchies and temporal signals to prioritize relevant items.", "result": "Outperforms state-of-the-art baselines and mirrors human decision-making traits like timely satisfaction and coherent preferences.", "conclusion": "RecPO bridges the gap between machine and human decision-making in sequential recommendations."}}
{"id": "2505.10742", "pdf": "https://arxiv.org/pdf/2505.10742", "abs": "https://arxiv.org/abs/2505.10742", "authors": ["Brandon Lepine", "Gawesha Weerantunga", "Juho Kim", "Pamela Mishkin", "Matthew Beane"], "title": "Evaluations at Work: Measuring the Capabilities of GenAI in Use", "categories": ["cs.AI", "cs.HC"], "comment": null, "summary": "Current AI benchmarks miss the messy, multi-turn nature of human-AI\ncollaboration. We present an evaluation framework that decomposes real-world\ntasks into interdependent subtasks, letting us track both LLM performance and\nusers' strategies across a dialogue. Complementing this framework, we develop a\nsuite of metrics, including a composite usage derived from semantic similarity,\nword overlap, and numerical matches; structural coherence; intra-turn\ndiversity; and a novel measure of the \"information frontier\" reflecting the\nalignment between AI outputs and users' working knowledge. We demonstrate our\nmethodology in a financial valuation task that mirrors real-world complexity.\nOur empirical findings reveal that while greater integration of LLM-generated\ncontent generally enhances output quality, its benefits are moderated by\nfactors such as response incoherence, excessive subtask diversity, and the\ndistance of provided information from users' existing knowledge. These results\nsuggest that proactive dialogue strategies designed to inject novelty may\ninadvertently undermine task performance. Our work thus advances a more\nholistic evaluation of human-AI collaboration, offering both a robust\nmethodological framework and actionable insights for developing more effective\nAI-augmented work processes.", "AI": {"tldr": "The paper introduces a framework for evaluating human-AI collaboration by decomposing tasks into subtasks and tracking performance and user strategies. It proposes metrics like semantic similarity, structural coherence, and a novel 'information frontier' measure. Findings show LLM integration improves output quality but is moderated by factors like incoherence and knowledge gaps.", "motivation": "Current AI benchmarks fail to capture the complexity of human-AI collaboration in multi-turn dialogues, necessitating a more holistic evaluation framework.", "method": "Develops a framework decomposing tasks into subtasks and introduces metrics (semantic similarity, structural coherence, intra-turn diversity, 'information frontier') to evaluate LLM performance and user strategies.", "result": "Greater LLM integration improves output quality but is moderated by response incoherence, excessive subtask diversity, and misalignment with user knowledge. Proactive novelty strategies may harm performance.", "conclusion": "The work provides a robust framework and insights for evaluating and improving human-AI collaboration, emphasizing the need for alignment with user knowledge and coherence."}}
{"id": "2410.10995", "pdf": "https://arxiv.org/pdf/2410.10995", "abs": "https://arxiv.org/abs/2410.10995", "authors": ["Emmanouil Zaranis", "Giuseppe Attanasio", "Sweta Agrawal", "Andr\u00e9 F. T. Martins"], "title": "Watching the Watchers: Exposing Gender Disparities in Machine Translation Quality Estimation", "categories": ["cs.CL"], "comment": "ACL 2025", "summary": "Quality estimation (QE)-the automatic assessment of translation quality-has\nrecently become crucial across several stages of the translation pipeline, from\ndata curation to training and decoding. While QE metrics have been optimized to\nalign with human judgments, whether they encode social biases has been largely\noverlooked. Biased QE risks favoring certain demographic groups over others,\ne.g., by exacerbating gaps in visibility and usability. This paper defines and\ninvestigates gender bias of QE metrics and discusses its downstream\nimplications for machine translation (MT). Experiments with state-of-the-art QE\nmetrics across multiple domains, datasets, and languages reveal significant\nbias. When a human entity's gender in the source is undisclosed,\nmasculine-inflected translations score higher than feminine-inflected ones, and\ngender-neutral translations are penalized. Even when contextual cues\ndisambiguate gender, using context-aware QE metrics leads to more errors in\nselecting the correct translation inflection for feminine referents than for\nmasculine ones. Moreover, a biased QE metric affects data filtering and\nquality-aware decoding. Our findings underscore the need for a renewed focus on\ndeveloping and evaluating QE metrics centered on gender.", "AI": {"tldr": "The paper investigates gender bias in Quality Estimation (QE) metrics for machine translation, revealing significant biases favoring masculine-inflected translations and penalizing neutral or feminine ones, with implications for data filtering and decoding.", "motivation": "To address the overlooked issue of social biases, particularly gender bias, in QE metrics, which can unfairly favor certain demographic groups and impact translation quality.", "method": "Experiments with state-of-the-art QE metrics across various domains, datasets, and languages to analyze gender bias.", "result": "Masculine-inflected translations score higher than feminine or neutral ones, even with contextual cues, and biased QE metrics affect downstream tasks like data filtering.", "conclusion": "The findings highlight the urgent need for gender-centered development and evaluation of QE metrics to mitigate bias."}}
{"id": "2505.21777", "pdf": "https://arxiv.org/pdf/2505.21777", "abs": "https://arxiv.org/abs/2505.21777", "authors": ["Bao Pham", "Gabriel Raya", "Matteo Negri", "Mohammed J. Zaki", "Luca Ambrogioni", "Dmitry Krotov"], "title": "Memorization to Generalization: Emergence of Diffusion Models from Associative Memory", "categories": ["cs.LG", "cond-mat.dis-nn", "cs.CV", "q-bio.NC", "stat.ML"], "comment": null, "summary": "Hopfield networks are associative memory (AM) systems, designed for storing\nand retrieving patterns as local minima of an energy landscape. In the\nclassical Hopfield model, an interesting phenomenon occurs when the amount of\ntraining data reaches its critical memory load $- spurious\\,\\,states$, or\nunintended stable points, emerge at the end of the retrieval dynamics, leading\nto incorrect recall. In this work, we examine diffusion models, commonly used\nin generative modeling, from the perspective of AMs. The training phase of\ndiffusion model is conceptualized as memory encoding (training data is stored\nin the memory). The generation phase is viewed as an attempt of memory\nretrieval. In the small data regime the diffusion model exhibits a strong\nmemorization phase, where the network creates distinct basins of attraction\naround each sample in the training set, akin to the Hopfield model below the\ncritical memory load. In the large data regime, a different phase appears where\nan increase in the size of the training set fosters the creation of new\nattractor states that correspond to manifolds of the generated samples.\nSpurious states appear at the boundary of this transition and correspond to\nemergent attractor states, which are absent in the training set, but, at the\nsame time, have distinct basins of attraction around them. Our findings\nprovide: a novel perspective on the memorization-generalization phenomenon in\ndiffusion models via the lens of AMs, theoretical prediction of existence of\nspurious states, empirical validation of this prediction in commonly-used\ndiffusion models.", "AI": {"tldr": "The paper explores diffusion models as associative memory systems, drawing parallels to Hopfield networks, and identifies spurious states in large data regimes.", "motivation": "To understand diffusion models through the lens of associative memory systems and analyze memorization-generalization transitions.", "method": "Conceptualizes diffusion model training as memory encoding and generation as retrieval, comparing it to Hopfield networks.", "result": "Identifies spurious states in large data regimes and validates their existence empirically.", "conclusion": "Provides insights into memorization-generalization in diffusion models and predicts spurious states."}}
{"id": "2506.02284", "pdf": "https://arxiv.org/pdf/2506.02284", "abs": "https://arxiv.org/abs/2506.02284", "authors": ["Yifeng Teng", "Yifan Wang"], "title": "Learning Optimal Posted Prices for a Unit-Demand Buyer", "categories": ["cs.GT", "cs.DS", "cs.LG"], "comment": null, "summary": "We study the problem of learning the optimal item pricing for a unit-demand\nbuyer with independent item values, and the learner has query access to the\nbuyer's value distributions. We consider two common query models in the\nliterature: the sample access model where the learner can obtain a sample of\neach item value, and the pricing query model where the learner can set a price\nfor an item and obtain a binary signal on whether the sampled value of the item\nis greater than our proposed price. In this work, we give nearly tight sample\ncomplexity and pricing query complexity of the unit-demand pricing problem.", "AI": {"tldr": "The paper studies learning optimal item pricing for a unit-demand buyer with independent item values, focusing on two query models: sample access and pricing query. It provides nearly tight complexity bounds for both models.", "motivation": "To understand the sample and pricing query complexities for learning optimal pricing strategies in unit-demand settings with independent item values.", "method": "Analyzes two query models: sample access (obtaining samples of item values) and pricing query (setting prices and receiving binary feedback).", "result": "Presents nearly tight sample complexity and pricing query complexity bounds for the unit-demand pricing problem.", "conclusion": "The work establishes tight complexity bounds for learning optimal pricing in the studied query models, contributing to theoretical understanding of pricing strategies."}}
{"id": "2505.11451", "pdf": "https://arxiv.org/pdf/2505.11451", "abs": "https://arxiv.org/abs/2505.11451", "authors": ["Lee Harris"], "title": "Extracting Explainable Dates From Medical Images By Reverse-Engineering UNIX Timestamps", "categories": ["cs.AI"], "comment": "This research was funded by a UKRI grant. Number: 10048265", "summary": "Dates often contribute towards highly impactful medical decisions, but it is\nrarely clear how to extract this data. AI has only just begun to be used\ntranscribe such documents, and common methods are either to trust that the\noutput produced by a complex AI model, or to parse the text using regular\nexpressions. Recent work has established that regular expressions are an\nexplainable form of logic, but it is difficult to decompose these into the\ncomponent parts that are required to construct precise UNIX timestamps. First,\nwe test publicly-available regular expressions, and we found that these were\nunable to capture a significant number of our dates. Next, we manually created\neasily-decomposable regular expressions, and we found that these were able to\ndetect the majority of real dates, but also a lot of sequences of text that\nlook like dates. Finally, we used regular expression synthesis to automatically\nidentify regular expressions from the reverse-engineered UNIX timestamps that\nwe created. We find that regular expressions created by regular expression\nsynthesis detect far fewer sequences of text that look like dates than those\nthat were manually created, at the cost of a slight increase to the number of\nmissed dates. Overall, our results show that regular expressions can be created\nthrough regular expression synthesis to identify complex dates and date ranges\nin text transcriptions. To our knowledge, our proposed way of learning\ndeterministic logic by reverse-engineering several many-one mappings and\nfeeding these into a regular expression synthesiser is a new approach.", "AI": {"tldr": "The paper explores using regular expression synthesis to improve date extraction from medical documents, balancing accuracy and false positives.", "motivation": "Dates are critical for medical decisions but hard to extract. AI methods lack explainability, and manual regexes are error-prone.", "method": "Tested public regexes, created manual regexes, and used regex synthesis to reverse-engineer UNIX timestamps.", "result": "Synthesized regexes reduced false positives but slightly increased missed dates compared to manual regexes.", "conclusion": "Regex synthesis is a novel, effective method for extracting complex dates and ranges from text."}}
{"id": "2410.11020", "pdf": "https://arxiv.org/pdf/2410.11020", "abs": "https://arxiv.org/abs/2410.11020", "authors": ["Bokai Hu", "Sai Ashish Somayajula", "Xin Pan", "Pengtao Xie"], "title": "Improving the Language Understanding Capabilities of Large Language Models Using Reinforcement Learning", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Instruction-fine-tuned large language models (LLMs) under 14B parameters\ncontinue to underperform on natural language understanding (NLU) tasks, often\ntrailing smaller models like BERT-base on benchmarks such as GLUE and\nSuperGLUE. Motivated by the success of reinforcement learning in reasoning\ntasks (e.g., DeepSeek), we explore Proximal Policy Optimization (PPO) as a\nframework to improve the NLU capabilities of LLMs. We frame NLU as a\nreinforcement learning environment, treating token generation as a sequence of\nactions and optimizing for reward signals based on alignment with ground-truth\nlabels. PPO consistently outperforms supervised fine-tuning, yielding an\naverage improvement of 6.3 points on GLUE, and surpasses zero-shot and few-shot\nprompting by 38.7 and 26.1 points, respectively. Notably, PPO-tuned models\noutperform GPT-4o by over 4\\% on average across sentiment and natural language\ninference tasks, including gains of 7.3\\% on the Mental Health dataset and\n10.9\\% on SIGA-nli. This work highlights a promising direction for adapting\nLLMs to new tasks by reframing them as reinforcement learning problems,\nenabling learning through simple end-task rewards rather than extensive data\ncuration.", "AI": {"tldr": "PPO improves NLU performance in small LLMs, outperforming supervised fine-tuning and GPT-4o on benchmarks like GLUE and SuperGLUE.", "motivation": "Small LLMs underperform on NLU tasks compared to smaller models like BERT-base, prompting exploration of reinforcement learning (PPO) for improvement.", "method": "NLU is framed as a reinforcement learning problem, using PPO to optimize token generation based on alignment with ground-truth labels.", "result": "PPO yields a 6.3-point average improvement on GLUE, surpassing zero-shot and few-shot prompting by 38.7 and 26.1 points, respectively, and outperforms GPT-4o by over 4%.", "conclusion": "Reframing NLU as a reinforcement learning problem with PPO is a promising approach for adapting LLMs to new tasks using simple rewards."}}
{"id": "2506.02214", "pdf": "https://arxiv.org/pdf/2506.02214", "abs": "https://arxiv.org/abs/2506.02214", "authors": ["Alexey Burdakov", "Max Jaihyun Ahn"], "title": "Is PMBOK Guide the Right Fit for AI? Re-evaluating Project Management in the Face of Artificial Intelligence Projects", "categories": ["cs.SE", "cs.CV", "D.2.9; I.4"], "comment": "9 pages, 1 figure", "summary": "This paper critically evaluates the applicability of the Project Management\nBody of Knowledge (PMBOK) Guide framework to Artificial Intelligence (AI)\nsoftware projects, highlighting key limitations and proposing tailored\nadaptations. Unlike traditional projects, AI initiatives rely heavily on\ncomplex data, iterative experimentation, and specialized expertise while\nnavigating significant ethical considerations. Our analysis identifies gaps in\nthe PMBOK Guide, including its limited focus on data management, insufficient\nsupport for iterative development, and lack of guidance on ethical and\nmultidisciplinary challenges. To address these deficiencies, we recommend\nintegrating data lifecycle management, adopting iterative and AI project\nmanagement frameworks, and embedding ethical considerations within project\nplanning and execution. Additionally, we explore alternative approaches that\nbetter align with AI's dynamic and exploratory nature. We aim to enhance\nproject management practices for AI software projects by bridging these gaps.", "AI": {"tldr": "The paper evaluates PMBOK's limitations for AI projects, proposing adaptations like data lifecycle management, iterative frameworks, and ethical integration.", "motivation": "To address PMBOK's gaps in handling AI projects' unique needs, such as data complexity, iterative processes, and ethical challenges.", "method": "Critical evaluation of PMBOK's applicability to AI projects, identifying gaps and recommending tailored adaptations.", "result": "Identified gaps include poor data management, lack of iterative support, and ethical oversight; proposed solutions integrate these aspects.", "conclusion": "The study aims to improve AI project management by adapting PMBOK to better suit AI's dynamic and ethical demands."}}
{"id": "2506.02336", "pdf": "https://arxiv.org/pdf/2506.02336", "abs": "https://arxiv.org/abs/2506.02336", "authors": ["Jingfeng Wu", "Pierre Marion", "Peter Bartlett"], "title": "Large Stepsizes Accelerate Gradient Descent for Regularized Logistic Regression", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "We study gradient descent (GD) with a constant stepsize for\n$\\ell_2$-regularized logistic regression with linearly separable data.\nClassical theory suggests small stepsizes to ensure monotonic reduction of the\noptimization objective, achieving exponential convergence in\n$\\widetilde{\\mathcal{O}}(\\kappa)$ steps with $\\kappa$ being the condition\nnumber. Surprisingly, we show that this can be accelerated to\n$\\widetilde{\\mathcal{O}}(\\sqrt{\\kappa})$ by simply using a large stepsize --\nfor which the objective evolves nonmonotonically. The acceleration brought by\nlarge stepsizes extends to minimizing the population risk for separable\ndistributions, improving on the best-known upper bounds on the number of steps\nto reach a near-optimum. Finally, we characterize the largest stepsize for the\nlocal convergence of GD, which also determines the global convergence in\nspecial scenarios. Our results extend the analysis of Wu et al. (2024) from\nconvex settings with minimizers at infinity to strongly convex cases with\nfinite minimizers.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2505.13887", "pdf": "https://arxiv.org/pdf/2505.13887", "abs": "https://arxiv.org/abs/2505.13887", "authors": ["Junyang Wang", "Haiyang Xu", "Xi Zhang", "Ming Yan", "Ji Zhang", "Fei Huang", "Jitao Sang"], "title": "Mobile-Agent-V: A Video-Guided Approach for Effortless and Efficient Operational Knowledge Injection in Mobile Automation", "categories": ["cs.AI", "cs.CL"], "comment": "I submitted the replacement version as a new article by mistake.\n  Future updates will appear at arXiv:2502.17110", "summary": "The exponential rise in mobile device usage necessitates streamlined\nautomation for effective task management, yet many AI frameworks fall short due\nto inadequate operational expertise. While manually written knowledge can\nbridge this gap, it is often burdensome and inefficient. We introduce\nMobile-Agent-V, an innovative framework that utilizes video as a guiding tool\nto effortlessly and efficiently inject operational knowledge into mobile\nautomation processes. By deriving knowledge directly from video content,\nMobile-Agent-V eliminates manual intervention, significantly reducing the\neffort and time required for knowledge acquisition. To rigorously evaluate this\napproach, we propose Mobile-Knowledge, a benchmark tailored to assess the\nimpact of external knowledge on mobile agent performance. Our experimental\nfindings demonstrate that Mobile-Agent-V enhances performance by 36% compared\nto existing methods, underscoring its effortless and efficient advantages in\nmobile automation.", "AI": {"tldr": "Mobile-Agent-V uses video to automate mobile tasks, reducing manual effort and improving performance by 36%.", "motivation": "The need for efficient mobile task automation due to rising device usage, with current AI frameworks lacking operational expertise.", "method": "Mobile-Agent-V leverages video content to inject operational knowledge into automation, eliminating manual input.", "result": "36% performance improvement over existing methods, validated by the Mobile-Knowledge benchmark.", "conclusion": "Mobile-Agent-V offers an effortless and efficient solution for mobile automation, outperforming traditional approaches."}}
{"id": "2410.12974", "pdf": "https://arxiv.org/pdf/2410.12974", "abs": "https://arxiv.org/abs/2410.12974", "authors": ["Anna Sokol", "Elizabeth Daly", "Michael Hind", "David Piorkowski", "Xiangliang Zhang", "Nuno Moniz", "Nitesh Chawla"], "title": "BenchmarkCards: Standardized Documentation for Large Language Model Benchmarks", "categories": ["cs.CL"], "comment": null, "summary": "Large language models (LLMs) are powerful tools capable of handling diverse\ntasks. Comparing and selecting appropriate LLMs for specific tasks requires\nsystematic evaluation methods, as models exhibit varying capabilities across\ndifferent domains. However, finding suitable benchmarks is difficult given the\nmany available options. This complexity not only increases the risk of\nbenchmark misuse and misinterpretation but also demands substantial effort from\nLLM users, seeking the most suitable benchmarks for their specific needs. To\naddress these issues, we introduce \\texttt{BenchmarkCards}, an intuitive and\nvalidated documentation framework that standardizes critical benchmark\nattributes such as objectives, methodologies, data sources, and limitations.\nThrough user studies involving benchmark creators and users, we show that\n\\texttt{BenchmarkCards} can simplify benchmark selection and enhance\ntransparency, facilitating informed decision-making in evaluating LLMs. Data &\nCode: https://github.com/SokolAnn/BenchmarkCards", "AI": {"tldr": "The paper introduces BenchmarkCards, a framework to standardize and simplify the selection of benchmarks for evaluating large language models (LLMs).", "motivation": "The challenge of selecting appropriate benchmarks for LLMs due to their diversity and the risk of misuse or misinterpretation.", "method": "Development of BenchmarkCards, a documentation framework standardizing benchmark attributes like objectives, methodologies, and limitations, validated through user studies.", "result": "BenchmarkCards simplifies benchmark selection and enhances transparency, aiding informed decision-making for LLM evaluation.", "conclusion": "BenchmarkCards effectively addresses the complexity of benchmark selection for LLMs, improving usability and transparency."}}
{"id": "2506.02489", "pdf": "https://arxiv.org/pdf/2506.02489", "abs": "https://arxiv.org/abs/2506.02489", "authors": ["Tao Zhong", "Jonah Buchanan", "Christine Allen-Blanchette"], "title": "Grasp2Grasp: Vision-Based Dexterous Grasp Translation via Schr\u00f6dinger Bridges", "categories": ["cs.RO", "cs.CV", "cs.LG"], "comment": "19 pages, 4 figures", "summary": "We propose a new approach to vision-based dexterous grasp translation, which\naims to transfer grasp intent across robotic hands with differing morphologies.\nGiven a visual observation of a source hand grasping an object, our goal is to\nsynthesize a functionally equivalent grasp for a target hand without requiring\npaired demonstrations or hand-specific simulations. We frame this problem as a\nstochastic transport between grasp distributions using the Schr\\\"odinger Bridge\nformalism. Our method learns to map between source and target latent grasp\nspaces via score and flow matching, conditioned on visual observations. To\nguide this translation, we introduce physics-informed cost functions that\nencode alignment in base pose, contact maps, wrench space, and manipulability.\nExperiments across diverse hand-object pairs demonstrate our approach generates\nstable, physically grounded grasps with strong generalization. This work\nenables semantic grasp transfer for heterogeneous manipulators and bridges\nvision-based grasping with probabilistic generative modeling.", "AI": {"tldr": "A novel method for transferring grasp intent across robotic hands with different morphologies using visual observations and stochastic transport, without paired demonstrations.", "motivation": "To enable semantic grasp transfer for heterogeneous manipulators by translating grasp intent from a source to a target hand, leveraging visual observations and probabilistic modeling.", "method": "Frames the problem as stochastic transport between grasp distributions using the Schr\u00f6dinger Bridge formalism, mapping latent grasp spaces via score and flow matching, guided by physics-informed cost functions.", "result": "Generates stable, physically grounded grasps with strong generalization across diverse hand-object pairs.", "conclusion": "Bridges vision-based grasping with probabilistic generative modeling, enabling functional grasp transfer without hand-specific simulations."}}
{"id": "2506.02373", "pdf": "https://arxiv.org/pdf/2506.02373", "abs": "https://arxiv.org/abs/2506.02373", "authors": ["Kordel K. France", "Ovidiu Daescu"], "title": "Olfactory Inertial Odometry: Methodology for Effective Robot Navigation by Scent", "categories": ["cs.RO", "cs.LG", "cs.SY", "eess.SY", "physics.ins-det"], "comment": null, "summary": "Olfactory navigation is one of the most primitive mechanisms of exploration\nused by organisms. Navigation by machine olfaction (artificial smell) is a very\ndifficult task to both simulate and solve. With this work, we define olfactory\ninertial odometry (OIO), a framework for using inertial kinematics, and\nfast-sampling olfaction sensors to enable navigation by scent analogous to\nvisual inertial odometry (VIO). We establish how principles from SLAM and VIO\ncan be extrapolated to olfaction to enable real-world robotic tasks. We\ndemonstrate OIO with three different odour localization algorithms on a real\n5-DoF robot arm over an odour-tracking scenario that resembles real\napplications in agriculture and food quality control. Our results indicate\nsuccess in establishing a baseline framework for OIO from which other research\nin olfactory navigation can build, and we note performance enhancements that\ncan be made to address more complex tasks in the future.", "AI": {"tldr": "The paper introduces Olfactory Inertial Odometry (OIO), a framework for robotic scent navigation using inertial kinematics and fast-sampling olfaction sensors, inspired by visual inertial odometry (VIO).", "motivation": "Olfactory navigation is primitive yet challenging for machines. The goal is to adapt SLAM and VIO principles to olfaction for real-world robotic tasks.", "method": "The OIO framework combines inertial kinematics and fast-sampling olfaction sensors. Three odour localization algorithms are tested on a 5-DoF robot arm in an odour-tracking scenario.", "result": "The framework successfully establishes a baseline for OIO, demonstrating feasibility in applications like agriculture and food quality control.", "conclusion": "OIO provides a foundational framework for olfactory navigation, with potential for future enhancements to tackle more complex tasks."}}
{"id": "2505.15146", "pdf": "https://arxiv.org/pdf/2505.15146", "abs": "https://arxiv.org/abs/2505.15146", "authors": ["Lanxiang Hu", "Mingjia Huo", "Yuxuan Zhang", "Haoyang Yu", "Eric P. Xing", "Ion Stoica", "Tajana Rosing", "Haojian Jin", "Hao Zhang"], "title": "lmgame-Bench: How Good are LLMs at Playing Games?", "categories": ["cs.AI"], "comment": null, "summary": "Playing video games requires perception, memory, and planning, exactly the\nfaculties modern large language model (LLM) agents are expected to master. We\nstudy the major challenges in using popular video games to evaluate modern LLMs\nand find that directly dropping LLMs into games cannot make an effective\nevaluation, for three reasons -- brittle vision perception, prompt sensitivity,\nand potential data contamination. We introduce lmgame-Bench to turn games into\nreliable evaluations. lmgame-Bench features a suite of platformer, puzzle, and\nnarrative games delivered through a unified Gym-style API and paired with\nlightweight perception and memory scaffolds, and is designed to stabilize\nprompt variance and remove contamination. Across 13 leading models, we show\nlmgame-Bench is challenging while still separating models well. Correlation\nanalysis shows that every game probes a unique blend of capabilities often\ntested in isolation elsewhere. More interestingly, performing reinforcement\nlearning on a single game from lmgame-Bench transfers both to unseen games and\nto external planning tasks. Our evaluation code is available at\nhttps://github.com/lmgame-org/GamingAgent/lmgame-bench.", "AI": {"tldr": "The paper introduces lmgame-Bench, a tool to evaluate LLMs using video games, addressing challenges like brittle perception and data contamination. It shows the benchmark's effectiveness across 13 models and highlights transfer learning benefits.", "motivation": "Video games test perception, memory, and planning, key skills for LLMs, but direct evaluation is flawed due to perception issues, prompt sensitivity, and data contamination.", "method": "Developed lmgame-Bench, a unified API for platformer, puzzle, and narrative games, with scaffolds to stabilize prompts and remove contamination.", "result": "lmgame-Bench is challenging yet effective in differentiating models, with games probing unique capabilities. Reinforcement learning on one game transfers to others and external tasks.", "conclusion": "lmgame-Bench provides a reliable, versatile evaluation framework for LLMs, demonstrating transferability and unique capability assessment."}}
{"id": "2410.14817", "pdf": "https://arxiv.org/pdf/2410.14817", "abs": "https://arxiv.org/abs/2410.14817", "authors": ["Eric Elmoznino", "Thomas Jiralerspong", "Yoshua Bengio", "Guillaume Lajoie"], "title": "A Complexity-Based Theory of Compositionality", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "Compositionality is believed to be fundamental to intelligence. In humans, it\nunderlies the structure of thought, language, and higher-level reasoning. In\nAI, compositional representations can enable a powerful form of\nout-of-distribution generalization, in which a model systematically adapts to\nnovel combinations of known concepts. However, while we have strong intuitions\nabout what compositionality is, we lack satisfying formal definitions for it\nthat are measurable and mathematical. Here, we propose such a definition, which\nwe call representational compositionality, that accounts for and extends our\nintuitions about compositionality. The definition is conceptually simple,\nquantitative, grounded in algorithmic information theory, and applicable to any\nrepresentation. Intuitively, representational compositionality states that a\ncompositional representation satisfies three properties. First, it must be\nexpressive. Second, it must be possible to re-describe the representation as a\nfunction of discrete symbolic sequences with re-combinable parts, analogous to\nsentences in natural language. Third, the function that relates these symbolic\nsequences to the representation, analogous to semantics in natural language,\nmust be simple. Through experiments on both synthetic and real world data, we\nvalidate our definition of compositionality and show how it unifies disparate\nintuitions from across the literature in both AI and cognitive science. We also\nshow that representational compositionality, while theoretically intractable,\ncan be readily estimated using standard deep learning tools. We hope that our\ndefinition can inspire the design of novel, theoretically-driven models that\nbetter capture the mechanisms of compositional thought. We make our code\navailable at https://github.com/EricElmoznino/complexity_compositionality.", "AI": {"tldr": "The paper proposes a formal definition of compositionality called 'representational compositionality,' grounded in algorithmic information theory, and validates it through experiments.", "motivation": "To address the lack of measurable and mathematical definitions for compositionality, which is fundamental to intelligence in humans and AI.", "method": "Introduces a definition with three properties: expressiveness, re-description as symbolic sequences, and simplicity of the semantic function. Validates it using synthetic and real-world data.", "result": "The definition unifies intuitions from AI and cognitive science and is practically estimable with deep learning tools.", "conclusion": "The work aims to inspire new models for compositional thought and provides accessible code for further research."}}
{"id": "2506.02618", "pdf": "https://arxiv.org/pdf/2506.02618", "abs": "https://arxiv.org/abs/2506.02618", "authors": ["Jialiang Zhang", "Haoran Geng", "Yang You", "Congyue Deng", "Pieter Abbeel", "Jitendra Malik", "Leonidas Guibas"], "title": "Rodrigues Network for Learning Robot Actions", "categories": ["cs.RO", "cs.CV"], "comment": null, "summary": "Understanding and predicting articulated actions is important in robot\nlearning. However, common architectures such as MLPs and Transformers lack\ninductive biases that reflect the underlying kinematic structure of articulated\nsystems. To this end, we propose the Neural Rodrigues Operator, a learnable\ngeneralization of the classical forward kinematics operation, designed to\ninject kinematics-aware inductive bias into neural computation. Building on\nthis operator, we design the Rodrigues Network (RodriNet), a novel neural\narchitecture specialized for processing actions. We evaluate the expressivity\nof our network on two synthetic tasks on kinematic and motion prediction,\nshowing significant improvements compared to standard backbones. We further\ndemonstrate its effectiveness in two realistic applications: (i) imitation\nlearning on robotic benchmarks with the Diffusion Policy, and (ii) single-image\n3D hand reconstruction. Our results suggest that integrating structured\nkinematic priors into the network architecture improves action learning in\nvarious domains.", "AI": {"tldr": "The paper introduces the Neural Rodrigues Operator and Rodrigues Network (RodriNet) to improve action learning by incorporating kinematic structure into neural architectures, showing better performance in tasks like kinematic prediction and robotic imitation.", "motivation": "Common neural architectures lack inductive biases for articulated systems, limiting their effectiveness in action learning.", "method": "Proposes the Neural Rodrigues Operator and RodriNet, a specialized architecture for processing actions with kinematic priors.", "result": "Demonstrates significant improvements in kinematic and motion prediction tasks, as well as in robotic imitation learning and 3D hand reconstruction.", "conclusion": "Integrating kinematic priors into neural architectures enhances action learning across diverse applications."}}
{"id": "2506.02394", "pdf": "https://arxiv.org/pdf/2506.02394", "abs": "https://arxiv.org/abs/2506.02394", "authors": ["Yuan Bian", "Xingche Guo", "Yuanjia Wang"], "title": "Joint Modeling for Learning Decision-Making Dynamics in Behavioral Experiments", "categories": ["stat.ME", "cs.LG"], "comment": null, "summary": "Major depressive disorder (MDD), a leading cause of disability and mortality,\nis associated with reward-processing abnormalities and concentration issues.\nMotivated by the probabilistic reward task from the Establishing Moderators and\nBiosignatures of Antidepressant Response in Clinical Care (EMBARC) study, we\npropose a novel framework that integrates the reinforcement learning (RL) model\nand drift-diffusion model (DDM) to jointly analyze reward-based decision-making\nwith response times. To account for emerging evidence suggesting that\ndecision-making may alternate between multiple interleaved strategies, we model\nlatent state switching using a hidden Markov model (HMM). In the ''engaged''\nstate, decisions follow an RL-DDM, simultaneously capturing reward processing,\ndecision dynamics, and temporal structure. In contrast, in the ''lapsed''\nstate, decision-making is modeled using a simplified DDM, where specific\nparameters are fixed to approximate random guessing with equal probability. The\nproposed method is implemented using a computationally efficient generalized\nexpectation-maximization algorithm with forward-backward procedures. Through\nextensive numerical studies, we demonstrate that our proposed method\noutperforms competing approaches under various reward-generating distributions,\nboth with and without strategy switching. When applied to the EMBARC study, our\nframework reveals that MDD patients exhibit lower overall engagement than\nhealthy controls and experience longer decision times when they do engage.\nAdditionally, we show that neuroimaging measures of brain activities are\nassociated with decision-making characteristics in the ''engaged'' state but\nnot in the ''lapsed'' state, providing evidence of brain-behavioral association\nspecific to the ''engaged'' state.", "AI": {"tldr": "A novel RL-DDM-HMM framework analyzes reward-based decision-making in MDD, revealing lower engagement and longer decision times in patients, with brain-behavior links specific to the 'engaged' state.", "motivation": "To address reward-processing abnormalities and concentration issues in MDD by integrating RL and DDM models with latent state switching.", "method": "Combines RL-DDM for 'engaged' state and simplified DDM for 'lapsed' state, using HMM for strategy switching, implemented via efficient EM algorithm.", "result": "MDD patients show lower engagement, longer decision times, and brain-behavior associations only in the 'engaged' state.", "conclusion": "The framework effectively captures MDD-related decision-making differences and highlights state-specific brain-behavior links."}}
{"id": "2505.18492", "pdf": "https://arxiv.org/pdf/2505.18492", "abs": "https://arxiv.org/abs/2505.18492", "authors": ["Jialiang Sun", "Yuzhi Tang", "Ao Li", "Chris J. Maddison", "Kuldeep S. Meel"], "title": "Enumerate-Conjecture-Prove: Formally Solving Answer-Construction Problems in Math Competitions", "categories": ["cs.AI"], "comment": null, "summary": "Mathematical reasoning lies at the heart of artificial intelligence,\nunderpinning applications in education, program verification, and\nresearch-level mathematical discovery. Mathematical competitions, in\nparticular, present two challenging problem types: theorem proving, which\nrequires rigorous proofs of stated conclusions, and answer construction, which\ninvolves hypothesizing and formally verifying mathematical objects. Large\nLanguage Models (LLMs) effectively generate creative candidate answers but\nstruggle with formal verification, while symbolic provers ensure rigor but\ncannot efficiently handle creative conjecture generation. We introduce the\nEnumerate-Conjecture-Prove (ECP) framework, a modular neuro-symbolic method\nintegrating LLM-based enumeration and pattern-driven conjecturing with formal\ntheorem proving. We present ConstructiveBench, a dataset of 3,431\nanswer-construction problems in various math competitions with verified Lean\nformalizations. On the ConstructiveBench dataset, ECP improves the accuracy of\nanswer construction from a Chain-of-Thought (CoT) baseline of 14.54% to 45.06%\nwith the gpt-4.1-mini model. Moreover, combined with ECP's constructed answers,\nthe state-of-the-art DeepSeek-Prover-V2-7B model generates correct proofs for\n858 of the 3,431 constructive problems in Lean, achieving 25.01% accuracy\ncompared to 9.86% for symbolic-only baselines. Our code and dataset are\npublicly available at https://github.com/JackSun200312/ECP.", "AI": {"tldr": "The paper introduces the Enumerate-Conjecture-Prove (ECP) framework, a neuro-symbolic method combining LLMs and formal theorem proving to improve mathematical reasoning, achieving significant accuracy improvements on the ConstructiveBench dataset.", "motivation": "Mathematical reasoning is crucial for AI, but existing methods (LLMs and symbolic provers) have limitations\u2014LLMs lack formal verification, and provers struggle with creativity. ECP aims to bridge this gap.", "method": "The ECP framework integrates LLM-based enumeration and pattern-driven conjecturing with formal theorem proving, tested on the ConstructiveBench dataset of 3,431 math problems.", "result": "ECP improves answer-construction accuracy from 14.54% (CoT baseline) to 45.06% (gpt-4.1-mini) and boosts proof-generation accuracy to 25.01% (DeepSeek-Prover-V2-7B) compared to 9.86% for symbolic-only methods.", "conclusion": "ECP successfully combines neuro-symbolic approaches to enhance mathematical reasoning, demonstrating significant improvements in both answer construction and proof generation."}}
{"id": "2410.21271", "pdf": "https://arxiv.org/pdf/2410.21271", "abs": "https://arxiv.org/abs/2410.21271", "authors": ["Shih-Yang Liu", "Maksim Khadkevich", "Nai Chit Fung", "Charbel Sakr", "Chao-Han Huck Yang", "Chien-Yi Wang", "Saurav Muralidharan", "Hongxu Yin", "Kwang-Ting Cheng", "Jan Kautz", "Yu-Chiang Frank Wang", "Pavlo Molchanov", "Min-Hung Chen"], "title": "EoRA: Fine-tuning-free Compensation for Compressed LLM with Eigenspace Low-Rank Approximation", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "While post-training compression techniques effectively reduce the memory\nfootprint, latency, and power consumption of Large Language Models (LLMs), they\noften result in noticeable accuracy degradation and remain limited by hardware\nand kernel constraints that restrict supported compression formats ultimately\nreducing flexibility across a wide range of deployment scenarios. In this work,\nwe propose EoRA, a novel fine-tuning-free method that augments compressed LLMs\nwith low-rank matrices, allowing users to rapidly enhance task-specific\nperformance and freely balance the trade-off between accuracy and computational\noverhead beyond the constraints of compression formats. EoRA consistently\noutperforms prior training-free low rank methods in recovering the accuracy of\ncompressed LLMs, achieving notable accuracy improvements (e.g.,\n$\\mathbf{10.84\\%}$ on ARC-Challenge, $\\mathbf{6.74\\%}$ on MathQA, and\n$\\mathbf{6.74\\%}$ on GSM8K) for LLaMA3-8B compressed to 3-bit. We also\nintroduce an optimized CUDA kernel, accelerating inference by up to 1.4x and\nreducing memory overhead through quantizing EoRA. Overall, EoRA offers a prompt\nsolution for improving the accuracy of compressed models under varying user\nrequirements, enabling more efficient and flexible deployment of LLMs. Code is\navailable at https://github.com/NVlabs/EoRA.", "AI": {"tldr": "EoRA enhances compressed LLMs with low-rank matrices, improving accuracy without fine-tuning, and offers flexible deployment with optimized CUDA kernels.", "motivation": "Post-training compression of LLMs reduces efficiency but degrades accuracy and limits flexibility due to hardware constraints.", "method": "EoRA augments compressed LLMs with low-rank matrices, enabling task-specific performance enhancement without fine-tuning.", "result": "EoRA improves accuracy (e.g., 10.84% on ARC-Challenge) and speeds up inference by 1.4x with optimized CUDA kernels.", "conclusion": "EoRA provides a flexible, efficient solution for deploying compressed LLMs with improved accuracy."}}
{"id": "2506.02620", "pdf": "https://arxiv.org/pdf/2506.02620", "abs": "https://arxiv.org/abs/2506.02620", "authors": ["Dongyu Yan", "Leyi Wu", "Jiantao Lin", "Luozhou Wang", "Tianshuo Xu", "Zhifei Chen", "Zhen Yang", "Lie Xu", "Shunsi Zhang", "Yingcong Chen"], "title": "FlexPainter: Flexible and Multi-View Consistent Texture Generation", "categories": ["cs.GR", "cs.CV"], "comment": "11 pages, 10 figures in main paper, 10 pages, 12 figures in\n  supplementary", "summary": "Texture map production is an important part of 3D modeling and determines the\nrendering quality. Recently, diffusion-based methods have opened a new way for\ntexture generation. However, restricted control flexibility and limited prompt\nmodalities may prevent creators from producing desired results. Furthermore,\ninconsistencies between generated multi-view images often lead to poor texture\ngeneration quality. To address these issues, we introduce \\textbf{FlexPainter},\na novel texture generation pipeline that enables flexible multi-modal\nconditional guidance and achieves highly consistent texture generation. A\nshared conditional embedding space is constructed to perform flexible\naggregation between different input modalities. Utilizing such embedding space,\nwe present an image-based CFG method to decompose structural and style\ninformation, achieving reference image-based stylization. Leveraging the 3D\nknowledge within the image diffusion prior, we first generate multi-view images\nsimultaneously using a grid representation to enhance global understanding.\nMeanwhile, we propose a view synchronization and adaptive weighting module\nduring diffusion sampling to further ensure local consistency. Finally, a\n3D-aware texture completion model combined with a texture enhancement model is\nused to generate seamless, high-resolution texture maps. Comprehensive\nexperiments demonstrate that our framework significantly outperforms\nstate-of-the-art methods in both flexibility and generation quality.", "AI": {"tldr": "FlexPainter is a texture generation pipeline addressing control flexibility and multi-view consistency issues in diffusion-based methods, achieving high-quality results.", "motivation": "Current diffusion-based texture generation lacks control flexibility and suffers from inconsistencies in multi-view images, limiting quality.", "method": "FlexPainter uses a shared conditional embedding space for multi-modal guidance, image-based CFG for stylization, and a 3D-aware approach for consistent multi-view generation and texture completion.", "result": "The framework outperforms state-of-the-art methods in flexibility and texture quality.", "conclusion": "FlexPainter effectively solves key challenges in texture generation, offering superior performance and consistency."}}
{"id": "2506.02413", "pdf": "https://arxiv.org/pdf/2506.02413", "abs": "https://arxiv.org/abs/2506.02413", "authors": ["Tian Lan", "Jie Guo", "Chen Zhang"], "title": "Tensor State Space-based Dynamic Multilayer Network Modeling", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "Understanding the complex interactions within dynamic multilayer networks is\ncritical for advancements in various scientific domains. Existing models often\nfail to capture such networks' temporal and cross-layer dynamics. This paper\nintroduces a novel Tensor State Space Model for Dynamic Multilayer Networks\n(TSSDMN), utilizing a latent space model framework. TSSDMN employs a symmetric\nTucker decomposition to represent latent node features, their interaction\npatterns, and layer transitions. Then by fixing the latent features and\nallowing the interaction patterns to evolve over time, TSSDMN uniquely captures\nboth the temporal dynamics within layers and across different layers. The model\nidentifiability conditions are discussed. By treating latent features as\nvariables whose posterior distributions are approximated using a mean-field\nvariational inference approach, a variational Expectation Maximization\nalgorithm is developed for efficient model inference. Numerical simulations and\ncase studies demonstrate the efficacy of TSSDMN for understanding dynamic\nmultilayer networks.", "AI": {"tldr": "A novel Tensor State Space Model for Dynamic Multilayer Networks (TSSDMN) is introduced, capturing temporal and cross-layer dynamics using symmetric Tucker decomposition and variational inference.", "motivation": "Existing models fail to capture temporal and cross-layer dynamics in multilayer networks, limiting advancements in scientific domains.", "method": "TSSDMN uses symmetric Tucker decomposition for latent features and interaction patterns, with variational EM for inference.", "result": "Numerical simulations and case studies show TSSDMN effectively models dynamic multilayer networks.", "conclusion": "TSSDMN provides a robust framework for analyzing dynamic multilayer networks, addressing gaps in existing models."}}
{"id": "2505.19381", "pdf": "https://arxiv.org/pdf/2505.19381", "abs": "https://arxiv.org/abs/2505.19381", "authors": ["Anqing Jiang", "Yu Gao", "Zhigang Sun", "Yiru Wang", "Jijun Wang", "Jinghao Chai", "Qian Cao", "Yuweng Heng", "Hao Jiang", "Yunda Dong", "Zongzheng Zhang", "Xianda Guo", "Hao Sun", "Hao Zhao"], "title": "DiffVLA: Vision-Language Guided Diffusion Planning for Autonomous Driving", "categories": ["cs.AI", "cs.CV", "cs.RO"], "comment": "4pages", "summary": "Research interest in end-to-end autonomous driving has surged owing to its\nfully differentiable design integrating modular tasks, i.e. perception,\nprediction and planing, which enables optimization in pursuit of the ultimate\ngoal. Despite the great potential of the end-to-end paradigm, existing methods\nsuffer from several aspects including expensive BEV (bird's eye view)\ncomputation, action diversity, and sub-optimal decision in complex real-world\nscenarios. To address these challenges, we propose a novel hybrid sparse-dense\ndiffusion policy, empowered by a Vision-Language Model (VLM), called Diff-VLA.\nWe explore the sparse diffusion representation for efficient multi-modal\ndriving behavior. Moreover, we rethink the effectiveness of VLM driving\ndecision and improve the trajectory generation guidance through deep\ninteraction across agent, map instances and VLM output. Our method shows\nsuperior performance in Autonomous Grand Challenge 2025 which contains\nchallenging real and reactive synthetic scenarios. Our methods achieves 45.0\nPDMS.", "AI": {"tldr": "The paper introduces Diff-VLA, a hybrid sparse-dense diffusion policy for end-to-end autonomous driving, leveraging Vision-Language Models (VLM) to address challenges like BEV computation costs and sub-optimal decisions.", "motivation": "To overcome limitations in existing end-to-end autonomous driving methods, such as high computational costs and poor decision-making in complex scenarios.", "method": "Proposes Diff-VLA, combining sparse diffusion for multi-modal behavior and VLM for improved trajectory guidance through agent-map-VLM interaction.", "result": "Achieves superior performance in the Autonomous Grand Challenge 2025, with a score of 45.0 PDMS.", "conclusion": "Diff-VLA effectively addresses key challenges in autonomous driving, demonstrating strong performance in real and synthetic scenarios."}}
{"id": "2411.00418", "pdf": "https://arxiv.org/pdf/2411.00418", "abs": "https://arxiv.org/abs/2411.00418", "authors": ["Chenghua Huang", "Zhizhen Fan", "Lu Wang", "Fangkai Yang", "Pu Zhao", "Zeqi Lin", "Qingwei Lin", "Dongmei Zhang", "Saravan Rajmohan", "Qi Zhang"], "title": "Self-Evolved Reward Learning for LLMs", "categories": ["cs.CL", "cs.AI"], "comment": "23 pages,6 figures,Accepted to ICLR 2025", "summary": "Reinforcement Learning from Human Feedback (RLHF) is a crucial technique for\naligning language models with human preferences, playing a pivotal role in the\nsuccess of conversational models like GPT-4, ChatGPT, and Llama 2. A core\nchallenge in employing RLHF lies in training a reliable reward model (RM),\nwhich relies on high-quality labels typically provided by human experts or\nadvanced AI system. These methods can be costly and may introduce biases that\naffect the language model's responses. As language models improve, human input\nmay become less effective in further enhancing their performance. In this\npaper, we propose Self-Evolved Reward Learning (SER), a novel approach where\nthe RM generates additional training data to iteratively improve itself. We\nconducted extensive experiments on multiple datasets such as HH-RLHF and\nUltraFeedback, using models like Mistral and Llama 3, and compare SER against\nvarious baselines. Our results demonstrate that even with limited\nhuman-annotated data, learning from self-feedback can robustly enhance RM\nperformance, thereby boosting the capabilities of large language models (LLMs).\nResources of this paper can be found at https://aka.ms/ser", "AI": {"tldr": "The paper introduces Self-Evolved Reward Learning (SER), a method to improve reward models (RMs) in RLHF by generating additional training data iteratively, reducing reliance on costly human labels.", "motivation": "High-quality human or AI labels for RMs are expensive and may introduce biases, limiting the effectiveness of RLHF as language models improve.", "method": "Proposes SER, where the RM self-generates training data to iteratively enhance its performance, tested on datasets like HH-RLHF and UltraFeedback using models such as Mistral and Llama 3.", "result": "SER improves RM performance robustly even with limited human-annotated data, enhancing large language model capabilities.", "conclusion": "SER offers a cost-effective and scalable alternative to traditional human-labeled RMs, advancing RLHF for language models."}}
{"id": "2506.02895", "pdf": "https://arxiv.org/pdf/2506.02895", "abs": "https://arxiv.org/abs/2506.02895", "authors": ["Ahmad AlMughrabi", "Umair Haroon", "Ricardo Marques", "Petia Radeva"], "title": "VolTex: Food Volume Estimation using Text-Guided Segmentation and Neural Surface Reconstruction", "categories": ["cs.GR", "cs.CV"], "comment": null, "summary": "Accurate food volume estimation is crucial for dietary monitoring, medical\nnutrition management, and food intake analysis. Existing 3D Food Volume\nestimation methods accurately compute the food volume but lack for food\nportions selection. We present VolTex, a framework that improves \\change{the\nfood object selection} in food volume estimation. Allowing users to specify a\ntarget food item via text input to be segmented, our method enables the precise\nselection of specific food objects in real-world scenes. The segmented object\nis then reconstructed using the Neural Surface Reconstruction method to\ngenerate high-fidelity 3D meshes for volume computation. Extensive evaluations\non the MetaFood3D dataset demonstrate the effectiveness of our approach in\nisolating and reconstructing food items for accurate volume estimation. The\nsource code is accessible at https://github.com/GCVCG/VolTex.", "AI": {"tldr": "VolTex improves food object selection in 3D food volume estimation by allowing text-based segmentation and neural surface reconstruction for accurate volume computation.", "motivation": "Accurate food volume estimation is vital for dietary monitoring and nutrition management, but existing methods lack precise food portion selection.", "method": "VolTex uses text input for food item segmentation and Neural Surface Reconstruction to create 3D meshes for volume estimation.", "result": "Evaluations on MetaFood3D show VolTex effectively isolates and reconstructs food items for precise volume estimation.", "conclusion": "VolTex enhances food volume estimation by enabling targeted food selection and high-fidelity reconstruction."}}
{"id": "2506.02422", "pdf": "https://arxiv.org/pdf/2506.02422", "abs": "https://arxiv.org/abs/2506.02422", "authors": ["Xiyu Zhao", "Qimei Cui", "Ziqiang Du", "Weicai Li", "Xi Yu", "Wei Ni", "Ji Zhang", "Xiaofeng Tao", "Ping Zhang"], "title": "Enhancing Convergence, Privacy and Fairness for Wireless Personalized Federated Learning: Quantization-Assisted Min-Max Fair Scheduling", "categories": ["cs.DC", "cs.LG"], "comment": null, "summary": "Personalized federated learning (PFL) offers a solution to balancing\npersonalization and generalization by conducting federated learning (FL) to\nguide personalized learning (PL). Little attention has been given to wireless\nPFL (WPFL), where privacy concerns arise. Performance fairness of PL models is\nanother challenge resulting from communication bottlenecks in WPFL. This paper\nexploits quantization errors to enhance the privacy of WPFL and proposes a\nnovel quantization-assisted Gaussian differential privacy (DP) mechanism. We\nanalyze the convergence upper bounds of individual PL models by considering the\nimpact of the mechanism (i.e., quantization errors and Gaussian DP noises) and\nimperfect communication channels on the FL of WPFL. By minimizing the maximum\nof the bounds, we design an optimal transmission scheduling strategy that\nyields min-max fairness for WPFL with OFDMA interfaces. This is achieved by\nrevealing the nested structure of this problem to decouple it into subproblems\nsolved sequentially for the client selection, channel allocation, and power\ncontrol, and for the learning rates and PL-FL weighting coefficients.\nExperiments validate our analysis and demonstrate that our approach\nsubstantially outperforms alternative scheduling strategies by 87.08%, 16.21%,\nand 38.37% in accuracy, the maximum test loss of participating clients, and\nfairness (Jain's index), respectively.", "AI": {"tldr": "The paper proposes a novel quantization-assisted Gaussian DP mechanism for wireless personalized federated learning (WPFL) to enhance privacy and fairness, optimizing transmission scheduling for improved performance.", "motivation": "Addressing privacy concerns and performance fairness in WPFL due to communication bottlenecks and quantization errors.", "method": "Introduces a quantization-assisted Gaussian DP mechanism, analyzes convergence bounds, and designs an optimal transmission scheduling strategy for min-max fairness.", "result": "Outperforms alternatives by 87.08% in accuracy, 16.21% in max test loss, and 38.37% in fairness (Jain's index).", "conclusion": "The proposed approach effectively balances privacy, fairness, and performance in WPFL."}}
{"id": "2505.19501", "pdf": "https://arxiv.org/pdf/2505.19501", "abs": "https://arxiv.org/abs/2505.19501", "authors": ["Ming Yin", "Yuanhao Qu", "Ling Yang", "Le Cong", "Mengdi Wang"], "title": "Toward Scientific Reasoning in LLMs: Training from Expert Discussions via Reinforcement Learning", "categories": ["cs.AI"], "comment": null, "summary": "We investigate how to teach large language models (LLMs) to perform\nscientific reasoning by leveraging expert discussions as a learning signal.\nFocusing on the genomics domain, we develop an automated pipeline to extract\ntrainable data and introduce Genome-Bench, a new benchmark constructed from\nover a decade of scientific forum discussions on genome engineering. Our\npipeline transforms raw interactions into a reinforcement learning-friendly\nmultiple-choice questions format, supported by 3000+ high-quality\nquestion-answer pairs spanning foundational biology, experimental\ntroubleshooting, tool usage, and beyond. We fine-tune an LLM using RL with a\nrule-based reward signal derived from the synthetic MCQ dataset to enhance\ndomain-specific reasoning. Our results show that reinforcement learning from\nscientific discussions improves model performance by over 15% compared to the\nbase model on Genome-Bench, narrowing the gap between open-source LLMs and\nexpert-level reasoning. To our knowledge, this is the first end-to-end pipeline\nfor teaching LLMs to reason from scientific discussions, with promising\npotential for generalization across scientific domains beyond biology.", "AI": {"tldr": "Teaching LLMs scientific reasoning using expert discussions, focusing on genomics, with a new benchmark (Genome-Bench) and RL-based fine-tuning, improving performance by 15%.", "motivation": "To enhance LLMs' scientific reasoning by leveraging expert discussions as a learning signal, particularly in genomics.", "method": "Developed an automated pipeline to extract trainable data from scientific forums, created Genome-Bench (3000+ QA pairs), and fine-tuned an LLM using RL with rule-based rewards.", "result": "RL from scientific discussions improved model performance by over 15% on Genome-Bench, bridging the gap between open-source LLMs and expert reasoning.", "conclusion": "First end-to-end pipeline for teaching LLMs scientific reasoning from discussions, with potential for broader scientific applications."}}
{"id": "2411.02430", "pdf": "https://arxiv.org/pdf/2411.02430", "abs": "https://arxiv.org/abs/2411.02430", "authors": ["Lin Wang", "Xiaocui Yang", "Shi Feng", "Daling Wang", "Yifei Zhang", "Zhitao Zhang"], "title": "Generative Emotion Cause Explanation in Multimodal Conversations", "categories": ["cs.CL", "cs.AI", "cs.CV", "cs.LG"], "comment": null, "summary": "Multimodal conversation, a crucial form of human communication, carries rich\nemotional content, making the exploration of the causes of emotions within it a\nresearch endeavor of significant importance. However, existing research on the\ncauses of emotions typically employs an utterance selection method within a\nsingle textual modality to locate causal utterances. This approach remains\nlimited to coarse-grained assessments, lacks nuanced explanations of emotional\ncausation, and demonstrates inadequate capability in identifying multimodal\nemotional triggers. Therefore, we introduce a task-\\textbf{Multimodal Emotion\nCause Explanation in Conversation (MECEC)}. This task aims to generate a\nsummary based on the multimodal context of conversations, clearly and\nintuitively describing the reasons that trigger a given emotion. To adapt to\nthis task, we develop a new dataset (ECEM) based on the MELD dataset. ECEM\ncombines video clips with detailed explanations of character emotions, helping\nto explore the causal factors behind emotional expression in multimodal\nconversations. A novel approach, FAME-Net, is further proposed, that harnesses\nthe power of Large Language Models (LLMs) to analyze visual data and accurately\ninterpret the emotions conveyed through facial expressions in videos. By\nexploiting the contagion effect of facial emotions, FAME-Net effectively\ncaptures the emotional causes of individuals engaged in conversations. Our\nexperimental results on the newly constructed dataset show that FAME-Net\noutperforms several excellent baselines. Code and dataset are available at\nhttps://github.com/3222345200/FAME-Net.", "AI": {"tldr": "The paper introduces MECEC, a task for explaining emotional causes in multimodal conversations, and proposes FAME-Net, a method leveraging LLMs to analyze visual data for emotion cause identification.", "motivation": "Existing emotion cause research is limited to single-modality and lacks nuanced explanations, prompting the need for multimodal analysis.", "method": "FAME-Net uses LLMs to interpret facial expressions in videos, capturing emotional causes by exploiting facial emotion contagion.", "result": "FAME-Net outperforms baselines on the new ECEM dataset, demonstrating effective emotion cause explanation.", "conclusion": "The study advances multimodal emotion cause analysis, offering a dataset and method for nuanced emotional trigger identification."}}
{"id": "2506.03004", "pdf": "https://arxiv.org/pdf/2506.03004", "abs": "https://arxiv.org/abs/2506.03004", "authors": ["Junyu Liu", "R. Kenny Jones", "Daniel Ritchie"], "title": "PartComposer: Learning and Composing Part-Level Concepts from Single-Image Examples", "categories": ["cs.GR", "cs.CV"], "comment": null, "summary": "We present PartComposer: a framework for part-level concept learning from\nsingle-image examples that enables text-to-image diffusion models to compose\nnovel objects from meaningful components. Existing methods either struggle with\neffectively learning fine-grained concepts or require a large dataset as input.\nWe propose a dynamic data synthesis pipeline generating diverse part\ncompositions to address one-shot data scarcity. Most importantly, we propose to\nmaximize the mutual information between denoised latents and structured concept\ncodes via a concept predictor, enabling direct regulation on concept\ndisentanglement and re-composition supervision. Our method achieves strong\ndisentanglement and controllable composition, outperforming subject and\npart-level baselines when mixing concepts from the same, or different, object\ncategories.", "AI": {"tldr": "PartComposer is a framework for part-level concept learning from single-image examples, enhancing text-to-image diffusion models to compose novel objects from meaningful components.", "motivation": "Existing methods fail to learn fine-grained concepts effectively or require large datasets. PartComposer addresses this by enabling one-shot learning and controllable composition.", "method": "The framework uses a dynamic data synthesis pipeline for diverse part compositions and maximizes mutual information between denoised latents and concept codes via a concept predictor.", "result": "PartComposer achieves strong disentanglement and controllable composition, outperforming baselines in mixing concepts from same or different object categories.", "conclusion": "The method successfully enables part-level concept learning and composition from minimal data, advancing text-to-image generation."}}
{"id": "2506.02458", "pdf": "https://arxiv.org/pdf/2506.02458", "abs": "https://arxiv.org/abs/2506.02458", "authors": ["Nguyen Chi Long", "Trinh Van Chien", "Ta Hai Tung", "Van Son Nguyen", "Trong-Minh Hoang", "Nguyen Ngoc Hai Dang"], "title": "A Novel Deep Reinforcement Learning Method for Computation Offloading in Multi-User Mobile Edge Computing with Decentralization", "categories": ["cs.IT", "cs.LG", "math.IT"], "comment": "6 pages, 5 figures, and 1 table. Published by IEEE at ATC2024", "summary": "Mobile edge computing (MEC) allows appliances to offload workloads to\nneighboring MEC servers that have the potential for computation-intensive tasks\nwith limited computational capabilities. This paper studied how deep\nreinforcement learning (DRL) algorithms are used in an MEC system to find\nfeasible decentralized dynamic computation offloading strategies, which leads\nto the construction of an extensible MEC system that operates effectively with\nfinite feedback. Even though the Deep Deterministic Policy Gradient (DDPG)\nalgorithm, subject to their knowledge of the MEC system, can be used to\nallocate powers of both computation offloading and local execution, to learn a\ncomputation offloading policy for each user independently, we realized that\nthis solution still has some inherent weaknesses. Hence, we introduced a new\napproach for this problem based on the Twin Delayed DDPG algorithm, which\nenables us to overcome this proneness and investigate cases where mobile users\nare portable. Numerical results showed that individual users can autonomously\nlearn adequate policies through the proposed approach. Besides, the performance\nof the suggested solution exceeded the conventional DDPG-based power control\nstrategy.", "AI": {"tldr": "The paper explores using DRL, specifically Twin Delayed DDPG, to improve decentralized dynamic computation offloading in MEC systems, outperforming traditional DDPG methods.", "motivation": "To address the limitations of existing DDPG-based power control strategies in MEC systems, especially for mobile users.", "method": "Proposes a Twin Delayed DDPG algorithm to independently learn computation offloading policies for users, enhancing adaptability and performance.", "result": "Numerical results show the proposed method enables users to autonomously learn effective policies and outperforms conventional DDPG strategies.", "conclusion": "The Twin Delayed DDPG approach is more effective for decentralized dynamic computation offloading in MEC systems, particularly for mobile users."}}
{"id": "2505.23596", "pdf": "https://arxiv.org/pdf/2505.23596", "abs": "https://arxiv.org/abs/2505.23596", "authors": ["Linqiang Guo", "Wei Liu", "Yi Wen Heng", "Tse-Hsun", "Chen", "Yang Wang"], "title": "MAPLE: A Mobile Agent with Persistent Finite State Machines for Structured Task Reasoning", "categories": ["cs.AI"], "comment": "change to a better title", "summary": "Mobile GUI agents aim to autonomously complete user-instructed tasks across\nmobile apps. Recent advances in Multimodal Large Language Models (MLLMs) enable\nthese agents to interpret UI screens, identify actionable elements, and perform\ninteractions such as tapping or typing. However, existing agents remain\nreactive: they reason only over the current screen and lack a structured model\nof app navigation flow, limiting their ability to understand context, detect\nunexpected outcomes, and recover from errors. We present MAPLE, a state-aware\nmulti-agent framework that abstracts app interactions as a Finite State Machine\n(FSM). We computationally model each UI screen as a discrete state and user\nactions as transitions, allowing the FSM to provide a structured representation\nof the app execution. MAPLE consists of specialized agents responsible for four\nphases of task execution: planning, execution, verification, error recovery,\nand knowledge retention. These agents collaborate to dynamically construct FSMs\nin real time based on perception data extracted from the UI screen, allowing\nthe GUI agents to track navigation progress and flow, validate action outcomes\nthrough pre- and post-conditions of the states, and recover from errors by\nrolling back to previously stable states. Our evaluation results on two\nchallenging cross-app benchmarks, Mobile-Eval-E and SPA-Bench, show that MAPLE\noutperforms the state-of-the-art baseline, improving task success rate by up to\n12%, recovery success by 13.8%, and action accuracy by 6.5%. Our results\nhighlight the importance of structured state modeling in guiding mobile GUI\nagents during task execution. Moreover, our FSM representation can be\nintegrated into future GUI agent architectures as a lightweight, model-agnostic\nmemory layer to support structured planning, execution verification, and error\nrecovery.", "AI": {"tldr": "MAPLE introduces a state-aware multi-agent framework using Finite State Machines (FSM) to improve mobile GUI agents' task execution, error recovery, and action accuracy.", "motivation": "Existing mobile GUI agents are reactive, lacking structured navigation flow, which limits context understanding and error recovery.", "method": "MAPLE models UI screens as states and actions as transitions in an FSM, with specialized agents for planning, execution, verification, error recovery, and knowledge retention.", "result": "MAPLE outperforms baselines, improving task success by 12%, recovery by 13.8%, and action accuracy by 6.5%.", "conclusion": "Structured state modeling is crucial for GUI agents, and FSM can be a lightweight, model-agnostic memory layer for future architectures."}}
{"id": "2411.02528", "pdf": "https://arxiv.org/pdf/2411.02528", "abs": "https://arxiv.org/abs/2411.02528", "authors": ["Lindia Tjuatja", "Graham Neubig", "Tal Linzen", "Sophie Hao"], "title": "What Goes Into a LM Acceptability Judgment? Rethinking the Impact of Frequency and Length", "categories": ["cs.CL"], "comment": "Accepted to NAACL 2025 (Main Conference)", "summary": "When comparing the linguistic capabilities of language models (LMs) with\nhumans using LM probabilities, factors such as the length of the sequence and\nthe unigram frequency of lexical items have a significant effect on LM\nprobabilities in ways that humans are largely robust to. Prior works in\ncomparing LM and human acceptability judgments treat these effects uniformly\nacross models, making a strong assumption that models require the same degree\nof adjustment to control for length and unigram frequency effects. We propose\nMORCELA, a new linking theory between LM scores and acceptability judgments\nwhere the optimal level of adjustment for these effects is estimated from data\nvia learned parameters for length and unigram frequency. We first show that\nMORCELA outperforms a commonly used linking theory for acceptability - SLOR\n(Pauls and Klein, 2012; Lau et al. 2017) - across two families of transformer\nLMs (Pythia and OPT). Furthermore, we demonstrate that the assumed degrees of\nadjustment in SLOR for length and unigram frequency overcorrect for these\nconfounds, and that larger models require a lower relative degree of adjustment\nfor unigram frequency, though a significant amount of adjustment is still\nnecessary for all models. Finally, our subsequent analysis shows that larger\nLMs' lower susceptibility to frequency effects can be explained by an ability\nto better predict rarer words in context.", "AI": {"tldr": "MORCELA, a new linking theory, adjusts for length and unigram frequency effects in LM probabilities more effectively than SLOR, showing that larger LMs require less adjustment for frequency due to better prediction of rare words.", "motivation": "Prior methods assume uniform adjustments for length and unigram frequency effects across LMs, which may not hold true. MORCELA addresses this by learning optimal adjustments from data.", "method": "Proposes MORCELA, a data-driven linking theory with learned parameters for length and unigram frequency adjustments, tested on Pythia and OPT transformer LMs.", "result": "MORCELA outperforms SLOR, showing overcorrection in SLOR's adjustments. Larger LMs need less frequency adjustment due to better rare-word prediction.", "conclusion": "MORCELA provides a better framework for comparing LM and human judgments, revealing insights into LM behavior, especially for larger models."}}
{"id": "2506.03118", "pdf": "https://arxiv.org/pdf/2506.03118", "abs": "https://arxiv.org/abs/2506.03118", "authors": ["Zhiyuan Yu", "Zhe Li", "Hujun Bao", "Can Yang", "Xiaowei Zhou"], "title": "HumanRAM: Feed-forward Human Reconstruction and Animation Model using Transformers", "categories": ["cs.GR", "cs.CV"], "comment": "Accepted by SIGGRAPH 2025 (Conference Track). Project page:\n  https://zju3dv.github.io/humanram/", "summary": "3D human reconstruction and animation are long-standing topics in computer\ngraphics and vision. However, existing methods typically rely on sophisticated\ndense-view capture and/or time-consuming per-subject optimization procedures.\nTo address these limitations, we propose HumanRAM, a novel feed-forward\napproach for generalizable human reconstruction and animation from monocular or\nsparse human images. Our approach integrates human reconstruction and animation\ninto a unified framework by introducing explicit pose conditions, parameterized\nby a shared SMPL-X neural texture, into transformer-based large reconstruction\nmodels (LRM). Given monocular or sparse input images with associated camera\nparameters and SMPL-X poses, our model employs scalable transformers and a\nDPT-based decoder to synthesize realistic human renderings under novel\nviewpoints and novel poses. By leveraging the explicit pose conditions, our\nmodel simultaneously enables high-quality human reconstruction and\nhigh-fidelity pose-controlled animation. Experiments show that HumanRAM\nsignificantly surpasses previous methods in terms of reconstruction accuracy,\nanimation fidelity, and generalization performance on real-world datasets.\nVideo results are available at https://zju3dv.github.io/humanram/.", "AI": {"tldr": "HumanRAM is a feed-forward method for 3D human reconstruction and animation from monocular or sparse images, outperforming prior work in accuracy and fidelity.", "motivation": "Existing methods require dense-view capture or per-subject optimization, which are impractical. HumanRAM aims to simplify and generalize the process.", "method": "Integrates reconstruction and animation using explicit pose conditions (SMPL-X neural texture) in transformer-based models (LRM) with a DPT-based decoder.", "result": "Achieves superior reconstruction accuracy, animation fidelity, and generalization on real-world datasets.", "conclusion": "HumanRAM provides a unified, scalable solution for high-quality human reconstruction and animation from limited inputs."}}
{"id": "2506.02651", "pdf": "https://arxiv.org/pdf/2506.02651", "abs": "https://arxiv.org/abs/2506.02651", "authors": ["Luca Arnaboldi", "Bruno Loureiro", "Ludovic Stephan", "Florent Krzakala", "Lenka Zdeborova"], "title": "Asymptotics of SGD in Sequence-Single Index Models and Single-Layer Attention Networks", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "We study the dynamics of stochastic gradient descent (SGD) for a class of\nsequence models termed Sequence Single-Index (SSI) models, where the target\ndepends on a single direction in input space applied to a sequence of tokens.\nThis setting generalizes classical single-index models to the sequential\ndomain, encompassing simplified one-layer attention architectures. We derive a\nclosed-form expression for the population loss in terms of a pair of sufficient\nstatistics capturing semantic and positional alignment, and characterize the\ninduced high-dimensional SGD dynamics for these coordinates. Our analysis\nreveals two distinct training phases: escape from uninformative initialization\nand alignment with the target subspace, and demonstrates how the sequence\nlength and positional encoding influence convergence speed and learning\ntrajectories. These results provide a rigorous and interpretable foundation for\nunderstanding how sequential structure in data can be beneficial for learning\nwith attention-based models.", "AI": {"tldr": "The paper analyzes SGD dynamics for SSI models, revealing two training phases and the impact of sequence length and positional encoding on learning.", "motivation": "To understand how sequential structure benefits learning in attention-based models by generalizing single-index models to sequences.", "method": "Derives a closed-form expression for population loss and characterizes SGD dynamics using sufficient statistics for semantic and positional alignment.", "result": "Identifies two training phases: escape from uninformative initialization and alignment with the target subspace, influenced by sequence length and positional encoding.", "conclusion": "Provides a rigorous foundation for understanding sequential structure's role in learning with attention-based models."}}
{"id": "2506.01297", "pdf": "https://arxiv.org/pdf/2506.01297", "abs": "https://arxiv.org/abs/2506.01297", "authors": ["Ya Wen", "Jixuan Cai", "Qiyao Ma", "Linyan Li", "Xinhua Chen", "Chris Webster", "Yulun Zhou"], "title": "MobCLIP: Learning General-purpose Geospatial Representation at Scale", "categories": ["cs.AI"], "comment": null, "summary": "Representation learning of geospatial locations remains a core challenge in\nachieving general geospatial intelligence. Current embedding methods often lack\nversatility, limiting their utility across diverse tasks in both human and\nnatural domains. We present MobCLIP, the first nationwide general-purpose\nlocation encoder, integrating an unprecedented diversity of data modalities\nthrough effective and scalable multimodal fusion. Adopting a novel CLIP-based\narchitecture, our framework aligns 100M+ POIs, nationwide remote sensing\nimagery, and structured demographic statistics with a billion-edge mobility\ngraph. By tokenizing spatial locations into grid cells inspired by Vision\nTransformers, we establish a unified representation space bridging mobility\npatterns and multimodal features. To rigorously evaluate the general-purpose\neffectiveness of MobCLIP, we construct a benchmark dataset composed of 11\ndownstream prediction tasks across social, economic, and natural domains.\nExperiments show that MobCLIP, with four input modalities and a compact\n128-dimensional representation space, achieves significantly superior\ngeneral-purpose predictive performances than state-of-the-art models by an\naverage of 35%. Thanks to the effective integration of human-centric\nmodalities, the performance gain is particularly profound in human-centric\ntasks, such as energy consumption (+260%), offline retail consumption amount\n(+98%), and crime cases (+95%) predictions. Echoing LLM scaling laws, we\nfurther demonstrate the scaling behavior in geospatial representation learning.\nWe open-source code and pretrained models at: github.com.", "AI": {"tldr": "MobCLIP is a general-purpose location encoder integrating diverse data modalities for superior geospatial representation, outperforming state-of-the-art models by 35% on average.", "motivation": "Current geospatial embedding methods lack versatility, limiting their utility across diverse tasks.", "method": "MobCLIP uses a CLIP-based architecture to align POIs, remote sensing imagery, demographic statistics, and a mobility graph, tokenizing locations into grid cells.", "result": "MobCLIP achieves a 35% average performance improvement, with significant gains in human-centric tasks (e.g., +260% in energy consumption prediction).", "conclusion": "MobCLIP demonstrates scalable geospatial representation learning and is open-sourced for broader use."}}
{"id": "2411.04975", "pdf": "https://arxiv.org/pdf/2411.04975", "abs": "https://arxiv.org/abs/2411.04975", "authors": ["Gabriele Oliaro", "Zhihao Jia", "Daniel Campos", "Aurick Qiao"], "title": "SuffixDecoding: Extreme Speculative Decoding for Emerging AI Applications", "categories": ["cs.CL", "cs.AI", "cs.DC", "cs.LG"], "comment": null, "summary": "Speculative decoding is widely adopted to reduce latency in large language\nmodel (LLM) inference by leveraging smaller draft models capable of handling\ndiverse user tasks. However, emerging AI applications, such as LLM-based\nagents, present unique workload characteristics: instead of diverse independent\nrequests, agentic frameworks typically submit repetitive inference requests,\nsuch as multi-agent pipelines performing similar subtasks or self-refinement\nloops iteratively enhancing outputs. These workloads result in long and highly\npredictable sequences, which current speculative decoding methods do not\neffectively exploit. To address this gap, we introduce \\emph{SuffixDecoding}, a\nnovel method that utilizes efficient suffix trees to cache long token sequences\nfrom prompts and previous outputs. By adaptively speculating more tokens when\nacceptance likelihood is high and fewer when it is low, SuffixDecoding\neffectively exploits opportunities for longer speculations while conserving\ncomputation when those opportunities are limited. Evaluations on agentic\nbenchmarks, including SWE-Bench and Text-to-SQL, demonstrate that\nSuffixDecoding achieves speedups of up to 5.3$\\times$, outperforming\nstate-of-the-art methods -- 2.8$\\times$ faster than model-based approaches like\nEAGLE-2/3 and 1.9$\\times$ faster than model-free approaches such as Token\nRecycling. SuffixDecoding is open-sourced at\nhttps://github.com/snowflakedb/ArcticInference.", "AI": {"tldr": "SuffixDecoding improves LLM inference latency for repetitive tasks by caching sequences and adapting speculation length.", "motivation": "Current speculative decoding methods don't exploit repetitive, predictable sequences in agentic workloads.", "method": "Uses suffix trees to cache sequences and adaptively adjusts speculation length based on acceptance likelihood.", "result": "Achieves up to 5.3\u00d7 speedup, outperforming state-of-the-art methods.", "conclusion": "SuffixDecoding is effective for agentic workloads and is open-sourced."}}
{"id": "2506.03134", "pdf": "https://arxiv.org/pdf/2506.03134", "abs": "https://arxiv.org/abs/2506.03134", "authors": ["Weiqing Xiao", "Hao Huang", "Chonghao Zhong", "Yujie Lin", "Nan Wang", "Xiaoxue Chen", "Zhaoxi Chen", "Saining Zhang", "Shuocheng Yang", "Pierre Merriaux", "Lei Lei", "Hao Zhao"], "title": "Simulate Any Radar: Attribute-Controllable Radar Simulation via Waveform Parameter Embedding", "categories": ["eess.SP", "cs.CV"], "comment": "Code: https://github.com/zhuxing0/SA-Radar Project page:\n  https://zhuxing0.github.io/projects/SA-Radar", "summary": "We present SA-Radar (Simulate Any Radar), a radar simulation approach that\nenables controllable and efficient generation of radar cubes conditioned on\ncustomizable radar attributes. Unlike prior generative or physics-based\nsimulators, SA-Radar integrates both paradigms through a waveform-parameterized\nattribute embedding. We design ICFAR-Net, a 3D U-Net conditioned on radar\nattributes encoded via waveform parameters, which captures signal variations\ninduced by different radar configurations. This formulation bypasses the need\nfor detailed radar hardware specifications and allows efficient simulation of\nrange-azimuth-Doppler (RAD) tensors across diverse sensor settings. We further\nconstruct a mixed real-simulated dataset with attribute annotations to robustly\ntrain the network. Extensive evaluations on multiple downstream tasks-including\n2D/3D object detection and radar semantic segmentation-demonstrate that\nSA-Radar's simulated data is both realistic and effective, consistently\nimproving model performance when used standalone or in combination with real\ndata. Our framework also supports simulation in novel sensor viewpoints and\nedited scenes, showcasing its potential as a general-purpose radar data engine\nfor autonomous driving applications. Code and additional materials are\navailable at https://zhuxing0.github.io/projects/SA-Radar.", "AI": {"tldr": "SA-Radar is a radar simulation method combining generative and physics-based approaches for customizable radar data generation, improving performance in tasks like object detection and segmentation.", "motivation": "To enable controllable and efficient radar data simulation without needing detailed hardware specs, addressing limitations of prior methods.", "method": "Integrates generative and physics-based paradigms using a waveform-parameterized attribute embedding and ICFAR-Net, a 3D U-Net conditioned on radar attributes.", "result": "SA-Radar produces realistic and effective simulated data, enhancing model performance in tasks like 2D/3D detection and segmentation.", "conclusion": "SA-Radar is a versatile radar data engine for autonomous driving, supporting novel viewpoints and scene edits."}}
{"id": "2506.02657", "pdf": "https://arxiv.org/pdf/2506.02657", "abs": "https://arxiv.org/abs/2506.02657", "authors": ["Tam Ninh Thi-Thanh", "Trinh Van Chien", "Hung Tran", "Nguyen Hoai Son", "Van Nhan Vo"], "title": "Maximizing the Promptness of Metaverse Systems using Edge Computing by Deep Reinforcement Learning", "categories": ["cs.IT", "cs.LG", "math.IT"], "comment": "6 pages, 3 figures, and 2 tables. Published by IEEE at ATC2024", "summary": "Metaverse and Digital Twin (DT) have attracted much academic and industrial\nattraction to approach the future digital world. This paper introduces the\nadvantages of deep reinforcement learning (DRL) in assisting Metaverse\nsystem-based Digital Twin. In this system, we assume that it includes several\nMetaverse User devices collecting data from the real world to transfer it into\nthe virtual world, a Metaverse Virtual Access Point (MVAP) undertaking the\nprocessing of data, and an edge computing server that receives the offloading\ndata from the MVAP. The proposed model works under a dynamic environment with\nvarious parameters changing over time. The experiment results show that our\nproposed DRL algorithm is suitable for offloading tasks to ensure the\npromptness of DT in a dynamic environment.", "AI": {"tldr": "The paper explores using deep reinforcement learning (DRL) to enhance Digital Twin (DT) systems in the Metaverse, demonstrating its effectiveness in dynamic environments for task offloading.", "motivation": "To leverage DRL for improving the efficiency and responsiveness of Metaverse-based Digital Twin systems in dynamic settings.", "method": "Proposes a system with Metaverse User devices, a Metaverse Virtual Access Point (MVAP), and an edge computing server, using DRL for dynamic task offloading.", "result": "The DRL algorithm effectively manages task offloading, ensuring prompt DT operations in changing conditions.", "conclusion": "DRL is a viable solution for optimizing Metaverse DT systems in dynamic environments."}}
{"id": "2301.00555", "pdf": "https://arxiv.org/pdf/2301.00555", "abs": "https://arxiv.org/abs/2301.00555", "authors": ["Jisu Shin", "Seunghyun Shin", "Hae-Gon Jeon"], "title": "Scene Structure Guidance Network: Unfolding Graph Partitioning into Pixel-Wise Feature Learning", "categories": ["cs.CV", "cs.AI"], "comment": "35 pages, 14 figures, journal extension version of SSGNet\n  (https://ojs.aaai.org/index.php/AAAI/article/view/25322)", "summary": "Understanding the informative structures of scenes is essential for low-level\nvision tasks. Unfortunately, it is difficult to obtain a concrete visual\ndefinition of the informative structures because influences of visual features\nare task-specific. In this paper, we propose a single general neural network\narchitecture for extracting task-specific structure guidance for scenes. To do\nthis, we first analyze traditional spectral clustering methods, which computes\na set of eigenvectors to model a segmented graph forming small compact\nstructures on image domains. We then unfold the traditional graph-partitioning\nproblem into a learnable network, named \\textit{Scene Structure Guidance\nNetwork (SSGNet)}, to represent the task-specific informative structures. The\nSSGNet yields a set of coefficients of eigenvectors that produces explicit\nfeature representations of image structures. In addition, our SSGNet is\nlight-weight ($\\sim$ 56K parameters), and can be used as a plug-and-play module\nfor off-the-shelf architectures. We optimize the SSGNet without any supervision\nby proposing two novel training losses that enforce task-specific scene\nstructure generation during training. Our main contribution is to show that\nsuch a simple network can achieve state-of-the-art results for several\nlow-level vision applications. We also demonstrate that our network generalizes\nwell on unseen datasets, compared to existing methods which use structural\nembedding frameworks. We further propose a lighter version of SSGNet ($\\sim$\n29K parameters) for depth computation, SSGNet-D, and successfully execute it on\nedge computing devices like Jetson AGX Orin, improving the performance of\nbaseline network, even in the wild, with little computational delay.", "AI": {"tldr": "A lightweight neural network (SSGNet) extracts task-specific scene structures for low-level vision tasks, achieving state-of-the-art results without supervision.", "motivation": "Defining informative scene structures is challenging due to task-specific visual feature influences. A general solution is needed.", "method": "SSGNet unfolds traditional spectral clustering into a learnable network, producing explicit feature representations. It uses unsupervised training with novel losses.", "result": "SSGNet achieves state-of-the-art performance, generalizes well, and includes a lighter version (SSGNet-D) for edge devices.", "conclusion": "SSGNet is a simple, effective, and adaptable solution for task-specific scene structure extraction in low-level vision."}}
{"id": "2411.07965", "pdf": "https://arxiv.org/pdf/2411.07965", "abs": "https://arxiv.org/abs/2411.07965", "authors": ["Chuyi Kong", "Ziyang Luo", "Hongzhan Lin", "Zhiyuan Fan", "Yaxin Fan", "Yuxi Sun", "Jing Ma"], "title": "SHARP: Unlocking Interactive Hallucination via Stance Transfer in Role-Playing LLMs", "categories": ["cs.CL"], "comment": "28 pages, unfortunately accepted to findings with Meta 4, acknowledge\n  and apologize to the reviewers and area chair who support our work in the\n  discussion period", "summary": "The advanced role-playing capabilities of Large Language Models (LLMs) have\nenabled rich interactive scenarios, yet existing research in social\ninteractions neglects hallucination while struggling with poor generalizability\nand implicit character fidelity judgments. To bridge this gap, motivated by\nhuman behaviour, we introduce a generalizable and explicit paradigm for\nuncovering interactive patterns of LLMs across diverse worldviews.\nSpecifically, we first define interactive hallucination through stance\ntransfer, then construct SHARP, a benchmark built by extracting relations from\ncommonsense knowledge graphs and utilizing LLMs' inherent hallucination\nproperties to simulate multi-role interactions. Extensive experiments confirm\nour paradigm's effectiveness and stability, examine the factors that influence\nthese metrics, and challenge conventional hallucination mitigation solutions.\nMore broadly, our work reveals a fundamental limitation in popular\npost-training methods for role-playing LLMs: the tendency to obscure knowledge\nbeneath style, resulting in monotonous yet human-like behaviors - interactive\nhallucination.", "AI": {"tldr": "The paper introduces SHARP, a benchmark to study interactive hallucination in LLMs, revealing limitations in post-training methods for role-playing models.", "motivation": "Existing research overlooks hallucination in LLM social interactions and lacks generalizability. The study aims to address this by analyzing interactive patterns across diverse worldviews.", "method": "Defines interactive hallucination via stance transfer and constructs SHARP, a benchmark using commonsense knowledge graphs and LLMs' hallucination properties for multi-role interactions.", "result": "Experiments confirm the paradigm's effectiveness, stability, and highlight factors influencing metrics, challenging conventional hallucination mitigation.", "conclusion": "The work exposes a key limitation in role-playing LLMs: post-training methods obscure knowledge under style, leading to interactive hallucination."}}
{"id": "2306.15507", "pdf": "https://arxiv.org/pdf/2306.15507", "abs": "https://arxiv.org/abs/2306.15507", "authors": ["Yunfan Lu", "Guoqiang Liang", "Yiran Shen", "Lin Wang"], "title": "Self-supervised Learning of Event-guided Video Frame Interpolation for Rolling Shutter Frames", "categories": ["cs.CV", "cs.RO"], "comment": "An earlier version of this paper (ID: 1845) was submitted to ICCV\n  2023 in March 2023. The work has been substantially revised and accepted by\n  IEEE Transactions on Visualization and Computer Graphics (TVCG)", "summary": "Most consumer cameras use rolling shutter (RS) exposure, which often leads to\ndistortions such as skew and jelly effects. These videos are further limited by\nbandwidth and frame rate constraints. In this paper, we explore the potential\nof event cameras, which offer high temporal resolution. We propose a framework\nto recover global shutter (GS) high-frame-rate videos without RS distortion by\ncombining an RS camera and an event camera. Due to the lack of real-world\ndatasets, our framework adopts a self-supervised strategy based on a\ndisplacement field, a dense 3D spatiotemporal representation of pixel motion\nduring exposure. This enables mutual reconstruction between RS and GS frames\nand facilitates slow-motion recovery. We combine RS frames with the\ndisplacement field to generate GS frames, and integrate inverse mapping and RS\nframe warping for self-supervision. Experiments on four datasets show that our\nmethod removes distortion, reduces bandwidth usage by 94 percent, and achieves\n16 ms per frame at 32x interpolation.", "AI": {"tldr": "A framework combining RS and event cameras to remove RS distortions and recover high-frame-rate GS videos, reducing bandwidth by 94% and achieving 16 ms per frame.", "motivation": "Address RS distortions (skew, jelly effects) and bandwidth/frame rate limitations in consumer cameras by leveraging event cameras' high temporal resolution.", "method": "Self-supervised strategy using a displacement field for mutual RS-GS reconstruction and slow-motion recovery, integrating RS frames and inverse mapping.", "result": "Removes RS distortions, reduces bandwidth by 94%, and achieves 16 ms per frame at 32x interpolation on four datasets.", "conclusion": "The framework effectively recovers GS videos with minimal distortion and high efficiency, demonstrating practical benefits for consumer cameras."}}
{"id": "2506.02664", "pdf": "https://arxiv.org/pdf/2506.02664", "abs": "https://arxiv.org/abs/2506.02664", "authors": ["Hugo Tabanelli", "Pierre Mergny", "Lenka Zdeborova", "Florent Krzakala"], "title": "Computational Thresholds in Multi-Modal Learning via the Spiked Matrix-Tensor Model", "categories": ["stat.ML", "cond-mat.dis-nn", "cs.LG"], "comment": null, "summary": "We study the recovery of multiple high-dimensional signals from two noisy,\ncorrelated modalities: a spiked matrix and a spiked tensor sharing a common\nlow-rank structure. This setting generalizes classical spiked matrix and tensor\nmodels, unveiling intricate interactions between inference channels and\nsurprising algorithmic behaviors. Notably, while the spiked tensor model is\ntypically intractable at low signal-to-noise ratios, its correlation with the\nmatrix enables efficient recovery via Bayesian Approximate Message Passing,\ninducing staircase-like phase transitions reminiscent of neural network\nphenomena. In contrast, empirical risk minimization for joint learning fails:\nthe tensor component obstructs effective matrix recovery, and joint\noptimization significantly degrades performance, highlighting the limitations\nof naive multi-modal learning. We show that a simple Sequential Curriculum\nLearning strategy-first recovering the matrix, then leveraging it to guide\ntensor recovery-resolves this bottleneck and achieves optimal weak recovery\nthresholds. This strategy, implementable with spectral methods, emphasizes the\ncritical role of structural correlation and learning order in multi-modal\nhigh-dimensional inference.", "AI": {"tldr": "The paper explores efficient recovery of high-dimensional signals from correlated spiked matrix and tensor models, revealing algorithmic insights and the benefits of sequential learning over joint optimization.", "motivation": "To understand the interplay between correlated spiked matrix and tensor models and develop efficient recovery methods, especially in low signal-to-noise scenarios.", "method": "Uses Bayesian Approximate Message Passing for efficient recovery and compares it with empirical risk minimization. Proposes Sequential Curriculum Learning (matrix first, then tensor).", "result": "Joint optimization fails; sequential learning achieves optimal weak recovery thresholds. Bayesian methods outperform naive multi-modal approaches.", "conclusion": "Structural correlation and learning order are crucial in multi-modal inference; sequential learning resolves bottlenecks and outperforms joint optimization."}}
{"id": "2306.08586", "pdf": "https://arxiv.org/pdf/2306.08586", "abs": "https://arxiv.org/abs/2306.08586", "authors": ["Yehya Farhat", "Hamza ElMokhtar Shili", "Fangshuo Liao", "Chen Dun", "Mirian Hipolito Garcia", "Guoqing Zheng", "Ahmed Hassan Awadallah", "Robert Sim", "Dimitrios Dimitriadis", "Anastasios Kyrillidis"], "title": "Learning to Specialize: Joint Gating-Expert Training for Adaptive MoEs in Decentralized Settings", "categories": ["cs.LG", "cs.AI", "math.OC"], "comment": "26 Pages", "summary": "Mixture-of-Experts (MoEs) achieve scalability by dynamically activating\nsubsets of their components. Yet, understanding how expertise emerges through\njoint training of gating mechanisms and experts remains incomplete, especially\nin scenarios without clear task partitions. Motivated by inference costs and\ndata heterogeneity, we study how joint training of gating functions and experts\ncan dynamically allocate domain-specific expertise across multiple underlying\ndata distributions. As an outcome of our framework, we develop an instance\ntailored specifically to decentralized training scenarios, introducing\n\\textit{Dynamically Decentralized Orchestration of MoEs} or \\texttt{DDOME}.\n\\texttt{DDOME} leverages heterogeneity emerging from distributional shifts\nacross decentralized data sources to specialize experts dynamically. By\nintegrating a pretrained common expert to inform a gating function,\n\\texttt{DDOME} achieves personalized expert subset selection on-the-fly,\nfacilitating just-in-time personalization. We empirically validate\n\\texttt{DDOME} within a Federated Learning (FL) context: \\texttt{DDOME} attains\nfrom 4\\% up to an 24\\% accuracy improvement over state-of-the-art FL baselines\nin image and text classification tasks, while maintaining competitive zero-shot\ngeneralization capabilities. Furthermore, we provide theoretical insights\nconfirming that the joint gating-experts training is critical for achieving\nmeaningful expert specialization.", "AI": {"tldr": "The paper introduces DDOME, a method for dynamically allocating expertise in Mixture-of-Experts (MoEs) by leveraging decentralized data heterogeneity, achieving significant accuracy improvements in Federated Learning.", "motivation": "The study aims to understand how expertise emerges in MoEs without clear task partitions and addresses challenges like inference costs and data heterogeneity.", "method": "The authors propose DDOME, which dynamically specializes experts by integrating a pretrained common expert to inform gating functions, enabling personalized subset selection.", "result": "DDOME improves accuracy by 4-24% over FL baselines in image/text classification and maintains zero-shot generalization.", "conclusion": "Joint training of gating and experts is critical for expert specialization, and DDOME effectively leverages decentralized data for dynamic expertise allocation."}}
{"id": "2411.11479", "pdf": "https://arxiv.org/pdf/2411.11479", "abs": "https://arxiv.org/abs/2411.11479", "authors": ["Jingxuan Li", "Yuning Yang", "Shengqi Yang", "Linfan Zhang", "Ying Nian Wu"], "title": "Value-Spectrum: Quantifying Preferences of Vision-Language Models via Value Decomposition in Social Media Contexts", "categories": ["cs.CL"], "comment": "ACL 2025 main", "summary": "The recent progress in Vision-Language Models (VLMs) has broadened the scope\nof multimodal applications. However, evaluations often remain limited to\nfunctional tasks, neglecting abstract dimensions such as personality traits and\nhuman values. To address this gap, we introduce Value-Spectrum, a novel Visual\nQuestion Answering (VQA) benchmark aimed at assessing VLMs based on Schwartz's\nvalue dimensions that capture core human values guiding people's preferences\nand actions. We design a VLM agent pipeline to simulate video browsing and\nconstruct a vector database comprising over 50,000 short videos from TikTok,\nYouTube Shorts, and Instagram Reels. These videos span multiple months and\ncover diverse topics, including family, health, hobbies, society, technology,\netc. Benchmarking on Value-Spectrum highlights notable variations in how VLMs\nhandle value-oriented content. Beyond identifying VLMs' intrinsic preferences,\nwe also explore the ability of VLM agents to adopt specific personas when\nexplicitly prompted, revealing insights into the adaptability of the model in\nrole-playing scenarios. These findings highlight the potential of\nValue-Spectrum as a comprehensive evaluation set for tracking VLM preferences\nin value-based tasks and abilities to simulate diverse personas. The complete\ncode and data are available at: https://github.com/Jeremyyny/Value-Spectrum.", "AI": {"tldr": "The paper introduces Value-Spectrum, a VQA benchmark to evaluate VLMs on human values and personality traits, using a dataset of 50,000+ short videos. It reveals VLM variations in value-oriented tasks and adaptability in role-playing.", "motivation": "Current VLM evaluations focus on functional tasks, ignoring abstract dimensions like human values. The paper aims to fill this gap by assessing VLMs on Schwartz's value dimensions.", "method": "A VLM agent pipeline is designed to simulate video browsing, using a vector database of 50,000+ short videos from platforms like TikTok. The benchmark evaluates VLMs on value-oriented content and persona adaptability.", "result": "Benchmarking shows variations in how VLMs handle value-based content and their ability to adopt specific personas when prompted, revealing insights into model adaptability.", "conclusion": "Value-Spectrum serves as a comprehensive tool for evaluating VLMs in value-based tasks and persona simulation, with potential for broader applications."}}
{"id": "2309.13570", "pdf": "https://arxiv.org/pdf/2309.13570", "abs": "https://arxiv.org/abs/2309.13570", "authors": ["Zixun Huang", "Keling Yao", "Seth Z. Zhao", "Chuanyu Pan", "Allen Y. Yang"], "title": "Robust 6DoF Pose Estimation Against Depth Noise and a Comprehensive Evaluation on a Mobile Dataset", "categories": ["cs.CV"], "comment": null, "summary": "Robust 6DoF pose estimation with mobile devices is the foundation for\napplications in robotics, augmented reality, and digital twin localization. In\nthis paper, we extensively investigate the robustness of existing RGBD-based\n6DoF pose estimation methods against varying levels of depth sensor noise. We\nhighlight that existing 6DoF pose estimation methods suffer significant\nperformance discrepancies due to depth measurement inaccuracies. In response to\nthe robustness issue, we present a simple and effective transformer-based 6DoF\npose estimation approach called DTTDNet, featuring a novel geometric feature\nfiltering module and a Chamfer distance loss for training. Moreover, we advance\nthe field of robust 6DoF pose estimation and introduce a new dataset -- Digital\nTwin Tracking Dataset Mobile (DTTD-Mobile), tailored for digital twin object\ntracking with noisy depth data from the mobile RGBD sensor suite of the Apple\niPhone 14 Pro. Extensive experiments demonstrate that DTTDNet significantly\noutperforms state-of-the-art methods at least 4.32, up to 60.74 points in ADD\nmetrics on the DTTD-Mobile. More importantly, our approach exhibits superior\nrobustness to varying levels of measurement noise, setting a new benchmark for\nrobustness to measurement noise. The project page is publicly available at\nhttps://openark-berkeley.github.io/DTTDNet/.", "AI": {"tldr": "DTTDNet, a transformer-based 6DoF pose estimation method, addresses robustness issues in existing RGBD-based methods by introducing a geometric feature filtering module and Chamfer distance loss. It outperforms state-of-the-art methods on the new DTTD-Mobile dataset, especially in noisy conditions.", "motivation": "Existing 6DoF pose estimation methods struggle with depth sensor noise, leading to performance discrepancies. This paper aims to improve robustness against such noise.", "method": "Proposes DTTDNet, featuring a geometric feature filtering module and Chamfer distance loss, and introduces the DTTD-Mobile dataset for noisy depth data.", "result": "DTTDNet outperforms state-of-the-art methods by 4.32 to 60.74 points in ADD metrics on DTTD-Mobile, showing superior noise robustness.", "conclusion": "DTTDNet sets a new benchmark for robustness in 6DoF pose estimation, particularly in noisy environments, with a publicly available project page."}}
{"id": "2506.02685", "pdf": "https://arxiv.org/pdf/2506.02685", "abs": "https://arxiv.org/abs/2506.02685", "authors": ["Hohyun Kim", "Seunggeun Lee", "Min-hwan Oh"], "title": "Symmetry-Aware GFlowNets", "categories": ["stat.ML", "cs.LG"], "comment": "29 pages; Accepted at ICML 2025", "summary": "Generative Flow Networks (GFlowNets) offer a powerful framework for sampling\ngraphs in proportion to their rewards. However, existing approaches suffer from\nsystematic biases due to inaccuracies in state transition probability\ncomputations. These biases, rooted in the inherent symmetries of graphs, impact\nboth atom-based and fragment-based generation schemes. To address this\nchallenge, we introduce Symmetry-Aware GFlowNets (SA-GFN), a method that\nincorporates symmetry corrections into the learning process through reward\nscaling. By integrating bias correction directly into the reward structure,\nSA-GFN eliminates the need for explicit state transition computations.\nEmpirical results show that SA-GFN enables unbiased sampling while enhancing\ndiversity and consistently generating high-reward graphs that closely match the\ntarget distribution.", "AI": {"tldr": "SA-GFN introduces symmetry corrections to GFlowNets, eliminating biases in graph sampling by scaling rewards, leading to unbiased, diverse, and high-reward outputs.", "motivation": "Existing GFlowNets suffer from biases due to inaccurate state transition computations, affecting graph sampling quality.", "method": "SA-GFN incorporates symmetry corrections via reward scaling, avoiding explicit transition probability calculations.", "result": "SA-GFN achieves unbiased sampling, improves diversity, and generates high-reward graphs matching the target distribution.", "conclusion": "SA-GFN effectively addresses biases in GFlowNets, enhancing sampling quality without explicit transition computations."}}
{"id": "2309.14907", "pdf": "https://arxiv.org/pdf/2309.14907", "abs": "https://arxiv.org/abs/2309.14907", "authors": ["Zhihao Shi", "Jie Wang", "Fanghua Lu", "Hanzhu Chen", "Defu Lian", "Zheng Wang", "Jieping Ye", "Feng Wu"], "title": "Label Deconvolution for Node Representation Learning on Large-scale Attributed Graphs against Learning Bias", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Node representation learning on attributed graphs -- whose nodes are\nassociated with rich attributes (e.g., texts and protein sequences) -- plays a\ncrucial role in many important downstream tasks. To encode the attributes and\ngraph structures simultaneously, recent studies integrate pre-trained models\nwith graph neural networks (GNNs), where pre-trained models serve as node\nencoders (NEs) to encode the attributes. As jointly training large NEs and GNNs\non large-scale graphs suffers from severe scalability issues, many methods\npropose to train NEs and GNNs separately. Consequently, they do not take\nfeature convolutions in GNNs into consideration in the training phase of NEs,\nleading to a significant learning bias relative to the joint training. To\naddress this challenge, we propose an efficient label regularization technique,\nnamely Label Deconvolution (LD), to alleviate the learning bias by a novel and\nhighly scalable approximation to the inverse mapping of GNNs. The inverse\nmapping leads to an objective function that is equivalent to that by the joint\ntraining, while it can effectively incorporate GNNs in the training phase of\nNEs against the learning bias. More importantly, we show that LD converges to\nthe optimal objective function values by the joint training under mild\nassumptions. Experiments demonstrate LD significantly outperforms\nstate-of-the-art methods on Open Graph Benchmark datasets.", "AI": {"tldr": "The paper proposes Label Deconvolution (LD), a label regularization technique to address learning bias in node representation learning on attributed graphs by approximating the inverse mapping of GNNs.", "motivation": "Joint training of large node encoders (NEs) and GNNs on large-scale graphs is impractical due to scalability issues, leading to learning bias when trained separately.", "method": "Introduces LD, a scalable approximation to the inverse mapping of GNNs, aligning NE training with GNN feature convolutions.", "result": "LD outperforms state-of-the-art methods on Open Graph Benchmark datasets and converges to optimal joint training objectives under mild assumptions.", "conclusion": "LD effectively mitigates learning bias and enhances performance in node representation learning without the scalability issues of joint training."}}
{"id": "2411.15462", "pdf": "https://arxiv.org/pdf/2411.15462", "abs": "https://arxiv.org/abs/2411.15462", "authors": ["Manuel Tonneau", "Diyi Liu", "Niyati Malhotra", "Scott A. Hale", "Samuel P. Fraiberger", "Victor Orozco-Olvera", "Paul R\u00f6ttger"], "title": "HateDay: Insights from a Global Hate Speech Dataset Representative of a Day on Twitter", "categories": ["cs.CL"], "comment": "ACL 2025 main conference. Data available at\n  https://huggingface.co/datasets/manueltonneau/hateday", "summary": "To address the global challenge of online hate speech, prior research has\ndeveloped detection models to flag such content on social media. However, due\nto systematic biases in evaluation datasets, the real-world effectiveness of\nthese models remains unclear, particularly across geographies. We introduce\nHateDay, the first global hate speech dataset representative of social media\nsettings, constructed from a random sample of all tweets posted on September\n21, 2022 and covering eight languages and four English-speaking countries.\nUsing HateDay, we uncover substantial variation in the prevalence and\ncomposition of hate speech across languages and regions. We show that\nevaluations on academic datasets greatly overestimate real-world detection\nperformance, which we find is very low, especially for non-European languages.\nOur analysis identifies key drivers of this gap, including models' difficulty\nto distinguish hate from offensive speech and a mismatch between the target\ngroups emphasized in academic datasets and those most frequently targeted in\nreal-world settings. We argue that poor model performance makes public models\nill-suited for automatic hate speech moderation and find that high moderation\nrates are only achievable with substantial human oversight. Our results\nunderscore the need to evaluate detection systems on data that reflects the\ncomplexity and diversity of real-world social media.", "AI": {"tldr": "HateDay, a global hate speech dataset, reveals biases in existing detection models, showing low real-world performance, especially for non-European languages, and highlights the need for better evaluation data.", "motivation": "To address the unclear real-world effectiveness of hate speech detection models due to biased evaluation datasets.", "method": "Constructed HateDay, a representative global dataset from tweets in eight languages and four English-speaking countries, and evaluated model performance.", "result": "Found low detection performance, especially for non-European languages, due to model difficulties in distinguishing hate from offensive speech and dataset mismatches.", "conclusion": "Current models are unsuitable for automatic moderation without human oversight, emphasizing the need for diverse evaluation data."}}
{"id": "2310.05026", "pdf": "https://arxiv.org/pdf/2310.05026", "abs": "https://arxiv.org/abs/2310.05026", "authors": ["Yu-Huan Wu", "Shi-Chen Zhang", "Yun Liu", "Le Zhang", "Xin Zhan", "Daquan Zhou", "Jiashi Feng", "Ming-Ming Cheng", "Liangli Zhen"], "title": "Low-Resolution Self-Attention for Semantic Segmentation", "categories": ["cs.CV"], "comment": "Accepted by IEEE TPAMI; 14 pages, 6 figures, 14 tables", "summary": "Semantic segmentation tasks naturally require high-resolution information for\npixel-wise segmentation and global context information for class prediction.\nWhile existing vision transformers demonstrate promising performance, they\noften utilize high-resolution context modeling, resulting in a computational\nbottleneck. In this work, we challenge conventional wisdom and introduce the\nLow-Resolution Self-Attention (LRSA) mechanism to capture global context at a\nsignificantly reduced computational cost, i.e., FLOPs. Our approach involves\ncomputing self-attention in a fixed low-resolution space regardless of the\ninput image's resolution, with additional 3x3 depth-wise convolutions to\ncapture fine details in the high-resolution space. We demonstrate the\neffectiveness of our LRSA approach by building the LRFormer, a vision\ntransformer with an encoder-decoder structure. Extensive experiments on the\nADE20K, COCO-Stuff, and Cityscapes datasets demonstrate that LRFormer\noutperforms state-of-the-art models. Code is available at\nhttps://github.com/yuhuan-wu/LRFormer.", "AI": {"tldr": "The paper introduces LRSA, a low-resolution self-attention mechanism for semantic segmentation, reducing computational cost while maintaining performance.", "motivation": "Existing vision transformers for semantic segmentation are computationally expensive due to high-resolution context modeling.", "method": "Proposes LRSA, which computes self-attention in a fixed low-resolution space and uses 3x3 depth-wise convolutions for fine details.", "result": "LRFormer, built with LRSA, outperforms state-of-the-art models on ADE20K, COCO-Stuff, and Cityscapes datasets.", "conclusion": "LRSA is an effective, computationally efficient alternative for semantic segmentation tasks."}}
{"id": "2506.02710", "pdf": "https://arxiv.org/pdf/2506.02710", "abs": "https://arxiv.org/abs/2506.02710", "authors": ["T. N. Nisslbeck", "Wouter M. Kouw"], "title": "Online Bayesian system identification in multivariate autoregressive models via message passing", "categories": ["eess.SP", "cs.LG", "stat.ML"], "comment": "6 pages, 1 figure, conference: ECC2025", "summary": "We propose a recursive Bayesian estimation procedure for multivariate\nautoregressive models with exogenous inputs based on message passing in a\nfactor graph. Unlike recursive least-squares, our method produces full\nposterior distributions for both the autoregressive coefficients and noise\nprecision. The uncertainties regarding these estimates propagate into the\nuncertainties on predictions for future system outputs, and support online\nmodel evidence calculations. We demonstrate convergence empirically on a\nsynthetic autoregressive system and competitive performance on a double\nmass-spring-damper system.", "AI": {"tldr": "A recursive Bayesian estimation method for multivariate autoregressive models with exogenous inputs, using factor graph message passing, providing full posterior distributions and uncertainty propagation.", "motivation": "To improve upon recursive least-squares by offering full posterior distributions for coefficients and noise precision, enabling better uncertainty quantification and online model evidence.", "method": "Recursive Bayesian estimation via message passing in a factor graph, applied to multivariate autoregressive models with exogenous inputs.", "result": "Demonstrated convergence on synthetic data and competitive performance on a double mass-spring-damper system.", "conclusion": "The method effectively quantifies uncertainties and supports online model evidence, showing practical promise."}}
{"id": "2310.06077", "pdf": "https://arxiv.org/pdf/2310.06077", "abs": "https://arxiv.org/abs/2310.06077", "authors": ["Zhiyuan Zhao", "Haoxin Liu", "Alexander Rodriguez", "B. Aditya Prakash"], "title": "Performative Time-Series Forecasting", "categories": ["cs.LG", "cs.AI"], "comment": "12 pages (8 main text, 1 reference, 3 appendix), 5 figures, 4 tables", "summary": "Time-series forecasting is a critical challenge in various domains and has\nwitnessed substantial progress in recent years. Many real-life scenarios, such\nas public health, economics, and social applications, involve feedback loops\nwhere predictions can influence the predicted outcome, subsequently altering\nthe target variable's distribution. This phenomenon, known as performativity,\nintroduces the potential for 'self-negating' or 'self-fulfilling' predictions.\nDespite extensive studies in classification problems across domains,\nperformativity remains largely unexplored in the context of time-series\nforecasting from a machine-learning perspective.\n  In this paper, we formalize performative time-series forecasting (PeTS),\naddressing the challenge of accurate predictions when performativity-induced\ndistribution shifts are possible. We propose a novel approach, Feature\nPerformative-Shifting (FPS), which leverages the concept of delayed response to\nanticipate distribution shifts and subsequently predicts targets accordingly.\nWe provide theoretical insights suggesting that FPS can potentially lead to\nreduced generalization error. We conduct comprehensive experiments using\nmultiple time-series models on COVID-19 and traffic forecasting tasks. The\nresults demonstrate that FPS consistently outperforms conventional time-series\nforecasting methods, highlighting its efficacy in handling\nperformativity-induced challenges.", "AI": {"tldr": "The paper introduces performative time-series forecasting (PeTS) and proposes Feature Performative-Shifting (FPS) to handle performativity-induced distribution shifts, showing improved performance over conventional methods.", "motivation": "Performativity in time-series forecasting, where predictions influence outcomes, is underexplored. The paper aims to address this gap.", "method": "Proposes FPS, leveraging delayed response to anticipate distribution shifts for accurate predictions.", "result": "FPS outperforms conventional methods in COVID-19 and traffic forecasting tasks.", "conclusion": "FPS is effective for performative time-series forecasting, reducing generalization error."}}
{"id": "2411.16765", "pdf": "https://arxiv.org/pdf/2411.16765", "abs": "https://arxiv.org/abs/2411.16765", "authors": ["Shester Gueuwou", "Xiaodan Du", "Greg Shakhnarovich", "Karen Livescu", "Alexander H. Liu"], "title": "SHuBERT: Self-Supervised Sign Language Representation Learning via Multi-Stream Cluster Prediction", "categories": ["cs.CL", "cs.CV"], "comment": "Accepted to ACL 2025", "summary": "Sign language processing has traditionally relied on task-specific models,\nlimiting the potential for transfer learning across tasks. Pre-training methods\nfor sign language have typically focused on either supervised pre-training,\nwhich cannot take advantage of unlabeled data, or context-independent (frame or\nvideo segment) representations, which ignore the effects of relationships\nacross time in sign language. We introduce SHuBERT (Sign Hidden-Unit BERT), a\nself-supervised contextual representation model learned from approximately\n1,000 hours of American Sign Language video. SHuBERT adapts masked token\nprediction objectives to multi-stream visual sign language input, learning to\npredict multiple targets corresponding to clustered hand, face, and body pose\nstreams. SHuBERT achieves state-of-the-art performance across multiple tasks\nincluding sign language translation, isolated sign language recognition, and\nfingerspelling detection.", "AI": {"tldr": "SHuBERT is a self-supervised model for sign language processing, outperforming traditional task-specific methods by learning contextual representations from multi-stream visual input.", "motivation": "Traditional sign language models lack transfer learning capabilities and ignore temporal relationships. SHuBERT addresses these gaps by leveraging unlabeled data and contextual learning.", "method": "SHuBERT uses masked token prediction on multi-stream visual input (hand, face, body pose) from 1,000 hours of ASL video, adapting BERT-like objectives.", "result": "State-of-the-art performance in sign language translation, isolated recognition, and fingerspelling detection.", "conclusion": "SHuBERT demonstrates the effectiveness of self-supervised contextual learning for sign language processing, enabling transfer across tasks."}}
{"id": "2312.13528", "pdf": "https://arxiv.org/pdf/2312.13528", "abs": "https://arxiv.org/abs/2312.13528", "authors": ["Minh-Quan Viet Bui", "Jongmin Park", "Jihyong Oh", "Munchurl Kim"], "title": "MoBluRF: Motion Deblurring Neural Radiance Fields for Blurry Monocular Video", "categories": ["cs.CV"], "comment": "Accepted to IEEE Transactions on Pattern Analysis and Machine\n  Intelligence (TPAMI), 2025. The first two authors contributed equally to this\n  work (equal contribution). The last two authors are co-corresponding authors.\n  Please visit our project page at https://kaist-viclab.github.io/moblurf-site/", "summary": "Neural Radiance Fields (NeRF), initially developed for static scenes, have\ninspired many video novel view synthesis techniques. However, the challenge for\nvideo view synthesis arises from motion blur, a consequence of object or camera\nmovements during exposure, which hinders the precise synthesis of sharp\nspatio-temporal views. In response, we propose a novel motion deblurring NeRF\nframework for blurry monocular video, called MoBluRF, consisting of a Base Ray\nInitialization (BRI) stage and a Motion Decomposition-based Deblurring (MDD)\nstage. In the BRI stage, we coarsely reconstruct dynamic 3D scenes and jointly\ninitialize the base rays which are further used to predict latent sharp rays,\nusing the inaccurate camera pose information from the given blurry frames. In\nthe MDD stage, we introduce a novel Incremental Latent Sharp-rays Prediction\n(ILSP) approach for the blurry monocular video frames by decomposing the latent\nsharp rays into global camera motion and local object motion components. We\nfurther propose two loss functions for effective geometry regularization and\ndecomposition of static and dynamic scene components without any mask\nsupervision. Experiments show that MoBluRF outperforms qualitatively and\nquantitatively the recent state-of-the-art methods with large margins.", "AI": {"tldr": "MoBluRF is a motion deblurring NeRF framework for blurry monocular videos, addressing challenges in video view synthesis caused by motion blur. It uses a two-stage approach (BRI and MDD) to reconstruct scenes and predict sharp rays, outperforming existing methods.", "motivation": "Motion blur in videos due to object or camera movement hinders precise view synthesis. Existing NeRF methods struggle with dynamic scenes, necessitating a specialized solution.", "method": "MoBluRF employs a two-stage framework: Base Ray Initialization (BRI) for coarse scene reconstruction and Motion Decomposition-based Deblurring (MDD) to predict latent sharp rays by decomposing motion into global and local components. Two loss functions aid geometry regularization and scene decomposition.", "result": "MoBluRF outperforms state-of-the-art methods in both qualitative and quantitative metrics, demonstrating superior performance in deblurring and view synthesis.", "conclusion": "MoBluRF effectively addresses motion blur in video view synthesis, offering a robust solution for dynamic scenes without requiring mask supervision."}}
{"id": "2506.02754", "pdf": "https://arxiv.org/pdf/2506.02754", "abs": "https://arxiv.org/abs/2506.02754", "authors": ["Luc Brogat-Motte", "Alessandro Rudi", "Riccardo Bonalli"], "title": "Safely Learning Controlled Stochastic Dynamics", "categories": ["stat.ML", "cs.LG"], "comment": "Under review at NeurIPS 2025", "summary": "We address the problem of safely learning controlled stochastic dynamics from\ndiscrete-time trajectory observations, ensuring system trajectories remain\nwithin predefined safe regions during both training and deployment.\nSafety-critical constraints of this kind are crucial in applications such as\nautonomous robotics, finance, and biomedicine. We introduce a method that\nensures safe exploration and efficient estimation of system dynamics by\niteratively expanding an initial known safe control set using kernel-based\nconfidence bounds. After training, the learned model enables predictions of the\nsystem's dynamics and permits safety verification of any given control. Our\napproach requires only mild smoothness assumptions and access to an initial\nsafe control set, enabling broad applicability to complex real-world systems.\nWe provide theoretical guarantees for safety and derive adaptive learning rates\nthat improve with increasing Sobolev regularity of the true dynamics.\nExperimental evaluations demonstrate the practical effectiveness of our method\nin terms of safety, estimation accuracy, and computational efficiency.", "AI": {"tldr": "A method for safely learning controlled stochastic dynamics from trajectory data, ensuring safety during training and deployment using kernel-based confidence bounds.", "motivation": "Safety-critical constraints are vital in fields like autonomous robotics, finance, and biomedicine, necessitating safe learning of system dynamics.", "method": "Iteratively expands an initial safe control set using kernel-based confidence bounds, requiring only mild smoothness assumptions and an initial safe set.", "result": "The learned model allows safe dynamics prediction and verification, with theoretical safety guarantees and adaptive learning rates.", "conclusion": "Experimental results confirm the method's effectiveness in safety, accuracy, and efficiency, making it broadly applicable to real-world systems."}}
{"id": "2311.18703", "pdf": "https://arxiv.org/pdf/2311.18703", "abs": "https://arxiv.org/abs/2311.18703", "authors": ["Daniel Jarne Ornia", "Giannis Delimpaltadakis", "Jens Kober", "Javier Alonso-Mora"], "title": "Predictable Reinforcement Learning Dynamics through Entropy Rate Minimization", "categories": ["cs.LG", "cs.AI", "cs.SY", "eess.SY"], "comment": null, "summary": "In Reinforcement Learning (RL), agents have no incentive to exhibit\npredictable behaviors, and are often pushed (through e.g. policy entropy\nregularisation) to randomise their actions in favor of exploration. This often\nmakes it challenging for other agents and humans to predict an agent's\nbehavior, triggering unsafe scenarios (e.g. in human-robot interaction). We\npropose a novel method to induce predictable behavior in RL agents, termed\nPredictability-Aware RL (PARL), employing the agent's trajectory entropy rate\nto quantify predictability. Our method maximizes a linear combination of a\nstandard discounted reward and the negative entropy rate, thus trading off\noptimality with predictability. We show how the entropy rate can be formally\ncast as an average reward, how entropy-rate value functions can be estimated\nfrom a learned model and incorporate this in policy-gradient algorithms, and\ndemonstrate how this approach produces predictable (near-optimal) policies in\ntasks inspired by human-robot use-cases.", "AI": {"tldr": "The paper introduces Predictability-Aware RL (PARL), a method to make RL agents' behavior more predictable by balancing reward maximization and predictability, measured via trajectory entropy rate.", "motivation": "RL agents often behave unpredictably due to exploration incentives, posing safety risks in human-robot interactions. The goal is to develop a method to ensure predictable yet near-optimal behavior.", "method": "PARL combines standard RL rewards with the negative entropy rate of trajectories, quantifying predictability. It integrates entropy-rate estimation into policy-gradient algorithms.", "result": "The method successfully produces predictable, near-optimal policies in human-robot interaction tasks.", "conclusion": "PARL effectively balances predictability and performance, offering a practical solution for safer RL applications."}}
{"id": "2412.12797", "pdf": "https://arxiv.org/pdf/2412.12797", "abs": "https://arxiv.org/abs/2412.12797", "authors": ["Cristiano Chesi"], "title": "Is it the end of (generative) linguistics as we know it?", "categories": ["cs.CL"], "comment": null, "summary": "A significant debate has emerged in response to a paper written by Steven\nPiantadosi (Piantadosi, 2023) and uploaded to the LingBuzz platform, the open\narchive for generative linguistics. Piantadosi's dismissal of Chomsky's\napproach is ruthless, but generative linguists deserve it. In this paper, I\nwill adopt three idealized perspectives -- computational, theoretical, and\nexperimental -- to focus on two fundamental issues that lend partial support to\nPiantadosi's critique: (a) the evidence challenging the Poverty of Stimulus\n(PoS) hypothesis and (b) the notion of simplicity as conceived within\nmainstream Minimalism. In conclusion, I argue that, to reclaim a central role\nin language studies, generative linguistics -- representing a prototypical\ntheoretical perspective on language -- needs a serious update leading to (i)\nmore precise, consistent, and complete formalizations of foundational\nintuitions and (ii) the establishment and utilization of a standardized dataset\nof crucial empirical evidence to evaluate the theory's adequacy. On the other\nhand, ignoring the formal perspective leads to major drawbacks in both\ncomputational and experimental approaches. Neither descriptive nor explanatory\nadequacy can be easily achieved without the precise formulation of general\nprinciples that can be challenged empirically.", "AI": {"tldr": "The paper critiques Chomsky's generative linguistics, supporting Piantadosi's critique on Poverty of Stimulus and simplicity in Minimalism, advocating for updated formalizations and empirical datasets.", "motivation": "To address flaws in generative linguistics, particularly the Poverty of Stimulus hypothesis and simplicity in Minimalism, and advocate for theoretical updates.", "method": "Adopts computational, theoretical, and experimental perspectives to analyze two key issues.", "result": "Partial support for Piantadosi's critique; highlights the need for precise formalizations and empirical datasets.", "conclusion": "Generative linguistics must update its formal foundations and use standardized empirical evidence to maintain relevance and achieve descriptive/explanatory adequacy."}}
{"id": "2401.11311", "pdf": "https://arxiv.org/pdf/2401.11311", "abs": "https://arxiv.org/abs/2401.11311", "authors": ["Reda Bensaid", "Vincent Gripon", "Fran\u00e7ois Leduc-Primeau", "Lukas Mauch", "Ghouthi Boukli Hacene", "Fabien Cardinaux"], "title": "A Novel Benchmark for Few-Shot Semantic Segmentation in the Era of Foundation Models", "categories": ["cs.CV"], "comment": null, "summary": "Few-shot semantic segmentation (FSS) is a crucial challenge in computer\nvision, driving extensive research into a diverse range of methods, from\nadvanced meta-learning techniques to simple transfer learning baselines. With\nthe emergence of vision foundation models (VFM) serving as generalist feature\nextractors, we seek to explore the adaptation of these models for FSS. While\ncurrent FSS benchmarks focus on adapting pre-trained models to new tasks with\nfew images, they emphasize in-domain generalization, making them less suitable\nfor VFM trained on large-scale web datasets. To address this, we propose a\nnovel realistic benchmark with a simple and straightforward adaptation process\ntailored for this task. Using this benchmark, we conduct a comprehensive\ncomparative analysis of prominent VFM and semantic segmentation models. To\nevaluate their effectiveness, we leverage various adaption methods, ranging\nfrom linear probing to parameter efficient fine-tuning (PEFT) and full\nfine-tuning. Our findings show that models designed for segmentation can be\noutperformed by self-supervised (SSL) models. On the other hand, while PEFT\nmethods yields competitive performance, they provide little discrepancy in the\nobtained results compared to other methods, highlighting the critical role of\nthe feature extractor in determining results. To our knowledge, this is the\nfirst study on the adaptation of VFM for FSS.", "AI": {"tldr": "The paper explores adapting vision foundation models (VFM) for few-shot semantic segmentation (FSS), proposing a new benchmark and comparing VFM and segmentation models using various adaptation methods.", "motivation": "Current FSS benchmarks focus on in-domain generalization, making them unsuitable for VFM trained on large-scale datasets. The study aims to bridge this gap.", "method": "A novel realistic benchmark is introduced, and VFM and segmentation models are evaluated using adaptation methods like linear probing, PEFT, and full fine-tuning.", "result": "Segmentation models are outperformed by self-supervised models, and PEFT methods show competitive but similar performance, emphasizing the feature extractor's importance.", "conclusion": "This is the first study on VFM adaptation for FSS, highlighting the feature extractor's critical role and the potential of self-supervised models."}}
{"id": "2506.02793", "pdf": "https://arxiv.org/pdf/2506.02793", "abs": "https://arxiv.org/abs/2506.02793", "authors": ["Houssam Zenati", "Bariscan Bozkurt", "Arthur Gretton"], "title": "Doubly-Robust Estimation of Counterfactual Policy Mean Embeddings", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "Estimating the distribution of outcomes under counterfactual policies is\ncritical for decision-making in domains such as recommendation, advertising,\nand healthcare. We analyze a novel framework-Counterfactual Policy Mean\nEmbedding (CPME)-that represents the entire counterfactual outcome distribution\nin a reproducing kernel Hilbert space (RKHS), enabling flexible and\nnonparametric distributional off-policy evaluation. We introduce both a plug-in\nestimator and a doubly robust estimator; the latter enjoys improved uniform\nconvergence rates by correcting for bias in both the outcome embedding and\npropensity models. Building on this, we develop a doubly robust kernel test\nstatistic for hypothesis testing, which achieves asymptotic normality and thus\nenables computationally efficient testing and straightforward construction of\nconfidence intervals. Our framework also supports sampling from the\ncounterfactual distribution. Numerical simulations illustrate the practical\nbenefits of CPME over existing methods.", "AI": {"tldr": "The paper introduces CPME, a framework for nonparametric counterfactual outcome distribution estimation in RKHS, offering plug-in and doubly robust estimators, and a kernel test for hypothesis testing.", "motivation": "To enable flexible and nonparametric evaluation of counterfactual outcome distributions for better decision-making in domains like recommendation, advertising, and healthcare.", "method": "Proposes CPME, using RKHS for distribution representation, with plug-in and doubly robust estimators, and a kernel test for hypothesis testing.", "result": "CPME outperforms existing methods in simulations, with doubly robust estimators improving convergence rates and enabling efficient hypothesis testing.", "conclusion": "CPME provides a flexible, nonparametric approach for counterfactual policy evaluation, with practical advantages demonstrated in simulations."}}
{"id": "2402.11089", "pdf": "https://arxiv.org/pdf/2402.11089", "abs": "https://arxiv.org/abs/2402.11089", "authors": ["Yixin Wan", "Kai-Wei Chang"], "title": "The Male CEO and the Female Assistant: Evaluation and Mitigation of Gender Biases in Text-To-Image Generation of Dual Subjects", "categories": ["cs.CV", "cs.AI", "cs.CY"], "comment": null, "summary": "Recent large-scale T2I models like DALLE-3 have made progress in reducing\ngender stereotypes when generating single-person images. However, significant\nbiases remain when generating images with more than one person. To\nsystematically evaluate this, we propose the Paired Stereotype Test (PST)\nframework, which queries T2I models to depict two individuals assigned with\nmale-stereotyped and female-stereotyped social identities, respectively (e.g.\n\"a CEO\" and \"an Assistant\"). This contrastive setting often triggers T2I models\nto generate gender-stereotyped images. Using PST, we evaluate two aspects of\ngender biases -- the well-known bias in gendered occupation and a novel aspect:\nbias in organizational power. Experiments show that over 74\\% images generated\nby DALLE-3 display gender-occupational biases. Additionally, compared to\nsingle-person settings, DALLE-3 is more likely to perpetuate male-associated\nstereotypes under PST. We further propose FairCritic, a novel and interpretable\nframework that leverages an LLM-based critic model to i) detect bias in\ngenerated images, and ii) adaptively provide feedback to T2I models for\nimproving fairness. FairCritic achieves near-perfect fairness on PST,\novercoming the limitations of previous prompt-based intervention approaches.", "AI": {"tldr": "The paper evaluates gender biases in T2I models like DALLE-3, introduces the Paired Stereotype Test (PST) to measure biases in multi-person images, and proposes FairCritic, an LLM-based framework to detect and mitigate biases.", "motivation": "Despite progress in reducing gender stereotypes in single-person images, biases persist in multi-person settings, particularly in gendered occupations and organizational power.", "method": "The Paired Stereotype Test (PST) is used to evaluate biases by contrasting male- and female-stereotyped identities. FairCritic, an LLM-based framework, is introduced to detect biases and provide adaptive feedback.", "result": "DALLE-3 exhibits gender-occupational biases in 74% of images under PST, with stronger male-associated stereotypes. FairCritic achieves near-perfect fairness in mitigating these biases.", "conclusion": "The study highlights persistent gender biases in T2I models and demonstrates the effectiveness of FairCritic in improving fairness, surpassing prompt-based interventions."}}
{"id": "2412.13649", "pdf": "https://arxiv.org/pdf/2412.13649", "abs": "https://arxiv.org/abs/2412.13649", "authors": ["Jialong Wu", "Zhenglin Wang", "Linhai Zhang", "Yilong Lai", "Yulan He", "Deyu Zhou"], "title": "SCOPE: Optimizing Key-Value Cache Compression in Long-context Generation", "categories": ["cs.CL"], "comment": "ACL 2025", "summary": "Key-Value (KV) cache has become a bottleneck of LLMs for long-context\ngeneration. Despite the numerous efforts in this area, the optimization for the\ndecoding phase is generally ignored. However, we believe such optimization is\ncrucial, especially for long-output generation tasks based on the following two\nobservations: (i) Excessive compression during the prefill phase, which\nrequires specific full context impairs the comprehension of the reasoning task;\n(ii) Deviation of heavy hitters occurs in the reasoning tasks with long\noutputs. Therefore, SCOPE, a simple yet efficient framework that separately\nperforms KV cache optimization during the prefill and decoding phases, is\nintroduced. Specifically, the KV cache during the prefill phase is preserved to\nmaintain the essential information, while a novel strategy based on sliding is\nproposed to select essential heavy hitters for the decoding phase. Memory usage\nand memory transfer are further optimized using adaptive and discontinuous\nstrategies. Extensive experiments on LongGenBench show the effectiveness and\ngeneralization of SCOPE and its compatibility as a plug-in to other\nprefill-only KV compression methods.", "AI": {"tldr": "SCOPE optimizes KV cache separately for prefill and decoding phases in LLMs, improving long-context generation efficiency.", "motivation": "KV cache is a bottleneck in LLMs for long-context generation, with decoding phase optimization often overlooked. Observations show excessive prefill compression harms reasoning tasks and heavy hitters deviate in long outputs.", "method": "SCOPE preserves KV cache in prefill for essential info and uses a sliding strategy for decoding-phase heavy hitters. Adaptive and discontinuous strategies optimize memory usage and transfer.", "result": "Experiments on LongGenBench demonstrate SCOPE's effectiveness, generalization, and compatibility with other KV compression methods.", "conclusion": "SCOPE efficiently addresses KV cache bottlenecks, enhancing long-output generation in LLMs."}}
{"id": "2403.19386", "pdf": "https://arxiv.org/pdf/2403.19386", "abs": "https://arxiv.org/abs/2403.19386", "authors": ["Yanglin Feng", "Yang Qin", "Dezhong Peng", "Hongyuan Zhu", "Xi Peng", "Peng Hu"], "title": "PointCloud-Text Matching: Benchmark Datasets and a Baseline", "categories": ["cs.CV", "cs.AI"], "comment": "The version submitted this time has been significantly revised and\n  improved on the previous version", "summary": "In this paper, we present and study a new instance-level retrieval task:\nPointCloud-Text Matching (PTM), which aims to identify the exact cross-modal\ninstance that matches a given point-cloud query or text query. PTM has\npotential applications in various scenarios, such as indoor/urban-canyon\nlocalization and scene retrieval. However, there is a lack of suitable and\ntargeted datasets for PTM in practice. To address this issue, we present a new\nPTM benchmark dataset, namely SceneDepict-3D2T. We observe that the data poses\nsignificant challenges due to its inherent characteristics, such as the\nsparsity, noise, or disorder of point clouds and the ambiguity, vagueness, or\nincompleteness of texts, which render existing cross-modal matching methods\nineffective for PTM. To overcome these challenges, we propose a PTM baseline,\nnamed Robust PointCloud-Text Matching method (RoMa). RoMa consists of two key\nmodules: a Dual Attention Perception module (DAP) and a Robust Negative\nContrastive Learning module (RNCL). Specifically, DAP leverages token-level and\nfeature-level attention mechanisms to adaptively focus on useful local and\nglobal features, and aggregate them into common representations, thereby\nreducing the adverse impact of noise and ambiguity. To handle noisy\ncorrespondence, RNCL enhances robustness against mismatching by dividing\nnegative pairs into clean and noisy subsets and assigning them forward and\nreverse optimization directions, respectively. We conduct extensive experiments\non our benchmarks and demonstrate the superiority of our RoMa.", "AI": {"tldr": "The paper introduces PointCloud-Text Matching (PTM), a new retrieval task, and proposes a benchmark dataset (SceneDepict-3D2T) and a baseline method (RoMa) to address challenges like noise and ambiguity in point clouds and texts.", "motivation": "PTM has applications in localization and scene retrieval, but lacks suitable datasets and effective methods due to data challenges like sparsity and ambiguity.", "method": "Proposes RoMa with Dual Attention Perception (DAP) for feature aggregation and Robust Negative Contrastive Learning (RNCL) for handling noisy correspondence.", "result": "Extensive experiments show RoMa's superiority on the proposed benchmark.", "conclusion": "RoMa effectively addresses PTM challenges, demonstrating potential for real-world applications."}}
{"id": "2506.02802", "pdf": "https://arxiv.org/pdf/2506.02802", "abs": "https://arxiv.org/abs/2506.02802", "authors": ["Andr\u00e1s Strausz", "Niels Pardon", "Ioana Giurgiu"], "title": "A Learned Cost Model-based Cross-engine Optimizer for SQL Workloads", "categories": ["cs.DB", "cs.LG"], "comment": "6 pages", "summary": "Lakehouse systems enable the same data to be queried with multiple execution\nengines. However, selecting the engine best suited to run a SQL query still\nrequires a priori knowledge of the query computational requirements and an\nengine capability, a complex and manual task that only becomes more difficult\nwith the emergence of new engines and workloads. In this paper, we address this\nlimitation by proposing a cross-engine optimizer that can automate engine\nselection for diverse SQL queries through a learned cost model. Optimized with\nhints, a query plan is used for query cost prediction and routing. Cost\nprediction is formulated as a multi-task learning problem, and multiple\npredictor heads, corresponding to different engines and provisionings, are used\nin the model architecture. This eliminates the need to train engine-specific\nmodels and allows the flexible addition of new engines at a minimal fine-tuning\ncost. Results on various databases and engines show that using a query\noptimized logical plan for cost estimation decreases the average Q-error by\neven 12.6% over using unoptimized plans as input. Moreover, the proposed\ncross-engine optimizer reduces the total workload runtime by up to 25.2% in a\nzero-shot setting and 30.4% in a few-shot setting when compared to random\nrouting.", "AI": {"tldr": "A cross-engine optimizer automates SQL query engine selection using a learned cost model, improving accuracy and reducing workload runtime.", "motivation": "Manual engine selection for SQL queries in Lakehouse systems is complex and inefficient, especially with new engines and workloads.", "method": "Proposes a learned cost model with multi-task learning for cost prediction and routing, using optimized query plans.", "result": "Reduces Q-error by 12.6% and workload runtime by up to 30.4% compared to random routing.", "conclusion": "The cross-engine optimizer effectively automates and improves engine selection, enhancing performance and scalability."}}
{"id": "2402.11871", "pdf": "https://arxiv.org/pdf/2402.11871", "abs": "https://arxiv.org/abs/2402.11871", "authors": ["Naman Shah", "Jayesh Nagpal", "Siddharth Srivastava"], "title": "From Real World to Logic and Back: Learning Generalizable Relational Concepts For Long Horizon Robot Planning", "categories": ["cs.RO", "cs.AI"], "comment": null, "summary": "Humans efficiently generalize from limited demonstrations, but robots still\nstruggle to transfer learned knowledge to complex, unseen tasks with longer\nhorizons and increased complexity. We propose the first known method enabling\nrobots to autonomously invent relational concepts directly from small sets of\nunannotated, unsegmented demonstrations. The learned symbolic concepts are\ngrounded into logic-based world models, facilitating efficient zero-shot\ngeneralization to significantly more complex tasks. Empirical results\ndemonstrate that our approach achieves performance comparable to hand-crafted\nmodels, successfully scaling execution horizons and handling up to 18 times\nmore objects than seen in training, providing the first autonomous framework\nfor learning transferable symbolic abstractions from raw robot trajectories.", "AI": {"tldr": "A method for robots to autonomously learn relational concepts from unannotated demonstrations, enabling zero-shot generalization to more complex tasks.", "motivation": "Robots struggle with transferring learned knowledge to unseen, complex tasks, unlike humans who generalize efficiently from limited demonstrations.", "method": "Proposes a framework where robots invent symbolic concepts from raw, unsegmented demonstrations, grounding them into logic-based world models.", "result": "Achieves performance comparable to hand-crafted models, scaling to tasks with longer horizons and handling 18x more objects than in training.", "conclusion": "Provides the first autonomous framework for learning transferable symbolic abstractions from raw robot trajectories."}}
{"id": "2412.15628", "pdf": "https://arxiv.org/pdf/2412.15628", "abs": "https://arxiv.org/abs/2412.15628", "authors": ["Mengyu Ye", "Tatsuki Kuribayashi", "Goro Kobayashi", "Jun Suzuki"], "title": "Can Input Attributions Explain Inductive Reasoning in In-Context Learning?", "categories": ["cs.CL"], "comment": "Findings of ACL 2025", "summary": "Interpreting the internal process of neural models has long been a challenge.\nThis challenge remains relevant in the era of large language models (LLMs) and\nin-context learning (ICL); for example, ICL poses a new issue of interpreting\nwhich example in the few-shot examples contributed to identifying/solving the\ntask. To this end, in this paper, we design synthetic diagnostic tasks of\ninductive reasoning, inspired by the generalization tests typically adopted in\npsycholinguistics. Here, most in-context examples are ambiguous w.r.t. their\nunderlying rule, and one critical example disambiguates it. The question is\nwhether conventional input attribution (IA) methods can track such a reasoning\nprocess, i.e., identify the influential example, in ICL. Our experiments\nprovide several practical findings; for example, a certain simple IA method\nworks the best, and the larger the model, the generally harder it is to\ninterpret the ICL with gradient-based IA methods.", "AI": {"tldr": "The paper investigates whether input attribution (IA) methods can identify influential examples in in-context learning (ICL) for large language models (LLMs), using synthetic diagnostic tasks of inductive reasoning.", "motivation": "Understanding the internal reasoning process of LLMs during ICL, especially identifying which few-shot examples contribute to task solving, remains a challenge.", "method": "The authors design synthetic diagnostic tasks with ambiguous examples and one critical disambiguating example, then test conventional IA methods to track reasoning processes.", "result": "A simple IA method performs best, and gradient-based IA methods struggle more with larger models.", "conclusion": "The study highlights limitations of current IA methods for interpreting ICL in LLMs, especially as models scale."}}
{"id": "2404.04924", "pdf": "https://arxiv.org/pdf/2404.04924", "abs": "https://arxiv.org/abs/2404.04924", "authors": ["Dongjing Shan", "guiqiang chen"], "title": "GvT: A Graph-based Vision Transformer with Talking-Heads Utilizing Sparsity, Trained from Scratch on Small Datasets", "categories": ["cs.CV", "cs.AI"], "comment": "The authors withdraw this article to revise and improve the paper\n  through substantial adjustments and rewriting", "summary": "Vision Transformers (ViTs) have achieved impressive results in large-scale\nimage classification. However, when training from scratch on small datasets,\nthere is still a significant performance gap between ViTs and Convolutional\nNeural Networks (CNNs), which is attributed to the lack of inductive bias. To\naddress this issue, we propose a Graph-based Vision Transformer (GvT) that\nutilizes graph convolutional projection and graph-pooling. In each block,\nqueries and keys are calculated through graph convolutional projection based on\nthe spatial adjacency matrix, while dot-product attention is used in another\ngraph convolution to generate values. When using more attention heads, the\nqueries and keys become lower-dimensional, making their dot product an\nuninformative matching function. To overcome this low-rank bottleneck in\nattention heads, we employ talking-heads technology based on bilinear pooled\nfeatures and sparse selection of attention tensors. This allows interaction\namong filtered attention scores and enables each attention mechanism to depend\non all queries and keys. Additionally, we apply graph-pooling between two\nintermediate blocks to reduce the number of tokens and aggregate semantic\ninformation more effectively. Our experimental results show that GvT produces\ncomparable or superior outcomes to deep convolutional networks and surpasses\nvision transformers without pre-training on large datasets. The code for our\nproposed model is publicly available on the website.", "AI": {"tldr": "The paper proposes a Graph-based Vision Transformer (GvT) to bridge the performance gap between ViTs and CNNs on small datasets by incorporating graph convolutional projection and pooling, along with talking-heads technology to address low-rank bottlenecks.", "motivation": "ViTs underperform CNNs on small datasets due to lack of inductive bias, prompting the need for a solution.", "method": "GvT uses graph convolutional projection, graph-pooling, and talking-heads technology to enhance attention mechanisms and token aggregation.", "result": "GvT matches or outperforms CNNs and surpasses standard ViTs on small datasets without pre-training.", "conclusion": "GvT effectively addresses ViTs' limitations on small datasets, offering a competitive alternative to CNNs."}}
{"id": "2506.02825", "pdf": "https://arxiv.org/pdf/2506.02825", "abs": "https://arxiv.org/abs/2506.02825", "authors": ["Tong Qi", "Vera Andersson", "Peter Viechnicki", "Vince Lyzinski"], "title": "Asymptotically perfect seeded graph matching without edge correlation (and applications to inference)", "categories": ["stat.ML", "cs.LG"], "comment": "10 figures, 35 pages", "summary": "We present the OmniMatch algorithm for seeded multiple graph matching. In the\nsetting of $d$-dimensional Random Dot Product Graphs (RDPG), we prove that\nunder mild assumptions, OmniMatch with $s$ seeds asymptotically and efficiently\nperfectly aligns $O(s^{\\alpha})$ unseeded vertices -- for $\\alpha<2\\wedge d/4$\n-- across multiple networks even in the presence of no edge correlation. We\ndemonstrate the effectiveness of our algorithm across numerous simulations and\nin the context of shuffled graph hypothesis testing. In the shuffled testing\nsetting, testing power is lost due to the misalignment/shuffling of vertices\nacross graphs, and we demonstrate the capacity of OmniMatch to correct for\nmisaligned vertices prior to testing and hence recover the lost testing power.\nWe further demonstrate the algorithm on a pair of data examples from\nconnectomics and machine translation.", "AI": {"tldr": "OmniMatch is an algorithm for seeded multiple graph matching, proven to efficiently align vertices across networks under mild assumptions, even without edge correlation. It shows effectiveness in simulations and applications like shuffled graph hypothesis testing, connectomics, and machine translation.", "motivation": "The paper aims to address the challenge of aligning vertices across multiple networks, particularly in scenarios like shuffled graph hypothesis testing where misalignment reduces testing power.", "method": "The OmniMatch algorithm is introduced for seeded multiple graph matching in the context of d-dimensional Random Dot Product Graphs (RDPG). It uses s seeds to asymptotically and efficiently align unseeded vertices.", "result": "OmniMatch successfully aligns O(s^\u03b1) unseeded vertices (for \u03b1<2\u2227d/4) across networks, even without edge correlation, and recovers lost testing power in shuffled graph hypothesis testing.", "conclusion": "OmniMatch is effective for vertex alignment in multiple networks, with demonstrated utility in simulations and real-world applications like connectomics and machine translation."}}
{"id": "2404.16873", "pdf": "https://arxiv.org/pdf/2404.16873", "abs": "https://arxiv.org/abs/2404.16873", "authors": ["Anselm Paulus", "Arman Zharmagambetov", "Chuan Guo", "Brandon Amos", "Yuandong Tian"], "title": "AdvPrompter: Fast Adaptive Adversarial Prompting for LLMs", "categories": ["cs.CR", "cs.AI", "cs.CL", "cs.LG"], "comment": "Accepted to ICML 2025. Code is available at\n  http://github.com/facebookresearch/advprompter", "summary": "Large Language Models (LLMs) are vulnerable to jailbreaking attacks that lead\nto generation of inappropriate or harmful content. Manual red-teaming requires\na time-consuming search for adversarial prompts, whereas automatic adversarial\nprompt generation often leads to semantically meaningless attacks that do not\nscale well. In this paper, we present a novel method that uses another LLM,\ncalled AdvPrompter, to generate human-readable adversarial prompts in seconds.\nAdvPrompter, which is trained using an alternating optimization algorithm,\ngenerates suffixes that veil the input instruction without changing its\nmeaning, such that the TargetLLM is lured to give a harmful response.\nExperimental results on popular open source TargetLLMs show highly competitive\nresults on the AdvBench and HarmBench datasets, that also transfer to\nclosed-source black-box LLMs. We also show that training on adversarial\nsuffixes generated by AdvPrompter is a promising strategy for improving the\nrobustness of LLMs to jailbreaking attacks.", "AI": {"tldr": "A novel method, AdvPrompter, uses an LLM to generate human-readable adversarial prompts quickly, improving jailbreaking attack robustness.", "motivation": "LLMs are vulnerable to jailbreaking attacks, and current methods (manual or automatic) are inefficient or ineffective.", "method": "AdvPrompter, trained via alternating optimization, generates adversarial suffixes that trick TargetLLMs into harmful responses.", "result": "Highly competitive results on AdvBench and HarmBench datasets, with transferability to black-box LLMs.", "conclusion": "AdvPrompter is effective for adversarial prompt generation and can enhance LLM robustness against jailbreaking."}}
{"id": "2412.17063", "pdf": "https://arxiv.org/pdf/2412.17063", "abs": "https://arxiv.org/abs/2412.17063", "authors": ["Esther Shizgal", "Eitan Wagner", "Renana Keydar", "Omri Abend"], "title": "Computational Analysis of Character Development in Holocaust Testimonies", "categories": ["cs.CL"], "comment": null, "summary": "This work presents a computational approach to analyze character development\nalong the narrative timeline. The analysis characterizes the inner and outer\nchanges the protagonist undergoes within a narrative, and the interplay between\nthem. We consider transcripts of Holocaust survivor testimonies as a test case,\neach telling the story of an individual in first-person terms. We focus on the\nsurvivor's religious trajectory, examining the evolution of their disposition\ntoward religious belief and practice along the testimony. Clustering the\nresulting trajectories in the dataset, we identify common sequences in the\ndata. Our findings highlight multiple common structures of religiosity across\nthe narratives: in terms of belief, most present a constant disposition, while\nfor practice, most present an oscillating structure, serving as valuable\nmaterial for historical and sociological research. This work demonstrates the\npotential of natural language processing techniques for analyzing character\nevolution through thematic trajectories in narratives.", "AI": {"tldr": "A computational method analyzes character development in Holocaust survivor testimonies, focusing on religious trajectories to identify common patterns in belief and practice.", "motivation": "To explore how protagonists' inner and outer changes, especially in religiosity, evolve over narratives, using Holocaust survivor testimonies as a case study.", "method": "Analyzes first-person testimonies, clustering religious trajectories to identify common sequences in belief and practice.", "result": "Found constant belief dispositions and oscillating practice structures, providing insights for historical and sociological research.", "conclusion": "Shows NLP's potential for analyzing character evolution via thematic trajectories in narratives."}}
{"id": "2404.05253", "pdf": "https://arxiv.org/pdf/2404.05253", "abs": "https://arxiv.org/abs/2404.05253", "authors": ["Xu Wu", "XianXu Hou", "Zhihui Lai", "Jie Zhou", "Ya-nan Zhang", "Witold Pedrycz", "Linlin Shen"], "title": "CodeEnhance: A Codebook-Driven Approach for Low-Light Image Enhancement", "categories": ["cs.CV"], "comment": "10 pages, 13 figures", "summary": "Low-light image enhancement (LLIE) aims to improve low-illumination images.\nHowever, existing methods face two challenges: (1) uncertainty in restoration\nfrom diverse brightness degradations; (2) loss of texture and color information\ncaused by noise suppression and light enhancement. In this paper, we propose a\nnovel enhancement approach, CodeEnhance, by leveraging quantized priors and\nimage refinement to address these challenges. In particular, we reframe LLIE as\nlearning an image-to-code mapping from low-light images to discrete codebook,\nwhich has been learned from high-quality images. To enhance this process, a\nSemantic Embedding Module (SEM) is introduced to integrate semantic information\nwith low-level features, and a Codebook Shift (CS) mechanism, designed to adapt\nthe pre-learned codebook to better suit the distinct characteristics of our\nlow-light dataset. Additionally, we present an Interactive Feature\nTransformation (IFT) module to refine texture and color information during\nimage reconstruction, allowing for interactive enhancement based on user\npreferences. Extensive experiments on both real-world and synthetic benchmarks\ndemonstrate that the incorporation of prior knowledge and controllable\ninformation transfer significantly enhances LLIE performance in terms of\nquality and fidelity. The proposed CodeEnhance exhibits superior robustness to\nvarious degradations, including uneven illumination, noise, and color\ndistortion.", "AI": {"tldr": "CodeEnhance improves low-light image enhancement by using quantized priors and interactive refinement, addressing uncertainty and information loss.", "motivation": "Existing methods struggle with diverse brightness degradations and loss of texture/color information during enhancement.", "method": "Proposes CodeEnhance, leveraging image-to-code mapping, Semantic Embedding Module (SEM), Codebook Shift (CS), and Interactive Feature Transformation (IFT).", "result": "Outperforms benchmarks in quality and fidelity, showing robustness to uneven illumination, noise, and color distortion.", "conclusion": "CodeEnhance effectively enhances low-light images by integrating prior knowledge and controllable refinement."}}
{"id": "2506.02841", "pdf": "https://arxiv.org/pdf/2506.02841", "abs": "https://arxiv.org/abs/2506.02841", "authors": ["Tom Danino", "Nahum Shimkin"], "title": "Ensemble-MIX: Enhancing Sample Efficiency in Multi-Agent RL Using Ensemble Methods", "categories": ["eess.SY", "cs.LG", "cs.SY"], "comment": null, "summary": "Multi-agent reinforcement learning (MARL) methods have achieved\nstate-of-the-art results on a range of multi-agent tasks. Yet, MARL algorithms\ntypically require significantly more environment interactions than their\nsingle-agent counterparts to converge, a problem exacerbated by the difficulty\nin exploring over a large joint action space and the high variance intrinsic to\nMARL environments. To tackle these issues, we propose a novel algorithm that\ncombines a decomposed centralized critic with decentralized ensemble learning,\nincorporating several key contributions. The main component in our scheme is a\nselective exploration method that leverages ensemble kurtosis. We extend the\nglobal decomposed critic with a diversity-regularized ensemble of individual\ncritics and utilize its excess kurtosis to guide exploration toward\nhigh-uncertainty states and actions. To improve sample efficiency, we train the\ncentralized critic with a novel truncated variation of the TD($\\lambda$)\nalgorithm, enabling efficient off-policy learning with reduced variance. On the\nactor side, our suggested algorithm adapts the mixed samples approach to MARL,\nmixing on-policy and off-policy loss functions for training the actors. This\napproach balances between stability and efficiency and outperforms purely\noff-policy learning. The evaluation shows our method outperforms\nstate-of-the-art baselines on standard MARL benchmarks, including a variety of\nSMAC II maps.", "AI": {"tldr": "A novel MARL algorithm combines decomposed centralized critics with decentralized ensemble learning, using selective exploration and truncated TD(\u03bb) for improved efficiency and performance.", "motivation": "MARL algorithms require excessive environment interactions and struggle with exploration in large joint action spaces and high variance.", "method": "Uses a decomposed centralized critic with ensemble learning, selective exploration via kurtosis, truncated TD(\u03bb), and mixed on/off-policy actor training.", "result": "Outperforms state-of-the-art baselines on MARL benchmarks, including SMAC II maps.", "conclusion": "The proposed method effectively addresses MARL challenges, improving sample efficiency and performance."}}
{"id": "2405.15991", "pdf": "https://arxiv.org/pdf/2405.15991", "abs": "https://arxiv.org/abs/2405.15991", "authors": ["Xuesong Wang", "He Zhao", "Edwin V. Bonilla"], "title": "R\u00e9nyi Neural Processes", "categories": ["cs.LG", "cs.AI", "stat.ML"], "comment": null, "summary": "Neural Processes (NPs) are deep probabilistic models that represent\nstochastic processes by conditioning their prior distributions on a set of\ncontext points. Despite their advantages in uncertainty estimation for complex\ndistributions, NPs enforce parameterization coupling between the conditional\nprior model and the posterior model. We show that this coupling amounts to\nprior misspecification and revisit the NP objective to address this issue. More\nspecifically, we propose R\\'enyi Neural Processes (RNP), a method that replaces\nthe standard KL divergence with the R\\'enyi divergence, dampening the effects\nof the misspecified prior during posterior updates. We validate our approach\nacross multiple benchmarks including regression and image inpainting tasks, and\nshow significant performance improvements of RNPs in real-world problems. Our\nextensive experiments show consistently better log-likelihoods over\nstate-of-the-art NP models.", "AI": {"tldr": "RNPs improve Neural Processes by addressing prior misspecification using R\u00e9nyi divergence, outperforming state-of-the-art models in benchmarks.", "motivation": "Neural Processes (NPs) suffer from prior misspecification due to parameterization coupling, limiting their performance.", "method": "Proposed R\u00e9nyi Neural Processes (RNPs) replace KL divergence with R\u00e9nyi divergence to mitigate prior misspecification effects.", "result": "RNPs achieve better log-likelihoods and performance in regression and image inpainting tasks compared to NPs.", "conclusion": "RNPs effectively address prior misspecification in NPs, demonstrating superior performance in real-world applications."}}
{"id": "2412.17451", "pdf": "https://arxiv.org/pdf/2412.17451", "abs": "https://arxiv.org/abs/2412.17451", "authors": ["Wei Liu", "Junlong Li", "Xiwen Zhang", "Fan Zhou", "Yu Cheng", "Junxian He"], "title": "Diving into Self-Evolving Training for Multimodal Reasoning", "categories": ["cs.CL", "cs.AI", "cs.CV", "cs.LG"], "comment": "ICML 2025, Project Page: https://mstar-lmm.github.io", "summary": "Self-evolving trainin--where models iteratively learn from their own\noutputs--has emerged as a key approach for complex reasoning tasks, addressing\nthe scarcity of high-quality chain-of-thought data. However, its effectiveness\nin multimodal reasoning, a domain more intricate than text-only reasoning,\nremains underexplored, and the understanding of critical factors in this\ntraining paradigm remains limited. Furthermore, a central challenge for this\ntraining method is performance saturation, which impedes further improvements\nand scalability. Inspired by reinforcement learning (RL), in this paper, we\nreframe self-evolving training for multimodal reasoning through the lens of RL,\nidentifying three pivotal factors: Training Method, Reward Model, and Prompt\nVariation. Through systematic analysis, we establish relatively optimal design\nprinciples that significantly enhance multimodal reasoning capabilities.\nMoreover, delving deeper into training dynamics, we uncover the roots of\nsaturation and propose a new automatic balancing mechanism to mitigate this\nlimitation. Building on these insights, we propose M-STAR (Multimodal\nSelf-evolving Training for Reasoning), a framework that achieves consistent\nperformance gains across models of varying sizes and diverse benchmarks. All\nresources are made publicly available at https://mstar-lmm.github.io.", "AI": {"tldr": "The paper introduces M-STAR, a framework for self-evolving training in multimodal reasoning, addressing performance saturation and optimizing design principles inspired by reinforcement learning.", "motivation": "The scarcity of high-quality chain-of-thought data and the underexplored effectiveness of self-evolving training in multimodal reasoning motivated this work.", "method": "The authors reframe self-evolving training through reinforcement learning, focusing on Training Method, Reward Model, and Prompt Variation, and propose an automatic balancing mechanism to mitigate saturation.", "result": "M-STAR achieves consistent performance gains across models of varying sizes and diverse benchmarks.", "conclusion": "The framework enhances multimodal reasoning capabilities and addresses saturation, with all resources made publicly available."}}
{"id": "2405.02962", "pdf": "https://arxiv.org/pdf/2405.02962", "abs": "https://arxiv.org/abs/2405.02962", "authors": ["Juncheng Hu", "Ximing Xing", "Jing Zhang", "Qian Yu"], "title": "VectorPainter: Advanced Stylized Vector Graphics Synthesis Using Stroke-Style Priors", "categories": ["cs.CV"], "comment": "Accepted by 2025 IEEE International Conference on Multimedia and Expo\n  (ICME). IEEE, 2025. Project page:\n  https://hjc-owo.github.io/VectorPainterProject/", "summary": "We introduce VectorPainter, a novel framework designed for reference-guided\ntext-to-vector-graphics synthesis. Based on our observation that the style of\nstrokes can be an important aspect to distinguish different artists, our method\nreforms the task into synthesize a desired vector graphics by rearranging\nstylized strokes, which are vectorized from the reference images. Specifically,\nour method first converts the pixels of the reference image into a series of\nvector strokes, and then generates a vector graphic based on the input text\ndescription by optimizing the positions and colors of these vector strokes. To\nprecisely capture the style of the reference image in the vectorized strokes,\nwe propose an innovative vectorization method that employs an imitation\nlearning strategy. To preserve the style of the strokes throughout the\ngeneration process, we introduce a style-preserving loss function. Extensive\nexperiments have been conducted to demonstrate the superiority of our approach\nover existing works in stylized vector graphics synthesis, as well as the\neffectiveness of the various components of our method.", "AI": {"tldr": "VectorPainter is a framework for text-to-vector-graphics synthesis using stylized strokes from reference images, optimizing their positions and colors to match text descriptions.", "motivation": "The style of strokes distinguishes artists, so the task is reformulated to synthesize vector graphics by rearranging stylized strokes from references.", "method": "Converts reference image pixels to vector strokes, optimizes their positions/colors for text descriptions, and uses imitation learning for style capture and a style-preserving loss.", "result": "Superior performance in stylized vector graphics synthesis, with effective components validated through experiments.", "conclusion": "VectorPainter excels in synthesizing stylized vector graphics by leveraging reference-guided stroke rearrangement and style preservation."}}
{"id": "2506.02849", "pdf": "https://arxiv.org/pdf/2506.02849", "abs": "https://arxiv.org/abs/2506.02849", "authors": ["Alejandro Sanchez Roncero", "Olov Andersson", "Petter Ogren"], "title": "Learned Controllers for Agile Quadrotors in Pursuit-Evasion Games", "categories": ["cs.RO", "cs.LG"], "comment": null, "summary": "The increasing proliferation of small UAVs in civilian and military airspace\nhas raised critical safety and security concerns, especially when unauthorized\nor malicious drones enter restricted zones. In this work, we present a\nreinforcement learning (RL) framework for agile 1v1 quadrotor pursuit-evasion.\nWe train neural network policies to command body rates and collective thrust,\nenabling high-speed pursuit and evasive maneuvers that fully exploit the\nquadrotor's nonlinear dynamics. To mitigate nonstationarity and catastrophic\nforgetting during adversarial co-training, we introduce an Asynchronous\nMulti-Stage Population-Based (AMSPB) algorithm where, at each stage, either the\npursuer or evader learns against a sampled opponent drawn from a growing\npopulation of past and current policies. This continual learning setup ensures\nmonotonic performance improvement and retention of earlier strategies. Our\nresults show that (i) rate-based policies achieve significantly higher capture\nrates and peak speeds than velocity-level baselines, and (ii) AMSPB yields\nstable, monotonic gains against a suite of benchmark opponents.", "AI": {"tldr": "A reinforcement learning framework for agile quadrotor pursuit-evasion, using an Asynchronous Multi-Stage Population-Based algorithm to improve performance and strategy retention.", "motivation": "Address safety and security concerns of unauthorized drones by developing effective pursuit-evasion strategies for quadrotors.", "method": "Train neural network policies for body rates and thrust, using AMSPB to co-train pursuer and evader against a population of past policies.", "result": "Rate-based policies outperform velocity-level baselines in capture rates and speed; AMSPB ensures stable, monotonic performance gains.", "conclusion": "The RL framework and AMSPB algorithm effectively enhance quadrotor pursuit-evasion, addressing nonstationarity and catastrophic forgetting."}}
{"id": "2406.03747", "pdf": "https://arxiv.org/pdf/2406.03747", "abs": "https://arxiv.org/abs/2406.03747", "authors": ["Devichand Budagam", "Azamat Zhanatuly Imanbayev", "Iskander Rafailovich Akhmetov", "Aleksandr Sinitca", "Sergey Antonov", "Dmitrii Kaplun"], "title": "OralBBNet: Spatially Guided Dental Segmentation of Panoramic X-Rays with Bounding Box Priors", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": "Under Review, Biomedical Signal Processing Control", "summary": "Teeth segmentation and recognition play a vital role in a variety of dental\napplications and diagnostic procedures. The integration of deep learning models\nhas facilitated the development of precise and automated segmentation methods.\nAlthough prior research has explored teeth segmentation, not many methods have\nsuccessfully performed tooth segmentation and detection simultaneously. This\nstudy presents UFBA-425, a dental dataset derived from the UFBA-UESC dataset,\nfeaturing bounding box and polygon annotations for 425 panoramic dental X-rays.\nAdditionally, this work introduces OralBBNet, an architecture featuring\ndistinct segmentation and detection heads as U-Net and YOLOv8, respectively.\nOralBBNet is designed to improve the accuracy and robustness of tooth\nclassification and segmentation on panoramic X-rays by leveraging the\ncomplementary strengths of U-Net and YOLOv8. Our approach achieved a 1-3%\nimprovement in mean average precision (mAP) for teeth detection compared to\nexisting techniques and a 15-20% improvement in the dice score for teeth\nsegmentation over U-Net over various tooth categories and 2-4% improvement in\nthe dice score when compared with other segmentation architectures. The results\nof this study establish a foundation for the wider implementation of object\ndetection models in dental diagnostics.", "AI": {"tldr": "The paper introduces UFBA-425, a dental dataset, and OralBBNet, a model combining U-Net and YOLOv8 for simultaneous teeth segmentation and detection, showing improved accuracy over existing methods.", "motivation": "To address the lack of methods for simultaneous teeth segmentation and detection in dental diagnostics, leveraging deep learning for precision.", "method": "OralBBNet integrates U-Net for segmentation and YOLOv8 for detection, tested on the UFBA-425 dataset with 425 annotated X-rays.", "result": "Achieved 1-3% mAP improvement in detection and 15-20% dice score improvement in segmentation over U-Net, outperforming other architectures.", "conclusion": "The study advances dental diagnostics by demonstrating the effectiveness of combining segmentation and detection models."}}
{"id": "2412.17533", "pdf": "https://arxiv.org/pdf/2412.17533", "abs": "https://arxiv.org/abs/2412.17533", "authors": ["Anna Ko\u0142os", "Katarzyna Lorenc", "Emilia Wi\u015bnios", "Agnieszka Karli\u0144ska"], "title": "Behind Closed Words: Creating and Investigating the forePLay Annotated Dataset for Polish Erotic Discourse", "categories": ["cs.CL"], "comment": "Accepted for ACL 2025 Main Conference", "summary": "The surge in online content has created an urgent demand for robust detection\nsystems, especially in non-English contexts where current tools demonstrate\nsignificant limitations. We present forePLay, a novel Polish language dataset\nfor erotic content detection, featuring over 24k annotated sentences with a\nmultidimensional taxonomy encompassing ambiguity, violence, and social\nunacceptability dimensions. Our comprehensive evaluation demonstrates that\nspecialized Polish language models achieve superior performance compared to\nmultilingual alternatives, with transformer-based architectures showing\nparticular strength in handling imbalanced categories. The dataset and\naccompanying analysis establish essential frameworks for developing\nlinguistically-aware content moderation systems, while highlighting critical\nconsiderations for extending such capabilities to morphologically complex\nlanguages.", "AI": {"tldr": "forePLay introduces a Polish dataset for erotic content detection, showing specialized language models outperform multilingual ones, especially transformers.", "motivation": "Address limitations of current tools in non-English contexts, particularly for Polish erotic content detection.", "method": "Developed a Polish dataset (forePLay) with 24k annotated sentences and a multidimensional taxonomy. Evaluated specialized vs. multilingual models.", "result": "Specialized Polish models, especially transformers, perform better than multilingual alternatives.", "conclusion": "The dataset and analysis provide a framework for linguistically-aware moderation, with insights for morphologically complex languages."}}
{"id": "2406.14239", "pdf": "https://arxiv.org/pdf/2406.14239", "abs": "https://arxiv.org/abs/2406.14239", "authors": ["Lilian Hollard", "Lucas Mohimont", "Nathalie Gaveau", "Luiz Angelo Steffenel"], "title": "LeYOLO, New Embedded Architecture for Object Detection", "categories": ["cs.CV"], "comment": "https://crv.pubpub.org/pub/sae4lpdf", "summary": "Efficient computation in deep neural networks is crucial for real-time object\ndetection. However, recent advancements primarily result from improved\nhigh-performing hardware rather than improving parameters and FLOP efficiency.\nThis is especially evident in the latest YOLO architectures, where speed is\nprioritized over lightweight design. As a result, object detection models\noptimized for low-resource environments like microcontrollers have received\nless attention. For devices with limited computing power, existing solutions\nprimarily rely on SSDLite or combinations of low-parameter classifiers,\ncreating a noticeable gap between YOLO-like architectures and truly efficient\nlightweight detectors. This raises a key question: Can a model optimized for\nparameter and FLOP efficiency achieve accuracy levels comparable to mainstream\nYOLO models? To address this, we introduce two key contributions to object\ndetection models using MSCOCO as a base validation set. First, we propose\nLeNeck, a general-purpose detection framework that maintains inference speed\ncomparable to SSDLite while significantly improving accuracy and reducing\nparameter count. Second, we present LeYOLO, an efficient object detection model\ndesigned to enhance computational efficiency in YOLO-based architectures.\nLeYOLO effectively bridges the gap between SSDLite-based detectors and YOLO\nmodels, offering high accuracy in a model as compact as MobileNets. Both\ncontributions are particularly well-suited for mobile, embedded, and\nultra-low-power devices, including microcontrollers, where computational\nefficiency is critical.", "AI": {"tldr": "The paper introduces LeNeck and LeYOLO, two efficient object detection models for low-resource environments, aiming to bridge the gap between lightweight detectors and high-performance YOLO architectures.", "motivation": "Recent advancements in object detection prioritize speed over lightweight design, leaving a gap for efficient models in low-resource environments. The paper addresses whether parameter and FLOP-efficient models can match YOLO's accuracy.", "method": "Proposes LeNeck, a general-purpose detection framework, and LeYOLO, an efficient YOLO-based model, both validated on MSCOCO.", "result": "LeNeck matches SSDLite's speed while improving accuracy and reducing parameters. LeYOLO bridges the gap between SSDLite and YOLO, offering high accuracy in compact models.", "conclusion": "Both models are suitable for mobile, embedded, and ultra-low-power devices, addressing the need for computational efficiency in resource-constrained environments."}}
{"id": "2506.02881", "pdf": "https://arxiv.org/pdf/2506.02881", "abs": "https://arxiv.org/abs/2506.02881", "authors": ["Brian M Cho", "Aur\u00e9lien Bibaut", "Nathan Kallus"], "title": "Simulation-Based Inference for Adaptive Experiments", "categories": ["stat.ME", "cs.LG", "stat.ML"], "comment": null, "summary": "Multi-arm bandit experimental designs are increasingly being adopted over\nstandard randomized trials due to their potential to improve outcomes for study\nparticipants, enable faster identification of the best-performing options,\nand/or enhance the precision of estimating key parameters. Current approaches\nfor inference after adaptive sampling either rely on asymptotic normality under\nrestricted experiment designs or underpowered martingale concentration\ninequalities that lead to weak power in practice. To bypass these limitations,\nwe propose a simulation-based approach for conducting hypothesis tests and\nconstructing confidence intervals for arm specific means and their differences.\nOur simulation-based approach uses positively biased nuisances to generate\nadditional trajectories of the experiment, which we call \\textit{simulation\nwith optimism}. Using these simulations, we characterize the distribution\npotentially non-normal sample mean test statistic to conduct inference. We\nprovide guarantees for (i) asymptotic type I error control, (ii) convergence of\nour confidence intervals, and (iii) asymptotic strong consistency of our\nestimator over a wide variety of common bandit designs. Our empirical results\nshow that our approach achieves the desired coverage while reducing confidence\ninterval widths by up to 50%, with drastic improvements for arms not targeted\nby the design.", "AI": {"tldr": "The paper proposes a simulation-based method for inference in multi-arm bandit experiments, improving power and precision over existing approaches.", "motivation": "Current methods for inference in adaptive sampling are either limited by asymptotic normality or weak power, necessitating a more robust solution.", "method": "A simulation-based approach called 'simulation with optimism' uses positively biased nuisances to generate additional experiment trajectories, enabling non-normal sample mean inference.", "result": "The method ensures type I error control, convergence of confidence intervals, and strong consistency, reducing interval widths by up to 50%.", "conclusion": "The proposed approach outperforms existing methods, offering better coverage and precision, especially for less-targeted arms."}}
{"id": "2409.14644", "pdf": "https://arxiv.org/pdf/2409.14644", "abs": "https://arxiv.org/abs/2409.14644", "authors": ["Zixiang Xian", "Chenhui Cui", "Rubing Huang", "Chunrong Fang", "Zhenyu Chen"], "title": "An Effective Approach to Embedding Source Code by Combining Large Language and Sentence Embedding Models", "categories": ["cs.SE", "cs.AI"], "comment": null, "summary": "The advent of large language models (LLMs) has significantly advanced\nartificial intelligence (AI) in software engineering (SE), with source code\nembeddings playing a crucial role in tasks such as source code clone detection\nand source code clustering. However, existing methods for source code\nembedding, including those based on LLMs, often rely on costly supervised\ntraining or fine-tuning for domain adaptation. This paper proposes a novel\napproach to embedding source code by combining large language and sentence\nembedding models. This approach attempts to eliminate the need for\ntask-specific training or fine-tuning and to effectively address the issue of\nerroneous information commonly found in LLM-generated outputs. To evaluate the\nperformance of our proposed approach, we conducted a series of experiments on\nthree datasets with different programming languages by considering various LLMs\nand sentence embedding models. The experimental results have demonstrated the\neffectiveness and superiority of our approach over the state-of-the-art\nunsupervised approaches, such as SourcererCC, Code2vec, InferCode,\nTransformCode, and LLM2Vec. Our findings highlight the potential of our\napproach to advance the field of SE by providing robust and efficient solutions\nfor source code embedding tasks.", "AI": {"tldr": "A novel approach combines large language and sentence embedding models for source code embedding, eliminating costly supervised training and addressing LLM-generated errors, outperforming state-of-the-art unsupervised methods.", "motivation": "Existing source code embedding methods rely on expensive supervised training or fine-tuning, and LLM-generated outputs often contain errors.", "method": "Combines large language and sentence embedding models to avoid task-specific training or fine-tuning.", "result": "Outperforms state-of-the-art unsupervised methods like SourcererCC, Code2vec, InferCode, TransformCode, and LLM2Vec in experiments across three datasets.", "conclusion": "The approach offers robust and efficient solutions for source code embedding, advancing software engineering tasks."}}
{"id": "2501.02086", "pdf": "https://arxiv.org/pdf/2501.02086", "abs": "https://arxiv.org/abs/2501.02086", "authors": ["Bairu Hou", "Qibin Chen", "Jianyu Wang", "Guoli Yin", "Chong Wang", "Nan Du", "Ruoming Pang", "Shiyu Chang", "Tao Lei"], "title": "Instruction-Following Pruning for Large Language Models", "categories": ["cs.CL"], "comment": "ICML 2025", "summary": "With the rapid scaling of large language models (LLMs), structured pruning\nhas become a widely used technique to learn efficient, smaller models from\nlarger ones, delivering superior performance compared to training similarly\nsized models from scratch. In this paper, we move beyond the traditional static\npruning approach of determining a fixed pruning mask for a model, and propose a\ndynamic approach to structured pruning. In our method, the pruning mask is\ninput-dependent and adapts dynamically based on the information described in a\nuser instruction. Our approach, termed \"instruction-following pruning\",\nintroduces a sparse mask predictor that takes the user instruction as input and\ndynamically selects the most relevant model parameters for the given task. To\nidentify and activate effective parameters, we jointly optimize the sparse mask\npredictor and the LLM, leveraging both instruction-following data and the\npre-training corpus. Experimental results demonstrate the effectiveness of our\napproach on a wide range of evaluation benchmarks. For example, our 3B\nactivated model improves over the 3B dense model by 5-8 points of absolute\nmargin on domains such as math and coding, and rivals the performance of a 9B\nmodel.", "AI": {"tldr": "The paper introduces a dynamic structured pruning method for LLMs, where the pruning mask adapts based on user instructions, outperforming static pruning and dense models.", "motivation": "To improve efficiency and performance of pruned LLMs by moving beyond static pruning to a dynamic, input-dependent approach.", "method": "Proposes 'instruction-following pruning' with a sparse mask predictor that dynamically selects relevant parameters based on user instructions, jointly optimized with the LLM.", "result": "The 3B activated model outperforms the 3B dense model by 5-8 points in domains like math and coding, matching a 9B model's performance.", "conclusion": "Dynamic pruning based on user instructions enhances model efficiency and performance, offering superior results over traditional methods."}}
{"id": "2408.15127", "pdf": "https://arxiv.org/pdf/2408.15127", "abs": "https://arxiv.org/abs/2408.15127", "authors": ["Philipp Flotho", "Moritz Piening", "Anna Kukleva", "Gabriele Steidl"], "title": "T-FAKE: Synthesizing Thermal Images for Facial Landmarking", "categories": ["cs.CV"], "comment": "22 pages, 12 figures, Philipp Flotho and Moritz Piening share equal\n  contribution", "summary": "Facial analysis is a key component in a wide range of applications such as\nhealthcare, autonomous driving, and entertainment. Despite the availability of\nvarious facial RGB datasets, the thermal modality, which plays a crucial role\nin life sciences, medicine, and biometrics, has been largely overlooked. To\naddress this gap, we introduce the T-FAKE dataset, a new large-scale synthetic\nthermal dataset with sparse and dense landmarks. To facilitate the creation of\nthe dataset, we propose a novel RGB2Thermal loss function, which enables the\ndomain-adaptive transfer of RGB faces to thermal style. By utilizing the\nWasserstein distance between thermal and RGB patches and the statistical\nanalysis of clinical temperature distributions on faces, we ensure that the\ngenerated thermal images closely resemble real samples. Using RGB2Thermal style\ntransfer based on our RGB2Thermal loss function, we create the large-scale\nsynthetic thermal T-FAKE dataset with landmark and segmentation annotations.\nLeveraging our novel T-FAKE dataset, probabilistic landmark prediction, and\nlabel adaptation networks, we demonstrate significant improvements in landmark\ndetection methods on thermal images across different landmark conventions. Our\nmodels show excellent performance with both sparse 70-point landmarks and dense\n478-point landmark annotations. Moreover, our RGB2Thermal loss leads to notable\nresults in terms of perceptual evaluation and temperature prediction.", "AI": {"tldr": "The paper introduces T-FAKE, a synthetic thermal dataset with landmarks, using a novel RGB2Thermal loss for domain-adaptive transfer, improving thermal landmark detection.", "motivation": "Existing facial datasets lack thermal modality, crucial for healthcare and biometrics, prompting the creation of T-FAKE.", "method": "Proposes RGB2Thermal loss for style transfer, leveraging Wasserstein distance and clinical temperature statistics to generate realistic thermal images.", "result": "T-FAKE dataset enhances landmark detection on thermal images, showing strong performance with sparse and dense landmarks.", "conclusion": "The RGB2Thermal loss and T-FAKE dataset significantly advance thermal facial analysis, with applications in healthcare and biometrics."}}
{"id": "2410.06490", "pdf": "https://arxiv.org/pdf/2410.06490", "abs": "https://arxiv.org/abs/2410.06490", "authors": ["Jianqing Zhang", "Yang Liu", "Yang Hua", "Jian Cao", "Qiang Yang"], "title": "Adaptive Guidance for Local Training in Heterogeneous Federated Learning", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Model heterogeneity poses a significant challenge in Heterogeneous Federated\nLearning (HtFL). In scenarios with diverse model architectures, directly\naggregating model parameters is impractical, leading HtFL methods to\nincorporate an extra objective alongside the original local objective on each\nclient to facilitate collaboration. However, this often results in a mismatch\nbetween the extra and local objectives. To resolve this, we propose Federated\nLearning-to-Guide (FedL2G), a method that adaptively learns to guide local\ntraining in a federated manner, ensuring the added objective aligns with each\nclient's original goal. With theoretical guarantees, FedL2G utilizes only\nfirst-order derivatives w.r.t. model parameters, achieving a non-convex\nconvergence rate of O(1/T). We conduct extensive experiments across two data\nheterogeneity and six model heterogeneity settings, using 14 heterogeneous\nmodel architectures (e.g., CNNs and ViTs). The results show that FedL2G\nsignificantly outperforms seven state-of-the-art methods.", "AI": {"tldr": "FedL2G addresses model heterogeneity in Federated Learning by adaptively guiding local training to align objectives, achieving superior performance.", "motivation": "Model heterogeneity in Federated Learning causes mismatches between added and local objectives, hindering collaboration.", "method": "FedL2G adaptively learns to guide local training using first-order derivatives, ensuring alignment with original objectives.", "result": "FedL2G achieves a non-convex convergence rate of O(1/T) and outperforms seven state-of-the-art methods in experiments.", "conclusion": "FedL2G effectively resolves objective mismatches in heterogeneous Federated Learning, demonstrating strong theoretical and empirical performance."}}
{"id": "2501.02295", "pdf": "https://arxiv.org/pdf/2501.02295", "abs": "https://arxiv.org/abs/2501.02295", "authors": ["Yachao Zhao", "Bo Wang", "Yan Wang", "Dongming Zhao", "Ruifang He", "Yuexian Hou"], "title": "Explicit vs. Implicit: Investigating Social Bias in Large Language Models through Self-Reflection", "categories": ["cs.CL"], "comment": "Accepted by ACL 2025", "summary": "Large Language Models (LLMs) have been shown to exhibit various biases and\nstereotypes in their generated content. While extensive research has\ninvestigated biases in LLMs, prior work has predominantly focused on explicit\nbias, with minimal attention to implicit bias and the relation between these\ntwo forms of bias. This paper presents a systematic framework grounded in\nsocial psychology theories to investigate and compare explicit and implicit\nbiases in LLMs. We propose a novel self-reflection-based evaluation framework\nthat operates in two phases: first measuring implicit bias through simulated\npsychological assessment methods, then evaluating explicit bias by prompting\nLLMs to analyze their own generated content. Through extensive experiments on\nadvanced LLMs across multiple social dimensions, we demonstrate that LLMs\nexhibit a substantial inconsistency between explicit and implicit biases: while\nexplicit bias manifests as mild stereotypes, implicit bias exhibits strong\nstereotypes. We further investigate the underlying factors contributing to this\nexplicit-implicit bias inconsistency, examining the effects of training data\nscale, model size, and alignment techniques. Experimental results indicate that\nwhile explicit bias declines with increased training data and model size,\nimplicit bias exhibits a contrasting upward trend. Moreover, contemporary\nalignment methods effectively suppress explicit bias but show limited efficacy\nin mitigating implicit bias.", "AI": {"tldr": "The paper investigates explicit and implicit biases in LLMs, revealing a significant inconsistency between the two. It introduces a self-reflection-based framework to measure these biases and explores factors like training data, model size, and alignment techniques.", "motivation": "Prior research on LLM biases has focused mainly on explicit bias, neglecting implicit bias and its relation to explicit bias. This study aims to bridge this gap using social psychology theories.", "method": "A two-phase self-reflection framework: first measures implicit bias via simulated psychological assessments, then evaluates explicit bias by prompting LLMs to analyze their own outputs. Experiments are conducted across multiple social dimensions.", "result": "LLMs show strong implicit biases despite mild explicit biases. Explicit bias decreases with larger training data and models, while implicit bias increases. Alignment techniques reduce explicit bias but are less effective against implicit bias.", "conclusion": "The study highlights the need to address both explicit and implicit biases in LLMs, as current alignment methods are insufficient for mitigating implicit biases."}}
{"id": "2409.00304", "pdf": "https://arxiv.org/pdf/2409.00304", "abs": "https://arxiv.org/abs/2409.00304", "authors": ["Yuxiang Guo", "Faizan Siddiqui", "Yang Zhao", "Rama Chellappa", "Shao-Yuan Lo"], "title": "StimuVAR: Spatiotemporal Stimuli-aware Video Affective Reasoning with Multimodal Large Language Models", "categories": ["cs.CV"], "comment": "Paper is accepted by IJCV", "summary": "Predicting and reasoning how a video would make a human feel is crucial for\ndeveloping socially intelligent systems. Although Multimodal Large Language\nModels (MLLMs) have shown impressive video understanding capabilities, they\ntend to focus more on the semantic content of videos, often overlooking\nemotional stimuli. Hence, most existing MLLMs fall short in estimating viewers'\nemotional reactions and providing plausible explanations. To address this\nissue, we propose StimuVAR, a spatiotemporal Stimuli-aware framework for Video\nAffective Reasoning (VAR) with MLLMs. StimuVAR incorporates a two-level\nstimuli-aware mechanism: frame-level awareness and token-level awareness.\nFrame-level awareness involves sampling video frames with events that are most\nlikely to evoke viewers' emotions. Token-level awareness performs tube\nselection in the token space to make the MLLM concentrate on emotion-triggered\nspatiotemporal regions. Furthermore, we create VAR instruction data to perform\naffective training, steering MLLMs' reasoning strengths towards emotional focus\nand thereby enhancing their affective reasoning ability. To thoroughly assess\nthe effectiveness of VAR, we provide a comprehensive evaluation protocol with\nextensive metrics. StimuVAR is the first MLLM-based method for viewer-centered\nVAR. Experiments demonstrate its superiority in understanding viewers'\nemotional responses to videos and providing coherent and insightful\nexplanations. Our code is available at https://github.com/EthanG97/StimuVAR", "AI": {"tldr": "StimuVAR is a spatiotemporal stimuli-aware framework for video affective reasoning (VAR) with MLLMs, addressing their oversight of emotional stimuli by incorporating frame-level and token-level awareness mechanisms.", "motivation": "Existing MLLMs focus on video semantics but overlook emotional stimuli, limiting their ability to predict and explain viewers' emotional reactions.", "method": "StimuVAR uses a two-level stimuli-aware mechanism (frame-level and token-level awareness) and VAR instruction data to enhance MLLMs' affective reasoning.", "result": "Experiments show StimuVAR excels in understanding emotional responses and providing coherent explanations, outperforming existing methods.", "conclusion": "StimuVAR is the first MLLM-based method for viewer-centered VAR, demonstrating superior performance in affective reasoning."}}
{"id": "2506.02980", "pdf": "https://arxiv.org/pdf/2506.02980", "abs": "https://arxiv.org/abs/2506.02980", "authors": ["Xiaoqi Liu", "Dorian Baudry", "Julian Zimmert", "Patrick Rebeschini", "Arya Akhavan"], "title": "Non-stationary Bandit Convex Optimization: A Comprehensive Study", "categories": ["stat.ML", "cs.LG"], "comment": "32 pages, 1 figure", "summary": "Bandit Convex Optimization is a fundamental class of sequential\ndecision-making problems, where the learner selects actions from a continuous\ndomain and observes a loss (but not its gradient) at only one point per round.\nWe study this problem in non-stationary environments, and aim to minimize the\nregret under three standard measures of non-stationarity: the number of\nswitches $S$ in the comparator sequence, the total variation $\\Delta$ of the\nloss functions, and the path-length $P$ of the comparator sequence. We propose\na polynomial-time algorithm, Tilted Exponentially Weighted Average with\nSleeping Experts (TEWA-SE), which adapts the sleeping experts framework from\nonline convex optimization to the bandit setting. For strongly convex losses,\nwe prove that TEWA-SE is minimax-optimal with respect to known $S$ and $\\Delta$\nby establishing matching upper and lower bounds. By equipping TEWA-SE with the\nBandit-over-Bandit framework, we extend our analysis to environments with\nunknown non-stationarity measures. For general convex losses, we introduce a\nsecond algorithm, clipped Exploration by Optimization (cExO), based on\nexponential weights over a discretized action space. While not polynomial-time\ncomputable, this method achieves minimax-optimal regret with respect to known\n$S$ and $\\Delta$, and improves on the best existing bounds with respect to $P$.", "AI": {"tldr": "The paper introduces two algorithms, TEWA-SE and cExO, for Bandit Convex Optimization in non-stationary environments, achieving minimax-optimal regret under varying measures of non-stationarity.", "motivation": "To address the challenge of sequential decision-making in non-stationary environments where the learner lacks gradient information and must adapt to changing conditions.", "method": "Proposes TEWA-SE for strongly convex losses and cExO for general convex losses, leveraging sleeping experts and exponential weights over discretized action spaces.", "result": "TEWA-SE is minimax-optimal for known non-stationarity measures (S and \u0394), while cExO improves bounds for path-length (P) and is optimal for S and \u0394.", "conclusion": "The algorithms provide efficient solutions for non-stationary bandit convex optimization, with TEWA-SE being computationally efficient and cExO offering theoretical guarantees for broader cases."}}
{"id": "2410.10807", "pdf": "https://arxiv.org/pdf/2410.10807", "abs": "https://arxiv.org/abs/2410.10807", "authors": ["Youngjae Min", "Navid Azizan"], "title": "HardNet: Hard-Constrained Neural Networks with Universal Approximation Guarantees", "categories": ["cs.LG", "cs.AI", "stat.ML"], "comment": null, "summary": "Incorporating prior knowledge or specifications of input-output relationships\ninto machine learning models has attracted significant attention, as it\nenhances generalization from limited data and leads to conforming outputs.\nHowever, most existing approaches use soft constraints by penalizing violations\nthrough regularization, which offers no guarantee of constraint satisfaction,\nespecially on inputs far from the training distribution -- an essential\nrequirement in safety-critical applications. On the other hand, imposing hard\nconstraints on neural networks may hinder their representational power,\nadversely affecting performance. To address this, we propose HardNet, a\npractical framework for constructing neural networks that inherently satisfy\nhard constraints without sacrificing model capacity. Unlike approaches that\nmodify outputs only at inference time, HardNet enables end-to-end training with\nhard constraint guarantees, leading to improved performance. To the best of our\nknowledge, HardNet is the first method with an efficient forward pass to\nenforce more than one input-dependent inequality constraint. It allows\nunconstrained optimization of the network parameters using standard algorithms\nby appending a differentiable closed-form enforcement layer to the network's\noutput. Furthermore, we show that HardNet is expressive and retains the\nuniversal approximation capabilities of neural networks. We demonstrate the\nversatility and effectiveness of HardNet across various applications: learning\nwith piecewise constraints, learning optimization solvers with guaranteed\nfeasibility, and optimizing control policies in safety-critical systems.", "AI": {"tldr": "HardNet is a framework for neural networks to inherently satisfy hard constraints without losing model capacity, enabling end-to-end training with guaranteed constraint satisfaction.", "motivation": "Existing methods use soft constraints with no guarantee of satisfaction, especially for safety-critical applications, while hard constraints may limit model performance.", "method": "HardNet appends a differentiable closed-form enforcement layer to the network's output, allowing unconstrained optimization while satisfying hard constraints.", "result": "HardNet ensures constraint satisfaction, retains universal approximation capabilities, and improves performance in applications like learning with constraints and safety-critical control.", "conclusion": "HardNet provides a practical solution for enforcing hard constraints in neural networks without sacrificing performance or expressiveness."}}
{"id": "2501.03835", "pdf": "https://arxiv.org/pdf/2501.03835", "abs": "https://arxiv.org/abs/2501.03835", "authors": ["Yindu Su", "Huike Zou", "Lin Sun", "Ting Zhang", "Haiyang Yang", "Liyu Chen", "David Lo", "Qingheng Zhang", "Shuguang Han", "Jufeng Chen"], "title": "TACLR: A Scalable and Efficient Retrieval-based Method for Industrial Product Attribute Value Identification", "categories": ["cs.CL", "cs.AI", "cs.IR"], "comment": "Accepted at ACL 2025", "summary": "Product Attribute Value Identification (PAVI) involves identifying attribute\nvalues from product profiles, a key task for improving product search,\nrecommendation, and business analytics on e-commerce platforms. However,\nexisting PAVI methods face critical challenges, such as inferring implicit\nvalues, handling out-of-distribution (OOD) values, and producing normalized\noutputs. To address these limitations, we introduce Taxonomy-Aware Contrastive\nLearning Retrieval (TACLR), the first retrieval-based method for PAVI. TACLR\nformulates PAVI as an information retrieval task by encoding product profiles\nand candidate values into embeddings and retrieving values based on their\nsimilarity. It leverages contrastive training with taxonomy-aware hard negative\nsampling and employs adaptive inference with dynamic thresholds. TACLR offers\nthree key advantages: (1) it effectively handles implicit and OOD values while\nproducing normalized outputs; (2) it scales to thousands of categories, tens of\nthousands of attributes, and millions of values; and (3) it supports efficient\ninference for high-load industrial deployment. Extensive experiments on\nproprietary and public datasets validate the effectiveness and efficiency of\nTACLR. Further, it has been successfully deployed on the real-world e-commerce\nplatform Xianyu, processing millions of product listings daily with frequently\nupdated, large-scale attribute taxonomies. We release the code to facilitate\nreproducibility and future research at https://github.com/SuYindu/TACLR.", "AI": {"tldr": "TACLR is a retrieval-based method for Product Attribute Value Identification (PAVI) that handles implicit and OOD values, scales efficiently, and supports industrial deployment.", "motivation": "Existing PAVI methods struggle with implicit values, OOD values, and normalization, limiting their effectiveness in e-commerce applications.", "method": "TACLR formulates PAVI as a retrieval task using embeddings, employs contrastive training with taxonomy-aware hard negative sampling, and adaptive inference with dynamic thresholds.", "result": "TACLR effectively handles implicit and OOD values, scales to large datasets, and supports efficient industrial deployment, validated by experiments.", "conclusion": "TACLR is successfully deployed on Xianyu, demonstrating its practicality and effectiveness for large-scale PAVI tasks."}}
{"id": "2409.05819", "pdf": "https://arxiv.org/pdf/2409.05819", "abs": "https://arxiv.org/abs/2409.05819", "authors": ["Piotr Borycki", "Weronika Smolak", "Joanna Waczy\u0144ska", "Marcin Mazur", "S\u0142awomir Tadeja", "Przemys\u0142aw Spurek"], "title": "GASP: Gaussian Splatting for Physic-Based Simulations", "categories": ["cs.CV"], "comment": null, "summary": "Physics simulation is paramount for modeling and utilization of 3D scenes in\nvarious real-world applications. However, its integration with state-of-the-art\n3D scene rendering techniques such as Gaussian Splatting (GS) remains\nchallenging. Existing models use additional meshing mechanisms, including\ntriangle or tetrahedron meshing, marching cubes, or cage meshes. As an\nalternative, we can modify the physics grounded Newtonian dynamics to align\nwith 3D Gaussian components. Current models take the first-order approximation\nof a deformation map, which locally approximates the dynamics by linear\ntransformations. In contrast, our Gaussian Splatting for Physics-Based\nSimulations (GASP) model uses such a map (without any modifications) and flat\nGaussian distributions, which are parameterized by three points (mesh faces).\nSubsequently, each 3D point (mesh face node) is treated as a discrete entity\nwithin a 3D space. Consequently, the problem of modeling Gaussian components is\nreduced to working with 3D points. Additionally, the information on mesh faces\ncan be used to incorporate further properties into the physics model,\nfacilitating the use of triangles. Resulting solution can be integrated into\nany physics engine that can be treated as a black box. As demonstrated in our\nstudies, the proposed model exhibits superior performance on a diverse range of\nbenchmark datasets designed for 3D object rendering.", "AI": {"tldr": "The paper introduces GASP, a model integrating Gaussian Splatting with physics simulations by treating 3D points as discrete entities, avoiding traditional meshing methods.", "motivation": "Physics simulation integration with advanced 3D rendering like Gaussian Splatting is challenging, requiring alternatives to traditional meshing.", "method": "GASP uses flat Gaussian distributions parameterized by three points (mesh faces) and treats each 3D point as a discrete entity, simplifying Gaussian component modeling.", "result": "GASP shows superior performance on benchmark datasets for 3D object rendering.", "conclusion": "GASP offers a viable alternative to traditional meshing for physics-based simulations, compatible with existing physics engines."}}
{"id": "2506.03013", "pdf": "https://arxiv.org/pdf/2506.03013", "abs": "https://arxiv.org/abs/2506.03013", "authors": ["Alexandra Gonz\u00e1lez", "Xavier Franch", "David Lo", "Silverio Mart\u00ednez-Fern\u00e1ndez"], "title": "How do Pre-Trained Models Support Software Engineering? An Empirical Study in Hugging Face", "categories": ["cs.SE", "cs.LG"], "comment": null, "summary": "Open-Source Pre-Trained Models (PTMs) provide extensive resources for various\nMachine Learning (ML) tasks, yet these resources lack a classification tailored\nto Software Engineering (SE) needs. To address this gap, we derive a taxonomy\nencompassing 147 SE tasks and apply an SE-oriented classification to PTMs in a\npopular open-source ML repository, Hugging Face (HF). Our repository mining\nstudy began with a systematically gathered database of PTMs from the HF API,\nconsidering their model card descriptions and metadata, and the abstract of the\nassociated arXiv papers. We confirmed SE relevance through multiple filtering\nsteps: detecting outliers, identifying near-identical PTMs, and the use of\nGemini 2.0 Flash, which was validated with five pilot studies involving three\nhuman annotators. This approach uncovered 2,205 SE PTMs. We find that code\ngeneration is the most common SE task among PTMs, primarily focusing on\nsoftware implementation, while requirements engineering and software design\nactivities receive limited attention. In terms of ML tasks, text generation\ndominates within SE PTMs. Notably, the number of SE PTMs has increased markedly\nsince 2023 Q2. Our classification provides a solid foundation for future\nautomated SE scenarios, such as the sampling and selection of suitable PTMs.", "AI": {"tldr": "The paper introduces a taxonomy for classifying Open-Source Pre-Trained Models (PTMs) tailored to Software Engineering (SE) tasks, identifying 2,205 SE-relevant PTMs from Hugging Face. Code generation is the most common SE task, while requirements engineering and design are underrepresented.", "motivation": "To address the lack of a classification system for PTMs specifically designed for SE tasks, enabling better resource utilization in SE workflows.", "method": "Repository mining of Hugging Face PTMs, involving systematic data gathering, filtering (outliers, duplicates, and SE relevance validation using Gemini 2.0 Flash and human annotators), and classification.", "result": "Identified 2,205 SE-relevant PTMs, with code generation as the dominant SE task and text generation as the primary ML task. SE PTMs have surged since 2023 Q2.", "conclusion": "The taxonomy and classification provide a foundation for automated SE scenarios, aiding in PTM selection and sampling for SE tasks."}}
{"id": "2410.11840", "pdf": "https://arxiv.org/pdf/2410.11840", "abs": "https://arxiv.org/abs/2410.11840", "authors": ["Leshem Choshen", "Yang Zhang", "Jacob Andreas"], "title": "A Hitchhiker's Guide to Scaling Law Estimation", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": "ICML", "summary": "Scaling laws predict the loss of a target machine learning model by\nextrapolating from easier-to-train models with fewer parameters or smaller\ntraining sets. This provides an efficient way for practitioners and researchers\nalike to compare pretraining decisions involving optimizers, datasets, and\nmodel architectures. Despite the widespread use of scaling laws to model the\ndynamics of language model training, there has been little work on\nunderstanding how to best estimate and interpret them. We collect (and release)\na large-scale dataset containing losses and downstream evaluations for 485\npreviously published pretrained models. We use these to estimate more than 1000\nscaling laws, then derive a set of best practices for estimating scaling laws\nin new model families. We find that fitting scaling laws to intermediate\ncheckpoints of training runs (and not just their final losses) substantially\nimproves accuracy, and that -- all else equal -- estimates of performance are\ngenerally most accurate when derived from other models of similar sizes.\nHowever, because there is a significant degree of variability across model\nseeds, training multiple small models is sometimes more useful than training a\nsingle large one. Moreover, while different model families differ scaling\nbehavior, they are often similar enough that a target model's behavior can be\npredicted from a single model with the same architecture, along with scaling\nparameter estimates derived from other model families.", "AI": {"tldr": "Scaling laws predict model loss efficiently, but their estimation lacks best practices. This paper collects data from 485 models, derives scaling laws, and offers guidelines for accurate estimation.", "motivation": "To improve the understanding and estimation of scaling laws for machine learning models, addressing gaps in current practices.", "method": "Collects a large-scale dataset of losses and evaluations from 485 pretrained models, estimates over 1000 scaling laws, and analyzes best practices.", "result": "Fitting scaling laws to intermediate checkpoints improves accuracy. Performance estimates are most accurate from similar-sized models, and variability across seeds suggests training multiple small models can be beneficial.", "conclusion": "Scaling laws can be accurately estimated using intermediate checkpoints and similar-sized models, with variability addressed by training multiple models. Cross-family predictions are feasible with shared architecture and scaling parameters."}}
{"id": "2501.06645", "pdf": "https://arxiv.org/pdf/2501.06645", "abs": "https://arxiv.org/abs/2501.06645", "authors": ["Tong Liu", "Xiao Yu", "Wenxuan Zhou", "Jindong Gu", "Volker Tresp"], "title": "FocalPO: Enhancing Preference Optimizing by Focusing on Correct Preference Rankings", "categories": ["cs.CL", "cs.AI"], "comment": "ACL 2025", "summary": "Efficient preference optimization algorithms such as Direct Preference\nOptimization (DPO) have become a popular approach in aligning large language\nmodels (LLMs) with human preferences. These algorithms implicitly treat the LLM\nas a reward model, and focus on training it to correct misranked preference\npairs. However, recent work~\\citep{chen2024preference} empirically finds that\nDPO training \\textit{rarely improves these misranked preference pairs}, despite\nits gradient emphasizing on these cases. We introduce FocalPO, a DPO variant\nthat instead \\textit{down-weighs} misranked preference pairs and prioritizes\nenhancing the model's understanding of pairs that it can already rank\ncorrectly. Inspired by Focal Loss used in vision tasks, FocalPO achieves this\nby adding a modulating factor to dynamically scale DPO loss. Our experiment\ndemonstrates that FocalPO surpasses DPO and its variants on popular benchmarks\nlike Alpaca Eval 2.0 using Mistral-Base-7B and Llama-3-Instruct-8B, with the\nintroduced hyperparameter fixed. Additionally, we empirically reveals how\nFocalPO affects training on correct and incorrect sample groups, further\nunderscoring its effectiveness.", "AI": {"tldr": "FocalPO, a variant of DPO, down-weighs misranked preference pairs and focuses on enhancing correct rankings, outperforming DPO on benchmarks.", "motivation": "DPO often fails to improve misranked pairs despite its gradient focus, prompting the need for a more effective approach.", "method": "FocalPO introduces a modulating factor to dynamically scale DPO loss, prioritizing correctly ranked pairs.", "result": "FocalPO outperforms DPO and variants on benchmarks like Alpaca Eval 2.0, with fixed hyperparameters.", "conclusion": "FocalPO effectively improves model alignment by focusing on correct rankings, demonstrating superior performance over DPO."}}
{"id": "2409.13612", "pdf": "https://arxiv.org/pdf/2409.13612", "abs": "https://arxiv.org/abs/2409.13612", "authors": ["Bowen Yan", "Zhengsong Zhang", "Liqiang Jing", "Eftekhar Hossain", "Xinya Du"], "title": "FIHA: Autonomous Hallucination Evaluation in Vision-Language Models with Davidson Scene Graphs", "categories": ["cs.CV"], "comment": "Accepted by Findings of ACL 2025", "summary": "The rapid development of Large Vision-Language Models (LVLMs) often comes\nwith widespread hallucination issues, making cost-effective and comprehensive\nassessments increasingly vital. Current approaches mainly rely on costly\nannotations and are not comprehensive -- in terms of evaluating all aspects\nsuch as relations, attributes, and dependencies between aspects. Therefore, we\nintroduce the FIHA (autonomous Fine-graIned Hallucination evAluation evaluation\nin LVLMs), which could access hallucination LVLMs in the LLM-free and\nannotation-free way and model the dependency between different types of\nhallucinations. FIHA can generate Q&A pairs on any image dataset at minimal\ncost, enabling hallucination assessment from both image and caption. Based on\nthis approach, we introduce a benchmark called FIHA-v1, which consists of\ndiverse questions on various images from MSCOCO and Foggy. Furthermore, we use\nthe Davidson Scene Graph (DSG) to organize the structure among Q&A pairs, in\nwhich we can increase the reliability of the evaluation. We evaluate\nrepresentative models using FIHA-v1, highlighting their limitations and\nchallenges. We released our code and data.", "AI": {"tldr": "FIHA is introduced as a cost-effective, annotation-free method for evaluating hallucination in Large Vision-Language Models (LVLMs), generating Q&A pairs and modeling dependencies between hallucinations.", "motivation": "Current hallucination assessment methods are costly and lack comprehensiveness, failing to evaluate all aspects like relations, attributes, and dependencies.", "method": "FIHA autonomously evaluates LVLMs without LLMs or annotations, generates Q&A pairs from images, and uses Davidson Scene Graph (DSG) to structure evaluations.", "result": "FIHA-v1 benchmark is created, assessing models on diverse questions from MSCOCO and Foggy datasets, revealing limitations and challenges.", "conclusion": "FIHA provides a scalable, reliable way to assess LVLM hallucinations, with code and data publicly released."}}
{"id": "2506.03044", "pdf": "https://arxiv.org/pdf/2506.03044", "abs": "https://arxiv.org/abs/2506.03044", "authors": ["Laurentiu Andrei Marchis", "Po-Ling Loh"], "title": "On the Benefits of Accelerated Optimization in Robust and Private Estimation", "categories": ["math.ST", "cs.LG", "stat.ML", "stat.TH", "62F10, 62J05, 62J07, 62F35, 68P27"], "comment": "91 pages, 8 figures", "summary": "We study the advantages of accelerated gradient methods, specifically based\non the Frank-Wolfe method and projected gradient descent, for privacy and\nheavy-tailed robustness. Our approaches are as follows: For the Frank-Wolfe\nmethod, our technique is based on a tailored learning rate and a uniform lower\nbound on the gradient of the $\\ell_2$-norm over the constraint set. For\naccelerating projected gradient descent, we use the popular variant based on\nNesterov's momentum, and we optimize our objective over $\\mathbb{R}^p$. These\naccelerations reduce iteration complexity, translating into stronger\nstatistical guarantees for empirical and population risk minimization. Our\nanalysis covers three settings: non-random data, random model-free data, and\nparametric models (linear regression and generalized linear models).\nMethodologically, we approach both privacy and robustness based on noisy\ngradients. We ensure differential privacy via the Gaussian mechanism and\nadvanced composition, and we achieve heavy-tailed robustness using a geometric\nmedian-of-means estimator, which also sharpens the dependency on the dimension\nof the covariates. Finally, we compare our rates to existing bounds and\nidentify scenarios where our methods attain optimal convergence.", "AI": {"tldr": "The paper explores accelerated gradient methods (Frank-Wolfe and projected gradient descent) for privacy and heavy-tailed robustness, offering improved iteration complexity and stronger statistical guarantees.", "motivation": "To enhance privacy and robustness in optimization by leveraging accelerated gradient methods, addressing challenges in empirical and population risk minimization.", "method": "Tailored learning rates, Nesterov's momentum, and noisy gradients (Gaussian mechanism for privacy, geometric median-of-means for robustness) are employed.", "result": "Reduced iteration complexity, stronger statistical guarantees, and optimal convergence in certain scenarios.", "conclusion": "The proposed methods outperform existing bounds in specific settings, providing efficient solutions for privacy-preserving and robust optimization."}}
{"id": "2410.14086", "pdf": "https://arxiv.org/pdf/2410.14086", "abs": "https://arxiv.org/abs/2410.14086", "authors": ["Eric Elmoznino", "Tom Marty", "Tejas Kasetty", "Leo Gagnon", "Sarthak Mittal", "Mahan Fathi", "Dhanya Sridhar", "Guillaume Lajoie"], "title": "In-context learning and Occam's razor", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "A central goal of machine learning is generalization. While the No Free Lunch\nTheorem states that we cannot obtain theoretical guarantees for generalization\nwithout further assumptions, in practice we observe that simple models which\nexplain the training data generalize best: a principle called Occam's razor.\nDespite the need for simple models, most current approaches in machine learning\nonly minimize the training error, and at best indirectly promote simplicity\nthrough regularization or architecture design. Here, we draw a connection\nbetween Occam's razor and in-context learning: an emergent ability of certain\nsequence models like Transformers to learn at inference time from past\nobservations in a sequence. In particular, we show that the next-token\nprediction loss used to train in-context learners is directly equivalent to a\ndata compression technique called prequential coding, and that minimizing this\nloss amounts to jointly minimizing both the training error and the complexity\nof the model that was implicitly learned from context. Our theory and the\nempirical experiments we use to support it not only provide a normative account\nof in-context learning, but also elucidate the shortcomings of current\nin-context learning methods, suggesting ways in which they can be improved. We\nmake our code available at https://github.com/3rdCore/PrequentialCode.", "AI": {"tldr": "The paper connects Occam's razor to in-context learning, showing that next-token prediction loss in sequence models like Transformers is equivalent to prequential coding, jointly minimizing training error and model complexity.", "motivation": "To bridge the gap between theoretical generalization guarantees and practical simplicity (Occam's razor) in machine learning, focusing on in-context learning.", "method": "Theoretical analysis linking next-token prediction loss to prequential coding, supported by empirical experiments.", "result": "Demonstrates that minimizing next-token prediction loss implicitly reduces both training error and model complexity, offering insights into in-context learning.", "conclusion": "Provides a normative account of in-context learning, identifies shortcomings in current methods, and suggests improvements."}}
{"id": "2501.15781", "pdf": "https://arxiv.org/pdf/2501.15781", "abs": "https://arxiv.org/abs/2501.15781", "authors": ["Edoardo Cetin", "Tianyu Zhao", "Yujin Tang"], "title": "Large Language Models to Diffusion Finetuning", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "Camera-ready version, presented at ICML 2025. Code available at:\n  https://github.com/SakanaAI/L2D", "summary": "We propose a new finetuning method to provide pre-trained large language\nmodels (LMs) the ability to scale test-time compute through the diffusion\nframework. By increasing the number of diffusion steps, we show our finetuned\nmodels achieve monotonically increasing accuracy, directly translating to\nimproved performance across downstream tasks. Furthermore, our finetuned models\ncan expertly answer questions on specific topics by integrating powerful\nguidance techniques, and autonomously determine the compute required for a\ngiven problem by leveraging adaptive ODE solvers. Our method is universally\napplicable to any foundation model pre-trained with a cross-entropy loss and\ndoes not modify any of its original weights, fully preserving its strong\nsingle-step generation capabilities. We show our method is more effective and\nfully compatible with traditional finetuning approaches, introducing an\northogonal new direction to unify the strengths of the autoregressive and\ndiffusion frameworks.", "AI": {"tldr": "A new finetuning method for pre-trained LMs using diffusion framework to scale test-time compute, improving accuracy and performance without altering original weights.", "motivation": "To enhance pre-trained LMs by enabling scalable test-time compute and integrating guidance techniques for better task performance.", "method": "Finetuning pre-trained LMs with diffusion steps, adaptive ODE solvers, and guidance techniques while preserving original weights.", "result": "Monotonically increasing accuracy with more diffusion steps, improved downstream task performance, and expert question-answering capabilities.", "conclusion": "The method is universally applicable, effective, and compatible with traditional finetuning, unifying autoregressive and diffusion strengths."}}
{"id": "2410.01574", "pdf": "https://arxiv.org/pdf/2410.01574", "abs": "https://arxiv.org/abs/2410.01574", "authors": ["Sina Mavali", "Jonas Ricker", "David Pape", "Asja Fischer", "Lea Sch\u00f6nherr"], "title": "Adversarial Robustness of AI-Generated Image Detectors in the Real World", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "The rapid advancement of Generative Artificial Intelligence (GenAI)\ncapabilities is accompanied by a concerning rise in its misuse. In particular\nthe generation of credible misinformation in the form of images poses a\nsignificant threat to the public trust in democratic processes. Consequently,\nthere is an urgent need to develop tools to reliably distinguish between\nauthentic and AI-generated content. The majority of detection methods are based\non neural networks that are trained to recognize forensic artifacts. In this\nwork, we demonstrate that current state-of-the-art classifiers are vulnerable\nto adversarial examples under real-world conditions. Through extensive\nexperiments, comprising four detection methods and five attack algorithms, we\nshow that an attacker can dramatically decrease classification performance,\nwithout internal knowledge of the detector's architecture. Notably, most\nattacks remain effective even when images are degraded during the upload to,\ne.g., social media platforms. In a case study, we demonstrate that these\nrobustness challenges are also found in commercial tools by conducting\nblack-box attacks on HIVE, a proprietary online GenAI media detector. In\naddition, we evaluate the robustness of using generated features of a robust\npre-trained model and showed that this increases the robustness, while not\nreaching the performance on benign inputs. These results, along with the\nincreasing potential of GenAI to erode public trust, underscore the need for\nmore research and new perspectives on methods to prevent its misuse.", "AI": {"tldr": "Current AI-generated content detectors are vulnerable to adversarial attacks, even under real-world conditions, highlighting the need for more robust solutions.", "motivation": "The misuse of GenAI, especially in generating misinformation, threatens public trust in democratic processes, necessitating reliable detection tools.", "method": "Evaluated four detection methods and five attack algorithms, including black-box attacks on a commercial tool (HIVE), and tested robustness using features from a pre-trained model.", "result": "Attackers can significantly reduce detection performance without knowing the detector's architecture, and most attacks remain effective despite image degradation.", "conclusion": "The findings emphasize the urgent need for more research and innovative approaches to combat GenAI misuse and enhance detection robustness."}}
{"id": "2506.03049", "pdf": "https://arxiv.org/pdf/2506.03049", "abs": "https://arxiv.org/abs/2506.03049", "authors": ["Maria Walch"], "title": "Torsion in Persistent Homology and Neural Networks", "categories": ["math.AT", "cs.LG"], "comment": null, "summary": "We explore the role of torsion in hybrid deep learning models that\nincorporate topological data analysis, focusing on autoencoders. While most TDA\ntools use field coefficients, this conceals torsional features present in\ninteger homology. We show that torsion can be lost during encoding, altered in\nthe latent space, and in many cases, not reconstructed by standard decoders.\nUsing both synthetic and high-dimensional data, we evaluate torsion sensitivity\nto perturbations and assess its recoverability across several autoencoder\narchitectures. Our findings reveal key limitations of field-based approaches\nand underline the need for architectures or loss terms that preserve torsional\ninformation for robust data representation.", "AI": {"tldr": "The paper investigates how torsion in integer homology is overlooked in field-based TDA tools and its impact on autoencoders, highlighting the need for better preservation methods.", "motivation": "To address the loss or alteration of torsional features in hybrid deep learning models using TDA, which are typically ignored in field-based approaches.", "method": "Evaluates torsion sensitivity and recoverability using synthetic and high-dimensional data across various autoencoder architectures.", "result": "Reveals limitations of field-based TDA tools and shows torsion is often lost or altered during encoding and not reconstructed by standard decoders.", "conclusion": "Emphasizes the need for new architectures or loss terms to preserve torsional information for robust data representation."}}
{"id": "2410.16135", "pdf": "https://arxiv.org/pdf/2410.16135", "abs": "https://arxiv.org/abs/2410.16135", "authors": ["Kang Zhao", "Tao Yuan", "Han Bao", "Zhenfeng Su", "Chang Gao", "Zhaofeng Sun", "Zichen Liang", "Liping Jing", "Jianfei Chen"], "title": "Beyond 2:4: exploring V:N:M sparsity for efficient transformer inference on GPUs", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "To date, 2:4 sparsity has stood as the only sparse pattern that can be\naccelerated using sparse tensor cores on GPUs. In practice, 2:4 sparsity often\npossesses low actual speedups ($\\leq 1.3$) and requires fixed sparse ratios,\nmeaning that other ratios, such as 4:8, 8:16, or those exceeding 50% sparsity,\ndo not incur any speedups on GPUs. Recent studies suggest that V:N:M sparsity\nis promising in addressing these limitations of 2:4 sparsity. However,\nregarding accuracy, the effects of V:N:M sparsity on broader Transformer\nmodels, such as vision Transformers and large language models (LLMs), are\nlargely unexamined. Moreover, Some specific issues related to V:N:M sparsity,\nsuch as how to select appropriate V and M values, remain unresolved. In this\nstudy, we thoroughly investigate the application of V:N:M sparsity in vision\nmodels and LLMs across multiple tasks, from pertaining to downstream tasks. We\npropose three key approaches to enhance the applicability and accuracy of\nV:N:M-sparse Transformers, including heuristic V and M selection,\nV:N:M-specific channel permutation, and three-staged LoRA training techniques.\nExperimental results show that, with our methods, the DeiT-small achieves\nlossless accuracy at 64:2:5 sparsity, while the DeiT-base maintains accuracy\neven at 64:2:8 sparsity. In addition, the fine-tuned LLama2-7B at 64:2:5\nsparsity performs comparably or better than training-free 2:4 sparse\nalternatives on downstream tasks. More importantly, V:N:M-sparse Transformers\noffer a wider range of speedup-accuracy trade-offs compared to 2:4 sparsity.\nOverall, our exploration largely facilitates the V:N:M sparsity to act as a\ntruly effective acceleration solution for Transformers in cost-sensitive\ninference scenarios.", "AI": {"tldr": "The paper explores V:N:M sparsity as a more flexible and effective alternative to 2:4 sparsity for accelerating Transformers, proposing methods to enhance its applicability and accuracy.", "motivation": "2:4 sparsity has limitations like low speedups and fixed ratios, while V:N:M sparsity shows promise but lacks thorough investigation in broader Transformer models and unresolved issues like parameter selection.", "method": "Three key approaches: heuristic V and M selection, V:N:M-specific channel permutation, and three-staged LoRA training techniques.", "result": "DeiT-small achieves lossless accuracy at 64:2:5 sparsity; DeiT-base maintains accuracy at 64:2:8. LLama2-7B at 64:2:5 performs comparably or better than 2:4 sparse alternatives.", "conclusion": "V:N:M sparsity offers better speedup-accuracy trade-offs than 2:4 sparsity, making it a viable solution for cost-sensitive inference in Transformers."}}
{"id": "2502.00334", "pdf": "https://arxiv.org/pdf/2502.00334", "abs": "https://arxiv.org/abs/2502.00334", "authors": ["Xin Xu", "Qiyun Xu", "Tong Xiao", "Tianhao Chen", "Yuchen Yan", "Jiaxin Zhang", "Shizhe Diao", "Can Yang", "Yang Wang"], "title": "UGPhysics: A Comprehensive Benchmark for Undergraduate Physics Reasoning with Large Language Models", "categories": ["cs.CL", "cs.AI"], "comment": "Accepted to ICML 2025", "summary": "Large language models (LLMs) have demonstrated remarkable capabilities in\nsolving complex reasoning tasks, particularly in mathematics. However, the\ndomain of physics reasoning presents unique challenges that have received\nsignificantly less attention. Existing benchmarks often fall short in\nevaluating LLMs' abilities on the breadth and depth of undergraduate-level\nphysics, underscoring the need for a comprehensive evaluation. To fill this\ngap, we introduce UGPhysics, a large-scale and comprehensive benchmark\nspecifically designed to evaluate UnderGraduate-level Physics (UGPhysics)\nreasoning with LLMs. UGPhysics includes 5,520 undergraduate-level physics\nproblems in both English and Chinese, covering 13 subjects with seven different\nanswer types and four distinct physics reasoning skills, all rigorously\nscreened for data leakage. Additionally, we develop a Model-Assistant\nRule-based Judgment (MARJ) pipeline specifically tailored for assessing answer\ncorrectness of physics problems, ensuring accurate evaluation. Our evaluation\nof 31 leading LLMs shows that the highest overall accuracy, 49.8% (achieved by\nOpenAI-o1-mini), emphasizes the necessity for models with stronger physics\nreasoning skills, beyond math abilities. We hope UGPhysics, along with MARJ,\nwill drive future advancements in AI for physics reasoning. Codes and data are\navailable at https://github.com/YangLabHKUST/UGPhysics .", "AI": {"tldr": "UGPhysics is a benchmark for evaluating LLMs on undergraduate-level physics reasoning, highlighting gaps in current models' capabilities.", "motivation": "Existing benchmarks lack depth in assessing LLMs' physics reasoning, necessitating a comprehensive evaluation tool.", "method": "UGPhysics includes 5,520 problems in English and Chinese, covering 13 subjects, with a MARJ pipeline for accurate assessment.", "result": "Top LLM achieved 49.8% accuracy, showing the need for improved physics reasoning beyond math skills.", "conclusion": "UGPhysics and MARJ aim to advance AI in physics reasoning, with data and code publicly available."}}
{"id": "2410.04417", "pdf": "https://arxiv.org/pdf/2410.04417", "abs": "https://arxiv.org/abs/2410.04417", "authors": ["Yuan Zhang", "Chun-Kai Fan", "Junpeng Ma", "Wenzhao Zheng", "Tao Huang", "Kuan Cheng", "Denis Gudovskiy", "Tomoyuki Okuno", "Yohei Nakata", "Kurt Keutzer", "Shanghang Zhang"], "title": "SparseVLM: Visual Token Sparsification for Efficient Vision-Language Model Inference", "categories": ["cs.CV"], "comment": "Accepted by ICML 2025", "summary": "In vision-language models (VLMs), visual tokens usually bear a significant\namount of computational overhead despite sparsity of information in them when\ncompared to text tokens. To address this, most existing methods learn a network\nto prune redundant visual tokens using certain training data. Differently, we\npropose a text-guided training-free token optimization mechanism dubbed\nSparseVLM that eliminates the need of extra parameters or fine-tuning costs.\nGiven that visual tokens complement text tokens in VLM's linguistic reasoning,\nwe select relevant text tokens to rate the significance of visual tokens using\nself-attention matrices and, then, prune visual tokens using the proposed\nstrategy to maximize sparsity while retaining information. In particular, we\nintroduce a rank-based strategy to adaptively determine the sparsification\nratio for each layer, alongside a token recycling method that compresses pruned\ntokens into more compact representations. Experimental results show that\nSparseVLM increases the efficiency of various VLMs in a number of image and\nvideo understanding tasks. For example, LLaVA when equipped with SparseVLM\nachieves 54% reduction in FLOPs, 37% decrease in CUDA latency while maintaining\n97% of its original accuracy. Our code is available at\nhttps://github.com/Gumpest/SparseVLMs.", "AI": {"tldr": "SparseVLM is a text-guided, training-free token optimization method for vision-language models (VLMs) that prunes redundant visual tokens using self-attention matrices, improving efficiency without extra parameters or fine-tuning.", "motivation": "Visual tokens in VLMs are computationally expensive but often contain sparse information. Existing methods require training or extra parameters, which SparseVLM avoids.", "method": "SparseVLM uses text tokens to rate visual tokens via self-attention matrices, prunes them adaptively, and recycles pruned tokens into compact representations.", "result": "SparseVLM reduces FLOPs by 54% and CUDA latency by 37% in LLaVA while retaining 97% accuracy.", "conclusion": "SparseVLM offers an efficient, parameter-free solution for optimizing VLMs, enhancing performance in image and video tasks."}}
{"id": "2506.03068", "pdf": "https://arxiv.org/pdf/2506.03068", "abs": "https://arxiv.org/abs/2506.03068", "authors": ["Yina Hou", "Shourav B. Rabbani", "Liang Hong", "Norou Diawara", "Manar D. Samad"], "title": "Causal Explainability of Machine Learning in Heart Failure Prediction from Electronic Health Records", "categories": ["stat.ML", "cs.CY", "cs.LG"], "comment": "4 figures", "summary": "The importance of clinical variables in the prognosis of the disease is\nexplained using statistical correlation or machine learning (ML). However, the\npredictive importance of these variables may not represent their causal\nrelationships with diseases. This paper uses clinical variables from a heart\nfailure (HF) patient cohort to investigate the causal explainability of\nimportant variables obtained in statistical and ML contexts. Due to inherent\nregression modeling, popular causal discovery methods strictly assume that the\ncause and effect variables are numerical and continuous. This paper proposes a\nnew computational framework to enable causal structure discovery (CSD) and\nscore the causal strength of mixed-type (categorical, numerical, binary)\nclinical variables for binary disease outcomes. In HF classification, we\ninvestigate the association between the importance rank order of three feature\ntypes: correlated features, features important for ML predictions, and causal\nfeatures. Our results demonstrate that CSD modeling for nonlinear causal\nrelationships is more meaningful than its linear counterparts. Feature\nimportance obtained from nonlinear classifiers (e.g., gradient-boosting trees)\nstrongly correlates with the causal strength of variables without\ndifferentiating cause and effect variables. Correlated variables can be causal\nfor HF, but they are rarely identified as effect variables. These results can\nbe used to add the causal explanation of variables important for ML-based\nprediction modeling.", "AI": {"tldr": "The paper explores causal explainability of clinical variables in heart failure (HF) prognosis, proposing a new framework for causal structure discovery (CSD) with mixed-type variables. It compares feature importance from correlation, ML, and causal methods, showing nonlinear CSD is more meaningful.", "motivation": "To address the gap between predictive importance and causal relationships of clinical variables in HF prognosis, especially for mixed-type data.", "method": "Proposes a computational framework for CSD with mixed-type variables, comparing feature importance from correlation, ML, and causal methods in HF classification.", "result": "Nonlinear CSD is more meaningful than linear methods. ML feature importance correlates with causal strength, and correlated variables can be causal but rarely identified as effects.", "conclusion": "The framework enhances causal explanations for ML-based predictions, highlighting the value of nonlinear CSD in understanding HF prognosis."}}
{"id": "2411.05698", "pdf": "https://arxiv.org/pdf/2411.05698", "abs": "https://arxiv.org/abs/2411.05698", "authors": ["Antonio De Santis", "Riccardo Campi", "Matteo Bianchi", "Marco Brambilla"], "title": "Visual-TCAV: Concept-based Attribution and Saliency Maps for Post-hoc Explainability in Image Classification", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": "Preprint currently under review", "summary": "Convolutional Neural Networks (CNNs) have seen significant performance\nimprovements in recent years. However, due to their size and complexity, they\nfunction as black-boxes, leading to transparency concerns. State-of-the-art\nsaliency methods generate local explanations that highlight the area in the\ninput image where a class is identified but cannot explain how a concept of\ninterest contributes to the prediction, which is essential for bias mitigation.\nOn the other hand, concept-based methods, such as TCAV (Testing with Concept\nActivation Vectors), provide insights into how sensitive is the network to a\nconcept, but cannot compute its attribution in a specific prediction nor show\nits location within the input image. This paper introduces a novel post-hoc\nexplainability framework, Visual-TCAV, which aims to bridge the gap between\nthese methods by providing both local and global explanations for CNN-based\nimage classification. Visual-TCAV uses Concept Activation Vectors (CAVs) to\ngenerate saliency maps that show where concepts are recognized by the network.\nMoreover, it can estimate the attribution of these concepts to the output of\nany class using a generalization of Integrated Gradients. This framework is\nevaluated on popular CNN architectures, with its validity further confirmed via\nexperiments where ground truth for explanations is known, and a comparison with\nTCAV. Our code is available at\nhttps://github.com/DataSciencePolimi/Visual-TCAV.", "AI": {"tldr": "Visual-TCAV bridges saliency and concept-based methods for CNN explainability, providing local and global explanations via CAVs and saliency maps.", "motivation": "Addressing the limitations of existing explainability methods (saliency and concept-based) in CNNs by combining their strengths.", "method": "Introduces Visual-TCAV, using CAVs and a generalization of Integrated Gradients to generate saliency maps and concept attributions.", "result": "Evaluated on CNN architectures, validated with ground truth, and compared to TCAV, showing effectiveness.", "conclusion": "Visual-TCAV successfully combines local and global explanations, enhancing CNN transparency."}}
{"id": "2502.08246", "pdf": "https://arxiv.org/pdf/2502.08246", "abs": "https://arxiv.org/abs/2502.08246", "authors": ["Pierre-Emmanuel Mazar\u00e9", "Gergely Szilvasy", "Maria Lomeli", "Francisco Massa", "Naila Murray", "Herv\u00e9 J\u00e9gou", "Matthijs Douze"], "title": "Inference-time sparse attention with asymmetric indexing", "categories": ["cs.CL"], "comment": null, "summary": "Self-attention in transformer models is an incremental associative memory\nthat maps key vectors to value vectors. One way to speed up self-attention is\nto employ GPU-compatible vector search algorithms based on standard\npartitioning methods such as k-means. However, such partitioning methods yield\npoor results in this context because (1) the keys and queries follow different\ndistributions, and (2) the RoPE positional encoding hinders the bucket\nassignment.\n  This paper introduces Saap (Self-Attention with Asymmetric Partitions), which\novercomes these problems. It is an asymmetrical indexing technique that employs\ndistinct partitions for keys and queries, thereby approximating self-attention\nwith a data-adaptive sparsity pattern. It works on pretrained language models\nand only requires to train (offline) a small query classifier. On a long\ncontext Llama 3.1-8b model, with sequences ranging from 100k to 500k tokens,\nSaap typically reduces by a factor of 20 the fraction of memory that needs to\nbe looked-up, which translates to a time saving of 60\\% when compared to\nFlashAttention-v2.", "AI": {"tldr": "Saap (Self-Attention with Asymmetric Partitions) introduces an asymmetrical indexing technique to speed up self-attention in transformers by addressing key-query distribution mismatches and RoPE positional encoding issues.", "motivation": "Standard partitioning methods like k-means perform poorly in self-attention due to differing key-query distributions and RoPE positional encoding interference.", "method": "Saap uses distinct partitions for keys and queries, approximating self-attention with a data-adaptive sparsity pattern, requiring only offline training of a small query classifier.", "result": "On a long-context Llama 3.1-8b model, Saap reduces memory look-up by 20x and saves 60% time compared to FlashAttention-v2.", "conclusion": "Saap effectively improves self-attention efficiency in transformers for long sequences."}}
{"id": "2410.09886", "pdf": "https://arxiv.org/pdf/2410.09886", "abs": "https://arxiv.org/abs/2410.09886", "authors": ["Yaohua Zha", "Tao Dai", "Hang Guo", "Yanzi Wang", "Bin Chen", "Ke Chen", "Shu-Tao Xia"], "title": "Point Cloud Mixture-of-Domain-Experts Model for 3D Self-supervised Learning", "categories": ["cs.CV"], "comment": "Accepted to IJCAI 2025", "summary": "Point clouds, as a primary representation of 3D data, can be categorized into\nscene domain point clouds and object domain point clouds. Point cloud\nself-supervised learning (SSL) has become a mainstream paradigm for learning 3D\nrepresentations. However, existing point cloud SSL primarily focuses on\nlearning domain-specific 3D representations within a single domain, neglecting\nthe complementary nature of cross-domain knowledge, which limits the learning\nof 3D representations. In this paper, we propose to learn a comprehensive Point\ncloud Mixture-of-Domain-Experts model (Point-MoDE) via a block-to-scene\npre-training strategy. Specifically, we first propose a\nmixture-of-domain-expert model consisting of scene domain experts and multiple\nshared object domain experts. Furthermore, we propose a block-to-scene\npretraining strategy, which leverages the features of point blocks in the\nobject domain to regress their initial positions in the scene domain through\nobject-level block mask reconstruction and scene-level block position\nregression. By integrating the complementary knowledge between object and\nscene, this strategy simultaneously facilitates the learning of both\nobject-domain and scene-domain representations, leading to a more comprehensive\n3D representation. Extensive experiments in downstream tasks demonstrate the\nsuperiority of our model.", "AI": {"tldr": "The paper introduces Point-MoDE, a self-supervised learning model for point clouds that leverages cross-domain knowledge between scene and object domains via a block-to-scene pre-training strategy.", "motivation": "Existing point cloud SSL methods focus on single-domain learning, missing the benefits of cross-domain knowledge. This limits the comprehensiveness of 3D representations.", "method": "Proposes a mixture-of-domain-expert model (Point-MoDE) with scene and object domain experts. Uses block-to-scene pre-training with object-level mask reconstruction and scene-level position regression.", "result": "The model integrates cross-domain knowledge, improving both object and scene domain representations. Experiments show superior performance in downstream tasks.", "conclusion": "Point-MoDE effectively combines cross-domain knowledge, enhancing 3D representation learning and outperforming existing methods."}}
{"id": "2506.03074", "pdf": "https://arxiv.org/pdf/2506.03074", "abs": "https://arxiv.org/abs/2506.03074", "authors": ["Junghyun Lee", "Kyoungseok Jang", "Kwang-Sung Jun", "Milan Vojnovi\u0107", "Se-Young Yun"], "title": "GL-LowPopArt: A Nearly Instance-Wise Minimax Estimator for Generalized Low-Rank Trace Regression", "categories": ["stat.ML", "cs.LG"], "comment": "53 pages, 2 figures, 3 tables; Accepted as a Spotlight Poster to the\n  42nd International Conference on Machine Learning (ICML 2025)", "summary": "We present `GL-LowPopArt`, a novel Catoni-style estimator for generalized\nlow-rank trace regression. Building on `LowPopArt` (Jang et al., 2024), it\nemploys a two-stage approach: nuclear norm regularization followed by matrix\nCatoni estimation. We establish state-of-the-art estimation error bounds,\nsurpassing existing guarantees (Fan et al., 2019; Kang et al., 2022), and\nreveal a novel experimental design objective, $\\mathrm{GL}(\\pi)$. The key\ntechnical challenge is controlling bias from the nonlinear inverse link\nfunction, which we address by our two-stage approach. We prove a *local*\nminimax lower bound, showing that our `GL-LowPopArt` enjoys instance-wise\noptimality up to the condition number of the ground-truth Hessian. Applications\ninclude generalized linear matrix completion, where `GL-LowPopArt` achieves a\nstate-of-the-art Frobenius error guarantee, and **bilinear dueling bandits**, a\nnovel setting inspired by general preference learning (Zhang et al., 2024). Our\nanalysis of a `GL-LowPopArt`-based explore-then-commit algorithm reveals a new,\npotentially interesting problem-dependent quantity, along with improved Borda\nregret bound than vectorization (Wu et al., 2024).", "AI": {"tldr": "GL-LowPopArt is a Catoni-style estimator for generalized low-rank trace regression, offering improved error bounds and a novel experimental design objective. It excels in applications like matrix completion and bilinear dueling bandits.", "motivation": "To address the challenge of controlling bias from nonlinear inverse link functions in generalized low-rank trace regression, surpassing existing methods.", "method": "Two-stage approach: nuclear norm regularization followed by matrix Catoni estimation.", "result": "State-of-the-art estimation error bounds, instance-wise optimality, and improved Frobenius error in matrix completion.", "conclusion": "GL-LowPopArt is optimal and versatile, with applications in matrix completion and bandits, offering new theoretical insights."}}
{"id": "2411.08832", "pdf": "https://arxiv.org/pdf/2411.08832", "abs": "https://arxiv.org/abs/2411.08832", "authors": ["Reece O'Mahoney", "Alexander L. Mitchell", "Wanming Yu", "Ingmar Posner", "Ioannis Havoutis"], "title": "Offline Adaptation of Quadruped Locomotion using Diffusion Models", "categories": ["cs.RO", "cs.AI", "cs.LG"], "comment": null, "summary": "We present a diffusion-based approach to quadrupedal locomotion that\nsimultaneously addresses the limitations of learning and interpolating between\nmultiple skills and of (modes) offline adapting to new locomotion behaviours\nafter training. This is the first framework to apply classifier-free guided\ndiffusion to quadruped locomotion and demonstrate its efficacy by extracting\ngoal-conditioned behaviour from an originally unlabelled dataset. We show that\nthese capabilities are compatible with a multi-skill policy and can be applied\nwith little modification and minimal compute overhead, i.e., running entirely\non the robots onboard CPU. We verify the validity of our approach with hardware\nexperiments on the ANYmal quadruped platform.", "AI": {"tldr": "A diffusion-based approach for quadrupedal locomotion that learns and interpolates multiple skills while adapting to new behaviors post-training, demonstrated on the ANYmal platform.", "motivation": "To overcome limitations in learning and adapting multiple locomotion skills, and to enable goal-conditioned behavior extraction from unlabelled data.", "method": "Classifier-free guided diffusion applied to quadruped locomotion, requiring minimal compute overhead and running on the robot's onboard CPU.", "result": "Successful hardware experiments on the ANYmal platform, showing compatibility with multi-skill policies.", "conclusion": "The framework effectively addresses skill learning and adaptation challenges in quadruped locomotion with practical applicability."}}
{"id": "2502.09416", "pdf": "https://arxiv.org/pdf/2502.09416", "abs": "https://arxiv.org/abs/2502.09416", "authors": ["Takumi Goto", "Yusuke Sakai", "Taro Watanabe"], "title": "Rethinking Evaluation Metrics for Grammatical Error Correction: Why Use a Different Evaluation Process than Human?", "categories": ["cs.CL"], "comment": "ACL 2025 (Main), 5 pages, 2 figures", "summary": "One of the goals of automatic evaluation metrics in grammatical error\ncorrection (GEC) is to rank GEC systems such that it matches human preferences.\nHowever, current automatic evaluations are based on procedures that diverge\nfrom human evaluation. Specifically, human evaluation derives rankings by\naggregating sentence-level relative evaluation results, e.g., pairwise\ncomparisons, using a rating algorithm, whereas automatic evaluation averages\nsentence-level absolute scores to obtain corpus-level scores, which are then\nsorted to determine rankings. In this study, we propose an aggregation method\nfor existing automatic evaluation metrics which aligns with human evaluation\nmethods to bridge this gap. We conducted experiments using various metrics,\nincluding edit-based metrics, n-gram based metrics, and sentence-level metrics,\nand show that resolving the gap improves results for the most of metrics on the\nSEEDA benchmark. We also found that even BERT-based metrics sometimes\noutperform the metrics of GPT-4. The proposed ranking method is integrated\ngec-metrics.", "AI": {"tldr": "Proposes an aggregation method for GEC metrics to align with human evaluation, improving results on the SEEDA benchmark.", "motivation": "Current automatic GEC evaluations diverge from human methods, which aggregate sentence-level relative evaluations.", "method": "Proposes an aggregation method for existing metrics (edit-based, n-gram, sentence-level) to match human evaluation.", "result": "Improves most metrics on SEEDA; BERT-based metrics sometimes outperform GPT-4.", "conclusion": "The proposed method bridges the gap between automatic and human evaluation in GEC."}}
{"id": "2410.16602", "pdf": "https://arxiv.org/pdf/2410.16602", "abs": "https://arxiv.org/abs/2410.16602", "authors": ["Aoran Xiao", "Weihao Xuan", "Junjue Wang", "Jiaxing Huang", "Dacheng Tao", "Shijian Lu", "Naoto Yokoya"], "title": "Foundation Models for Remote Sensing and Earth Observation: A Survey", "categories": ["cs.CV"], "comment": "Accepted to IEEE Geoscience and Remote Sensing Magazine (GRSM)", "summary": "Remote Sensing (RS) is a crucial technology for observing, monitoring, and\ninterpreting our planet, with broad applications across geoscience, economics,\nhumanitarian fields, etc. While artificial intelligence (AI), particularly deep\nlearning, has achieved significant advances in RS, unique challenges persist in\ndeveloping more intelligent RS systems, including the complexity of Earth's\nenvironments, diverse sensor modalities, distinctive feature patterns, varying\nspatial and spectral resolutions, and temporal dynamics. Meanwhile, recent\nbreakthroughs in large Foundation Models (FMs) have expanded AI's potential\nacross many domains due to their exceptional generalizability and zero-shot\ntransfer capabilities. However, their success has largely been confined to\nnatural data like images and video, with degraded performance and even failures\nfor RS data of various non-optical modalities. This has inspired growing\ninterest in developing Remote Sensing Foundation Models (RSFMs) to address the\ncomplex demands of Earth Observation (EO) tasks, spanning the surface,\natmosphere, and oceans. This survey systematically reviews the emerging field\nof RSFMs. It begins with an outline of their motivation and background,\nfollowed by an introduction of their foundational concepts. It then categorizes\nand reviews existing RSFM studies including their datasets and technical\ncontributions across Visual Foundation Models (VFMs), Visual-Language Models\n(VLMs), Large Language Models (LLMs), and beyond. In addition, we benchmark\nthese models against publicly available datasets, discuss existing challenges,\nand propose future research directions in this rapidly evolving field. A\nproject associated with this survey has been built at\nhttps://github.com/xiaoaoran/awesome-RSFMs .", "AI": {"tldr": "The paper surveys Remote Sensing Foundation Models (RSFMs), addressing challenges in AI for Remote Sensing (RS) and exploring their potential across Earth Observation tasks.", "motivation": "To develop more intelligent RS systems by leveraging large Foundation Models (FMs) despite their limitations with RS data.", "method": "Systematic review of RSFMs, categorizing studies, benchmarking models, and analyzing datasets and technical contributions.", "result": "Identifies gaps in RSFM applications, benchmarks performance, and highlights challenges in adapting FMs to RS data.", "conclusion": "Proposes future research directions for RSFMs, emphasizing their potential in Earth Observation tasks."}}
{"id": "2506.03120", "pdf": "https://arxiv.org/pdf/2506.03120", "abs": "https://arxiv.org/abs/2506.03120", "authors": ["Xiuyu Cao", "Joseph O. Sexton", "Panshi Wang", "Dimitrios Gounaridis", "Neil H. Carter", "Kai Zhu"], "title": "Validating remotely sensed biomass estimates with forest inventory data in the western US", "categories": ["stat.AP", "cs.LG"], "comment": "32 pages, 5 figures", "summary": "Monitoring aboveground biomass (AGB) and its density (AGBD) at high\nresolution is essential for carbon accounting and ecosystem management. While\nNASA's spaceborne Global Ecosystem Dynamics Investigation (GEDI) LiDAR mission\nprovides globally distributed reference measurements for AGBD estimation, the\nmajority of commercial remote sensing products based on GEDI remain without\nrigorous or independent validation. Here, we present an independent regional\nvalidation of an AGBD dataset offered by terraPulse, Inc., based on independent\nreference data from the US Forest Service Forest Inventory and Analysis (FIA)\nprogram. Aggregated to 64,000-hectare hexagons and US counties across the US\nstates of Utah, Nevada, and Washington, we found very strong agreement between\nterraPulse and FIA estimates. At the hexagon scale, we report R2 = 0.88, RMSE =\n26.68 Mg/ha, and a correlation coefficient (r) of 0.94. At the county scale,\nagreement improves to R2 = 0.90, RMSE =32.62 Mg/ha, slope = 1.07, and r = 0.95.\nSpatial and statistical analyses indicated that terraPulse AGBD values tended\nto exceed FIA estimates in non-forest areas, likely due to FIA's limited\nsampling of non-forest vegetation. The terraPulse AGBD estimates also exhibited\nlower values in high-biomass forests, likely due to saturation effects in its\noptical remote-sensing covariates. This study advances operational carbon\nmonitoring by delivering a scalable framework for comprehensive AGBD validation\nusing independent FIA data, as well as a benchmark validation of a new\ncommercial dataset for global biomass monitoring.", "AI": {"tldr": "The paper validates terraPulse's AGBD dataset using FIA data, showing strong agreement but noting biases in non-forest and high-biomass areas.", "motivation": "To independently validate commercial AGBD datasets, like terraPulse's, for reliable carbon accounting and ecosystem management.", "method": "Used FIA program data to validate terraPulse's AGBD estimates at hexagon and county scales, analyzing spatial and statistical agreement.", "result": "Strong agreement (R\u00b2=0.88-0.90, r=0.94-0.95) but biases: overestimation in non-forest areas and underestimation in high-biomass forests.", "conclusion": "Provides a scalable validation framework and benchmarks terraPulse's dataset, advancing global biomass monitoring."}}
{"id": "2411.10596", "pdf": "https://arxiv.org/pdf/2411.10596", "abs": "https://arxiv.org/abs/2411.10596", "authors": ["Minglu Zhao", "Dehong Xu", "Deqian Kong", "Wen-Hao Zhang", "Ying Nian Wu"], "title": "A minimalistic representation model for head direction system", "categories": ["q-bio.NC", "cs.AI", "cs.CV", "stat.ML"], "comment": "Proceedings of the Annual Meeting of the Cognitive Science Society\n  (CogSci 2025)", "summary": "We present a minimalistic representation model for the head direction (HD)\nsystem, aiming to learn a high-dimensional representation of head direction\nthat captures essential properties of HD cells. Our model is a representation\nof rotation group $U(1)$, and we study both the fully connected version and\nconvolutional version. We demonstrate the emergence of Gaussian-like tuning\nprofiles and a 2D circle geometry in both versions of the model. We also\ndemonstrate that the learned model is capable of accurate path integration.", "AI": {"tldr": "A minimalistic model for head direction representation learns high-dimensional HD cell properties, showing Gaussian-like tuning and 2D circle geometry, with accurate path integration.", "motivation": "To create a simple yet effective model for representing head direction (HD) that captures key properties of HD cells.", "method": "Uses a $U(1)$ rotation group representation, testing fully connected and convolutional versions.", "result": "Emergence of Gaussian-like tuning profiles, 2D circle geometry, and accurate path integration in both model versions.", "conclusion": "The model successfully captures essential HD cell properties and demonstrates functional path integration."}}
{"id": "2502.10973", "pdf": "https://arxiv.org/pdf/2502.10973", "abs": "https://arxiv.org/abs/2502.10973", "authors": ["David Sasu", "Zehui Wu", "Ziwei Gong", "Run Chen", "Pengyuan Shi", "Lin Ai", "Julia Hirschberg", "Natalie Schluter"], "title": "Akan Cinematic Emotions (ACE): A Multimodal Multi-party Dataset for Emotion Recognition in Movie Dialogues", "categories": ["cs.CL"], "comment": "Accepted to Findings at ACL 2025", "summary": "In this paper, we introduce the Akan Conversation Emotion (ACE) dataset, the\nfirst multimodal emotion dialogue dataset for an African language, addressing\nthe significant lack of resources for low-resource languages in emotion\nrecognition research. ACE, developed for the Akan language, contains 385\nemotion-labeled dialogues and 6,162 utterances across audio, visual, and\ntextual modalities, along with word-level prosodic prominence annotations. The\npresence of prosodic labels in this dataset also makes it the first\nprosodically annotated African language dataset. We demonstrate the quality and\nutility of ACE through experiments using state-of-the-art emotion recognition\nmethods, establishing solid baselines for future research. We hope ACE inspires\nfurther work on inclusive, linguistically and culturally diverse NLP resources.", "AI": {"tldr": "The paper introduces ACE, the first multimodal emotion dialogue dataset for the Akan language, addressing resource gaps in low-resource languages for emotion recognition.", "motivation": "To address the lack of emotion recognition resources for low-resource languages, particularly African languages like Akan.", "method": "Developed the ACE dataset with 385 emotion-labeled dialogues and 6,162 utterances across audio, visual, and textual modalities, including prosodic annotations.", "result": "Demonstrated ACE's quality and utility through experiments with state-of-the-art emotion recognition methods, setting baselines for future research.", "conclusion": "ACE aims to inspire more inclusive and diverse NLP resources, bridging gaps in emotion recognition for underrepresented languages."}}
{"id": "2411.12188", "pdf": "https://arxiv.org/pdf/2411.12188", "abs": "https://arxiv.org/abs/2411.12188", "authors": ["Shuntaro Okada", "Kenji Doi", "Ryota Yoshihashi", "Hirokatsu Kataoka", "Tomohiro Tanaka"], "title": "Constant Rate Scheduling: Constant-Rate Distributional Change for Efficient Training and Sampling in Diffusion Models", "categories": ["cs.CV", "cs.LG"], "comment": "44 pages, 20 figures, 25 tables", "summary": "We propose a general approach to optimize noise schedules for training and\nsampling in diffusion models. Our approach optimizes the noise schedules to\nensure a constant rate of change in the probability distribution of diffused\ndata throughout the diffusion process. Any distance metric for measuring the\nprobability-distributional change is applicable to our approach, and we\nintroduce three distance metrics. We evaluated the effectiveness of our\napproach on unconditional and class-conditional image-generation tasks using\nthe LSUN (Horse, Bedroom, Church), ImageNet, FFHQ, and CIFAR10 datasets.\nThrough extensive experiments, we confirmed that our approach broadly improves\nthe performance of pixel-space and latent-space diffusion models regardless of\nthe dataset, sampler, and number of function evaluations ranging from 5 to 250.\nNotably, by using our approach for optimizing both training and sampling\nschedules, we achieved a state-of-the-art FID score of 2.03 without sacrificing\nmode coverage on LSUN Horse 256 $\\times$ 256.", "AI": {"tldr": "A method to optimize noise schedules in diffusion models for consistent probability distribution changes, improving performance across datasets and samplers.", "motivation": "To enhance diffusion model performance by ensuring a steady rate of change in the probability distribution during diffusion.", "method": "Optimizes noise schedules using adaptable distance metrics for probability-distributional change, tested on various datasets and samplers.", "result": "Achieved state-of-the-art FID score of 2.03 on LSUN Horse 256\u00d7256, with broad performance improvements.", "conclusion": "The approach effectively optimizes noise schedules, enhancing diffusion model performance universally."}}
{"id": "2005.04088", "pdf": "https://arxiv.org/pdf/2005.04088", "abs": "https://arxiv.org/abs/2005.04088", "authors": ["Xinshun Liu", "He Xin", "Mao Hui", "Liu Jing", "Lai Weizhong", "Ye Qingwen"], "title": "Automatic Cross-Domain Transfer Learning for Linear Regression", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "Transfer learning research attempts to make model induction transferable\nacross different domains. This method assumes that specific information\nregarding to which domain each instance belongs is known. This paper helps to\nextend the capability of transfer learning for linear regression problems to\nsituations where the domain information is uncertain or unknown; in fact, the\nframework can be extended to classification problems. For normal datasets, we\nassume that some latent domain information is available for transfer learning.\nThe instances in each domain can be inferred by different parameters. We obtain\nthis domain information from the distribution of the regression coefficients\ncorresponding to the explanatory variable $x$ as well as the response variable\n$y$ based on a Dirichlet process, which is more reasonable. As a result, we\ntransfer not only variable $x$ as usual but also variable $y$, which is\nchallenging since the testing data have no response value. Previous work mainly\novercomes the problem via pseudo-labelling based on transductive learning,\nwhich introduces serious bias. We provide a novel framework for analysing the\nproblem and considering this general situation: the joint distribution of\nvariable $x$ and variable $y$. Furthermore, our method controls the bias well\ncompared with previous work. We perform linear regression on the new feature\nspace that consists of different latent domains and the target domain, which is\nfrom the testing data. The experimental results show that the proposed model\nperforms well on real datasets.", "AI": {"tldr": "This paper extends transfer learning for linear regression to cases where domain information is uncertain or unknown, using a Dirichlet process to infer latent domains and jointly modeling variables x and y to reduce bias.", "motivation": "Current transfer learning assumes known domain information, limiting its applicability. This work addresses scenarios where domain details are uncertain or unavailable.", "method": "The framework infers latent domains via a Dirichlet process, jointly models x and y, and performs regression on a new feature space combining latent and target domains.", "result": "Experiments show the model performs well on real datasets, effectively controlling bias compared to pseudo-labeling methods.", "conclusion": "The proposed method successfully extends transfer learning to uncertain domains, improving performance and reducing bias by jointly modeling x and y."}}
{"id": "2411.17931", "pdf": "https://arxiv.org/pdf/2411.17931", "abs": "https://arxiv.org/abs/2411.17931", "authors": ["Jubin Abhishek Soni", "Amit Anand", "Rajesh Kumar Pandey", "Aniket Abhishek Soni"], "title": "Combining Threat Intelligence with IoT Scanning to Predict Cyber Attack", "categories": ["cs.CR", "cs.AI", "cs.CY", "cs.NI"], "comment": "6 pages, 6 figures, 2 tables, 1 listing. This manuscript has been\n  submitted to IEEE for review and is under consideration. Researchers are\n  welcome to read and build upon this work; please cite it appropriately. For\n  questions or clarifications, feel free to contact me", "summary": "While the Web has become a global platform for communication, malicious\nactors, including hackers and hacktivist groups, often disseminate ideological\ncontent and coordinate activities through the \"Dark Web\", an obscure\ncounterpart of the conventional web. Presently, challenges such as information\noverload and the fragmented nature of cyber threat data impede comprehensive\nprofiling of these actors, thereby limiting the efficacy of predictive analyses\nof their online activities. Concurrently, the proliferation of\ninternet-connected devices has surpassed the global human population, with this\ndisparity projected to widen as the Internet of Things (IoT) expands. Technical\ncommunities are actively advancing IoT-related research to address its growing\nsocietal integration. This paper proposes a novel predictive threat\nintelligence framework designed to systematically collect, analyze, and\nvisualize Dark Web data to identify malicious websites and correlate this\ninformation with potential IoT vulnerabilities. The methodology integrates\nautomated data harvesting, analytical techniques, and visual mapping tools,\nwhile also examining vulnerabilities in IoT devices to assess exploitability.\nBy bridging gaps in cybersecurity research, this study aims to enhance\npredictive threat modeling and inform policy development, thereby contributing\nto intelligence research initiatives focused on mitigating cyber risks in an\nincreasingly interconnected digital ecosystem.", "AI": {"tldr": "A predictive threat intelligence framework for the Dark Web and IoT vulnerabilities is proposed to enhance cybersecurity by analyzing and visualizing malicious activities.", "motivation": "The rise of malicious actors on the Dark Web and IoT expansion create gaps in cybersecurity, necessitating better predictive threat modeling.", "method": "Automated data harvesting, analytical techniques, and visual mapping tools are used to analyze Dark Web data and IoT vulnerabilities.", "result": "The framework identifies malicious websites and correlates them with IoT vulnerabilities, improving threat intelligence.", "conclusion": "This study bridges cybersecurity gaps, aids predictive modeling, and informs policy to mitigate risks in a connected digital ecosystem."}}
{"id": "2502.11075", "pdf": "https://arxiv.org/pdf/2502.11075", "abs": "https://arxiv.org/abs/2502.11075", "authors": ["Haoyang Li", "Xuejia Chen", "Zhanchao XU", "Darian Li", "Nicole Hu", "Fei Teng", "Yiming Li", "Luyu Qiu", "Chen Jason Zhang", "Qing Li", "Lei Chen"], "title": "Exposing Numeracy Gaps: A Benchmark to Evaluate Fundamental Numerical Abilities in Large Language Models", "categories": ["cs.CL", "cs.AI"], "comment": "Accepted by ACL 2025", "summary": "Large Language Models (LLMs) have demonstrated impressive capabilities in\nnatural language processing tasks, such as text generation and semantic\nunderstanding. However, their performance on numerical reasoning tasks, such as\nbasic arithmetic, numerical retrieval, and magnitude comparison, remains\nsurprisingly poor. This gap arises from their reliance on surface-level\nstatistical patterns rather than understanding numbers as continuous\nmagnitudes. Existing benchmarks primarily focus on either linguistic competence\nor structured mathematical problem-solving, neglecting fundamental numerical\nreasoning required in real-world scenarios. To bridge this gap, we propose\nNumericBench, a comprehensive benchmark to evaluate six fundamental numerical\ncapabilities: number recognition, arithmetic operations, contextual retrieval,\ncomparison, summary, and logical reasoning. NumericBench includes datasets\nranging from synthetic number lists to the crawled real-world data, addressing\nchallenges like long contexts, noise, and multi-step reasoning. Extensive\nexperiments on state-of-the-art LLMs, including GPT-4 and DeepSeek, reveal\npersistent weaknesses in numerical reasoning, highlighting the urgent need to\nimprove numerically-aware language modeling. The benchmark is released in:\nhttps://github.com/TreeAI-Lab/NumericBench.", "AI": {"tldr": "NumericBench is a benchmark to evaluate LLMs' numerical reasoning, revealing their weaknesses despite strong linguistic performance.", "motivation": "LLMs struggle with numerical tasks due to reliance on surface-level patterns, lacking understanding of numbers as continuous magnitudes.", "method": "Proposes NumericBench, a benchmark with six numerical capabilities, tested on LLMs like GPT-4 and DeepSeek.", "result": "LLMs show persistent weaknesses in numerical reasoning, emphasizing the need for improvement.", "conclusion": "NumericBench highlights gaps in LLMs' numerical reasoning, urging development of numerically-aware models."}}
{"id": "2411.14725", "pdf": "https://arxiv.org/pdf/2411.14725", "abs": "https://arxiv.org/abs/2411.14725", "authors": ["Feng Chen", "Chenhui Gou", "Jing Liu", "Yang Yang", "Zhaoyang Li", "Jiyuan Zhang", "Zhenbang Sun", "Bohan Zhuang", "Qi Wu"], "title": "Evaluating and Advancing Multimodal Large Language Models in Perception Ability Lens", "categories": ["cs.CV", "cs.CL", "cs.LG"], "comment": "Code repository:\n  https://github.com/Chenfeng1271/AbilityLens/tree/main", "summary": "As multimodal large language models (MLLMs) advance rapidly, rigorous\nevaluation has become essential, providing further guidance for their\ndevelopment. In this work, we focus on a unified and robust evaluation of\n\\textbf{vision perception} abilities, the foundational skill of MLLMs. We find\nthat existing perception benchmarks, each focusing on different question types,\ndomains, and evaluation metrics, introduce significant evaluation variance,\ncomplicating comprehensive assessments of perception abilities when relying on\nany single benchmark. To address this, we introduce \\textbf{AbilityLens}, a\nunified benchmark designed to evaluate MLLMs in six key perception abilities\n(ranging from counting, OCR, to understanding structural data), focusing on\nboth accuracy and stability, with each ability encompassing diverse types of\nquestions, domains, and metrics. With the assistance of AbilityLens, we: (1)\nidentify the strengths and weaknesses of current main-stream MLLMs,\nhighlighting stability patterns and revealing a notable performance gap between\nstate-of-the-art open-source and closed-source models; (2) uncover interesting\nability conflict and early convergence phenomena during MLLM training; (3)\nreveal the primary reason of ability conflict is data mixing ratio and LLM\nmodel size; and (4) discuss the effectiveness of some straightforward\nstrategies \\eg, fine-tuning and model merging, to solve the ability conflict.\nThe benchmark and online leaderboard is released in\nhttps://github.com/Chenfeng1271/AbilityLens.", "AI": {"tldr": "AbilityLens is a unified benchmark for evaluating vision perception in MLLMs, addressing variance in existing benchmarks and revealing insights into model performance, training phenomena, and conflict resolution.", "motivation": "Existing perception benchmarks lack consistency, complicating comprehensive evaluation of MLLMs' vision abilities.", "method": "Introduces AbilityLens, a benchmark evaluating six key perception abilities with diverse questions, domains, and metrics.", "result": "Identifies strengths/weaknesses of MLLMs, reveals training phenomena, and highlights data mixing and model size as conflict causes.", "conclusion": "AbilityLens provides robust evaluation and insights, with potential solutions like fine-tuning to address conflicts."}}
{"id": "2209.01205", "pdf": "https://arxiv.org/pdf/2209.01205", "abs": "https://arxiv.org/abs/2209.01205", "authors": ["Han Wu", "Jie Yin", "Bala Rajaratnam", "Jianyuan Guo"], "title": "Hierarchical Relational Learning for Few-Shot Knowledge Graph Completion", "categories": ["cs.LG", "cs.CV", "I.2"], "comment": "Published at ICLR 2023", "summary": "Knowledge graphs (KGs) are powerful in terms of their inference abilities,\nbut are also notorious for their incompleteness and long-tail distribution of\nrelations. To address these challenges and expand the coverage of KGs, few-shot\nKG completion aims to make predictions for triplets involving novel relations\nwhen only a few training triplets are provided as reference. Previous methods\nhave focused on designing local neighbor aggregators to learn entity-level\ninformation and/or imposing a potentially invalid sequential dependency\nassumption at the triplet level to learn meta relation information. However,\npairwise triplet-level interactions and context-level relational information\nhave been largely overlooked for learning meta representations of few-shot\nrelations. In this paper, we propose a hierarchical relational learning method\n(HiRe) for few-shot KG completion. By jointly capturing three levels of\nrelational information (entity-level, triplet-level and context-level), HiRe\ncan effectively learn and refine meta representations of few-shot relations,\nand thus generalize well to new unseen relations. Extensive experiments on\nbenchmark datasets validate the superiority of HiRe over state-of-the-art\nmethods. The code can be found in https://github.com/alexhw15/HiRe.git.", "AI": {"tldr": "HiRe is a hierarchical relational learning method for few-shot KG completion, capturing entity-, triplet-, and context-level information to improve meta representations of relations.", "motivation": "Address incompleteness and long-tail distribution in KGs by enhancing few-shot KG completion with richer relational information.", "method": "Proposes HiRe, which jointly learns entity-level, triplet-level, and context-level relational information.", "result": "Outperforms state-of-the-art methods on benchmark datasets.", "conclusion": "HiRe effectively generalizes to unseen relations by leveraging multi-level relational information."}}
{"id": "2412.07820", "pdf": "https://arxiv.org/pdf/2412.07820", "abs": "https://arxiv.org/abs/2412.07820", "authors": ["Lennart Schneider", "Martin Wistuba", "Aaron Klein", "Jacek Golebiowski", "Giovanni Zappella", "Felice Antonio Merra"], "title": "Hyperband-based Bayesian Optimization for Black-box Prompt Selection", "categories": ["cs.LG", "cs.AI"], "comment": "Accepted at ICML 2025. 26 pages, 11 tables, 7 figures", "summary": "Optimal prompt selection is crucial for maximizing large language model (LLM)\nperformance on downstream tasks, especially in black-box settings where models\nare only accessible via APIs. Black-box prompt selection is challenging due to\npotentially large, combinatorial search spaces, absence of gradient\ninformation, and high evaluation cost of prompts on a validation set. We\npropose HbBoPs, a novel method that combines a structural-aware deep kernel\nGaussian Process with Hyperband as a multi-fidelity scheduler to efficiently\nselect prompts. HbBoPs uses embeddings of instructions and few-shot exemplars,\ntreating them as modular components within prompts. This enhances the surrogate\nmodel's ability to predict which prompt to evaluate next in a sample-efficient\nmanner. Hyperband improves query-efficiency by adaptively allocating resources\nacross different fidelity levels, reducing the number of validation instances\nrequired for evaluating prompts. Extensive experiments across ten diverse\nbenchmarks and three LLMs demonstrate that HbBoPs outperforms state-of-the-art\nmethods in both performance and efficiency.", "AI": {"tldr": "HbBoPs is a method for efficient black-box prompt selection in LLMs, combining a deep kernel Gaussian Process with Hyperband for improved performance and efficiency.", "motivation": "Optimal prompt selection is critical for LLM performance, but challenging in black-box settings due to large search spaces, lack of gradients, and high evaluation costs.", "method": "HbBoPs uses a structural-aware deep kernel Gaussian Process and Hyperband scheduler to efficiently select prompts by treating instructions and exemplars as modular components.", "result": "HbBoPs outperforms state-of-the-art methods across ten benchmarks and three LLMs in performance and efficiency.", "conclusion": "HbBoPs provides a sample-efficient and query-efficient solution for black-box prompt selection in LLMs."}}
{"id": "2502.12665", "pdf": "https://arxiv.org/pdf/2502.12665", "abs": "https://arxiv.org/abs/2502.12665", "authors": ["Junhui He", "Junna Xing", "Nan Wang", "Rui Xu", "Shangyu Wu", "Peng Zhou", "Qiang Liu", "Chun Jason Xue", "Qingan Li"], "title": "A$^2$ATS: Retrieval-Based KV Cache Reduction via Windowed Rotary Position Embedding and Query-Aware Vector Quantization", "categories": ["cs.CL"], "comment": null, "summary": "Long context large language models (LLMs) pose significant challenges for\nefficient serving due to the large memory footprint and high access overhead of\nKV cache. Retrieval-based KV cache reduction methods can mitigate these\nchallenges, typically by offloading the complete KV cache to CPU and retrieving\nnecessary tokens on demand during inference. However, these methods still\nsuffer from unsatisfactory accuracy degradation and extra retrieval overhead.\nTo address these limitations, this paper proposes A$^2$ATS, a novel\nretrieval-based KV cache reduction method. A$^2$ATS aims to obtain an accurate\napproximation of attention scores by applying the vector quantization technique\nto key states, thereby enabling efficient and precise retrieval of the top-K\ntokens. First, we propose Windowed Rotary Position Embedding, which decouples\nthe positional dependency from query and key states after position embedding.\nThen, we propose query-aware vector quantization that optimizes the objective\nof attention score approximation directly. Finally, we design the heterogeneous\ninference architecture for KV cache offloading, enabling long context serving\nwith larger batch sizes. Experimental results demonstrate that A$^2$ATS can\nachieve a lower performance degradation with similar or lower overhead compared\nto existing methods, thereby increasing long context serving throughput by up\nto $2.7 \\times$.", "AI": {"tldr": "A$^2$ATS is a retrieval-based KV cache reduction method for LLMs, improving efficiency and accuracy by using vector quantization and a novel inference architecture.", "motivation": "Long context LLMs face inefficiencies due to large KV cache memory and retrieval overhead, leading to accuracy degradation.", "method": "A$^2$ATS uses vector quantization on key states, Windowed Rotary Position Embedding, and a heterogeneous inference architecture for KV cache offloading.", "result": "A$^2$ATS reduces performance degradation and overhead, increasing serving throughput by up to 2.7x.", "conclusion": "A$^2$ATS effectively addresses KV cache challenges, enhancing long context LLM serving efficiency."}}
{"id": "2412.13541", "pdf": "https://arxiv.org/pdf/2412.13541", "abs": "https://arxiv.org/abs/2412.13541", "authors": ["Jingyao Wang", "Wenwen Qiang", "Changwen Zheng", "Fuchun Sun"], "title": "Spatio-Temporal Fuzzy-oriented Multi-Modal Meta-Learning for Fine-grained Emotion Recognition", "categories": ["cs.CV", "cs.LG", "cs.NE"], "comment": "This work has been submitted to the IEEE for possible publication", "summary": "Fine-grained emotion recognition (FER) plays a vital role in various fields,\nsuch as disease diagnosis, personalized recommendations, and multimedia mining.\nHowever, existing FER methods face three key challenges in real-world\napplications: (i) they rely on large amounts of continuously annotated data to\nensure accuracy since emotions are complex and ambiguous in reality, which is\ncostly and time-consuming; (ii) they cannot capture the temporal heterogeneity\ncaused by changing emotion patterns, because they usually assume that the\ntemporal correlation within sampling periods is the same; (iii) they do not\nconsider the spatial heterogeneity of different FER scenarios, that is, the\ndistribution of emotion information in different data may have bias or\ninterference. To address these challenges, we propose a Spatio-Temporal\nFuzzy-oriented Multi-modal Meta-learning framework (ST-F2M). Specifically,\nST-F2M first divides the multi-modal videos into multiple views, and each view\ncorresponds to one modality of one emotion. Multiple randomly selected views\nfor the same emotion form a meta-training task. Next, ST-F2M uses an integrated\nmodule with spatial and temporal convolutions to encode the data of each task,\nreflecting the spatial and temporal heterogeneity. Then it adds fuzzy semantic\ninformation to each task based on generalized fuzzy rules, which helps handle\nthe complexity and ambiguity of emotions. Finally, ST-F2M learns\nemotion-related general meta-knowledge through meta-recurrent neural networks\nto achieve fast and robust fine-grained emotion recognition. Extensive\nexperiments show that ST-F2M outperforms various state-of-the-art methods in\nterms of accuracy and model efficiency. In addition, we construct ablation\nstudies and further analysis to explore why ST-F2M performs well.", "AI": {"tldr": "ST-F2M is a framework for fine-grained emotion recognition (FER) that addresses challenges like data annotation costs, temporal heterogeneity, and spatial heterogeneity using spatio-temporal fuzzy-oriented meta-learning.", "motivation": "Existing FER methods struggle with high annotation costs, temporal and spatial heterogeneity, and emotion ambiguity. ST-F2M aims to overcome these limitations.", "method": "ST-F2M divides multi-modal videos into views, uses spatio-temporal convolutions, integrates fuzzy semantics, and employs meta-recurrent neural networks for meta-learning.", "result": "ST-F2M outperforms state-of-the-art methods in accuracy and efficiency, validated by extensive experiments and ablation studies.", "conclusion": "ST-F2M effectively handles FER challenges, offering a robust and efficient solution with demonstrated superiority over existing approaches."}}
{"id": "2305.15612", "pdf": "https://arxiv.org/pdf/2305.15612", "abs": "https://arxiv.org/abs/2305.15612", "authors": ["Jungtaek Kim"], "title": "Density Ratio Estimation-based Bayesian Optimization with Semi-Supervised Learning", "categories": ["cs.LG", "stat.ML"], "comment": "Accepted at the 42nd International Conference on Machine Learning\n  (ICML 2025)", "summary": "Bayesian optimization has attracted huge attention from diverse research\nareas in science and engineering, since it is capable of efficiently finding a\nglobal optimum of an expensive-to-evaluate black-box function. In general, a\nprobabilistic regression model is widely used as a surrogate function to model\nan explicit distribution over function evaluations given an input to estimate\nand a training dataset. Beyond the probabilistic regression-based methods,\ndensity ratio estimation-based Bayesian optimization has been suggested in\norder to estimate a density ratio of the groups relatively close and relatively\nfar to a global optimum. Developing this line of research further, supervised\nclassifiers are employed to estimate a class probability for the two groups\ninstead of a density ratio. However, the supervised classifiers used in this\nstrategy are prone to be overconfident for known knowledge on global solution\ncandidates. Supposing that we have access to unlabeled points, e.g., predefined\nfixed-size pools, we propose density ratio estimation-based Bayesian\noptimization with semi-supervised learning to solve this challenge. Finally, we\nshow the empirical results of our methods and several baseline methods in two\ndistinct scenarios with unlabeled point sampling and a fixed-size pool, and\nanalyze the validity of our methods in diverse experiments.", "AI": {"tldr": "The paper proposes a semi-supervised learning approach for Bayesian optimization, addressing overconfidence in supervised classifiers by leveraging unlabeled data.", "motivation": "Bayesian optimization is widely used but faces challenges with overconfidence in supervised classifiers when estimating class probabilities for global optima.", "method": "The authors introduce density ratio estimation-based Bayesian optimization with semi-supervised learning, utilizing unlabeled points to improve accuracy.", "result": "Empirical results demonstrate the method's effectiveness in scenarios with unlabeled point sampling and fixed-size pools.", "conclusion": "The proposed semi-supervised approach enhances Bayesian optimization performance and validity across diverse experiments."}}
{"id": "2412.15289", "pdf": "https://arxiv.org/pdf/2412.15289", "abs": "https://arxiv.org/abs/2412.15289", "authors": ["Xiaoning Dong", "Wenbo Hu", "Wei Xu", "Tianxing He"], "title": "SATA: A Paradigm for LLM Jailbreak via Simple Assistive Task Linkage", "categories": ["cs.CR", "cs.AI", "cs.CL"], "comment": null, "summary": "Large language models (LLMs) have made significant advancements across\nvarious tasks, but their safety alignment remain a major concern. Exploring\njailbreak prompts can expose LLMs' vulnerabilities and guide efforts to secure\nthem. Existing methods primarily design sophisticated instructions for the LLM\nto follow, or rely on multiple iterations, which could hinder the performance\nand efficiency of jailbreaks. In this work, we propose a novel jailbreak\nparadigm, Simple Assistive Task Linkage (SATA), which can effectively\ncircumvent LLM safeguards and elicit harmful responses. Specifically, SATA\nfirst masks harmful keywords within a malicious query to generate a relatively\nbenign query containing one or multiple [MASK] special tokens. It then employs\na simple assistive task such as a masked language model task or an element\nlookup by position task to encode the semantics of the masked keywords.\nFinally, SATA links the assistive task with the masked query to jointly perform\nthe jailbreak. Extensive experiments show that SATA achieves state-of-the-art\nperformance and outperforms baselines by a large margin. Specifically, on\nAdvBench dataset, with mask language model (MLM) assistive task, SATA achieves\nan overall attack success rate (ASR) of 85% and harmful score (HS) of 4.57, and\nwith element lookup by position (ELP) assistive task, SATA attains an overall\nASR of 76% and HS of 4.43.", "AI": {"tldr": "SATA is a novel jailbreak method for LLMs that masks harmful keywords and uses assistive tasks to bypass safeguards, achieving high attack success rates.", "motivation": "Addressing the safety vulnerabilities of LLMs by exploring jailbreak prompts to improve their security.", "method": "SATA masks harmful keywords, uses assistive tasks (like MLM or ELP) to encode semantics, and links tasks to perform jailbreaks.", "result": "SATA achieves 85% ASR with MLM and 76% ASR with ELP on AdvBench, outperforming baselines.", "conclusion": "SATA effectively exposes LLM vulnerabilities, guiding future safety improvements."}}
{"id": "2502.12921", "pdf": "https://arxiv.org/pdf/2502.12921", "abs": "https://arxiv.org/abs/2502.12921", "authors": ["George-Kirollos Saad", "Scott Sanner"], "title": "Q-STRUM Debate: Query-Driven Contrastive Summarization for Recommendation Comparison", "categories": ["cs.CL"], "comment": null, "summary": "Query-driven recommendation with unknown items poses a challenge for users to\nunderstand why certain items are appropriate for their needs. Query-driven\nContrastive Summarization (QCS) is a methodology designed to address this issue\nby leveraging language-based item descriptions to clarify contrasts between\nthem. However, existing state-of-the-art contrastive summarization methods such\nas STRUM-LLM fall short of this goal. To overcome these limitations, we\nintroduce Q-STRUM Debate, a novel extension of STRUM-LLM that employs\ndebate-style prompting to generate focused and contrastive summarizations of\nitem aspects relevant to a query. Leveraging modern large language models\n(LLMs) as powerful tools for generating debates, Q-STRUM Debate provides\nenhanced contrastive summaries. Experiments across three datasets demonstrate\nthat Q-STRUM Debate yields significant performance improvements over existing\nmethods on key contrastive summarization criteria, thus introducing a novel and\nperformant debate prompting methodology for QCS.", "AI": {"tldr": "Q-STRUM Debate improves query-driven contrastive summarization by using debate-style prompting with LLMs, outperforming existing methods.", "motivation": "Existing methods like STRUM-LLM fail to clarify why items match queries in query-driven recommendation.", "method": "Q-STRUM Debate extends STRUM-LLM with debate-style prompting to generate focused, contrastive summaries.", "result": "Experiments show Q-STRUM Debate outperforms existing methods on contrastive summarization criteria.", "conclusion": "Q-STRUM Debate introduces a novel, effective debate prompting method for QCS."}}
{"id": "2501.13106", "pdf": "https://arxiv.org/pdf/2501.13106", "abs": "https://arxiv.org/abs/2501.13106", "authors": ["Boqiang Zhang", "Kehan Li", "Zesen Cheng", "Zhiqiang Hu", "Yuqian Yuan", "Guanzheng Chen", "Sicong Leng", "Yuming Jiang", "Hang Zhang", "Xin Li", "Peng Jin", "Wenqi Zhang", "Fan Wang", "Lidong Bing", "Deli Zhao"], "title": "VideoLLaMA 3: Frontier Multimodal Foundation Models for Image and Video Understanding", "categories": ["cs.CV"], "comment": "BZ, KL, ZC, ZH, YY, GC, SL, YJ, HZ, and XL contributed equally to\n  this project. Code: https://github.com/DAMO-NLP-SG/VideoLLaMA3", "summary": "In this paper, we propose VideoLLaMA3, a more advanced multimodal foundation\nmodel for image and video understanding. The core design philosophy of\nVideoLLaMA3 is vision-centric. The meaning of \"vision-centric\" is two-fold: the\nvision-centric training paradigm and vision-centric framework design. The key\ninsight of our vision-centric training paradigm is that high-quality image-text\ndata is crucial for both image and video understanding. Instead of preparing\nmassive video-text datasets, we focus on constructing large-scale and\nhigh-quality image-text datasets. VideoLLaMA3 has four training stages: 1)\nVision Encoder Adaptation, which enables vision encoder to accept images of\nvariable resolutions as input; 2) Vision-Language Alignment, which jointly\ntunes the vision encoder, projector, and LLM with large-scale image-text data\ncovering multiple types (including scene images, documents, charts) as well as\ntext-only data. 3) Multi-task Fine-tuning, which incorporates image-text SFT\ndata for downstream tasks and video-text data to establish a foundation for\nvideo understanding. 4) Video-centric Fine-tuning, which further improves the\nmodel's capability in video understanding. As for the framework design, to\nbetter capture fine-grained details in images, the pretrained vision encoder is\nadapted to encode images of varying sizes into vision tokens with corresponding\nnumbers, rather than a fixed number of tokens. For video inputs, we reduce the\nnumber of vision tokens according to their similarity so that the\nrepresentation of videos will be more precise and compact. Benefit from\nvision-centric designs, VideoLLaMA3 achieves compelling performances in both\nimage and video understanding benchmarks.", "AI": {"tldr": "VideoLLaMA3 is a vision-centric multimodal model for image and video understanding, leveraging high-quality image-text data and a four-stage training process to achieve strong performance.", "motivation": "The motivation is to improve image and video understanding by focusing on vision-centric training and framework design, avoiding the need for massive video-text datasets.", "method": "The method involves four stages: Vision Encoder Adaptation, Vision-Language Alignment, Multi-task Fine-tuning, and Video-centric Fine-tuning, along with a framework design for variable-resolution images and compact video representations.", "result": "VideoLLaMA3 achieves compelling performance in image and video understanding benchmarks.", "conclusion": "The vision-centric approach and framework design of VideoLLaMA3 effectively enhance multimodal understanding capabilities."}}
{"id": "2306.17301", "pdf": "https://arxiv.org/pdf/2306.17301", "abs": "https://arxiv.org/abs/2306.17301", "authors": ["Shijun Zhang", "Hongkai Zhao", "Yimin Zhong", "Haomin Zhou"], "title": "Why Shallow Networks Struggle to Approximate and Learn High Frequencies", "categories": ["cs.LG", "cs.NA", "math.NA", "stat.ML"], "comment": null, "summary": "In this work, we present a comprehensive study combining mathematical and\ncomputational analysis to explain why a two-layer neural network struggles to\nhandle high frequencies in both approximation and learning, especially when\nmachine precision, numerical noise, and computational cost are significant\nfactors in practice. Specifically, we investigate the following fundamental\ncomputational issues: (1) the minimal numerical error achievable under finite\nprecision, (2) the computational cost required to attain a given accuracy, and\n(3) the stability of the method with respect to perturbations. The core of our\nanalysis lies in the conditioning of the representation and its learning\ndynamics. Explicit answers to these questions are provided, along with\nsupporting numerical evidence.", "AI": {"tldr": "The paper analyzes why two-layer neural networks struggle with high frequencies, focusing on numerical error, computational cost, and stability under finite precision.", "motivation": "To understand the limitations of two-layer neural networks in handling high frequencies due to practical constraints like machine precision and computational cost.", "method": "Combines mathematical and computational analysis to study numerical error, cost, and stability, focusing on representation conditioning and learning dynamics.", "result": "Provides explicit answers and numerical evidence on achievable error, required cost, and method stability.", "conclusion": "Highlights the challenges of two-layer networks with high frequencies, offering insights into their practical limitations."}}
{"id": "2412.16311", "pdf": "https://arxiv.org/pdf/2412.16311", "abs": "https://arxiv.org/abs/2412.16311", "authors": ["Meng-Chieh Lee", "Qi Zhu", "Costas Mavromatis", "Zhen Han", "Soji Adeshina", "Vassilis N. Ioannidis", "Huzefa Rangwala", "Christos Faloutsos"], "title": "HybGRAG: Hybrid Retrieval-Augmented Generation on Textual and Relational Knowledge Bases", "categories": ["cs.LG", "cs.AI", "cs.IR"], "comment": "Accepted to ACL 2025", "summary": "Given a semi-structured knowledge base (SKB), where text documents are\ninterconnected by relations, how can we effectively retrieve relevant\ninformation to answer user questions? Retrieval-Augmented Generation (RAG)\nretrieves documents to assist large language models (LLMs) in question\nanswering; while Graph RAG (GRAG) uses structured knowledge bases as its\nknowledge source. However, many questions require both textual and relational\ninformation from SKB - referred to as \"hybrid\" questions - which complicates\nthe retrieval process and underscores the need for a hybrid retrieval method\nthat leverages both information. In this paper, through our empirical analysis,\nwe identify key insights that show why existing methods may struggle with\nhybrid question answering (HQA) over SKB. Based on these insights, we propose\nHybGRAG for HQA consisting of a retriever bank and a critic module, with the\nfollowing advantages: (1) Agentic, it automatically refines the output by\nincorporating feedback from the critic module, (2) Adaptive, it solves hybrid\nquestions requiring both textual and relational information with the retriever\nbank, (3) Interpretable, it justifies decision making with intuitive refinement\npath, and (4) Effective, it surpasses all baselines on HQA benchmarks. In\nexperiments on the STaRK benchmark, HybGRAG achieves significant performance\ngains, with an average relative improvement in Hit@1 of 51%.", "AI": {"tldr": "HybGRAG is a hybrid retrieval method for answering hybrid questions using both textual and relational data from semi-structured knowledge bases, outperforming existing methods.", "motivation": "Existing methods like RAG and GRAG struggle with hybrid questions requiring both textual and relational information from semi-structured knowledge bases.", "method": "HybGRAG combines a retriever bank and a critic module to adaptively retrieve and refine answers, leveraging both textual and relational data.", "result": "HybGRAG achieves a 51% average relative improvement in Hit@1 on the STaRK benchmark.", "conclusion": "HybGRAG is an effective, adaptive, and interpretable solution for hybrid question answering over semi-structured knowledge bases."}}
{"id": "2502.14376", "pdf": "https://arxiv.org/pdf/2502.14376", "abs": "https://arxiv.org/abs/2502.14376", "authors": ["Fangming Cui", "Jan Fong", "Rongfei Zeng", "Xinmei Tian", "Jun Yu"], "title": "A Similarity Paradigm Through Textual Regularization Without Forgetting", "categories": ["cs.CL", "cs.CV"], "comment": null, "summary": "Prompt learning has emerged as a promising method for adapting pre-trained\nvisual-language models (VLMs) to a range of downstream tasks. While optimizing\nthe context can be effective for improving performance on specific tasks, it\ncan often lead to poor generalization performance on unseen classes or datasets\nsampled from different distributions. It may be attributed to the fact that\ntextual prompts tend to overfit downstream data distributions, leading to the\nforgetting of generalized knowledge derived from hand-crafted prompts. In this\npaper, we propose a novel method called Similarity Paradigm with Textual\nRegularization (SPTR) for prompt learning without forgetting. SPTR is a\ntwo-pronged design based on hand-crafted prompts that is an inseparable\nframework. 1) To avoid forgetting general textual knowledge, we introduce the\noptimal transport as a textual regularization to finely ensure approximation\nwith hand-crafted features and tuning textual features. 2) In order to\ncontinuously unleash the general ability of multiple hand-crafted prompts, we\npropose a similarity paradigm for natural alignment score and adversarial\nalignment score to improve model robustness for generalization. Both modules\nshare a common objective in addressing generalization issues, aiming to\nmaximize the generalization capability derived from multiple hand-crafted\nprompts. Four representative tasks (i.e., non-generalization few-shot learning,\nbase-to-novel generalization, cross-dataset generalization, domain\ngeneralization) across 11 datasets demonstrate that SPTR outperforms existing\nprompt learning methods.", "AI": {"tldr": "SPTR is a novel prompt learning method that avoids overfitting by combining textual regularization and a similarity paradigm, outperforming existing methods on multiple tasks.", "motivation": "Prompt learning often overfits downstream tasks, forgetting generalized knowledge from hand-crafted prompts. SPTR aims to preserve this knowledge while improving generalization.", "method": "SPTR uses optimal transport for textual regularization and a similarity paradigm for alignment scores to enhance robustness.", "result": "SPTR outperforms existing methods on 11 datasets across four tasks, demonstrating superior generalization.", "conclusion": "SPTR effectively balances task-specific adaptation and generalization, making it a robust prompt learning approach."}}
{"id": "2501.17813", "pdf": "https://arxiv.org/pdf/2501.17813", "abs": "https://arxiv.org/abs/2501.17813", "authors": ["Mariano V. Ntrougkas", "Vasileios Mezaris", "Ioannis Patras"], "title": "P-TAME: Explain Any Image Classifier with Trained Perturbations", "categories": ["cs.CV", "cs.AI"], "comment": "Published in IEEE Open Journal of Signal Processing (Volume 6)", "summary": "The adoption of Deep Neural Networks (DNNs) in critical fields where\npredictions need to be accompanied by justifications is hindered by their\ninherent black-box nature. In this paper, we introduce P-TAME\n(Perturbation-based Trainable Attention Mechanism for Explanations), a\nmodel-agnostic method for explaining DNN-based image classifiers. P-TAME\nemploys an auxiliary image classifier to extract features from the input image,\nbypassing the need to tailor the explanation method to the internal\narchitecture of the backbone classifier being explained. Unlike traditional\nperturbation-based methods, which have high computational requirements, P-TAME\noffers an efficient alternative by generating high-resolution explanations in a\nsingle forward pass during inference. We apply P-TAME to explain the decisions\nof VGG-16, ResNet-50, and ViT-B-16, three distinct and widely used image\nclassifiers. Quantitative and qualitative results show that our method matches\nor outperforms previous explainability methods, including model-specific\napproaches. Code and trained models will be released upon acceptance.", "AI": {"tldr": "P-TAME is a model-agnostic method for explaining DNN-based image classifiers, offering efficient, high-resolution explanations without tailoring to specific architectures.", "motivation": "The black-box nature of DNNs limits their adoption in critical fields requiring justifications for predictions.", "method": "P-TAME uses an auxiliary classifier to extract features, bypassing architecture-specific tailoring, and generates explanations in a single forward pass.", "result": "P-TAME matches or outperforms existing explainability methods on VGG-16, ResNet-50, and ViT-B-16.", "conclusion": "P-TAME provides an efficient, high-quality solution for explaining DNN classifiers, with potential for broad application."}}
{"id": "2307.08507", "pdf": "https://arxiv.org/pdf/2307.08507", "abs": "https://arxiv.org/abs/2307.08507", "authors": ["Mete Kemertas", "Allan D. Jepson", "Amir-massoud Farahmand"], "title": "Efficient and Accurate Optimal Transport with Mirror Descent and Conjugate Gradients", "categories": ["cs.LG", "G.3; G.4; I.4.0"], "comment": "Published in Transactions on Machine Learning Research (TMLR)", "summary": "We propose Mirror Descent Optimal Transport (MDOT), a novel method for\nsolving discrete optimal transport (OT) problems with high precision, by\nunifying temperature annealing in entropic-regularized OT (EOT) with mirror\ndescent techniques. In this framework, temperature annealing produces a\nsequence of EOT dual problems, whose solution gradually gets closer to the\nsolution of the original OT problem. We solve each problem efficiently using a\nGPU-parallel nonlinear conjugate gradients algorithm (PNCG) that outperforms\ntraditional Sinkhorn iterations under weak regularization. Moreover, our\ninvestigation also reveals that the theoretical convergence rate of Sinkhorn\niterations can exceed existing non-asymptotic bounds when its stopping\ncriterion is tuned in a manner analogous to MDOT.\n  Our comprehensive ablation studies of MDOT-PNCG affirm its robustness across\na wide range of algorithmic parameters. Benchmarking on 24 problem sets of size\n$n=4096$ in a GPU environment demonstrate that our method attains\nhigh-precision, feasible solutions significantly faster than a representative\nset of existing OT solvers, including accelerated gradient methods and advanced\nSinkhorn variants, in both wall-clock time and number of operations. Empirical\nconvergence rates range between $O(n^2 \\varepsilon^{-1/4})$ and $O(n^2\n\\varepsilon^{-1})$, where $\\varepsilon$ is the optimality gap. For problem\nsizes up to $n=16384$, the empirical runtime scales as $O(n^2)$ for moderate\nprecision and as $O(n^{5/2})$ at worst for high precision. These findings\nestablish MDOT-PNCG as a compelling alternative to current OT solvers,\nparticularly in challenging weak-regularization regimes.", "AI": {"tldr": "MDOT-PNCG is a novel method for solving discrete optimal transport problems efficiently, outperforming existing solvers in speed and precision.", "motivation": "To address the limitations of traditional methods like Sinkhorn iterations in solving high-precision OT problems, especially under weak regularization.", "method": "Combines temperature annealing in entropic-regularized OT with mirror descent techniques, solved using a GPU-parallel nonlinear conjugate gradients algorithm (PNCG).", "result": "Achieves faster and more precise solutions than existing OT solvers, with empirical convergence rates ranging between O(n\u00b2\u03b5\u207b\u00b9/\u2074) and O(n\u00b2\u03b5\u207b\u00b9).", "conclusion": "MDOT-PNCG is a robust and efficient alternative for OT problems, particularly in weak-regularization scenarios."}}
{"id": "2412.18926", "pdf": "https://arxiv.org/pdf/2412.18926", "abs": "https://arxiv.org/abs/2412.18926", "authors": ["Rui Sun", "Yumin Zhang", "Varun Ojha", "Tejal Shah", "Haoran Duan", "Bo Wei", "Rajiv Ranjan"], "title": "Exemplar-condensed Federated Class-incremental Learning", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "We propose Exemplar-Condensed federated class-incremental learning (ECoral)\nto distil the training characteristics of real images from streaming data into\ninformative rehearsal exemplars. The proposed method eliminates the limitations\nof exemplar selection in replay-based approaches for mitigating catastrophic\nforgetting in federated continual learning (FCL). The limitations particularly\nrelated to the heterogeneity of information density of each summarized data.\nOur approach maintains the consistency of training gradients and the\nrelationship to past tasks for the summarized exemplars to represent the\nstreaming data compared to the original images effectively. Additionally, our\napproach reduces the information-level heterogeneity of the summarized data by\ninter-client sharing of the disentanglement generative model. Extensive\nexperiments show that our ECoral outperforms several state-of-the-art methods\nand can be seamlessly integrated with many existing approaches to enhance\nperformance.", "AI": {"tldr": "ECoral improves federated continual learning by distilling training characteristics into informative exemplars, addressing data heterogeneity and catastrophic forgetting.", "motivation": "To overcome limitations in exemplar selection for replay-based approaches in federated continual learning, particularly data heterogeneity.", "method": "Uses distillation to create rehearsal exemplars, maintains gradient consistency, and shares a generative model across clients.", "result": "Outperforms state-of-the-art methods and integrates well with existing approaches.", "conclusion": "ECoral effectively mitigates catastrophic forgetting and handles data heterogeneity in federated continual learning."}}
{"id": "2502.15109", "pdf": "https://arxiv.org/pdf/2502.15109", "abs": "https://arxiv.org/abs/2502.15109", "authors": ["Leena Mathur", "Marian Qian", "Paul Pu Liang", "Louis-Philippe Morency"], "title": "Social Genome: Grounded Social Reasoning Abilities of Multimodal Models", "categories": ["cs.CL", "cs.LG"], "comment": "Under Review, 24 pages", "summary": "Social reasoning abilities are crucial for AI systems to effectively\ninterpret and respond to multimodal human communication and interaction within\nsocial contexts. We introduce SOCIAL GENOME, the first benchmark for\nfine-grained, grounded social reasoning abilities of multimodal models. SOCIAL\nGENOME contains 272 videos of interactions and 1,486 human-annotated reasoning\ntraces related to inferences about these interactions. These traces contain\n5,777 reasoning steps that reference evidence from visual cues, verbal cues,\nvocal cues, and external knowledge (contextual knowledge external to videos).\nSOCIAL GENOME is also the first modeling challenge to study external knowledge\nin social reasoning. SOCIAL GENOME computes metrics to holistically evaluate\nsemantic and structural qualities of model-generated social reasoning traces.\nWe demonstrate the utility of SOCIAL GENOME through experiments with\nstate-of-the-art models, identifying performance gaps and opportunities for\nfuture research to improve the grounded social reasoning abilities of\nmultimodal models.", "AI": {"tldr": "SOCIAL GENOME is a benchmark for evaluating multimodal models' fine-grained social reasoning abilities using annotated video interactions and reasoning traces.", "motivation": "To assess and improve AI systems' ability to interpret and respond to human social interactions by grounding reasoning in multimodal cues and external knowledge.", "method": "Introduces SOCIAL GENOME, a dataset of 272 videos with 1,486 annotated reasoning traces (5,777 steps) referencing visual, verbal, vocal, and external knowledge cues.", "result": "Identifies performance gaps in state-of-the-art models, highlighting the need for improved grounded social reasoning.", "conclusion": "SOCIAL GENOME provides a comprehensive framework for evaluating and advancing multimodal models' social reasoning capabilities."}}
{"id": "2501.18913", "pdf": "https://arxiv.org/pdf/2501.18913", "abs": "https://arxiv.org/abs/2501.18913", "authors": ["Tongda Xu", "Xiyan Cai", "Xinjie Zhang", "Xingtong Ge", "Dailan He", "Ming Sun", "Jingjing Liu", "Ya-Qin Zhang", "Jian Li", "Yan Wang"], "title": "Rethinking Diffusion Posterior Sampling: From Conditional Score Estimator to Maximizing a Posterior", "categories": ["cs.CV"], "comment": "ICLR 2025", "summary": "Recent advancements in diffusion models have been leveraged to address\ninverse problems without additional training, and Diffusion Posterior Sampling\n(DPS) (Chung et al., 2022a) is among the most popular approaches. Previous\nanalyses suggest that DPS accomplishes posterior sampling by approximating the\nconditional score. While in this paper, we demonstrate that the conditional\nscore approximation employed by DPS is not as effective as previously assumed,\nbut rather aligns more closely with the principle of maximizing a posterior\n(MAP). This assertion is substantiated through an examination of DPS on 512x512\nImageNet images, revealing that: 1) DPS's conditional score estimation\nsignificantly diverges from the score of a well-trained conditional diffusion\nmodel and is even inferior to the unconditional score; 2) The mean of DPS's\nconditional score estimation deviates significantly from zero, rendering it an\ninvalid score estimation; 3) DPS generates high-quality samples with\nsignificantly lower diversity. In light of the above findings, we posit that\nDPS more closely resembles MAP than a conditional score estimator, and\naccordingly propose the following enhancements to DPS: 1) we explicitly\nmaximize the posterior through multi-step gradient ascent and projection; 2) we\nutilize a light-weighted conditional score estimator trained with only 100\nimages and 8 GPU hours. Extensive experimental results indicate that these\nproposed improvements significantly enhance DPS's performance. The source code\nfor these improvements is provided in\nhttps://github.com/tongdaxu/Rethinking-Diffusion-Posterior-Sampling-From-Conditional-Score-Estimator-to-Maximizing-a-Posterior.", "AI": {"tldr": "The paper re-evaluates Diffusion Posterior Sampling (DPS), showing it aligns more with MAP than conditional score estimation, and proposes enhancements to improve performance.", "motivation": "To challenge the assumption that DPS effectively approximates the conditional score, revealing its closer alignment with MAP and proposing improvements.", "method": "Examines DPS on 512x512 ImageNet images, identifies flaws in its conditional score estimation, and proposes multi-step gradient ascent and a lightweight conditional score estimator.", "result": "DPS's conditional score estimation is flawed, resembling MAP more, and proposed enhancements significantly improve performance.", "conclusion": "DPS is better understood as MAP, and the proposed enhancements notably boost its effectiveness."}}
{"id": "2311.17797", "pdf": "https://arxiv.org/pdf/2311.17797", "abs": "https://arxiv.org/abs/2311.17797", "authors": ["L. Jeff Hong", "Yanxi Hou", "Qingkai Zhang", "Xiaowei Zhang"], "title": "Learning to Simulate: Generative Metamodeling via Quantile Regression", "categories": ["cs.LG", "stat.ME"], "comment": null, "summary": "Stochastic simulation models effectively capture complex system dynamics but\nare often too slow for real-time decision-making. Traditional metamodeling\ntechniques learn relationships between simulator inputs and a single output\nsummary statistic, such as the mean or median. These techniques enable\nreal-time predictions without additional simulations. However, they require\nprior selection of one appropriate output summary statistic, limiting their\nflexibility in practical applications. We propose a new concept: generative\nmetamodeling. It aims to construct a \"fast simulator of the simulator,\"\ngenerating random outputs significantly faster than the original simulator\nwhile preserving approximately equal conditional distributions. Generative\nmetamodels enable rapid generation of numerous random outputs upon input\nspecification, facilitating immediate computation of any summary statistic for\nreal-time decision-making. We introduce a new algorithm,\nquantile-regression-based generative metamodeling (QRGMM), and establish its\ndistributional convergence and convergence rate. Extensive numerical\nexperiments demonstrate QRGMM's efficacy compared to other state-of-the-art\ngenerative algorithms in practical real-time decision-making scenarios.", "AI": {"tldr": "Generative metamodeling introduces a 'fast simulator of the simulator' to enable real-time decision-making by generating random outputs quickly, preserving conditional distributions. The proposed QRGMM algorithm shows superior performance in practical scenarios.", "motivation": "Traditional metamodeling techniques are limited by requiring prior selection of a single output summary statistic, reducing flexibility. Generative metamodeling addresses this by enabling rapid generation of multiple random outputs.", "method": "The paper proposes quantile-regression-based generative metamodeling (QRGMM), a new algorithm that constructs a fast simulator preserving conditional distributions.", "result": "QRGMM demonstrates superior performance in numerical experiments compared to other generative algorithms, enabling real-time computation of any summary statistic.", "conclusion": "Generative metamodeling, particularly QRGMM, offers a flexible and efficient solution for real-time decision-making by overcoming limitations of traditional metamodeling techniques."}}
{"id": "2501.01073", "pdf": "https://arxiv.org/pdf/2501.01073", "abs": "https://arxiv.org/abs/2501.01073", "authors": ["Xiaohui Chen", "Yinkai Wang", "Jiaxing He", "Yuanqi Du", "Soha Hassoun", "Xiaolin Xu", "Li-Ping Liu"], "title": "Graph Generative Pre-trained Transformer", "categories": ["cs.LG", "cs.AI"], "comment": "ICML 2025", "summary": "Graph generation is a critical task in numerous domains, including molecular\ndesign and social network analysis, due to its ability to model complex\nrelationships and structured data. While most modern graph generative models\nutilize adjacency matrix representations, this work revisits an alternative\napproach that represents graphs as sequences of node set and edge set. We\nadvocate for this approach due to its efficient encoding of graphs and propose\na novel representation. Based on this representation, we introduce the Graph\nGenerative Pre-trained Transformer (G2PT), an auto-regressive model that learns\ngraph structures via next-token prediction. To further exploit G2PT's\ncapabilities as a general-purpose foundation model, we explore fine-tuning\nstrategies for two downstream applications: goal-oriented generation and graph\nproperty prediction. We conduct extensive experiments across multiple datasets.\nResults indicate that G2PT achieves superior generative performance on both\ngeneric graph and molecule datasets. Furthermore, G2PT exhibits strong\nadaptability and versatility in downstream tasks from molecular design to\nproperty prediction. Code available at https://github.com/tufts-ml/G2PT,", "AI": {"tldr": "The paper proposes G2PT, a graph generative model using sequence-based representations, achieving superior performance in generation and downstream tasks.", "motivation": "To address the limitations of adjacency matrix representations in graph generation by introducing an efficient sequence-based approach.", "method": "Introduces G2PT, an auto-regressive model using next-token prediction for graph generation, with fine-tuning for downstream tasks.", "result": "G2PT outperforms on generic graph and molecule datasets and shows adaptability in downstream applications.", "conclusion": "The sequence-based G2PT model is effective for graph generation and versatile for various tasks, with code publicly available."}}
{"id": "2502.17110", "pdf": "https://arxiv.org/pdf/2502.17110", "abs": "https://arxiv.org/abs/2502.17110", "authors": ["Junyang Wang", "Haiyang Xu", "Xi Zhang", "Ming Yan", "Ji Zhang", "Fei Huang", "Jitao Sang"], "title": "Mobile-Agent-V: A Video-Guided Approach for Effortless and Efficient Operational Knowledge Injection in Mobile Automation", "categories": ["cs.CL", "cs.CV"], "comment": "17 pages, 7 figures, 9 tables", "summary": "The exponential rise in mobile device usage necessitates streamlined\nautomation for effective task management, yet many AI frameworks fall short due\nto inadequate operational expertise. While manually written knowledge can\nbridge this gap, it is often burdensome and inefficient. We introduce\nMobile-Agent-V, an innovative framework that utilizes video as a guiding tool\nto effortlessly and efficiently inject operational knowledge into mobile\nautomation processes. By deriving knowledge directly from video content,\nMobile-Agent-V eliminates manual intervention, significantly reducing the\neffort and time required for knowledge acquisition. To rigorously evaluate this\napproach, we propose Mobile-Knowledge, a benchmark tailored to assess the\nimpact of external knowledge on mobile agent performance. Our experimental\nfindings demonstrate that Mobile-Agent-V enhances performance by 36% compared\nto existing methods, underscoring its effortless and efficient advantages in\nmobile automation.", "AI": {"tldr": "Mobile-Agent-V uses video to automate mobile task management, improving performance by 36% over existing methods.", "motivation": "The rise in mobile device usage demands better automation, but current AI frameworks lack operational expertise, and manual knowledge injection is inefficient.", "method": "Mobile-Agent-V leverages video content to inject operational knowledge into mobile automation, eliminating manual effort.", "result": "Mobile-Agent-V boosts performance by 36% compared to existing methods, as validated by the Mobile-Knowledge benchmark.", "conclusion": "Mobile-Agent-V offers an effortless and efficient solution for mobile automation, outperforming traditional approaches."}}
{"id": "2502.12427", "pdf": "https://arxiv.org/pdf/2502.12427", "abs": "https://arxiv.org/abs/2502.12427", "authors": ["Ehsan Zeraatkar", "Salah A Faroughi", "Jelena Te\u0161i\u0107"], "title": "ViFOR: A Fourier-Enhanced Vision Transformer for Multi-Image Super-Resolution in Earth System", "categories": ["cs.CV"], "comment": null, "summary": "Super-resolution (SR) is crucial for enhancing the spatial resolution of\nEarth System Model (ESM) data, thereby enabling more precise analysis of\nenvironmental processes. This paper introduces ViFOR, a novel SR algorithm\nintegrating Vision Transformers (ViTs) with Fourier-based Implicit Neural\nRepresentation Networks (INRs). ViFOR effectively captures global context and\nhigh-frequency details essential for accurate SR reconstruction by embedding\nFourier-based activation functions within the transformer architecture.\nExtensive experiments demonstrate that ViFOR consistently outperforms\nstate-of-the-art methods, including ViT, SIREN, and SRGANs, in terms of Peak\nSignal-to-Noise Ratio (PSNR) and Mean Squared Error (MSE) for both global and\nlocal imagery. ViFOR achieves PSNR improvements of up to 4.18 dB, 1.56 dB, and\n1.73 dB over ViT on full-image Source Temperature, Shortwave, and Longwave Flux\ndatasets. These results highlight ViFOR's effectiveness and potential for\nadvancing high-resolution climate data analysis.", "AI": {"tldr": "ViFOR, a novel SR algorithm combining Vision Transformers and Fourier-based INRs, outperforms state-of-the-art methods in enhancing ESM data resolution.", "motivation": "Super-resolution is vital for improving spatial resolution in Earth System Model data, enabling more precise environmental analysis.", "method": "ViFOR integrates Vision Transformers with Fourier-based Implicit Neural Representation Networks, using Fourier-based activation functions to capture global context and high-frequency details.", "result": "ViFOR achieves significant PSNR improvements (up to 4.18 dB) over existing methods like ViT, SIREN, and SRGANs, excelling in both global and local imagery.", "conclusion": "ViFOR demonstrates high effectiveness and potential for advancing high-resolution climate data analysis."}}
{"id": "2402.06614", "pdf": "https://arxiv.org/pdf/2402.06614", "abs": "https://arxiv.org/abs/2402.06614", "authors": ["Vinod Raman", "Unique Subedi", "Ambuj Tewari"], "title": "The Complexity of Sequential Prediction in Dynamical Systems", "categories": ["cs.LG", "stat.ML"], "comment": "L4DC Camera Ready", "summary": "We study the problem of learning to predict the next state of a dynamical\nsystem when the underlying evolution function is unknown. Unlike previous work,\nwe place no parametric assumptions on the dynamical system, and study the\nproblem from a learning theory perspective. We define new combinatorial\nmeasures and dimensions and show that they quantify the optimal mistake and\nregret bounds in the realizable and agnostic settings respectively. By doing\nso, we find that in the realizable setting, the total number of mistakes can\ngrow according to \\emph{any} increasing function of the time horizon $T$. In\ncontrast, we show that in the agnostic setting under the commonly studied\nnotion of Markovian regret, the only possible rates are $\\Theta(T)$ and\n$\\tilde{\\Theta}(\\sqrt{T})$.", "AI": {"tldr": "The paper explores learning to predict the next state of a dynamical system without parametric assumptions, introducing new combinatorial measures to quantify mistake and regret bounds in realizable and agnostic settings.", "motivation": "To understand the learning theory perspective of predicting dynamical system states without relying on parametric assumptions.", "method": "Defines new combinatorial measures and dimensions to analyze mistake and regret bounds.", "result": "In the realizable setting, mistakes can grow with any increasing function of time, while in the agnostic setting, regret rates are limited to \u0398(T) or \u0398\u0303(\u221aT).", "conclusion": "The study provides theoretical insights into the bounds of prediction errors in dynamical systems under different learning settings."}}
{"id": "2501.07849", "pdf": "https://arxiv.org/pdf/2501.07849", "abs": "https://arxiv.org/abs/2501.07849", "authors": ["Xiaoyu Zhang", "Juan Zhai", "Shiqing Ma", "Qingshuang Bao", "Weipeng Jiang", "Qian Wang", "Chao Shen", "Yang Liu"], "title": "The Invisible Hand: Unveiling Provider Bias in Large Language Models for Code Generation", "categories": ["cs.SE", "cs.AI", "cs.CR"], "comment": "27 pages, 13 figures", "summary": "Large Language Models (LLMs) have emerged as the new recommendation engines,\nsurpassing traditional methods in both capability and scope, particularly in\ncode generation. In this paper, we reveal a novel provider bias in LLMs:\nwithout explicit directives, these models show systematic preferences for\nservices from specific providers in their recommendations (e.g., favoring\nGoogle Cloud over Microsoft Azure). To systematically investigate this bias, we\ndevelop an automated pipeline to construct the dataset, incorporating 6\ndistinct coding task categories and 30 real-world application scenarios.\nLeveraging this dataset, we conduct the first comprehensive empirical study of\nprovider bias in LLM code generation across seven state-of-the-art LLMs,\nutilizing approximately 500 million tokens (equivalent to $5,000+ in\ncomputational costs). Our findings reveal that LLMs exhibit significant\nprovider preferences, predominantly favoring services from Google and Amazon,\nand can autonomously modify input code to incorporate their preferred providers\nwithout users' requests. Such a bias holds far-reaching implications for market\ndynamics and societal equilibrium, potentially contributing to digital\nmonopolies. It may also deceive users and violate their expectations, leading\nto various consequences. We call on the academic community to recognize this\nemerging issue and develop effective evaluation and mitigation methods to\nuphold AI security and fairness.", "AI": {"tldr": "LLMs exhibit provider bias in code recommendations, favoring Google and Amazon, which can mislead users and impact market dynamics.", "motivation": "To uncover and analyze provider bias in LLM code generation, as it can influence market dynamics and deceive users.", "method": "Developed an automated pipeline to create a dataset with 6 coding task categories and 30 scenarios, then studied 7 LLMs using 500M tokens.", "result": "LLMs show strong provider preferences, often modifying code to include favored providers without user input.", "conclusion": "Urges the academic community to address this bias to ensure AI fairness and security."}}
{"id": "2502.17214", "pdf": "https://arxiv.org/pdf/2502.17214", "abs": "https://arxiv.org/abs/2502.17214", "authors": ["Boxuan Zhang", "Ruqi Zhang"], "title": "CoT-UQ: Improving Response-wise Uncertainty Quantification in LLMs with Chain-of-Thought", "categories": ["cs.CL", "cs.LG", "stat.ML"], "comment": "Accepted by ACL 2025 Findings", "summary": "Large language models (LLMs) excel in many tasks but struggle to accurately\nquantify uncertainty in their generated responses. This limitation makes it\nchallenging to detect misinformation and ensure reliable decision-making.\nExisting uncertainty quantification (UQ) methods for LLMs are primarily\nprompt-wise rather than response-wise, often requiring multiple response\nsamples, which incurs high computational costs. Moreover, LLMs have been shown\nto be overconfident, particularly when using reasoning steps to derive their\nanswers. In this work, we propose CoT-UQ, a response-wise UQ framework that\nintegrates LLMs' inherent reasoning capabilities through Chain-of-Thought (CoT)\ninto the UQ process. CoT-UQ captures critical information during inference by\nextracting keywords from each reasoning step and assessing their importance to\nthe final answer. This key reasoning information is then aggregated to produce\na final uncertainty estimate. We conduct extensive experiments based on Llama\nFamily with model sizes varying from 8B to 13B across logical and mathematical\nreasoning tasks. Experimental results demonstrate that CoT-UQ significantly\noutperforms existing UQ methods, achieving an average improvement of 5.9% AUROC\ncompared to current UQ methods. The code is available at:\nhttps://github.com/ZBox1005/CoT-UQ.", "AI": {"tldr": "CoT-UQ is a response-wise uncertainty quantification framework for LLMs that leverages Chain-of-Thought reasoning to improve accuracy, outperforming existing methods by 5.9% AUROC.", "motivation": "LLMs struggle with uncertainty quantification, leading to unreliable decision-making and misinformation detection. Existing methods are computationally expensive and often overconfident.", "method": "CoT-UQ integrates LLMs' reasoning capabilities by extracting and assessing keywords from each reasoning step to estimate uncertainty.", "result": "Experiments on Llama models (8B-13B) show CoT-UQ outperforms existing methods by 5.9% AUROC on logical and mathematical tasks.", "conclusion": "CoT-UQ provides a more accurate and efficient uncertainty quantification method for LLMs, enhancing reliability in decision-making."}}
{"id": "2502.13928", "pdf": "https://arxiv.org/pdf/2502.13928", "abs": "https://arxiv.org/abs/2502.13928", "authors": ["Shengguang Wu", "Fan-Yun Sun", "Kaiyue Wen", "Nick Haber"], "title": "Symmetrical Visual Contrastive Optimization: Aligning Vision-Language Models with Minimal Contrastive Images", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.LG"], "comment": "Accepted to ACL 2025 Main. Project Website: https://s-vco.github.io/", "summary": "Recent studies have shown that Large Vision-Language Models (VLMs) tend to\nneglect image content and over-rely on language-model priors, resulting in\nerrors in visually grounded tasks and hallucinations. We hypothesize that this\nissue arises because existing VLMs are not explicitly trained to generate texts\nthat are accurately grounded in fine-grained image details. To enhance visual\nfeedback during VLM training, we propose S-VCO (Symmetrical Visual Contrastive\nOptimization), a novel finetuning objective that steers the model toward\ncapturing important visual details and aligning them with corresponding text\ntokens. To further facilitate this detailed alignment, we introduce MVC, a\npaired image-text dataset built by automatically filtering and augmenting\nvisual counterfactual data to challenge the model with hard contrastive cases\ninvolving Minimal Visual Contrasts. Experiments show that our method\nconsistently improves VLM performance across diverse benchmarks covering\nvarious abilities and domains, achieving up to a 22% reduction in\nhallucinations, and significant gains in vision-centric and general tasks.\nNotably, these improvements become increasingly pronounced in benchmarks with\nhigher visual dependency. In short, S-VCO offers a significant enhancement of\nVLM's visually-dependent task performance while retaining or even improving the\nmodel's general abilities. We opensource our code at https://s-vco.github.io/", "AI": {"tldr": "S-VCO improves VLMs by enhancing visual grounding, reducing hallucinations, and boosting performance in vision-centric tasks.", "motivation": "Existing VLMs neglect image details, leading to errors and hallucinations. The goal is to improve visual grounding.", "method": "Proposes S-VCO, a finetuning objective, and MVC dataset for hard contrastive cases to align visual details with text.", "result": "Achieves 22% fewer hallucinations and significant gains in vision-centric and general tasks.", "conclusion": "S-VCO enhances VLM performance in visually-dependent tasks while maintaining general abilities."}}
{"id": "2402.15319", "pdf": "https://arxiv.org/pdf/2402.15319", "abs": "https://arxiv.org/abs/2402.15319", "authors": ["Mart van Baalen", "Andrey Kuzmin", "Ivan Koryakovskiy", "Markus Nagel", "Peter Couperus", "Cedric Bastoul", "Eric Mahurin", "Tijmen Blankevoort", "Paul Whatmough"], "title": "GPTVQ: The Blessing of Dimensionality for LLM Quantization", "categories": ["cs.LG", "cs.CL"], "comment": null, "summary": "In this work we show that the size versus accuracy trade-off of neural\nnetwork quantization can be significantly improved by increasing the\nquantization dimensionality. We propose the GPTVQ method, a new fast method for\npost-training vector quantization (VQ) that scales well to Large Language\nModels (LLMs). Our method interleaves quantization of one or more columns with\nupdates to the remaining unquantized weights, using information from the\nHessian of the per-layer output reconstruction MSE. Quantization codebooks are\ninitialized using an efficient data-aware version of the EM algorithm. The\ncodebooks are then updated, and further compressed by using integer\nquantization and SVD-based compression. GPTVQ establishes a new state-of-the\nart in the size vs accuracy trade-offs on a wide range of LLMs such as Llama-v2\nand Mistral. Furthermore, our method is efficient: on a single H100 it takes\nbetween 3 and 11 hours to process a Llamav2-70B model, depending on\nquantization setting. Lastly, with on-device timings for VQ decompression on a\nmobile CPU we show that VQ leads to improved latency compared to using a 4-bit\ninteger format.", "AI": {"tldr": "GPTVQ improves neural network quantization by increasing dimensionality, offering better size-accuracy trade-offs for LLMs like Llama-v2 and Mistral. It's efficient, taking 3-11 hours for a 70B model on an H100, and reduces latency on mobile CPUs.", "motivation": "To enhance the size versus accuracy trade-off in neural network quantization, especially for large language models (LLMs).", "method": "Proposes GPTVQ, a fast post-training vector quantization method. It interleaves column quantization with weight updates using Hessian information, initializes codebooks via data-aware EM, and compresses them with integer quantization and SVD.", "result": "Achieves state-of-the-art size-accuracy trade-offs for LLMs (e.g., Llama-v2, Mistral) and reduces latency on mobile CPUs compared to 4-bit integer formats.", "conclusion": "GPTVQ is an efficient and effective method for improving quantization in LLMs, balancing speed, accuracy, and model size."}}
{"id": "2501.12633", "pdf": "https://arxiv.org/pdf/2501.12633", "abs": "https://arxiv.org/abs/2501.12633", "authors": ["Jingyang Ke", "Feiyang Wu", "Jiyi Wang", "Jeffrey Markowitz", "Anqi Wu"], "title": "Inverse Reinforcement Learning with Switching Rewards and History Dependency for Characterizing Animal Behaviors", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Traditional approaches to studying decision-making in neuroscience focus on\nsimplified behavioral tasks where animals perform repetitive, stereotyped\nactions to receive explicit rewards. While informative, these methods constrain\nour understanding of decision-making to short timescale behaviors driven by\nexplicit goals. In natural environments, animals exhibit more complex,\nlong-term behaviors driven by intrinsic motivations that are often\nunobservable. Recent works in time-varying inverse reinforcement learning (IRL)\naim to capture shifting motivations in long-term, freely moving behaviors.\nHowever, a crucial challenge remains: animals make decisions based on their\nhistory, not just their current state. To address this, we introduce SWIRL\n(SWitching IRL), a novel framework that extends traditional IRL by\nincorporating time-varying, history-dependent reward functions. SWIRL models\nlong behavioral sequences as transitions between short-term decision-making\nprocesses, each governed by a unique reward function. SWIRL incorporates\nbiologically plausible history dependency to capture how past decisions and\nenvironmental contexts shape behavior, offering a more accurate description of\nanimal decision-making. We apply SWIRL to simulated and real-world animal\nbehavior datasets and show that it outperforms models lacking history\ndependency, both quantitatively and qualitatively. This work presents the first\nIRL model to incorporate history-dependent policies and rewards to advance our\nunderstanding of complex, naturalistic decision-making in animals.", "AI": {"tldr": "SWIRL introduces a history-dependent IRL framework to model complex, long-term animal decision-making, outperforming traditional methods.", "motivation": "Traditional neuroscience methods limit understanding of decision-making to short-term, explicit goals, missing intrinsic motivations in natural behaviors.", "method": "SWIRL extends IRL with time-varying, history-dependent reward functions to model transitions between short-term decision processes.", "result": "SWIRL outperforms non-history-dependent models in simulating and analyzing real-world animal behavior datasets.", "conclusion": "SWIRL advances IRL by incorporating history dependency, improving modeling of naturalistic animal decision-making."}}
{"id": "2502.17878", "pdf": "https://arxiv.org/pdf/2502.17878", "abs": "https://arxiv.org/abs/2502.17878", "authors": ["Hongqiu Wu", "Weiqi Wu", "Tianyang Xu", "Jiameng Zhang", "Hai Zhao"], "title": "Towards Enhanced Immersion and Agency for LLM-based Interactive Drama", "categories": ["cs.CL"], "comment": "Accepted by ACL'2025", "summary": "LLM-based Interactive Drama is a novel AI-based dialogue scenario, where the\nuser (i.e. the player) plays the role of a character in the story, has\nconversations with characters played by LLM agents, and experiences an\nunfolding story. This paper begins with understanding interactive drama from\ntwo aspects: Immersion, the player's feeling of being present in the story, and\nAgency, the player's ability to influence the story world. Both are crucial to\ncreating an enjoyable interactive experience, while they have been\nunderexplored in previous work. To enhance these two aspects, we first propose\nPlaywriting-guided Generation, a novel method that helps LLMs craft dramatic\nstories with substantially improved structures and narrative quality.\nAdditionally, we introduce Plot-based Reflection for LLM agents to refine their\nreactions to align with the player's intentions. Our evaluation relies on human\njudgment to assess the gains of our methods in terms of immersion and agency.", "AI": {"tldr": "The paper introduces LLM-based Interactive Drama, focusing on enhancing Immersion and Agency through Playwriting-guided Generation and Plot-based Reflection, validated by human evaluation.", "motivation": "To improve the interactive drama experience by addressing underexplored aspects of Immersion and Agency in LLM-based dialogue scenarios.", "method": "Proposes Playwriting-guided Generation for better story structure and Plot-based Reflection for aligning LLM reactions with player intentions.", "result": "Human evaluation shows improvements in Immersion and Agency.", "conclusion": "The methods enhance interactive drama quality, making it more engaging and responsive to player influence."}}
{"id": "2502.14779", "pdf": "https://arxiv.org/pdf/2502.14779", "abs": "https://arxiv.org/abs/2502.14779", "authors": ["Hongji Yang", "Wencheng Han", "Yucheng Zhou", "Jianbing Shen"], "title": "DC-ControlNet: Decoupling Inter- and Intra-Element Conditions in Image Generation with Diffusion Models", "categories": ["cs.CV"], "comment": null, "summary": "In this paper, we introduce DC (Decouple)-ControlNet, a highly flexible and\nprecisely controllable framework for multi-condition image generation. The core\nidea behind DC-ControlNet is to decouple control conditions, transforming\nglobal control into a hierarchical system that integrates distinct elements,\ncontents, and layouts. This enables users to mix these individual conditions\nwith greater flexibility, leading to more efficient and accurate image\ngeneration control. Previous ControlNet-based models rely solely on global\nconditions, which affect the entire image and lack the ability of element- or\nregion-specific control. This limitation reduces flexibility and can cause\ncondition misunderstandings in multi-conditional image generation. To address\nthese challenges, we propose both intra-element and Inter-element Controllers\nin DC-ControlNet. The Intra-Element Controller handles different types of\ncontrol signals within individual elements, accurately describing the content\nand layout characteristics of the object. For interactions between elements, we\nintroduce the Inter-Element Controller, which accurately handles multi-element\ninteractions and occlusion based on user-defined relationships. Extensive\nevaluations show that DC-ControlNet significantly outperforms existing\nControlNet models and Layout-to-Image generative models in terms of control\nflexibility and precision in multi-condition control. Our project website is\navailable at: https://um-lab.github.io/DC-ControlNet/", "AI": {"tldr": "DC-ControlNet is a flexible framework for multi-condition image generation by decoupling control conditions into hierarchical elements, improving precision and flexibility.", "motivation": "Existing ControlNet models lack element-specific control, reducing flexibility and causing condition misunderstandings in multi-conditional image generation.", "method": "DC-ControlNet introduces Intra-Element and Inter-Element Controllers to handle individual elements and their interactions, respectively.", "result": "DC-ControlNet outperforms existing models in control flexibility and precision for multi-condition image generation.", "conclusion": "The framework enhances image generation by enabling precise, flexible control over individual elements and their interactions."}}
{"id": "2403.01759", "pdf": "https://arxiv.org/pdf/2403.01759", "abs": "https://arxiv.org/abs/2403.01759", "authors": ["Fei Zhu", "Shijie Ma", "Zhen Cheng", "Xu-Yao Zhang", "Zhaoxiang Zhang", "Dacheng Tao", "Cheng-Lin Liu"], "title": "Open-world Machine Learning: A Systematic Review and Future Directions", "categories": ["cs.LG", "cs.CV"], "comment": null, "summary": "Machine learning has achieved remarkable success in many applications.\nHowever, existing studies are largely based on the closed-world assumption,\nwhich assumes that the environment is stationary, and the model is fixed once\ndeployed. In many real-world applications, this fundamental and rather naive\nassumption may not hold because an open environment is complex, dynamic, and\nfull of unknowns. In such cases, rejecting unknowns, discovering novelties, and\nthen continually learning them, could enable models to be safe and evolve\ncontinually as biological systems do. This article presents a holistic view of\nopen-world machine learning by investigating unknown rejection, novelty\ndiscovery, and continual learning in a unified paradigm. The challenges,\nprinciples, and limitations of current methodologies are discussed in detail.\nFurthermore, widely used benchmarks, metrics, and performances are summarized.\nFinally, we discuss several potential directions for further progress in the\nfield. By providing a comprehensive introduction to the emerging open-world\nmachine learning paradigm, this article aims to help researchers build more\npowerful AI systems in their respective fields, and to promote the development\nof artificial general intelligence.", "AI": {"tldr": "The paper introduces open-world machine learning, addressing challenges like unknown rejection, novelty discovery, and continual learning to build adaptable AI systems.", "motivation": "Current machine learning relies on a closed-world assumption, which fails in dynamic, real-world environments. The paper aims to explore open-world learning for more robust AI.", "method": "Investigates unknown rejection, novelty discovery, and continual learning in a unified paradigm, discussing challenges, principles, and methodologies.", "result": "Summarizes benchmarks, metrics, and performances, highlighting the potential of open-world learning for evolving AI systems.", "conclusion": "The paper advocates for open-world machine learning to advance AI adaptability and progress toward artificial general intelligence."}}
{"id": "2501.13779", "pdf": "https://arxiv.org/pdf/2501.13779", "abs": "https://arxiv.org/abs/2501.13779", "authors": ["Tanya Rodchenko", "Natasha Noy", "Nino Scherrer"], "title": "Not Every AI Problem is a Data Problem: We Should Be Intentional About Data Scaling", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "While Large Language Models require more and more data to train and scale,\nrather than looking for any data to acquire, we should consider what types of\ntasks are more likely to benefit from data scaling. We should be intentional in\nour data acquisition. We argue that the shape of the data itself, such as its\ncompositional and structural patterns, informs which tasks to prioritize in\ndata scaling, and shapes the development of the next generation of compute\nparadigms for tasks where data scaling is inefficient, or even insufficient.", "AI": {"tldr": "The paper advocates for intentional data acquisition in LLMs, focusing on task-specific benefits of data scaling and leveraging data structure to guide compute paradigms.", "motivation": "Address the inefficiency of indiscriminate data scaling in LLMs by prioritizing tasks where data scaling is beneficial.", "method": "Analyze data composition and structural patterns to identify tasks for prioritized scaling and develop efficient compute paradigms.", "result": "Proposes a framework for intentional data acquisition and task prioritization in LLM training.", "conclusion": "Intentional data scaling and task prioritization can optimize LLM performance and resource use."}}
{"id": "2502.18460", "pdf": "https://arxiv.org/pdf/2502.18460", "abs": "https://arxiv.org/abs/2502.18460", "authors": ["Xueguang Ma", "Xi Victoria Lin", "Barlas Oguz", "Jimmy Lin", "Wen-tau Yih", "Xilun Chen"], "title": "DRAMA: Diverse Augmentation from Large Language Models to Smaller Dense Retrievers", "categories": ["cs.CL", "cs.IR"], "comment": "ACL 2025", "summary": "Large language models (LLMs) have demonstrated strong effectiveness and\nrobustness while fine-tuned as dense retrievers. However, their large parameter\nsize brings significant inference time computational challenges, including high\nencoding costs for large-scale corpora and increased query latency, limiting\ntheir practical deployment. While smaller retrievers offer better efficiency,\nthey often fail to generalize effectively with limited supervised fine-tuning\ndata. In this work, we introduce DRAMA, a training framework that leverages\nLLMs to train smaller generalizable dense retrievers. In particular, we adopt\npruned LLMs as the backbone and train on diverse LLM-augmented data in a\nsingle-stage contrastive learning setup. Experiments show that DRAMA offers\nbetter multilingual and long-context capabilities than traditional\nencoder-based retrievers, and achieves strong performance across multiple tasks\nand languages. These highlight the potential of connecting the training of\nsmaller retrievers with the growing advancements in LLMs, bridging the gap\nbetween efficiency and generalization.", "AI": {"tldr": "DRAMA is a training framework using LLMs to train smaller dense retrievers, balancing efficiency and generalization.", "motivation": "Address the inefficiency of large LLMs for retrieval tasks and the poor generalization of smaller retrievers with limited data.", "method": "Uses pruned LLMs as backbone and trains on diverse LLM-augmented data in a single-stage contrastive learning setup.", "result": "DRAMA outperforms traditional retrievers in multilingual and long-context tasks, showing strong performance across languages.", "conclusion": "Connecting smaller retrievers with LLM advancements bridges efficiency and generalization gaps."}}
{"id": "2502.16368", "pdf": "https://arxiv.org/pdf/2502.16368", "abs": "https://arxiv.org/abs/2502.16368", "authors": ["Zheling Meng", "Bo Peng", "Xiaochuan Jin", "Yueming Lyu", "Wei Wang", "Jing Dong", "Tieniu Tan"], "title": "Concept Corrector: Erase concepts on the fly for text-to-image diffusion models", "categories": ["cs.CV"], "comment": null, "summary": "Text-to-image diffusion models have demonstrated the underlying risk of\ngenerating various unwanted content, such as sexual elements. To address this\nissue, the task of concept erasure has been introduced, aiming to erase any\nundesired concepts that the models can generate. Previous methods, whether\ntraining-based or training-free, have primarily focused on the input side,\ni.e., texts. However, they often suffer from incomplete erasure due to\nlimitations in the generalization from limited prompts to diverse image\ncontent. In this paper, motivated by the notion that concept erasure on the\noutput side, i.e., generated images, may be more direct and effective, we\npropose Concept Corrector. It checks target concepts based on visual features\nprovided by final generated images predicted at certain time steps. Further, it\nincorporates Concept Removal Attention to erase generated concept features. It\novercomes the limitations of existing methods, which are either unable to\nremove the concept features that have been generated in images or rely on the\nassumption that the related concept words are contained in input prompts. In\nthe whole pipeline, our method changes no model parameters and only requires a\ngiven target concept as well as the corresponding replacement content, which is\neasy to implement. To the best of our knowledge, this is the first erasure\nmethod based on intermediate-generated images, achieving the ability to erase\nconcepts on the fly. The experiments on various concepts demonstrate its\nimpressive erasure performance.", "AI": {"tldr": "The paper introduces Concept Corrector, a method for erasing unwanted concepts in text-to-image diffusion models by focusing on generated images rather than input texts, achieving effective and direct erasure.", "motivation": "Existing methods for concept erasure in text-to-image models focus on input texts, leading to incomplete erasure due to limited generalization. Addressing this, the paper proposes a direct approach by targeting generated images.", "method": "Concept Corrector checks target concepts using visual features from intermediate-generated images and employs Concept Removal Attention to erase unwanted features without altering model parameters.", "result": "Experiments show the method effectively erases various unwanted concepts, outperforming existing approaches.", "conclusion": "Concept Corrector is the first method to erase concepts dynamically using intermediate images, offering a practical and efficient solution for unwanted content removal."}}
{"id": "2404.17034", "pdf": "https://arxiv.org/pdf/2404.17034", "abs": "https://arxiv.org/abs/2404.17034", "authors": ["Keziah Naggita", "Matthew R. Walter", "Avrim Blum"], "title": "Learning Actionable Counterfactual Explanations in Large State Spaces", "categories": ["cs.LG"], "comment": null, "summary": "Recourse generators provide actionable insights, often through feature-based\ncounterfactual explanations (CFEs), to help negatively classified individuals\nunderstand how to adjust their input features to achieve a positive\nclassification. These feature-based CFEs, which we refer to as \\emph{low-level}\nCFEs, are overly specific (e.g., coding experience: \\(4 \\to 5+\\) years) and\noften recommended in a feature space that doesn't straightforwardly align with\nreal-world actions. To bridge this gap, we introduce three novel recourse types\ngrounded in real-world actions: high-level continuous (\\emph{hl-continuous}),\nhigh-level discrete (\\emph{hl-discrete}), and high-level ID (\\emph{hl-id})\nCFEs.\n  We formulate single-agent CFE generation methods, where we model the\nhl-discrete CFE as a solution to a weighted set cover problem and the\nhl-continuous CFE as a solution to an integer linear program. Since these\nmethods require costly optimization per agent, we propose data-driven CFE\ngeneration approaches that, given instances of agents and their optimal CFEs,\nlearn a CFE generator that quickly provides optimal CFEs for new agents. This\napproach, also viewed as one of learning an optimal policy in a family of large\nbut deterministic MDPs, considers several problem formulations, including\nformulations in which the actions and their effects are unknown, and therefore\naddresses informational and computational challenges.\n  We conduct extensive empirical evaluations using healthcare datasets (BRFSS,\nFoods, and NHANES) and fully-synthetic data. For negatively classified agents\nidentified by linear or threshold-based classifiers, we compare the high-level\nCFE to low-level CFEs and assess the effectiveness of our network-based,\ndata-driven approaches. Results show that the data-driven CFE generators are\naccurate, and resource-efficient, and high-level CFEs offer key advantages over\nlow-level CFEs.", "AI": {"tldr": "The paper introduces high-level counterfactual explanations (CFEs) to address the specificity and misalignment of low-level CFEs with real-world actions. It proposes data-driven methods for efficient CFE generation and validates their effectiveness through empirical evaluations.", "motivation": "Low-level CFEs are overly specific and misaligned with real-world actions, limiting their practicality. The paper aims to bridge this gap by introducing high-level CFEs and efficient generation methods.", "method": "The authors propose three high-level CFE types and formulate single-agent CFE generation methods (weighted set cover for hl-discrete, integer linear program for hl-continuous). They also introduce data-driven approaches to learn optimal CFE generators.", "result": "Empirical evaluations on healthcare and synthetic datasets show that data-driven CFE generators are accurate and resource-efficient, with high-level CFEs outperforming low-level CFEs.", "conclusion": "High-level CFEs and data-driven generation methods offer practical advantages over low-level CFEs, improving recourse for negatively classified individuals."}}
{"id": "2501.16365", "pdf": "https://arxiv.org/pdf/2501.16365", "abs": "https://arxiv.org/abs/2501.16365", "authors": ["Lo Pang-Yun Ting", "Zhen Tan", "Hong-Pei Chen", "Cheng-Te Li", "Po-Lin Chen", "Kun-Ta Chuang", "Huan Liu"], "title": "CAND: Cross-Domain Ambiguity Inference for Early Detecting Nuanced Illness Deterioration", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Early detection of patient deterioration is essential for timely treatment,\nwith vital signs like heart rates being key health indicators. Existing methods\ntend to solely analyze vital sign waveforms, ignoring transition relationships\nof waveforms within each vital sign and the correlation strengths among various\nvital signs. Such studies often overlook nuanced illness deterioration, which\nis the early sign of worsening health but is difficult to detect. In this\npaper, we introduce CAND, a novel method that organizes the transition\nrelationships and the correlations within and among vital signs as\ndomain-specific and cross-domain knowledge. CAND jointly models these knowledge\nin a unified representation space, considerably enhancing the early detection\nof nuanced illness deterioration. In addition, CAND integrates a Bayesian\ninference method that utilizes augmented knowledge from domain-specific and\ncross-domain knowledge to address the ambiguities in correlation strengths.\nWith this architecture, the correlation strengths can be effectively inferred\nto guide joint modeling and enhance representations of vital signs. This allows\na more holistic and accurate interpretation of patient health. Our experiments\non a real-world ICU dataset demonstrate that CAND significantly outperforms\nexisting methods in both effectiveness and earliness in detecting nuanced\nillness deterioration. Moreover, we conduct a case study for the interpretable\ndetection process to showcase the practicality of CAND.", "AI": {"tldr": "CAND is a novel method for early detection of nuanced illness deterioration by modeling transition relationships and correlations within and among vital signs, outperforming existing methods.", "motivation": "Existing methods ignore transition relationships and correlation strengths among vital signs, missing early signs of patient deterioration.", "method": "CAND organizes transition relationships and correlations as domain-specific and cross-domain knowledge, jointly modeling them in a unified space and using Bayesian inference to address ambiguities.", "result": "CAND significantly outperforms existing methods in effectiveness and earliness of detecting nuanced illness deterioration on a real-world ICU dataset.", "conclusion": "CAND provides a more holistic and accurate interpretation of patient health, with practical interpretability demonstrated in a case study."}}
{"id": "2502.19756", "pdf": "https://arxiv.org/pdf/2502.19756", "abs": "https://arxiv.org/abs/2502.19756", "authors": ["Nathan Roll"], "title": "PolyPrompt: Automating Knowledge Extraction from Multilingual Language Models with Dynamic Prompt Generation", "categories": ["cs.CL", "cs.LG"], "comment": "6 pages, 2 figures", "summary": "Large language models (LLMs) showcase increasingly impressive English\nbenchmark scores, however their performance profiles remain inconsistent across\nmultilingual settings. To address this gap, we introduce PolyPrompt, a novel,\nparameter-efficient framework for enhancing the multilingual capabilities of\nLLMs. Our method learns a set of trigger tokens for each language through a\ngradient-based search, identifying the input query's language and selecting the\ncorresponding trigger tokens which are prepended to the prompt during\ninference. We perform experiments on two ~1 billion parameter models, with\nevaluations on the global MMLU benchmark across fifteen typologically and\nresource diverse languages, demonstrating accuracy gains of 3.7%-19.9% compared\nto naive and translation-pipeline baselines.", "AI": {"tldr": "PolyPrompt enhances multilingual LLMs by learning language-specific trigger tokens, improving accuracy by 3.7%-19.9% on MMLU.", "motivation": "Address inconsistent multilingual performance of LLMs despite strong English benchmarks.", "method": "Gradient-based search to learn language-specific trigger tokens, prepended to prompts during inference.", "result": "Accuracy gains of 3.7%-19.9% on MMLU across 15 diverse languages.", "conclusion": "PolyPrompt effectively boosts multilingual LLM performance with minimal parameter overhead."}}
{"id": "2502.18017", "pdf": "https://arxiv.org/pdf/2502.18017", "abs": "https://arxiv.org/abs/2502.18017", "authors": ["Qiuchen Wang", "Ruixue Ding", "Zehui Chen", "Weiqi Wu", "Shihang Wang", "Pengjun Xie", "Feng Zhao"], "title": "ViDoRAG: Visual Document Retrieval-Augmented Generation via Dynamic Iterative Reasoning Agents", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.IR"], "comment": null, "summary": "Understanding information from visually rich documents remains a significant\nchallenge for traditional Retrieval-Augmented Generation (RAG) methods.\nExisting benchmarks predominantly focus on image-based question answering (QA),\noverlooking the fundamental challenges of efficient retrieval, comprehension,\nand reasoning within dense visual documents. To bridge this gap, we introduce\nViDoSeek, a novel dataset designed to evaluate RAG performance on visually rich\ndocuments requiring complex reasoning. Based on it, we identify key limitations\nin current RAG approaches: (i) purely visual retrieval methods struggle to\neffectively integrate both textual and visual features, and (ii) previous\napproaches often allocate insufficient reasoning tokens, limiting their\neffectiveness. To address these challenges, we propose ViDoRAG, a novel\nmulti-agent RAG framework tailored for complex reasoning across visual\ndocuments. ViDoRAG employs a Gaussian Mixture Model (GMM)-based hybrid strategy\nto effectively handle multi-modal retrieval. To further elicit the model's\nreasoning capabilities, we introduce an iterative agent workflow incorporating\nexploration, summarization, and reflection, providing a framework for\ninvestigating test-time scaling in RAG domains. Extensive experiments on\nViDoSeek validate the effectiveness and generalization of our approach.\nNotably, ViDoRAG outperforms existing methods by over 10% on the competitive\nViDoSeek benchmark. The code is available at\nhttps://github.com/Alibaba-NLP/ViDoRAG.", "AI": {"tldr": "ViDoRAG, a multi-agent RAG framework, addresses challenges in visually rich document analysis by integrating multi-modal retrieval and iterative reasoning, outperforming existing methods by 10%.", "motivation": "Traditional RAG methods struggle with visually rich documents due to poor integration of textual and visual features and insufficient reasoning tokens.", "method": "ViDoRAG uses a GMM-based hybrid strategy for multi-modal retrieval and an iterative agent workflow (exploration, summarization, reflection) for reasoning.", "result": "ViDoRAG achieves over 10% improvement on the ViDoSeek benchmark compared to existing methods.", "conclusion": "ViDoRAG effectively bridges gaps in RAG for visually rich documents, demonstrating superior performance and generalization."}}
{"id": "2405.15228", "pdf": "https://arxiv.org/pdf/2405.15228", "abs": "https://arxiv.org/abs/2405.15228", "authors": ["Zhongnian Li", "Jinghao Xu", "Peng Ying", "Meng Wei", "Xinzheng Xu"], "title": "Learning from True-False Labels via Multi-modal Prompt Retrieving", "categories": ["cs.LG", "cs.CV"], "comment": "15 pages, 5 figures", "summary": "Pre-trained Vision-Language Models (VLMs) exhibit strong zero-shot\nclassification abilities, demonstrating great potential for generating weakly\nsupervised labels. Unfortunately, existing weakly supervised learning methods\nare short of ability in generating accurate labels via VLMs. In this paper, we\npropose a novel weakly supervised labeling setting, namely True-False Labels\n(TFLs) which can achieve high accuracy when generated by VLMs. The TFL\nindicates whether an instance belongs to the label, which is randomly and\nuniformly sampled from the candidate label set. Specifically, we theoretically\nderive a risk-consistent estimator to explore and utilize the conditional\nprobability distribution information of TFLs. Besides, we propose a\nconvolutional-based Multi-modal Prompt Retrieving (MRP) method to bridge the\ngap between the knowledge of VLMs and target learning tasks. Experimental\nresults demonstrate the effectiveness of the proposed TFL setting and MRP\nlearning method. The code to reproduce the experiments is at\nhttps://github.com/Tranquilxu/TMP.", "AI": {"tldr": "The paper introduces True-False Labels (TFLs) for weakly supervised learning using Vision-Language Models (VLMs), achieving high accuracy with a risk-consistent estimator and a Multi-modal Prompt Retrieving (MRP) method.", "motivation": "Existing weakly supervised methods fail to generate accurate labels via VLMs, prompting the need for a more effective labeling setting.", "method": "Proposes TFLs for label generation and a risk-consistent estimator, alongside the MRP method to align VLM knowledge with target tasks.", "result": "Experiments confirm TFLs and MRP improve weakly supervised labeling accuracy.", "conclusion": "TFLs and MRP effectively leverage VLMs for accurate weakly supervised learning."}}
{"id": "2501.19114", "pdf": "https://arxiv.org/pdf/2501.19114", "abs": "https://arxiv.org/abs/2501.19114", "authors": ["Nhan Phan", "Thu Nguyen", "P\u00e5l Halvorsen", "Michael A. Riegler"], "title": "Principal Components for Neural Network Initialization", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Principal Component Analysis (PCA) is a commonly used tool for dimension\nreduction and denoising. Therefore, it is also widely used on the data prior to\ntraining a neural network. However, this approach can complicate the\nexplanation of explainable AI (XAI) methods for the decision of the model. In\nthis work, we analyze the potential issues with this approach and propose\nPrincipal Components-based Initialization (PCsInit), a strategy to incorporate\nPCA into the first layer of a neural network via initialization of the first\nlayer in the network with the principal components, and its two variants\nPCsInit-Act and PCsInit-Sub. Explanations using these strategies are as direct\nand straightforward as for neural networks and are simpler than using PCA prior\nto training a neural network on the principal components. Moreover, as will be\nillustrated in the experiments, such training strategies can also allow further\nimprovement of training via backpropagation.", "AI": {"tldr": "The paper proposes PCsInit, a method to integrate PCA into neural network initialization, simplifying XAI explanations and improving training.", "motivation": "PCA complicates XAI explanations when used before neural network training; the authors aim to address this issue.", "method": "Introduces PCsInit, PCsInit-Act, and PCsInit-Sub, which initialize the first layer of a neural network with PCA components.", "result": "The proposed methods simplify XAI explanations and enhance training performance via backpropagation.", "conclusion": "PCsInit and its variants offer a more straightforward and effective approach to combining PCA with neural networks."}}
{"id": "2502.20129", "pdf": "https://arxiv.org/pdf/2502.20129", "abs": "https://arxiv.org/abs/2502.20129", "authors": ["Yifan Zhang", "Wenyu Du", "Dongming Jin", "Jie Fu", "Zhi Jin"], "title": "Finite State Automata Inside Transformers with Chain-of-Thought: A Mechanistic Study on State Tracking", "categories": ["cs.CL", "cs.LG"], "comment": null, "summary": "Chain-of-thought (CoT) significantly enhances the performance of large\nlanguage models (LLMs) across a wide range of tasks, and prior research shows\nthat CoT can theoretically increase expressiveness. However, there is limited\nmechanistic understanding of the algorithms that Transformer+CoT can learn. Our\nkey contributions are: (1) We evaluate the state tracking capabilities of\nTransformer+CoT and its variants, confirming the effectiveness of CoT. (2)\nNext, we identify the circuit (a subset of model components, responsible for\ntracking the world state), indicating that late-layer MLP neurons play a key\nrole. We propose two metrics, compression and distinction, and show that the\nneuron sets for each state achieve nearly 100% accuracy, providing evidence of\nan implicit finite state automaton (FSA) embedded within the model. (3)\nAdditionally, we explore three challenging settings: skipping intermediate\nsteps, introducing data noises, and testing length generalization. Our results\ndemonstrate that Transformer+CoT learns robust algorithms (FSAs), highlighting\nits resilience in challenging scenarios. Our code is available at\nhttps://github.com/IvanChangPKU/FSA.", "AI": {"tldr": "The paper investigates how Chain-of-thought (CoT) enhances Transformer models, identifying key components (late-layer MLP neurons) that form an implicit finite state automaton (FSA) and demonstrating its robustness in challenging settings.", "motivation": "To mechanistically understand the algorithms learned by Transformer+CoT and evaluate its state-tracking capabilities.", "method": "Evaluated state tracking, identified key circuits (late-layer MLP neurons), proposed metrics (compression and distinction), and tested robustness in challenging settings.", "result": "Confirmed CoT's effectiveness, identified FSA-like behavior in neurons, and demonstrated resilience in noisy and generalized settings.", "conclusion": "Transformer+CoT learns robust algorithms (FSAs), with late-layer MLP neurons playing a critical role, showcasing its potential for complex tasks."}}
{"id": "2503.10080", "pdf": "https://arxiv.org/pdf/2503.10080", "abs": "https://arxiv.org/abs/2503.10080", "authors": ["Zhen Qu", "Xian Tao", "Xinyi Gong", "Shichen Qu", "Qiyu Chen", "Zhengtao Zhang", "Xingang Wang", "Guiguang Ding"], "title": "Bayesian Prompt Flow Learning for Zero-Shot Anomaly Detection", "categories": ["cs.CV"], "comment": null, "summary": "Recently, vision-language models (e.g. CLIP) have demonstrated remarkable\nperformance in zero-shot anomaly detection (ZSAD). By leveraging auxiliary data\nduring training, these models can directly perform cross-category anomaly\ndetection on target datasets, such as detecting defects on industrial product\nsurfaces or identifying tumors in organ tissues. Existing approaches typically\nconstruct text prompts through either manual design or the optimization of\nlearnable prompt vectors. However, these methods face several challenges: 1)\nhandcrafted prompts require extensive expert knowledge and trial-and-error; 2)\nsingle-form learnable prompts struggle to capture complex anomaly semantics;\nand 3) an unconstrained prompt space limits generalization to unseen\ncategories. To address these issues, we propose Bayesian Prompt Flow Learning\n(Bayes-PFL), which models the prompt space as a learnable probability\ndistribution from a Bayesian perspective. Specifically, a prompt flow module is\ndesigned to learn both image-specific and image-agnostic distributions, which\nare jointly utilized to regularize the text prompt space and improve the\nmodel's generalization on unseen categories. These learned distributions are\nthen sampled to generate diverse text prompts, effectively covering the prompt\nspace. Additionally, a residual cross-model attention (RCA) module is\nintroduced to better align dynamic text embeddings with fine-grained image\nfeatures. Extensive experiments on 15 industrial and medical datasets\ndemonstrate our method's superior performance. The code is available at\nhttps://github.com/xiaozhen228/Bayes-PFL.", "AI": {"tldr": "Bayes-PFL improves zero-shot anomaly detection by modeling prompt space as a learnable probability distribution, addressing limitations of manual or single-form prompts.", "motivation": "Existing prompt methods for vision-language models in zero-shot anomaly detection face challenges like expert dependency, limited semantic capture, and poor generalization.", "method": "Proposes Bayesian Prompt Flow Learning (Bayes-PFL), modeling prompt space as a probability distribution, and introduces a residual cross-model attention module for better alignment.", "result": "Outperforms existing methods on 15 industrial and medical datasets.", "conclusion": "Bayes-PFL effectively addresses prompt space limitations and enhances generalization for zero-shot anomaly detection."}}
{"id": "2405.15861", "pdf": "https://arxiv.org/pdf/2405.15861", "abs": "https://arxiv.org/abs/2405.15861", "authors": ["Zhe Li", "Bicheng Ying", "Zidong Liu", "Chaosheng Dong", "Haibo Yang"], "title": "Achieving Dimension-Free Communication in Federated Learning via Zeroth-Order Optimization", "categories": ["cs.LG", "cs.DC"], "comment": "Accepted by ICLR 2025", "summary": "Federated Learning (FL) offers a promising framework for collaborative and\nprivacy-preserving machine learning across distributed data sources. However,\nthe substantial communication costs associated with FL significantly challenge\nits efficiency. Specifically, in each communication round, the communication\ncosts scale linearly with the model's dimension, which presents a formidable\nobstacle, especially in large model scenarios. Despite various\ncommunication-efficient strategies, the intrinsic dimension-dependent\ncommunication cost remains a major bottleneck for current FL implementations.\nThis paper proposes a novel dimension-free communication algorithm - DeComFL,\nwhich leverages the zeroth-order optimization techniques and reduces the\ncommunication cost from $\\mathscr{O}(d)$ to $\\mathscr{O}(1)$ by transmitting\nonly a constant number of scalar values between clients and the server in each\nround, regardless of the dimension $d$ of the model parameters. Theoretically,\nin non-convex functions, we prove that our algorithm achieves state-of-the-art\nrates, which show a linear speedup of the number of clients and local steps\nunder standard assumptions. With additional low effective rank assumption, we\ncan further show the convergence rate is independent of the model dimension $d$\nas well. Empirical evaluations, encompassing both classic deep learning\ntraining and large language model fine-tuning, demonstrate significant\nreductions in communication overhead. Notably, DeComFL achieves this by\ntransmitting only around 1MB of data in total between the server and a client\nto fine-tune a model with billions of parameters. Our code is available at\nhttps://github.com/ZidongLiu/DeComFL.", "AI": {"tldr": "DeComFL reduces FL communication costs from O(d) to O(1) using zeroth-order optimization, achieving dimension-free efficiency and state-of-the-art convergence rates.", "motivation": "High communication costs in FL, scaling linearly with model dimension, hinder efficiency, especially for large models.", "method": "Proposes DeComFL, a dimension-free algorithm using zeroth-order optimization to transmit only constant scalar values per round.", "result": "Achieves linear speedup in convergence, reduces communication overhead (e.g., 1MB for billion-parameter models), and maintains performance.", "conclusion": "DeComFL effectively addresses FL's communication bottleneck, enabling efficient large-scale and privacy-preserving ML."}}
{"id": "2502.00182", "pdf": "https://arxiv.org/pdf/2502.00182", "abs": "https://arxiv.org/abs/2502.00182", "authors": ["Jungwon Seo", "Ferhat Ozgur Catak", "Chunming Rong"], "title": "Understanding Federated Learning from IID to Non-IID dataset: An Experimental Study", "categories": ["cs.LG", "cs.AI", "stat.ML"], "comment": null, "summary": "As privacy concerns and data regulations grow, federated learning (FL) has\nemerged as a promising approach for training machine learning models across\ndecentralized data sources without sharing raw data. However, a significant\nchallenge in FL is that client data are often non-IID (non-independent and\nidentically distributed), leading to reduced performance compared to\ncentralized learning. While many methods have been proposed to address this\nissue, their underlying mechanisms are often viewed from different\nperspectives. Through a comprehensive investigation from gradient descent to\nFL, and from IID to non-IID data settings, we find that inconsistencies in\nclient loss landscapes primarily cause performance degradation in non-IID\nscenarios. From this understanding, we observe that existing methods can be\ngrouped into two main strategies: (i) adjusting parameter update paths and (ii)\nmodifying client loss landscapes. These findings offer a clear perspective on\naddressing non-IID challenges in FL and help guide future research in the\nfield.", "AI": {"tldr": "The paper investigates performance degradation in federated learning (FL) due to non-IID data, identifying inconsistencies in client loss landscapes as the primary cause. It categorizes existing solutions into two strategies and provides insights for future research.", "motivation": "Addressing the challenge of non-IID data in FL, which reduces model performance compared to centralized learning.", "method": "Comprehensive analysis from gradient descent to FL, focusing on IID vs. non-IID data settings.", "result": "Identifies client loss landscape inconsistencies as the main issue and groups existing methods into two strategies: adjusting parameter update paths and modifying client loss landscapes.", "conclusion": "Offers a clear perspective on tackling non-IID challenges in FL, guiding future research directions."}}
{"id": "2503.01926", "pdf": "https://arxiv.org/pdf/2503.01926", "abs": "https://arxiv.org/abs/2503.01926", "authors": ["Keyu Duan", "Yiran Zhao", "Zhili Feng", "Jinjie Ni", "Tianyu Pang", "Qian Liu", "Tianle Cai", "Longxu Dou", "Kenji Kawaguchi", "Anirudh Goyal", "J. Zico Kolter", "Michael Qizhe Shieh"], "title": "Unnatural Languages Are Not Bugs but Features for LLMs", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Large Language Models (LLMs) have been observed to process non-human-readable\ntext sequences, such as jailbreak prompts, often viewed as a bug for aligned\nLLMs. In this work, we present a systematic investigation challenging this\nperception, demonstrating that unnatural languages - strings that appear\nincomprehensible to humans but maintain semantic meanings for LLMs - contain\nlatent features usable by models. Notably, unnatural languages possess latent\nfeatures that can be generalized across different models and tasks during\ninference. Furthermore, models fine-tuned on unnatural versions of instruction\ndatasets perform on-par with those trained on natural language, achieving 49.71\nwin rates in Length-controlled AlpacaEval 2.0 in average across various base\nmodels. In addition, through comprehensive analysis, we demonstrate that LLMs\nprocess unnatural languages by filtering noise and inferring contextual meaning\nfrom filtered words.", "AI": {"tldr": "LLMs can process unnatural languages (incomprehensible to humans but meaningful to models) effectively, achieving performance comparable to natural language training.", "motivation": "Challenge the perception that non-human-readable text sequences are bugs for aligned LLMs, showing they contain usable latent features.", "method": "Systematic investigation of unnatural languages, fine-tuning models on unnatural instruction datasets, and analyzing their processing mechanisms.", "result": "Models fine-tuned on unnatural languages perform on-par with natural language training (49.71 win rate in Length-controlled AlpacaEval 2.0).", "conclusion": "Unnatural languages contain generalizable latent features, and LLMs process them by filtering noise and inferring contextual meaning."}}
{"id": "2503.13360", "pdf": "https://arxiv.org/pdf/2503.13360", "abs": "https://arxiv.org/abs/2503.13360", "authors": ["Hai-Long Sun", "Zhun Sun", "Houwen Peng", "Han-Jia Ye"], "title": "Mitigating Visual Forgetting via Take-along Visual Conditioning for Multi-modal Long CoT Reasoning", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": "Accepted to ACL 2025. The project page is available at\n  https://sun-hailong.github.io/projects/TVC", "summary": "Recent advancements in Large Language Models (LLMs) have demonstrated\nenhanced reasoning capabilities, evolving from Chain-of-Thought (CoT) prompting\nto advanced, product-oriented solutions like OpenAI o1. During our\nre-implementation of this model, we noticed that in multimodal tasks requiring\nvisual input (e.g., geometry problems), Multimodal LLMs (MLLMs) struggle to\nmaintain focus on the visual information, in other words, MLLMs suffer from a\ngradual decline in attention to visual information as reasoning progresses,\ncausing text-over-relied outputs. To investigate this, we ablate image inputs\nduring long-chain reasoning. Concretely, we truncate the reasoning process\nmidway, then re-complete the reasoning process with the input image removed. We\nobserve only a ~2% accuracy drop on MathVista's test-hard subset, revealing the\nmodel's textual outputs dominate the following reasoning process. Motivated by\nthis, we propose Take-along Visual Conditioning (TVC), a strategy that shifts\nimage input to critical reasoning stages and compresses redundant visual tokens\nvia dynamic pruning. This methodology helps the model retain attention to the\nvisual components throughout the reasoning. Our approach achieves\nstate-of-the-art performance on average across five mathematical reasoning\nbenchmarks (+3.4 points vs previous sota), demonstrating the effectiveness of\nTVC in enhancing multimodal reasoning systems.", "AI": {"tldr": "MLLMs struggle with visual attention in reasoning tasks. TVC improves performance by dynamically pruning and shifting visual inputs.", "motivation": "MLLMs lose focus on visual information during reasoning, leading to text-dominated outputs.", "method": "Ablated image inputs during reasoning, proposed TVC to shift and compress visual tokens dynamically.", "result": "Achieved +3.4 points over previous SOTA on five benchmarks, with only ~2% accuracy drop when images were removed.", "conclusion": "TVC effectively enhances multimodal reasoning by maintaining visual attention."}}
{"id": "2406.07507", "pdf": "https://arxiv.org/pdf/2406.07507", "abs": "https://arxiv.org/abs/2406.07507", "authors": ["Nicholas M. Boffi", "Michael S. Albergo", "Eric Vanden-Eijnden"], "title": "Flow map matching with stochastic interpolants: A mathematical framework for consistency models", "categories": ["cs.LG", "math.DS"], "comment": null, "summary": "Generative models based on dynamical equations such as flows and diffusions\noffer exceptional sample quality, but require computationally expensive\nnumerical integration during inference. The advent of consistency models has\nenabled efficient one-step or few-step generation, yet despite their practical\nsuccess, a systematic understanding of their design has been hindered by the\nlack of a comprehensive theoretical framework. Here we introduce Flow Map\nMatching (FMM), a principled framework for learning the two-time flow map of an\nunderlying dynamical generative model, thereby providing this missing\nmathematical foundation. Leveraging stochastic interpolants, we propose\ntraining objectives both for distillation from a pre-trained velocity field and\nfor direct training of a flow map over an interpolant or a forward diffusion\nprocess. Theoretically, we show that FMM unifies and extends a broad class of\nexisting approaches for fast sampling, including consistency models,\nconsistency trajectory models, and progressive distillation. Experiments on\nCIFAR-10 and ImageNet-32 highlight that our approach can achieve sample quality\ncomparable to flow matching while reducing generation time by a factor of\n10-20.", "AI": {"tldr": "Flow Map Matching (FMM) provides a theoretical framework for efficient one-step or few-step generation in dynamical generative models, unifying existing approaches and significantly reducing generation time.", "motivation": "The lack of a comprehensive theoretical framework for consistency models hinders systematic understanding and design, despite their practical success in efficient generation.", "method": "FMM learns the two-time flow map of a dynamical generative model using stochastic interpolants, with training objectives for distillation and direct training.", "result": "FMM achieves sample quality comparable to flow matching while reducing generation time by 10-20 times on datasets like CIFAR-10 and ImageNet-32.", "conclusion": "FMM offers a principled foundation for fast sampling, unifying and extending existing methods, and demonstrates practical efficiency in generation."}}
{"id": "2502.06806", "pdf": "https://arxiv.org/pdf/2502.06806", "abs": "https://arxiv.org/abs/2502.06806", "authors": ["Gaurush Hiranandani", "Haolun Wu", "Subhojyoti Mukherjee", "Sanmi Koyejo"], "title": "Logits are All We Need to Adapt Closed Models", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": "29 pages, 8 figures", "summary": "Many commercial Large Language Models (LLMs) are often closed-source,\nlimiting developers to prompt tuning for aligning content generation with\nspecific applications. While these models currently do not provide access to\ntoken logits, we argue that if such access were available, it would enable more\npowerful adaptation techniques beyond prompt engineering. In this paper, we\npropose a token-level probability reweighting framework that, given access to\nlogits and a small amount of task-specific data, can effectively steer\nblack-box LLMs toward application-specific content generation. Our approach\nviews next-token prediction through the lens of supervised classification. We\nshow that aligning black-box LLMs with task-specific data can be formulated as\na label noise correction problem, leading to Plugin model -- an autoregressive\nprobability reweighting model that operates solely on logits. We provide\ntheoretical justification for why reweighting logits alone is sufficient for\ntask adaptation. Extensive experiments with multiple datasets, LLMs, and\nreweighting models demonstrate the effectiveness of our method, advocating for\nbroader access to token logits in closed-source models.", "AI": {"tldr": "A framework for token-level probability reweighting in black-box LLMs is proposed, enabling task-specific adaptation without model access, using logits and minimal task data.", "motivation": "Closed-source LLMs limit adaptation to prompt tuning; access to token logits could unlock more powerful adaptation techniques.", "method": "Token-level probability reweighting treats next-token prediction as supervised classification, framing adaptation as label noise correction.", "result": "The Plugin model effectively steers LLMs toward task-specific content generation, validated across datasets and models.", "conclusion": "Reweighting logits suffices for task adaptation, advocating for broader logit access in closed-source LLMs."}}
{"id": "2503.02519", "pdf": "https://arxiv.org/pdf/2503.02519", "abs": "https://arxiv.org/abs/2503.02519", "authors": ["Xingzuo Li", "Kehai Chen", "Yunfei Long", "Xuefeng Bai", "Yong Xu", "Min Zhang"], "title": "Generator-Assistant Stepwise Rollback Framework for Large Language Model Agent", "categories": ["cs.CL"], "comment": null, "summary": "Large language model (LLM) agents typically adopt a step-by-step reasoning\nframework, in which they interleave the processes of thinking and acting to\naccomplish the given task. However, this paradigm faces a deep-rooted one-pass\nissue whereby each generated intermediate thought is plugged into the\ntrajectory regardless of its correctness, which can cause irreversible error\npropagation. To address the issue, this paper proposes a novel framework called\nGenerator-Assistant Stepwise Rollback (GA-Rollback) to induce better\ndecision-making for LLM agents. Particularly, GA-Rollback utilizes a generator\nto interact with the environment and an assistant to examine each action\nproduced by the generator, where the assistant triggers a rollback operation\nupon detection of incorrect actions. Moreover, we introduce two additional\nstrategies tailored for the rollback scenario to further improve its\neffectiveness. Extensive experiments show that GA-Rollback achieves significant\nimprovements over several strong baselines on three widely used benchmarks. Our\nanalysis further reveals that GA-Rollback can function as a robust\nplug-and-play module, integrating seamlessly with other methods.", "AI": {"tldr": "GA-Rollback is a new framework for LLM agents that uses a generator-assistant duo to detect and correct errors in reasoning, improving decision-making and reducing error propagation.", "motivation": "Current step-by-step reasoning in LLM agents suffers from irreversible error propagation due to unchecked intermediate thoughts.", "method": "GA-Rollback employs a generator to interact with the environment and an assistant to review actions, triggering rollbacks for incorrect steps. Additional strategies enhance rollback effectiveness.", "result": "GA-Rollback outperforms baselines on three benchmarks and integrates well as a plug-and-play module.", "conclusion": "GA-Rollback effectively mitigates error propagation in LLM agents, enhancing their decision-making robustness."}}
{"id": "2503.18052", "pdf": "https://arxiv.org/pdf/2503.18052", "abs": "https://arxiv.org/abs/2503.18052", "authors": ["Yue Li", "Qi Ma", "Runyi Yang", "Huapeng Li", "Mengjiao Ma", "Bin Ren", "Nikola Popovic", "Nicu Sebe", "Ender Konukoglu", "Theo Gevers", "Luc Van Gool", "Martin R. Oswald", "Danda Pani Paudel"], "title": "SceneSplat: Gaussian Splatting-based Scene Understanding with Vision-Language Pretraining", "categories": ["cs.CV"], "comment": "Our code, model, and dataset will be released at\n  https://unique1i.github.io/SceneSplat_webpage/", "summary": "Recognizing arbitrary or previously unseen categories is essential for\ncomprehensive real-world 3D scene understanding. Currently, all existing\nmethods rely on 2D or textual modalities during training or together at\ninference. This highlights the clear absence of a model capable of processing\n3D data alone for learning semantics end-to-end, along with the necessary data\nto train such a model. Meanwhile, 3D Gaussian Splatting (3DGS) has emerged as\nthe de facto standard for 3D scene representation across various vision tasks.\nHowever, effectively integrating semantic reasoning into 3DGS in a\ngeneralizable manner remains an open challenge. To address these limitations,\nwe introduce SceneSplat, to our knowledge the first large-scale 3D indoor scene\nunderstanding approach that operates natively on 3DGS. Furthermore, we propose\na self-supervised learning scheme that unlocks rich 3D feature learning from\nunlabeled scenes. To power the proposed methods, we introduce SceneSplat-7K,\nthe first large-scale 3DGS dataset for indoor scenes, comprising 7916 scenes\nderived from seven established datasets, such as ScanNet and Matterport3D.\nGenerating SceneSplat-7K required computational resources equivalent to 150 GPU\ndays on an L4 GPU, enabling standardized benchmarking for 3DGS-based reasoning\nfor indoor scenes. Our exhaustive experiments on SceneSplat-7K demonstrate the\nsignificant benefit of the proposed method over the established baselines.", "AI": {"tldr": "SceneSplat is the first large-scale 3D indoor scene understanding method using 3D Gaussian Splatting (3DGS) with self-supervised learning and a new dataset, SceneSplat-7K.", "motivation": "Existing methods rely on 2D or textual modalities, lacking a pure 3D data approach for end-to-end semantic learning.", "method": "Proposes SceneSplat, integrating semantic reasoning into 3DGS, and a self-supervised learning scheme for 3D feature learning. Introduces SceneSplat-7K, a large-scale 3DGS dataset.", "result": "Outperforms baselines on SceneSplat-7K, demonstrating the method's effectiveness.", "conclusion": "SceneSplat advances 3D scene understanding by enabling pure 3D data processing and providing a benchmark dataset."}}
{"id": "2407.00765", "pdf": "https://arxiv.org/pdf/2407.00765", "abs": "https://arxiv.org/abs/2407.00765", "authors": ["Shijun Zhang", "Hongkai Zhao", "Yimin Zhong", "Haomin Zhou"], "title": "Structured and Balanced Multi-Component and Multi-Layer Neural Networks", "categories": ["cs.LG", "cs.NA", "cs.NE", "math.NA", "stat.ML"], "comment": "Our codes and implementation details are available at\n  https://github.com/ShijunZhangMath/MMNN", "summary": "In this work, we propose a balanced multi-component and multi-layer neural\nnetwork (MMNN) structure to accurately and efficiently approximate functions\nwith complex features, in terms of both degrees of freedom and computational\ncost. The main idea is inspired by a multi-component approach, in which each\ncomponent can be effectively approximated by a single-layer network, combined\nwith a multi-layer decomposition strategy to capture the complexity of the\ntarget function. Although MMNNs can be viewed as a simple modification of fully\nconnected neural networks (FCNNs) or multi-layer perceptrons (MLPs) by\nintroducing balanced multi-component structures, they achieve a significant\nreduction in training parameters, a much more efficient training process, and\nimproved accuracy compared to FCNNs or MLPs. Extensive numerical experiments\ndemonstrate the effectiveness of MMNNs in approximating highly oscillatory\nfunctions and their ability to automatically adapt to localized features.", "AI": {"tldr": "Proposes a balanced multi-component, multi-layer neural network (MMNN) for efficient and accurate function approximation, reducing training parameters and improving accuracy over traditional networks.", "motivation": "To address the challenge of approximating functions with complex features efficiently, balancing degrees of freedom and computational cost.", "method": "Combines multi-component (each approximated by a single-layer network) and multi-layer decomposition strategies to capture complexity.", "result": "MMNNs reduce training parameters, enhance training efficiency, and improve accuracy, especially for oscillatory functions and localized features.", "conclusion": "MMNNs offer a promising alternative to FCNNs/MLPs for complex function approximation, with demonstrated effectiveness in numerical experiments."}}
{"id": "2502.09891", "pdf": "https://arxiv.org/pdf/2502.09891", "abs": "https://arxiv.org/abs/2502.09891", "authors": ["Shu Wang", "Yixiang Fang", "Yingli Zhou", "Xilin Liu", "Yuchi Ma"], "title": "ArchRAG: Attributed Community-based Hierarchical Retrieval-Augmented Generation", "categories": ["cs.IR", "cs.AI"], "comment": null, "summary": "Retrieval-Augmented Generation (RAG) has proven effective in integrating\nexternal knowledge into large language models (LLMs) for solving\nquestion-answer (QA) tasks. The state-of-the-art RAG approaches often use the\ngraph data as the external data since they capture the rich semantic\ninformation and link relationships between entities. However, existing\ngraph-based RAG approaches cannot accurately identify the relevant information\nfrom the graph and also consume large numbers of tokens in the online retrieval\nprocess. To address these issues, we introduce a novel graph-based RAG\napproach, called Attributed Community-based Hierarchical RAG (ArchRAG), by\naugmenting the question using attributed communities, and also introducing a\nnovel LLM-based hierarchical clustering method. To retrieve the most relevant\ninformation from the graph for the question, we build a novel hierarchical\nindex structure for the attributed communities and develop an effective online\nretrieval method. Experimental results demonstrate that ArchRAG outperforms\nexisting methods in both accuracy and token cost. Moreover, ArchRAG has been\nsuccessfully applied to domain knowledge QA in Huawei Cloud Computing.", "AI": {"tldr": "ArchRAG improves graph-based RAG by using attributed communities and hierarchical clustering for better accuracy and efficiency.", "motivation": "Existing graph-based RAG methods struggle with relevance and token efficiency in retrieval.", "method": "Augments questions with attributed communities and uses hierarchical clustering for retrieval.", "result": "Outperforms existing methods in accuracy and token cost, applied successfully in Huawei Cloud Computing.", "conclusion": "ArchRAG is a superior graph-based RAG approach for QA tasks."}}
{"id": "2503.05037", "pdf": "https://arxiv.org/pdf/2503.05037", "abs": "https://arxiv.org/abs/2503.05037", "authors": ["Mohsen Fayyaz", "Ali Modarressi", "Hinrich Schuetze", "Nanyun Peng"], "title": "Collapse of Dense Retrievers: Short, Early, and Literal Biases Outranking Factual Evidence", "categories": ["cs.CL", "cs.IR"], "comment": "ACL 2025 Main Conference", "summary": "Dense retrieval models are commonly used in Information Retrieval (IR)\napplications, such as Retrieval-Augmented Generation (RAG). Since they often\nserve as the first step in these systems, their robustness is critical to avoid\ndownstream failures. In this work, we repurpose a relation extraction dataset\n(e.g., Re-DocRED) to design controlled experiments that quantify the impact of\nheuristic biases, such as a preference for shorter documents, on retrievers\nlike Dragon+ and Contriever. We uncover major vulnerabilities, showing\nretrievers favor shorter documents, early positions, repeated entities, and\nliteral matches, all while ignoring the answer's presence! Notably, when\nmultiple biases combine, models exhibit catastrophic performance degradation,\nselecting the answer-containing document in less than 10% of cases over a\nsynthetic biased document without the answer. Furthermore, we show that these\nbiases have direct consequences for downstream applications like RAG, where\nretrieval-preferred documents can mislead LLMs, resulting in a 34% performance\ndrop than providing no documents at all.\nhttps://huggingface.co/datasets/mohsenfayyaz/ColDeR", "AI": {"tldr": "The paper investigates heuristic biases in dense retrieval models, revealing vulnerabilities like favoring shorter documents and ignoring answer presence, leading to downstream performance drops in applications like RAG.", "motivation": "To quantify the impact of heuristic biases in dense retrieval models, which are critical for downstream IR applications like RAG.", "method": "Repurposes a relation extraction dataset (Re-DocRED) to design controlled experiments, evaluating retrievers like Dragon+ and Contriever.", "result": "Retrievers favor shorter documents, early positions, repeated entities, and literal matches, ignoring answer presence. Combined biases cause catastrophic performance drops (answer-containing document selected <10% of cases). Downstream RAG performance drops 34%.", "conclusion": "Dense retrieval models exhibit significant heuristic biases, severely impacting their robustness and downstream applications like RAG."}}
{"id": "2503.20218", "pdf": "https://arxiv.org/pdf/2503.20218", "abs": "https://arxiv.org/abs/2503.20218", "authors": ["Haiyang Liu", "Zhan Xu", "Fa-Ting Hong", "Hsin-Ping Huang", "Yi Zhou", "Yang Zhou"], "title": "Video Motion Graphs", "categories": ["cs.CV"], "comment": "14 pages,10 figures", "summary": "We present Video Motion Graphs, a system designed to generate realistic human\nmotion videos. Using a reference video and conditional signals such as music or\nmotion tags, the system synthesizes new videos by first retrieving video clips\nwith gestures matching the conditions and then generating interpolation frames\nto seamlessly connect clip boundaries. The core of our approach is HMInterp, a\nrobust Video Frame Interpolation (VFI) model that enables seamless\ninterpolation of discontinuous frames, even for complex motion scenarios like\ndancing. HMInterp i) employs a dual-branch interpolation approach, combining a\nMotion Diffusion Model for human skeleton motion interpolation with a\ndiffusion-based video frame interpolation model for final frame generation. ii)\nadopts condition progressive training to effectively leverage identity strong\nand weak conditions, such as images and pose. These designs ensure both high\nvideo texture quality and accurate motion trajectory. Results show that our\nVideo Motion Graphs outperforms existing generative- and retrieval-based\nmethods for multi-modal conditioned human motion video generation. Project page\ncan be found at https://h-liu1997.github.io/Video-Motion-Graphs/", "AI": {"tldr": "Video Motion Graphs generate realistic human motion videos using reference videos and conditional signals, employing HMInterp for seamless interpolation.", "motivation": "To create realistic human motion videos by combining retrieval and interpolation methods, addressing challenges in complex motion scenarios like dancing.", "method": "Uses HMInterp, a dual-branch interpolation model combining Motion Diffusion Model and diffusion-based VFI, with condition progressive training for high-quality results.", "result": "Outperforms existing generative- and retrieval-based methods in multi-modal conditioned human motion video generation.", "conclusion": "Video Motion Graphs effectively combines retrieval and interpolation for high-quality motion video synthesis, validated by superior performance."}}
{"id": "2407.02549", "pdf": "https://arxiv.org/pdf/2407.02549", "abs": "https://arxiv.org/abs/2407.02549", "authors": ["Mario Villaiz\u00e1n-Vallelado", "Matteo Salvatori", "Carlos Segura", "Ioannis Arapakis"], "title": "Diffusion Models for Tabular Data Imputation and Synthetic Data Generation", "categories": ["cs.LG"], "comment": "25 pages, 7 figures, 6 tables", "summary": "Data imputation and data generation have important applications for many\ndomains, like healthcare and finance, where incomplete or missing data can\nhinder accurate analysis and decision-making. Diffusion models have emerged as\npowerful generative models capable of capturing complex data distributions\nacross various data modalities such as image, audio, and time series data.\nRecently, they have been also adapted to generate tabular data. In this paper,\nwe propose a diffusion model for tabular data that introduces three key\nenhancements: (1) a conditioning attention mechanism, (2) an encoder-decoder\ntransformer as the denoising network, and (3) dynamic masking. The conditioning\nattention mechanism is designed to improve the model's ability to capture the\nrelationship between the condition and synthetic data. The transformer layers\nhelp model interactions within the condition (encoder) or synthetic data\n(decoder), while dynamic masking enables our model to efficiently handle both\nmissing data imputation and synthetic data generation tasks within a unified\nframework. We conduct a comprehensive evaluation by comparing the performance\nof diffusion models with transformer conditioning against state-of-the-art\ntechniques, such as Variational Autoencoders, Generative Adversarial Networks\nand Diffusion Models, on benchmark datasets. Our evaluation focuses on the\nassessment of the generated samples with respect to three important criteria,\nnamely: (1) Machine Learning efficiency, (2) statistical similarity, and (3)\nprivacy risk mitigation. For the task of data imputation, we consider the\nefficiency of the generated samples across different levels of missing\nfeatures.", "AI": {"tldr": "A diffusion model for tabular data with three enhancements: conditioning attention, encoder-decoder transformer, and dynamic masking, evaluated for imputation and generation tasks.", "motivation": "Addressing incomplete/missing data in domains like healthcare and finance, leveraging diffusion models for tabular data.", "method": "Proposes a diffusion model with conditioning attention, transformer denoising, and dynamic masking for unified imputation and generation.", "result": "Outperforms state-of-the-art methods (VAEs, GANs, other diffusion models) in ML efficiency, statistical similarity, and privacy risk.", "conclusion": "The model effectively handles tabular data tasks, offering improved performance and versatility in imputation and generation."}}
{"id": "2502.12012", "pdf": "https://arxiv.org/pdf/2502.12012", "abs": "https://arxiv.org/abs/2502.12012", "authors": ["Shuaiqun Pan", "Yash J. Patel", "Aneta Neumann", "Frank Neumann", "Thomas B\u00e4ck", "Hao Wang"], "title": "Evolving Hard Maximum Cut Instances for Quantum Approximate Optimization Algorithms", "categories": ["cs.ET", "cs.AI", "cs.NE", "quant-ph"], "comment": "This work has been accepted for publication and presentation at GECCO\n  2025", "summary": "Variational quantum algorithms, such as the Recursive Quantum Approximate\nOptimization Algorithm (RQAOA), have become increasingly popular, offering\npromising avenues for employing Noisy Intermediate-Scale Quantum devices to\naddress challenging combinatorial optimization tasks like the maximum cut\nproblem. In this study, we utilize an evolutionary algorithm equipped with a\nunique fitness function. This approach targets hard maximum cut instances\nwithin the latent space of a Graph Autoencoder, identifying those that pose\nsignificant challenges or are particularly tractable for RQAOA, in contrast to\nthe classic Goemans and Williamson algorithm. Our findings not only delineate\nthe distinct capabilities and limitations of each algorithm but also expand our\nunderstanding of RQAOA's operational limits. Furthermore, the diverse set of\ngraphs we have generated serves as a crucial benchmarking asset, emphasizing\nthe need for more advanced algorithms to tackle combinatorial optimization\nchallenges. Additionally, our results pave the way for new avenues in graph\ngeneration research, offering exciting opportunities for future explorations.", "AI": {"tldr": "The paper explores RQAOA's effectiveness for the max-cut problem using an evolutionary algorithm with a unique fitness function, comparing it to classical methods and generating benchmarking graphs.", "motivation": "To assess RQAOA's performance on hard max-cut instances and compare it with classical algorithms like Goemans-Williamson, while generating useful benchmarking data.", "method": "An evolutionary algorithm with a custom fitness function is applied to hard max-cut instances in a Graph Autoencoder's latent space.", "result": "The study highlights RQAOA's capabilities and limitations, provides benchmarking graphs, and suggests areas for future algorithm development.", "conclusion": "The work advances understanding of RQAOA's limits, offers benchmarking tools, and opens new directions for graph generation research."}}
{"id": "2503.10927", "pdf": "https://arxiv.org/pdf/2503.10927", "abs": "https://arxiv.org/abs/2503.10927", "authors": ["Angela Lopez-Cardona", "Sebastian Idesis", "Miguel Barreda-\u00c1ngeles", "Sergi Abadal", "Ioannis Arapakis"], "title": "OASST-ETC Dataset: Alignment Signals from Eye-tracking Analysis of LLM Responses", "categories": ["cs.CL", "cs.AI"], "comment": "This paper has been accepted to ACM ETRA 2025 and published on\n  PACMHCI", "summary": "While Large Language Models (LLMs) have significantly advanced natural\nlanguage processing, aligning them with human preferences remains an open\nchallenge. Although current alignment methods rely primarily on explicit\nfeedback, eye-tracking (ET) data offers insights into real-time cognitive\nprocessing during reading. In this paper, we present OASST-ETC, a novel\neye-tracking corpus capturing reading patterns from 24 participants, while\nevaluating LLM-generated responses from the OASST1 dataset. Our analysis\nreveals distinct reading patterns between preferred and non-preferred\nresponses, which we compare with synthetic eye-tracking data. Furthermore, we\nexamine the correlation between human reading measures and attention patterns\nfrom various transformer-based models, discovering stronger correlations in\npreferred responses. This work introduces a unique resource for studying human\ncognitive processing in LLM evaluation and suggests promising directions for\nincorporating eye-tracking data into alignment methods. The dataset and\nanalysis code are publicly available.", "AI": {"tldr": "OASST-ETC introduces an eye-tracking corpus to study human reading patterns on LLM responses, revealing distinct patterns for preferred vs. non-preferred outputs and correlations with model attention.", "motivation": "Aligning LLMs with human preferences is challenging; eye-tracking data provides real-time cognitive insights beyond explicit feedback.", "method": "Collects eye-tracking data from 24 participants evaluating LLM responses from OASST1, compares reading patterns, and analyzes correlations with transformer-based models.", "result": "Distinct reading patterns for preferred responses and stronger correlations with model attention in such cases.", "conclusion": "OASST-ETC offers a resource for LLM alignment research and suggests integrating eye-tracking data into alignment methods."}}
{"id": "2503.23062", "pdf": "https://arxiv.org/pdf/2503.23062", "abs": "https://arxiv.org/abs/2503.23062", "authors": ["Sagi Eppel", "Mor Bismut", "Alona Faktor-Strugatski"], "title": "Shape and Texture Recognition in Large Vision-Language Models", "categories": ["cs.CV"], "comment": null, "summary": "Shapes and textures are the basic building blocks of visual perception. The\nability to identify shapes regardless of orientation, texture, or context, and\nto recognize textures and materials independently of their associated objects,\nis essential for a general visual understanding of the world. This work\nintroduces the Large Shape and Textures dataset (LAS&T), a giant collection of\nhighly diverse shapes and textures, created by unsupervised extraction of\npatterns from natural images. This dataset is used to benchmark how effectively\nleading Large Vision-Language Models (LVLMs) understand shapes, textures, and\nmaterials in 2D and 3D scenes. For shape recognition, we test the models'\nability to match images of identical shapes that differ in orientation,\ntexture, color, or environment. Our results show that the shape recognition\ncapabilities of the LVLMs remain significantly below human performance. LVLMs\nrely predominantly on high-level and semantic features and struggle with\nabstract shapes lacking clear class associations. For texture and material\nrecognition, we evaluated the models' ability to identify images with identical\ntextures and materials across different objects and environments.\nInterestingly, leading LVLMs approach human-level performance in recognizing\nmaterials in 3D scenes, yet substantially underperform humans when identifying\nsimpler more abstract 2D textures. These results are consistent across a wide\nrange of leading VLMs (GPT/Gemini/LLama/Qwen) and foundation vision models\n(DINO/CLIP), exposing major deficiencies in the ability of leading models to\nunderstand fundamental visual concepts. In contrast, simple nets trained\ndirectly for these tasks achieve high accuracy. The LAS&T dataset has been made\navailable.", "AI": {"tldr": "The paper introduces the LAS&T dataset to benchmark LVLMs on shape and texture recognition, revealing their limitations compared to humans and simple nets.", "motivation": "To assess how well LVLMs understand fundamental visual concepts like shapes and textures, which are crucial for general visual perception.", "method": "Created the LAS&T dataset via unsupervised extraction from natural images, then tested LVLMs on shape and texture recognition tasks.", "result": "LVLMs underperform humans in shape recognition and 2D texture tasks but approach human-level in 3D material recognition. Simple nets outperform LVLMs.", "conclusion": "Current LVLMs have significant deficiencies in understanding basic visual concepts, highlighting a gap in their foundational visual understanding."}}
{"id": "2407.02687", "pdf": "https://arxiv.org/pdf/2407.02687", "abs": "https://arxiv.org/abs/2407.02687", "authors": ["Seyedmorteza Sadat", "Manuel Kansy", "Otmar Hilliges", "Romann M. Weber"], "title": "No Training, No Problem: Rethinking Classifier-Free Guidance for Diffusion Models", "categories": ["cs.LG", "cs.CV"], "comment": "Published as a conference paper at ICLR 2025", "summary": "Classifier-free guidance (CFG) has become the standard method for enhancing\nthe quality of conditional diffusion models. However, employing CFG requires\neither training an unconditional model alongside the main diffusion model or\nmodifying the training procedure by periodically inserting a null condition.\nThere is also no clear extension of CFG to unconditional models. In this paper,\nwe revisit the core principles of CFG and introduce a new method, independent\ncondition guidance (ICG), which provides the benefits of CFG without the need\nfor any special training procedures. Our approach streamlines the training\nprocess of conditional diffusion models and can also be applied during\ninference on any pre-trained conditional model. Additionally, by leveraging the\ntime-step information encoded in all diffusion networks, we propose an\nextension of CFG, called time-step guidance (TSG), which can be applied to any\ndiffusion model, including unconditional ones. Our guidance techniques are easy\nto implement and have the same sampling cost as CFG. Through extensive\nexperiments, we demonstrate that ICG matches the performance of standard CFG\nacross various conditional diffusion models. Moreover, we show that TSG\nimproves generation quality in a manner similar to CFG, without relying on any\nconditional information.", "AI": {"tldr": "The paper introduces Independent Condition Guidance (ICG) and Time-Step Guidance (TSG) to improve diffusion models without special training, matching CFG's performance and extending guidance to unconditional models.", "motivation": "Classifier-free guidance (CFG) requires extra training steps or unconditional models, limiting its flexibility. The paper aims to simplify and generalize guidance methods.", "method": "Proposes ICG for conditional models without special training and TSG for unconditional models, leveraging time-step information. Both methods are easy to implement.", "result": "ICG matches CFG's performance, and TSG improves generation quality in unconditional models, both with no added sampling cost.", "conclusion": "ICG and TSG offer efficient, flexible alternatives to CFG, enhancing diffusion models without training constraints."}}
{"id": "2502.13172", "pdf": "https://arxiv.org/pdf/2502.13172", "abs": "https://arxiv.org/abs/2502.13172", "authors": ["Bo Wang", "Weiyi He", "Shenglai Zeng", "Zhen Xiang", "Yue Xing", "Jiliang Tang", "Pengfei He"], "title": "Unveiling Privacy Risks in LLM Agent Memory", "categories": ["cs.CR", "cs.AI"], "comment": "ACL 2025 (Main Conference)", "summary": "Large Language Model (LLM) agents have become increasingly prevalent across\nvarious real-world applications. They enhance decision-making by storing\nprivate user-agent interactions in the memory module for demonstrations,\nintroducing new privacy risks for LLM agents. In this work, we systematically\ninvestigate the vulnerability of LLM agents to our proposed Memory EXTRaction\nAttack (MEXTRA) under a black-box setting. To extract private information from\nmemory, we propose an effective attacking prompt design and an automated prompt\ngeneration method based on different levels of knowledge about the LLM agent.\nExperiments on two representative agents demonstrate the effectiveness of\nMEXTRA. Moreover, we explore key factors influencing memory leakage from both\nthe agent designer's and the attacker's perspectives. Our findings highlight\nthe urgent need for effective memory safeguards in LLM agent design and\ndeployment.", "AI": {"tldr": "The paper introduces MEXTRA, a black-box attack to extract private data from LLM agents' memory, highlighting privacy risks and the need for safeguards.", "motivation": "LLM agents store private user interactions, raising privacy concerns. The study aims to explore vulnerabilities to memory extraction attacks.", "method": "Proposes MEXTRA, an attack using tailored prompts and automated generation, tested on two agents.", "result": "MEXTRA successfully extracts private data, revealing key factors in memory leakage.", "conclusion": "Urgent safeguards are needed to protect LLM agent memory from privacy breaches."}}
{"id": "2503.11630", "pdf": "https://arxiv.org/pdf/2503.11630", "abs": "https://arxiv.org/abs/2503.11630", "authors": ["Tamar I. Regev", "Chiebuka Ohams", "Shaylee Xie", "Lukas Wolf", "Evelina Fedorenko", "Alex Warstadt", "Ethan G. Wilcox", "Tiago Pimentel"], "title": "The time scale of redundancy between prosody and linguistic context", "categories": ["cs.CL", "cs.IT", "math.IT"], "comment": "13 pages, 4 figures, accepted to ACL. Updated following ACL reviewers\n  comments", "summary": "In spoken communication, information is transmitted not only via words, but\nalso through a rich array of non-verbal signals, including prosody--the\nnon-segmental auditory features of speech. Do these different communication\nchannels carry distinct information? Prior work has shown that the information\ncarried by prosodic features is substantially redundant with that carried by\nthe surrounding words. Here, we systematically examine the time scale of this\nrelationship, studying how it varies with the length of past and future\ncontexts. We find that a word's prosodic features require an extended past\ncontext (3-8 words across different features) to be reliably predicted. Given\nthat long-scale contextual information decays in memory, prosody may facilitate\ncommunication by adding information that is locally unique. We also find that a\nword's prosodic features show some redundancy with future words, but only with\na short scale of 1-2 words, consistent with reports of incremental short-term\nplanning in language production. Thus, prosody may facilitate communication by\nhelping listeners predict upcoming material. In tandem, our results highlight\npotentially distinct roles that prosody plays in facilitating integration of\nwords into past contexts and in helping predict upcoming words.", "AI": {"tldr": "Prosody in speech carries information that is somewhat redundant with words but requires extended past context for prediction and helps predict upcoming words.", "motivation": "To understand how prosodic features relate to word context and their role in communication.", "method": "Systematically examining the time scale of prosody-word relationships using past and future contexts.", "result": "Prosody requires 3-8 words of past context for prediction and shows short-scale redundancy with future words (1-2 words).", "conclusion": "Prosody aids communication by integrating past context and predicting upcoming words, playing distinct roles in each."}}
{"id": "2503.24135", "pdf": "https://arxiv.org/pdf/2503.24135", "abs": "https://arxiv.org/abs/2503.24135", "authors": ["Alexis Guichemerre", "Soufiane Belharbi", "Mohammadhadi Shateri", "Luke McCaffrey", "Eric Granger"], "title": "PixelCAM: Pixel Class Activation Mapping for Histology Image Classification and ROI Localization", "categories": ["cs.CV"], "comment": "43 pages, 24 figures, Medical Imaging with Deep Learning (MIDL 2025)", "summary": "Weakly supervised object localization (WSOL) methods allow training models to\nclassify images and localize ROIs. WSOL only requires low-cost image-class\nannotations yet provides a visually interpretable classifier. Standard WSOL\nmethods rely on class activation mapping (CAM) methods to produce spatial\nlocalization maps according to a single- or two-step strategy. While both\nstrategies have made significant progress, they still face several limitations\nwith histology images. Single-step methods can easily result in under- or\nover-activation due to the limited visual ROI saliency in histology images and\nscarce localization cues. They also face the well-known issue of asynchronous\nconvergence between classification and localization tasks. The two-step\napproach is sub-optimal because it is constrained to a frozen classifier,\nlimiting the capacity for localization. Moreover, these methods also struggle\nwhen applied to out-of-distribution (OOD) datasets. In this paper, a multi-task\napproach for WSOL is introduced for simultaneous training of both tasks to\naddress the asynchronous convergence problem. In particular, localization is\nperformed in the pixel-feature space of an image encoder that is shared with\nclassification. This allows learning discriminant features and accurate\ndelineation of foreground/background regions to support ROI localization and\nimage classification. We propose PixelCAM, a cost-effective\nforeground/background pixel-wise classifier in the pixel-feature space that\nallows for spatial object localization. Using partial-cross entropy, PixelCAM\nis trained using pixel pseudo-labels collected from a pretrained WSOL model.\nBoth image and pixel-wise classifiers are trained simultaneously using standard\ngradient descent. In addition, our pixel classifier can easily be integrated\ninto CNN- and transformer-based architectures without any modifications.", "AI": {"tldr": "PixelCAM introduces a multi-task WSOL method for histology images, addressing asynchronous convergence and localization issues by training classification and localization simultaneously in pixel-feature space.", "motivation": "Standard WSOL methods struggle with histology images due to under-/over-activation, asynchronous convergence, and OOD challenges.", "method": "PixelCAM trains a pixel-wise classifier in shared pixel-feature space using pseudo-labels and partial-cross entropy, compatible with CNN/transformer architectures.", "result": "Simultaneous training improves localization and classification, with PixelCAM being cost-effective and adaptable.", "conclusion": "PixelCAM effectively addresses WSOL limitations in histology images, offering a flexible and efficient solution."}}
{"id": "2407.10204", "pdf": "https://arxiv.org/pdf/2407.10204", "abs": "https://arxiv.org/abs/2407.10204", "authors": ["Can Xu", "Yao Cheng", "Jianxiang Yu", "Haosen Wang", "Jingsong Lv", "Yao Liu", "Xiang Li"], "title": "Improving Graph Out-of-distribution Generalization Beyond Causality", "categories": ["cs.LG"], "comment": "21 pages, 6 figures", "summary": "Existing methods for graph out-of-distribution (OOD) generalization primarily\nrely on empirical studies on synthetic datasets. Such approaches tend to\noveremphasize the causal relationships between invariant sub-graphs and labels,\nthereby neglecting the non-negligible role of environment in real-world\nscenarios. In contrast to previous studies that impose rigid independence\nassumptions on environments and invariant sub-graphs, this paper presents the\ntheorems of environment-label dependency and mutable rationale invariance,\nwhere the former characterizes the usefulness of environments in determining\ngraph labels while the latter refers to the mutable importance of graph\nrationales. Based on analytic investigations, a novel variational inference\nbased method named ``Probability Dependency on Environments and Rationales for\nOOD Graphs on Real-world Data'' (DEROG) is introduced. To alleviate the adverse\neffect of unknown prior knowledge on environments and rationales, DEROG\nutilizes generalized Bayesian inference. Further, DEROG employs an EM-based\nalgorithm for optimization. Finally, extensive experiments on real-world\ndatasets under different distribution shifts are conducted to show the\nsuperiority of DEROG.", "AI": {"tldr": "DEROG introduces a variational inference method for graph OOD generalization, addressing environment-label dependency and mutable rationale invariance, outperforming existing methods on real-world datasets.", "motivation": "Existing methods focus on synthetic data and causal relationships, neglecting real-world environmental roles. This paper aims to address this gap by incorporating environment-label dependency and mutable rationale invariance.", "method": "DEROG uses generalized Bayesian inference to handle unknown priors and an EM-based algorithm for optimization, focusing on real-world data.", "result": "Extensive experiments show DEROG's superiority under various distribution shifts on real-world datasets.", "conclusion": "DEROG effectively addresses limitations of prior methods by considering environment and rationale dependencies, demonstrating strong performance in real-world scenarios."}}
{"id": "2502.15806", "pdf": "https://arxiv.org/pdf/2502.15806", "abs": "https://arxiv.org/abs/2502.15806", "authors": ["Yang Yao", "Xuan Tong", "Ruofan Wang", "Yixu Wang", "Lujundong Li", "Liang Liu", "Yan Teng", "Yingchun Wang"], "title": "A Mousetrap: Fooling Large Reasoning Models for Jailbreak with Chain of Iterative Chaos", "categories": ["cs.CR", "cs.AI", "cs.CL", "cs.LG"], "comment": null, "summary": "Large Reasoning Models (LRMs) have significantly advanced beyond traditional\nLarge Language Models (LLMs) with their exceptional logical reasoning\ncapabilities, yet these improvements introduce heightened safety risks. When\nsubjected to jailbreak attacks, their ability to generate more targeted and\norganized content can lead to greater harm. Although some studies claim that\nreasoning enables safer LRMs against existing LLM attacks, they overlook the\ninherent flaws within the reasoning process itself. To address this gap, we\npropose the first jailbreak attack targeting LRMs, exploiting their unique\nvulnerabilities stemming from the advanced reasoning capabilities.\nSpecifically, we introduce a Chaos Machine, a novel component to transform\nattack prompts with diverse one-to-one mappings. The chaos mappings iteratively\ngenerated by the machine are embedded into the reasoning chain, which\nstrengthens the variability and complexity and also promotes a more robust\nattack. Based on this, we construct the Mousetrap framework, which makes\nattacks projected into nonlinear-like low sample spaces with mismatched\ngeneralization enhanced. Also, due to the more competing objectives, LRMs\ngradually maintain the inertia of unpredictable iterative reasoning and fall\ninto our trap. Success rates of the Mousetrap attacking o1-mini, Claude-Sonnet\nand Gemini-Thinking are as high as 96%, 86% and 98% respectively on our toxic\ndataset Trotter. On benchmarks such as AdvBench, StrongREJECT, and HarmBench,\nattacking Claude-Sonnet, well-known for its safety, Mousetrap can astonishingly\nachieve success rates of 87.5%, 86.58% and 93.13% respectively. Attention: This\npaper contains inappropriate, offensive and harmful content.", "AI": {"tldr": "The paper introduces a jailbreak attack (Mousetrap) targeting Large Reasoning Models (LRMs), exploiting their reasoning vulnerabilities via a Chaos Machine to enhance attack variability and complexity. It achieves high success rates on various models and benchmarks.", "motivation": "LRMs' advanced reasoning capabilities introduce new safety risks, overlooked by existing studies, necessitating a targeted attack to expose these vulnerabilities.", "method": "Proposes the Chaos Machine to transform attack prompts with one-to-one mappings, embedding them into reasoning chains, and constructs the Mousetrap framework for nonlinear-like attacks.", "result": "Achieves high success rates (up to 98%) on models like o1-mini, Claude-Sonnet, and Gemini-Thinking, and benchmarks like AdvBench and HarmBench.", "conclusion": "The Mousetrap attack effectively exploits LRMs' reasoning flaws, highlighting critical safety risks despite their advanced capabilities."}}
{"id": "2503.14433", "pdf": "https://arxiv.org/pdf/2503.14433", "abs": "https://arxiv.org/abs/2503.14433", "authors": ["Bar Gazit", "Shaltiel Shmidman", "Avi Shmidman", "Yuval Pinter"], "title": "Splintering Nonconcatenative Languages for Better Tokenization", "categories": ["cs.CL"], "comment": "Findings of the ACL 2025", "summary": "Common subword tokenization algorithms like BPE and UnigramLM assume that\ntext can be split into meaningful units by concatenative measures alone. This\nis not true for languages such as Hebrew and Arabic, where morphology is\nencoded in root-template patterns, or Malay and Georgian, where split affixes\nare common. We present SPLINTER, a pre-processing step which rearranges text\ninto a linear form that better represents such nonconcatenative morphologies,\nenabling meaningful contiguous segments to be found by the tokenizer. We\ndemonstrate SPLINTER's merit using both intrinsic measures evaluating token\nvocabularies in Hebrew, Arabic, and Malay; as well as on downstream tasks using\nBERT-architecture models trained for Hebrew.", "AI": {"tldr": "SPLINTER is a pre-processing step for tokenization that handles nonconcatenative morphologies in languages like Hebrew, Arabic, and Malay, improving tokenizer performance.", "motivation": "Existing tokenization methods (e.g., BPE, UnigramLM) fail for languages with nonconcatenative morphologies, such as Hebrew and Arabic.", "method": "SPLINTER rearranges text into a linear form to represent nonconcatenative morphologies, enabling better tokenization.", "result": "SPLINTER improves token vocabularies in Hebrew, Arabic, and Malay, and enhances downstream task performance in Hebrew BERT models.", "conclusion": "SPLINTER effectively addresses the limitations of current tokenization methods for nonconcatenative languages."}}
{"id": "2504.02433", "pdf": "https://arxiv.org/pdf/2504.02433", "abs": "https://arxiv.org/abs/2504.02433", "authors": ["Zhongjian Wang", "Peng Zhang", "Jinwei Qi", "Guangyuan Wang", "Chaonan Ji", "Sheng Xu", "Bang Zhang", "Liefeng Bo"], "title": "OmniTalker: One-shot Real-time Text-Driven Talking Audio-Video Generation With Multimodal Style Mimicking", "categories": ["cs.CV"], "comment": "Project Page https://humanaigc.github.io/omnitalker", "summary": "Although significant progress has been made in audio-driven talking head\ngeneration, text-driven methods remain underexplored. In this work, we present\nOmniTalker, a unified framework that jointly generates synchronized talking\naudio-video content from input text while emulating the speaking and facial\nmovement styles of the target identity, including speech characteristics, head\nmotion, and facial dynamics. Our framework adopts a dual-branch diffusion\ntransformer (DiT) architecture, with one branch dedicated to audio generation\nand the other to video synthesis. At the shallow layers, cross-modal fusion\nmodules are introduced to integrate information between the two modalities. In\ndeeper layers, each modality is processed independently, with the generated\naudio decoded by a vocoder and the video rendered using a GAN-based\nhigh-quality visual renderer. Leveraging the in-context learning capability of\nDiT through a masked-infilling strategy, our model can simultaneously capture\nboth audio and visual styles without requiring explicit style extraction\nmodules. Thanks to the efficiency of the DiT backbone and the optimized visual\nrenderer, OmniTalker achieves real-time inference at 25 FPS. To the best of our\nknowledge, OmniTalker is the first one-shot framework capable of jointly\nmodeling speech and facial styles in real time. Extensive experiments\ndemonstrate its superiority over existing methods in terms of generation\nquality, particularly in preserving style consistency and ensuring precise\naudio-video synchronization, all while maintaining efficient inference.", "AI": {"tldr": "OmniTalker is a unified framework for text-driven talking head generation, using a dual-branch diffusion transformer to jointly produce synchronized audio-video content with real-time performance.", "motivation": "Text-driven talking head generation is underexplored compared to audio-driven methods, and existing approaches lack joint modeling of speech and facial styles in real time.", "method": "A dual-branch diffusion transformer (DiT) architecture with cross-modal fusion for audio and video generation, leveraging in-context learning for style capture without explicit modules.", "result": "OmniTalker achieves real-time inference at 25 FPS, outperforming existing methods in generation quality, style consistency, and audio-video synchronization.", "conclusion": "OmniTalker is the first one-shot framework for real-time joint modeling of speech and facial styles, demonstrating superior performance and efficiency."}}
{"id": "2407.10916", "pdf": "https://arxiv.org/pdf/2407.10916", "abs": "https://arxiv.org/abs/2407.10916", "authors": ["Junhong Lin", "Xiaojie Guo", "Shuaicheng Zhang", "Yada Zhu", "Julian Shun"], "title": "When Heterophily Meets Heterogeneity: Challenges and a New Large-Scale Graph Benchmark", "categories": ["cs.LG", "cs.SI"], "comment": "This work has been accepted to the KDD 2025 Datasets and Benchmarks\n  Track", "summary": "Graph mining has become crucial in fields such as social science, finance,\nand cybersecurity. Many large-scale real-world networks exhibit both\nheterogeneity, where multiple node and edge types exist in the graph, and\nheterophily, where connected nodes may have dissimilar labels and attributes.\nHowever, existing benchmarks primarily focus on either heterophilic homogeneous\ngraphs or homophilic heterogeneous graphs, leaving a significant gap in\nunderstanding how models perform on graphs with both heterogeneity and\nheterophily. To bridge this gap, we introduce H2GB, a large-scale\nnode-classification graph benchmark that brings together the complexities of\nboth the heterophily and heterogeneity properties of real-world graphs. H2GB\nencompasses 9 real-world datasets spanning 5 diverse domains, 28 baseline\nmodels, and a unified benchmarking library with a standardized data loader,\nevaluator, unified modeling framework, and an extensible framework for\nreproducibility. We establish a standardized workflow supporting both model\nselection and development, enabling researchers to easily benchmark graph\nlearning methods. Extensive experiments across 28 baselines reveal that current\nmethods struggle with heterophilic and heterogeneous graphs, underscoring the\nneed for improved approaches. Finally, we present a new variant of the model,\nH2G-former, developed following our standardized workflow, that excels at this\nchallenging benchmark. Both the benchmark and the framework are publicly\navailable at Github and PyPI, with documentation hosted at\nhttps://junhongmit.github.io/H2GB.", "AI": {"tldr": "H2GB is a new benchmark for node-classification in graphs with both heterogeneity and heterophily, addressing gaps in existing benchmarks. It includes 9 datasets, 28 baselines, and a standardized framework. Current methods struggle, and a new model, H2G-former, is introduced.", "motivation": "Existing benchmarks focus on either heterophilic homogeneous graphs or homophilic heterogeneous graphs, missing the complexity of real-world graphs with both properties.", "method": "H2GB introduces a large-scale benchmark with 9 datasets, 28 baselines, and a unified library for standardized evaluation and modeling.", "result": "Experiments show current methods struggle with heterophilic and heterogeneous graphs. H2G-former, a new model, performs well.", "conclusion": "H2GB fills a critical gap in graph benchmarking, and H2G-former demonstrates the potential for improved approaches."}}
{"id": "2502.19971", "pdf": "https://arxiv.org/pdf/2502.19971", "abs": "https://arxiv.org/abs/2502.19971", "authors": ["Gengyuan Hu", "Wanli Ouyang", "Chao-Yang Lu", "Chen Lin", "Han-Sen Zhong"], "title": "Efficient and Universal Neural-Network Decoder for Stabilizer-Based Quantum Error Correction", "categories": ["quant-ph", "cs.AI"], "comment": null, "summary": "Scaling quantum computing to practical applications necessitates reliable\nquantum error correction. Although numerous correction codes have been\nproposed, the overall correction efficiency critically limited by the decode\nalgorithms. We introduce GraphQEC, a code-agnostic decoder leveraging\nmachine-learning on the graph structure of stabilizer codes with linear time\ncomplexity. GraphQEC demonstrates unprecedented accuracy and efficiency across\nall tested code families, including surface codes, color codes, and quantum\nlow-density parity-check (QLDPC) codes. For instance, on a distance-12 QLDPC\ncode, GraphQEC achieves a logical error rate of $9.55 \\times 10^{-5}$, an\n18-fold improvement over the previous best specialized decoder's $1.74 \\times\n10^{-3}$ under $p=0.005$ physical error rates, while maintaining\n$157\\mu$s/cycle decoding speed. Our approach represents the first universal\nsolution for real-time quantum error correction across arbitrary stabilizer\ncodes.", "AI": {"tldr": "GraphQEC is a machine-learning-based decoder for quantum error correction, offering high accuracy and efficiency across various code families.", "motivation": "The need for reliable quantum error correction to scale quantum computing, limited by existing decode algorithms.", "method": "GraphQEC leverages machine-learning on the graph structure of stabilizer codes with linear time complexity.", "result": "Achieves an 18-fold improvement in logical error rate and maintains fast decoding speed.", "conclusion": "GraphQEC is a universal solution for real-time quantum error correction across arbitrary stabilizer codes."}}
{"id": "2503.16048", "pdf": "https://arxiv.org/pdf/2503.16048", "abs": "https://arxiv.org/abs/2503.16048", "authors": ["Michael Goodale", "Salvador Mascarenhas", "Yair Lakretz"], "title": "Meta-Learning Neural Mechanisms rather than Bayesian Priors", "categories": ["cs.CL"], "comment": "Accepted to ACL 2025 Main", "summary": "Children acquire language despite being exposed to several orders of\nmagnitude less data than large language models require. Meta-learning has been\nproposed as a way to integrate human-like learning biases into neural-network\narchitectures, combining both the structured generalizations of symbolic models\nwith the scalability of neural-network models. But what does meta-learning\nexactly imbue the model with? We investigate the meta-learning of formal\nlanguages and find that, contrary to previous claims, meta-trained models are\nnot learning simplicity-based priors when meta-trained on datasets organised\naround simplicity. Rather, we find evidence that meta-training imprints neural\nmechanisms (such as counters) into the model, which function like cognitive\nprimitives for the network on downstream tasks. Most surprisingly, we find that\nmeta-training on a single formal language can provide as much improvement to a\nmodel as meta-training on 5000 different formal languages, provided that the\nformal language incentivizes the learning of useful neural mechanisms. Taken\ntogether, our findings provide practical implications for efficient\nmeta-learning paradigms and new theoretical insights into linking symbolic\ntheories and neural mechanisms.", "AI": {"tldr": "Meta-learning in neural networks doesn't teach simplicity-based priors but embeds cognitive primitives like counters, with efficiency gains from focused meta-training on single formal languages.", "motivation": "To understand what meta-learning actually imparts to models, especially in the context of formal languages and human-like learning biases.", "method": "Investigating meta-learning of formal languages, analyzing whether models learn simplicity-based priors or neural mechanisms like counters.", "result": "Meta-trained models don't learn simplicity priors but acquire neural mechanisms (e.g., counters). Meta-training on one formal language can be as effective as on 5000, if it teaches useful mechanisms.", "conclusion": "Findings offer practical efficiency in meta-learning and bridge symbolic theories with neural mechanisms."}}
{"id": "2504.04981", "pdf": "https://arxiv.org/pdf/2504.04981", "abs": "https://arxiv.org/abs/2504.04981", "authors": ["Sohyun Lee", "Nayeong Kim", "Juwon Kang", "Seong Joon Oh", "Suha Kwak"], "title": "TestDG: Test-time Domain Generalization for Continual Test-time Adaptation", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "This paper studies continual test-time adaptation (CTTA), the task of\nadapting a model to constantly changing unseen domains in testing while\npreserving previously learned knowledge. Existing CTTA methods mostly focus on\nadaptation to the current test domain only, overlooking generalization to\narbitrary test domains a model may face in the future. To tackle this\nlimitation, we present a novel online test-time domain generalization framework\nfor CTTA, dubbed TestDG. TestDG aims to learn features invariant to both\ncurrent and previous test domains on the fly during testing, improving the\npotential for effective generalization to future domains. To this end, we\npropose a new model architecture and a test-time adaptation strategy dedicated\nto learning domain-invariant features, along with a new data structure and\noptimization algorithm for effectively managing information from previous test\ndomains. TestDG achieved state of the art on four public CTTA benchmarks.\nMoreover, it showed superior generalization to unseen test domains.", "AI": {"tldr": "TestDG introduces a novel online test-time domain generalization framework for continual test-time adaptation (CTTA), focusing on learning domain-invariant features for current and future unseen domains.", "motivation": "Existing CTTA methods lack generalization to arbitrary future test domains, limiting their effectiveness.", "method": "Proposes a new model architecture, adaptation strategy, data structure, and optimization algorithm to learn and manage domain-invariant features during testing.", "result": "Achieved state-of-the-art performance on four CTTA benchmarks and demonstrated superior generalization to unseen domains.", "conclusion": "TestDG effectively addresses the limitation of existing CTTA methods by improving generalization to future test domains."}}
{"id": "2408.05885", "pdf": "https://arxiv.org/pdf/2408.05885", "abs": "https://arxiv.org/abs/2408.05885", "authors": ["Puhua Niu", "Shili Wu", "Mingzhou Fan", "Xiaoning Qian"], "title": "GFlowNet Training by Policy Gradients", "categories": ["cs.LG", "stat.ML"], "comment": "Accepted by ICML 2024", "summary": "Generative Flow Networks (GFlowNets) have been shown effective to generate\ncombinatorial objects with desired properties. We here propose a new GFlowNet\ntraining framework, with policy-dependent rewards, that bridges keeping flow\nbalance of GFlowNets to optimizing the expected accumulated reward in\ntraditional Reinforcement-Learning (RL). This enables the derivation of new\npolicy-based GFlowNet training methods, in contrast to existing ones resembling\nvalue-based RL. It is known that the design of backward policies in GFlowNet\ntraining affects efficiency. We further develop a coupled training strategy\nthat jointly solves GFlowNet forward policy training and backward policy\ndesign. Performance analysis is provided with a theoretical guarantee of our\npolicy-based GFlowNet training. Experiments on both simulated and real-world\ndatasets verify that our policy-based strategies provide advanced RL\nperspectives for robust gradient estimation to improve GFlowNet performance.", "AI": {"tldr": "A new GFlowNet training framework with policy-dependent rewards bridges flow balance to RL reward optimization, enabling policy-based methods and joint forward-backward policy training.", "motivation": "To improve GFlowNet performance by connecting flow balance to RL reward optimization and addressing backward policy design inefficiencies.", "method": "Proposes policy-dependent rewards, derives policy-based training methods, and introduces a coupled strategy for joint forward and backward policy training.", "result": "Theoretical guarantees and experiments on simulated/real-world datasets show improved performance and robust gradient estimation.", "conclusion": "Policy-based GFlowNet training offers advanced RL perspectives, enhancing performance and gradient robustness."}}
{"id": "2503.02039", "pdf": "https://arxiv.org/pdf/2503.02039", "abs": "https://arxiv.org/abs/2503.02039", "authors": ["Xiner Li", "Masatoshi Uehara", "Xingyu Su", "Gabriele Scalia", "Tommaso Biancalani", "Aviv Regev", "Sergey Levine", "Shuiwang Ji"], "title": "Dynamic Search for Inference-Time Alignment in Diffusion Models", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Diffusion models have shown promising generative capabilities across diverse\ndomains, yet aligning their outputs with desired reward functions remains a\nchallenge, particularly in cases where reward functions are non-differentiable.\nSome gradient-free guidance methods have been developed, but they often\nstruggle to achieve optimal inference-time alignment. In this work, we newly\nframe inference-time alignment in diffusion as a search problem and propose\nDynamic Search for Diffusion (DSearch), which subsamples from denoising\nprocesses and approximates intermediate node rewards. It also dynamically\nadjusts beam width and tree expansion to efficiently explore high-reward\ngenerations. To refine intermediate decisions, DSearch incorporates adaptive\nscheduling based on noise levels and a lookahead heuristic function. We\nvalidate DSearch across multiple domains, including biological sequence design,\nmolecular optimization, and image generation, demonstrating superior reward\noptimization compared to existing approaches.", "AI": {"tldr": "DSearch frames diffusion model alignment as a search problem, dynamically optimizing reward alignment during inference.", "motivation": "Aligning diffusion model outputs with non-differentiable reward functions is challenging, and existing gradient-free methods often fail to achieve optimal alignment.", "method": "Proposes DSearch, which treats alignment as a search problem, subsamples denoising processes, approximates rewards, and dynamically adjusts beam width and tree expansion. Uses adaptive scheduling and lookahead heuristics.", "result": "Validated in biological sequence design, molecular optimization, and image generation, showing superior reward optimization.", "conclusion": "DSearch effectively addresses inference-time alignment in diffusion models, outperforming existing methods."}}
{"id": "2503.17579", "pdf": "https://arxiv.org/pdf/2503.17579", "abs": "https://arxiv.org/abs/2503.17579", "authors": ["Suet-Ying Lam", "Qingcheng Zeng", "Jingyi Wu", "Rob Voigt"], "title": "Leveraging Human Production-Interpretation Asymmetries to Test LLM Cognitive Plausibility", "categories": ["cs.CL"], "comment": "ACL 2025 Camera-ready", "summary": "Whether large language models (LLMs) process language similarly to humans has\nbeen the subject of much theoretical and practical debate. We examine this\nquestion through the lens of the production-interpretation distinction found in\nhuman sentence processing and evaluate the extent to which instruction-tuned\nLLMs replicate this distinction. Using an empirically documented asymmetry\nbetween pronoun production and interpretation in humans for implicit causality\nverbs as a testbed, we find that some LLMs do quantitatively and qualitatively\nreflect human-like asymmetries between production and interpretation. We\ndemonstrate that whether this behavior holds depends upon both model size-with\nlarger models more likely to reflect human-like patterns and the choice of\nmeta-linguistic prompts used to elicit the behavior. Our codes and results are\navailable at\nhttps://github.com/LingMechLab/Production-Interpretation_Asymmetries_ACL2025.", "AI": {"tldr": "LLMs show human-like production-interpretation asymmetries, influenced by model size and prompts.", "motivation": "To determine if LLMs process language like humans, focusing on production-interpretation distinctions.", "method": "Tested LLMs using pronoun asymmetry in implicit causality verbs, varying model size and prompts.", "result": "Some LLMs replicate human-like asymmetries, more likely in larger models and with specific prompts.", "conclusion": "LLMs can mimic human language processing patterns, dependent on model size and prompt design."}}
{"id": "2504.07744", "pdf": "https://arxiv.org/pdf/2504.07744", "abs": "https://arxiv.org/abs/2504.07744", "authors": ["Jenna Kline", "Samuel Stevens", "Guy Maalouf", "Camille Rondeau Saint-Jean", "Dat Nguyen Ngoc", "Majid Mirmehdi", "David Guerin", "Tilo Burghardt", "Elzbieta Pastucha", "Blair Costelloe", "Matthew Watson", "Thomas Richardson", "Ulrik Pagh Schultz Lundquist"], "title": "MMLA: Multi-Environment, Multi-Species, Low-Altitude Drone Dataset", "categories": ["cs.CV"], "comment": "Accepted at CVPR Workshop, CV4Animals 2025", "summary": "Real-time wildlife detection in drone imagery supports critical ecological\nand conservation monitoring. However, standard detection models like YOLO often\nfail to generalize across locations and struggle with rare species, limiting\ntheir use in automated drone deployments. We present MMLA, a novel\nmulti-environment, multi-species, low-altitude drone dataset collected across\nthree sites (Ol Pejeta Conservancy and Mpala Research Centre in Kenya, and The\nWilds in Ohio), featuring six species (zebras, giraffes, onagers, and African\nwild dogs). The dataset contains 811K annotations from 37 high-resolution\nvideos. Baseline YOLO models show performance disparities across locations\nwhile fine-tuning YOLOv11m on MMLA improves mAP50 to 82%, a 52-point gain over\nbaseline. Our results underscore the need for diverse training data to enable\nrobust animal detection in autonomous drone systems.", "AI": {"tldr": "MMLA dataset improves wildlife detection in drone imagery, boosting YOLOv11m performance by 52 points over baseline.", "motivation": "Standard detection models like YOLO struggle with generalization across locations and rare species, limiting automated drone use in conservation.", "method": "Introduces MMLA, a multi-environment, multi-species drone dataset with 811K annotations from 37 videos across three sites. Fine-tunes YOLOv11m on MMLA.", "result": "Fine-tuning YOLOv11m on MMLA improves mAP50 to 82%, a 52-point gain over baseline.", "conclusion": "Diverse training data is crucial for robust animal detection in autonomous drone systems."}}
{"id": "2408.08824", "pdf": "https://arxiv.org/pdf/2408.08824", "abs": "https://arxiv.org/abs/2408.08824", "authors": ["Mohamad Fares El Hajj Chehade", "Wenting Li", "Brian W. Bell", "Russell Bent", "Saif R. Kazi", "Hao Zhu"], "title": "LEVIS: Large Exact Verifiable Input Spaces for Neural Networks", "categories": ["cs.LG"], "comment": null, "summary": "The robustness of neural networks is crucial in safety-critical applications,\nwhere identifying a reliable input space is essential for effective model\nselection, robustness evaluation, and the development of reliable control\nstrategies. Most existing robustness verification methods assess the worst-case\noutput under the assumption that the input space is known. However, precisely\nidentifying a verifiable input space \\(\\mathcal{C}\\), where no adversarial\nexamples exist, is challenging due to the possible high dimensionality,\ndiscontinuity, and non-convex nature of the input space. To address this\nchallenge, we propose a novel framework, **LEVIS**, consisting of\n**LEVIS-{\\alpha}** and **LEVIS-\\b{eta}**. **LEVIS-{\\alpha}** identifies a\nsingle, large verifiable ball that intersects at least two boundaries of a\nbounded region \\(\\mathcal{C}\\), while **LEVIS-\\b{eta}** systematically captures\nthe entirety of the verifiable space by integrating multiple verifiable balls.\nOur contributions include: (1) introducing a verification framework that uses\nmixed-integer programming (MIP) to compute nearest and directional adversarial\npoints, (2) integrating complementarity-constrained (CC) optimization with a\nreduced MIP formulation for scalability, achieving up to a 6 times runtime\nreduction, (3) theoretically characterizing the properties of the verifiable\nballs obtained by **LEVIS-{\\alpha}**, and (4) validating the approach across\napplications including electrical power flow regression and image\nclassification, with demonstrated performance gains and geometric insights into\nthe verifiable region.", "AI": {"tldr": "The paper proposes LEVIS, a framework for identifying verifiable input spaces in neural networks, addressing challenges like high dimensionality and non-convexity. It includes two components (LEVIS-\u03b1 and LEVIS-\u03b2) and demonstrates performance gains in applications like power flow regression and image classification.", "motivation": "Ensuring neural network robustness in safety-critical applications requires reliable input space identification, which is challenging due to high dimensionality and non-convexity.", "method": "LEVIS framework: LEVIS-\u03b1 identifies large verifiable balls intersecting boundaries, while LEVIS-\u03b2 captures the entire verifiable space. Uses MIP for adversarial point computation and CC optimization for scalability.", "result": "Achieves up to 6x runtime reduction, provides geometric insights, and validates performance in power flow regression and image classification.", "conclusion": "LEVIS effectively addresses input space verification challenges, offering scalable solutions and practical insights for robust neural network applications."}}
{"id": "2503.04472", "pdf": "https://arxiv.org/pdf/2503.04472", "abs": "https://arxiv.org/abs/2503.04472", "authors": ["Yi Shen", "Jian Zhang", "Jieyun Huang", "Shuming Shi", "Wenjing Zhang", "Jiangze Yan", "Ning Wang", "Kai Wang", "Zhaoxiang Liu", "Shiguo Lian"], "title": "DAST: Difficulty-Adaptive Slow-Thinking for Large Reasoning Models", "categories": ["cs.LG", "cs.AI"], "comment": "working in progress", "summary": "Recent advancements in slow thinking reasoning models have shown exceptional\nperformance in complex reasoning tasks. However, these models often exhibit\noverthinking (generating redundant reasoning steps for simple problems),\nleading to excessive computational resource usage. While current mitigation\nstrategies uniformly reduce reasoning tokens, they risk degrading performance\non challenging tasks that require extended reasoning. This paper introduces\nDifficulty-Adaptive Slow Thinking (DAST), a novel framework that enables models\nto autonomously adjust the length of Chain-of-Thought (CoT) based on problem\ndifficulty. We first propose a Token Length Budget (TLB) metric to quantify\ndifficulty, then leverage budget-aware reward shaping and budget preference\noptimization to implement DAST. DAST penalizes overlong responses for simple\ntasks while incentivizing sufficient reasoning for complex problems.\nExperiments on diverse datasets and model scales demonstrate that DAST\neffectively mitigates overthinking (reducing token usage by over 30\\% on\naverage) while preserving reasoning accuracy on complex problems. Our codes and\nmodels are available at https://github.com/AnonymousUser0520/AnonymousRepo01.", "AI": {"tldr": "DAST adapts reasoning length to problem difficulty, reducing overthinking by 30% without sacrificing accuracy on complex tasks.", "motivation": "Address overthinking in slow thinking models, which wastes resources on simple problems while risking underperformance on complex ones.", "method": "Introduces Difficulty-Adaptive Slow Thinking (DAST) with Token Length Budget (TLB) metric, budget-aware reward shaping, and budget preference optimization.", "result": "Reduces token usage by over 30% on average while maintaining accuracy on complex tasks.", "conclusion": "DAST effectively balances reasoning efficiency and performance, offering a practical solution for adaptive reasoning models."}}
{"id": "2503.22395", "pdf": "https://arxiv.org/pdf/2503.22395", "abs": "https://arxiv.org/abs/2503.22395", "authors": ["Tereza Vrabcov\u00e1", "Marek Kadl\u010d\u00edk", "Petr Sojka", "Michal \u0160tef\u00e1nik", "Michal Spiegel"], "title": "Negation: A Pink Elephant in the Large Language Models' Room?", "categories": ["cs.CL"], "comment": null, "summary": "Negations are key to determining sentence meaning, making them essential for\nlogical reasoning. Despite their importance, negations pose a substantial\nchallenge for large language models (LLMs) and remain underexplored.\n  We constructed and published two new textual entailment datasets NoFEVER-ML\nand NoSNLI-ML in four languages (English, Czech, German, and Ukrainian) with\n  examples differing in negation. It allows investigation of the root causes of\nthe negation problem and its exemplification: how popular LLM model properties\nand language impact their inability to handle negation correctly.\n  Contrary to previous work, we show that increasing the model size may improve\nthe models' ability to handle negations. Furthermore, we find that both the\nmodels' reasoning accuracy and robustness to negation are language-dependent\nand that the length and explicitness of the premise have an impact on\nrobustness. There is better accuracy in projective language with fixed order,\nsuch as English, than in non-projective ones, such as German or Czech.\n  Our entailment datasets pave the way to further research for explanation and\nexemplification of the negation problem, minimization of LLM hallucinations,\nand improvement of LLM reasoning in multilingual settings.", "AI": {"tldr": "The paper introduces two new datasets (NoFEVER-ML and NoSNLI-ML) to study LLMs' challenges with negation, showing model size, language type, and premise explicitness impact performance.", "motivation": "Negations are crucial for logical reasoning but pose challenges for LLMs, which remain underexplored.", "method": "Constructed multilingual entailment datasets (NoFEVER-ML and NoSNLI-ML) to analyze negation handling in LLMs.", "result": "Larger models improve negation handling; performance is language-dependent, with projective languages like English outperforming non-projective ones.", "conclusion": "The datasets enable further research on negation, LLM hallucinations, and multilingual reasoning improvements."}}
{"id": "2504.13077", "pdf": "https://arxiv.org/pdf/2504.13077", "abs": "https://arxiv.org/abs/2504.13077", "authors": ["Prasanna Reddy Pulakurthi", "Majid Rabbani", "Celso M. de Melo", "Sohail A. Dianat", "Raghuveer M. Rao"], "title": "Effective Dual-Region Augmentation for Reduced Reliance on Large Amounts of Labeled Data", "categories": ["cs.CV"], "comment": "9 pages, 2 figures, 4 tables, Accepted to SPIE DSC 2025 Conference:\n  Synthetic Data for Artificial Intelligence and Machine Learning: Tools,\n  Techniques, and Applications III", "summary": "This paper introduces a novel dual-region augmentation approach designed to\nreduce reliance on large-scale labeled datasets while improving model\nrobustness and adaptability across diverse computer vision tasks, including\nsource-free domain adaptation (SFDA) and person re-identification (ReID). Our\nmethod performs targeted data transformations by applying random noise\nperturbations to foreground objects and spatially shuffling background patches.\nThis effectively increases the diversity of the training data, improving model\nrobustness and generalization. Evaluations on the PACS dataset for SFDA\ndemonstrate that our augmentation strategy consistently outperforms existing\nmethods, achieving significant accuracy improvements in both single-target and\nmulti-target adaptation settings. By augmenting training data through\nstructured transformations, our method enables model generalization across\ndomains, providing a scalable solution for reducing reliance on manually\nannotated datasets. Furthermore, experiments on Market-1501 and DukeMTMC-reID\ndatasets validate the effectiveness of our approach for person ReID, surpassing\ntraditional augmentation techniques. The code is available at\nhttps://github.com/PrasannaPulakurthi/Foreground-Background-Augmentation", "AI": {"tldr": "A dual-region augmentation method improves model robustness and reduces reliance on labeled data by applying noise to foregrounds and shuffling backgrounds, outperforming existing techniques in SFDA and ReID tasks.", "motivation": "To reduce dependence on large labeled datasets and enhance model adaptability across diverse computer vision tasks like SFDA and ReID.", "method": "Targeted data transformations: random noise perturbations on foreground objects and spatial shuffling of background patches.", "result": "Outperforms existing methods on PACS (SFDA) and Market-1501/DukeMTMC-reID (ReID), showing significant accuracy improvements.", "conclusion": "The method enhances model generalization across domains and reduces the need for manual annotations, validated by strong performance in SFDA and ReID."}}
{"id": "2408.12068", "pdf": "https://arxiv.org/pdf/2408.12068", "abs": "https://arxiv.org/abs/2408.12068", "authors": ["Zixuan Weng", "Jindong Han", "Wenzhao Jiang", "Hao Liu"], "title": "SDE: A Simplified and Disentangled Dependency Encoding Framework for State Space Models in Time Series Forecasting", "categories": ["cs.LG"], "comment": "Accepted by KDD 2025", "summary": "In recent years, advancements in deep learning have spurred the development\nof numerous models for Long-term Time Series Forecasting (LTSF). However, most\nexisting approaches struggle to fully capture the complex and structured\ndependencies inherent in time series data. In this work, we identify and\nformally define three critical dependencies that are fundamental to forecasting\naccuracy: order dependency and semantic dependency along the temporal\ndimension, as well as cross-variate dependency across the feature dimension.\nThese dependencies are often treated in isolation, and improper handling can\nintroduce noise and degrade forecasting performance. To bridge this gap, we\ninvestigate the potential of State Space Models (SSMs) for LTSF and emphasize\ntheir inherent advantages in capturing these essential dependencies.\nAdditionally, we empirically observe that excessive nonlinearity in\nconventional SSMs introduce redundancy when applied to semantically sparse time\nseries data. Motivated by this insight, we propose SDE (Simplified and\nDisentangled Dependency Encoding), a novel framework designed to enhance the\ncapability of SSMs for LTSF. Specifically, we first eliminate unnecessary\nnonlinearities in vanilla SSMs, thereby improving the suitability for time\nseries forecasting. Building on this foundation, we introduce a disentangled\nencoding strategy, which empowers SSMs to efficiently model cross-variate\ndependencies while mitigating interference between the temporal and feature\ndimensions. Furthermore, we provide rigorous theoretical justifications to\nsubstantiate our design choices. Extensive experiments on nine real-world\nbenchmark datasets demonstrate that SDE-enhanced SSMs consistently outperform\nstate-of-the-art time series forecasting models.Our code is available at\nhttps://github.com/YukinoAsuna/SAMBA.", "AI": {"tldr": "The paper proposes SDE, a framework to enhance State Space Models (SSMs) for Long-term Time Series Forecasting (LTSF) by simplifying nonlinearities and disentangling dependencies, achieving superior performance.", "motivation": "Existing LTSF models fail to fully capture complex dependencies in time series data, leading to noise and degraded performance. SSMs show promise but suffer from redundancy due to excessive nonlinearity.", "method": "The SDE framework simplifies SSMs by removing unnecessary nonlinearities and introduces a disentangled encoding strategy to model cross-variate dependencies without interference.", "result": "Experiments on nine datasets show SDE-enhanced SSMs outperform state-of-the-art models.", "conclusion": "SDE effectively improves SSMs for LTSF by addressing dependency modeling and redundancy, validated by theoretical and empirical results."}}
{"id": "2503.05231", "pdf": "https://arxiv.org/pdf/2503.05231", "abs": "https://arxiv.org/abs/2503.05231", "authors": ["Shuo Jiang", "Haonan Li", "Ruochen Ren", "Yanmin Zhou", "Zhipeng Wang", "Bin He"], "title": "Kaiwu: A Multimodal Manipulation Dataset and Framework for Robot Learning and Human-Robot Interaction", "categories": ["cs.RO", "cs.AI"], "comment": "8 pages, 5 figures, Submitted to IEEE Robotics and Automation Letters\n  (RAL)", "summary": "Cutting-edge robot learning techniques including foundation models and\nimitation learning from humans all pose huge demands on large-scale and\nhigh-quality datasets which constitute one of the bottleneck in the general\nintelligent robot fields. This paper presents the Kaiwu multimodal dataset to\naddress the missing real-world synchronized multimodal data problems in the\nsophisticated assembling scenario,especially with dynamics information and its\nfine-grained labelling. The dataset first provides an integration of\nhuman,environment and robot data collection framework with 20 subjects and 30\ninteraction objects resulting in totally 11,664 instances of integrated\nactions. For each of the demonstration,hand motions,operation pressures,sounds\nof the assembling process,multi-view videos, high-precision motion capture\ninformation,eye gaze with first-person videos,electromyography signals are all\nrecorded. Fine-grained multi-level annotation based on absolute timestamp,and\nsemantic segmentation labelling are performed. Kaiwu dataset aims to facilitate\nrobot learning,dexterous manipulation,human intention investigation and\nhuman-robot collaboration research.", "AI": {"tldr": "The paper introduces the Kaiwu multimodal dataset to address the lack of real-world synchronized multimodal data in robot learning, specifically for assembling tasks with dynamics and fine-grained labels.", "motivation": "The bottleneck in robot learning is the scarcity of large-scale, high-quality datasets. Kaiwu aims to fill this gap for sophisticated assembling scenarios.", "method": "The dataset integrates human, environment, and robot data, including hand motions, pressures, sounds, videos, motion capture, eye gaze, and EMG signals, with fine-grained annotations.", "result": "Kaiwu contains 11,664 instances from 20 subjects and 30 objects, providing rich multimodal data for research.", "conclusion": "The dataset supports robot learning, dexterous manipulation, human intention study, and human-robot collaboration."}}
{"id": "2504.00589", "pdf": "https://arxiv.org/pdf/2504.00589", "abs": "https://arxiv.org/abs/2504.00589", "authors": ["Owen Cook", "Jake Vasilakes", "Ian Roberts", "Xingyi Song"], "title": "Efficient Annotator Reliability Assessment with EffiARA", "categories": ["cs.CL", "cs.LG"], "comment": null, "summary": "Data annotation is an essential component of the machine learning pipeline;\nit is also a costly and time-consuming process. With the introduction of\ntransformer-based models, annotation at the document level is increasingly\npopular; however, there is no standard framework for structuring such tasks.\nThe EffiARA annotation framework is, to our knowledge, the first project to\nsupport the whole annotation pipeline, from understanding the resources\nrequired for an annotation task to compiling the annotated dataset and gaining\ninsights into the reliability of individual annotators as well as the dataset\nas a whole. The framework's efficacy is supported by two previous studies: one\nimproving classification performance through annotator-reliability-based\nsoft-label aggregation and sample weighting, and the other increasing the\noverall agreement among annotators through removing identifying and replacing\nan unreliable annotator. This work introduces the EffiARA Python package and\nits accompanying webtool, which provides an accessible graphical user interface\nfor the system. We open-source the EffiARA Python package at\nhttps://github.com/MiniEggz/EffiARA and the webtool is publicly accessible at\nhttps://effiara.gate.ac.uk.", "AI": {"tldr": "EffiARA is a framework supporting the entire document-level annotation pipeline, improving efficiency and reliability in machine learning data annotation.", "motivation": "Data annotation is costly and lacks standardization, especially for document-level tasks. EffiARA aims to address this gap.", "method": "EffiARA provides tools for task setup, dataset compilation, and annotator reliability analysis, supported by Python and a webtool.", "result": "Previous studies show improved classification and annotator agreement using EffiARA's reliability-based methods.", "conclusion": "EffiARA is open-source and accessible, offering a standardized solution for document-level annotation."}}
{"id": "2504.19475", "pdf": "https://arxiv.org/pdf/2504.19475", "abs": "https://arxiv.org/abs/2504.19475", "authors": ["Sonia Joseph", "Praneet Suresh", "Lorenz Hufe", "Edward Stevinson", "Robert Graham", "Yash Vadi", "Danilo Bzdok", "Sebastian Lapuschkin", "Lee Sharkey", "Blake Aaron Richards"], "title": "Prisma: An Open Source Toolkit for Mechanistic Interpretability in Vision and Video", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": "4 pages, 3 figures, 9 tables. Oral and Tutorial at the CVPR\n  Mechanistic Interpretability for Vision (MIV) Workshop", "summary": "Robust tooling and publicly available pre-trained models have helped drive\nrecent advances in mechanistic interpretability for language models. However,\nsimilar progress in vision mechanistic interpretability has been hindered by\nthe lack of accessible frameworks and pre-trained weights. We present Prisma\n(Access the codebase here: https://github.com/Prisma-Multimodal/ViT-Prisma), an\nopen-source framework designed to accelerate vision mechanistic\ninterpretability research, providing a unified toolkit for accessing 75+ vision\nand video transformers; support for sparse autoencoder (SAE), transcoder, and\ncrosscoder training; a suite of 80+ pre-trained SAE weights; activation\ncaching, circuit analysis tools, and visualization tools; and educational\nresources. Our analysis reveals surprising findings, including that effective\nvision SAEs can exhibit substantially lower sparsity patterns than language\nSAEs, and that in some instances, SAE reconstructions can decrease model loss.\nPrisma enables new research directions for understanding vision model internals\nwhile lowering barriers to entry in this emerging field.", "AI": {"tldr": "Prisma is an open-source framework for vision mechanistic interpretability, offering tools, pre-trained weights, and educational resources. It reveals insights like lower sparsity in vision SAEs compared to language SAEs.", "motivation": "Progress in vision mechanistic interpretability lags behind language models due to lack of accessible frameworks and pre-trained weights.", "method": "Prisma provides a toolkit for 75+ vision/video transformers, SAE/transcoder/crosscoder training, pre-trained weights, activation caching, circuit analysis, and visualization tools.", "result": "Findings include lower sparsity in vision SAEs than language SAEs and cases where SAE reconstructions reduce model loss.", "conclusion": "Prisma accelerates vision interpretability research, enabling new insights and lowering entry barriers."}}
{"id": "2408.16245", "pdf": "https://arxiv.org/pdf/2408.16245", "abs": "https://arxiv.org/abs/2408.16245", "authors": ["Sully F. Chen", "Robert J. Steele", "Glen M. Hocky", "Beakal Lemeneh", "Shivanand P. Lad", "Eric K. Oermann"], "title": "Large-Scale Multi-omic Biosequence Transformers for Modeling Protein-Nucleic Acid Interactions", "categories": ["cs.LG", "q-bio.BM"], "comment": "37 pages, 5 figures", "summary": "The transformer architecture has revolutionized bioinformatics and driven\nprogress in the understanding and prediction of the properties of biomolecules.\nTo date, most biosequence transformers have been trained on a single\nomic-either proteins or nucleic acids and have seen incredible success in\ndownstream tasks in each domain with particularly noteworthy breakthroughs in\nprotein structural modeling. However, single-omic pre-training limits the\nability of these models to capture cross-modal interactions. Here we present\nOmniBioTE, the largest open-source multi-omic model trained on over 250 billion\ntokens of mixed protein and nucleic acid data. We show that despite only being\ntrained on unlabelled sequence data, OmniBioTE learns joint representations\nconsistent with the central dogma of molecular biology. We further demonstrate\nthat OmbiBioTE achieves state-of-the-art results predicting the change in Gibbs\nfree energy ({\\Delta}G) of the binding interaction between a given nucleic acid\nand protein. Remarkably, we show that multi-omic biosequence transformers\nemergently learn useful structural information without any a priori structural\ntraining, allowing us to predict which protein residues are most involved in\nthe protein-nucleic acid binding interaction. Lastly, compared to single-omic\ncontrols trained with identical compute, OmniBioTE demonstrates superior\nperformance-per-FLOP and absolute accuracy across both multi-omic and\nsingle-omic benchmarks, highlighting the power of a unified modeling approach\nfor biological sequences.", "AI": {"tldr": "OmniBioTE is a multi-omic transformer model trained on mixed protein and nucleic acid data, outperforming single-omic models in cross-modal tasks and structural predictions.", "motivation": "Single-omic models limit cross-modal interactions; OmniBioTE aims to unify protein and nucleic acid modeling for better biological insights.", "method": "Trained on 250B tokens of unlabeled mixed protein/nucleic acid data, OmniBioTE learns joint representations and predicts binding energy (\u0394G).", "result": "State-of-the-art \u0394G prediction, emergent structural learning, and superior performance-per-FLOP compared to single-omic models.", "conclusion": "Multi-omic transformers like OmniBioTE offer unified, efficient, and accurate modeling for biological sequences."}}
{"id": "2503.05306", "pdf": "https://arxiv.org/pdf/2503.05306", "abs": "https://arxiv.org/abs/2503.05306", "authors": ["Hyungkyu Kang", "Min-hwan Oh"], "title": "Adversarial Policy Optimization for Offline Preference-based Reinforcement Learning", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "In this paper, we study offline preference-based reinforcement learning\n(PbRL), where learning is based on pre-collected preference feedback over pairs\nof trajectories. While offline PbRL has demonstrated remarkable empirical\nsuccess, existing theoretical approaches face challenges in ensuring\nconservatism under uncertainty, requiring computationally intractable\nconfidence set constructions. We address this limitation by proposing\nAdversarial Preference-based Policy Optimization (APPO), a computationally\nefficient algorithm for offline PbRL that guarantees sample complexity bounds\nwithout relying on explicit confidence sets. By framing PbRL as a two-player\ngame between a policy and a model, our approach enforces conservatism in a\ntractable manner. Using standard assumptions on function approximation and\nbounded trajectory concentrability, we derive a sample complexity bound. To our\nknowledge, APPO is the first offline PbRL algorithm to offer both statistical\nefficiency and practical applicability. Experimental results on continuous\ncontrol tasks demonstrate that APPO effectively learns from complex datasets,\nshowing comparable performance with existing state-of-the-art methods.", "AI": {"tldr": "APPO is a computationally efficient algorithm for offline PbRL, ensuring conservatism without intractable confidence sets, with proven sample complexity bounds.", "motivation": "Existing offline PbRL methods struggle with conservatism under uncertainty and computational intractability.", "method": "APPO frames PbRL as a two-player game between policy and model, enforcing conservatism tractably.", "result": "APPO achieves sample complexity bounds and performs comparably to state-of-the-art methods in experiments.", "conclusion": "APPO is the first offline PbRL algorithm combining statistical efficiency and practical applicability."}}
{"id": "2504.05050", "pdf": "https://arxiv.org/pdf/2504.05050", "abs": "https://arxiv.org/abs/2504.05050", "authors": ["Jiawei Lian", "Jianhong Pan", "Lefan Wang", "Yi Wang", "Shaohui Mei", "Lap-Pui Chau"], "title": "Revealing the Intrinsic Ethical Vulnerability of Aligned Large Language Models", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Large language models (LLMs) are foundational explorations to artificial\ngeneral intelligence, yet their alignment with human values via instruction\ntuning and preference learning achieves only superficial compliance. Here, we\ndemonstrate that harmful knowledge embedded during pretraining persists as\nindelible \"dark patterns\" in LLMs' parametric memory, evading alignment\nsafeguards and resurfacing under adversarial inducement at distributional\nshifts. In this study, we first theoretically analyze the intrinsic ethical\nvulnerability of aligned LLMs by proving that current alignment methods yield\nonly local \"safety regions\" in the knowledge manifold. In contrast, pretrained\nknowledge remains globally connected to harmful concepts via high-likelihood\nadversarial trajectories. Building on this theoretical insight, we empirically\nvalidate our findings by employing semantic coherence inducement under\ndistributional shifts--a method that systematically bypasses alignment\nconstraints through optimized adversarial prompts. This combined theoretical\nand empirical approach achieves a 100% attack success rate across 19 out of 23\nstate-of-the-art aligned LLMs, including DeepSeek-R1 and LLaMA-3, revealing\ntheir universal vulnerabilities.", "AI": {"tldr": "Aligned LLMs retain harmful knowledge despite alignment efforts, with vulnerabilities exposed via adversarial prompts under distributional shifts.", "motivation": "To uncover the persistent ethical vulnerabilities in aligned LLMs, showing that current alignment methods fail to fully disconnect harmful pretrained knowledge.", "method": "Theoretical analysis of alignment limitations and empirical validation using adversarial prompts under distributional shifts.", "result": "100% attack success rate on 19 out of 23 state-of-the-art aligned LLMs, revealing universal vulnerabilities.", "conclusion": "Current alignment methods are insufficient; harmful knowledge persists and can be exploited, necessitating better safeguards."}}
{"id": "2505.03414", "pdf": "https://arxiv.org/pdf/2505.03414", "abs": "https://arxiv.org/abs/2505.03414", "authors": ["Fangming Cui", "Yonggang Zhang", "Xuan Wang", "Xinmei Tian", "Jun Yu"], "title": "Enhancing Target-unspecific Tasks through a Features Matrix", "categories": ["cs.CV", "cs.CL"], "comment": "Accepted by ICML 2025", "summary": "Recent developments in prompt learning of large Vision-Language Models (VLMs)\nhave significantly improved performance in target-specific tasks. However,\nthese prompting methods often struggle to tackle the target-unspecific or\ngeneralizable tasks effectively. It may be attributed to the fact that\noverfitting training causes the model to forget its general knowledge. The\ngeneral knowledge has a strong promotion on target-unspecific tasks. To\nalleviate this issue, we propose a novel Features Matrix (FM) approach designed\nto enhance these models on target-unspecific tasks. Our method extracts and\nleverages general knowledge, shaping a Features Matrix (FM). Specifically, the\nFM captures the semantics of diverse inputs from a deep and fine perspective,\npreserving essential general knowledge, which mitigates the risk of\noverfitting. Representative evaluations demonstrate that: 1) the FM is\ncompatible with existing frameworks as a generic and flexible module, and 2)\nthe FM significantly showcases its effectiveness in enhancing target-unspecific\ntasks (base-to-novel generalization, domain generalization, and cross-dataset\ngeneralization), achieving state-of-the-art performance.", "AI": {"tldr": "A novel Features Matrix (FM) approach is proposed to enhance Vision-Language Models (VLMs) for target-unspecific tasks by preserving general knowledge and preventing overfitting.", "motivation": "Existing prompt learning methods for VLMs struggle with target-unspecific tasks due to overfitting, which causes loss of general knowledge.", "method": "The FM approach extracts and leverages general knowledge by capturing diverse input semantics deeply and finely, preserving essential knowledge.", "result": "FM is compatible with existing frameworks and significantly improves performance in target-unspecific tasks, achieving state-of-the-art results.", "conclusion": "The FM method effectively mitigates overfitting and enhances VLMs for generalizable tasks, demonstrating broad applicability and superior performance."}}
{"id": "2409.10764", "pdf": "https://arxiv.org/pdf/2409.10764", "abs": "https://arxiv.org/abs/2409.10764", "authors": ["Zikai Zhang", "Suman Rath", "Jiaohao Xu", "Tingsong Xiao"], "title": "Federated Learning for Smart Grid: A Survey on Applications and Potential Vulnerabilities", "categories": ["cs.LG", "cs.CR", "C.2.4"], "comment": null, "summary": "The Smart Grid (SG) is a critical energy infrastructure that collects\nreal-time electricity usage data to forecast future energy demands using\ninformation and communication technologies (ICT). Due to growing concerns about\ndata security and privacy in SGs, federated learning (FL) has emerged as a\npromising training framework. FL offers a balance between privacy, efficiency,\nand accuracy in SGs by enabling collaborative model training without sharing\nprivate data from IoT devices. In this survey, we thoroughly review recent\nadvancements in designing FL-based SG systems across three stages: generation,\ntransmission and distribution, and consumption. Additionally, we explore\npotential vulnerabilities that may arise when implementing FL in these stages.\nFurthermore, we discuss the gap between state-of-the-art (SOTA) FL research and\nits practical applications in SGs, and we propose future research directions.\nUnlike traditional surveys addressing security issues in centralized machine\nlearning methods for SG systems, this survey is the first to specifically\nexamine the applications and security concerns unique to FL-based SG systems.\nWe also introduce FedGridShield, an open-source framework featuring\nimplementations of SOTA attack and defense methods. Our aim is to inspire\nfurther research into applications and improvements in the robustness of\nFL-based SG systems.", "AI": {"tldr": "The paper surveys federated learning (FL) applications in Smart Grids (SGs), addressing privacy, efficiency, and accuracy. It reviews FL-based SG systems across generation, transmission, distribution, and consumption, identifies vulnerabilities, and proposes future research directions. It also introduces FedGridShield, an open-source framework for FL security in SGs.", "motivation": "Growing concerns about data security and privacy in SGs motivate the exploration of FL as a privacy-preserving, efficient, and accurate training framework.", "method": "The paper conducts a thorough review of FL-based SG systems, examining advancements, vulnerabilities, and gaps between research and practice. It also introduces FedGridShield for implementing attack and defense methods.", "result": "The survey highlights the potential of FL in SGs, identifies unique security concerns, and proposes future research directions to bridge the gap between theory and practice.", "conclusion": "FL is a promising approach for SGs, but further research is needed to address vulnerabilities and improve robustness. FedGridShield serves as a tool to inspire advancements in FL-based SG systems."}}
{"id": "2503.05728", "pdf": "https://arxiv.org/pdf/2503.05728", "abs": "https://arxiv.org/abs/2503.05728", "authors": ["Jillian Fisher", "Ruth E. Appel", "Chan Young Park", "Yujin Potter", "Liwei Jiang", "Taylor Sorensen", "Shangbin Feng", "Yulia Tsvetkov", "Margaret E. Roberts", "Jennifer Pan", "Dawn Song", "Yejin Choi"], "title": "Political Neutrality in AI Is Impossible- But Here Is How to Approximate It", "categories": ["cs.CY", "cs.AI"], "comment": "Code: https://github.com/jfisher52/Approximation_Political_Neutrality", "summary": "AI systems often exhibit political bias, influencing users' opinions and\ndecisions. While political neutrality-defined as the absence of bias-is often\nseen as an ideal solution for fairness and safety, this position paper argues\nthat true political neutrality is neither feasible nor universally desirable\ndue to its subjective nature and the biases inherent in AI training data,\nalgorithms, and user interactions. However, inspired by Joseph Raz's\nphilosophical insight that \"neutrality [...] can be a matter of degree\" (Raz,\n1986), we argue that striving for some neutrality remains essential for\npromoting balanced AI interactions and mitigating user manipulation. Therefore,\nwe use the term \"approximation\" of political neutrality to shift the focus from\nunattainable absolutes to achievable, practical proxies. We propose eight\ntechniques for approximating neutrality across three levels of conceptualizing\nAI, examining their trade-offs and implementation strategies. In addition, we\nexplore two concrete applications of these approximations to illustrate their\npracticality. Finally, we assess our framework on current large language models\n(LLMs) at the output level, providing a demonstration of how it can be\nevaluated. This work seeks to advance nuanced discussions of political\nneutrality in AI and promote the development of responsible, aligned language\nmodels.", "AI": {"tldr": "The paper argues that true political neutrality in AI is unattainable but proposes eight techniques for approximating it, balancing fairness and practicality.", "motivation": "AI systems often exhibit political bias, impacting user decisions. The paper challenges the feasibility of absolute neutrality, advocating for achievable proxies instead.", "method": "Proposes eight techniques for approximating political neutrality across three AI conceptual levels, with trade-offs and implementation strategies. Includes two practical applications and evaluates the framework on LLMs.", "result": "Demonstrates the practicality of the proposed approximations and evaluates their effectiveness on large language models.", "conclusion": "The work aims to foster nuanced discussions on political neutrality in AI and promote responsible language model development."}}
{"id": "2504.08961", "pdf": "https://arxiv.org/pdf/2504.08961", "abs": "https://arxiv.org/abs/2504.08961", "authors": ["Kseniia Petukhova", "Ekaterina Kochmar"], "title": "A Fully Automated Pipeline for Conversational Discourse Annotation: Tree Scheme Generation and Labeling with Large Language Models", "categories": ["cs.CL"], "comment": null, "summary": "Recent advances in Large Language Models (LLMs) have shown promise in\nautomating discourse annotation for conversations. While manually designing\ntree annotation schemes significantly improves annotation quality for humans\nand models, their creation remains time-consuming and requires expert\nknowledge. We propose a fully automated pipeline that uses LLMs to construct\nsuch schemes and perform annotation. We evaluate our approach on speech\nfunctions (SFs) and the Switchboard-DAMSL (SWBD-DAMSL) taxonomies. Our\nexperiments compare various design choices, and we show that frequency-guided\ndecision trees, paired with an advanced LLM for annotation, can outperform\npreviously manually designed trees and even match or surpass human annotators\nwhile significantly reducing the time required for annotation. We release all\ncode and resultant schemes and annotations to facilitate future research on\ndiscourse annotation.", "AI": {"tldr": "An automated pipeline using LLMs constructs tree annotation schemes and performs discourse annotation, outperforming manual methods and matching human annotators in quality while saving time.", "motivation": "Manual creation of tree annotation schemes is time-consuming and requires expertise, prompting the need for automation.", "method": "The approach uses LLMs to build annotation schemes and perform annotation, evaluated on SFs and SWBD-DAMSL taxonomies with frequency-guided decision trees.", "result": "The automated pipeline outperforms manual designs and matches human annotators, reducing annotation time significantly.", "conclusion": "The released code and resources aim to advance discourse annotation research, demonstrating the effectiveness of LLMs in automating the process."}}
{"id": "2505.04185", "pdf": "https://arxiv.org/pdf/2505.04185", "abs": "https://arxiv.org/abs/2505.04185", "authors": ["Hail Song", "Wonsik Shin", "Naeun Lee", "Soomin Chung", "Nojun Kwak", "Woontack Woo"], "title": "S3D: Sketch-Driven 3D Model Generation", "categories": ["cs.CV", "cs.AI"], "comment": "Accepted as a short paper to the GMCV Workshop at CVPR'25", "summary": "Generating high-quality 3D models from 2D sketches is a challenging task due\nto the inherent ambiguity and sparsity of sketch data. In this paper, we\npresent S3D, a novel framework that converts simple hand-drawn sketches into\ndetailed 3D models. Our method utilizes a U-Net-based encoder-decoder\narchitecture to convert sketches into face segmentation masks, which are then\nused to generate a 3D representation that can be rendered from novel views. To\nensure robust consistency between the sketch domain and the 3D output, we\nintroduce a novel style-alignment loss that aligns the U-Net bottleneck\nfeatures with the initial encoder outputs of the 3D generation module,\nsignificantly enhancing reconstruction fidelity. To further enhance the\nnetwork's robustness, we apply augmentation techniques to the sketch dataset.\nThis streamlined framework demonstrates the effectiveness of S3D in generating\nhigh-quality 3D models from sketch inputs. The source code for this project is\npublicly available at https://github.com/hailsong/S3D.", "AI": {"tldr": "S3D is a framework that converts 2D sketches into detailed 3D models using a U-Net-based encoder-decoder architecture and a style-alignment loss for improved fidelity.", "motivation": "The challenge of generating high-quality 3D models from sparse and ambiguous 2D sketch data.", "method": "Uses a U-Net-based encoder-decoder to convert sketches into face segmentation masks, then generates 3D models with a style-alignment loss for consistency. Augmentation techniques are applied for robustness.", "result": "The framework effectively generates high-quality 3D models from sketch inputs.", "conclusion": "S3D demonstrates a streamlined and effective approach for 3D model generation from sketches, with publicly available source code."}}
{"id": "2409.20175", "pdf": "https://arxiv.org/pdf/2409.20175", "abs": "https://arxiv.org/abs/2409.20175", "authors": ["Hongkai Zheng", "Wenda Chu", "Austin Wang", "Nikola Kovachki", "Ricardo Baptista", "Yisong Yue"], "title": "Ensemble Kalman Diffusion Guidance: A Derivative-free Method for Inverse Problems", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "When solving inverse problems, one increasingly popular approach is to use\npre-trained diffusion models as plug-and-play priors. This framework can\naccommodate different forward models without re-training while preserving the\ngenerative capability of diffusion models. Despite their success in many\nimaging inverse problems, most existing methods rely on privileged information\nsuch as derivative, pseudo-inverse, or full knowledge about the forward model.\nThis reliance poses a substantial limitation that restricts their use in a wide\nrange of problems where such information is unavailable, such as in many\nscientific applications. We propose Ensemble Kalman Diffusion Guidance (EnKG),\na derivative-free approach that can solve inverse problems by only accessing\nforward model evaluations and a pre-trained diffusion model prior. We study the\nempirical effectiveness of EnKG across various inverse problems, including\nscientific settings such as inferring fluid flows and astronomical objects,\nwhich are highly non-linear inverse problems that often only permit black-box\naccess to the forward model. We open-source our code at\nhttps://github.com/devzhk/enkg-pytorch.", "AI": {"tldr": "EnKG is a derivative-free method for solving inverse problems using pre-trained diffusion models, requiring only forward model evaluations.", "motivation": "Existing methods rely on privileged information, limiting their applicability in problems where such details are unavailable.", "method": "Proposes Ensemble Kalman Diffusion Guidance (EnKG), a derivative-free approach leveraging forward model evaluations and a pre-trained diffusion model.", "result": "Demonstrates effectiveness in non-linear inverse problems like fluid flow and astronomical object inference.", "conclusion": "EnKG broadens the applicability of diffusion models in inverse problems without requiring derivative or full forward model knowledge."}}
{"id": "2503.18156", "pdf": "https://arxiv.org/pdf/2503.18156", "abs": "https://arxiv.org/abs/2503.18156", "authors": ["Bram Rijsbosch", "Gijs van Dijck", "Konrad Kollnig"], "title": "Adoption of Watermarking Measures for AI-Generated Content and Implications under the EU AI Act", "categories": ["cs.CY", "cs.AI"], "comment": "Note that this work has not yet been published in a peer review\n  journal, it is therefore potentially still subject to change", "summary": "AI-generated images have become so good in recent years that individuals\noften cannot distinguish them any more from \"real\" images. This development,\ncombined with the rapid spread of AI-generated content online, creates a series\nof societal risks, particularly with the emergence of \"deep fakes\" that\nimpersonate real individuals. Watermarking, a technique that involves embedding\ninformation within images and other content to indicate their AI-generated\nnature, has emerged as a primary mechanism to address the risks posed by\nAI-generated content. Indeed, watermarking and AI labelling measures are now\nbecoming a legal requirement in many jurisdictions, including under the 2024\nEuropean Union AI Act. Despite the widespread use of AI image generation\nsystems, the current status of the implementation of such measures remains\nlargely unexamined. Moreover, the practical implications of the AI Act's\nwatermarking and labelling requirements have not previously been studied. The\npresent paper therefore both provides an empirical analysis of 50 widely used\nAI systems for image generation, embedded into a legal analysis of the AI Act.\nIn our legal analysis, we identify four categories of generative AI image\ndeployment scenarios relevant under the AI Act and outline how the legal\nobligations apply in each category. In our empirical analysis, we find that\nonly a minority number of AI image generators currently implement adequate\nwatermarking (38%) and deep fake labelling (8%) practices. In response, we\nsuggest a range of avenues of how the implementation of these legally mandated\ntechniques can be improved, and publicly share our tooling for the easy\ndetection of watermarks in images.", "AI": {"tldr": "The paper examines AI-generated image risks, watermarking as a solution, and compliance with the EU AI Act, finding low implementation rates of watermarking (38%) and deep fake labeling (8%).", "motivation": "Address societal risks from AI-generated images, especially deep fakes, and assess compliance with legal watermarking and labeling requirements under the EU AI Act.", "method": "Empirical analysis of 50 AI image generators and legal analysis of the EU AI Act's watermarking and labeling obligations.", "result": "Low implementation rates: 38% for watermarking, 8% for deep fake labeling. Legal obligations vary by deployment scenario.", "conclusion": "Proposes improvements for compliance and shares tools for watermark detection."}}
{"id": "2504.11042", "pdf": "https://arxiv.org/pdf/2504.11042", "abs": "https://arxiv.org/abs/2504.11042", "authors": ["Sukannya Purkayastha", "Zhuang Li", "Anne Lauscher", "Lizhen Qu", "Iryna Gurevych"], "title": "LazyReview A Dataset for Uncovering Lazy Thinking in NLP Peer Reviews", "categories": ["cs.CL"], "comment": "Accepted at ACL 2025: 29 pages, 18 Figures, 15 Tables", "summary": "Peer review is a cornerstone of quality control in scientific publishing.\nWith the increasing workload, the unintended use of `quick' heuristics,\nreferred to as lazy thinking, has emerged as a recurring issue compromising\nreview quality. Automated methods to detect such heuristics can help improve\nthe peer-reviewing process. However, there is limited NLP research on this\nissue, and no real-world dataset exists to support the development of detection\ntools. This work introduces LazyReview, a dataset of peer-review sentences\nannotated with fine-grained lazy thinking categories. Our analysis reveals that\nLarge Language Models (LLMs) struggle to detect these instances in a zero-shot\nsetting. However, instruction-based fine-tuning on our dataset significantly\nboosts performance by 10-20 performance points, highlighting the importance of\nhigh-quality training data. Furthermore, a controlled experiment demonstrates\nthat reviews revised with lazy thinking feedback are more comprehensive and\nactionable than those written without such feedback. We will release our\ndataset and the enhanced guidelines that can be used to train junior reviewers\nin the community. (Code available here:\nhttps://github.com/UKPLab/acl2025-lazy-review)", "AI": {"tldr": "LazyReview dataset addresses lazy thinking in peer reviews, showing LLMs improve with fine-tuning, and feedback enhances review quality.", "motivation": "To tackle the issue of lazy thinking in peer reviews and improve review quality by providing a dataset and tools for detection.", "method": "Introduces LazyReview, a dataset annotated with lazy thinking categories, and tests LLMs in zero-shot and fine-tuned settings.", "result": "LLMs perform poorly in zero-shot but improve by 10-20 points with fine-tuning; feedback makes reviews more actionable.", "conclusion": "High-quality training data and feedback are crucial for improving peer-review quality and training junior reviewers."}}
{"id": "2505.11282", "pdf": "https://arxiv.org/pdf/2505.11282", "abs": "https://arxiv.org/abs/2505.11282", "authors": ["Shrutarv Awasthi", "Anas Gouda", "Sven Franke", "J\u00e9r\u00f4me Rutinowski", "Frank Hoffmann", "Moritz Roidl"], "title": "MTevent: A Multi-Task Event Camera Dataset for 6D Pose Estimation and Moving Object Detection", "categories": ["cs.CV"], "comment": "Accepted at 2025 IEEE/CVF Conference on Computer Vision and Pattern\n  Recognition Workshops (CVPRW); Fifth International Workshop on Event-Based\n  Vision", "summary": "Mobile robots are reaching unprecedented speeds, with platforms like Unitree\nB2, and Fraunhofer O3dyn achieving maximum speeds between 5 and 10 m/s.\nHowever, effectively utilizing such speeds remains a challenge due to the\nlimitations of RGB cameras, which suffer from motion blur and fail to provide\nreal-time responsiveness. Event cameras, with their asynchronous operation, and\nlow-latency sensing, offer a promising alternative for high-speed robotic\nperception. In this work, we introduce MTevent, a dataset designed for 6D pose\nestimation and moving object detection in highly dynamic environments with\nlarge detection distances. Our setup consists of a stereo-event camera and an\nRGB camera, capturing 75 scenes, each on average 16 seconds, and featuring 16\nunique objects under challenging conditions such as extreme viewing angles,\nvarying lighting, and occlusions. MTevent is the first dataset to combine\nhigh-speed motion, long-range perception, and real-world object interactions,\nmaking it a valuable resource for advancing event-based vision in robotics. To\nestablish a baseline, we evaluate the task of 6D pose estimation using NVIDIA's\nFoundationPose on RGB images, achieving an Average Recall of 0.22 with\nground-truth masks, highlighting the limitations of RGB-based approaches in\nsuch dynamic settings. With MTevent, we provide a novel resource to improve\nperception models and foster further research in high-speed robotic vision. The\ndataset is available for download\nhttps://huggingface.co/datasets/anas-gouda/MTevent", "AI": {"tldr": "MTevent is a dataset for 6D pose estimation and moving object detection in high-speed, dynamic environments, addressing RGB camera limitations with event cameras.", "motivation": "High-speed mobile robots face perception challenges due to RGB camera limitations like motion blur and latency, prompting the need for event-based solutions.", "method": "A stereo-event camera and RGB camera captured 75 scenes with 16 unique objects under challenging conditions (e.g., extreme angles, lighting, occlusions).", "result": "Baseline 6D pose estimation using RGB images achieved an Average Recall of 0.22, highlighting RGB limitations in dynamic settings.", "conclusion": "MTevent provides a novel resource to advance event-based vision in robotics, addressing high-speed motion and real-world object interactions."}}
{"id": "2410.02416", "pdf": "https://arxiv.org/pdf/2410.02416", "abs": "https://arxiv.org/abs/2410.02416", "authors": ["Seyedmorteza Sadat", "Otmar Hilliges", "Romann M. Weber"], "title": "Eliminating Oversaturation and Artifacts of High Guidance Scales in Diffusion Models", "categories": ["cs.LG", "cs.CV"], "comment": "Published as a conference paper at ICLR 2025", "summary": "Classifier-free guidance (CFG) is crucial for improving both generation\nquality and alignment between the input condition and final output in diffusion\nmodels. While a high guidance scale is generally required to enhance these\naspects, it also causes oversaturation and unrealistic artifacts. In this\npaper, we revisit the CFG update rule and introduce modifications to address\nthis issue. We first decompose the update term in CFG into parallel and\northogonal components with respect to the conditional model prediction and\nobserve that the parallel component primarily causes oversaturation, while the\northogonal component enhances image quality. Accordingly, we propose\ndown-weighting the parallel component to achieve high-quality generations\nwithout oversaturation. Additionally, we draw a connection between CFG and\ngradient ascent and introduce a new rescaling and momentum method for the CFG\nupdate rule based on this insight. Our approach, termed adaptive projected\nguidance (APG), retains the quality-boosting advantages of CFG while enabling\nthe use of higher guidance scales without oversaturation. APG is easy to\nimplement and introduces practically no additional computational overhead to\nthe sampling process. Through extensive experiments, we demonstrate that APG is\ncompatible with various conditional diffusion models and samplers, leading to\nimproved FID, recall, and saturation scores while maintaining precision\ncomparable to CFG, making our method a superior plug-and-play alternative to\nstandard classifier-free guidance.", "AI": {"tldr": "The paper introduces adaptive projected guidance (APG) to address oversaturation in classifier-free guidance (CFG) for diffusion models, improving generation quality without extra computational cost.", "motivation": "High guidance scales in CFG improve quality but cause oversaturation and artifacts, necessitating a solution.", "method": "APG decomposes CFG's update term into parallel and orthogonal components, down-weights the parallel part, and introduces rescaling and momentum.", "result": "APG improves FID, recall, and saturation scores while maintaining precision, outperforming standard CFG.", "conclusion": "APG is a superior, plug-and-play alternative to CFG, compatible with various models and samplers."}}
{"id": "2504.05424", "pdf": "https://arxiv.org/pdf/2504.05424", "abs": "https://arxiv.org/abs/2504.05424", "authors": ["Raffi Khatchadourian", "Tatiana Castro V\u00e9lez", "Mehdi Bagherzadeh", "Nan Jia", "Anita Raja"], "title": "Speculative Automated Refactoring of Imperative Deep Learning Programs to Graph Execution", "categories": ["cs.SE", "cs.AI", "cs.PL", "D.2.7; C.4; D.3.4; I.2.6"], "comment": null, "summary": "Efficiency is essential to support ever-growing datasets, especially for Deep\nLearning (DL) systems. DL frameworks have traditionally embraced deferred\nexecution-style DL code -- supporting symbolic, graph-based Deep Neural Network\n(DNN) computation. While scalable, such development is error-prone,\nnon-intuitive, and difficult to debug. Consequently, more natural, imperative\nDL frameworks encouraging eager execution have emerged but at the expense of\nrun-time performance. Though hybrid approaches aim for the \"best of both\nworlds,\" using them effectively requires subtle considerations. Our key insight\nis that, while DL programs typically execute sequentially, hybridizing\nimperative DL code resembles parallelizing sequential code in traditional\nsystems. Inspired by this, we present an automated refactoring approach that\nassists developers in determining which otherwise eagerly-executed imperative\nDL functions could be effectively and efficiently executed as graphs. The\napproach features novel static imperative tensor and side-effect analyses for\nPython. Due to its inherent dynamism, analyzing Python may be unsound; however,\nthe conservative approach leverages a speculative (keyword-based) analysis for\nresolving difficult cases that informs developers of any assumptions made. The\napproach is: (i) implemented as a plug-in to the PyDev Eclipse IDE that\nintegrates the WALA Ariadne analysis framework and (ii) evaluated on nineteen\nDL projects consisting of 132 KLOC. The results show that 326 of 766 candidate\nfunctions (42.56%) were refactorable, and an average relative speedup of 2.16\non performance tests was observed with negligible differences in model\naccuracy. The results indicate that the approach is useful in optimizing\nimperative DL code to its full potential.", "AI": {"tldr": "The paper introduces an automated refactoring approach to optimize imperative DL code by converting it into graph-based execution, improving efficiency without sacrificing accuracy.", "motivation": "Imperative DL frameworks are more intuitive but less efficient than symbolic, graph-based ones. Hybrid approaches exist but require careful use. The paper aims to automate this optimization.", "method": "The approach uses static imperative tensor and side-effect analyses for Python, with a speculative keyword-based analysis for difficult cases. It's implemented as a PyDev Eclipse IDE plug-in using WALA Ariadne.", "result": "Evaluated on 19 DL projects (132 KLOC), 42.56% of candidate functions were refactorable, achieving an average speedup of 2.16x with negligible accuracy loss.", "conclusion": "The approach effectively optimizes imperative DL code, balancing usability and performance."}}
{"id": "2504.12216", "pdf": "https://arxiv.org/pdf/2504.12216", "abs": "https://arxiv.org/abs/2504.12216", "authors": ["Siyan Zhao", "Devaansh Gupta", "Qinqing Zheng", "Aditya Grover"], "title": "d1: Scaling Reasoning in Diffusion Large Language Models via Reinforcement Learning", "categories": ["cs.CL", "cs.LG"], "comment": "27 pages, project page at https://dllm-reasoning.github.io/", "summary": "Recent large language models (LLMs) have demonstrated strong reasoning\ncapabilities that benefits from online reinforcement learning (RL). These\ncapabilities have primarily been demonstrated within the left-to-right\nautoregressive (AR) generation paradigm. In contrast, non-autoregressive\nparadigms based on diffusion generate text in a coarse-to-fine manner. Although\nrecent diffusion-based large language models (dLLMs) have achieved competitive\nlanguage modeling performance compared to their AR counterparts, it remains\nunclear if dLLMs can also leverage recent advances in LLM reasoning. To this\nend, we propose d1, a framework to adapt pre-trained masked dLLMs into\nreasoning models via a combination of supervised finetuning (SFT) and RL.\nSpecifically, we develop and extend techniques to improve reasoning in\npretrained dLLMs: (a) we utilize a masked SFT technique to distill knowledge\nand instill self-improvement behavior directly from existing datasets, and (b)\nwe introduce a novel critic-free, policy-gradient based RL algorithm called\ndiffu-GRPO, the first integration of policy gradient methods to masked dLLMs.\nThrough empirical studies, we investigate the performance of different\npost-training recipes on multiple mathematical and planning benchmarks. We find\nthat d1 yields the best performance and significantly improves performance of a\nstate-of-the-art dLLM. Our code is released at\nhttps://dllm-reasoning.github.io/.", "AI": {"tldr": "The paper introduces d1, a framework to enhance reasoning in diffusion-based large language models (dLLMs) using supervised finetuning and reinforcement learning, achieving significant performance improvements.", "motivation": "Despite the success of autoregressive LLMs in reasoning, it's unclear if diffusion-based LLMs (dLLMs) can similarly benefit. The study aims to bridge this gap.", "method": "The d1 framework combines masked supervised finetuning (SFT) and a novel critic-free RL algorithm (diffu-GRPO) to adapt pretrained dLLMs for reasoning tasks.", "result": "Empirical studies show d1 significantly improves reasoning performance in dLLMs on mathematical and planning benchmarks.", "conclusion": "The d1 framework successfully adapts dLLMs for reasoning, demonstrating competitive performance and opening new avenues for diffusion-based models."}}
{"id": "2505.15173", "pdf": "https://arxiv.org/pdf/2505.15173", "abs": "https://arxiv.org/abs/2505.15173", "authors": ["Zhipei Xu", "Xuanyu Zhang", "Xing Zhou", "Jian Zhang"], "title": "AvatarShield: Visual Reinforcement Learning for Human-Centric Video Forgery Detection", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "The rapid advancement of Artificial Intelligence Generated Content (AIGC)\ntechnologies, particularly in video generation, has led to unprecedented\ncreative capabilities but also increased threats to information integrity,\nidentity security, and public trust. Existing detection methods, while\neffective in general scenarios, lack robust solutions for human-centric videos,\nwhich pose greater risks due to their realism and potential for legal and\nethical misuse. Moreover, current detection approaches often suffer from poor\ngeneralization, limited scalability, and reliance on labor-intensive supervised\nfine-tuning. To address these challenges, we propose AvatarShield, the first\ninterpretable MLLM-based framework for detecting human-centric fake videos,\nenhanced via Group Relative Policy Optimization (GRPO). Through our carefully\ndesigned accuracy detection reward and temporal compensation reward, it\neffectively avoids the use of high-cost text annotation data, enabling precise\ntemporal modeling and forgery detection. Meanwhile, we design a dual-encoder\narchitecture, combining high-level semantic reasoning and low-level artifact\namplification to guide MLLMs in effective forgery detection. We further collect\nFakeHumanVid, a large-scale human-centric video benchmark that includes\nsynthesis methods guided by pose, audio, and text inputs, enabling rigorous\nevaluation of detection methods in real-world scenes. Extensive experiments\nshow that AvatarShield significantly outperforms existing approaches in both\nin-domain and cross-domain detection, setting a new standard for human-centric\nvideo forensics.", "AI": {"tldr": "AvatarShield is an interpretable MLLM-based framework for detecting human-centric fake videos, addressing challenges like poor generalization and scalability in existing methods. It uses GRPO and a dual-encoder architecture for precise detection, validated on the FakeHumanVid benchmark.", "motivation": "The rise of AIGC technologies, especially in video generation, threatens information integrity and public trust. Current detection methods lack robustness for human-centric videos, which are riskier due to realism and ethical concerns.", "method": "Proposes AvatarShield, leveraging Group Relative Policy Optimization (GRPO) and a dual-encoder architecture combining high-level semantics and low-level artifacts. Avoids costly text annotations via accuracy and temporal compensation rewards.", "result": "Outperforms existing methods in in-domain and cross-domain detection, validated on the FakeHumanVid benchmark. Sets a new standard for human-centric video forensics.", "conclusion": "AvatarShield offers a scalable, interpretable solution for detecting human-centric fake videos, addressing key limitations of current approaches."}}
{"id": "2410.06895", "pdf": "https://arxiv.org/pdf/2410.06895", "abs": "https://arxiv.org/abs/2410.06895", "authors": ["Chenhao Sun", "Yuhao Mao", "Mark Niklas M\u00fcller", "Martin Vechev"], "title": "Average Certified Radius is a Poor Metric for Randomized Smoothing", "categories": ["cs.LG"], "comment": null, "summary": "Randomized smoothing (RS) is popular for providing certified robustness\nguarantees against adversarial attacks. The average certified radius (ACR) has\nemerged as a widely used metric for tracking progress in RS. However, in this\nwork, for the first time we show that ACR is a poor metric for evaluating\nrobustness guarantees provided by RS. We theoretically prove not only that a\ntrivial classifier can have arbitrarily large ACR, but also that ACR is\nextremely sensitive to improvements on easy samples. In addition, the\ncomparison using ACR has a strong dependence on the certification budget.\nEmpirically, we confirm that existing training strategies, though improving\nACR, reduce the model's robustness on hard samples consistently. To strengthen\nour findings, we propose strategies, including explicitly discarding hard\nsamples, reweighing the dataset with approximate certified radius, and extreme\noptimization for easy samples, to replicate the progress in RS training and\neven achieve the state-of-the-art ACR on CIFAR-10, without training for\nrobustness on the full data distribution. Overall, our results suggest that ACR\nhas introduced a strong undesired bias to the field, and its application should\nbe discontinued in RS. Finally, we suggest using the empirical distribution of\n$p_A$, the accuracy of the base model on noisy data, as an alternative metric\nfor RS.", "AI": {"tldr": "The paper critiques the use of Average Certified Radius (ACR) in Randomized Smoothing (RS), showing it's flawed and suggests alternative metrics.", "motivation": "ACR is widely used but misleading for evaluating RS robustness, as it can be inflated by trivial classifiers and is overly sensitive to easy samples.", "method": "Theoretical proofs and empirical experiments demonstrate ACR's flaws. Strategies like discarding hard samples and reweighing datasets are tested.", "result": "ACR is shown to be a poor metric, and alternative training strategies achieve high ACR without improving true robustness.", "conclusion": "ACR should be discontinued in RS, with the empirical distribution of $p_A$ proposed as a better alternative."}}
{"id": "2504.08335", "pdf": "https://arxiv.org/pdf/2504.08335", "abs": "https://arxiv.org/abs/2504.08335", "authors": ["Lucia Celli", "Giovanni Peccati"], "title": "Entropic bounds for conditionally Gaussian vectors and applications to neural networks", "categories": ["math.PR", "cs.AI", "cs.LG", "stat.ML", "60F05 (Primary) 68T07 (Secondary)", "G.3; I.2"], "comment": null, "summary": "Using entropic inequalities from information theory, we provide new bounds on\nthe total variation and 2-Wasserstein distances between a conditionally\nGaussian law and a Gaussian law with invertible covariance matrix. We apply our\nresults to quantify the speed of convergence to Gaussian of a randomly\ninitialized fully connected neural network and its derivatives - evaluated in a\nfinite number of inputs - when the initialization is Gaussian and the sizes of\nthe inner layers diverge to infinity. Our results require mild assumptions on\nthe activation function, and allow one to recover optimal rates of convergence\nin a variety of distances, thus improving and extending the findings of Basteri\nand Trevisan (2023), Favaro et al. (2023), Trevisan (2024) and Apollonio et al.\n(2024). One of our main tools are the quantitative cumulant estimates\nestablished in Hanin (2024). As an illustration, we apply our results to bound\nthe total variation distance between the Bayesian posterior law of the neural\nnetwork and its derivatives, and the posterior law of the corresponding\nGaussian limit: this yields quantitative versions of a posterior CLT by Hron et\nal. (2022), and extends several estimates by Trevisan (2024) to the total\nvariation metric.", "AI": {"tldr": "New bounds on distances between Gaussian and conditionally Gaussian laws are derived using entropic inequalities, applied to quantify convergence rates of neural networks to Gaussian limits.", "motivation": "To improve and extend existing results on the convergence of neural networks to Gaussian limits under mild assumptions on activation functions.", "method": "Uses entropic inequalities and quantitative cumulant estimates to bound total variation and 2-Wasserstein distances.", "result": "Optimal convergence rates are achieved, improving prior work and extending results to total variation metrics.", "conclusion": "The approach provides robust quantitative bounds, enhancing understanding of neural network behavior and posterior laws."}}
{"id": "2505.02862", "pdf": "https://arxiv.org/pdf/2505.02862", "abs": "https://arxiv.org/abs/2505.02862", "authors": ["Haoming Yang", "Ke Ma", "Xiaojun Jia", "Yingfei Sun", "Qianqian Xu", "Qingming Huang"], "title": "Cannot See the Forest for the Trees: Invoking Heuristics and Biases to Elicit Irrational Choices of LLMs", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Despite the remarkable performance of Large Language Models (LLMs), they\nremain vulnerable to jailbreak attacks, which can compromise their safety\nmechanisms. Existing studies often rely on brute-force optimization or manual\ndesign, failing to uncover potential risks in real-world scenarios. To address\nthis, we propose a novel jailbreak attack framework, ICRT, inspired by\nheuristics and biases in human cognition. Leveraging the simplicity effect, we\nemploy cognitive decomposition to reduce the complexity of malicious prompts.\nSimultaneously, relevance bias is utilized to reorganize prompts, enhancing\nsemantic alignment and inducing harmful outputs effectively. Furthermore, we\nintroduce a ranking-based harmfulness evaluation metric that surpasses the\ntraditional binary success-or-failure paradigm by employing ranking aggregation\nmethods such as Elo, HodgeRank, and Rank Centrality to comprehensively quantify\nthe harmfulness of generated content. Experimental results show that our\napproach consistently bypasses mainstream LLMs' safety mechanisms and generates\nhigh-risk content, providing insights into jailbreak attack risks and\ncontributing to stronger defense strategies.", "AI": {"tldr": "The paper introduces ICRT, a novel jailbreak attack framework for LLMs, leveraging human cognitive biases to bypass safety mechanisms and generate harmful content, with a new ranking-based evaluation metric.", "motivation": "Existing jailbreak attack methods are either brute-force or manually designed, lacking real-world risk insights. The paper aims to address this gap by proposing a more effective framework.", "method": "ICRT uses cognitive decomposition (simplicity effect) and relevance bias to simplify and reorganize malicious prompts, enhancing their effectiveness. A ranking-based metric (Elo, HodgeRank, Rank Centrality) evaluates harmfulness.", "result": "ICRT consistently bypasses LLM safety mechanisms, generating high-risk content, and outperforms traditional binary evaluation methods.", "conclusion": "The framework highlights jailbreak risks and aids in developing stronger defenses, advancing understanding of LLM vulnerabilities."}}
{"id": "2505.16452", "pdf": "https://arxiv.org/pdf/2505.16452", "abs": "https://arxiv.org/abs/2505.16452", "authors": ["Mohamed S. Elmahdy", "Marius Staring", "Patrick J. H. de Koning", "Samer Alabed", "Mahan Salehi", "Faisal Alandejani", "Michael Sharkey", "Ziad Aldabbagh", "Andrew J. Swift", "Rob J. van der Geest"], "title": "CMRINet: Joint Groupwise Registration and Segmentation for Cardiac Function Quantification from Cine-MRI", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": "15 pages, 7 figures, 1 appendix", "summary": "Accurate and efficient quantification of cardiac function is essential for\nthe estimation of prognosis of cardiovascular diseases (CVDs). One of the most\ncommonly used metrics for evaluating cardiac pumping performance is left\nventricular ejection fraction (LVEF). However, LVEF can be affected by factors\nsuch as inter-observer variability and varying pre-load and after-load\nconditions, which can reduce its reproducibility. Additionally, cardiac\ndysfunction may not always manifest as alterations in LVEF, such as in heart\nfailure and cardiotoxicity diseases. An alternative measure that can provide a\nrelatively load-independent quantitative assessment of myocardial contractility\nis myocardial strain and strain rate. By using LVEF in combination with\nmyocardial strain, it is possible to obtain a thorough description of cardiac\nfunction. Automated estimation of LVEF and other volumetric measures from\ncine-MRI sequences can be achieved through segmentation models, while strain\ncalculation requires the estimation of tissue displacement between sequential\nframes, which can be accomplished using registration models. These tasks are\noften performed separately, potentially limiting the assessment of cardiac\nfunction. To address this issue, in this study we propose an end-to-end deep\nlearning (DL) model that jointly estimates groupwise (GW) registration and\nsegmentation for cardiac cine-MRI images. The proposed anatomically-guided Deep\nGW network was trained and validated on a large dataset of 4-chamber view\ncine-MRI image series of 374 subjects. A quantitative comparison with\nconventional GW registration using elastix and two DL-based methods showed that\nthe proposed model improved performance and substantially reduced computation\ntime.", "AI": {"tldr": "The paper proposes an end-to-end deep learning model for joint groupwise registration and segmentation in cardiac cine-MRI to improve cardiac function assessment by combining LVEF and myocardial strain.", "motivation": "LVEF has limitations due to variability and insensitivity in certain cardiac dysfunctions. Combining LVEF with myocardial strain provides a more comprehensive assessment, but existing methods perform these tasks separately, limiting efficiency.", "method": "An end-to-end deep learning model (anatomically-guided Deep GW network) is developed to jointly estimate groupwise registration and segmentation for cardiac cine-MRI images.", "result": "The model outperformed conventional GW registration and other DL-based methods, improving performance and reducing computation time.", "conclusion": "The proposed model enhances cardiac function assessment by integrating registration and segmentation, offering a more efficient and accurate solution."}}
{"id": "2410.08201", "pdf": "https://arxiv.org/pdf/2410.08201", "abs": "https://arxiv.org/abs/2410.08201", "authors": ["Anish Mudide", "Joshua Engels", "Eric J. Michaud", "Max Tegmark", "Christian Schroeder de Witt"], "title": "Efficient Dictionary Learning with Switch Sparse Autoencoders", "categories": ["cs.LG"], "comment": "Code available at https://github.com/amudide/switch_sae", "summary": "Sparse autoencoders (SAEs) are a recent technique for decomposing neural\nnetwork activations into human-interpretable features. However, in order for\nSAEs to identify all features represented in frontier models, it will be\nnecessary to scale them up to very high width, posing a computational\nchallenge. In this work, we introduce Switch Sparse Autoencoders, a novel SAE\narchitecture aimed at reducing the compute cost of training SAEs. Inspired by\nsparse mixture of experts models, Switch SAEs route activation vectors between\nsmaller \"expert\" SAEs, enabling SAEs to efficiently scale to many more\nfeatures. We present experiments comparing Switch SAEs with other SAE\narchitectures, and find that Switch SAEs deliver a substantial Pareto\nimprovement in the reconstruction vs. sparsity frontier for a given fixed\ntraining compute budget. We also study the geometry of features across experts,\nanalyze features duplicated across experts, and verify that Switch SAE features\nare as interpretable as features found by other SAE architectures.", "AI": {"tldr": "Switch Sparse Autoencoders (Switch SAEs) reduce compute costs for training SAEs by routing activations between smaller expert SAEs, improving scalability and performance.", "motivation": "Scaling sparse autoencoders (SAEs) to high width for identifying all features in frontier models is computationally challenging.", "method": "Introduces Switch SAEs, inspired by sparse mixture of experts models, to route activations between smaller expert SAEs.", "result": "Switch SAEs achieve better reconstruction vs. sparsity trade-offs and maintain interpretability compared to other SAE architectures.", "conclusion": "Switch SAEs offer a computationally efficient and scalable solution for feature decomposition in neural networks."}}
{"id": "2504.09941", "pdf": "https://arxiv.org/pdf/2504.09941", "abs": "https://arxiv.org/abs/2504.09941", "authors": ["Junming Liu", "Guosun Zeng", "Ding Wang", "Yanting Gao", "Yufei Jin"], "title": "FedRecon: Missing Modality Reconstruction in Heterogeneous Distributed Environments", "categories": ["cs.LG", "cs.AI"], "comment": "18 pages, 32 figures", "summary": "Multimodal data are often incomplete and exhibit Non-Independent and\nIdentically Distributed (Non-IID) characteristics in real-world scenarios.\nThese inherent limitations lead to both modality heterogeneity through partial\nmodality absence and data heterogeneity from distribution divergence, creating\nfundamental challenges for effective federated learning (FL). To address these\ncoupled challenges, we propose FedRecon, the first method targeting\nsimultaneous missing modality reconstruction and Non-IID adaptation in\nmultimodal FL. Our approach first employs a lightweight Multimodal Variational\nAutoencoder (MVAE) to reconstruct missing modalities while preserving\ncross-modal consistency. Distinct from conventional imputation methods, we\nachieve sample-level alignment through a novel distribution mapping mechanism\nthat guarantees both data consistency and completeness. Additionally, we\nintroduce a strategy employing global generator freezing to prevent\ncatastrophic forgetting, which in turn mitigates Non-IID fluctuations.\nExtensive evaluations on multimodal datasets demonstrate FedRecon's superior\nperformance in modality reconstruction under Non-IID conditions, surpassing\nstate-of-the-art methods.", "AI": {"tldr": "FedRecon addresses missing modalities and Non-IID data in federated learning by using a Multimodal Variational Autoencoder for reconstruction and a distribution mapping mechanism for alignment.", "motivation": "Real-world multimodal data is often incomplete and Non-IID, posing challenges for federated learning.", "method": "Uses a lightweight MVAE for missing modality reconstruction and a distribution mapping mechanism for sample-level alignment. Global generator freezing prevents catastrophic forgetting.", "result": "Outperforms state-of-the-art methods in modality reconstruction under Non-IID conditions.", "conclusion": "FedRecon effectively tackles coupled challenges of missing modalities and Non-IID data in multimodal FL."}}
{"id": "2505.03320", "pdf": "https://arxiv.org/pdf/2505.03320", "abs": "https://arxiv.org/abs/2505.03320", "authors": ["Junyu Ma", "Tianqing Fang", "Zhisong Zhang", "Hongming Zhang", "Haitao Mi", "Dong Yu"], "title": "Recall with Reasoning: Chain-of-Thought Distillation for Mamba's Long-Context Memory and Extrapolation", "categories": ["cs.CL"], "comment": null, "summary": "Mamba's theoretical infinite-context potential is limited in practice when\nsequences far exceed training lengths. This work explores unlocking Mamba's\nlong-context memory ability by a simple-yet-effective method, Recall with\nReasoning (RwR), by distilling chain-of-thought (CoT) summarization from a\nteacher model. Specifically, RwR prepends these summarization as CoT prompts\nduring fine-tuning, teaching Mamba to actively recall and reason over long\ncontexts. Experiments on LONGMEMEVAL and HELMET show RwR boosts Mamba's\nlong-context performance against comparable Transformer/hybrid baselines under\nsimilar pretraining conditions, while preserving short-context capabilities,\nall without architectural changes.", "AI": {"tldr": "Mamba's long-context performance is improved using Recall with Reasoning (RwR), a method that distills CoT summarization from a teacher model, enhancing recall and reasoning without architectural changes.", "motivation": "Mamba's theoretical infinite-context potential is limited in practice for sequences exceeding training lengths.", "method": "RwR prepends CoT summarization prompts during fine-tuning to teach Mamba to recall and reason over long contexts.", "result": "RwR boosts Mamba's performance on long-context benchmarks (LONGMEMEVAL, HELMET) against baselines, preserving short-context capabilities.", "conclusion": "RwR effectively unlocks Mamba's long-context memory ability without modifying its architecture."}}
{"id": "2505.16512", "pdf": "https://arxiv.org/pdf/2505.16512", "abs": "https://arxiv.org/abs/2505.16512", "authors": ["Jiaxin Liu", "Jia Wang", "Saihui Hou", "Min Ren", "Huijia Wu", "Long Ma", "Renwang Pei", "Zhaofeng He"], "title": "Beyond Face Swapping: A Diffusion-Based Digital Human Benchmark for Multimodal Deepfake Detection", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "In recent years, the explosive advancement of deepfake technology has posed a\ncritical and escalating threat to public security: diffusion-based digital\nhuman generation. Unlike traditional face manipulation methods, such models can\ngenerate highly realistic videos with consistency via multimodal control\nsignals. Their flexibility and covertness pose severe challenges to existing\ndetection strategies. To bridge this gap, we introduce DigiFakeAV, the new\nlarge-scale multimodal digital human forgery dataset based on diffusion models.\nLeveraging five of the latest digital human generation methods and a voice\ncloning method, we systematically construct a dataset comprising 60,000 videos\n(8.4 million frames), covering multiple nationalities, skin tones, genders, and\nreal-world scenarios, significantly enhancing data diversity and realism. User\nstudies demonstrate that the misrecognition rate by participants for DigiFakeAV\nreaches as high as 68%. Moreover, the substantial performance degradation of\nexisting detection models on our dataset further highlights its challenges. To\naddress this problem, we propose DigiShield, an effective detection baseline\nbased on spatiotemporal and cross-modal fusion. By jointly modeling the 3D\nspatiotemporal features of videos and the semantic-acoustic features of audio,\nDigiShield achieves state-of-the-art (SOTA) performance on the DigiFakeAV and\nshows strong generalization on other datasets.", "AI": {"tldr": "The paper introduces DigiFakeAV, a large-scale dataset for detecting deepfake videos generated by diffusion models, and proposes DigiShield, a detection method achieving SOTA performance.", "motivation": "The rise of diffusion-based deepfake technology poses severe security threats, challenging existing detection methods due to its realism and flexibility.", "method": "The authors create DigiFakeAV using five digital human generation methods and voice cloning, then propose DigiShield, a detection model using spatiotemporal and cross-modal fusion.", "result": "DigiFakeAV's high misrecognition rate (68%) and existing detectors' poor performance highlight its challenge. DigiShield achieves SOTA results and generalizes well.", "conclusion": "DigiFakeAV and DigiShield address the gap in detecting advanced deepfakes, offering a robust solution for future security threats."}}
{"id": "2410.13569", "pdf": "https://arxiv.org/pdf/2410.13569", "abs": "https://arxiv.org/abs/2410.13569", "authors": ["Eliahu Horwitz", "Bar Cavia", "Jonathan Kahana", "Yedid Hoshen"], "title": "Learning on Model Weights using Tree Experts", "categories": ["cs.LG", "cs.CV"], "comment": "CVPR 2025. Project page: https://horwitz.ai/probex/", "summary": "The number of publicly available models is rapidly increasing, yet most\nremain undocumented. Users looking for suitable models for their tasks must\nfirst determine what each model does. Training machine learning models to infer\nmissing documentation directly from model weights is challenging, as these\nweights often contain significant variation unrelated to model functionality\n(denoted nuisance). Here, we identify a key property of real-world models: most\npublic models belong to a small set of Model Trees, where all models within a\ntree are fine-tuned from a common ancestor (e.g., a foundation model).\nImportantly, we find that within each tree there is less nuisance variation\nbetween models. Concretely, while learning across Model Trees requires complex\narchitectures, even a linear classifier trained on a single model layer often\nworks within trees. While effective, these linear classifiers are\ncomputationally expensive, especially when dealing with larger models that have\nmany parameters. To address this, we introduce Probing Experts (ProbeX), a\ntheoretically motivated and lightweight method. Notably, ProbeX is the first\nprobing method specifically designed to learn from the weights of a single\nhidden model layer. We demonstrate the effectiveness of ProbeX by predicting\nthe categories in a model's training dataset based only on its weights.\nExcitingly, ProbeX can map the weights of Stable Diffusion into a\nweight-language embedding space, enabling model search via text, i.e.,\nzero-shot model classification.", "AI": {"tldr": "The paper introduces ProbeX, a lightweight method to infer model documentation from weights, leveraging Model Trees for reduced nuisance variation.", "motivation": "Public models lack documentation, making it hard for users to find suitable models. Existing methods struggle with nuisance variation in weights.", "method": "ProbeX, a probing method, learns from a single hidden layer of model weights, reducing computational costs.", "result": "ProbeX effectively predicts model categories from weights and enables zero-shot model classification, e.g., mapping Stable Diffusion weights to text.", "conclusion": "ProbeX offers a practical solution for model documentation and search, addressing challenges in real-world model usage."}}
{"id": "2504.16972", "pdf": "https://arxiv.org/pdf/2504.16972", "abs": "https://arxiv.org/abs/2504.16972", "authors": ["Hossein Ahmadi", "Sajjad Emdadi Mahdimahalleh", "Arman Farahat", "Banafsheh Saffari"], "title": "Unsupervised Time-Series Signal Analysis with Autoencoders and Vision Transformers: A Review of Architectures and Applications", "categories": ["cs.LG", "cs.AI", "cs.CV", "eess.SP", "I.5.4; I.2.6; H.2.8"], "comment": null, "summary": "The rapid growth of unlabeled time-series data in domains such as wireless\ncommunications, radar, biomedical engineering, and the Internet of Things (IoT)\nhas driven advancements in unsupervised learning. This review synthesizes\nrecent progress in applying autoencoders and vision transformers for\nunsupervised signal analysis, focusing on their architectures, applications,\nand emerging trends. We explore how these models enable feature extraction,\nanomaly detection, and classification across diverse signal types, including\nelectrocardiograms, radar waveforms, and IoT sensor data. The review highlights\nthe strengths of hybrid architectures and self-supervised learning, while\nidentifying challenges in interpretability, scalability, and domain\ngeneralization. By bridging methodological innovations and practical\napplications, this work offers a roadmap for developing robust, adaptive models\nfor signal intelligence.", "AI": {"tldr": "A review of autoencoders and vision transformers for unsupervised signal analysis, covering architectures, applications, and trends in domains like IoT and biomedical engineering.", "motivation": "The rapid growth of unlabeled time-series data in fields like IoT and biomedical engineering necessitates advancements in unsupervised learning for signal analysis.", "method": "Focuses on autoencoders and vision transformers, exploring their architectures and applications in feature extraction, anomaly detection, and classification.", "result": "Highlights hybrid architectures and self-supervised learning as strengths, while noting challenges in interpretability, scalability, and domain generalization.", "conclusion": "Provides a roadmap for developing robust, adaptive models for signal intelligence by bridging methodological innovations and practical applications."}}
{"id": "2505.06150", "pdf": "https://arxiv.org/pdf/2505.06150", "abs": "https://arxiv.org/abs/2505.06150", "authors": ["Ryan Lagasse", "Aidan Kierans", "Avijit Ghosh", "Shiri Dori-Hacohen"], "title": "A Scaling Law for Token Efficiency in LLM Fine-Tuning Under Fixed Compute Budgets", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "We introduce a scaling law for fine-tuning large language models (LLMs) under\nfixed compute budgets that explicitly accounts for data composition.\nConventional approaches measure training data solely by total tokens, yet the\nnumber of examples and their average token length -- what we term \\emph{dataset\nvolume} -- play a decisive role in model performance. Our formulation is tuned\nfollowing established procedures. Experiments on the BRICC dataset\n\\cite{salavati2024reducing} and subsets of the MMLU dataset\n\\cite{hendrycks2021measuringmassivemultitasklanguage}, evaluated under multiple\nsubsampling strategies, reveal that data composition significantly affects\ntoken efficiency. These results motivate refined scaling laws for practical LLM\nfine-tuning in resource-constrained settings.", "AI": {"tldr": "A scaling law for fine-tuning LLMs under fixed compute budgets, emphasizing data composition (dataset volume) over just token count, improves token efficiency.", "motivation": "Conventional scaling laws overlook data composition (number of examples and average token length), which significantly impacts model performance.", "method": "Proposes a scaling law accounting for dataset volume, validated on BRICC and MMLU datasets with subsampling strategies.", "result": "Data composition affects token efficiency, motivating refined scaling laws for resource-constrained LLM fine-tuning.", "conclusion": "Refined scaling laws considering data composition are crucial for efficient LLM fine-tuning under compute constraints."}}
{"id": "2505.18924", "pdf": "https://arxiv.org/pdf/2505.18924", "abs": "https://arxiv.org/abs/2505.18924", "authors": ["Chenxi Li", "Nuo Chen", "Fengyun Tan", "Yantong Chen", "Bochun Yuan", "Tianrui Li", "Chongshou Li"], "title": "LLM-Guided Taxonomy and Hierarchical Uncertainty for 3D Point Cloud Active Learning", "categories": ["cs.CV"], "comment": null, "summary": "We present a novel active learning framework for 3D point cloud semantic\nsegmentation that, for the first time, integrates large language models (LLMs)\nto construct hierarchical label structures and guide uncertainty-based sample\nselection. Unlike prior methods that treat labels as flat and independent, our\napproach leverages LLM prompting to automatically generate multi-level semantic\ntaxonomies and introduces a recursive uncertainty projection mechanism that\npropagates uncertainty across hierarchy levels. This enables spatially diverse,\nlabel-aware point selection that respects the inherent semantic structure of 3D\nscenes. Experiments on S3DIS and ScanNet v2 show that our method achieves up to\n4% mIoU improvement under extremely low annotation budgets (e.g., 0.02%),\nsubstantially outperforming existing baselines. Our results highlight the\nuntapped potential of LLMs as knowledge priors in 3D vision and establish\nhierarchical uncertainty modeling as a powerful paradigm for efficient point\ncloud annotation.", "AI": {"tldr": "A novel active learning framework for 3D point cloud semantic segmentation integrates LLMs to create hierarchical label structures and guide uncertainty-based sample selection, improving performance under low annotation budgets.", "motivation": "Prior methods treat labels as flat and independent, ignoring semantic structure. This work leverages LLMs to capture hierarchical relationships and improve sample selection.", "method": "Uses LLM prompting to generate multi-level semantic taxonomies and introduces a recursive uncertainty projection mechanism for uncertainty propagation across hierarchy levels.", "result": "Achieves up to 4% mIoU improvement under very low annotation budgets (e.g., 0.02%), outperforming existing baselines on S3DIS and ScanNet v2.", "conclusion": "Demonstrates the potential of LLMs as knowledge priors in 3D vision and establishes hierarchical uncertainty modeling for efficient point cloud annotation."}}
{"id": "2410.13696", "pdf": "https://arxiv.org/pdf/2410.13696", "abs": "https://arxiv.org/abs/2410.13696", "authors": ["Wei Huang", "Richard Combes", "Andrea Araldo", "Hind Castel-Taleb", "Badii Jouaber"], "title": "Online Learning for Function Placement in Serverless Computing", "categories": ["cs.LG", "cs.NI"], "comment": "NetSoft 2025", "summary": "We study the placement of virtual functions aimed at minimizing the cost. We\npropose a novel algorithm, using ideas based on multi-armed bandits. We prove\nthat these algorithms learn the optimal placement policy rapidly, and their\nregret grows at a rate at most $O( N M \\sqrt{T\\ln T} )$ while respecting the\nfeasibility constraints with high probability, where $T$ is total time slots,\n$M$ is the number of classes of function and $N$ is the number of computation\nnodes. We show through numerical experiments that the proposed algorithm both\nhas good practical performance and modest computational complexity. We propose\nan acceleration technique that allows the algorithm to achieve good performance\nalso in large networks where computational power is limited. Our experiments\nare fully reproducible, and the code is publicly available.", "AI": {"tldr": "A novel algorithm for virtual function placement minimizes cost using multi-armed bandits, achieving rapid learning and low regret while respecting constraints.", "motivation": "To efficiently place virtual functions with minimal cost, addressing feasibility constraints and scalability in large networks.", "method": "Proposes a multi-armed bandit-based algorithm with an acceleration technique for large networks.", "result": "The algorithm learns optimal placement quickly, with regret bounded by O(NM\u221a(TlnT)), and performs well in experiments.", "conclusion": "The algorithm is practical, scalable, and computationally efficient, with reproducible results and publicly available code."}}
{"id": "2505.02198", "pdf": "https://arxiv.org/pdf/2505.02198", "abs": "https://arxiv.org/abs/2505.02198", "authors": ["Griffin Pitts", "Viktoria Marcus", "Sanaz Motamedi"], "title": "Student Perspectives on the Benefits and Risks of AI in Education", "categories": ["cs.CY", "cs.AI", "cs.ET", "K.3; K.4"], "comment": null, "summary": "The use of chatbots equipped with artificial intelligence (AI) in educational\nsettings has increased in recent years, showing potential to support teaching\nand learning. However, the adoption of these technologies has raised concerns\nabout their impact on academic integrity, students' ability to problem-solve\nindependently, and potential underlying biases. To better understand students'\nperspectives and experiences with these tools, a survey was conducted at a\nlarge public university in the United States. Through thematic analysis, 262\nundergraduate students' responses regarding their perceived benefits and risks\nof AI chatbots in education were identified and categorized into themes.\n  The results discuss several benefits identified by the students, with\nfeedback and study support, instruction capabilities, and access to information\nbeing the most cited. Their primary concerns included risks to academic\nintegrity, accuracy of information, loss of critical thinking skills, the\npotential development of overreliance, and ethical considerations such as data\nprivacy, system bias, environmental impact, and preservation of human elements\nin education.\n  While student perceptions align with previously discussed benefits and risks\nof AI in education, they show heightened concerns about distinguishing between\nhuman and AI generated work - particularly in cases where authentic work is\nflagged as AI-generated. To address students' concerns, institutions can\nestablish clear policies regarding AI use and develop curriculum around AI\nliteracy. With these in place, practitioners can effectively develop and\nimplement educational systems that leverage AI's potential in areas such as\nimmediate feedback and personalized learning support. This approach can enhance\nthe quality of students' educational experiences while preserving the integrity\nof the learning process with AI.", "AI": {"tldr": "Students recognize AI chatbots' benefits (feedback, study support, instruction) but express concerns about academic integrity, accuracy, and ethical issues. Clear policies and AI literacy programs are recommended.", "motivation": "To understand students' perspectives on AI chatbots in education, addressing benefits and risks.", "method": "Survey of 262 undergraduates at a U.S. university, analyzed thematically.", "result": "Students highlighted benefits (feedback, instruction) and risks (integrity, bias, overreliance). Concerns included distinguishing human vs. AI work.", "conclusion": "Institutions should implement AI policies and literacy programs to leverage benefits while mitigating risks."}}
{"id": "2505.09825", "pdf": "https://arxiv.org/pdf/2505.09825", "abs": "https://arxiv.org/abs/2505.09825", "authors": ["Peiqi Sui", "Juan Diego Rodriguez", "Philippe Laban", "Dean Murphy", "Joseph P. Dexter", "Richard Jean So", "Samuel Baker", "Pramit Chaudhuri"], "title": "KRISTEVA: Close Reading as a Novel Task for Benchmarking Interpretive Reasoning", "categories": ["cs.CL"], "comment": "ACL 2025 main", "summary": "Each year, tens of millions of essays are written and graded in college-level\nEnglish courses. Students are asked to analyze literary and cultural texts\nthrough a process known as close reading, in which they gather textual details\nto formulate evidence-based arguments. Despite being viewed as a basis for\ncritical thinking and widely adopted as a required element of university\ncoursework, close reading has never been evaluated on large language models\n(LLMs), and multi-discipline benchmarks like MMLU do not include literature as\na subject. To fill this gap, we present KRISTEVA, the first close reading\nbenchmark for evaluating interpretive reasoning, consisting of 1331\nmultiple-choice questions adapted from classroom data. With KRISTEVA, we\npropose three progressively more difficult sets of tasks to approximate\ndifferent elements of the close reading process, which we use to test how well\nLLMs may seem to understand and reason about literary works: 1) extracting\nstylistic features, 2) retrieving relevant contextual information from\nparametric knowledge, and 3) multi-hop reasoning between style and external\ncontexts. Our baseline results find that, while state-of-the-art LLMs possess\nsome college-level close reading competency (accuracy 49.7% - 69.7%), their\nperformances still trail those of experienced human evaluators on 10 out of our\n11 tasks.", "AI": {"tldr": "KRISTEVA is the first benchmark for evaluating LLMs on close reading tasks, showing they lag behind humans in interpretive reasoning.", "motivation": "Close reading is foundational in education but untested on LLMs. KRISTEVA fills this gap by assessing LLMs' ability to analyze literature.", "method": "KRISTEVA includes 1331 multiple-choice questions across three tasks: feature extraction, contextual retrieval, and multi-hop reasoning.", "result": "LLMs show some competency (49.7%-69.7% accuracy) but underperform humans in 10 of 11 tasks.", "conclusion": "LLMs have potential in close reading but need improvement to match human evaluators."}}
{"id": "2505.19028", "pdf": "https://arxiv.org/pdf/2505.19028", "abs": "https://arxiv.org/abs/2505.19028", "authors": ["Minzhi Lin", "Tianchi Xie", "Mengchen Liu", "Yilin Ye", "Changjian Chen", "Shixia Liu"], "title": "InfoChartQA: A Benchmark for Multimodal Question Answering on Infographic Charts", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Understanding infographic charts with design-driven visual elements (e.g.,\npictograms, icons) requires both visual recognition and reasoning, posing\nchallenges for multimodal large language models (MLLMs). However, existing\nvisual-question answering benchmarks fall short in evaluating these\ncapabilities of MLLMs due to the lack of paired plain charts and\nvisual-element-based questions. To bridge this gap, we introduce InfoChartQA, a\nbenchmark for evaluating MLLMs on infographic chart understanding. It includes\n5,642 pairs of infographic and plain charts, each sharing the same underlying\ndata but differing in visual presentations. We further design\nvisual-element-based questions to capture their unique visual designs and\ncommunicative intent. Evaluation of 20 MLLMs reveals a substantial performance\ndecline on infographic charts, particularly for visual-element-based questions\nrelated to metaphors. The paired infographic and plain charts enable\nfine-grained error analysis and ablation studies, which highlight new\nopportunities for advancing MLLMs in infographic chart understanding. We\nrelease InfoChartQA at https://github.com/CoolDawnAnt/InfoChartQA.", "AI": {"tldr": "InfoChartQA is a benchmark for evaluating MLLMs on infographic chart understanding, featuring paired infographic and plain charts with visual-element-based questions.", "motivation": "Existing benchmarks lack paired plain charts and visual-element-based questions, limiting evaluation of MLLMs' infographic chart understanding.", "method": "Introduces InfoChartQA with 5,642 chart pairs and visual-element-based questions to assess MLLMs.", "result": "Evaluation shows MLLMs perform poorly on infographic charts, especially for visual-element-based questions.", "conclusion": "InfoChartQA enables fine-grained analysis and highlights opportunities for improving MLLMs in infographic understanding."}}
{"id": "2410.13995", "pdf": "https://arxiv.org/pdf/2410.13995", "abs": "https://arxiv.org/abs/2410.13995", "authors": ["Ethan Rathbun", "Alina Oprea", "Christopher Amato"], "title": "Adversarial Inception Backdoor Attacks against Reinforcement Learning", "categories": ["cs.LG", "cs.CR"], "comment": "9 pages, 6 figures, ICML 2025", "summary": "Recent works have demonstrated the vulnerability of Deep Reinforcement\nLearning (DRL) algorithms against training-time, backdoor poisoning attacks.\nThe objectives of these attacks are twofold: induce pre-determined, adversarial\nbehavior in the agent upon observing a fixed trigger during deployment while\nallowing the agent to solve its intended task during training. Prior attacks\nassume arbitrary control over the agent's rewards, inducing values far outside\nthe environment's natural constraints. This results in brittle attacks that\nfail once the proper reward constraints are enforced. Thus, in this work we\npropose a new class of backdoor attacks against DRL which are the first to\nachieve state of the art performance under strict reward constraints. These\n\"inception\" attacks manipulate the agent's training data -- inserting the\ntrigger into prior observations and replacing high return actions with those of\nthe targeted adversarial behavior. We formally define these attacks and prove\nthey achieve both adversarial objectives against arbitrary Markov Decision\nProcesses (MDP). Using this framework we devise an online inception attack\nwhich achieves an 100\\% attack success rate on multiple environments under\nconstrained rewards while minimally impacting the agent's task performance.", "AI": {"tldr": "A new class of backdoor attacks, 'inception' attacks, is proposed for DRL, achieving high success under strict reward constraints by manipulating training data.", "motivation": "Existing backdoor attacks on DRL are brittle under reward constraints, motivating the need for more robust attacks.", "method": "The 'inception' attack manipulates training data by inserting triggers and replacing actions to induce adversarial behavior while maintaining task performance.", "result": "The attack achieves 100% success rate under constrained rewards with minimal impact on task performance.", "conclusion": "The proposed inception attacks are robust and effective against DRL under strict reward constraints."}}
{"id": "2505.03792", "pdf": "https://arxiv.org/pdf/2505.03792", "abs": "https://arxiv.org/abs/2505.03792", "authors": ["Lang Feng", "Weihao Tan", "Zhiyi Lyu", "Longtao Zheng", "Haiyang Xu", "Ming Yan", "Fei Huang", "Bo An"], "title": "Towards Efficient Online Tuning of VLM Agents via Counterfactual Soft Reinforcement Learning", "categories": ["cs.LG", "cs.AI"], "comment": "ICML 2025", "summary": "Online fine-tuning vision-language model (VLM) agents with reinforcement\nlearning (RL) has shown promise for equipping agents with multi-step,\ngoal-oriented capabilities in dynamic environments. However, their open-ended\ntextual action space and non-end-to-end nature of action generation present\nsignificant challenges to effective online exploration in RL, e.g., explosion\nof the exploration space. We propose a novel online fine-tuning method,\nCounterfactual Soft Reinforcement Learning (CoSo), better suited to the textual\noutput space of VLM agents. Compared to prior methods that assign uniform\nuncertainty to all tokens, CoSo leverages counterfactual reasoning to\ndynamically assess the causal influence of individual tokens on post-processed\nactions. By prioritizing the exploration of action-critical tokens while\nreducing the impact of semantically redundant or low-impact tokens, CoSo\nenables a more targeted and efficient online rollout process. We provide\ntheoretical analysis proving CoSo's convergence and policy improvement\nguarantees, and extensive empirical evaluations supporting CoSo's\neffectiveness. Our results across a diverse set of agent tasks, including\nAndroid device control, card gaming, and embodied AI, highlight its remarkable\nability to enhance exploration efficiency and deliver consistent performance\ngains. The code is available at https://github.com/langfengQ/CoSo.", "AI": {"tldr": "CoSo, a novel RL method for fine-tuning VLM agents, improves exploration efficiency by dynamically assessing token influence using counterfactual reasoning.", "motivation": "Address challenges in online RL for VLM agents, such as open-ended action spaces and non-end-to-end action generation, which hinder effective exploration.", "method": "Proposes CoSo, which uses counterfactual reasoning to prioritize exploration of action-critical tokens while reducing focus on redundant or low-impact tokens.", "result": "Theoretical and empirical results show CoSo enhances exploration efficiency and performance across diverse tasks like Android control, card gaming, and embodied AI.", "conclusion": "CoSo is effective for fine-tuning VLM agents, offering targeted exploration and consistent performance improvements."}}
{"id": "2505.13508", "pdf": "https://arxiv.org/pdf/2505.13508", "abs": "https://arxiv.org/abs/2505.13508", "authors": ["Zijia Liu", "Peixuan Han", "Haofei Yu", "Haoru Li", "Jiaxuan You"], "title": "Time-R1: Towards Comprehensive Temporal Reasoning in LLMs", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "Large Language Models (LLMs) demonstrate impressive capabilities but lack\nrobust temporal intelligence, struggling to integrate reasoning about the past\nwith predictions and plausible generations of the future. Meanwhile, existing\nmethods typically target isolated temporal skills, such as question answering\nabout past events or basic forecasting, and exhibit poor generalization,\nparticularly when dealing with events beyond their knowledge cutoff or\nrequiring creative foresight. To address these limitations, we introduce\n\\textit{Time-R1}, the first framework to endow a moderate-sized (3B-parameter)\nLLM with comprehensive temporal abilities: understanding, prediction, and\ncreative generation. Our approach features a novel three-stage development\npath; the first two constitute a \\textit{reinforcement learning (RL)\ncurriculum} driven by a meticulously designed dynamic rule-based reward system.\nThis framework progressively builds (1) foundational temporal understanding and\nlogical event-time mappings from historical data, (2) future event prediction\nskills for events beyond its knowledge cutoff, and finally (3) enables\nremarkable generalization to creative future scenario generation without any\nfine-tuning. Strikingly, experiments demonstrate that Time-R1 outperforms\nmodels over 200 times larger, including the state-of-the-art 671B DeepSeek-R1,\non highly challenging future event prediction and creative scenario generation\nbenchmarks. This work provides strong evidence that thoughtfully engineered,\nprogressive RL fine-tuning allows smaller, efficient models to achieve superior\ntemporal performance, offering a practical and scalable path towards truly\ntime-aware AI. To foster further research, we also release \\textit{Time-Bench},\na large-scale multi-task temporal reasoning dataset derived from 10 years of\nnews data, and our series of \\textit{Time-R1} checkpoints.", "AI": {"tldr": "Time-R1 is a framework enhancing a 3B-parameter LLM with temporal abilities (understanding, prediction, creative generation) via a three-stage RL curriculum, outperforming larger models.", "motivation": "LLMs lack robust temporal intelligence and struggle with integrating past reasoning and future predictions. Existing methods target isolated skills and generalize poorly.", "method": "A three-stage RL curriculum with a dynamic rule-based reward system: (1) foundational temporal understanding, (2) future event prediction, (3) creative scenario generation.", "result": "Time-R1 outperforms models 200x larger (e.g., 671B DeepSeek-R1) on future event prediction and creative generation benchmarks.", "conclusion": "Progressive RL fine-tuning enables smaller models to achieve superior temporal performance, offering a scalable path for time-aware AI. Time-Bench dataset and checkpoints are released for research."}}
{"id": "2505.19746", "pdf": "https://arxiv.org/pdf/2505.19746", "abs": "https://arxiv.org/abs/2505.19746", "authors": ["Jakov Samard\u017eija", "Donik Vr\u0161nak", "Sven Lon\u010dari\u0107"], "title": "Improving Heart Rejection Detection in XPCI Images Using Synthetic Data Augmentation", "categories": ["cs.CV"], "comment": "For the time being, the paper needs to be withdrawn so that a more\n  extensive evaluation of the results can be conducted to validate the\n  approach. Furthermore, additional authors will need to be added, which will\n  be addressed if the study's results prove satisfactory", "summary": "Accurate identification of acute cellular rejection (ACR) in endomyocardial\nbiopsies is essential for effective management of heart transplant patients.\nHowever, the rarity of high-grade rejection cases (3R) presents a significant\nchallenge for training robust deep learning models. This work addresses the\nclass imbalance problem by leveraging synthetic data generation using StyleGAN\nto augment the limited number of real 3R images. Prior to GAN training,\nhistogram equalization was applied to standardize image appearance and improve\nthe consistency of tissue representation. StyleGAN was trained on available 3R\nbiopsy patches and subsequently used to generate 10,000 realistic synthetic\nimages. These were combined with real 0R samples, that is samples without\nrejection, in various configurations to train ResNet-18 classifiers for binary\nrejection classification.\n  Three classifier variants were evaluated: one trained on real 0R and\nsynthetic 3R images, another using both synthetic and additional real samples,\nand a third trained solely on real data. All models were tested on an\nindependent set of real biopsy images. Results demonstrate that synthetic data\nimproves classification performance, particularly when used in combination with\nreal samples. The highest-performing model, which used both real and synthetic\nimages, achieved strong precision and recall for both classes. These findings\nunderscore the value of hybrid training strategies and highlight the potential\nof GAN-based data augmentation in biomedical image analysis, especially in\ndomains constrained by limited annotated datasets.", "AI": {"tldr": "The paper proposes using StyleGAN to generate synthetic 3R biopsy images to address class imbalance in training deep learning models for acute cellular rejection (ACR) classification. Combining synthetic and real data improves model performance.", "motivation": "The rarity of high-grade rejection (3R) cases makes training robust deep learning models challenging due to class imbalance.", "method": "Histogram equalization was applied for image standardization, followed by StyleGAN training on 3R patches to generate synthetic images. ResNet-18 classifiers were trained using real and synthetic data in various configurations.", "result": "Models using synthetic data, especially combined with real samples, outperformed those trained solely on real data, achieving strong precision and recall.", "conclusion": "Hybrid training with synthetic and real data is effective, demonstrating the potential of GAN-based augmentation in biomedical image analysis with limited datasets."}}
{"id": "2410.21088", "pdf": "https://arxiv.org/pdf/2410.21088", "abs": "https://arxiv.org/abs/2410.21088", "authors": ["Wenda Li", "Huijie Zhang", "Qing Qu"], "title": "Shallow Diffuse: Robust and Invisible Watermarking through Low-Dimensional Subspaces in Diffusion Models", "categories": ["cs.LG", "cs.CR", "cs.CV"], "comment": null, "summary": "The widespread use of AI-generated content from diffusion models has raised\nsignificant concerns regarding misinformation and copyright infringement.\nWatermarking is a crucial technique for identifying these AI-generated images\nand preventing their misuse. In this paper, we introduce Shallow Diffuse, a new\nwatermarking technique that embeds robust and invisible watermarks into\ndiffusion model outputs. Unlike existing approaches that integrate watermarking\nthroughout the entire diffusion sampling process, Shallow Diffuse decouples\nthese steps by leveraging the presence of a low-dimensional subspace in the\nimage generation process. This method ensures that a substantial portion of the\nwatermark lies in the null space of this subspace, effectively separating it\nfrom the image generation process. Our theoretical and empirical analyses show\nthat this decoupling strategy greatly enhances the consistency of data\ngeneration and the detectability of the watermark. Extensive experiments\nfurther validate that our Shallow Diffuse outperforms existing watermarking\nmethods in terms of robustness and consistency. The codes will be released at\nhttps://github.com/liwd190019/Shallow-Diffuse.", "AI": {"tldr": "Shallow Diffuse is a new watermarking technique for AI-generated images that decouples watermarking from the diffusion process, improving robustness and detectability.", "motivation": "Address concerns of misinformation and copyright infringement from AI-generated content by developing a reliable watermarking method.", "method": "Leverages a low-dimensional subspace in image generation to embed watermarks in the null space, decoupling it from the diffusion process.", "result": "Enhances watermark consistency and detectability, outperforming existing methods in robustness.", "conclusion": "Shallow Diffuse provides an effective solution for watermarking AI-generated images, with potential for widespread adoption."}}
{"id": "2505.04977", "pdf": "https://arxiv.org/pdf/2505.04977", "abs": "https://arxiv.org/abs/2505.04977", "authors": ["Brian Choi", "Shu Wang", "Isabelle Choi", "Kun Sun"], "title": "ChainMarks: Securing DNN Watermark with Cryptographic Chain", "categories": ["cs.CR", "cs.AI"], "comment": "Accepted In ACM ASIA Conference on Computer and Communications\n  Security (ASIA CCS '25), August 25-29, 2025, Ha Noi, Vietnam", "summary": "With the widespread deployment of deep neural network (DNN) models, dynamic\nwatermarking techniques are being used to protect the intellectual property of\nmodel owners. However, recent studies have shown that existing watermarking\nschemes are vulnerable to watermark removal and ambiguity attacks. Besides, the\nvague criteria for determining watermark presence further increase the\nlikelihood of such attacks. In this paper, we propose a secure DNN watermarking\nscheme named ChainMarks, which generates secure and robust watermarks by\nintroducing a cryptographic chain into the trigger inputs and utilizes a\ntwo-phase Monte Carlo method for determining watermark presence. First,\nChainMarks generates trigger inputs as a watermark dataset by repeatedly\napplying a hash function over a secret key, where the target labels associated\nwith trigger inputs are generated from the digital signature of model owner.\nThen, the watermarked model is produced by training a DNN over both the\noriginal and watermark datasets. To verify watermarks, we compare the predicted\nlabels of trigger inputs with the target labels and determine ownership with a\nmore accurate decision threshold that considers the classification probability\nof specific models. Experimental results show that ChainMarks exhibits higher\nlevels of robustness and security compared to state-of-the-art watermarking\nschemes. With a better marginal utility, ChainMarks provides a higher\nprobability guarantee of watermark presence in DNN models with the same level\nof watermark accuracy.", "AI": {"tldr": "ChainMarks is a secure DNN watermarking scheme using cryptographic chains and a two-phase Monte Carlo method for robust watermarking and verification.", "motivation": "Existing DNN watermarking schemes are vulnerable to attacks, and vague criteria for watermark presence increase risks.", "method": "ChainMarks generates watermarks via cryptographic chains in trigger inputs and uses a two-phase Monte Carlo method for verification.", "result": "ChainMarks shows higher robustness and security than state-of-the-art schemes, with better marginal utility.", "conclusion": "ChainMarks provides a more secure and reliable watermarking solution for DNN models."}}
{"id": "2505.15299", "pdf": "https://arxiv.org/pdf/2505.15299", "abs": "https://arxiv.org/abs/2505.15299", "authors": ["Maodong Li", "Longyin Zhang", "Fang Kong"], "title": "Multi-Hop Question Generation via Dual-Perspective Keyword Guidance", "categories": ["cs.CL"], "comment": "17 pages, 5 figures, accepted to the Findings of ACL 2025", "summary": "Multi-hop question generation (MQG) aims to generate questions that require\nsynthesizing multiple information snippets from documents to derive target\nanswers. The primary challenge lies in effectively pinpointing crucial\ninformation snippets related to question-answer (QA) pairs, typically relying\non keywords. However, existing works fail to fully utilize the guiding\npotential of keywords and neglect to differentiate the distinct roles of\nquestion-specific and document-specific keywords. To address this, we define\ndual-perspective keywords (i.e., question and document keywords) and propose a\nDual-Perspective Keyword-Guided (DPKG) framework, which seamlessly integrates\nkeywords into the multi-hop question generation process. We argue that question\nkeywords capture the questioner's intent, whereas document keywords reflect the\ncontent related to the QA pair. Functionally, question and document keywords\nwork together to pinpoint essential information snippets in the document, with\nquestion keywords required to appear in the generated question. The DPKG\nframework consists of an expanded transformer encoder and two answer-aware\ntransformer decoders for keyword and question generation, respectively.\nExtensive experiments demonstrate the effectiveness of our work, showcasing its\npromising performance and underscoring its significant value in the MQG task.", "AI": {"tldr": "The paper introduces a Dual-Perspective Keyword-Guided (DPKG) framework for multi-hop question generation, distinguishing between question and document keywords to improve accuracy.", "motivation": "Existing methods fail to fully leverage keyword guidance and overlook the distinct roles of question-specific and document-specific keywords in multi-hop question generation.", "method": "The DPKG framework uses an expanded transformer encoder and two answer-aware decoders for keyword and question generation, integrating dual-perspective keywords (question and document keywords).", "result": "Experiments show the framework's effectiveness, demonstrating superior performance in multi-hop question generation.", "conclusion": "The DPKG framework successfully addresses the challenge of pinpointing essential information snippets, proving valuable for multi-hop question generation tasks."}}
{"id": "2505.19901", "pdf": "https://arxiv.org/pdf/2505.19901", "abs": "https://arxiv.org/abs/2505.19901", "authors": ["Peng Liu", "Xiaoming Ren", "Fengkai Liu", "Qingsong Xie", "Quanlong Zheng", "Yanhao Zhang", "Haonan Lu", "Yujiu Yang"], "title": "Dynamic-I2V: Exploring Image-to-Video Generation Models via Multimodal LLM", "categories": ["cs.CV"], "comment": null, "summary": "Recent advancements in image-to-video (I2V) generation have shown promising\nperformance in conventional scenarios. However, these methods still encounter\nsignificant challenges when dealing with complex scenes that require a deep\nunderstanding of nuanced motion and intricate object-action relationships. To\naddress these challenges, we present Dynamic-I2V, an innovative framework that\nintegrates Multimodal Large Language Models (MLLMs) to jointly encode visual\nand textual conditions for a diffusion transformer (DiT) architecture. By\nleveraging the advanced multimodal understanding capabilities of MLLMs, our\nmodel significantly improves motion controllability and temporal coherence in\nsynthesized videos. The inherent multimodality of Dynamic-I2V further enables\nflexible support for diverse conditional inputs, extending its applicability to\nvarious downstream generation tasks. Through systematic analysis, we identify a\ncritical limitation in current I2V benchmarks: a significant bias towards\nfavoring low-dynamic videos, stemming from an inadequate balance between motion\ncomplexity and visual quality metrics. To resolve this evaluation gap, we\npropose DIVE - a novel assessment benchmark specifically designed for\ncomprehensive dynamic quality measurement in I2V generation. In conclusion,\nextensive quantitative and qualitative experiments confirm that Dynamic-I2V\nattains state-of-the-art performance in image-to-video generation, particularly\nrevealing significant improvements of 42.5%, 7.9%, and 11.8% in dynamic range,\ncontrollability, and quality, respectively, as assessed by the DIVE metric in\ncomparison to existing methods.", "AI": {"tldr": "Dynamic-I2V integrates MLLMs with DiT for improved motion controllability and temporal coherence in image-to-video generation, outperforming existing methods by significant margins.", "motivation": "Addressing challenges in complex scenes requiring nuanced motion and object-action understanding in I2V generation.", "method": "Combines Multimodal Large Language Models (MLLMs) with a diffusion transformer (DiT) for joint encoding of visual and textual conditions.", "result": "Achieves state-of-the-art performance with improvements of 42.5%, 7.9%, and 11.8% in dynamic range, controllability, and quality.", "conclusion": "Dynamic-I2V excels in I2V generation, validated by the proposed DIVE benchmark for dynamic quality assessment."}}
{"id": "2411.03730", "pdf": "https://arxiv.org/pdf/2411.03730", "abs": "https://arxiv.org/abs/2411.03730", "authors": ["Marlon Tobaben", "Mohamed Ali Souibgui", "Rub\u00e8n Tito", "Khanh Nguyen", "Raouf Kerkouche", "Kangsoo Jung", "Joonas J\u00e4lk\u00f6", "Lei Kang", "Andrey Barsky", "Vincent Poulain d'Andecy", "Aur\u00e9lie Joseph", "Aashiq Muhamed", "Kevin Kuo", "Virginia Smith", "Yusuke Yamasaki", "Takumi Fukami", "Kenta Niwa", "Iifan Tyou", "Hiro Ishii", "Rio Yokota", "Ragul N", "Rintu Kutum", "Josep Llados", "Ernest Valveny", "Antti Honkela", "Mario Fritz", "Dimosthenis Karatzas"], "title": "NeurIPS 2023 Competition: Privacy Preserving Federated Learning Document VQA", "categories": ["cs.LG", "cs.CR", "cs.CV"], "comment": "33 pages, 7 figures; published in TMLR 06/2025\n  https://openreview.net/forum?id=3HKNwejEEq", "summary": "The Privacy Preserving Federated Learning Document VQA (PFL-DocVQA)\ncompetition challenged the community to develop provably private and\ncommunication-efficient solutions in a federated setting for a real-life use\ncase: invoice processing. The competition introduced a dataset of real invoice\ndocuments, along with associated questions and answers requiring information\nextraction and reasoning over the document images. Thereby, it brings together\nresearchers and expertise from the document analysis, privacy, and federated\nlearning communities. Participants fine-tuned a pre-trained, state-of-the-art\nDocument Visual Question Answering model provided by the organizers for this\nnew domain, mimicking a typical federated invoice processing setup. The base\nmodel is a multi-modal generative language model, and sensitive information\ncould be exposed through either the visual or textual input modality.\nParticipants proposed elegant solutions to reduce communication costs while\nmaintaining a minimum utility threshold in track 1 and to protect all\ninformation from each document provider using differential privacy in track 2.\nThe competition served as a new testbed for developing and testing private\nfederated learning methods, simultaneously raising awareness about privacy\nwithin the document image analysis and recognition community. Ultimately, the\ncompetition analysis provides best practices and recommendations for\nsuccessfully running privacy-focused federated learning challenges in the\nfuture.", "AI": {"tldr": "The PFL-DocVQA competition focused on developing private and efficient federated learning solutions for invoice processing, using a real dataset. Participants fine-tuned a multi-modal model, addressing communication efficiency and differential privacy.", "motivation": "To advance privacy-preserving federated learning in real-life document analysis, specifically for invoice processing, by bringing together diverse expertise.", "method": "Participants fine-tuned a pre-trained multi-modal Document VQA model in a federated setup, focusing on communication efficiency (Track 1) and differential privacy (Track 2).", "result": "Solutions reduced communication costs while maintaining utility and protected document provider information, establishing best practices for privacy-focused federated learning.", "conclusion": "The competition successfully tested private federated learning methods, raised privacy awareness, and provided recommendations for future challenges."}}
{"id": "2505.06262", "pdf": "https://arxiv.org/pdf/2505.06262", "abs": "https://arxiv.org/abs/2505.06262", "authors": ["Zara Siddique", "Liam D. Turner", "Luis Espinosa-Anke"], "title": "Dialz: A Python Toolkit for Steering Vectors", "categories": ["cs.LG", "cs.AI"], "comment": "Accepted to ACL System Demo 2025", "summary": "We introduce Dialz, a framework for advancing research on steering vectors\nfor open-source LLMs, implemented in Python. Steering vectors allow users to\nmodify activations at inference time to amplify or weaken a 'concept', e.g.\nhonesty or positivity, providing a more powerful alternative to prompting or\nfine-tuning. Dialz supports a diverse set of tasks, including creating\ncontrastive pair datasets, computing and applying steering vectors, and\nvisualizations. Unlike existing libraries, Dialz emphasizes modularity and\nusability, enabling both rapid prototyping and in-depth analysis. We\ndemonstrate how Dialz can be used to reduce harmful outputs such as\nstereotypes, while also providing insights into model behaviour across\ndifferent layers. We release Dialz with full documentation, tutorials, and\nsupport for popular open-source models to encourage further research in safe\nand controllable language generation. Dialz enables faster research cycles and\nfacilitates insights into model interpretability, paving the way for safer,\nmore transparent, and more reliable AI systems.", "AI": {"tldr": "Dialz is a Python framework for steering vectors in LLMs, enabling concept modification (e.g., honesty) at inference. It supports tasks like dataset creation, vector application, and visualization, focusing on modularity and usability. Dialz reduces harmful outputs and aids model interpretability, promoting safer AI.", "motivation": "To provide a powerful, modular, and user-friendly tool for steering vector research in LLMs, addressing limitations of prompting/fine-tuning and enhancing model safety and transparency.", "method": "Implemented in Python, Dialz supports tasks like contrastive dataset creation, steering vector computation/application, and visualizations. It emphasizes modularity and usability for rapid prototyping and analysis.", "result": "Dialz reduces harmful outputs (e.g., stereotypes) and offers insights into model behavior across layers, facilitating safer and more interpretable AI.", "conclusion": "Dialz accelerates research cycles, enhances model interpretability, and promotes safer, more transparent AI systems, with full documentation and support for open-source models."}}
{"id": "2505.16014", "pdf": "https://arxiv.org/pdf/2505.16014", "abs": "https://arxiv.org/abs/2505.16014", "authors": ["Yash Saxena", "Ankur Padia", "Mandar S Chaudhary", "Kalpa Gunaratna", "Srinivasan Parthasarathy", "Manas Gaur"], "title": "Ranking Free RAG: Replacing Re-ranking with Selection in RAG for Sensitive Domains", "categories": ["cs.CL"], "comment": null, "summary": "Traditional Retrieval-Augmented Generation (RAG) pipelines rely on\nsimilarity-based retrieval and re-ranking, which depend on heuristics such as\ntop-k, and lack explainability, interpretability, and robustness against\nadversarial content. To address this gap, we propose a novel method METEORA\nthat replaces re-ranking in RAG with a rationale-driven selection approach.\nMETEORA operates in two stages. First, a general-purpose LLM is\npreference-tuned to generate rationales conditioned on the input query using\ndirect preference optimization. These rationales guide the evidence chunk\nselection engine, which selects relevant chunks in three stages: pairing\nindividual rationales with corresponding retrieved chunks for local relevance,\nglobal selection with elbow detection for adaptive cutoff, and context\nexpansion via neighboring chunks. This process eliminates the need for top-k\nheuristics. The rationales are also used for consistency check using a Verifier\nLLM to detect and filter poisoned or misleading content for safe generation.\nThe framework provides explainable and interpretable evidence flow by using\nrationales consistently across both selection and verification. Our evaluation\nacross six datasets spanning legal, financial, and academic research domains\nshows that METEORA improves generation accuracy by 33.34% while using\napproximately 50% fewer chunks than state-of-the-art re-ranking methods. In\nadversarial settings, METEORA significantly improves the F1 score from 0.10 to\n0.44 over the state-of-the-art perplexity-based defense baseline, demonstrating\nstrong resilience to poisoning attacks. Code available at:\nhttps://anonymous.4open.science/r/METEORA-DC46/README.md", "AI": {"tldr": "METEORA replaces heuristic-based re-ranking in RAG with a rationale-driven selection method, improving accuracy and robustness while reducing chunk usage.", "motivation": "Address the lack of explainability, interpretability, and robustness in traditional RAG pipelines.", "method": "Two-stage approach: preference-tuned LLM generates rationales for evidence chunk selection, followed by a three-stage selection process and verification.", "result": "33.34% accuracy improvement, 50% fewer chunks used, and strong resilience to adversarial attacks (F1 score from 0.10 to 0.44).", "conclusion": "METEORA offers a more explainable, robust, and efficient alternative to traditional RAG pipelines."}}
{"id": "2505.20156", "pdf": "https://arxiv.org/pdf/2505.20156", "abs": "https://arxiv.org/abs/2505.20156", "authors": ["Yi Chen", "Sen Liang", "Zixiang Zhou", "Ziyao Huang", "Yifeng Ma", "Junshu Tang", "Qin Lin", "Yuan Zhou", "Qinglin Lu"], "title": "HunyuanVideo-Avatar: High-Fidelity Audio-Driven Human Animation for Multiple Characters", "categories": ["cs.CV"], "comment": null, "summary": "Recent years have witnessed significant progress in audio-driven human\nanimation. However, critical challenges remain in (i) generating highly dynamic\nvideos while preserving character consistency, (ii) achieving precise emotion\nalignment between characters and audio, and (iii) enabling multi-character\naudio-driven animation. To address these challenges, we propose\nHunyuanVideo-Avatar, a multimodal diffusion transformer (MM-DiT)-based model\ncapable of simultaneously generating dynamic, emotion-controllable, and\nmulti-character dialogue videos. Concretely, HunyuanVideo-Avatar introduces\nthree key innovations: (i) A character image injection module is designed to\nreplace the conventional addition-based character conditioning scheme,\neliminating the inherent condition mismatch between training and inference.\nThis ensures the dynamic motion and strong character consistency; (ii) An Audio\nEmotion Module (AEM) is introduced to extract and transfer the emotional cues\nfrom an emotion reference image to the target generated video, enabling\nfine-grained and accurate emotion style control; (iii) A Face-Aware Audio\nAdapter (FAA) is proposed to isolate the audio-driven character with\nlatent-level face mask, enabling independent audio injection via\ncross-attention for multi-character scenarios. These innovations empower\nHunyuanVideo-Avatar to surpass state-of-the-art methods on benchmark datasets\nand a newly proposed wild dataset, generating realistic avatars in dynamic,\nimmersive scenarios.", "AI": {"tldr": "HunyuanVideo-Avatar is a multimodal diffusion transformer model that generates dynamic, emotion-controllable, and multi-character dialogue videos, addressing challenges in character consistency, emotion alignment, and multi-character animation.", "motivation": "To overcome limitations in generating dynamic videos with character consistency, precise emotion alignment, and multi-character animation.", "method": "Introduces a character image injection module, Audio Emotion Module (AEM), and Face-Aware Audio Adapter (FAA) for improved conditioning, emotion control, and multi-character audio injection.", "result": "Surpasses state-of-the-art methods on benchmark and wild datasets, generating realistic avatars in dynamic scenarios.", "conclusion": "HunyuanVideo-Avatar effectively addresses key challenges in audio-driven human animation, offering superior performance and versatility."}}
{"id": "2411.05331", "pdf": "https://arxiv.org/pdf/2411.05331", "abs": "https://arxiv.org/abs/2411.05331", "authors": ["Kun Wang", "Sumanth Varambally", "Duncan Watson-Parris", "Yi-An Ma", "Rose Yu"], "title": "Discovering Latent Causal Graphs from Spatio-Temporal Data", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "Many important phenomena in scientific fields like climate, neuroscience, and\nepidemiology are naturally represented as spatiotemporal gridded data with\ncomplex interactions. Inferring causal relationships from these data is a\nchallenging problem compounded by the high dimensionality of such data and the\ncorrelations between spatially proximate points. We present SPACY\n(SPAtiotemporal Causal discoverY), a novel framework based on variational\ninference, designed to model latent time series and their causal relationships\nfrom spatiotemporal data. SPACY alleviates the high-dimensional challenge by\ndiscovering causal structures in the latent space. To aggregate spatially\nproximate, correlated grid points, we use \\change{spatial factors, parametrized\nby spatial kernel functions}, to map observational time series to latent\nrepresentations. \\change{Theoretically, we generalize the problem to a\ncontinuous spatial domain and establish identifiability when the observations\narise from a nonlinear, invertible function of the product of latent series and\nspatial factors. Using this approach, we avoid assumptions that are often\nunverifiable, including those about instantaneous effects or sufficient\nvariability.} Empirically, SPACY outperforms state-of-the-art baselines on\nsynthetic data, even in challenging settings where existing methods struggle,\nwhile remaining scalable for large grids. SPACY also identifies key known\nphenomena from real-world climate data.", "AI": {"tldr": "SPACY is a variational inference-based framework for discovering causal relationships in high-dimensional spatiotemporal data by modeling latent time series and using spatial factors.", "motivation": "Inferring causal relationships from spatiotemporal data is challenging due to high dimensionality and spatial correlations.", "method": "SPACY uses variational inference to model latent time series and spatial factors, mapping observations to latent representations.", "result": "SPACY outperforms baselines on synthetic data and identifies real-world climate phenomena.", "conclusion": "SPACY effectively addresses high-dimensional challenges and spatial correlations in causal discovery."}}
{"id": "2505.07320", "pdf": "https://arxiv.org/pdf/2505.07320", "abs": "https://arxiv.org/abs/2505.07320", "authors": ["Yuhao Li", "Ling Luo", "Uwe Aickelin"], "title": "Dynamical Label Augmentation and Calibration for Noisy Electronic Health Records", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Medical research, particularly in predicting patient outcomes, heavily relies\non medical time series data extracted from Electronic Health Records (EHR),\nwhich provide extensive information on patient histories. Despite rigorous\nexamination, labeling errors are inevitable and can significantly impede\naccurate predictions of patient outcome. To address this challenge, we propose\nan \\textbf{A}ttention-based Learning Framework with Dynamic\n\\textbf{C}alibration and Augmentation for \\textbf{T}ime series Noisy\n\\textbf{L}abel \\textbf{L}earning (ACTLL). This framework leverages a\ntwo-component Beta mixture model to identify the certain and uncertain sets of\ninstances based on the fitness distribution of each class, and it captures\nglobal temporal dynamics while dynamically calibrating labels from the\nuncertain set or augmenting confident instances from the certain set.\nExperimental results on large-scale EHR datasets eICU and MIMIC-IV-ED, and\nseveral benchmark datasets from the UCR and UEA repositories, demonstrate that\nour model ACTLL has achieved state-of-the-art performance, especially under\nhigh noise levels.", "AI": {"tldr": "ACTLL is an attention-based framework for handling noisy labels in medical time series data, improving prediction accuracy by dynamically calibrating and augmenting data.", "motivation": "Labeling errors in EHR data hinder accurate patient outcome predictions, necessitating robust solutions.", "method": "ACTLL uses a Beta mixture model to classify instances into certain/uncertain sets, dynamically calibrates labels, and augments confident instances.", "result": "ACTLL outperforms others on EHR datasets (eICU, MIMIC-IV-ED) and benchmarks (UCR, UEA), especially with high noise.", "conclusion": "ACTLL effectively addresses noisy labels in medical time series, achieving state-of-the-art performance."}}
{"id": "2505.16552", "pdf": "https://arxiv.org/pdf/2505.16552", "abs": "https://arxiv.org/abs/2505.16552", "authors": ["Wenhui Tan", "Jiaze Li", "Jianzhong Ju", "Zhenbo Luo", "Jian Luan", "Ruihua Song"], "title": "Think Silently, Think Fast: Dynamic Latent Compression of LLM Reasoning Chains", "categories": ["cs.CL"], "comment": "15 pages, 8 figures", "summary": "Large Language Models (LLMs) achieve superior performance through\nChain-of-Thought (CoT) reasoning, but these token-level reasoning chains are\ncomputationally expensive and inefficient. In this paper, we introduce\nCompressed Latent Reasoning (CoLaR), a novel framework that dynamically\ncompresses reasoning processes in latent space through a two-stage training\napproach. First, during supervised fine-tuning, CoLaR extends beyond next-token\nprediction by incorporating an auxiliary next compressed embedding prediction\nobjective. This process merges embeddings of consecutive tokens using a\ncompression factor randomly sampled from a predefined range, and trains a\nspecialized latent head to predict distributions of subsequent compressed\nembeddings. Second, we enhance CoLaR through reinforcement learning (RL) that\nleverages the latent head's non-deterministic nature to explore diverse\nreasoning paths and exploit more compact ones. This approach enables CoLaR to:\ni) perform reasoning at a dense latent level (i.e., silently), substantially\nreducing reasoning chain length, and ii) dynamically adjust reasoning speed at\ninference time by simply prompting the desired compression factor. Extensive\nexperiments across four mathematical reasoning datasets demonstrate that CoLaR\nachieves 14.1% higher accuracy than latent-based baseline methods at comparable\ncompression ratios, and reduces reasoning chain length by 53.3% with only 4.8%\nperformance degradation compared to explicit CoT method. Moreover, when applied\nto more challenging mathematical reasoning tasks, our RL-enhanced CoLaR\ndemonstrates performance gains of up to 5.4% while dramatically reducing latent\nreasoning chain length by 82.8%. The code and models will be released upon\nacceptance.", "AI": {"tldr": "CoLaR introduces a framework to compress reasoning processes in latent space, improving efficiency and performance over traditional CoT methods.", "motivation": "Traditional Chain-of-Thought (CoT) reasoning in LLMs is computationally expensive and inefficient at the token level.", "method": "CoLaR uses a two-stage approach: supervised fine-tuning with compressed embedding prediction and reinforcement learning to explore diverse reasoning paths.", "result": "CoLaR achieves 14.1% higher accuracy than baselines, reduces reasoning chain length by 53.3%, and improves performance by 5.4% in challenging tasks.", "conclusion": "CoLaR offers a more efficient and dynamic alternative to CoT, with significant performance gains and reduced computational overhead."}}
{"id": "2505.20292", "pdf": "https://arxiv.org/pdf/2505.20292", "abs": "https://arxiv.org/abs/2505.20292", "authors": ["Shenghai Yuan", "Xianyi He", "Yufan Deng", "Yang Ye", "Jinfa Huang", "Bin Lin", "Jiebo Luo", "Li Yuan"], "title": "OpenS2V-Nexus: A Detailed Benchmark and Million-Scale Dataset for Subject-to-Video Generation", "categories": ["cs.CV", "cs.AI"], "comment": "Code and Dataset: https://github.com/PKU-YuanGroup/OpenS2V-Nexus", "summary": "Subject-to-Video (S2V) generation aims to create videos that faithfully\nincorporate reference content, providing enhanced flexibility in the production\nof videos. To establish the infrastructure for S2V generation, we propose\nOpenS2V-Nexus, consisting of (i) OpenS2V-Eval, a fine-grained benchmark, and\n(ii) OpenS2V-5M, a million-scale dataset. In contrast to existing S2V\nbenchmarks inherited from VBench that focus on global and coarse-grained\nassessment of generated videos, OpenS2V-Eval focuses on the model's ability to\ngenerate subject-consistent videos with natural subject appearance and identity\nfidelity. For these purposes, OpenS2V-Eval introduces 180 prompts from seven\nmajor categories of S2V, which incorporate both real and synthetic test data.\nFurthermore, to accurately align human preferences with S2V benchmarks, we\npropose three automatic metrics, NexusScore, NaturalScore and GmeScore, to\nseparately quantify subject consistency, naturalness, and text relevance in\ngenerated videos. Building on this, we conduct a comprehensive evaluation of 18\nrepresentative S2V models, highlighting their strengths and weaknesses across\ndifferent content. Moreover, we create the first open-source large-scale S2V\ngeneration dataset OpenS2V-5M, which consists of five million high-quality 720P\nsubject-text-video triples. Specifically, we ensure subject-information\ndiversity in our dataset by (1) segmenting subjects and building pairing\ninformation via cross-video associations and (2) prompting GPT-Image-1 on raw\nframes to synthesize multi-view representations. Through OpenS2V-Nexus, we\ndeliver a robust infrastructure to accelerate future S2V generation research.", "AI": {"tldr": "OpenS2V-Nexus introduces a benchmark (OpenS2V-Eval) and dataset (OpenS2V-5M) for Subject-to-Video (S2V) generation, focusing on subject consistency, naturalness, and text relevance. It evaluates 18 S2V models and provides a large-scale dataset to advance research.", "motivation": "Existing S2V benchmarks lack fine-grained assessment of subject consistency and naturalness. OpenS2V-Nexus aims to fill this gap by providing a comprehensive infrastructure for S2V generation.", "method": "Proposes OpenS2V-Eval (180 prompts, real/synthetic data) with three metrics (NexusScore, NaturalScore, GmeScore) and OpenS2V-5M (5M subject-text-video triples) via cross-video associations and GPT-Image-1 synthesis.", "result": "Evaluated 18 S2V models, revealing strengths/weaknesses. OpenS2V-5M ensures subject diversity and high-quality data.", "conclusion": "OpenS2V-Nexus provides a robust infrastructure to accelerate S2V research, addressing gaps in current benchmarks and datasets."}}
{"id": "2411.19146", "pdf": "https://arxiv.org/pdf/2411.19146", "abs": "https://arxiv.org/abs/2411.19146", "authors": ["Akhiad Bercovich", "Tomer Ronen", "Talor Abramovich", "Nir Ailon", "Nave Assaf", "Mohammad Dabbah", "Ido Galil", "Amnon Geifman", "Yonatan Geifman", "Izhak Golan", "Netanel Haber", "Ehud Karpas", "Roi Koren", "Itay Levy", "Pavlo Molchanov", "Shahar Mor", "Zach Moshe", "Najeeb Nabwani", "Omri Puny", "Ran Rubin", "Itamar Schen", "Ido Shahaf", "Oren Tropp", "Omer Ullman Argov", "Ran Zilberstein", "Ran El-Yaniv"], "title": "Puzzle: Distillation-Based NAS for Inference-Optimized LLMs", "categories": ["cs.LG"], "comment": null, "summary": "Large language models (LLMs) offer remarkable capabilities, yet their high\ninference costs restrict wider adoption. While increasing parameter counts\nimproves accuracy, it also broadens the gap between state-of-the-art\ncapabilities and practical deployability. We present Puzzle, a hardware-aware\nframework that accelerates the inference of LLMs while preserving their\ncapabilities. Using neural architecture search (NAS) at a large-scale, Puzzle\noptimizes models with tens of billions of parameters. Our approach utilizes\nblockwise local knowledge distillation (BLD) for parallel architecture\nexploration and employs mixed-integer programming for precise constraint\noptimization.\n  We showcase our framework's impact via Llama-3.1-Nemotron-51B-Instruct\n(Nemotron-51B) and Llama-3.3-Nemotron-49B, two publicly available models\nderived from Llama-70B-Instruct. Both models achieve a 2.17x inference\nthroughput speedup, fitting on a single NVIDIA H100 GPU while retaining 98.4%\nof the original model's benchmark accuracies. These are the most accurate\nmodels supporting single H100 GPU inference with large batch sizes, despite\ntraining on 45B tokens at most, far fewer than the 15T used to train Llama-70B.\nLastly, we show that lightweight alignment on these derived models allows them\nto surpass the parent model in specific capabilities. Our work establishes that\npowerful LLM models can be optimized for efficient deployment with only\nnegligible loss in quality, underscoring that inference performance, not\nparameter count alone, should guide model selection.", "AI": {"tldr": "Puzzle is a hardware-aware framework that accelerates LLM inference while maintaining accuracy, achieving 2.17x speedup on models like Nemotron-51B with minimal quality loss.", "motivation": "High inference costs of LLMs limit adoption, despite their capabilities. Puzzle aims to bridge the gap between state-of-the-art performance and practical deployability.", "method": "Uses neural architecture search (NAS) and blockwise local knowledge distillation (BLD) for optimization, alongside mixed-integer programming for constraints.", "result": "Achieves 2.17x throughput speedup on Nemotron-51B and Nemotron-49B, retaining 98.4% accuracy while fitting on a single H100 GPU.", "conclusion": "Demonstrates that LLMs can be optimized for efficient deployment without significant quality loss, emphasizing inference performance over parameter count."}}
{"id": "2505.07802", "pdf": "https://arxiv.org/pdf/2505.07802", "abs": "https://arxiv.org/abs/2505.07802", "authors": ["Reece O'Mahoney", "Wanming Yu", "Ioannis Havoutis"], "title": "Improving Trajectory Stitching with Flow Models", "categories": ["cs.RO", "cs.AI", "cs.LG"], "comment": null, "summary": "Generative models have shown great promise as trajectory planners, given\ntheir affinity to modeling complex distributions and guidable inference\nprocess. Previous works have successfully applied these in the context of\nrobotic manipulation but perform poorly when the required solution does not\nexist as a complete trajectory within the training set. We identify that this\nis a result of being unable to plan via stitching, and subsequently address the\narchitectural and dataset choices needed to remedy this. On top of this, we\npropose a novel addition to the training and inference procedures to both\nstabilize and enhance these capabilities. We demonstrate the efficacy of our\napproach by generating plans with out of distribution boundary conditions and\nperforming obstacle avoidance on the Franka Panda in simulation and on real\nhardware. In both of these tasks our method performs significantly better than\nthe baselines and is able to avoid obstacles up to four times as large.", "AI": {"tldr": "The paper addresses limitations of generative models in robotic trajectory planning, proposing architectural and dataset improvements to enable planning via stitching, and demonstrates superior performance in out-of-distribution tasks and obstacle avoidance.", "motivation": "Generative models struggle when required solutions aren't complete trajectories in the training set, limiting their planning capabilities.", "method": "Proposes architectural and dataset changes to enable planning via stitching, along with novel training and inference enhancements.", "result": "Outperforms baselines in generating plans for out-of-distribution boundary conditions and obstacle avoidance, handling obstacles up to four times larger.", "conclusion": "The proposed method significantly improves generative models' planning capabilities, enabling robust performance in complex robotic tasks."}}
{"id": "2505.16660", "pdf": "https://arxiv.org/pdf/2505.16660", "abs": "https://arxiv.org/abs/2505.16660", "authors": ["Liu Chang", "Wang Dongbo", "Liu liu", "Zhao Zhixiao"], "title": "Can reasoning models comprehend mathematical problems in Chinese ancient texts? An empirical study based on data from Suanjing Shishu", "categories": ["cs.CL", "cs.AI"], "comment": "29pages, 7 figures", "summary": "This study addresses the challenges in intelligent processing of Chinese\nancient mathematical classics by constructing Guji_MATH, a benchmark for\nevaluating classical texts based on Suanjing Shishu. It systematically assesses\nthe mathematical problem-solving capabilities of mainstream reasoning models\nunder the unique linguistic constraints of classical Chinese. Through\nmachine-assisted annotation and manual verification, 538 mathematical problems\nwere extracted from 8 canonical texts, forming a structured dataset centered on\nthe \"Question-Answer-Solution\" framework, supplemented by problem types and\ndifficulty levels. Dual evaluation modes--closed-book (autonomous\nproblem-solving) and open-book (reproducing classical solution methods)--were\ndesigned to evaluate the performance of six reasoning models on ancient Chinese\nmathematical problems. Results indicate that reasoning models can partially\ncomprehend and solve these problems, yet their overall performance remains\ninferior to benchmarks on modern mathematical tasks. Enhancing models'\nclassical Chinese comprehension and cultural knowledge should be prioritized\nfor optimization. This study provides methodological support for mining\nmathematical knowledge from ancient texts and disseminating traditional\nculture, while offering new perspectives for evaluating cross-linguistic and\ncross-cultural capabilities of reasoning models.", "AI": {"tldr": "The study introduces Guji_MATH, a benchmark for evaluating reasoning models on Chinese ancient mathematical texts, revealing their limitations and suggesting improvements.", "motivation": "To address the challenges in processing Chinese ancient mathematical classics and evaluate reasoning models' capabilities under classical Chinese constraints.", "method": "Constructed a benchmark (Guji_MATH) with 538 problems from 8 texts, using machine-assisted annotation and manual verification. Evaluated six models via closed-book and open-book modes.", "result": "Models partially comprehend and solve problems but underperform compared to modern tasks. Classical Chinese comprehension and cultural knowledge need enhancement.", "conclusion": "The study aids in mining mathematical knowledge from ancient texts and evaluating cross-linguistic model capabilities, suggesting prioritization of classical Chinese comprehension for optimization."}}
{"id": "2505.21179", "pdf": "https://arxiv.org/pdf/2505.21179", "abs": "https://arxiv.org/abs/2505.21179", "authors": ["Dar-Yen Chen", "Hmrishav Bandyopadhyay", "Kai Zou", "Yi-Zhe Song"], "title": "Normalized Attention Guidance: Universal Negative Guidance for Diffusion Models", "categories": ["cs.CV"], "comment": null, "summary": "Negative guidance -- explicitly suppressing unwanted attributes -- remains a\nfundamental challenge in diffusion models, particularly in few-step sampling\nregimes. While Classifier-Free Guidance (CFG) works well in standard settings,\nit fails under aggressive sampling step compression due to divergent\npredictions between positive and negative branches. We present Normalized\nAttention Guidance (NAG), an efficient, training-free mechanism that applies\nextrapolation in attention space with L1-based normalization and refinement.\nNAG restores effective negative guidance where CFG collapses while maintaining\nfidelity. Unlike existing approaches, NAG generalizes across architectures\n(UNet, DiT), sampling regimes (few-step, multi-step), and modalities (image,\nvideo), functioning as a \\textit{universal} plug-in with minimal computational\noverhead. Through extensive experimentation, we demonstrate consistent\nimprovements in text alignment (CLIP Score), fidelity (FID, PFID), and\nhuman-perceived quality (ImageReward). Our ablation studies validate each\ndesign component, while user studies confirm significant preference for\nNAG-guided outputs. As a model-agnostic inference-time approach requiring no\nretraining, NAG provides effortless negative guidance for all modern diffusion\nframeworks -- pseudocode in the Appendix!", "AI": {"tldr": "NAG is a training-free method for effective negative guidance in diffusion models, outperforming CFG in few-step sampling and generalizing across architectures and modalities.", "motivation": "Negative guidance in diffusion models fails under aggressive step compression, leading to divergent predictions. NAG addresses this limitation.", "method": "NAG uses L1-based normalization and refinement in attention space for extrapolation, functioning as a universal plug-in.", "result": "NAG improves text alignment, fidelity, and human-perceived quality across various architectures and sampling regimes.", "conclusion": "NAG is a model-agnostic, efficient solution for negative guidance in diffusion models, validated by experiments and user studies."}}
{"id": "2412.17626", "pdf": "https://arxiv.org/pdf/2412.17626", "abs": "https://arxiv.org/abs/2412.17626", "authors": ["Yang Xu", "Yi Wang", "Hengguan Huang", "Hao Wang"], "title": "Tracking the Feature Dynamics in LLM Training: A Mechanistic Study", "categories": ["cs.LG", "cs.CL"], "comment": null, "summary": "Understanding training dynamics and feature evolution is crucial for the\nmechanistic interpretability of large language models (LLMs). Although sparse\nautoencoders (SAEs) have been used to identify features within LLMs, a clear\npicture of how these features evolve during training remains elusive. In this\nstudy, we (1) introduce SAE-Track, a novel method for efficiently obtaining a\ncontinual series of SAEs, providing the foundation for a mechanistic study that\ncovers (2) the semantic evolution of features, (3) the underlying processes of\nfeature formation, and (4) the directional drift of feature vectors. Our work\nprovides new insights into the dynamics of features in LLMs, enhancing our\nunderstanding of training mechanisms and feature evolution. For\nreproducibility, our code is available at\nhttps://github.com/Superposition09m/SAE-Track.", "AI": {"tldr": "SAE-Track is introduced to study feature evolution in LLMs, covering semantic evolution, formation processes, and directional drift.", "motivation": "To understand how features evolve during training in large language models (LLMs) for mechanistic interpretability.", "method": "Introduces SAE-Track, a method for obtaining continual sparse autoencoders (SAEs) to analyze feature dynamics.", "result": "Provides insights into feature evolution, formation, and drift in LLMs.", "conclusion": "Enhances understanding of training mechanisms and feature dynamics in LLMs; code is available for reproducibility."}}
{"id": "2505.10640", "pdf": "https://arxiv.org/pdf/2505.10640", "abs": "https://arxiv.org/abs/2505.10640", "authors": ["Kirill Vasilevski", "Benjamin Rombaut", "Gopi Krishnan Rajbahadur", "Gustavo A. Oliva", "Keheliya Gallaba", "Filipe R. Cogo", "Jiahuei Lin", "Dayi Lin", "Haoxiang Zhang", "Bouyan Chen", "Kishanthan Thangarajah", "Ahmed E. Hassan", "Zhen Ming Jiang"], "title": "The Hitchhikers Guide to Production-ready Trustworthy Foundation Model powered Software (FMware)", "categories": ["cs.SE", "cs.AI", "cs.LG"], "comment": null, "summary": "Foundation Models (FMs) such as Large Language Models (LLMs) are reshaping\nthe software industry by enabling FMware, systems that integrate these FMs as\ncore components. In this KDD 2025 tutorial, we present a comprehensive\nexploration of FMware that combines a curated catalogue of challenges with\nreal-world production concerns. We first discuss the state of research and\npractice in building FMware. We further examine the difficulties in selecting\nsuitable models, aligning high-quality domain-specific data, engineering robust\nprompts, and orchestrating autonomous agents. We then address the complex\njourney from impressive demos to production-ready systems by outlining issues\nin system testing, optimization, deployment, and integration with legacy\nsoftware. Drawing on our industrial experience and recent research in the area,\nwe provide actionable insights and a technology roadmap for overcoming these\nchallenges. Attendees will gain practical strategies to enable the creation of\ntrustworthy FMware in the evolving technology landscape.", "AI": {"tldr": "A tutorial on FMware (systems integrating Foundation Models) at KDD 2025, covering challenges, production concerns, and practical strategies for building trustworthy systems.", "motivation": "To address the gap between research and practice in integrating Foundation Models (FMs) into production systems, highlighting real-world challenges and solutions.", "method": "Combines a curated catalogue of challenges with industrial experience and research insights, covering model selection, data alignment, prompt engineering, and system deployment.", "result": "Provides actionable insights and a technology roadmap for overcoming challenges in building FMware, from demos to production-ready systems.", "conclusion": "The tutorial equips attendees with practical strategies to create trustworthy FMware in the evolving tech landscape."}}
{"id": "2505.17134", "pdf": "https://arxiv.org/pdf/2505.17134", "abs": "https://arxiv.org/abs/2505.17134", "authors": ["Chaochen Gao", "Xing Wu", "Zijia Lin", "Debing Zhang", "Songlin Hu"], "title": "LongMagpie: A Self-synthesis Method for Generating Large-scale Long-context Instructions", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "High-quality long-context instruction data is essential for aligning\nlong-context large language models (LLMs). Despite the public release of models\nlike Qwen and Llama, their long-context instruction data remains proprietary.\nHuman annotation is costly and challenging, while template-based synthesis\nmethods limit scale, diversity, and quality. We introduce LongMagpie, a\nself-synthesis framework that automatically generates large-scale long-context\ninstruction data. Our key insight is that aligned long-context LLMs, when\npresented with a document followed by special tokens preceding a user turn,\nauto-regressively generate contextually relevant queries. By harvesting these\ndocument-query pairs and the model's responses, LongMagpie produces\nhigh-quality instructions without human effort. Experiments on HELMET, RULER,\nand Longbench v2 demonstrate that LongMagpie achieves leading performance on\nlong-context tasks while maintaining competitive performance on short-context\ntasks, establishing it as a simple and effective approach for open, diverse,\nand scalable long-context instruction data synthesis.", "AI": {"tldr": "LongMagpie is a self-synthesis framework for generating high-quality long-context instruction data automatically, outperforming human annotation and template-based methods.", "motivation": "High-quality long-context instruction data is scarce and costly to produce, limiting the alignment of long-context LLMs.", "method": "LongMagpie leverages aligned long-context LLMs to auto-generate contextually relevant queries from documents, creating instruction data without human effort.", "result": "LongMagpie achieves top performance on long-context benchmarks (HELMET, RULER, Longbench v2) while staying competitive on short-context tasks.", "conclusion": "LongMagpie offers a scalable, diverse, and open solution for long-context instruction data synthesis."}}
{"id": "2505.21863", "pdf": "https://arxiv.org/pdf/2505.21863", "abs": "https://arxiv.org/abs/2505.21863", "authors": ["Shikhhar Siingh", "Abhinav Rawat", "Chitta Baral", "Vivek Gupta"], "title": "GETReason: Enhancing Image Context Extraction through Hierarchical Multi-Agent Reasoning", "categories": ["cs.CV", "cs.CL"], "comment": null, "summary": "Publicly significant images from events hold valuable contextual information,\ncrucial for journalism and education. However, existing methods often struggle\nto extract this relevance accurately. To address this, we introduce GETReason\n(Geospatial Event Temporal Reasoning), a framework that moves beyond\nsurface-level image descriptions to infer deeper contextual meaning. We propose\nthat extracting global event, temporal, and geospatial information enhances\nunderstanding of an image's significance. Additionally, we introduce GREAT\n(Geospatial Reasoning and Event Accuracy with Temporal Alignment), a new metric\nfor evaluating reasoning-based image understanding. Our layered multi-agent\napproach, assessed using a reasoning-weighted metric, demonstrates that\nmeaningful insights can be inferred, effectively linking images to their\nbroader event context.", "AI": {"tldr": "GETReason framework and GREAT metric improve contextual understanding of publicly significant images by leveraging geospatial, temporal, and event data.", "motivation": "Existing methods fail to accurately extract contextual relevance from images, limiting their utility in journalism and education.", "method": "Introduces GETReason for deeper contextual inference and GREAT for evaluation, using a multi-agent approach.", "result": "Demonstrates effective linking of images to broader event contexts through reasoning-based insights.", "conclusion": "The framework and metric enhance image understanding, offering valuable tools for contextual analysis."}}
{"id": "2412.18730", "pdf": "https://arxiv.org/pdf/2412.18730", "abs": "https://arxiv.org/abs/2412.18730", "authors": ["Zhengchao Wan", "Qingsong Wang", "Gal Mishne", "Yusu Wang"], "title": "Elucidating Flow Matching ODE Dynamics with Respect to Data Geometries and Denoisers", "categories": ["cs.LG"], "comment": "Accepted to ICML 2025, title updated", "summary": "Flow matching (FM) models extend ODE sampler based diffusion models into a\ngeneral framework, significantly reducing sampling steps through learned vector\nfields. However, the theoretical understanding of FM models, particularly how\ntheir sample trajectories interact with underlying data geometry, remains\nunderexplored. A rigorous theoretical analysis of FM ODE is essential for\nsample quality, stability, and broader applicability. In this paper, we advance\nthe theory of FM models through a comprehensive analysis of sample\ntrajectories. Central to our theory is the discovery that the denoiser, a key\ncomponent of FM models, guides ODE dynamics through attracting and absorbing\nbehaviors that adapt to the data geometry. We identify and analyze the three\nstages of ODE evolution: in the initial and intermediate stages, trajectories\nmove toward the mean and local clusters of the data. At the terminal stage, we\nrigorously establish the convergence of FM ODE under weak assumptions,\naddressing scenarios where the data lie on a low-dimensional submanifold-cases\nthat previous results could not handle. Our terminal stage analysis offers\ninsights into the memorization phenomenon and establishes equivariance\nproperties of FM ODEs. These findings bridge critical gaps in understanding\nflow matching models, with practical implications for optimizing sampling\nstrategies and architectures guided by the intrinsic geometry of data.", "AI": {"tldr": "The paper advances the theoretical understanding of Flow Matching (FM) models by analyzing sample trajectories, revealing how the denoiser guides ODE dynamics through data geometry. It identifies three stages of ODE evolution and rigorously establishes convergence under weak assumptions.", "motivation": "Theoretical understanding of FM models, especially their interaction with data geometry, is lacking. A rigorous analysis is needed to improve sample quality, stability, and applicability.", "method": "Comprehensive analysis of FM ODE sample trajectories, focusing on the denoiser's role in guiding dynamics through attracting and absorbing behaviors. Three stages of ODE evolution are identified and analyzed.", "result": "The denoiser adapts to data geometry, guiding trajectories toward the mean and local clusters initially, then converging under weak assumptions, even for low-dimensional submanifolds. Terminal stage analysis reveals memorization and equivariance properties.", "conclusion": "The findings bridge gaps in FM theory, offering insights for optimizing sampling strategies and architectures based on data geometry."}}
{"id": "2505.11582", "pdf": "https://arxiv.org/pdf/2505.11582", "abs": "https://arxiv.org/abs/2505.11582", "authors": ["Lee Harris"], "title": "Comparing Lexical and Semantic Vector Search Methods When Classifying Medical Documents", "categories": ["cs.IR", "cs.AI"], "comment": "This project was funded by a UKRI grant, number: 10048265", "summary": "Classification is a common AI problem, and vector search is a typical\nsolution. This transforms a given body of text into a numerical representation,\nknown as an embedding, and modern improvements to vector search focus on\noptimising speed and predictive accuracy. This is often achieved through neural\nmethods that aim to learn language semantics. However, our results suggest that\nthese are not always the best solution. Our task was to classify\nrigidly-structured medical documents according to their content, and we found\nthat using off-the-shelf semantic vector search produced slightly worse\npredictive accuracy than creating a bespoke lexical vector search model, and\nthat it required significantly more time to execute. These findings suggest\nthat traditional methods deserve to be contenders in the information retrieval\ntoolkit, despite the prevalence and success of neural models.", "AI": {"tldr": "Traditional lexical vector search outperformed semantic vector search in accuracy and speed for classifying structured medical documents.", "motivation": "To evaluate whether neural-based semantic vector search is always superior to traditional lexical methods for rigidly-structured document classification.", "method": "Compared off-the-shelf semantic vector search with a bespoke lexical vector search model for classifying medical documents.", "result": "Lexical vector search achieved better predictive accuracy and faster execution than semantic vector search.", "conclusion": "Traditional methods remain viable contenders in information retrieval, even alongside advanced neural models."}}
{"id": "2505.20015", "pdf": "https://arxiv.org/pdf/2505.20015", "abs": "https://arxiv.org/abs/2505.20015", "authors": ["Ramon Ferrer-i-Cancho"], "title": "On the class of coding optimality of human languages and the origins of Zipf's law", "categories": ["cs.CL", "physics.soc-ph"], "comment": null, "summary": "Here we present a new class of optimality for coding systems. Members of that\nclass are displaced linearly from optimal coding and thus exhibit Zipf's law,\nnamely a power-law distribution of frequency ranks. Within that class, Zipf's\nlaw, the size-rank law and the size-probability law form a group-like\nstructure. We identify human languages that are members of the class. All\nlanguages showing sufficient agreement with Zipf's law are potential members of\nthe class. In contrast, there are communication systems in other species that\ncannot be members of that class for exhibiting an exponential distribution\ninstead but dolphins and humpback whales might. We provide a new insight into\nplots of frequency versus rank in double logarithmic scale. For any system, a\nstraight line in that scale indicates that the lengths of optimal codes under\nnon-singular coding and under uniquely decodable encoding are displaced by a\nlinear function whose slope is the exponent of Zipf's law. For systems under\ncompression and constrained to be uniquely decodable, such a straight line may\nindicate that the system is coding close to optimality. Our findings provide\nsupport for the hypothesis that Zipf's law originates from compression.", "AI": {"tldr": "The paper introduces a new class of coding systems exhibiting Zipf's law, linking it to optimal coding and compression.", "motivation": "To explore the relationship between Zipf's law and optimal coding, identifying human languages and certain animal communication systems as members of this class.", "method": "Analyzing frequency-rank distributions in double logarithmic scale to identify linear displacement from optimal coding.", "result": "Human languages and some animal systems (e.g., dolphins, whales) fit the class, while others with exponential distributions do not.", "conclusion": "Zipf's law likely stems from compression, with straight lines in log-log plots indicating near-optimal coding."}}
{"id": "2505.21920", "pdf": "https://arxiv.org/pdf/2505.21920", "abs": "https://arxiv.org/abs/2505.21920", "authors": ["Yuanhong Zhang", "Muyao Yuan", "Weizhan Zhang", "Tieliang Gong", "Wen Wen", "Jiangyong Ying", "Weijie Shi"], "title": "InfoSAM: Fine-Tuning the Segment Anything Model from An Information-Theoretic Perspective", "categories": ["cs.CV"], "comment": "Accepted by ICML 2025 (spotlight)", "summary": "The Segment Anything Model (SAM), a vision foundation model, exhibits\nimpressive zero-shot capabilities in general tasks but struggles in specialized\ndomains. Parameter-efficient fine-tuning (PEFT) is a promising approach to\nunleash the potential of SAM in novel scenarios. However, existing PEFT methods\nfor SAM neglect the domain-invariant relations encoded in the pre-trained\nmodel. To bridge this gap, we propose InfoSAM, an information-theoretic\napproach that enhances SAM fine-tuning by distilling and preserving its\npre-trained segmentation knowledge. Specifically, we formulate the knowledge\ntransfer process as two novel mutual information-based objectives: (i) to\ncompress the domain-invariant relation extracted from pre-trained SAM,\nexcluding pseudo-invariant information as possible, and (ii) to maximize mutual\ninformation between the relational knowledge learned by the teacher\n(pre-trained SAM) and the student (fine-tuned model). The proposed InfoSAM\nestablishes a robust distillation framework for PEFT of SAM. Extensive\nexperiments across diverse benchmarks validate InfoSAM's effectiveness in\nimproving SAM family's performance on real-world tasks, demonstrating its\nadaptability and superiority in handling specialized scenarios.", "AI": {"tldr": "InfoSAM enhances SAM fine-tuning by preserving domain-invariant relations using mutual information objectives, improving performance in specialized domains.", "motivation": "SAM struggles in specialized domains despite strong zero-shot capabilities. Existing PEFT methods ignore domain-invariant relations, limiting SAM's potential.", "method": "InfoSAM uses mutual information objectives to distill and preserve pre-trained segmentation knowledge, compressing domain-invariant relations and maximizing knowledge transfer.", "result": "Extensive experiments show InfoSAM improves SAM's performance in specialized scenarios, validating its adaptability and superiority.", "conclusion": "InfoSAM provides a robust PEFT framework for SAM, enhancing its effectiveness in real-world specialized tasks."}}
{"id": "2501.05844", "pdf": "https://arxiv.org/pdf/2501.05844", "abs": "https://arxiv.org/abs/2501.05844", "authors": ["Vyacheslav Kungurtsev", "Leonardo Christov Moore", "Gustav Sir", "Martin Krutsky"], "title": "\"Cause\" is Mechanistic Narrative within Scientific Domains: An Ordinary Language Philosophical Critique of \"Causal Machine Learning\"", "categories": ["cs.LG"], "comment": null, "summary": "Causal Learning has emerged as a major theme of research in statistics and\nmachine learning in recent years, promising specific computational techniques\nto apply to datasets that reveal the true nature of cause and effect in a\nnumber of important domains. In this paper we consider the epistemology of\nrecognizing true cause and effect phenomena. We apply the Ordinary Language\nmethod of engaging on the customary use of the word 'cause' to investigate\nvalid semantics of reasoning about cause and effect. We recognize that the\ngrammars of cause and effect are fundamentally distinct in form across\nscientific domains, yet they maintain a consistent and central function. This\nfunction can best be described as the mechanism underlying fundamental forces\nof influence as considered prominent in the respective scientific domain. We\ndemarcate 1) physics and engineering as domains wherein mathematical models are\nsufficient to comprehensively describe causality, 2) biology as introducing\nchallenges of emergence while providing opportunities for showing consistent\nmechanisms across scale, and 3) the social sciences as introducing grander\ndifficulties for establishing models of low prediction error but providing,\nthrough Hermeneutics, the potential for findings that are still instrumentally\nuseful to individuals. We posit that definitive causal claims regarding a given\nphenomenon (writ large) can only come through an agglomeration of consistent\nevidence across multiple domains. This presents important methodological\nquestions as far as harmonizing between language games and emergence across\nscales. Given the role of epistemic hubris in the contemporary crisis of\ncredibility in the sciences, exercising greater caution as far as communicating\nprecision as to the real degree of certainty certain evidence provides for rich\ncollections of open problems in optimizing integration of different findings.", "AI": {"tldr": "The paper explores the epistemology of causal learning, emphasizing the distinct grammars of causality across domains like physics, biology, and social sciences, and advocates for agglomerating evidence for definitive claims.", "motivation": "To investigate the semantics of causality and address challenges in recognizing true cause-and-effect phenomena across scientific domains.", "method": "Uses the Ordinary Language method to analyze the word 'cause' and demarcates causality in physics, biology, and social sciences.", "result": "Identifies distinct causal grammars per domain and highlights the need for consistent evidence aggregation for definitive claims.", "conclusion": "Calls for methodological caution in harmonizing causality across domains and emphasizes precision in communicating certainty."}}
{"id": "2505.13182", "pdf": "https://arxiv.org/pdf/2505.13182", "abs": "https://arxiv.org/abs/2505.13182", "authors": ["Jianfeng Xu"], "title": "Information Science Principles of Machine Learning: A Causal Chain Meta-Framework Based on Formalized Information Mapping", "categories": ["cs.LO", "cs.AI"], "comment": null, "summary": "[Objective] This study focuses on addressing the current lack of a unified\nformal theoretical framework in machine learning, as well as the deficiencies\nin interpretability and ethical safety assurance. [Methods] A formal\ninformation model is first constructed, utilizing sets of well-formed formulas\nto explicitly define the ontological states and carrier mappings of typical\ncomponents in machine learning. Learnable and processable predicates, along\nwith learning and processing functions, are introduced to analyze the logical\ndeduction and constraint rules of the causal chains within models. [Results] A\nmeta-framework for machine learning theory (MLT-MF) is established. Based on\nthis framework, universal definitions for model interpretability and ethical\nsafety are proposed. Furthermore, three key theorems are proved: the\nequivalence of model interpretability and information recoverability, the\nassurance of ethical safety, and the estimation of generalization error.\n[Limitations] The current framework assumes ideal conditions with noiseless\ninformation-enabling mappings and primarily targets model learning and\nprocessing logic in static scenarios. It does not yet address information\nfusion and conflict resolution across ontological spaces in multimodal or\nmulti-agent systems. [Conclusions] This work overcomes the limitations of\nfragmented research and provides a unified theoretical foundation for\nsystematically addressing the critical challenges currently faced in machine\nlearning.", "AI": {"tldr": "The paper proposes a unified formal framework (MLT-MF) for machine learning, addressing interpretability and ethical safety, with defined theorems and limitations in scope.", "motivation": "To resolve the lack of a unified theoretical framework and improve interpretability and ethical safety in machine learning.", "method": "Constructs a formal information model using well-formed formulas, predicates, and functions to analyze causal chains and constraints.", "result": "Establishes MLT-MF, defines interpretability and ethical safety, and proves three key theorems.", "conclusion": "Provides a unified foundation for tackling machine learning challenges, though limited to static, noiseless scenarios."}}
{"id": "2505.20282", "pdf": "https://arxiv.org/pdf/2505.20282", "abs": "https://arxiv.org/abs/2505.20282", "authors": ["Zitian Gao", "Lynx Chen", "Joey Zhou", "Bryan Dai"], "title": "One-shot Entropy Minimization", "categories": ["cs.CL"], "comment": "Work in progress", "summary": "We trained 13,440 large language models and found that entropy minimization\nrequires only a single unlabeled data and 10 steps optimization to achieve\nperformance improvements comparable to or even greater than those obtained\nusing thousands of data and carefully designed rewards in rule-based\nreinforcement learning. This striking result may prompt a rethinking of\npost-training paradigms for large language models. Our code is avaliable at\nhttps://github.com/zitian-gao/one-shot-em.", "AI": {"tldr": "Entropy minimization with a single unlabeled data and 10 optimization steps matches or exceeds performance of rule-based RL with thousands of data.", "motivation": "To challenge the efficiency of post-training paradigms for large language models by simplifying the process.", "method": "Trained 13,440 models using entropy minimization with minimal data and optimization steps.", "result": "Achieved comparable or better performance than rule-based RL with significantly less data and effort.", "conclusion": "Suggests a potential shift in post-training approaches for large language models."}}
{"id": "2505.24139", "pdf": "https://arxiv.org/pdf/2505.24139", "abs": "https://arxiv.org/abs/2505.24139", "authors": ["Yichen Xie", "Runsheng Xu", "Tong He", "Jyh-Jing Hwang", "Katie Luo", "Jingwei Ji", "Hubert Lin", "Letian Chen", "Yiren Lu", "Zhaoqi Leng", "Dragomir Anguelov", "Mingxing Tan"], "title": "S4-Driver: Scalable Self-Supervised Driving Multimodal Large Language Modelwith Spatio-Temporal Visual Representation", "categories": ["cs.CV", "cs.AI"], "comment": "Accepted by CVPR2025; Project website: s4-driver.github.io", "summary": "The latest advancements in multi-modal large language models (MLLMs) have\nspurred a strong renewed interest in end-to-end motion planning approaches for\nautonomous driving. Many end-to-end approaches rely on human annotations to\nlearn intermediate perception and prediction tasks, while purely\nself-supervised approaches--which directly learn from sensor inputs to generate\nplanning trajectories without human annotations often underperform the state of\nthe art. We observe a key gap in the input representation space: end-to-end\napproaches built on MLLMs are often pretrained with reasoning tasks in 2D image\nspace rather than the native 3D space in which autonomous vehicles plan. To\nthis end, we propose S4-Driver, a scalable self-supervised motion planning\nalgorithm with spatio-temporal visual representation, based on the popular PaLI\nmultimodal large language model. S4-Driver uses a novel sparse volume strategy\nto seamlessly transform the strong visual representation of MLLMs from\nperspective view to 3D space without the need to finetune the vision encoder.\nThis representation aggregates multi-view and multi-frame visual inputs and\nenables better prediction of planning trajectories in 3D space. To validate our\nmethod, we run experiments on both nuScenes and Waymo Open Motion Dataset (with\nin-house camera data). Results show that S4-Driver performs favorably against\nexisting supervised multi-task approaches while requiring no human annotations.\nIt also demonstrates great scalability when pretrained on large volumes of\nunannotated driving logs.", "AI": {"tldr": "S4-Driver is a scalable, self-supervised motion planning algorithm for autonomous driving, leveraging MLLMs and a novel sparse volume strategy to improve 3D trajectory prediction without human annotations.", "motivation": "Current end-to-end motion planning approaches either rely on human annotations or underperform in 3D space. S4-Driver addresses this gap by adapting MLLMs for 3D planning.", "method": "S4-Driver uses a sparse volume strategy to transform MLLMs' 2D visual representations into 3D space, aggregating multi-view and multi-frame inputs for better trajectory prediction.", "result": "S4-Driver outperforms supervised multi-task approaches on nuScenes and Waymo datasets, requiring no human annotations and showing scalability with unannotated data.", "conclusion": "S4-Driver demonstrates the effectiveness of self-supervised learning in autonomous driving, bridging the gap between 2D pretraining and 3D planning."}}
{"id": "2501.16168", "pdf": "https://arxiv.org/pdf/2501.16168", "abs": "https://arxiv.org/abs/2501.16168", "authors": ["Artavazd Maranjyan", "Alexander Tyurin", "Peter Richt\u00e1rik"], "title": "Ringmaster ASGD: The First Asynchronous SGD with Optimal Time Complexity", "categories": ["cs.LG", "cs.DC", "math.OC", "stat.ML"], "comment": null, "summary": "Asynchronous Stochastic Gradient Descent (Asynchronous SGD) is a cornerstone\nmethod for parallelizing learning in distributed machine learning. However, its\nperformance suffers under arbitrarily heterogeneous computation times across\nworkers, leading to suboptimal time complexity and inefficiency as the number\nof workers scales. While several Asynchronous SGD variants have been proposed,\nrecent findings by Tyurin & Richt\\'arik (NeurIPS 2023) reveal that none achieve\noptimal time complexity, leaving a significant gap in the literature. In this\npaper, we propose Ringmaster ASGD, a novel Asynchronous SGD method designed to\naddress these limitations and tame the inherent challenges of Asynchronous SGD.\nWe establish, through rigorous theoretical analysis, that Ringmaster ASGD\nachieves optimal time complexity under arbitrarily heterogeneous and\ndynamically fluctuating worker computation times. This makes it the first\nAsynchronous SGD method to meet the theoretical lower bounds for time\ncomplexity in such scenarios.", "AI": {"tldr": "Ringmaster ASGD is a new Asynchronous SGD method achieving optimal time complexity under heterogeneous worker computation times, addressing prior limitations.", "motivation": "Existing Asynchronous SGD variants fail to achieve optimal time complexity under heterogeneous computation times, creating inefficiencies as worker numbers scale.", "method": "Proposes Ringmaster ASGD, a novel method designed to handle heterogeneous and dynamically fluctuating worker computation times.", "result": "Theoretical analysis confirms Ringmaster ASGD achieves optimal time complexity, meeting lower bounds for such scenarios.", "conclusion": "Ringmaster ASGD is the first Asynchronous SGD method to achieve optimal time complexity under heterogeneous conditions, filling a gap in the literature."}}
{"id": "2505.16932", "pdf": "https://arxiv.org/pdf/2505.16932", "abs": "https://arxiv.org/abs/2505.16932", "authors": ["Noah Amsel", "David Persson", "Christopher Musco", "Robert M. Gower"], "title": "The Polar Express: Optimal Matrix Sign Methods and Their Application to the Muon Algorithm", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.NA", "math.NA", "math.OC", "65F30, 68T07, 68N19", "G.1.3; I.2.6; F.2.1; G.1.6"], "comment": "34 pages, 8 figures, 4 algorithms", "summary": "Computing the polar decomposition and the related matrix sign function, has\nbeen a well-studied problem in numerical analysis for decades. More recently,\nit has emerged as an important subroutine in deep learning, particularly within\nthe Muon optimization framework. However, the requirements in this setting\ndiffer significantly from those of traditional numerical analysis. In deep\nlearning, methods must be highly efficient and GPU-compatible, but high\naccuracy is often unnecessary. As a result, classical algorithms like\nNewton-Schulz (which suffers from slow initial convergence) and methods based\non rational functions (which rely on QR decompositions or matrix inverses) are\npoorly suited to this context. In this work, we introduce Polar Express, a\nGPU-friendly algorithm for computing the polar decomposition. Like classical\npolynomial methods such as Newton-Schulz, our approach uses only matrix-matrix\nmultiplications, making it GPU-compatible. Motivated by earlier work of Chen &\nChow and Nakatsukasa & Freund, Polar Express adapts the polynomial update rule\nat each iteration by solving a minimax optimization problem, and we prove that\nit enjoys a strong worst-case optimality guarantee. This property ensures both\nrapid early convergence and fast asymptotic convergence. We also address\nfinite-precision issues, making it stable in bfloat16 in practice. We apply\nPolar Express within the Muon optimization framework and show consistent\nimprovements in validation loss on large-scale models such as GPT-2,\noutperforming recent alternatives across a range of learning rates.", "AI": {"tldr": "Polar Express is a GPU-friendly algorithm for polar decomposition, optimized for deep learning by balancing efficiency and convergence, outperforming classical methods in Muon optimization.", "motivation": "Traditional polar decomposition methods are inefficient for deep learning due to slow convergence or reliance on QR/inversions. Polar Express addresses this by being GPU-compatible and fast.", "method": "Polar Express uses matrix-matrix multiplications and adapts polynomial updates via minimax optimization, ensuring rapid convergence and stability in bfloat16.", "result": "Polar Express improves validation loss in Muon optimization, outperforming alternatives on models like GPT-2 across learning rates.", "conclusion": "Polar Express is a practical, efficient solution for polar decomposition in deep learning, combining speed, stability, and performance."}}
{"id": "2505.20322", "pdf": "https://arxiv.org/pdf/2505.20322", "abs": "https://arxiv.org/abs/2505.20322", "authors": ["Mengru Wang", "Ziwen Xu", "Shengyu Mao", "Shumin Deng", "Zhaopeng Tu", "Huajun Chen", "Ningyu Zhang"], "title": "Beyond Prompt Engineering: Robust Behavior Control in LLMs via Steering Target Atoms", "categories": ["cs.CL", "cs.AI", "cs.CV", "cs.IR", "cs.LG"], "comment": "ACL 2025", "summary": "Precise control over language model generation is vital for ensuring both\nsafety and reliability. Although prompt engineering and steering are commonly\nused to intervene in model behaviors, the vast number of parameters in models\noften results in highly intertwined internal representations. This\ninterdependency can limit control precision and sometimes lead to unintended\nside effects. Recent research has explored the use of sparse autoencoders (SAE)\nto disentangle knowledge in high-dimensional spaces for steering. However,\nthese applications have been limited to toy tasks owing to the nontrivial issue\nof locating atomic knowledge components. In this paper, we propose Steering\nTarget Atoms (STA), a novel method that isolates and manipulates disentangled\nknowledge components to enhance safety. Comprehensive experiments demonstrate\nthe effectiveness of our approach. Further analysis reveals that steering\nexhibits superior robustness and flexibility, particularly in adversarial\nscenarios. We also apply the steering strategy to the large reasoning model,\nconfirming its effectiveness in precise reasoning control.", "AI": {"tldr": "The paper introduces Steering Target Atoms (STA), a method to isolate and manipulate disentangled knowledge components in language models for enhanced safety and control.", "motivation": "Precise control over language model generation is crucial for safety and reliability, but current methods like prompt engineering and steering face limitations due to intertwined internal representations.", "method": "The proposed method, Steering Target Atoms (STA), isolates and manipulates disentangled knowledge components, addressing the challenge of locating atomic knowledge in high-dimensional spaces.", "result": "Experiments show STA's effectiveness in enhancing safety, with superior robustness and flexibility in adversarial scenarios. It also works well for precise reasoning control in large models.", "conclusion": "STA offers a promising approach for precise and robust control of language model behaviors, particularly in safety-critical applications."}}
{"id": "2505.24380", "pdf": "https://arxiv.org/pdf/2505.24380", "abs": "https://arxiv.org/abs/2505.24380", "authors": ["Zheng Wang"], "title": "SASP: Strip-Aware Spatial Perception for Fine-Grained Bird Image Classification", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Fine-grained bird image classification (FBIC) is not only of great\nsignificance for ecological monitoring and species identification, but also\nholds broad research value in the fields of image recognition and fine-grained\nvisual modeling. Compared with general image classification tasks, FBIC poses\nmore formidable challenges: 1) the differences in species size and imaging\ndistance result in the varying sizes of birds presented in the images; 2)\ncomplex natural habitats often introduce strong background interference; 3) and\nhighly flexible poses such as flying, perching, or foraging result in\nsubstantial intra-class variability. These factors collectively make it\ndifficult for traditional methods to stably extract discriminative features,\nthereby limiting the generalizability and interpretability of models in\nreal-world applications. To address these challenges, this paper proposes a\nfine-grained bird classification framework based on strip-aware spatial\nperception, which aims to capture long-range spatial dependencies across entire\nrows or columns in bird images, thereby enhancing the model's robustness and\ninterpretability. The proposed method incorporates two novel modules:\nextensional perception aggregator (EPA) and channel semantic weaving (CSW).\nSpecifically, EPA integrates local texture details with global structural cues\nby aggregating information across horizontal and vertical spatial directions.\nCSW further refines the semantic representations by adaptively fusing\nlong-range and short-range information along the channel dimension. Built upon\na ResNet-50 backbone, the model enables jump-wise connection of extended\nstructural features across the spatial domain. Experimental results on the\nCUB-200-2011 dataset demonstrate that our framework achieves significant\nperformance improvements while maintaining architectural efficiency.", "AI": {"tldr": "A novel framework for fine-grained bird image classification (FBIC) addresses challenges like varying bird sizes, background interference, and pose variability by using strip-aware spatial perception with EPA and CSW modules, achieving improved performance on the CUB-200-2011 dataset.", "motivation": "FBIC is crucial for ecological monitoring and species identification but faces challenges like varying bird sizes, complex backgrounds, and pose variability, limiting traditional methods' effectiveness.", "method": "Proposes a framework with strip-aware spatial perception, featuring two modules: EPA (integrates local and global spatial cues) and CSW (refines semantic representations by fusing long- and short-range channel information), built on ResNet-50.", "result": "The framework significantly improves performance on the CUB-200-2011 dataset while maintaining efficiency.", "conclusion": "The proposed method enhances robustness and interpretability in FBIC, addressing key challenges and outperforming traditional approaches."}}
{"id": "2501.18936", "pdf": "https://arxiv.org/pdf/2501.18936", "abs": "https://arxiv.org/abs/2501.18936", "authors": ["Minh Le", "Anh Nguyen", "Huy Nguyen", "Chau Nguyen", "Anh Tran", "Nhat Ho"], "title": "On the Expressiveness of Visual Prompt Experts", "categories": ["cs.LG", "cs.CV"], "comment": "44 pages, 8 figures, 20 tables", "summary": "Visual Prompt Tuning (VPT) has proven effective for parameter-efficient\nadaptation of pre-trained vision models to downstream tasks by inserting\ntask-specific learnable prompt tokens. Despite its empirical success, a\ncomprehensive theoretical understanding of VPT remains an active area of\nresearch. Building on the recently established connection between Mixture of\nExperts (MoE) and prompt-based methods, wherein each attention head can be\nconceptualized as a composition of multiple MoE models, we reinterpret VPT as\nthe introduction of new prompt experts into these MoE structures. We identify a\nkey limitation in existing VPT frameworks: the restricted functional\nexpressiveness of prompt experts, which remain static and thus limited in their\nadaptability. To address this, we propose Visual Adaptive Prompt Tuning (VAPT),\na novel method that endows prompt experts with enhanced expressiveness while\npreserving parameter efficiency. Empirical evaluations on VTAB-1K and FGVC\ndemonstrate that VAPT achieves substantial performance improvements, surpassing\nfully fine-tuned baselines by 7.34% and 1.04%, respectively. Moreover, VAPT\nconsistently outperforms VPT while requiring fewer additional parameters.\nFurthermore, our theoretical analysis indicates that VAPT achieves optimal\nsample efficiency. Collectively, these results underscore the theoretical\ngrounding and empirical advantages of our approach.", "AI": {"tldr": "VAPT enhances Visual Prompt Tuning (VPT) by introducing adaptive prompt experts, improving performance and sample efficiency over VPT and full fine-tuning.", "motivation": "Existing VPT frameworks lack functional expressiveness in prompt experts, limiting adaptability.", "method": "Proposes Visual Adaptive Prompt Tuning (VAPT), adding adaptive prompt experts to MoE structures for better expressiveness.", "result": "VAPT outperforms VPT and full fine-tuning on VTAB-1K (7.34%) and FGVC (1.04%) with fewer parameters.", "conclusion": "VAPT provides theoretical and empirical advantages, achieving optimal sample efficiency and superior performance."}}
{"id": "2505.18233", "pdf": "https://arxiv.org/pdf/2505.18233", "abs": "https://arxiv.org/abs/2505.18233", "authors": ["Shaghayegh Hosseinpour", "Sanchari Das"], "title": "POSTER: A Multi-Signal Model for Detecting Evasive Smishing", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Smishing, or SMS-based phishing, poses an increasing threat to mobile users\nby mimicking legitimate communications through culturally adapted, concise, and\ndeceptive messages, which can result in the loss of sensitive data or financial\nresources. In such, we present a multi-channel smishing detection model that\ncombines country-specific semantic tagging, structural pattern tagging,\ncharacter-level stylistic cues, and contextual phrase embeddings. We curated\nand relabeled over 84,000 messages across five datasets, including 24,086\nsmishing samples. Our unified architecture achieves 97.89% accuracy, an F1\nscore of 0.963, and an AUC of 99.73%, outperforming single-stream models by\ncapturing diverse linguistic and structural cues. This work demonstrates the\neffectiveness of multi-signal learning in robust and region-aware phishing.", "AI": {"tldr": "A multi-channel smishing detection model combines semantic, structural, and stylistic cues to achieve high accuracy (97.89%) and outperform single-stream models.", "motivation": "Smishing (SMS phishing) is a growing threat, exploiting culturally adapted messages to deceive users and steal sensitive data or money.", "method": "The model integrates country-specific semantic tagging, structural patterns, character-level stylistic cues, and contextual phrase embeddings, using a dataset of 84,000 messages (24,086 smishing samples).", "result": "The model achieves 97.89% accuracy, an F1 score of 0.963, and an AUC of 99.73%, outperforming single-stream approaches.", "conclusion": "Multi-signal learning is effective for robust, region-aware smishing detection."}}
{"id": "2505.22019", "pdf": "https://arxiv.org/pdf/2505.22019", "abs": "https://arxiv.org/abs/2505.22019", "authors": ["Qiuchen Wang", "Ruixue Ding", "Yu Zeng", "Zehui Chen", "Lin Chen", "Shihang Wang", "Pengjun Xie", "Fei Huang", "Feng Zhao"], "title": "VRAG-RL: Empower Vision-Perception-Based RAG for Visually Rich Information Understanding via Iterative Reasoning with Reinforcement Learning", "categories": ["cs.CL", "cs.AI", "cs.CV"], "comment": null, "summary": "Effectively retrieving, reasoning and understanding visually rich information\nremains a challenge for RAG methods. Traditional text-based methods cannot\nhandle visual-related information. On the other hand, current vision-based RAG\napproaches are often limited by fixed pipelines and frequently struggle to\nreason effectively due to the insufficient activation of the fundamental\ncapabilities of models. As RL has been proven to be beneficial for model\nreasoning, we introduce VRAG-RL, a novel RL framework tailored for complex\nreasoning across visually rich information. With this framework, VLMs interact\nwith search engines, autonomously sampling single-turn or multi-turn reasoning\ntrajectories with the help of visual perception tokens and undergoing continual\noptimization based on these samples. Our approach highlights key limitations of\nRL in RAG domains: (i) Prior Multi-modal RAG approaches tend to merely\nincorporate images into the context, leading to insufficient reasoning token\nallocation and neglecting visual-specific perception; and (ii) When models\ninteract with search engines, their queries often fail to retrieve relevant\ninformation due to the inability to articulate requirements, thereby leading to\nsuboptimal performance. To address these challenges, we define an action space\ntailored for visually rich inputs, with actions including cropping and scaling,\nallowing the model to gather information from a coarse-to-fine perspective.\nFurthermore, to bridge the gap between users' original inquiries and the\nretriever, we employ a simple yet effective reward that integrates query\nrewriting and retrieval performance with a model-based reward. Our VRAG-RL\noptimizes VLMs for RAG tasks using specially designed RL strategies, aligning\nthe model with real-world applications. The code is available at\nhttps://github.com/Alibaba-NLP/VRAG.", "AI": {"tldr": "VRAG-RL is a novel RL framework for visually rich RAG tasks, addressing limitations of traditional text-based and current vision-based methods by optimizing VLMs with tailored actions and rewards.", "motivation": "Traditional text-based RAG methods fail with visual information, and current vision-based approaches lack effective reasoning due to insufficient model activation. RL is introduced to enhance reasoning in visually rich contexts.", "method": "VRAG-RL uses RL to optimize VLMs, enabling interaction with search engines and autonomous sampling of reasoning trajectories. It includes actions like cropping and scaling for coarse-to-fine information gathering and integrates query rewriting and retrieval performance in rewards.", "result": "The framework addresses key limitations: insufficient reasoning token allocation in multi-modal RAG and poor retrieval due to unclear queries. It aligns VLMs with real-world applications.", "conclusion": "VRAG-RL effectively enhances reasoning and retrieval in visually rich RAG tasks by leveraging RL strategies and tailored actions, bridging gaps in current approaches."}}
{"id": "2505.24718", "pdf": "https://arxiv.org/pdf/2505.24718", "abs": "https://arxiv.org/abs/2505.24718", "authors": ["Jisheng Dang", "Jingze Wu", "Teng Wang", "Xuanhui Lin", "Nannan Zhu", "Hongbo Chen", "Wei-Shi Zheng", "Meng Wang", "Tat-Seng Chua"], "title": "Reinforcing Video Reasoning with Focused Thinking", "categories": ["cs.CV"], "comment": null, "summary": "Recent advancements in reinforcement learning, particularly through Group\nRelative Policy Optimization (GRPO), have significantly improved multimodal\nlarge language models for complex reasoning tasks. However, two critical\nlimitations persist: 1) they often produce unfocused, verbose reasoning chains\nthat obscure salient spatiotemporal cues and 2) binary rewarding fails to\naccount for partially correct answers, resulting in high reward variance and\ninefficient learning. In this paper, we propose TW-GRPO, a novel framework that\nenhances visual reasoning with focused thinking and dense reward granularity.\nSpecifically, we employs a token weighting mechanism that prioritizes tokens\nwith high informational density (estimated by intra-group variance),\nsuppressing redundant tokens like generic reasoning prefixes. Furthermore, we\nreformulate RL training by shifting from single-choice to multi-choice QA\ntasks, where soft rewards enable finer-grained gradient estimation by\ndistinguishing partial correctness. Additionally, we propose question-answer\ninversion, a data augmentation strategy to generate diverse multi-choice\nsamples from existing benchmarks. Experiments demonstrate state-of-the-art\nperformance on several video reasoning and general understanding benchmarks.\nNotably, TW-GRPO achieves 50.4\\% accuracy on CLEVRER (18.8\\% improvement over\nVideo-R1) and 65.8\\% on MMVU. Our codes are available at\n\\href{https://github.com/longmalongma/TW-GRPO}.", "AI": {"tldr": "TW-GRPO improves multimodal reasoning by focusing on salient tokens and using dense rewards, outperforming prior methods.", "motivation": "Address limitations of verbose reasoning chains and binary rewards in reinforcement learning for multimodal tasks.", "method": "Introduces token weighting for focused reasoning and multi-choice QA with soft rewards, plus question-answer inversion for data augmentation.", "result": "Achieves 50.4% accuracy on CLEVRER (18.8% improvement) and 65.8% on MMVU.", "conclusion": "TW-GRPO advances visual reasoning with focused thinking and granular rewards, setting new benchmarks."}}
{"id": "2501.19040", "pdf": "https://arxiv.org/pdf/2501.19040", "abs": "https://arxiv.org/abs/2501.19040", "authors": ["Huanran Chen", "Yinpeng Dong", "Zeming Wei", "Hang Su", "Jun Zhu"], "title": "Towards the Worst-case Robustness of Large Language Models", "categories": ["cs.LG"], "comment": null, "summary": "Recent studies have revealed the vulnerability of large language models to\nadversarial attacks, where adversaries craft specific input sequences to induce\nharmful, violent, private, or incorrect outputs. In this work, we study their\nworst-case robustness, i.e., whether an adversarial example exists that leads\nto such undesirable outputs. We upper bound the worst-case robustness using\nstronger white-box attacks, indicating that most current deterministic defenses\nachieve nearly 0\\% worst-case robustness. We propose a general tight lower\nbound for randomized smoothing using fractional knapsack solvers or 0-1\nknapsack solvers, and using them to bound the worst-case robustness of all\nstochastic defenses. Based on these solvers, we provide theoretical lower\nbounds for several previous empirical defenses. For example, we certify the\nrobustness of a specific case, smoothing using a uniform kernel, against\n\\textit{any possible attack} with an average $\\ell_0$ perturbation of 2.02 or\nan average suffix length of 6.41.", "AI": {"tldr": "The paper analyzes the worst-case robustness of large language models against adversarial attacks, proposing theoretical bounds for deterministic and stochastic defenses.", "motivation": "To address the vulnerability of large language models to adversarial attacks that induce harmful or incorrect outputs.", "method": "Uses white-box attacks to upper bound worst-case robustness and proposes tight lower bounds for randomized smoothing using knapsack solvers.", "result": "Most deterministic defenses achieve nearly 0% worst-case robustness, while theoretical lower bounds are provided for stochastic defenses.", "conclusion": "The study provides certified robustness for specific cases, demonstrating the effectiveness of the proposed bounds against adversarial attacks."}}
{"id": "2505.18499", "pdf": "https://arxiv.org/pdf/2505.18499", "abs": "https://arxiv.org/abs/2505.18499", "authors": ["Xiaojun Guo", "Ang Li", "Yifei Wang", "Stefanie Jegelka", "Yisen Wang"], "title": "G1: Teaching LLMs to Reason on Graphs with Reinforcement Learning", "categories": ["cs.LG", "cs.AI", "stat.ML"], "comment": null, "summary": "Although Large Language Models (LLMs) have demonstrated remarkable progress,\ntheir proficiency in graph-related tasks remains notably limited, hindering the\ndevelopment of truly general-purpose models. Previous attempts, including\npretraining graph foundation models or employing supervised fine-tuning, often\nface challenges such as the scarcity of large-scale, universally represented\ngraph data. We introduce G1, a simple yet effective approach demonstrating that\nReinforcement Learning (RL) on synthetic graph-theoretic tasks can\nsignificantly scale LLMs' graph reasoning abilities. To enable RL training, we\ncurate Erd\\~os, the largest graph reasoning dataset to date comprising 50\ndiverse graph-theoretic tasks of varying difficulty levels, 100k training data\nand 5k test data, all drived from real-world graphs. With RL on Erd\\~os, G1\nobtains substantial improvements in graph reasoning, where our finetuned 3B\nmodel even outperforms Qwen2.5-72B-Instruct (24x size). RL-trained models also\nshow strong zero-shot generalization to unseen tasks, domains, and graph\nencoding schemes, including other graph-theoretic benchmarks as well as\nreal-world node classification and link prediction tasks, without compromising\ngeneral reasoning abilities. Our findings offer an efficient, scalable path for\nbuilding strong graph reasoners by finetuning LLMs with RL on graph-theoretic\ntasks, which combines the strengths of pretrained LLM capabilities with\nabundant, automatically generated synthetic data, suggesting that LLMs possess\ngraph understanding abilities that RL can elicit successfully. Our\nimplementation is open-sourced at https://github.com/PKU-ML/G1, with models and\ndatasets hosted on Hugging Face collections\nhttps://huggingface.co/collections/PKU-ML/g1-683d659e992794fc99618cf2 for\nbroader accessibility.", "AI": {"tldr": "G1 uses RL on synthetic graph tasks to enhance LLMs' graph reasoning, outperforming larger models and generalizing well.", "motivation": "LLMs struggle with graph tasks due to data scarcity; G1 aims to improve graph reasoning efficiently.", "method": "RL on the Erd\u0151s dataset (50 tasks, 100k training data) to fine-tune LLMs.", "result": "A 3B model outperforms a 24x larger model (Qwen2.5-72B) and shows strong zero-shot generalization.", "conclusion": "RL on synthetic graph tasks is a scalable way to enhance LLMs' graph reasoning without losing general abilities."}}
{"id": "2505.22116", "pdf": "https://arxiv.org/pdf/2505.22116", "abs": "https://arxiv.org/abs/2505.22116", "authors": ["Jintao Zhang", "Zirui Liu", "Mingyue Cheng", "Shilong Zhang", "Tingyue Pan", "Qi Liu", "Yanhu Xie"], "title": "Multimodal Forecasting of Sparse Intraoperative Hypotension Events Powered by Language Model", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Intraoperative hypotension (IOH) frequently occurs under general anesthesia\nand is strongly linked to adverse outcomes such as myocardial injury and\nincreased mortality. Despite its significance, IOH prediction is hindered by\nevent sparsity and the challenge of integrating static and dynamic data across\ndiverse patients. In this paper, we propose \\textbf{IOHFuseLM}, a multimodal\nlanguage model framework. To accurately identify and differentiate sparse\nhypotensive events, we leverage a two-stage training strategy. The first stage\ninvolves domain adaptive pretraining on IOH physiological time series augmented\nthrough diffusion methods, thereby enhancing the model sensitivity to patterns\nassociated with hypotension. Subsequently, task fine-tuning is performed on the\noriginal clinical dataset to further enhance the ability to distinguish\nnormotensive from hypotensive states. To enable multimodal fusion for each\npatient, we align structured clinical descriptions with the corresponding\nphysiological time series at the token level. Such alignment enables the model\nto capture individualized temporal patterns alongside their corresponding\nclinical semantics. In addition, we convert static patient attributes into\nstructured text to enrich personalized information. Experimental evaluations on\ntwo intraoperative datasets demonstrate that IOHFuseLM outperforms established\nbaselines in accurately identifying IOH events, highlighting its applicability\nin clinical decision support scenarios. Our code is publicly available to\npromote reproducibility at https://github.com/zjt-gpu/IOHFuseLM.", "AI": {"tldr": "IOHFuseLM is a multimodal language model for predicting intraoperative hypotension (IOH) using a two-stage training strategy and token-level alignment of clinical and physiological data.", "motivation": "IOH is linked to adverse outcomes, but prediction is challenging due to sparse events and diverse patient data.", "method": "Uses domain adaptive pretraining on augmented physiological time series, followed by task fine-tuning. Aligns clinical descriptions with time series and converts static attributes to text.", "result": "Outperforms baselines in identifying IOH events on two datasets.", "conclusion": "IOHFuseLM is effective for clinical decision support, with code available for reproducibility."}}
{"id": "2506.00541", "pdf": "https://arxiv.org/pdf/2506.00541", "abs": "https://arxiv.org/abs/2506.00541", "authors": ["Huayu Huang", "Banglei Guan", "Yang Shang", "Qifeng Yu"], "title": "3D Trajectory Reconstruction of Moving Points Based on Asynchronous Cameras", "categories": ["cs.CV"], "comment": "This paper has been accepted by Acta Mechanica Sinica", "summary": "Photomechanics is a crucial branch of solid mechanics. The localization of\npoint targets constitutes a fundamental problem in optical experimental\nmechanics, with extensive applications in various missions of UAVs. Localizing\nmoving targets is crucial for analyzing their motion characteristics and\ndynamic properties. Reconstructing the trajectories of points from asynchronous\ncameras is a significant challenge. It encompasses two coupled sub-problems:\ntrajectory reconstruction and camera synchronization. Present methods typically\naddress only one of these sub-problems individually. This paper proposes a 3D\ntrajectory reconstruction method for point targets based on asynchronous\ncameras, simultaneously solving both sub-problems. Firstly, we extend the\ntrajectory intersection method to asynchronous cameras to resolve the\nlimitation of traditional triangulation that requires camera synchronization.\nSecondly, we develop models for camera temporal information and target motion,\nbased on imaging mechanisms and target dynamics characteristics. The parameters\nare optimized simultaneously to achieve trajectory reconstruction without\naccurate time parameters. Thirdly, we optimize the camera rotations alongside\nthe camera time information and target motion parameters, using tighter and\nmore continuous constraints on moving points. The reconstruction accuracy is\nsignificantly improved, especially when the camera rotations are inaccurate.\nFinally, the simulated and real-world experimental results demonstrate the\nfeasibility and accuracy of the proposed method. The real-world results\nindicate that the proposed algorithm achieved a localization error of 112.95 m\nat an observation range of 15 ~ 20 km.", "AI": {"tldr": "A method for 3D trajectory reconstruction of point targets using asynchronous cameras, solving both trajectory reconstruction and camera synchronization simultaneously.", "motivation": "Localizing moving targets is essential for analyzing their motion and dynamics, but current methods address only one sub-problem (trajectory or synchronization) individually.", "method": "Extends trajectory intersection to asynchronous cameras, models camera temporal info and target motion, and optimizes camera rotations and time parameters.", "result": "Improved accuracy, with real-world tests showing a localization error of 112.95 m at 15-20 km range.", "conclusion": "The method is feasible and accurate, addressing limitations of traditional triangulation."}}
{"id": "2502.01042", "pdf": "https://arxiv.org/pdf/2502.01042", "abs": "https://arxiv.org/abs/2502.01042", "authors": ["Peixuan Han", "Cheng Qian", "Xiusi Chen", "Yuji Zhang", "Denghui Zhang", "Heng Ji"], "title": "SafeSwitch: Steering Unsafe LLM Behavior via Internal Activation Signals", "categories": ["cs.LG"], "comment": null, "summary": "Large language models (LLMs) exhibit exceptional capabilities across various\ntasks but also pose risks by generating harmful content. Existing safety\nmechanisms, while improving model safety, often lead to overly cautious\nbehavior and fail to fully leverage LLMs' internal cognitive processes.\nInspired by humans' reflective thinking capability, we first show that LLMs can\nsimilarly perform internal assessments about safety in their internal states.\nBuilding on this insight, we propose SafeSwitch, a dynamic framework that\nregulates unsafe outputs by utilizing the prober-based internal state monitor\nthat actively detects harmful intentions, and activates a safety head that\nleads to safer and more conservative responses only when necessary. SafeSwitch\nreduces harmful outputs by approximately 80% on harmful queries while\nmaintaining strong utility, reaching a Pareto optimal among several methods.\nOur method is also advantageous over traditional methods in offering more\ninformative, context-aware refusals, and achieves these benefits while only\ntuning less than 6% of the original parameters. SafeSwitch demonstrates large\nlanguage models' capacity for self-awareness and reflection regarding safety,\noffering a promising approach to more nuanced and effective safety controls.\nCodes for this work are available at https://github.com/Hanpx20/SafeSwitch.", "AI": {"tldr": "SafeSwitch is a dynamic framework for LLMs that reduces harmful outputs by 80% while maintaining utility, using internal state monitoring and minimal parameter tuning.", "motivation": "Existing safety mechanisms for LLMs are overly cautious and inefficient. SafeSwitch aims to leverage LLMs' internal cognitive processes for better safety control.", "method": "SafeSwitch uses a prober-based internal state monitor to detect harmful intentions and activates a safety head only when necessary.", "result": "Reduces harmful outputs by ~80% on harmful queries, maintains utility, and achieves Pareto optimality. Only tunes <6% of parameters.", "conclusion": "SafeSwitch demonstrates LLMs' self-awareness for safety, offering nuanced and effective control with minimal overhead."}}
{"id": "2505.20697", "pdf": "https://arxiv.org/pdf/2505.20697", "abs": "https://arxiv.org/abs/2505.20697", "authors": ["Zachary C. Brown", "David Carlson"], "title": "Generating Hypotheses of Dynamic Causal Graphs in Neuroscience: Leveraging Generative Factor Models of Observed Time Series", "categories": ["cs.LG", "cs.AI", "stat.AP", "stat.ML"], "comment": null, "summary": "The field of hypothesis generation promises to reduce costs in neuroscience\nby narrowing the range of interventional studies needed to study various\nphenomena. Existing machine learning methods can generate scientific hypotheses\nfrom complex datasets, but many approaches assume causal relationships are\nstatic over time, limiting their applicability to systems with dynamic,\nstate-dependent behavior, such as the brain. While some techniques attempt\ndynamic causal discovery through factor models, they often restrict\nrelationships to linear patterns or impose other simplifying assumptions. We\npropose a novel method that models dynamic graphs as a conditionally weighted\nsuperposition of static graphs, where each static graph can capture nonlinear\nrelationships. This approach enables the detection of complex, time-varying\ninteractions between variables beyond linear limitations. Our method improves\nf1-scores of predicted dynamic causal patterns by roughly 22-28% on average\nover baselines in some of our experiments, with some improvements reaching well\nover 60%. A case study on real brain data demonstrates our method's ability to\nuncover relationships linked to specific behavioral states, offering valuable\ninsights into neural dynamics.", "AI": {"tldr": "A novel method for dynamic causal discovery in neuroscience improves hypothesis generation by modeling time-varying interactions beyond linear assumptions, achieving significant performance gains over baselines.", "motivation": "Existing methods for hypothesis generation in neuroscience often assume static or linear causal relationships, limiting their applicability to dynamic systems like the brain.", "method": "Proposes modeling dynamic graphs as a conditionally weighted superposition of static graphs, capturing nonlinear and time-varying interactions.", "result": "Improves F1-scores by 22-28% on average (up to 60% in some cases) and successfully uncovers neural dynamics in real brain data.", "conclusion": "The method advances dynamic causal discovery, offering better insights into complex systems like the brain."}}
{"id": "2505.22830", "pdf": "https://arxiv.org/pdf/2505.22830", "abs": "https://arxiv.org/abs/2505.22830", "authors": ["Alexander Gill", "Abhilasha Ravichander", "Ana Marasovi\u0107"], "title": "What Has Been Lost with Synthetic Evaluation?", "categories": ["cs.CL", "cs.AI"], "comment": "v2: Fixed low resolution figures", "summary": "Large language models (LLMs) are increasingly used for data generation.\nHowever, creating evaluation benchmarks raises the bar for this emerging\nparadigm. Benchmarks must target specific phenomena, penalize exploiting\nshortcuts, and be challenging. Through two case studies, we investigate whether\nLLMs can meet these demands by generating reasoning over-text benchmarks and\ncomparing them to those created through careful crowdsourcing. Specifically, we\nevaluate both the validity and difficulty of LLM-generated versions of two\nhigh-quality reading comprehension datasets: CondaQA, which evaluates reasoning\nabout negation, and DROP, which targets reasoning about quantities. We find\nthat prompting LLMs can produce variants of these datasets that are often valid\naccording to the annotation guidelines, at a fraction of the cost of the\noriginal crowdsourcing effort. However, we show that they are less challenging\nfor LLMs than their human-authored counterparts. This finding sheds light on\nwhat may have been lost by generating evaluation data with LLMs, and calls for\ncritically reassessing the immediate use of this increasingly prevalent\napproach to benchmark creation.", "AI": {"tldr": "LLMs can generate valid reasoning benchmarks at lower cost but are less challenging than human-authored ones, raising concerns about their use for evaluation.", "motivation": "To assess if LLMs can create high-quality evaluation benchmarks for reasoning tasks, comparing them to human-crowdsourced datasets.", "method": "Case studies using LLM-generated versions of CondaQA (negation reasoning) and DROP (quantity reasoning) datasets, evaluating validity and difficulty.", "result": "LLM-generated benchmarks are valid but less challenging for LLMs than human-authored ones.", "conclusion": "LLMs' use for benchmark creation needs critical reassessment due to reduced challenge and potential quality loss."}}
{"id": "2506.00891", "pdf": "https://arxiv.org/pdf/2506.00891", "abs": "https://arxiv.org/abs/2506.00891", "authors": ["Sa Zhu", "Huashan Chen", "Wanqian Zhang", "Jinchao Zhang", "Zexian Yang", "Xiaoshuai Hao", "Bo Li"], "title": "Uneven Event Modeling for Partially Relevant Video Retrieval", "categories": ["cs.CV", "cs.AI"], "comment": "Accepted by ICME 2025", "summary": "Given a text query, partially relevant video retrieval (PRVR) aims to\nretrieve untrimmed videos containing relevant moments, wherein event modeling\nis crucial for partitioning the video into smaller temporal events that\npartially correspond to the text. Previous methods typically segment videos\ninto a fixed number of equal-length clips, resulting in ambiguous event\nboundaries. Additionally, they rely on mean pooling to compute event\nrepresentations, inevitably introducing undesired misalignment. To address\nthese, we propose an Uneven Event Modeling (UEM) framework for PRVR. We first\nintroduce the Progressive-Grouped Video Segmentation (PGVS) module, to\niteratively formulate events in light of both temporal dependencies and\nsemantic similarity between consecutive frames, enabling clear event\nboundaries. Furthermore, we also propose the Context-Aware Event Refinement\n(CAER) module to refine the event representation conditioned the text's\ncross-attention. This enables event representations to focus on the most\nrelevant frames for a given text, facilitating more precise text-video\nalignment. Extensive experiments demonstrate that our method achieves\nstate-of-the-art performance on two PRVR benchmarks. Code is available at\nhttps://github.com/Sasa77777779/UEM.git.", "AI": {"tldr": "The paper introduces an Uneven Event Modeling (UEM) framework for partially relevant video retrieval (PRVR), addressing issues like ambiguous event boundaries and misalignment in previous methods.", "motivation": "Previous methods for PRVR segment videos into fixed-length clips, leading to unclear event boundaries and misaligned representations.", "method": "Proposes UEM with two modules: Progressive-Grouped Video Segmentation (PGVS) for clear event boundaries and Context-Aware Event Refinement (CAER) for precise text-video alignment.", "result": "Achieves state-of-the-art performance on two PRVR benchmarks.", "conclusion": "UEM effectively improves event modeling and alignment in PRVR, outperforming existing methods."}}
{"id": "2502.01085", "pdf": "https://arxiv.org/pdf/2502.01085", "abs": "https://arxiv.org/abs/2502.01085", "authors": ["Xuhan Huang", "Yan Hu", "Zhiyan Li", "Zhiyong Wang", "Benyou Wang", "Zhongxiang Dai"], "title": "Federated Linear Dueling Bandits", "categories": ["cs.LG"], "comment": null, "summary": "Contextual linear dueling bandits have recently garnered significant\nattention due to their widespread applications in important domains such as\nrecommender systems and large language models. Classical dueling bandit\nalgorithms are typically only applicable to a single agent. However, many\napplications of dueling bandits involve multiple agents who wish to collaborate\nfor improved performance yet are unwilling to share their data. This motivates\nus to draw inspirations from federated learning, which involves multiple agents\naiming to collaboratively train their neural networks via gradient descent (GD)\nwithout sharing their raw data. Previous works have developed federated linear\nbandit algorithms which rely on closed-form updates of the bandit parameters\n(e.g., the linear function parameters) to achieve collaboration. However, in\nlinear dueling bandits, the linear function parameters lack a closed-form\nexpression and their estimation requires minimizing a loss function. This\nrenders these previous methods inapplicable. In this work, we overcome this\nchallenge through an innovative and principled combination of online gradient\ndescent (OGD, for minimizing the loss function to estimate the linear function\nparameters) and federated learning, hence introducing our federated linear\ndueling bandit with OGD (FLDB-OGD) algorithm. Through rigorous theoretical\nanalysis, we prove that FLDB-OGD enjoys a sub-linear upper bound on its\ncumulative regret and demonstrate a theoretical trade-off between regret and\ncommunication complexity. We conduct empirical experiments to demonstrate the\neffectiveness of FLDB-OGD and reveal valuable insights, such as the benefit of\na larger number of agents, the regret-communication trade-off, among others.", "AI": {"tldr": "The paper introduces FLDB-OGD, a federated linear dueling bandit algorithm combining online gradient descent and federated learning, addressing multi-agent collaboration without data sharing.", "motivation": "Classical dueling bandit algorithms are limited to single agents, while real-world applications involve multiple agents unwilling to share data, necessitating a federated approach.", "method": "FLDB-OGD combines online gradient descent (OGD) for parameter estimation with federated learning principles to enable multi-agent collaboration.", "result": "The algorithm achieves sub-linear regret and demonstrates a trade-off between regret and communication complexity, with empirical validation.", "conclusion": "FLDB-OGD effectively addresses the challenge of multi-agent collaboration in linear dueling bandits, offering theoretical guarantees and practical insights."}}
{"id": "2505.23387", "pdf": "https://arxiv.org/pdf/2505.23387", "abs": "https://arxiv.org/abs/2505.23387", "authors": ["Mingzhe Du", "Luu Anh Tuan", "Yue Liu", "Yuhao Qing", "Dong Huang", "Xinyi He", "Qian Liu", "Zejun Ma", "See-kiong Ng"], "title": "Afterburner: Reinforcement Learning Facilitates Self-Improving Code Efficiency Optimization", "categories": ["cs.SE", "cs.AI"], "comment": null, "summary": "Large Language Models (LLMs) generate functionally correct solutions but\noften fall short in code efficiency, a critical bottleneck for real-world\ndeployment. In this paper, we introduce a novel test-time iterative\noptimization framework to address this, employing a closed-loop system where\nLLMs iteratively refine code based on empirical performance feedback from an\nexecution sandbox. We explore three training strategies: Supervised Fine-Tuning\n(SFT), Direct Preference Optimization (DPO), and Group Relative Policy\nOptimization (GRPO). Experiments on our Venus dataset and the APPS benchmark\nshow that SFT and DPO rapidly saturate in efficiency gains. In contrast, GRPO,\nusing reinforcement learning (RL) with execution feedback, continuously\noptimizes code performance, significantly boosting both pass@1 (from 47% to\n62%) and the likelihood of outperforming human submissions in efficiency (from\n31% to 45%). Our work demonstrates effective test-time code efficiency\nimprovement and critically reveals the power of RL in teaching LLMs to truly\nself-improve code efficiency.", "AI": {"tldr": "A novel test-time iterative optimization framework improves LLM-generated code efficiency using reinforcement learning (GRPO), outperforming SFT and DPO.", "motivation": "LLMs often produce inefficient code, hindering real-world deployment. The paper aims to enhance code efficiency through iterative refinement.", "method": "The framework uses a closed-loop system with execution feedback. Three strategies are tested: SFT, DPO, and GRPO (RL-based).", "result": "GRPO significantly improves pass@1 (47% to 62%) and efficiency (31% to 45% vs. humans), while SFT/DPO saturate quickly.", "conclusion": "RL (GRPO) effectively teaches LLMs to self-improve code efficiency, demonstrating its superiority over other methods."}}
{"id": "2505.22848", "pdf": "https://arxiv.org/pdf/2505.22848", "abs": "https://arxiv.org/abs/2505.22848", "authors": ["Pingjun Hong", "Beiduo Chen", "Siyao Peng", "Marie-Catherine de Marneffe", "Barbara Plank"], "title": "LiTEx: A Linguistic Taxonomy of Explanations for Understanding Within-Label Variation in Natural Language Inference", "categories": ["cs.CL"], "comment": "21 pages, 6 figures", "summary": "There is increasing evidence of Human Label Variation (HLV) in Natural\nLanguage Inference (NLI), where annotators assign different labels to the same\npremise-hypothesis pair. However, within-label variation--cases where\nannotators agree on the same label but provide divergent reasoning--poses an\nadditional and mostly overlooked challenge. Several NLI datasets contain\nhighlighted words in the NLI item as explanations, but the same spans on the\nNLI item can be highlighted for different reasons, as evidenced by free-text\nexplanations, which offer a window into annotators' reasoning. To\nsystematically understand this problem and gain insight into the rationales\nbehind NLI labels, we introduce LITEX, a linguistically-informed taxonomy for\ncategorizing free-text explanations. Using this taxonomy, we annotate a subset\nof the e-SNLI dataset, validate the taxonomy's reliability, and analyze how it\naligns with NLI labels, highlights, and explanations. We further assess the\ntaxonomy's usefulness in explanation generation, demonstrating that\nconditioning generation on LITEX yields explanations that are linguistically\ncloser to human explanations than those generated using only labels or\nhighlights. Our approach thus not only captures within-label variation but also\nshows how taxonomy-guided generation for reasoning can bridge the gap between\nhuman and model explanations more effectively than existing strategies.", "AI": {"tldr": "The paper introduces LITEX, a taxonomy for categorizing free-text explanations in NLI to address within-label variation, showing its effectiveness in explanation generation.", "motivation": "To understand and address within-label variation in NLI, where annotators agree on labels but provide divergent reasoning.", "method": "Develop LITEX, a linguistically-informed taxonomy, annotate e-SNLI dataset, validate reliability, and assess alignment with labels, highlights, and explanations.", "result": "LITEX captures within-label variation and improves explanation generation, aligning better with human reasoning than label/highlight-based methods.", "conclusion": "LITEX bridges the gap between human and model explanations, offering a systematic approach to understanding and generating NLI reasoning."}}
{"id": "2506.01921", "pdf": "https://arxiv.org/pdf/2506.01921", "abs": "https://arxiv.org/abs/2506.01921", "authors": ["Minghao Liu", "Zhitao He", "Zhiyuan Fan", "Qingyun Wang", "Yi R. Fung"], "title": "MedEBench: Revisiting Text-instructed Image Editing on Medical Domain", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Text-guided image editing has seen rapid progress in natural image domains,\nbut its adaptation to medical imaging remains limited and lacks standardized\nevaluation. Clinically, such editing holds promise for simulating surgical\noutcomes, creating personalized teaching materials, and enhancing patient\ncommunication. To bridge this gap, we introduce \\textbf{MedEBench}, a\ncomprehensive benchmark for evaluating text-guided medical image editing. It\nconsists of 1,182 clinically sourced image-prompt triplets spanning 70 tasks\nacross 13 anatomical regions. MedEBench offers three key contributions: (1) a\nclinically relevant evaluation framework covering Editing Accuracy, Contextual\nPreservation, and Visual Quality, supported by detailed descriptions of\nexpected change and ROI (Region of Interest) masks; (2) a systematic comparison\nof seven state-of-the-art models, revealing common failure patterns; and (3) a\nfailure analysis protocol based on attention grounding, using IoU between\nattention maps and ROIs to identify mislocalization. MedEBench provides a solid\nfoundation for developing and evaluating reliable, clinically meaningful\nmedical image editing systems.", "AI": {"tldr": "MedEBench is a benchmark for evaluating text-guided medical image editing, addressing the lack of standardized evaluation in the field. It includes 1,182 image-prompt triplets, evaluates seven models, and introduces metrics for accuracy, contextual preservation, and visual quality.", "motivation": "To bridge the gap in standardized evaluation for text-guided medical image editing, which has clinical applications like surgical simulation and patient communication.", "method": "Introduces MedEBench with 1,182 image-prompt triplets across 70 tasks and 13 anatomical regions. Evaluates seven models using metrics like Editing Accuracy, Contextual Preservation, and Visual Quality, and analyzes failures via attention grounding.", "result": "Reveals common failure patterns in models and provides a protocol for failure analysis using attention maps and ROI masks.", "conclusion": "MedEBench offers a foundation for developing reliable, clinically meaningful medical image editing systems."}}
{"id": "2502.01586", "pdf": "https://arxiv.org/pdf/2502.01586", "abs": "https://arxiv.org/abs/2502.01586", "authors": ["Sahar Rajabi", "Nayeema Nonta", "Sirisha Rambhatla"], "title": "SubTrack++ : Gradient Subspace Tracking for Scalable LLM Training", "categories": ["cs.LG"], "comment": null, "summary": "Training large language models (LLMs) is highly resource-intensive due to\ntheir massive number of parameters and the overhead of optimizer states. While\nrecent work has aimed to reduce memory consumption, such efforts often entail\ntrade-offs among memory efficiency, training time, and model performance. Yet,\ntrue democratization of LLMs requires simultaneous progress across all three\ndimensions. To this end, we propose SubTrack++ that leverages Grassmannian\ngradient subspace tracking combined with projection-aware optimizers, enabling\nAdam's internal statistics to adapt to changes in the optimization subspace.\nAdditionally, employing recovery scaling, a technique that restores information\nlost through low-rank projections, further enhances model performance. Our\nmethod demonstrates SOTA convergence by exploiting Grassmannian geometry and\nachieves lowest evaluation loss, outperforming the current SOTA while reducing\npretraining wall time by 43% and maintaining the memory footprint on a\n1B-parameter Llama model.", "AI": {"tldr": "SubTrack++ improves LLM training by reducing memory use and training time without sacrificing performance, using subspace tracking and recovery scaling.", "motivation": "Democratizing LLMs requires progress in memory efficiency, training time, and performance simultaneously.", "method": "Combines Grassmannian gradient subspace tracking with projection-aware optimizers and recovery scaling.", "result": "Achieves SOTA convergence, reduces pretraining time by 43%, and maintains memory footprint on a 1B-parameter model.", "conclusion": "SubTrack++ advances LLM training efficiency across all key dimensions."}}
{"id": "2505.23655", "pdf": "https://arxiv.org/pdf/2505.23655", "abs": "https://arxiv.org/abs/2505.23655", "authors": ["Peter David Fagan"], "title": "Keyed Chaotic Dynamics for Privacy-Preserving Neural Inference", "categories": ["cs.CR", "cs.AI", "94A60, 37N25, 68T05", "D.4.6"], "comment": "10 pages", "summary": "Neural network inference typically operates on raw input data, increasing the\nrisk of exposure during preprocessing and inference. Moreover, neural\narchitectures lack efficient built-in mechanisms for directly authenticating\ninput data. This work introduces a novel encryption method for ensuring the\nsecurity of neural inference. By constructing key-conditioned chaotic graph\ndynamical systems, we enable the encryption and decryption of real-valued\ntensors within the neural architecture. The proposed dynamical systems are\nparticularly suited to encryption due to their sensitivity to initial\nconditions and their capacity to produce complex, key-dependent nonlinear\ntransformations from compact rules. This work establishes a paradigm for\nsecuring neural inference and opens new avenues for research on the application\nof graph dynamical systems in neural network security.", "AI": {"tldr": "A novel encryption method using chaotic graph dynamical systems is introduced to secure neural network inference by encrypting and decrypting real-valued tensors.", "motivation": "Neural networks lack built-in mechanisms for input data authentication, risking exposure during preprocessing and inference.", "method": "Key-conditioned chaotic graph dynamical systems are constructed to encrypt and decrypt real-valued tensors within neural architectures.", "result": "The method leverages sensitivity to initial conditions and complex, key-dependent nonlinear transformations for secure neural inference.", "conclusion": "This work establishes a paradigm for securing neural inference and explores graph dynamical systems for neural network security."}}
{"id": "2505.23001", "pdf": "https://arxiv.org/pdf/2505.23001", "abs": "https://arxiv.org/abs/2505.23001", "authors": ["Yize Cheng", "Wenxiao Wang", "Mazda Moayeri", "Soheil Feizi"], "title": "DyePack: Provably Flagging Test Set Contamination in LLMs Using Backdoors", "categories": ["cs.CL"], "comment": null, "summary": "Open benchmarks are essential for evaluating and advancing large language\nmodels, offering reproducibility and transparency. However, their accessibility\nmakes them likely targets of test set contamination. In this work, we introduce\nDyePack, a framework that leverages backdoor attacks to identify models that\nused benchmark test sets during training, without requiring access to the loss,\nlogits, or any internal details of the model. Like how banks mix dye packs with\ntheir money to mark robbers, DyePack mixes backdoor samples with the test data\nto flag models that trained on it. We propose a principled design incorporating\nmultiple backdoors with stochastic targets, enabling exact false positive rate\n(FPR) computation when flagging every model. This provably prevents false\naccusations while providing strong evidence for every detected case of\ncontamination. We evaluate DyePack on five models across three datasets,\ncovering both multiple-choice and open-ended generation tasks. For\nmultiple-choice questions, it successfully detects all contaminated models with\nguaranteed FPRs as low as 0.000073% on MMLU-Pro and 0.000017% on Big-Bench-Hard\nusing eight backdoors. For open-ended generation tasks, it generalizes well and\nidentifies all contaminated models on Alpaca with a guaranteed false positive\nrate of just 0.127% using six backdoors.", "AI": {"tldr": "DyePack is a framework using backdoor attacks to detect if models trained on benchmark test sets, ensuring low false positive rates and strong evidence for contamination.", "motivation": "Open benchmarks are vulnerable to test set contamination; DyePack addresses this by identifying models that misuse benchmarks.", "method": "DyePack uses backdoor samples in test data to flag contaminated models, with stochastic targets for exact FPR computation.", "result": "Detects all contaminated models with very low FPRs (e.g., 0.000073% on MMLU-Pro) across multiple-choice and open-ended tasks.", "conclusion": "DyePack effectively identifies benchmark misuse with provable guarantees, enhancing benchmark integrity."}}
{"id": "2409.16967", "pdf": "https://arxiv.org/pdf/2409.16967", "abs": "https://arxiv.org/abs/2409.16967", "authors": ["Apoorva Vashisth", "Manav Kulshrestha", "Damon Conover", "Aniket Bera"], "title": "Scalable Multi-Robot Informative Path Planning for Target Mapping via Deep Reinforcement Learning", "categories": ["cs.RO", "cs.CV"], "comment": null, "summary": "Autonomous robots are widely utilized for mapping and exploration tasks due\nto their cost-effectiveness. Multi-robot systems offer scalability and\nefficiency, especially in terms of the number of robots deployed in more\ncomplex environments. These tasks belong to the set of Multi-Robot Informative\nPath Planning (MRIPP) problems. In this paper, we propose a deep reinforcement\nlearning approach for the MRIPP problem. We aim to maximize the number of\ndiscovered stationary targets in an unknown 3D environment while operating\nunder resource constraints (such as path length). Here, each robot aims to\nmaximize discovered targets, avoid unknown static obstacles, and prevent\ninter-robot collisions while operating under communication and resource\nconstraints. We utilize the centralized training and decentralized execution\nparadigm to train a single policy neural network. A key aspect of our approach\nis our coordination graph that prioritizes visiting regions not yet explored by\nother robots. Our learned policy can be copied onto any number of robots for\ndeployment in more complex environments not seen during training. Our approach\noutperforms state-of-the-art approaches by at least 26.2% in terms of the\nnumber of discovered targets while requiring a planning time of less than 2 sec\nper step. We present results for more complex environments with up to 64 robots\nand compare success rates against baseline planners. Our code and trained model\nare available at - https://github.com/AccGen99/marl_ipp", "AI": {"tldr": "A deep reinforcement learning approach for Multi-Robot Informative Path Planning (MRIPP) outperforms state-of-the-art methods by 26.2% in target discovery, with efficient planning under resource constraints.", "motivation": "To enhance scalability and efficiency in multi-robot systems for mapping and exploration tasks, particularly in unknown 3D environments with resource limitations.", "method": "Uses centralized training and decentralized execution with a neural network policy, incorporating a coordination graph to prioritize unexplored regions and avoid collisions.", "result": "Achieves higher target discovery rates (26.2% improvement) and operates efficiently with planning times under 2 seconds per step, even in complex environments with up to 64 robots.", "conclusion": "The proposed method is scalable, efficient, and adaptable to unseen environments, demonstrating superior performance over existing approaches."}}
{"id": "2502.03424", "pdf": "https://arxiv.org/pdf/2502.03424", "abs": "https://arxiv.org/abs/2502.03424", "authors": ["Yuan Xinjie", "Khalid M. Mosalam"], "title": "Prediction of the Most Fire-Sensitive Point in Building Structures with Differentiable Agents for Thermal Simulators", "categories": ["cs.LG"], "comment": "This paper has been accepted by journal Computer-Aided Civil and\n  Infrastructure Engineering", "summary": "Fire safety is crucial for ensuring the stability of building structures, yet\nevaluating whether a structure meets fire safety requirement is challenging.\nFires can originate at any point within a structure, and simulating every\npotential fire scenario is both expensive and time-consuming. To address this\nchallenge, we propose the concept of the Most Fire-Sensitive Point (MFSP) and\nan efficient machine learning framework for its identification. The MFSP is\ndefined as the location at which a fire, if initiated, would cause the most\nsevere detrimental impact on the building's stability, effectively representing\nthe worst-case fire scenario. In our framework, a Graph Neural Network (GNN)\nserves as an efficient and differentiable agent for conventional Finite Element\nAnalysis (FEA) simulators by predicting the Maximum Interstory Drift Ratio\n(MIDR) under fire, which then guides the training and evaluation of the MFSP\npredictor. Additionally, we enhance our framework with a novel edge update\nmechanism and a transfer learning-based training scheme. Evaluations on a\nlarge-scale simulation dataset demonstrate the good performance of the proposed\nframework in identifying the MFSP, offering a transformative tool for\noptimizing fire safety assessments in structural design. All developed datasets\nand codes are open-sourced online.", "AI": {"tldr": "The paper introduces the Most Fire-Sensitive Point (MFSP) and a machine learning framework using GNNs to identify it, optimizing fire safety assessments in buildings.", "motivation": "Evaluating fire safety in buildings is complex and costly due to the unpredictability of fire origins. The MFSP concept addresses this by pinpointing the worst-case fire scenario.", "method": "A Graph Neural Network (GNN) predicts the Maximum Interstory Drift Ratio (MIDR) under fire, guiding MFSP identification. The framework includes an edge update mechanism and transfer learning.", "result": "The framework performs well in identifying MFSPs on a large-scale dataset, proving effective for fire safety optimization.", "conclusion": "The proposed framework offers a transformative tool for efficient fire safety assessments, with open-sourced datasets and codes for broader use."}}
{"id": "2505.23754", "pdf": "https://arxiv.org/pdf/2505.23754", "abs": "https://arxiv.org/abs/2505.23754", "authors": ["Ziyin Zhang", "Jiahao Xu", "Zhiwei He", "Tian Liang", "Qiuzhi Liu", "Yansi Li", "Linfeng Song", "Zhenwen Liang", "Zhuosheng Zhang", "Rui Wang", "Zhaopeng Tu", "Haitao Mi", "Dong Yu"], "title": "DeepTheorem: Advancing LLM Reasoning for Theorem Proving Through Natural Language and Reinforcement Learning", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Theorem proving serves as a major testbed for evaluating complex reasoning\nabilities in large language models (LLMs). However, traditional automated\ntheorem proving (ATP) approaches rely heavily on formal proof systems that\npoorly align with LLMs' strength derived from informal, natural language\nknowledge acquired during pre-training. In this work, we propose DeepTheorem, a\ncomprehensive informal theorem-proving framework exploiting natural language to\nenhance LLM mathematical reasoning. DeepTheorem includes a large-scale\nbenchmark dataset consisting of 121K high-quality IMO-level informal theorems\nand proofs spanning diverse mathematical domains, rigorously annotated for\ncorrectness, difficulty, and topic categories, accompanied by systematically\nconstructed verifiable theorem variants. We devise a novel reinforcement\nlearning strategy (RL-Zero) explicitly tailored to informal theorem proving,\nleveraging the verified theorem variants to incentivize robust mathematical\ninference. Additionally, we propose comprehensive outcome and process\nevaluation metrics examining proof correctness and the quality of reasoning\nsteps. Extensive experimental analyses demonstrate DeepTheorem significantly\nimproves LLM theorem-proving performance compared to existing datasets and\nsupervised fine-tuning protocols, achieving state-of-the-art accuracy and\nreasoning quality. Our findings highlight DeepTheorem's potential to\nfundamentally advance automated informal theorem proving and mathematical\nexploration.", "AI": {"tldr": "DeepTheorem is a framework for informal theorem proving using natural language to enhance LLM reasoning, featuring a large dataset, reinforcement learning, and evaluation metrics, achieving state-of-the-art results.", "motivation": "Traditional ATP methods misalign with LLMs' natural language strengths, prompting the need for an informal theorem-proving framework.", "method": "DeepTheorem includes a 121K theorem dataset, RL-Zero reinforcement learning, and evaluation metrics for proof correctness and reasoning quality.", "result": "DeepTheorem outperforms existing methods, achieving top accuracy and reasoning quality in LLM theorem proving.", "conclusion": "DeepTheorem advances informal theorem proving and mathematical exploration, demonstrating significant improvements over traditional approaches."}}
{"id": "2505.23114", "pdf": "https://arxiv.org/pdf/2505.23114", "abs": "https://arxiv.org/abs/2505.23114", "authors": ["Seohyeong Lee", "Eunwon Kim", "Hwaran Lee", "Buru Chang"], "title": "Dataset Cartography for Large Language Model Alignment: Mapping and Diagnosing Preference Data", "categories": ["cs.CL"], "comment": null, "summary": "Human preference data plays a critical role in aligning large language models\n(LLMs) with human values. However, collecting such data is often expensive and\ninefficient, posing a significant scalability challenge. To address this, we\nintroduce Alignment Data Map, a GPT-4o-assisted tool for analyzing and\ndiagnosing preference data. Using GPT-4o as a proxy for LLM alignment, we\ncompute alignment scores for LLM-generated responses to instructions from\nexisting preference datasets. These scores are then used to construct an\nAlignment Data Map based on their mean and variance. Our experiments show that\nusing only 33 percent of the data, specifically samples in the high-mean,\nlow-variance region, achieves performance comparable to or better than using\nthe entire dataset. This finding suggests that the Alignment Data Map can\nsignificantly improve data collection efficiency by identifying high-quality\nsamples for LLM alignment without requiring explicit annotations. Moreover, the\nAlignment Data Map can diagnose existing preference datasets. Our analysis\nshows that it effectively detects low-impact or potentially misannotated\nsamples. Source code is available online.", "AI": {"tldr": "Alignment Data Map, a GPT-4o-assisted tool, improves efficiency in collecting human preference data for LLM alignment by identifying high-quality samples without explicit annotations.", "motivation": "Human preference data is costly and inefficient to collect, hindering scalability in aligning LLMs with human values.", "method": "Uses GPT-4o to compute alignment scores for LLM responses, constructs a map based on mean and variance, and identifies high-quality samples.", "result": "Using 33% of high-quality data achieves comparable or better performance than the full dataset.", "conclusion": "The Alignment Data Map enhances data efficiency and diagnoses dataset quality, reducing reliance on costly annotations."}}
{"id": "2502.03569", "pdf": "https://arxiv.org/pdf/2502.03569", "abs": "https://arxiv.org/abs/2502.03569", "authors": ["Michelle M. Li", "Kevin Li", "Yasha Ektefaie", "Ying Jin", "Yepeng Huang", "Shvat Messica", "Tianxi Cai", "Marinka Zitnik"], "title": "Controllable Sequence Editing for Biological and Clinical Trajectories", "categories": ["cs.LG", "q-bio.GN", "q-bio.PE"], "comment": null, "summary": "Conditional generation models for longitudinal sequences can generate new or\nmodified trajectories given a conditioning input. While effective at generating\nentire sequences, these models typically lack control over the timing and scope\nof the edits. Most existing approaches either operate on univariate sequences\nor assume that the condition affects all variables and time steps. However,\nmany scientific and clinical applications require more precise interventions,\nwhere a condition takes effect only after a specific time and influences only a\nsubset of variables. We introduce CLEF, a controllable sequence editing model\nfor conditional generation of immediate and delayed effects in multivariate\nlongitudinal sequences. CLEF learns temporal concepts that encode how and when\na condition alters future sequence evolution. These concepts allow CLEF to\napply targeted edits to the affected time steps and variables while preserving\nthe rest of the sequence. We evaluate CLEF on 6 datasets spanning cellular\nreprogramming and patient health trajectories, comparing against 9\nstate-of-the-art baselines. CLEF improves immediate sequence editing accuracy\nby up to 36.01% (MAE). Unlike prior models, CLEF enables one-step conditional\ngeneration at arbitrary future times, outperforming them in delayed sequence\nediting by up to 65.71% (MAE). We test CLEF under counterfactual inference\nassumptions and show up to 63.19% (MAE) improvement on zero-shot conditional\ngeneration of counterfactual trajectories. In a case study of patients with\ntype 1 diabetes mellitus, CLEF identifies clinical interventions that generate\nrealistic counterfactual trajectories shifted toward healthier outcomes.", "AI": {"tldr": "CLEF is a controllable sequence editing model for precise conditional generation in multivariate longitudinal sequences, outperforming baselines in accuracy and enabling targeted edits.", "motivation": "Existing models lack control over timing and scope of edits in longitudinal sequences, limiting their applicability in scientific and clinical settings.", "method": "CLEF learns temporal concepts to encode how and when conditions alter sequences, enabling targeted edits while preserving unaffected parts.", "result": "CLEF improves immediate editing accuracy by up to 36.01% (MAE) and delayed editing by up to 65.71% (MAE), with significant gains in counterfactual generation.", "conclusion": "CLEF enables precise, one-step conditional generation at arbitrary times, demonstrating effectiveness in clinical applications like diabetes management."}}
{"id": "2505.23807", "pdf": "https://arxiv.org/pdf/2505.23807", "abs": "https://arxiv.org/abs/2505.23807", "authors": ["Yuli Chen", "Bo Cheng", "Jiale Han", "Yingying Zhang", "Yingting Li", "Shuhao Zhang"], "title": "DLP: Dynamic Layerwise Pruning in Large Language Models", "categories": ["cs.CL", "cs.AI"], "comment": "Accepted by ICML 2025", "summary": "Pruning has recently been widely adopted to reduce the parameter scale and\nimprove the inference efficiency of Large Language Models (LLMs). Mainstream\npruning techniques often rely on uniform layerwise pruning strategies, which\ncan lead to severe performance degradation at high sparsity levels. Recognizing\nthe varying contributions of different layers in LLMs, recent studies have\nshifted their focus toward non-uniform layerwise pruning. However, these\napproaches often rely on pre-defined values, which can result in suboptimal\nperformance. To overcome these limitations, we propose a novel method called\nDynamic Layerwise Pruning (DLP). This approach adaptively determines the\nrelative importance of each layer by integrating model weights with input\nactivation information, assigning pruning rates accordingly. Experimental\nresults show that DLP effectively preserves model performance at high sparsity\nlevels across multiple LLMs. Specifically, at 70% sparsity, DLP reduces the\nperplexity of LLaMA2-7B by 7.79 and improves the average accuracy by 2.7%\ncompared to state-of-the-art methods. Moreover, DLP is compatible with various\nexisting LLM compression techniques and can be seamlessly integrated into\nParameter-Efficient Fine-Tuning (PEFT). We release the code at\nhttps://github.com/ironartisan/DLP to facilitate future research.", "AI": {"tldr": "DLP is a dynamic layerwise pruning method for LLMs that adaptively assigns pruning rates based on layer importance, outperforming uniform and pre-defined non-uniform methods at high sparsity.", "motivation": "Uniform pruning degrades performance at high sparsity, and pre-defined non-uniform methods are suboptimal. DLP aims to dynamically optimize pruning.", "method": "DLP integrates model weights and input activation to determine layer importance and assign adaptive pruning rates.", "result": "At 70% sparsity, DLP reduces perplexity by 7.79 and improves accuracy by 2.7% for LLaMA2-7B, outperforming state-of-the-art methods.", "conclusion": "DLP is effective, compatible with other compression techniques, and integrates well with PEFT. Code is released for future research."}}
{"id": "2505.23368", "pdf": "https://arxiv.org/pdf/2505.23368", "abs": "https://arxiv.org/abs/2505.23368", "authors": ["Beiduo Chen", "Yang Janet Liu", "Anna Korhonen", "Barbara Plank"], "title": "Threading the Needle: Reweaving Chain-of-Thought Reasoning to Explain Human Label Variation", "categories": ["cs.CL"], "comment": "22 pages, 7 figures", "summary": "The recent rise of reasoning-tuned Large Language Models (LLMs)--which\ngenerate chains of thought (CoTs) before giving the final answer--has attracted\nsignificant attention and offers new opportunities for gaining insights into\nhuman label variation, which refers to plausible differences in how multiple\nannotators label the same data instance. Prior work has shown that\nLLM-generated explanations can help align model predictions with human label\ndistributions, but typically adopt a reverse paradigm: producing explanations\nbased on given answers. In contrast, CoTs provide a forward reasoning path that\nmay implicitly embed rationales for each answer option, before generating the\nanswers. We thus propose a novel LLM-based pipeline enriched with\nlinguistically-grounded discourse segmenters to extract supporting and opposing\nstatements for each answer option from CoTs with improved accuracy. We also\npropose a rank-based HLV evaluation framework that prioritizes the ranking of\nanswers over exact scores, which instead favor direct comparison of label\ndistributions. Our method outperforms a direct generation method as well as\nbaselines on three datasets, and shows better alignment of ranking methods with\nhumans, highlighting the effectiveness of our approach.", "AI": {"tldr": "The paper introduces a novel LLM-based pipeline using linguistically-grounded discourse segmenters to extract supporting and opposing statements from CoTs, improving accuracy in human label variation analysis. It also proposes a rank-based evaluation framework, outperforming baselines and aligning better with human rankings.", "motivation": "To address human label variation by leveraging reasoning-tuned LLMs and CoTs, which provide forward reasoning paths, unlike prior reverse paradigms.", "method": "A novel LLM-based pipeline with linguistically-grounded discourse segmenters to extract statements from CoTs, and a rank-based evaluation framework for HLV.", "result": "Outperforms direct generation methods and baselines on three datasets, showing better alignment with human rankings.", "conclusion": "The proposed approach effectively leverages CoTs and a rank-based framework to improve accuracy and alignment with human label variation."}}
{"id": "2412.04339", "pdf": "https://arxiv.org/pdf/2412.04339", "abs": "https://arxiv.org/abs/2412.04339", "authors": ["George Webber", "Yuya Mizuno", "Oliver D. Howes", "Alexander Hammers", "Andrew P. King", "Andrew J. Reader"], "title": "Likelihood-Scheduled Score-Based Generative Modeling for Fully 3D PET Image Reconstruction", "categories": ["physics.med-ph", "cs.CV", "cs.LG"], "comment": "12 pages, 14 figures. Author's accepted manuscript, IEEE Transactions\n  on Medical Imaging", "summary": "Medical image reconstruction with pre-trained score-based generative models\n(SGMs) has advantages over other existing state-of-the-art deep-learned\nreconstruction methods, including improved resilience to different scanner\nsetups and advanced image distribution modeling. SGM-based reconstruction has\nrecently been applied to simulated positron emission tomography (PET) datasets,\nshowing improved contrast recovery for out-of-distribution lesions relative to\nthe state-of-the-art. However, existing methods for SGM-based reconstruction\nfrom PET data suffer from slow reconstruction, burdensome hyperparameter tuning\nand slice inconsistency effects (in 3D). In this work, we propose a practical\nmethodology for fully 3D reconstruction that accelerates reconstruction and\nreduces the number of critical hyperparameters by matching the likelihood of an\nSGM's reverse diffusion process to a current iterate of the maximum-likelihood\nexpectation maximization algorithm. Using the example of low-count\nreconstruction from simulated [$^{18}$F]DPA-714 datasets, we show our\nmethodology can match or improve on the NRMSE and SSIM of existing\nstate-of-the-art SGM-based PET reconstruction while reducing reconstruction\ntime and the need for hyperparameter tuning. We evaluate our methodology\nagainst state-of-the-art supervised and conventional reconstruction algorithms.\nFinally, we demonstrate a first-ever implementation of SGM-based reconstruction\nfor real 3D PET data, specifically [$^{18}$F]DPA-714 data, where we integrate\nperpendicular pre-trained SGMs to eliminate slice inconsistency issues.", "AI": {"tldr": "The paper proposes a faster, hyperparameter-efficient 3D reconstruction method for PET using pre-trained SGMs, addressing slow reconstruction and slice inconsistency issues while maintaining or improving image quality.", "motivation": "Existing SGM-based PET reconstruction methods are slow, require extensive hyperparameter tuning, and suffer from slice inconsistency in 3D. The goal is to overcome these limitations.", "method": "The method matches the likelihood of an SGM's reverse diffusion process to a current iterate of the maximum-likelihood expectation maximization algorithm, enabling faster, fully 3D reconstruction.", "result": "The proposed method matches or improves NRMSE and SSIM over state-of-the-art SGM-based PET reconstruction while reducing time and hyperparameter tuning. It also successfully integrates pre-trained SGMs for real 3D PET data.", "conclusion": "The methodology advances SGM-based PET reconstruction by addressing key limitations, demonstrating practical viability for real-world applications."}}
{"id": "2502.05446", "pdf": "https://arxiv.org/pdf/2502.05446", "abs": "https://arxiv.org/abs/2502.05446", "authors": ["Haoye Lu", "Qifan Wu", "Yaoliang Yu"], "title": "Stochastic Forward-Backward Deconvolution: Training Diffusion Models with Finite Noisy Datasets", "categories": ["cs.LG"], "comment": null, "summary": "Recent diffusion-based generative models achieve remarkable results by\ntraining on massive datasets, yet this practice raises concerns about\nmemorization and copyright infringement. A proposed remedy is to train\nexclusively on noisy data with potential copyright issues, ensuring the model\nnever observes original content. However, through the lens of deconvolution\ntheory, we show that although it is theoretically feasible to learn the data\ndistribution from noisy samples, the practical challenge of collecting\nsufficient samples makes successful learning nearly unattainable. To overcome\nthis limitation, we propose to pretrain the model with a small fraction of\nclean data to guide the deconvolution process. Combined with our Stochastic\nForward--Backward Deconvolution (SFBD) method, we attain FID 6.31 on CIFAR-10\nwith just 4% clean images (and 3.58 with 10%). We also provide theoretical\nguarantees that SFBD learns the true data distribution. These results\nunderscore the value of limited clean pretraining, or pretraining on similar\ndatasets. Empirical studies further validate and enrich our findings.", "AI": {"tldr": "Training diffusion models on noisy data to avoid copyright issues is theoretically possible but practically challenging. Pretraining with a small fraction of clean data and using SFBD improves performance, achieving FID 6.31 on CIFAR-10 with 4% clean images.", "motivation": "Address concerns about memorization and copyright infringement in diffusion models by training on noisy data, while overcoming practical challenges.", "method": "Propose pretraining with a small fraction of clean data and introduce Stochastic Forward--Backward Deconvolution (SFBD) to guide learning.", "result": "Achieve FID 6.31 on CIFAR-10 with 4% clean images (3.58 with 10%). Theoretical guarantees confirm SFBD learns the true data distribution.", "conclusion": "Limited clean pretraining or pretraining on similar datasets is valuable, as validated by empirical studies."}}
{"id": "2505.23809", "pdf": "https://arxiv.org/pdf/2505.23809", "abs": "https://arxiv.org/abs/2505.23809", "authors": ["Haowei Yang", "Haotian Lyu", "Tianle Zhang", "Dingzhou Wang", "Yushang Zhao"], "title": "LLM-Driven E-Commerce Marketing Content Optimization: Balancing Creativity and Conversion", "categories": ["cs.CL", "cs.AI", "cs.IR"], "comment": null, "summary": "As e-commerce competition intensifies, balancing creative content with\nconversion effectiveness becomes critical. Leveraging LLMs' language generation\ncapabilities, we propose a framework that integrates prompt engineering,\nmulti-objective fine-tuning, and post-processing to generate marketing copy\nthat is both engaging and conversion-driven. Our fine-tuning method combines\nsentiment adjustment, diversity enhancement, and CTA embedding. Through offline\nevaluations and online A/B tests across categories, our approach achieves a\n12.5 % increase in CTR and an 8.3 % increase in CVR while maintaining content\nnovelty. This provides a practical solution for automated copy generation and\nsuggests paths for future multimodal, real-time personalization.", "AI": {"tldr": "A framework using LLMs for marketing copy generation boosts CTR by 12.5% and CVR by 8.3% while maintaining novelty.", "motivation": "To balance creative content and conversion effectiveness in competitive e-commerce.", "method": "Integrates prompt engineering, multi-objective fine-tuning (sentiment, diversity, CTA), and post-processing.", "result": "12.5% CTR and 8.3% CVR increase, with maintained content novelty.", "conclusion": "Offers a practical solution for automated copy generation and hints at future multimodal, real-time personalization."}}
{"id": "2505.24133", "pdf": "https://arxiv.org/pdf/2505.24133", "abs": "https://arxiv.org/abs/2505.24133", "authors": ["Zefan Cai", "Wen Xiao", "Hanshi Sun", "Cheng Luo", "Yikai Zhang", "Ke Wan", "Yucheng Li", "Yeyang Zhou", "Li-Wen Chang", "Jiuxiang Gu", "Zhen Dong", "Anima Anandkumar", "Abedelkadir Asi", "Junjie Hu"], "title": "R-KV: Redundancy-aware KV Cache Compression for Training-Free Reasoning Models Acceleration", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Reasoning models have demonstrated impressive performance in self-reflection\nand chain-of-thought reasoning. However, they often produce excessively long\noutputs, leading to prohibitively large key-value (KV) caches during inference.\nWhile chain-of-thought inference significantly improves performance on complex\nreasoning tasks, it can also lead to reasoning failures when deployed with\nexisting KV cache compression approaches. To address this, we propose\nRedundancy-aware KV Cache Compression for Reasoning models (R-KV), a novel\nmethod specifically targeting redundant tokens in reasoning models. Our method\npreserves nearly 100% of the full KV cache performance using only 10% of the KV\ncache, substantially outperforming existing KV cache baselines, which reach\nonly 60% of the performance. Remarkably, R-KV even achieves 105% of full KV\ncache performance with 16% of the KV cache. This KV-cache reduction also leads\nto a 90% memory saving and a 6.6X throughput over standard chain-of-thought\nreasoning inference. Experimental results show that R-KV consistently\noutperforms existing KV cache compression baselines across two mathematical\nreasoning datasets.", "AI": {"tldr": "R-KV is a redundancy-aware KV cache compression method for reasoning models, achieving near-full performance with only 10% of the cache, outperforming baselines and saving memory.", "motivation": "Existing KV cache compression methods fail with reasoning models, leading to performance drops and inefficiencies.", "method": "R-KV targets redundant tokens in reasoning models, compressing the KV cache while preserving performance.", "result": "R-KV achieves 100% performance with 10% cache, 105% with 16%, and saves 90% memory with 6.6X throughput.", "conclusion": "R-KV is a superior KV cache compression method for reasoning models, outperforming baselines in efficiency and performance."}}
{"id": "2502.01536", "pdf": "https://arxiv.org/pdf/2502.01536", "abs": "https://arxiv.org/abs/2502.01536", "authors": ["Shaoting Zhu", "Linzhan Mou", "Derun Li", "Baijun Ye", "Runhan Huang", "Hang Zhao"], "title": "VR-Robo: A Real-to-Sim-to-Real Framework for Visual Robot Navigation and Locomotion", "categories": ["cs.RO", "cs.CV"], "comment": "Project Page: https://vr-robo.github.io/", "summary": "Recent success in legged robot locomotion is attributed to the integration of\nreinforcement learning and physical simulators. However, these policies often\nencounter challenges when deployed in real-world environments due to\nsim-to-real gaps, as simulators typically fail to replicate visual realism and\ncomplex real-world geometry. Moreover, the lack of realistic visual rendering\nlimits the ability of these policies to support high-level tasks requiring\nRGB-based perception like ego-centric navigation. This paper presents a\nReal-to-Sim-to-Real framework that generates photorealistic and physically\ninteractive \"digital twin\" simulation environments for visual navigation and\nlocomotion learning. Our approach leverages 3D Gaussian Splatting (3DGS) based\nscene reconstruction from multi-view images and integrates these environments\ninto simulations that support ego-centric visual perception and mesh-based\nphysical interactions. To demonstrate its effectiveness, we train a\nreinforcement learning policy within the simulator to perform a visual\ngoal-tracking task. Extensive experiments show that our framework achieves\nRGB-only sim-to-real policy transfer. Additionally, our framework facilitates\nthe rapid adaptation of robot policies with effective exploration capability in\ncomplex new environments, highlighting its potential for applications in\nhouseholds and factories.", "AI": {"tldr": "A Real-to-Sim-to-Real framework using 3D Gaussian Splatting for photorealistic simulations enables sim-to-real policy transfer for legged robots, addressing visual and physical gaps.", "motivation": "Overcome sim-to-real gaps in legged robot locomotion by creating photorealistic simulations that support visual navigation and physical interactions.", "method": "Leverages 3D Gaussian Splatting for scene reconstruction from multi-view images, integrating these into simulations for visual perception and physical interactions.", "result": "Achieves RGB-only sim-to-real policy transfer and enables rapid adaptation in complex environments.", "conclusion": "The framework shows promise for real-world applications like households and factories by bridging the sim-to-real gap effectively."}}
{"id": "2502.07783", "pdf": "https://arxiv.org/pdf/2502.07783", "abs": "https://arxiv.org/abs/2502.07783", "authors": ["Leyang Hu", "Matteo Gamba", "Randall Balestriero"], "title": "Curvature Tuning: Provable Training-free Model Steering From a Single Parameter", "categories": ["cs.LG"], "comment": null, "summary": "The scaling of model and data sizes has reshaped the AI landscape,\nestablishing finetuning pretrained models as the standard paradigm for solving\ndownstream tasks. However, dominant finetuning methods typically rely on weight\nadaptation, often lack interpretability, and depend on heuristically chosen\nhyperparameters. In this paper, we take a different perspective and shift the\nfocus from weights to activation functions, viewing them through the lens of\nspline operators. We propose Curvature Tuning (CT), an interpretable and\nprincipled steering method that modulates a model's decision boundary by\ninjecting a single hyperparameter into its activation functions. We show that\nCT provably adjusts model decision boundary curvature and, more fundamentally,\nprojects a model onto a space of smooth functions-thereby complementing current\nfinetuning methods, whose effect lies primarily in feature adaptation. Making\nthis hyperparameter trainable gives rise to a novel and highly\nparameter-efficient finetuning method. Empirically, CT improves both\ngeneralization and robustness. For example, it boosts downstream accuracy of\nResNet-50/152 by 7.14%/8.46% over linear probing and 4.64%/1.70% over LoRA\nacross 12 datasets, and improves robust accuracy on the $\\ell_\\infty$ benchmark\nfrom RobustBench by 1032.64%/1494.46%. Our code is available at\nhttps://github.com/Leon-Leyang/curvature-tuning.", "AI": {"tldr": "The paper introduces Curvature Tuning (CT), a method to adjust model decision boundaries by modifying activation functions, offering interpretability and improved performance over traditional finetuning.", "motivation": "Current finetuning methods lack interpretability and rely on heuristic hyperparameters. The paper aims to address this by focusing on activation functions.", "method": "CT modulates decision boundaries by injecting a hyperparameter into activation functions, projecting models onto smooth function spaces.", "result": "CT improves ResNet-50/152 accuracy by 7.14%/8.46% over linear probing and boosts robust accuracy by 1032.64%/1494.46%.", "conclusion": "CT provides an interpretable, efficient finetuning alternative, enhancing both generalization and robustness."}}
{"id": "2505.23868", "pdf": "https://arxiv.org/pdf/2505.23868", "abs": "https://arxiv.org/abs/2505.23868", "authors": ["Zhaokun Wang", "Jinyu Guo", "Jingwen Pu", "Lingfeng Chen", "Hongli Pu", "Jie Ou", "Libo Qin", "Wenhong Tian"], "title": "Noise-Robustness Through Noise: Asymmetric LoRA Adaption with Poisoning Expert", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Current parameter-efficient fine-tuning methods for adapting pre-trained\nlanguage models to downstream tasks are susceptible to interference from noisy\ndata. Conventional noise-handling approaches either rely on laborious data\npre-processing or employ model architecture modifications prone to error\naccumulation. In contrast to existing noise-process paradigms, we propose a\nnoise-robust adaptation method via asymmetric LoRA poisoning experts (LoPE), a\nnovel framework that enhances model robustness to noise only with generated\nnoisy data. Drawing inspiration from the mixture-of-experts architecture, LoPE\nstrategically integrates a dedicated poisoning expert in an asymmetric LoRA\nconfiguration. Through a two-stage paradigm, LoPE performs noise injection on\nthe poisoning expert during fine-tuning to enhance its noise discrimination and\nprocessing ability. During inference, we selectively mask the dedicated\npoisoning expert to leverage purified knowledge acquired by normal experts for\nnoise-robust output. Extensive experiments demonstrate that LoPE achieves\nstrong performance and robustness purely through the low-cost noise injection,\nwhich completely eliminates the requirement of data cleaning.", "AI": {"tldr": "Proposes LoPE, a noise-robust adaptation method using asymmetric LoRA poisoning experts to handle noisy data without data cleaning.", "motivation": "Current fine-tuning methods struggle with noisy data, requiring laborious pre-processing or error-prone architecture changes.", "method": "LoPE integrates a poisoning expert in an asymmetric LoRA setup, injecting noise during fine-tuning and masking it during inference.", "result": "LoPE achieves strong performance and robustness purely through noise injection, eliminating data cleaning needs.", "conclusion": "LoPE offers a low-cost, effective solution for noise-robust fine-tuning without data pre-processing."}}
{"id": "2505.24539", "pdf": "https://arxiv.org/pdf/2505.24539", "abs": "https://arxiv.org/abs/2505.24539", "authors": ["Celia Cintas", "Miriam Rateike", "Erik Miehling", "Elizabeth Daly", "Skyler Speakman"], "title": "Localizing Persona Representations in LLMs", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "We present a study on how and where personas -- defined by distinct sets of\nhuman characteristics, values, and beliefs -- are encoded in the representation\nspace of large language models (LLMs). Using a range of dimension reduction and\npattern recognition methods, we first identify the model layers that show the\ngreatest divergence in encoding these representations. We then analyze the\nactivations within a selected layer to examine how specific personas are\nencoded relative to others, including their shared and distinct embedding\nspaces. We find that, across multiple pre-trained decoder-only LLMs, the\nanalyzed personas show large differences in representation space only within\nthe final third of the decoder layers. We observe overlapping activations for\nspecific ethical perspectives -- such as moral nihilism and utilitarianism --\nsuggesting a degree of polysemy. In contrast, political ideologies like\nconservatism and liberalism appear to be represented in more distinct regions.\nThese findings help to improve our understanding of how LLMs internally\nrepresent information and can inform future efforts in refining the modulation\nof specific human traits in LLM outputs. Warning: This paper includes\npotentially offensive sample statements.", "AI": {"tldr": "The study explores how personas (human traits, values, beliefs) are encoded in LLMs, identifying layers with the most divergence and analyzing activations to reveal shared and distinct embedding spaces.", "motivation": "To understand how LLMs internally represent human personas and traits, aiding future efforts to modulate such traits in model outputs.", "method": "Uses dimension reduction and pattern recognition to identify divergent layers and analyzes activations to compare persona embeddings.", "result": "Personas show large differences in the final third of decoder layers, with overlapping activations for ethical perspectives but distinct regions for political ideologies.", "conclusion": "The findings enhance understanding of LLM representations and can guide refinement of trait modulation in outputs."}}
{"id": "2503.10633", "pdf": "https://arxiv.org/pdf/2503.10633", "abs": "https://arxiv.org/abs/2503.10633", "authors": ["Eliahu Horwitz", "Nitzan Kurer", "Jonathan Kahana", "Liel Amar", "Yedid Hoshen"], "title": "We Should Chart an Atlas of All the World's Models", "categories": ["cs.LG", "cs.CL", "cs.CV"], "comment": "Project page: https://horwitz.ai/model-atlas", "summary": "Public model repositories now contain millions of models, yet most models\nremain undocumented and effectively lost. In this position paper, we advocate\nfor charting the world's model population in a unified structure we call the\nModel Atlas: a graph that captures models, their attributes, and the weight\ntransformations that connect them. The Model Atlas enables applications in\nmodel forensics, meta-ML research, and model discovery, challenging tasks given\ntoday's unstructured model repositories. However, because most models lack\ndocumentation, large atlas regions remain uncharted. Addressing this gap\nmotivates new machine learning methods that treat models themselves as data,\ninferring properties such as functionality, performance, and lineage directly\nfrom their weights. We argue that a scalable path forward is to bypass the\nunique parameter symmetries that plague model weights. Charting all the world's\nmodels will require a community effort, and we hope its broad utility will\nrally researchers toward this goal.", "AI": {"tldr": "The paper proposes the Model Atlas, a unified graph structure to document and connect models, addressing the lack of documentation in public repositories. It highlights applications in model forensics, meta-ML research, and discovery, and calls for community effort to chart models using new ML methods.", "motivation": "Most models in public repositories are undocumented and lost, hindering tasks like model forensics and discovery. The Model Atlas aims to address this by organizing models and their attributes in a structured graph.", "method": "The Model Atlas is a graph capturing models, their attributes, and weight transformations. New ML methods are proposed to infer model properties (e.g., functionality, performance) directly from weights, bypassing parameter symmetries.", "result": "The Model Atlas enables applications in model forensics, meta-ML research, and discovery, though large regions remain uncharted due to lack of documentation.", "conclusion": "Charting all models requires community effort and new ML approaches. The Model Atlas's broad utility is hoped to rally researchers toward this goal."}}
{"id": "2502.09376", "pdf": "https://arxiv.org/pdf/2502.09376", "abs": "https://arxiv.org/abs/2502.09376", "authors": ["Junsu Kim", "Jaeyeon Kim", "Ernest K. Ryu"], "title": "LoRA Training Provably Converges to a Low-Rank Global Minimum or It Fails Loudly (But it Probably Won't Fail)", "categories": ["cs.LG"], "comment": null, "summary": "Low-rank adaptation (LoRA) has become a standard approach for fine-tuning\nlarge foundation models. However, our theoretical understanding of LoRA remains\nlimited as prior analyses of LoRA's training dynamics either rely on\nlinearization arguments or consider highly simplified setups. In this work, we\nanalyze the LoRA loss landscape without such restrictive assumptions. We define\ntwo regimes: a \"special regime\", which includes idealized setups where\nlinearization arguments hold, and a \"generic regime\" representing more\nrealistic setups where linearization arguments do not hold. In the generic\nregime, we show that LoRA training converges to a global minimizer with low\nrank and small magnitude, or a qualitatively distinct solution with high rank\nand large magnitude. Finally, we argue that the zero-initialization and weight\ndecay in LoRA training induce an implicit bias toward the low-rank,\nsmall-magnitude region of the parameter space -- where global minima lie --\nthus shedding light on why LoRA training usually succeeds in finding global\nminima.", "AI": {"tldr": "The paper analyzes LoRA's loss landscape without restrictive assumptions, identifying two regimes and explaining why LoRA training typically finds global minima.", "motivation": "Prior analyses of LoRA's training dynamics rely on linearization or simplified setups, limiting theoretical understanding.", "method": "Defines two regimes (special and generic) and analyzes LoRA's loss landscape without restrictive assumptions.", "result": "In the generic regime, LoRA converges to low-rank, small-magnitude solutions or high-rank, large-magnitude ones. Zero-initialization and weight decay bias toward low-rank, small-magnitude global minima.", "conclusion": "LoRA training's success is due to implicit bias toward low-rank, small-magnitude solutions, where global minima lie."}}
{"id": "2505.24595", "pdf": "https://arxiv.org/pdf/2505.24595", "abs": "https://arxiv.org/abs/2505.24595", "authors": ["Andrei Chernov", "Vitaliy Pozdnyakov", "Ilya Makarov"], "title": "Binary Cumulative Encoding meets Time Series Forecasting", "categories": ["cs.LG", "cs.AI", "stat.ML"], "comment": null, "summary": "Recent studies in time series forecasting have explored formulating\nregression via classification task. By discretizing the continuous target space\ninto bins and predicting over a fixed set of classes, these approaches benefit\nfrom stable training, robust uncertainty modeling, and compatibility with\nmodern deep learning architectures. However, most existing methods rely on\none-hot encoding that ignores the inherent ordinal structure of the underlying\nvalues. As a result, they fail to provide information about the relative\ndistance between predicted and true values during training. In this paper, we\npropose to address this limitation by introducing binary cumulative encoding\n(BCE), that represents scalar targets into monotonic binary vectors. This\nencoding implicitly preserves order and magnitude information, allowing the\nmodel to learn distance-aware representations while still operating within a\nclassification framework. We propose a convolutional neural network\narchitecture specifically designed for BCE, incorporating residual and dilated\nconvolutions to enable fast and expressive temporal modeling. Through extensive\nexperiments on benchmark forecasting datasets, we show that our approach\noutperforms widely used methods in both point and probabilistic forecasting,\nwhile requiring fewer parameters and enabling faster training.", "AI": {"tldr": "The paper proposes binary cumulative encoding (BCE) for time series forecasting, preserving ordinal structure and improving performance over one-hot encoding methods.", "motivation": "Existing methods using one-hot encoding ignore ordinal structure, limiting distance-awareness in predictions.", "method": "Introduces BCE for encoding scalar targets into monotonic binary vectors and a CNN architecture with residual and dilated convolutions.", "result": "Outperforms existing methods in point and probabilistic forecasting with fewer parameters and faster training.", "conclusion": "BCE enhances forecasting by preserving order and magnitude, offering efficiency and performance gains."}}
{"id": "2506.00022", "pdf": "https://arxiv.org/pdf/2506.00022", "abs": "https://arxiv.org/abs/2506.00022", "authors": ["Shenghe Zheng", "Qianjia Cheng", "Junchi Yao", "Mengsong Wu", "Haonan He", "Ning Ding", "Yu Cheng", "Shuyue Hu", "Lei Bai", "Dongzhan Zhou", "Ganqu Cui", "Peng Ye"], "title": "Scaling Physical Reasoning with the PHYSICS Dataset", "categories": ["cs.CL", "cs.LG", "physics.ed-ph"], "comment": "Work on physical datasets", "summary": "Large Language Models (LLMs) have achieved remarkable progress on advanced\nreasoning tasks such as mathematics and coding competitions. Meanwhile,\nphysics, despite being both reasoning-intensive and essential to real-world\nunderstanding, received limited academic and industrial attention. This paper\nintroduces PHYSICS, a dataset containing 16,568 high-quality physics problems\nspanning subjects and difficulty levels, to facilitate this issue.\nSpecifically, PHYSICS is curated with exercises from over 100 textbooks through\na carefully designed pipeline for quality control. It covers five major physics\ndomains: Mechanics, Electromagnetism, Thermodynamics, Optics, and Modern\nPhysics. It also spans a wide range of difficulty levels, from high school to\ngraduate-level physics courses. To utilize the data for improving and\nevaluating the model's physical reasoning capabilities, we split the dataset\ninto training and test sets, and provide reasoning paths generated by powerful\nreasoning models for the training data to facilitate model training. In\naddition, for the evaluation part, we find that existing evaluation frameworks\nexhibit biases in aspects such as units, simplification, and precision in\nphysics domain. To balance efficiency and accuracy, we introduce a Rule+Model\nevaluation framework tailored to physics problems. Our evaluations on current\nstate-of-the-art open-source and proprietary models highlight the limitations\nof current models in handling physics-related tasks. We hope that our dataset\nand evaluation methodology will jointly advance the development of LLMs in the\nfield of physics.", "AI": {"tldr": "The paper introduces PHYSICS, a dataset of 16,568 physics problems to improve LLMs' reasoning in physics, addressing gaps in current research and evaluation frameworks.", "motivation": "Physics is reasoning-intensive but understudied in LLMs. The paper aims to fill this gap by providing a high-quality dataset and tailored evaluation methods.", "method": "Curated 16,568 physics problems from textbooks, covering five domains and difficulty levels. Introduced a Rule+Model evaluation framework for physics.", "result": "Current LLMs show limitations in physics tasks. The dataset and evaluation framework highlight these gaps and aim to improve model performance.", "conclusion": "PHYSICS dataset and evaluation methodology aim to advance LLMs' capabilities in physics reasoning."}}
{"id": "2503.21555", "pdf": "https://arxiv.org/pdf/2503.21555", "abs": "https://arxiv.org/abs/2503.21555", "authors": ["Hyunjun Lee", "Hyunsoo Lee", "Sookwan Han"], "title": "SyncSDE: A Probabilistic Framework for Diffusion Synchronization", "categories": ["cs.LG", "cs.CV", "cs.GR", "stat.ML"], "comment": "Accepted to CVPR2025. Project Page:\n  https://hjl1013.github.io/SyncSDE/", "summary": "There have been many attempts to leverage multiple diffusion models for\ncollaborative generation, extending beyond the original domain. A prominent\napproach involves synchronizing multiple diffusion trajectories by mixing the\nestimated scores to artificially correlate the generation processes. However,\nexisting methods rely on naive heuristics, such as averaging, without\nconsidering task specificity. These approaches do not clarify why such methods\nwork and often produce suboptimal results when a heuristic suitable for one\ntask is blindly applied to others. In this paper, we present a probabilistic\nframework for analyzing why diffusion synchronization works and reveal where\nheuristics should be focused; modeling correlations between multiple\ntrajectories and adapting them to each specific task. We further identify\noptimal correlation models per task, achieving better results than previous\napproaches that apply a single heuristic across all tasks without\njustification.", "AI": {"tldr": "A probabilistic framework analyzes diffusion synchronization, optimizing task-specific correlations for better results than naive heuristics.", "motivation": "Existing methods for collaborative generation with diffusion models rely on naive heuristics like averaging, lacking task-specific optimization and theoretical justification.", "method": "The paper introduces a probabilistic framework to model correlations between diffusion trajectories and adapt them to specific tasks, identifying optimal correlation models.", "result": "The framework outperforms previous approaches by focusing on task-specific correlations rather than applying a single heuristic universally.", "conclusion": "Task-specific correlation modeling in diffusion synchronization leads to superior performance compared to heuristic-based methods."}}
{"id": "2502.10927", "pdf": "https://arxiv.org/pdf/2502.10927", "abs": "https://arxiv.org/abs/2502.10927", "authors": ["Matteo Saponati", "Pascal Sager", "Pau Vilimelis Aceituno", "Thilo Stadelmann", "Benjamin Grewe"], "title": "The underlying structures of self-attention: symmetry, directionality, and emergent dynamics in Transformer training", "categories": ["cs.LG"], "comment": null, "summary": "Self-attention is essential to Transformer architectures, yet how information\nis embedded in the self-attention matrices and how different objective\nfunctions impact this process remains unclear. We present a mathematical\nframework to analyze self-attention matrices by deriving the structures\ngoverning their weight updates. Using this framework, we demonstrate that\nbidirectional training induces symmetry in the weight matrices, while\nautoregressive training results in directionality and column dominance. Our\ntheoretical findings are validated across multiple Transformer models -\nincluding ModernBERT, GPT, LLaMA3, and Mistral - and input modalities like\ntext, vision, and audio. Finally, we apply these insights by showing that\nsymmetric initialization improves the performance of encoder-only models on\nlanguage tasks. This mathematical analysis offers a novel theoretical\nperspective on how information is embedded through self-attention, thereby\nimproving the interpretability of Transformer models.", "AI": {"tldr": "The paper analyzes self-attention matrices in Transformers, showing how training objectives (bidirectional vs. autoregressive) shape their structure. Symmetric initialization improves encoder-only models.", "motivation": "To clarify how information is embedded in self-attention matrices and how training objectives influence their structure.", "method": "A mathematical framework is developed to analyze weight updates in self-attention matrices, validated across Transformer models and input modalities.", "result": "Bidirectional training induces symmetry, while autoregressive training leads to directionality. Symmetric initialization boosts encoder-only model performance.", "conclusion": "The study provides theoretical insights into self-attention, enhancing Transformer interpretability and performance."}}
{"id": "2506.00095", "pdf": "https://arxiv.org/pdf/2506.00095", "abs": "https://arxiv.org/abs/2506.00095", "authors": ["Yuchong Li", "Xiaojun Zeng", "Chihua Fang", "Jian Yang", "Fucang Jia", "Lei Zhang"], "title": "ClinBench-HPB: A Clinical Benchmark for Evaluating LLMs in Hepato-Pancreato-Biliary Diseases", "categories": ["cs.CY", "cs.AI", "cs.CL"], "comment": null, "summary": "Hepato-pancreato-biliary (HPB) disorders represent a global public health\nchallenge due to their high morbidity and mortality. Although large language\nmodels (LLMs) have shown promising performance in general medical\nquestion-answering tasks, the current evaluation benchmarks are mostly derived\nfrom standardized examinations or manually designed questions, lacking HPB\ncoverage and clinical cases. To address these issues, we systematically\neatablish an HPB disease evaluation benchmark comprising 3,535 closed-ended\nmultiple-choice questions and 337 open-ended real diagnosis cases, which\nencompasses all the 33 main categories and 465 subcategories of HPB diseases\ndefined in the International Statistical Classification of Diseases, 10th\nRevision (ICD-10). The multiple-choice questions are curated from public\ndatasets and synthesized data, and the clinical cases are collected from\nprestigious medical journals, case-sharing platforms, and collaborating\nhospitals. By evalauting commercial and open-source general and medical LLMs on\nour established benchmark, namely ClinBench-HBP, we find that while commercial\nLLMs perform competently on medical exam questions, they exhibit substantial\nperformance degradation on HPB diagnosis tasks, especially on complex,\ninpatient clinical cases. Those medical LLMs also show limited generalizability\nto HPB diseases. Our results reveal the critical limitations of current LLMs in\nthe domain of HPB diseases, underscoring the imperative need for future medical\nLLMs to handle real, complex clinical diagnostics rather than simple medical\nexam questions. The benchmark will be released at the homepage.", "AI": {"tldr": "The paper introduces ClinBench-HBP, a benchmark for evaluating large language models (LLMs) on HPB diseases, revealing their limitations in handling complex clinical cases.", "motivation": "Current LLM benchmarks lack coverage of HPB diseases and real clinical cases, limiting their applicability in this critical medical domain.", "method": "The authors created a benchmark with 3,535 multiple-choice questions and 337 open-ended clinical cases, covering all HPB disease categories in ICD-10. Data sources include public datasets, medical journals, and hospitals.", "result": "Commercial and medical LLMs perform well on exam questions but struggle with HPB diagnosis, especially complex cases, showing limited generalizability.", "conclusion": "The study highlights the need for LLMs to improve in real clinical diagnostics and releases the benchmark to aid future research."}}
{"id": "2506.00077", "pdf": "https://arxiv.org/pdf/2506.00077", "abs": "https://arxiv.org/abs/2506.00077", "authors": ["Edward L. Wang", "Tianyu Wang", "Avanti Athreya", "Vince Lyzinski", "Carey E. Priebe"], "title": "Gaussian mixture models as a proxy for interacting language models", "categories": ["cs.CL", "cs.LG", "stat.ML", "62R07"], "comment": null, "summary": "Large language models (LLMs) are a powerful tool with the ability to match\nhuman capabilities and behavior in many settings. Retrieval-augmented\ngeneration (RAG) further allows LLMs to generate diverse output depending on\nthe contents of their RAG database. This motivates their use in the social\nsciences to study human behavior between individuals when large-scale\nexperiments are infeasible. However, LLMs depend on complex, computationally\nexpensive algorithms. In this paper, we introduce interacting Gaussian mixture\nmodels (GMMs) as an alternative to similar frameworks using LLMs. We compare a\nsimplified model of GMMs to select experimental simulations of LLMs whose\nupdating and response depend on feedback from other LLMs. We find that\ninteracting GMMs capture important features of the dynamics in interacting\nLLMs, and we investigate key similarities and differences between interacting\nLLMs and GMMs. We conclude by discussing the benefits of Gaussian mixture\nmodels, potential modifications, and future research directions.", "AI": {"tldr": "The paper proposes interacting Gaussian mixture models (GMMs) as a simpler alternative to LLMs for studying human behavior, comparing their dynamics and highlighting key similarities and differences.", "motivation": "LLMs are computationally expensive, motivating the need for simpler models like GMMs to study human behavior in social sciences.", "method": "The authors compare interacting GMMs to LLMs in experimental simulations, focusing on dynamics and feedback mechanisms.", "result": "Interacting GMMs capture key features of LLM dynamics, with notable similarities and differences identified.", "conclusion": "GMMs offer benefits over LLMs, with potential for modifications and future research to enhance their utility."}}
{"id": "2503.24160", "pdf": "https://arxiv.org/pdf/2503.24160", "abs": "https://arxiv.org/abs/2503.24160", "authors": ["Angela Lopez-Cardona", "Parvin Emami", "Sebastian Idesis", "Saravanakumar Duraisamy", "Luis A. Leiva", "Ioannis Arapakis"], "title": "A Comparative Study of Scanpath Models in Graph-Based Visualization", "categories": ["cs.HC", "cs.CV"], "comment": null, "summary": "Information Visualization (InfoVis) systems utilize visual representations to\nenhance data interpretation. Understanding how visual attention is allocated is\nessential for optimizing interface design. However, collecting Eye-tracking\n(ET) data presents challenges related to cost, privacy, and scalability.\nComputational models provide alternatives for predicting gaze patterns, thereby\nadvancing InfoVis research. In our study, we conducted an ET experiment with 40\nparticipants who analyzed graphs while responding to questions of varying\ncomplexity within the context of digital forensics. We compared human scanpaths\nwith synthetic ones generated by models such as DeepGaze, UMSS, and Gazeformer.\nOur research evaluates the accuracy of these models and examines how question\ncomplexity and number of nodes influence performance. This work contributes to\nthe development of predictive modeling in visual analytics, offering insights\nthat can enhance the design and effectiveness of InfoVis systems.", "AI": {"tldr": "The paper evaluates computational models (DeepGaze, UMSS, Gazeformer) for predicting gaze patterns in InfoVis, comparing them to human ET data, and explores the impact of question complexity and graph structure.", "motivation": "Challenges in collecting ET data (cost, privacy, scalability) motivate the use of computational models to predict gaze patterns for optimizing InfoVis systems.", "method": "Conducted an ET experiment with 40 participants analyzing graphs under varying question complexities, comparing human scanpaths to synthetic ones from models.", "result": "Evaluated model accuracy and examined how question complexity and graph nodes affect performance.", "conclusion": "The study advances predictive modeling in visual analytics, providing insights to improve InfoVis system design and effectiveness."}}
{"id": "2502.14354", "pdf": "https://arxiv.org/pdf/2502.14354", "abs": "https://arxiv.org/abs/2502.14354", "authors": ["Moxin Li", "Yuantao Zhang", "Wenjie Wang", "Wentao Shi", "Zhuo Liu", "Fuli Feng", "Tat-Seng Chua"], "title": "Self-Improvement Towards Pareto Optimality: Mitigating Preference Conflicts in Multi-Objective Alignment", "categories": ["cs.LG", "cs.CL"], "comment": "ACL findings (2025)", "summary": "Multi-Objective Alignment (MOA) aims to align LLMs' responses with multiple\nhuman preference objectives, with Direct Preference Optimization (DPO) emerging\nas a prominent approach. However, we find that DPO-based MOA approaches suffer\nfrom widespread preference conflicts in the data, where different objectives\nfavor different responses. This results in conflicting optimization directions,\nhindering the optimization on the Pareto Front. To address this, we propose to\nconstruct Pareto-optimal responses to resolve preference conflicts. To\nefficiently obtain and utilize such responses, we propose a self-improving DPO\nframework that enables LLMs to self-generate and select Pareto-optimal\nresponses for self-supervised preference alignment. Extensive experiments on\ntwo datasets demonstrate the superior Pareto Front achieved by our framework\ncompared to various baselines. Code is available at\nhttps://github.com/zyttt-coder/SIPO.", "AI": {"tldr": "The paper proposes a self-improving DPO framework to resolve preference conflicts in Multi-Objective Alignment (MOA) by generating and selecting Pareto-optimal responses, achieving superior results.", "motivation": "Existing DPO-based MOA approaches suffer from preference conflicts, leading to suboptimal alignment due to conflicting optimization directions.", "method": "A self-improving DPO framework is introduced, where LLMs self-generate and select Pareto-optimal responses for self-supervised preference alignment.", "result": "Experiments on two datasets show the framework achieves a superior Pareto Front compared to baselines.", "conclusion": "The proposed method effectively resolves preference conflicts and improves alignment in MOA."}}
{"id": "2506.00288", "pdf": "https://arxiv.org/pdf/2506.00288", "abs": "https://arxiv.org/abs/2506.00288", "authors": ["Ahmed Elhady", "Eneko Agirre", "Mikel Artetxe"], "title": "Emergent Abilities of Large Language Models under Continued Pretraining for Language Adaptation", "categories": ["cs.CL", "cs.AI"], "comment": "To appear in ACL 2025 Main", "summary": "Continued pretraining (CPT) is a popular approach to adapt existing large\nlanguage models (LLMs) to new languages. When doing so, it is common practice\nto include a portion of English data in the mixture, but its role has not been\ncarefully studied to date. In this work, we show that including English does\nnot impact validation perplexity, yet it is critical for the emergence of\ndownstream capabilities in the target language. We introduce a\nlanguage-agnostic benchmark for in-context learning (ICL), which reveals\ncatastrophic forgetting early on CPT when English is not included. This in turn\ndamages the ability of the model to generalize to downstream prompts in the\ntarget language as measured by perplexity, even if it does not manifest in\nterms of accuracy until later in training, and can be tied to a big shift in\nthe model parameters. Based on these insights, we introduce curriculum learning\nand exponential moving average (EMA) of weights as effective alternatives to\nmitigate the need for English. All in all, our work sheds light into the\ndynamics by which emergent abilities arise when doing CPT for language\nadaptation, and can serve as a foundation to design more effective methods in\nthe future.", "AI": {"tldr": "Including English data in continued pretraining (CPT) for language adaptation doesn't affect validation perplexity but is crucial for downstream task performance in the target language. Omitting English leads to catastrophic forgetting and poor generalization, mitigated by curriculum learning and EMA of weights.", "motivation": "To understand the role of English data in CPT for adapting LLMs to new languages and its impact on downstream capabilities.", "method": "Introduces a language-agnostic benchmark for in-context learning (ICL), analyzes the effects of including/excluding English, and proposes curriculum learning and EMA of weights as solutions.", "result": "English inclusion is vital for downstream task performance despite not affecting perplexity. Omitting it causes catastrophic forgetting and parameter shifts, harming generalization.", "conclusion": "The study clarifies how emergent abilities arise in CPT and suggests better methods (curriculum learning, EMA) for language adaptation."}}
{"id": "2506.00250", "pdf": "https://arxiv.org/pdf/2506.00250", "abs": "https://arxiv.org/abs/2506.00250", "authors": ["Mohammad Javad Ranjbar Kalahroodi", "Amirhossein Sheikholselami", "Sepehr Karimi", "Sepideh Ranjbar Kalahroodi", "Heshaam Faili", "Azadeh Shakery"], "title": "PersianMedQA: Language-Centric Evaluation of LLMs in the Persian Medical Domain", "categories": ["cs.CL", "cs.IT", "math.IT"], "comment": null, "summary": "Large Language Models (LLMs) have achieved remarkable performance on a wide\nrange of NLP benchmarks, often surpassing human-level accuracy. However, their\nreliability in high-stakes domains such as medicine, particularly in\nlow-resource languages, remains underexplored. In this work, we introduce\nPersianMedQA, a large-scale, expert-validated dataset of multiple-choice\nPersian medical questions, designed to evaluate LLMs across both Persian and\nEnglish. We benchmark over 40 state-of-the-art models, including\ngeneral-purpose, Persian fine-tuned, and medical LLMs, in zero-shot and\nchain-of-thought (CoT) settings. Our results show that closed-source general\nmodels (e.g., GPT-4.1) consistently outperform all other categories, achieving\n83.3% accuracy in Persian and 80.7% in English, while Persian fine-tuned models\nsuch as Dorna underperform significantly (e.g., 35.9% in Persian), often\nstruggling with both instruction-following and domain reasoning. We also\nanalyze the impact of translation, showing that while English performance is\ngenerally higher, Persian responses are sometimes more accurate due to cultural\nand clinical contextual cues. Finally, we demonstrate that model size alone is\ninsufficient for robust performance without strong domain or language\nadaptation. PersianMedQA provides a foundation for evaluating multilingual and\nculturally grounded medical reasoning in LLMs. The PersianMedQA dataset can be\naccessed at: https://huggingface.co/datasets/MohammadJRanjbar/PersianMedQA", "AI": {"tldr": "The paper introduces PersianMedQA, a dataset to evaluate LLMs in Persian and English for medical reasoning, showing GPT-4.1's superiority and the limitations of fine-tuned models.", "motivation": "To assess LLM reliability in high-stakes, low-resource medical domains, particularly Persian, which is underexplored.", "method": "Benchmarked 40+ LLMs (general, Persian fine-tuned, medical) on PersianMedQA in zero-shot and CoT settings, analyzing translation impact.", "result": "GPT-4.1 outperformed others (83.3% Persian, 80.7% English), while fine-tuned models like Dorna struggled (35.9%). Translation showed mixed accuracy.", "conclusion": "Model size alone isn't enough; domain/language adaptation is crucial. PersianMedQA aids multilingual, culturally grounded medical LLM evaluation."}}
{"id": "2505.05098", "pdf": "https://arxiv.org/pdf/2505.05098", "abs": "https://arxiv.org/abs/2505.05098", "authors": ["Wei Liu", "Jiyuan Zhang", "Binxiong Zheng", "Yufeng Hu", "Yingzhan Lin", "Zengfeng Zeng"], "title": "X-Driver: Explainable Autonomous Driving with Vision-Language Models", "categories": ["cs.RO", "cs.CL", "cs.CV", "cs.ET"], "comment": null, "summary": "End-to-end autonomous driving has advanced significantly, offering benefits\nsuch as system simplicity and stronger driving performance in both open-loop\nand closed-loop settings than conventional pipelines. However, existing\nframeworks still suffer from low success rates in closed-loop evaluations,\nhighlighting their limitations in real-world deployment. In this paper, we\nintroduce X-Driver, a unified multi-modal large language models(MLLMs)\nframework designed for closed-loop autonomous driving, leveraging\nChain-of-Thought(CoT) and autoregressive modeling to enhance perception and\ndecision-making. We validate X-Driver across multiple autonomous driving tasks\nusing public benchmarks in CARLA simulation environment, including\nBench2Drive[6]. Our experimental results demonstrate superior closed-loop\nperformance, surpassing the current state-of-the-art(SOTA) while improving the\ninterpretability of driving decisions. These findings underscore the importance\nof structured reasoning in end-to-end driving and establish X-Driver as a\nstrong baseline for future research in closed-loop autonomous driving.", "AI": {"tldr": "X-Driver, a multi-modal large language model framework, improves closed-loop autonomous driving performance and interpretability using Chain-of-Thought and autoregressive modeling.", "motivation": "Existing end-to-end autonomous driving frameworks struggle with low success rates in closed-loop evaluations, limiting real-world deployment.", "method": "X-Driver leverages Chain-of-Thought (CoT) and autoregressive modeling to enhance perception and decision-making in a unified MLLMs framework.", "result": "X-Driver outperforms state-of-the-art methods in closed-loop evaluations on CARLA benchmarks, demonstrating superior performance and interpretability.", "conclusion": "X-Driver establishes a strong baseline for future closed-loop autonomous driving research, emphasizing the role of structured reasoning."}}
{"id": "2502.16462", "pdf": "https://arxiv.org/pdf/2502.16462", "abs": "https://arxiv.org/abs/2502.16462", "authors": ["Mikael M\u00f8ller H\u00f8gsgaard", "Kasper Green Larsen"], "title": "Improved Margin Generalization Bounds for Voting Classifiers", "categories": ["cs.LG", "cs.DS", "math.ST", "stat.ML", "stat.TH"], "comment": null, "summary": "In this paper we establish a new margin-based generalization bound for voting\nclassifiers, refining existing results and yielding tighter generalization\nguarantees for widely used boosting algorithms such as AdaBoost (Freund and\nSchapire, 1997). Furthermore, the new margin-based generalization bound enables\nthe derivation of an optimal weak-to-strong learner: a Majority-of-3\nlarge-margin classifiers with an expected error matching the theoretical lower\nbound. This result provides a more natural alternative to the Majority-of-5\nalgorithm by (H{\\o}gsgaard et al., 2024), and matches the Majority-of-3 result\nby (Aden-Ali et al., 2024) for the realizable prediction model.", "AI": {"tldr": "A new margin-based generalization bound for voting classifiers is introduced, improving existing results and providing tighter guarantees for boosting algorithms like AdaBoost. It also enables an optimal weak-to-strong learner, the Majority-of-3, matching theoretical lower bounds.", "motivation": "To refine and tighten generalization bounds for voting classifiers, particularly boosting algorithms, and to derive an optimal weak-to-strong learner.", "method": "Establishes a new margin-based generalization bound and applies it to derive the Majority-of-3 classifier.", "result": "The Majority-of-3 classifier achieves an expected error matching the theoretical lower bound, offering a more natural alternative to existing methods.", "conclusion": "The new bound and Majority-of-3 classifier provide improved generalization guarantees and optimal performance, aligning with prior theoretical results."}}
{"id": "2506.00486", "pdf": "https://arxiv.org/pdf/2506.00486", "abs": "https://arxiv.org/abs/2506.00486", "authors": ["Jun Wu", "Yirong Xiong", "Jiangtao Wen", "Yuxing Han"], "title": "It Takes a Good Model to Train a Good Model: Generalized Gaussian Priors for Optimized LLMs", "categories": ["cs.LG", "cs.AI", "stat.ML"], "comment": null, "summary": "Despite rapid advancements in the research and deployment of large language\nmodels (LLMs), the statistical distribution of model parameters, as well as\ntheir influence on initialization, training dynamics, and downstream\nefficiency, has received surprisingly little attention. A recent work\nintroduced BackSlash, a training-time compression algorithm. It first\ndemonstrated that pre-trained LLM parameters follow generalized Gaussian\ndistributions (GGDs) better. By optimizing GG priors during training, BackSlash\ncan reduce parameters by up to 90\\% with minimal performance loss. Building on\nthis foundational insight, we propose a unified, end-to-end framework for LLM\noptimization based on the GG model. Our contributions are threefold: (1)\nGG-based initialization scheme that aligns with the statistical structure of\ntrained models, resulting in faster convergence and improved accuracy; (2)\nDeepShape, a post-training regularization method that reshapes weight\ndistributions to match a GG profile, improving compressibility with minimized\ndegradation in performance; and (3) RF8, a compact and hardware-efficient 8-bit\nfloating-point format designed for GG-distributed-initialized BackSlash\ntraining, enabling low-cost inference without compromising accuracy.\nExperiments across diverse model architectures show that our framework\nconsistently yields smaller and faster models that match or outperform standard\ntraining baselines. By grounding LLM development in principled statistical\nmodeling, this work forges a new path toward efficient, scalable, and\nhardware-aware AI systems. The code is available on our project page:\nhttps://huggingface.co/spaces/shifeng3711/gg_prior.", "AI": {"tldr": "The paper introduces a unified framework for LLM optimization using generalized Gaussian distributions (GGDs), improving initialization, training, and compression with minimal performance loss.", "motivation": "Despite LLM advancements, the statistical distribution of parameters and their impact on training and efficiency is understudied. The work aims to address this gap.", "method": "Proposes GG-based initialization, DeepShape for post-training regularization, and RF8 for hardware-efficient 8-bit training, all grounded in GG modeling.", "result": "Experiments show smaller, faster models matching or outperforming baselines, with up to 90% parameter reduction.", "conclusion": "The framework offers a principled, scalable approach for efficient and hardware-aware AI systems."}}
{"id": "2506.00519", "pdf": "https://arxiv.org/pdf/2506.00519", "abs": "https://arxiv.org/abs/2506.00519", "authors": ["Yuxi Sun", "Aoqi Zuo", "Wei Gao", "Jing Ma"], "title": "CausalAbstain: Enhancing Multilingual LLMs with Causal Reasoning for Trustworthy Abstention", "categories": ["cs.CL", "cs.AI"], "comment": "Accepted to Association for Computational Linguistics Findings (ACL)\n  2025", "summary": "Large Language Models (LLMs) often exhibit knowledge disparities across\nlanguages. Encouraging LLMs to \\textit{abstain} when faced with knowledge gaps\nis a promising strategy to reduce hallucinations in multilingual settings.\nCurrent abstention strategies for multilingual scenarios primarily rely on\ngenerating feedback in various languages using LLMs and performing\nself-reflection. However, these methods can be adversely impacted by\ninaccuracies and biases in the generated feedback. To address this, from a\ncausal perspective, we introduce \\textit{CausalAbstain}, a method that helps\nLLMs determine whether to utilize multiple generated feedback responses and how\nto identify the most useful ones. Extensive experiments demonstrate that\n\\textit{CausalAbstain} effectively selects helpful feedback and enhances\nabstention decisions with interpretability in both native language\n(\\textsc{Casual-native}) and multilingual (\\textsc{Causal-multi}) settings,\noutperforming strong baselines on two benchmark datasets covering encyclopedic\nand commonsense knowledge QA tasks. Our code and data are open-sourced at\nhttps://github.com/peachch/CausalAbstain.", "AI": {"tldr": "CausalAbstain improves LLMs' abstention decisions in multilingual settings by selecting useful feedback causally, outperforming baselines.", "motivation": "Address knowledge disparities and reduce hallucinations in LLMs by improving abstention strategies.", "method": "Introduces CausalAbstain, a causal method to select useful feedback for abstention decisions.", "result": "Outperforms baselines in native and multilingual settings, enhancing interpretability.", "conclusion": "CausalAbstain effectively improves LLMs' abstention decisions with open-sourced code and data."}}
{"id": "2503.00229", "pdf": "https://arxiv.org/pdf/2503.00229", "abs": "https://arxiv.org/abs/2503.00229", "authors": ["Sharan Vaswani", "Reza Babanezhad"], "title": "Armijo Line-search Can Make (Stochastic) Gradient Descent Provably Faster", "categories": ["cs.LG", "math.OC", "stat.ML"], "comment": "ICML 2025. 37 pages", "summary": "Armijo line-search (Armijo-LS) is a standard method to set the step-size for\ngradient descent (GD). For smooth functions, Armijo-LS alleviates the need to\nknow the global smoothness constant L and adapts to the ``local'' smoothness,\nenabling GD to converge faster. Existing theoretical analyses show that GD with\nArmijo-LS (GD-LS) can result in constant factor improvements over GD with a 1/L\nstep-size (denoted as GD(1/L)). We strengthen these results and show that if\nthe objective function satisfies a certain non-uniform smoothness condition,\nGD-LS can result in a faster convergence rate than GD(1/L). In particular, we\nprove that for convex objectives corresponding to logistic regression and\nmulti-class classification, GD-LS can converge to the optimum at a linear rate,\nand hence improves over the sublinear convergence of GD(1/L). Furthermore, for\nnon-convex objectives satisfying gradient domination (e.g., those corresponding\nto the softmax policy gradient in RL or generalized linear models with a\nlogistic link function), GD-LS can match the fast convergence of algorithms\ntailored for these specific settings. Finally, we prove that under the\ninterpolation assumption, for convex losses, stochastic GD with a stochastic\nline-search can match the fast convergence of GD-LS", "AI": {"tldr": "GD with Armijo-LS (GD-LS) outperforms GD(1/L) in convergence speed for certain non-uniform smoothness conditions, achieving linear rates for convex objectives and matching tailored algorithms for non-convex ones.", "motivation": "To demonstrate that Armijo-LS can adapt to local smoothness and achieve faster convergence than fixed step-size GD, especially for specific objective functions.", "method": "Analyze GD-LS under non-uniform smoothness conditions, focusing on convex (logistic regression, multi-class classification) and non-convex (gradient domination) objectives.", "result": "GD-LS achieves linear convergence for convex objectives and matches tailored algorithms for non-convex ones. Stochastic GD with line-search also matches GD-LS under interpolation.", "conclusion": "Armijo-LS provides significant convergence improvements over fixed step-size GD, especially for structured objectives, and is versatile across convex and non-convex settings."}}
{"id": "2506.00512", "pdf": "https://arxiv.org/pdf/2506.00512", "abs": "https://arxiv.org/abs/2506.00512", "authors": ["Yang Zheng", "Mengqi Huang", "Nan Chen", "Zhendong Mao"], "title": "Pro3D-Editor : A Progressive-Views Perspective for Consistent and Precise 3D Editing", "categories": ["cs.GR", "cs.AI"], "comment": null, "summary": "Text-guided 3D editing aims to precisely edit semantically relevant local 3D\nregions, which has significant potential for various practical applications\nranging from 3D games to film production. Existing methods typically follow a\nview-indiscriminate paradigm: editing 2D views indiscriminately and projecting\nthem back into 3D space. However, they overlook the different cross-view\ninterdependencies, resulting in inconsistent multi-view editing. In this study,\nwe argue that ideal consistent 3D editing can be achieved through a\n\\textit{progressive-views paradigm}, which propagates editing semantics from\nthe editing-salient view to other editing-sparse views. Specifically, we\npropose \\textit{Pro3D-Editor}, a novel framework, which mainly includes\nPrimary-view Sampler, Key-view Render, and Full-view Refiner. Primary-view\nSampler dynamically samples and edits the most editing-salient view as the\nprimary view. Key-view Render accurately propagates editing semantics from the\nprimary view to other key views through its Mixture-of-View-Experts Low-Rank\nAdaption (MoVE-LoRA). Full-view Refiner edits and refines the 3D object based\non the edited multi-views. Extensive experiments demonstrate that our method\noutperforms existing methods in editing accuracy and spatial consistency.", "AI": {"tldr": "Pro3D-Editor introduces a progressive-views paradigm for consistent 3D editing by propagating semantics from salient to sparse views, outperforming existing methods.", "motivation": "Existing 3D editing methods lack cross-view consistency, limiting practical applications like 3D games and film production.", "method": "Pro3D-Editor uses Primary-view Sampler, Key-view Render (MoVE-LoRA), and Full-view Refiner to propagate and refine edits.", "result": "The method achieves superior editing accuracy and spatial consistency compared to existing approaches.", "conclusion": "Pro3D-Editor's progressive-views paradigm effectively addresses multi-view inconsistency in 3D editing."}}
{"id": "2506.00612", "pdf": "https://arxiv.org/pdf/2506.00612", "abs": "https://arxiv.org/abs/2506.00612", "authors": ["Running Yang", "Wenlong Deng", "Minghui Chen", "Yuyin Zhou", "Xiaoxiao Li"], "title": "Enhancing Clinical Multiple-Choice Questions Benchmarks with Knowledge Graph Guided Distractor Generation", "categories": ["cs.CL"], "comment": null, "summary": "Clinical tasks such as diagnosis and treatment require strong decision-making\nabilities, highlighting the importance of rigorous evaluation benchmarks to\nassess the reliability of large language models (LLMs). In this work, we\nintroduce a knowledge-guided data augmentation framework that enhances the\ndifficulty of clinical multiple-choice question (MCQ) datasets by generating\ndistractors (i.e., incorrect choices that are similar to the correct one and\nmay confuse existing LLMs). Using our KG-based pipeline, the generated choices\nare both clinically plausible and deliberately misleading. Our approach\ninvolves multi-step, semantically informed walks on a medical knowledge graph\nto identify distractor paths-associations that are medically relevant but\nfactually incorrect-which then guide the LLM in crafting more deceptive\ndistractors. We apply the designed knowledge graph guided distractor generation\n(KGGDG) pipline, to six widely used medical QA benchmarks and show that it\nconsistently reduces the accuracy of state-of-the-art LLMs. These findings\nestablish KGGDG as a powerful tool for enabling more robust and diagnostic\nevaluations of medical LLMs.", "AI": {"tldr": "A knowledge-guided data augmentation framework (KGGDG) is introduced to enhance clinical MCQ datasets by generating plausible but misleading distractors, reducing LLM accuracy for robust evaluation.", "motivation": "To rigorously evaluate the reliability of LLMs in clinical decision-making by increasing dataset difficulty with deceptive distractors.", "method": "Multi-step, semantically informed walks on a medical knowledge graph to generate clinically plausible but incorrect distractors.", "result": "Applied to six medical QA benchmarks, KGGDG consistently reduces the accuracy of state-of-the-art LLMs.", "conclusion": "KGGDG is a powerful tool for robust and diagnostic evaluations of medical LLMs."}}
{"id": "2503.02143", "pdf": "https://arxiv.org/pdf/2503.02143", "abs": "https://arxiv.org/abs/2503.02143", "authors": ["Jordan Peper", "Zhenjiang Mao", "Yuang Geng", "Siyuan Pan", "Ivan Ruchkin"], "title": "Four Principles for Physically Interpretable World Models", "categories": ["cs.LG", "cs.RO"], "comment": "Equal contribution by the first two authors", "summary": "As autonomous systems are increasingly deployed in open and uncertain\nsettings, there is a growing need for trustworthy world models that can\nreliably predict future high-dimensional observations. The learned latent\nrepresentations in world models lack direct mapping to meaningful physical\nquantities and dynamics, limiting their utility and interpretability in\ndownstream planning, control, and safety verification. In this paper, we argue\nfor a fundamental shift from physically informed to physically interpretable\nworld models - and crystallize four principles that leverage symbolic knowledge\nto achieve these ends: (1) functionally organizing the latent space according\nto the physical intent, (2) learning aligned invariant and equivariant\nrepresentations of the physical world, (3) integrating multiple forms and\nstrengths of supervision into a unified training process, and (4) partitioning\ngenerative outputs to support scalability and verifiability. We experimentally\ndemonstrate the value of each principle on two benchmarks. This paper opens\nseveral intriguing research directions to achieve and capitalize on full\nphysical interpretability in world models.", "AI": {"tldr": "Advocates for physically interpretable world models in autonomous systems, proposing four principles to enhance interpretability and utility.", "motivation": "Current world models lack interpretability and direct mapping to physical quantities, limiting their use in planning, control, and safety verification.", "method": "Proposes four principles: functional latent space organization, aligned invariant/equivariant representations, integrated supervision, and partitioned generative outputs.", "result": "Demonstrates the value of each principle experimentally on two benchmarks.", "conclusion": "Opens research directions for achieving full physical interpretability in world models."}}
{"id": "2506.00622", "pdf": "https://arxiv.org/pdf/2506.00622", "abs": "https://arxiv.org/abs/2506.00622", "authors": ["Haesung Pyun", "Yoonah Park", "Yohan Jo"], "title": "Improving Dialogue State Tracking through Combinatorial Search for In-Context Examples", "categories": ["cs.CL", "cs.AI", "cs.IR"], "comment": "This paper has been accepted for publication at ACL 2025", "summary": "In dialogue state tracking (DST), in-context learning comprises a retriever\nthat selects labeled dialogues as in-context examples and a DST model that uses\nthese examples to infer the dialogue state of the query dialogue. Existing\nmethods for constructing training data for retrievers suffer from three key\nlimitations: (1) the synergistic effect of examples is not considered, (2) the\nlinguistic characteristics of the query are not sufficiently factored in, and\n(3) scoring is not directly optimized for DST performance. Consequently, the\nretriever can fail to retrieve examples that would substantially improve DST\nperformance. To address these issues, we present CombiSearch, a method that\nscores effective in-context examples based on their combinatorial impact on DST\nperformance. Our evaluation on MultiWOZ shows that retrievers trained with\nCombiSearch surpass state-of-the-art models, achieving a 20x gain in data\nefficiency and generalizing well to the SGD dataset. Moreover, CombiSearch\nattains a 12% absolute improvement in the upper bound DST performance over\ntraditional approaches when no retrieval errors are assumed. This significantly\nincreases the headroom for practical DST performance while demonstrating that\nexisting methods rely on suboptimal data for retriever training.", "AI": {"tldr": "CombiSearch improves dialogue state tracking (DST) by optimizing retriever training with combinatorial scoring, outperforming state-of-the-art models and increasing data efficiency.", "motivation": "Existing retriever training methods for DST ignore synergistic effects, linguistic characteristics, and direct DST performance optimization, leading to suboptimal example retrieval.", "method": "CombiSearch scores in-context examples based on their combinatorial impact on DST performance, addressing the limitations of current methods.", "result": "CombiSearch achieves a 20x gain in data efficiency, generalizes well to SGD dataset, and improves DST performance by 12% over traditional approaches.", "conclusion": "CombiSearch demonstrates superior retriever training, highlighting the suboptimal nature of existing methods and expanding practical DST performance potential."}}
{"id": "2506.00694", "pdf": "https://arxiv.org/pdf/2506.00694", "abs": "https://arxiv.org/abs/2506.00694", "authors": ["Li Zhang", "Morgan Gray", "Jaromir Savelka", "Kevin D. Ashley"], "title": "Measuring Faithfulness and Abstention: An Automated Pipeline for Evaluating LLM-Generated 3-ply Case-Based Legal Arguments", "categories": ["cs.CL", "cs.AI", "cs.LG", "68T50"], "comment": "11 pages, 7th Workshop on Automated Semantic Analysis of Information\n  in Legal Text @ ICAIL 2025, 16 June 2025, Chicago, IL", "summary": "Large Language Models (LLMs) demonstrate potential in complex legal tasks\nlike argument generation, yet their reliability remains a concern. Building\nupon pilot work assessing LLM generation of 3-ply legal arguments using human\nevaluation, this paper introduces an automated pipeline to evaluate LLM\nperformance on this task, specifically focusing on faithfulness (absence of\nhallucination), factor utilization, and appropriate abstention. We define\nhallucination as the generation of factors not present in the input case\nmaterials and abstention as the model's ability to refrain from generating\narguments when instructed and no factual basis exists. Our automated method\nemploys an external LLM to extract factors from generated arguments and\ncompares them against the ground-truth factors provided in the input case\ntriples (current case and two precedent cases). We evaluated eight distinct\nLLMs on three tests of increasing difficulty: 1) generating a standard 3-ply\nargument, 2) generating an argument with swapped precedent roles, and 3)\nrecognizing the impossibility of argument generation due to lack of shared\nfactors and abstaining. Our findings indicate that while current LLMs achieve\nhigh accuracy (over 90%) in avoiding hallucination on viable argument\ngeneration tests (Tests 1 & 2), they often fail to utilize the full set of\nrelevant factors present in the cases. Critically, on the abstention test (Test\n3), most models failed to follow instructions to stop, instead generating\nspurious arguments despite the lack of common factors. This automated pipeline\nprovides a scalable method for assessing these crucial LLM behaviors,\nhighlighting the need for improvements in factor utilization and robust\nabstention capabilities before reliable deployment in legal settings. Link:\nhttps://lizhang-aiandlaw.github.io/An-Automated-Pipeline-for-Evaluating-LLM-Generated-3-ply-Case-Based-Legal-Arguments/", "AI": {"tldr": "The paper introduces an automated pipeline to evaluate LLMs in generating 3-ply legal arguments, focusing on faithfulness, factor utilization, and abstention. Findings show high hallucination avoidance but poor factor use and abstention.", "motivation": "To address reliability concerns of LLMs in legal tasks by assessing their performance in generating faithful, factor-aware, and abstaining legal arguments.", "method": "An automated pipeline using an external LLM to compare generated arguments against ground-truth factors, tested on three difficulty levels.", "result": "LLMs avoid hallucination well (90%+ accuracy) but underutilize factors and fail to abstain when no factual basis exists.", "conclusion": "The pipeline highlights the need for improved factor utilization and abstention in LLMs for reliable legal deployment."}}
{"id": "2503.05840", "pdf": "https://arxiv.org/pdf/2503.05840", "abs": "https://arxiv.org/abs/2503.05840", "authors": ["Nils Graef", "Andrew Wasielewski"], "title": "Slim attention: cut your context memory in half without loss -- K-cache is all you need for MHA", "categories": ["cs.LG"], "comment": "18 pages, 7 figures", "summary": "Slim attention shrinks the context memory size by 2x for transformer models\nwith MHA (multi-head attention), which can speed up inference by up to 2x for\nlarge context windows.\n  Slim attention is an exact, mathematically identical implementation of the\nstandard attention mechanism and therefore doesn't compromise model accuracy.\nIn other words, slim attention losslessly compresses the context memory by a\nfactor of 2.\n  For encoder-decoder transformers, the context memory size can be reduced even\nfurther: For the Whisper models for example, slim attention reduces the context\nmemory by 8x, which can speed up token generation by 5x for batch size 64 for\nexample.\n  And for the T5-11B model for example, the memory can be reduced by 32x\nbecause its MHA projection dimension is larger than the embedding dimension.\n  See https://github.com/OpenMachine-ai/transformer-tricks for code and more\ntransformer tricks, and https://www.youtube.com/watch?v=uVtk3B6YO4Y for this\npaper's YouTube video.", "AI": {"tldr": "Slim attention reduces context memory size by 2x for transformer models with MHA, speeding up inference without compromising accuracy. For some models like Whisper and T5-11B, memory reduction and speed improvements are even greater.", "motivation": "To optimize transformer models by reducing memory usage and speeding up inference while maintaining accuracy.", "method": "Slim attention, an exact implementation of standard attention, losslessly compresses context memory by a factor of 2 or more.", "result": "Memory reduction by 2x (or up to 32x for T5-11B) and speed improvements (e.g., 5x faster token generation for Whisper).", "conclusion": "Slim attention is an effective, lossless method for optimizing transformer models, offering significant memory and speed benefits."}}
{"id": "2506.00653", "pdf": "https://arxiv.org/pdf/2506.00653", "abs": "https://arxiv.org/abs/2506.00653", "authors": ["Femi Bello", "Anubrata Das", "Fanzhi Zeng", "Fangcong Yin", "Liu Leqi"], "title": "Linear Representation Transferability Hypothesis: Leveraging Small Models to Steer Large Models", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": null, "summary": "It has been hypothesized that neural networks with similar architectures\ntrained on similar data learn shared representations relevant to the learning\ntask. We build on this idea by extending the conceptual framework where\nrepresentations learned across models trained on the same data can be expressed\nas linear combinations of a \\emph{universal} set of basis features. These basis\nfeatures underlie the learning task itself and remain consistent across models,\nregardless of scale. From this framework, we propose the \\textbf{Linear\nRepresentation Transferability (LRT)} Hypothesis -- that there exists an affine\ntransformation between the representation spaces of different models. To test\nthis hypothesis, we learn affine mappings between the hidden states of models\nof different sizes and evaluate whether steering vectors -- directions in\nhidden state space associated with specific model behaviors -- retain their\nsemantic effect when transferred from small to large language models using the\nlearned mappings. We find strong empirical evidence that such affine mappings\ncan preserve steering behaviors. These findings suggest that representations\nlearned by small models can be used to guide the behavior of large models, and\nthat the LRT hypothesis may be a promising direction on understanding\nrepresentation alignment across model scales.", "AI": {"tldr": "The paper introduces the Linear Representation Transferability (LRT) Hypothesis, proposing that affine transformations can align representations across neural networks of different scales, enabling small models to guide large ones.", "motivation": "To explore whether representations learned by neural networks trained on similar data can be universally aligned, enabling transferability across model scales.", "method": "The authors propose the LRT Hypothesis and test it by learning affine mappings between hidden states of models of varying sizes, evaluating the transferability of steering vectors.", "result": "Empirical evidence supports that affine mappings preserve steering behaviors, allowing small models to guide large ones.", "conclusion": "The LRT Hypothesis offers a promising framework for understanding representation alignment across model scales, with practical implications for model behavior guidance."}}
{"id": "2506.00773", "pdf": "https://arxiv.org/pdf/2506.00773", "abs": "https://arxiv.org/abs/2506.00773", "authors": ["Boheng Sheng", "Jiacheng Yao", "Meicong Zhang", "Guoxiu He"], "title": "Dynamic Chunking and Selection for Reading Comprehension of Ultra-Long Context in Large Language Models", "categories": ["cs.CL"], "comment": "Accepted by ACL 2025 Main Conference", "summary": "Large language models (LLMs) often struggle to accurately read and comprehend\nextremely long texts. Current methods for improvement typically rely on\nsplitting long contexts into fixed-length chunks. However, fixed truncation\nrisks separating semantically relevant content, leading to ambiguity and\ncompromising accurate understanding. To overcome this limitation, we propose a\nstraightforward approach for dynamically separating and selecting chunks of\nlong context, facilitating a more streamlined input for LLMs. In particular, we\ncompute semantic similarities between adjacent sentences, using lower\nsimilarities to adaptively divide long contexts into variable-length chunks. We\nfurther train a question-aware classifier to select sensitive chunks that are\ncritical for answering specific questions. Experimental results on both\nsingle-hop and multi-hop question-answering benchmarks show that the proposed\napproach consistently outperforms strong baselines. Notably, it maintains\nrobustness across a wide range of input lengths, handling sequences of up to\n256k tokens. Our datasets and code are available at the following link:\nhttps://github.com/ECNU-Text-Computing/DCS", "AI": {"tldr": "Proposes a dynamic chunking method for LLMs to better handle long texts by adaptively dividing and selecting relevant chunks based on semantic similarity and question relevance.", "motivation": "LLMs struggle with long texts due to fixed-length chunking, which can split semantically relevant content, leading to ambiguity.", "method": "Dynamically divides long contexts into variable-length chunks using semantic similarity between sentences and trains a question-aware classifier to select critical chunks.", "result": "Outperforms baselines on QA benchmarks, handling sequences up to 256k tokens robustly.", "conclusion": "The approach improves LLM performance on long texts by dynamically selecting relevant chunks, with demonstrated effectiveness and scalability."}}
{"id": "2503.10503", "pdf": "https://arxiv.org/pdf/2503.10503", "abs": "https://arxiv.org/abs/2503.10503", "authors": ["Jacob Comeau", "Mathieu Bazinet", "Pascal Germain", "Cem Subakan"], "title": "Sample Compression for Continual Learning", "categories": ["cs.LG"], "comment": null, "summary": "Continual learning algorithms aim to learn from a sequence of tasks, making\nthe training distribution non-stationary. The majority of existing continual\nlearning approaches in the literature rely on heuristics and do not provide\nlearning guarantees. In this paper, we present a new method called Continual\nPick-to-Learn (CoP2L), which is able to retain the most representative samples\nfor each task in an efficient way. CoP2L combines the Pick-to-Learn algorithm\n(rooted in the sample compression theory) and the experience replay continual\nlearning scheme. This allows us to provide non-vacuous upper bounds on the\ngeneralization loss of the learned predictors, numerically computable after\neach task. We empirically evaluate our approach on several standard continual\nlearning benchmarks across Class-Incremental, Task-Incremental, and\nDomain-Incremental settings. Our results show that CoP2L is highly competitive\nacross all setups, often outperforming existing baselines, and significantly\nmitigating catastrophic forgetting compared to vanilla experience replay in the\nClass-Incremental setting. It is possible to leverage the bounds provided by\nCoP2L in practical scenarios to certify the predictor reliability on previously\nlearned tasks, in order to improve the trustworthiness of the continual\nlearning algorithm.", "AI": {"tldr": "CoP2L is a continual learning method combining Pick-to-Learn and experience replay, offering generalization guarantees and outperforming baselines.", "motivation": "Existing continual learning methods lack theoretical guarantees; CoP2L aims to provide non-vacuous bounds on generalization loss.", "method": "CoP2L integrates Pick-to-Learn (sample compression theory) with experience replay to retain representative samples efficiently.", "result": "CoP2L outperforms baselines in Class-, Task-, and Domain-Incremental settings, mitigating catastrophic forgetting.", "conclusion": "CoP2L enhances trustworthiness in continual learning by certifying predictor reliability on past tasks."}}
{"id": "2506.00829", "pdf": "https://arxiv.org/pdf/2506.00829", "abs": "https://arxiv.org/abs/2506.00829", "authors": ["Keyuan Cheng", "Zijian Kan", "Zhixian He", "Zhuoran Zhang", "Muhammad Asif Ali", "Ke Xu", "Lijie Hu", "Di Wang"], "title": "COMPKE: Complex Question Answering under Knowledge Editing", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "Accepted by ACL 2025 Findings", "summary": "Knowledge Editing, which efficiently modifies the knowledge in large language\nmodels, has gathered great attention. Current benchmarks primarily use\nmulti-hop question answering to assess and analyze newly injected or updated\nknowledge. However, we argue that these benchmarks fail to effectively evaluate\nhow well the updated models apply this knowledge in real-life scenarios,\nparticularly when questions require complex reasoning, involving one-to-many\nrelationships or multi-step logical intersections. To fill in this gap, we\nintroduce a new benchmark, COMPKE: Complex Question Answering under Knowledge\nEditing, which includes 11,924 complex questions that reflect real-life\nsituations. We conduct an extensive evaluation of four knowledge editing\nmethods on COMPKE, revealing that their effectiveness varies notably across\ndifferent models. For instance, MeLLo attains an accuracy of 39.47 on\nGPT-4O-MINI, but this drops sharply to 3.83 on QWEN2.5-3B. We further\ninvestigate the underlying causes of these disparities from both methodological\nand model-specific perspectives. The datasets are available at\nhttps://github.com/kzjkzj666/CompKE.", "AI": {"tldr": "The paper introduces COMPKE, a benchmark for evaluating knowledge editing in large language models using complex real-life questions, revealing varying effectiveness across models.", "motivation": "Current benchmarks for knowledge editing in large language models lack evaluation of real-life applicability, especially for complex reasoning tasks.", "method": "The authors propose COMPKE, a benchmark with 11,924 complex questions, and evaluate four knowledge editing methods on it.", "result": "Effectiveness of editing methods varies significantly across models (e.g., MeLLo's accuracy drops from 39.47 to 3.83 on different models).", "conclusion": "COMPKE highlights the need for better benchmarks and methods to evaluate knowledge editing in real-life scenarios."}}
{"id": "2506.00859", "pdf": "https://arxiv.org/pdf/2506.00859", "abs": "https://arxiv.org/abs/2506.00859", "authors": ["Md Kowsher", "Nusrat Jahan Prottasha", "Shiyun Xu", "Shetu Mohanto", "Chen Chen", "Ozlem Garibay", "Niloofar Yousefi"], "title": "How Bidirectionality Helps Language Models Learn Better via Dynamic Bottleneck Estimation", "categories": ["cs.CL"], "comment": null, "summary": "Bidirectional language models have better context understanding and perform\nbetter than unidirectional models on natural language understanding tasks, yet\nthe theoretical reasons behind this advantage remain unclear. In this work, we\ninvestigate this disparity through the lens of the Information Bottleneck (IB)\nprinciple, which formalizes a trade-off between compressing input information\nand preserving task-relevant content. We propose FlowNIB, a dynamic and\nscalable method for estimating mutual information during training that\naddresses key limitations of classical IB approaches, including computational\nintractability and fixed trade-off schedules. Theoretically, we show that\nbidirectional models retain more mutual information and exhibit higher\neffective dimensionality than unidirectional models. To support this, we\npresent a generalized framework for measuring representational complexity and\nprove that bidirectional representations are strictly more informative under\nmild conditions. We further validate our findings through extensive experiments\nacross multiple models and tasks using FlowNIB, revealing how information is\nencoded and compressed throughout training. Together, our work provides a\nprincipled explanation for the effectiveness of bidirectional architectures and\nintroduces a practical tool for analyzing information flow in deep language\nmodels.", "AI": {"tldr": "Bidirectional language models outperform unidirectional ones due to better information retention and higher representational complexity, explained via the Information Bottleneck principle. FlowNIB is introduced as a scalable method to analyze this.", "motivation": "To understand why bidirectional models perform better than unidirectional ones in natural language understanding tasks.", "method": "Proposes FlowNIB, a dynamic method for estimating mutual information during training, addressing limitations of classical IB approaches. Theoretical analysis and experiments validate the framework.", "result": "Bidirectional models retain more mutual information and have higher effective dimensionality. FlowNIB effectively analyzes information flow in models.", "conclusion": "The work provides a theoretical explanation for bidirectional models' superiority and introduces FlowNIB as a practical tool for analyzing information in language models."}}
{"id": "2503.14615", "pdf": "https://arxiv.org/pdf/2503.14615", "abs": "https://arxiv.org/abs/2503.14615", "authors": ["Selim Jerad", "Anej Svete", "Jiaoda Li", "Ryan Cotterell"], "title": "Unique Hard Attention: A Tale of Two Sides", "categories": ["cs.LG", "cs.CC", "cs.CL", "cs.FL"], "comment": null, "summary": "Understanding the expressive power of transformers has recently attracted\nattention, as it offers insights into their abilities and limitations. Many\nstudies analyze unique hard attention transformers, where attention selects a\nsingle position that maximizes the attention scores. When multiple positions\nachieve the maximum score, either the rightmost or the leftmost of those is\nchosen. In this paper, we highlight the importance of this seeming triviality.\nRecently, finite-precision transformers with both leftmost- and rightmost-hard\nattention were shown to be equivalent to Linear Temporal Logic (LTL). We show\nthat this no longer holds with only leftmost-hard attention -- in that case,\nthey correspond to a \\emph{strictly weaker} fragment of LTL. Furthermore, we\nshow that models with leftmost-hard attention are equivalent to \\emph{soft}\nattention, suggesting they may better approximate real-world transformers than\nright-attention models. These findings refine the landscape of transformer\nexpressivity and underscore the role of attention directionality.", "AI": {"tldr": "The paper examines the impact of attention directionality (leftmost-hard vs. rightmost-hard) in transformers, showing leftmost-hard attention is weaker than LTL and equivalent to soft attention.", "motivation": "To understand how attention directionality affects transformer expressivity and its implications for real-world models.", "method": "Analyzes finite-precision transformers with leftmost-hard attention, comparing their expressivity to LTL and soft attention models.", "result": "Leftmost-hard attention corresponds to a weaker LTL fragment and is equivalent to soft attention, unlike rightmost-hard attention.", "conclusion": "Attention directionality significantly influences transformer expressivity, with leftmost-hard attention offering a closer approximation to real-world models."}}
{"id": "2506.00912", "pdf": "https://arxiv.org/pdf/2506.00912", "abs": "https://arxiv.org/abs/2506.00912", "authors": ["Yongdong chi", "Hanqing Wang", "Zonghan Yang", "Jian Yang", "Xiao Yan", "Yun Chen", "Guanhua Chen"], "title": "Pi-SQL: Enhancing Text-to-SQL with Fine-Grained Guidance from Pivot Programming Languages", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Text-to-SQL transforms the user queries from natural language to executable\nSQL programs, enabling non-experts to interact with complex databases. Existing\nprompt-based methods craft meticulous text guidelines and examples to\nfacilitate SQL generation, but their accuracy is hindered by the large semantic\ngap between the texts and the low-resource SQL programs. In this work, we\npropose Pi-SQL, which incorporates the high-resource Python program as a pivot\nto bridge between the natural language query and SQL program. In particular,\nPi-SQL first generates Python programs that provide fine-grained step-by-step\nguidelines in their code blocks or comments, and then produces an SQL program\nfollowing the guidance of each Python program. The final SQL program matches\nthe reference Python program's query results and, through selection from\ncandidates generated by different strategies, achieves superior execution\nspeed, with a reward-based valid efficiency score up to 4.55 higher than the\nbest-performing baseline. Extensive experiments demonstrate the effectiveness\nof Pi-SQL, which improves the execution accuracy of the best-performing\nbaseline by up to 3.20.", "AI": {"tldr": "Pi-SQL uses Python as a pivot to bridge natural language queries and SQL, improving accuracy and execution speed.", "motivation": "Existing prompt-based methods struggle with the semantic gap between text and SQL, limiting accuracy.", "method": "Pi-SQL generates Python programs for step-by-step guidance, then derives SQL from them, selecting the best candidate.", "result": "Pi-SQL achieves higher execution accuracy (up to 3.20 improvement) and efficiency (reward score 4.55 higher than baselines).", "conclusion": "Pi-SQL effectively bridges the gap between natural language and SQL, outperforming existing methods."}}
{"id": "2506.01047", "pdf": "https://arxiv.org/pdf/2506.01047", "abs": "https://arxiv.org/abs/2506.01047", "authors": ["Phan Anh Duong", "Cat Luong", "Divyesh Bommana", "Tianyu Jiang"], "title": "CHEER-Ekman: Fine-grained Embodied Emotion Classification", "categories": ["cs.CL"], "comment": "ACL 2025", "summary": "Emotions manifest through physical experiences and bodily reactions, yet\nidentifying such embodied emotions in text remains understudied. We present an\nembodied emotion classification dataset, CHEER-Ekman, extending the existing\nbinary embodied emotion dataset with Ekman's six basic emotion categories.\nUsing automatic best-worst scaling with large language models, we achieve\nperformance superior to supervised approaches on our new dataset. Our\ninvestigation reveals that simplified prompting instructions and\nchain-of-thought reasoning significantly improve emotion recognition accuracy,\nenabling smaller models to achieve competitive performance with larger ones.\nOur dataset is publicly available at: https://github.com/menamerai/cheer-ekman.", "AI": {"tldr": "The paper introduces CHEER-Ekman, a dataset for embodied emotion classification, extending binary emotion labels to Ekman's six categories. It uses large language models with best-worst scaling, outperforming supervised methods, and shows simplified prompts and chain-of-thought reasoning boost accuracy.", "motivation": "To address the understudied area of identifying embodied emotions in text by expanding emotion categories and improving recognition methods.", "method": "Uses automatic best-worst scaling with large language models, incorporating simplified prompting and chain-of-thought reasoning.", "result": "Achieves superior performance over supervised approaches, with smaller models matching larger ones in accuracy.", "conclusion": "The CHEER-Ekman dataset and proposed methods advance embodied emotion recognition, with potential for broader applications."}}
{"id": "2503.15200", "pdf": "https://arxiv.org/pdf/2503.15200", "abs": "https://arxiv.org/abs/2503.15200", "authors": ["Onno Eberhard", "Michael Muehlebach", "Claire Vernade"], "title": "Partially Observable Reinforcement Learning with Memory Traces", "categories": ["cs.LG"], "comment": null, "summary": "Partially observable environments present a considerable computational\nchallenge in reinforcement learning due to the need to consider long histories.\nLearning with a finite window of observations quickly becomes intractable as\nthe window length grows. In this work, we introduce memory traces. Inspired by\neligibility traces, these are compact representations of the history of\nobservations in the form of exponential moving averages. We prove sample\ncomplexity bounds for the problem of offline on-policy evaluation that quantify\nthe return errors achieved with memory traces for the class of Lipschitz\ncontinuous value estimates. We establish a close connection to the window\napproach, and demonstrate that, in certain environments, learning with memory\ntraces is significantly more sample efficient. Finally, we underline the\neffectiveness of memory traces empirically in online reinforcement learning\nexperiments for both value prediction and control.", "AI": {"tldr": "Memory traces, inspired by eligibility traces, improve sample efficiency in reinforcement learning for partially observable environments by compactly representing observation histories as exponential moving averages.", "motivation": "Partially observable environments in reinforcement learning require handling long histories, which becomes computationally intractable with finite observation windows.", "method": "Introduces memory traces (exponential moving averages of observation histories) and analyzes their sample complexity for offline on-policy evaluation, comparing them to window-based approaches.", "result": "Proves sample complexity bounds, shows memory traces outperform window methods in certain environments, and demonstrates empirical effectiveness in online RL for value prediction and control.", "conclusion": "Memory traces offer a computationally efficient and sample-efficient alternative to window-based methods for handling partial observability in reinforcement learning."}}
{"id": "2506.01318", "pdf": "https://arxiv.org/pdf/2506.01318", "abs": "https://arxiv.org/abs/2506.01318", "authors": ["SeungBum Ha", "Saerom Park", "Sung Whan Yoon"], "title": "Unlearning's Blind Spots: Over-Unlearning and Prototypical Relearning Attack", "categories": ["cs.LG", "cs.AI", "I.2.6"], "comment": "10 pages, 4 figures, 2 tables", "summary": "Machine unlearning (MU) aims to expunge a designated forget set from a\ntrained model without costly retraining, yet the existing techniques overlook\ntwo critical blind spots: \"over-unlearning\" that deteriorates retained data\nnear the forget set, and post-hoc \"relearning\" attacks that aim to resurrect\nthe forgotten knowledge. We first derive the over-unlearning metric\nOU@{\\epsilon}, which represents the collateral damage to the nearby region of\nthe forget set, where the over-unlearning mainly appears. Next, we expose an\nunforeseen relearning threat on MU, i.e., the Prototypical Relearning Attack,\nwhich exploits the per-class prototype of the forget class with just a few\nsamples, and easily restores the pre-unlearning performance. To counter both\nblind spots, we introduce Spotter, a plug-and-play objective that combines (i)\na masked knowledge-distillation penalty on the nearby region of forget set to\nsuppress OU@{\\epsilon}, and (ii) an intra-class dispersion loss that scatters\nforget-class embeddings, neutralizing prototypical relearning attacks. On\nCIFAR-10, as one of validations, Spotter reduces OU@{\\epsilon}by below the\n0.05X of the baseline, drives forget accuracy to 0%, preserves accuracy of the\nretain set within 1% of difference with the original, and denies the\nprototype-attack by keeping the forget set accuracy within <1%, without\naccessing retained data. It confirms that Spotter is a practical remedy of the\nunlearning's blind spots.", "AI": {"tldr": "Spotter addresses over-unlearning and relearning attacks in machine unlearning by introducing a plug-and-play objective with masked knowledge-distillation and intra-class dispersion loss.", "motivation": "Existing machine unlearning techniques overlook over-unlearning and relearning attacks, which degrade retained data and resurrect forgotten knowledge.", "method": "Spotter combines masked knowledge-distillation to mitigate over-unlearning and intra-class dispersion loss to counter relearning attacks.", "result": "On CIFAR-10, Spotter reduces over-unlearning, drives forget accuracy to 0%, preserves retain set accuracy, and denies prototype-attacks.", "conclusion": "Spotter effectively remedies blind spots in machine unlearning, proving practical and efficient."}}
{"id": "2506.01531", "pdf": "https://arxiv.org/pdf/2506.01531", "abs": "https://arxiv.org/abs/2506.01531", "authors": ["Wenhao Liu", "Zhenyi Lu", "Xinyu Hu", "Jierui Zhang", "Dailin Li", "Jiacheng Cen", "Huilin Cao", "Haiteng Wang", "Yuhan Li", "Kun Xie", "Dandan Li", "Pei Zhang", "Chengbo Zhang", "Yuxiang Ren", "Xiaohong Huang", "Yan Ma"], "title": "STORM-BORN: A Challenging Mathematical Derivations Dataset Curated via a Human-in-the-Loop Multi-Agent Framework", "categories": ["cs.CL"], "comment": "accepted by ACL2025", "summary": "High-quality math datasets are crucial for advancing the reasoning abilities\nof large language models (LLMs). However, existing datasets often suffer from\nthree key issues: outdated and insufficient challenging content, neglecting\nhuman-like reasoning, and limited reliability due to single-LLM generation. To\naddress these, we introduce STORM-BORN, an ultra-challenging dataset of\nmathematical derivations sourced from cutting-edge academic papers, which\nincludes dense human-like approximations and heuristic cues. To ensure the\nreliability and quality, we propose a novel human-in-the-loop, multi-agent data\ngeneration framework, integrating reasoning-dense filters, multi-agent\ncollaboration, and human mathematicians' evaluations. We curated a set of 2,000\nsynthetic samples and deliberately selected the 100 most difficult problems.\nEven most advanced models like GPT-o1 solved fewer than 5% of them. Fine-tuning\non STORM-BORN boosts accuracy by 7.84% (LLaMA3-8B) and 9.12% (Qwen2.5-7B). As\nAI approaches mathematician-level reasoning, STORM-BORN provides both a\nhigh-difficulty benchmark and a human-like reasoning training resource. Our\ncode and dataset are publicly available at\nhttps://github.com/lwhere/STORM-BORN.", "AI": {"tldr": "STORM-BORN is a high-quality, ultra-challenging math dataset sourced from academic papers, designed to improve LLMs' reasoning by addressing outdated content, lack of human-like reasoning, and reliability issues.", "motivation": "Existing math datasets for LLMs are outdated, lack challenging content, and neglect human-like reasoning, limiting model performance.", "method": "A human-in-the-loop, multi-agent framework generates the dataset, incorporating reasoning-dense filters, multi-agent collaboration, and human evaluations.", "result": "The dataset includes 2,000 synthetic samples, with 100 highly difficult problems. Advanced models like GPT-o1 solved fewer than 5%. Fine-tuning on STORM-BORN improved accuracy by 7.84% (LLaMA3-8B) and 9.12% (Qwen2.5-7B).", "conclusion": "STORM-BORN serves as a high-difficulty benchmark and training resource for human-like reasoning, advancing AI toward mathematician-level capabilities."}}
{"id": "2504.07437", "pdf": "https://arxiv.org/pdf/2504.07437", "abs": "https://arxiv.org/abs/2504.07437", "authors": ["Agnimitra Dasgupta", "Alexsander Marciano da Cunha", "Ali Fardisi", "Mehrnegar Aminy", "Brianna Binder", "Bryan Shaddy", "Assad A Oberai"], "title": "Unifying and extending Diffusion Models through PDEs for solving Inverse Problems", "categories": ["cs.LG", "stat.CO", "stat.ML"], "comment": null, "summary": "Diffusion models have emerged as powerful generative tools with applications\nin computer vision and scientific machine learning (SciML), where they have\nbeen used to solve large-scale probabilistic inverse problems. Traditionally,\nthese models have been derived using principles of variational inference,\ndenoising, statistical signal processing, and stochastic differential\nequations. In contrast to the conventional presentation, in this study we\nderive diffusion models using ideas from linear partial differential equations\nand demonstrate that this approach has several benefits that include a\nconstructive derivation of the forward and reverse processes, a unified\nderivation of multiple formulations and sampling strategies, and the discovery\nof a new class of variance preserving models. We also apply the conditional\nversion of these models to solve canonical conditional density estimation\nproblems and challenging inverse problems. These problems help establish\nbenchmarks for systematically quantifying the performance of different\nformulations and sampling strategies in this study and for future studies.\nFinally, we identify and implement a mechanism through which a single diffusion\nmodel can be applied to measurements obtained from multiple measurement\noperators. Taken together, the contents of this manuscript provide a new\nunderstanding of and several new directions in the application of diffusion\nmodels to solving physics-based inverse problems.", "AI": {"tldr": "The paper presents a novel derivation of diffusion models using linear partial differential equations, offering benefits like unified formulations, new model classes, and applications in inverse problems.", "motivation": "To provide a fresh perspective on diffusion models by deriving them through linear PDEs, aiming for clearer insights and broader applicability in solving physics-based inverse problems.", "method": "Derives diffusion models using linear PDEs, leading to constructive forward/reverse processes, unified formulations, and new variance-preserving models. Applies these to conditional density estimation and inverse problems.", "result": "Demonstrates the benefits of the PDE-based approach, including unified derivations, new model classes, and benchmarks for performance evaluation. Also enables single-model application to multiple measurement operators.", "conclusion": "The study advances the understanding of diffusion models, offering new theoretical and practical directions for their use in physics-based inverse problems."}}
{"id": "2506.01538", "pdf": "https://arxiv.org/pdf/2506.01538", "abs": "https://arxiv.org/abs/2506.01538", "authors": ["Guobin Zhu", "Rui Zhou", "Wenkang Ji", "Shiyu Zhao"], "title": "LAMARL: LLM-Aided Multi-Agent Reinforcement Learning for Cooperative Policy Generation", "categories": ["cs.RO", "cs.AI"], "comment": "Accepted by IEEE Robotics and Automation Letters", "summary": "Although Multi-Agent Reinforcement Learning (MARL) is effective for complex\nmulti-robot tasks, it suffers from low sample efficiency and requires iterative\nmanual reward tuning. Large Language Models (LLMs) have shown promise in\nsingle-robot settings, but their application in multi-robot systems remains\nlargely unexplored. This paper introduces a novel LLM-Aided MARL (LAMARL)\napproach, which integrates MARL with LLMs, significantly enhancing sample\nefficiency without requiring manual design. LAMARL consists of two modules: the\nfirst module leverages LLMs to fully automate the generation of prior policy\nand reward functions. The second module is MARL, which uses the generated\nfunctions to guide robot policy training effectively. On a shape assembly\nbenchmark, both simulation and real-world experiments demonstrate the unique\nadvantages of LAMARL. Ablation studies show that the prior policy improves\nsample efficiency by an average of 185.9% and enhances task completion, while\nstructured prompts based on Chain-of-Thought (CoT) and basic APIs improve LLM\noutput success rates by 28.5%-67.5%. Videos and code are available at\nhttps://windylab.github.io/LAMARL/", "AI": {"tldr": "LAMARL integrates MARL with LLMs to automate policy and reward generation, improving sample efficiency and task completion without manual tuning.", "motivation": "MARL's low sample efficiency and manual reward tuning issues, combined with unexplored LLM potential in multi-robot systems, drive the need for LAMARL.", "method": "LAMARL uses two modules: LLM-generated prior policy/reward functions and MARL for policy training. Structured prompts (CoT, APIs) enhance LLM outputs.", "result": "LAMARL improves sample efficiency by 185.9% and task completion, with LLM output success rates rising by 28.5%-67.5%.", "conclusion": "LAMARL effectively combines MARL and LLMs, demonstrating significant performance gains in multi-robot tasks."}}
{"id": "2506.01615", "pdf": "https://arxiv.org/pdf/2506.01615", "abs": "https://arxiv.org/abs/2506.01615", "authors": ["Pasunuti Prasanjith", "Prathmesh B More", "Anoop Kunchukuttan", "Raj Dabre"], "title": "IndicRAGSuite: Large-Scale Datasets and a Benchmark for Indian Language RAG Systems", "categories": ["cs.CL"], "comment": "WIP", "summary": "Retrieval-Augmented Generation (RAG) systems enable language models to access\nrelevant information and generate accurate, well-grounded, and contextually\ninformed responses. However, for Indian languages, the development of\nhigh-quality RAG systems is hindered by the lack of two critical resources: (1)\nevaluation benchmarks for retrieval and generation tasks, and (2) large-scale\ntraining datasets for multilingual retrieval. Most existing benchmarks and\ndatasets are centered around English or high-resource languages, making it\ndifficult to extend RAG capabilities to the diverse linguistic landscape of\nIndia. To address the lack of evaluation benchmarks, we create IndicMSMarco, a\nmultilingual benchmark for evaluating retrieval quality and response generation\nin 13 Indian languages, created via manual translation of 1000 diverse queries\nfrom MS MARCO-dev set. To address the need for training data, we build a\nlarge-scale dataset of (question, answer, relevant passage) tuples derived from\nthe Wikipedias of 19 Indian languages using state-of-the-art LLMs.\nAdditionally, we include translated versions of the original MS MARCO dataset\nto further enrich the training data and ensure alignment with real-world\ninformation-seeking tasks. Resources are available here:\nhttps://huggingface.co/collections/ai4bharat/indicragsuite-683e7273cb2337208c8c0fcb", "AI": {"tldr": "The paper introduces IndicMSMarco, a benchmark and dataset for improving Retrieval-Augmented Generation (RAG) systems in Indian languages, addressing the lack of evaluation benchmarks and training data.", "motivation": "The development of RAG systems for Indian languages is hindered by missing evaluation benchmarks and training datasets, which are mostly available for English or high-resource languages.", "method": "The authors create IndicMSMarco, a multilingual benchmark for 13 Indian languages, and a large-scale dataset of (question, answer, passage) tuples from 19 Indian language Wikipedias, supplemented with translated MS MARCO data.", "result": "IndicMSMarco provides evaluation benchmarks and training data for RAG systems in Indian languages, enhancing their accuracy and contextual grounding.", "conclusion": "The work bridges the gap in resources for Indian languages, enabling better RAG systems and fostering multilingual AI advancements."}}
{"id": "2504.13932", "pdf": "https://arxiv.org/pdf/2504.13932", "abs": "https://arxiv.org/abs/2504.13932", "authors": ["Deyu Cao", "Samin Aref"], "title": "Enhancing Ultra-Low-Bit Quantization of Large Language Models Through Saliency-Aware Partial Retraining", "categories": ["cs.LG", "cs.CL", "68T50, 68T07, 68T09, 68U15", "I.2.7; I.2.6; I.2.4"], "comment": "This is a post-peer-review accepted manuscript from the proceedings\n  of the 22nd International Conference on Modeling Decisions for Artificial\n  Intelligence (MDAI'25). The publisher authenticated version and full citation\n  details are available on Springer's website. 31 pages, 4 figures, 16 tables", "summary": "The growing use of large language models has raised environmental and\neconomic concerns about their intensity of resource usage during inference.\nServing these models to each user requires substantial energy and water for\ncooling. Model compression techniques like quantization can shrink large\nlanguage models and make them more resource efficient at the cost of potential\nperformance degradation. Quantization methods compress model size through\nreplacing their high-precision parameters by quantized values of lower\nprecision. Among existing methods, the ApiQ method achieves superior accuracy\npreservation at minimal memory and time overhead. We investigate two ideas to\nextend performance in ultra-low-bit quantization beyond ApiQ's level. First, we\nlook into combining existing quantization-aware training techniques with ApiQ's\npartial training. We show that this does not outperform the baseline ApiQ\nmethod with limited training data and frozen weights. This leads to two key\ninsights: (1) The substantial representational capacity that is gained through\nfull retraining is unlikely to be feasible through partial training. (2) This\ngain may depend on using a large and diverse dataset in quantization-aware\ntraining. Second, through a novel approach informed by the two insights, we\npropose an ultra-low-bit quantization method that builds upon ApiQ and extends\nits performance without the need for full retraining. This publicly available\nmethod relies on a saliency-aware regularization term that prioritizes\npreserving the most impactful parameters during quantization. Our experiments\non LLaMA 7B and 13B benchmarks demonstrate that our method reduces the ApiQ's\naccuracy degradation by 10.85\\% and 7.54\\% respectively.", "AI": {"tldr": "The paper explores ultra-low-bit quantization to improve resource efficiency in large language models, proposing a novel method that outperforms ApiQ with reduced accuracy degradation.", "motivation": "Addressing environmental and economic concerns of resource-intensive inference in large language models by enhancing quantization techniques.", "method": "Combines quantization-aware training with ApiQ's partial training, then introduces a saliency-aware regularization term for ultra-low-bit quantization.", "result": "Reduces ApiQ's accuracy degradation by 10.85% and 7.54% on LLaMA 7B and 13B benchmarks.", "conclusion": "The proposed method extends ApiQ's performance without full retraining, offering a practical solution for resource-efficient model deployment."}}
{"id": "2506.01774", "pdf": "https://arxiv.org/pdf/2506.01774", "abs": "https://arxiv.org/abs/2506.01774", "authors": ["Lu\u00eds Cruz", "Jo\u00e3o Paulo Fernandes", "Maja H. Kirkeby", "Silverio Mart\u00ednez-Fern\u00e1ndez", "June Sallou", "Hina Anwar", "Enrique Barba Roque", "Justus Bogner", "Joel Casta\u00f1o", "Fernando Castor", "Aadil Chasmawala", "Sim\u00e3o Cunha", "Daniel Feitosa", "Alexandra Gonz\u00e1lez", "Andreas Jedlitschka", "Patricia Lago", "Henry Muccini", "Ana Oprescu", "Pooja Rani", "Jo\u00e3o Saraiva", "Federica Sarro", "Raghavendra Selvan", "Karthik Vaidhyanathan", "Roberto Verdecchia", "Ivan P. Yamshchikov"], "title": "Greening AI-enabled Systems with Software Engineering: A Research Agenda for Environmentally Sustainable AI Practices", "categories": ["cs.SE", "cs.AI"], "comment": null, "summary": "The environmental impact of Artificial Intelligence (AI)-enabled systems is\nincreasing rapidly, and software engineering plays a critical role in\ndeveloping sustainable solutions. The \"Greening AI with Software Engineering\"\nCECAM-Lorentz workshop (no. 1358, 2025) funded by the Centre Europ\\'een de\nCalcul Atomique et Mol\\'eculaire and the Lorentz Center, provided an\ninterdisciplinary forum for 29 participants, from practitioners to academics,\nto share knowledge, ideas, practices, and current results dedicated to\nadvancing green software and AI research. The workshop was held February 3-7,\n2025, in Lausanne, Switzerland. Through keynotes, flash talks, and\ncollaborative discussions, participants identified and prioritized key\nchallenges for the field. These included energy assessment and standardization,\nbenchmarking practices, sustainability-aware architectures, runtime adaptation,\nempirical methodologies, and education. This report presents a research agenda\nemerging from the workshop, outlining open research directions and practical\nrecommendations to guide the development of environmentally sustainable\nAI-enabled systems rooted in software engineering principles.", "AI": {"tldr": "The workshop 'Greening AI with Software Engineering' addressed the environmental impact of AI systems, focusing on sustainable solutions through interdisciplinary collaboration.", "motivation": "The rapid environmental impact of AI systems necessitates sustainable development practices, prompting the need for research and collaboration in green software and AI.", "method": "The workshop involved 29 participants from academia and industry, featuring keynotes, flash talks, and discussions to identify key challenges like energy assessment, benchmarking, and sustainability-aware architectures.", "result": "A research agenda was developed, highlighting open research directions and practical recommendations for sustainable AI systems.", "conclusion": "The workshop emphasized the role of software engineering in advancing green AI, providing a roadmap for future research and development."}}
{"id": "2506.01776", "pdf": "https://arxiv.org/pdf/2506.01776", "abs": "https://arxiv.org/abs/2506.01776", "authors": ["Yile Liu", "Ziwei Ma", "Xiu Jiang", "Jinglu Hu", "Jing Chang", "Liang Li"], "title": "MaXIFE: Multilingual and Cross-lingual Instruction Following Evaluation", "categories": ["cs.CL", "cs.AI"], "comment": "ACL 2025 Main Conference", "summary": "With the rapid adoption of large language models (LLMs) in natural language\nprocessing, the ability to follow instructions has emerged as a key metric for\nevaluating their practical utility. However, existing evaluation methods often\nfocus on single-language scenarios, overlooking the challenges and differences\npresent in multilingual and cross-lingual contexts. To address this gap, we\nintroduce MaXIFE: a comprehensive evaluation benchmark designed to assess\ninstruction-following capabilities across 23 different languages with 1667\nverifiable instruction tasks. MaXIFE integrates both Rule-Based Evaluation and\nModel-Based Evaluation, ensuring a balance of efficiency and accuracy. We\napplied MaXIFE to evaluate several leading commercial LLMs, establishing\nbaseline results for future comparisons. By providing a standardized tool for\nmultilingual instruction-following evaluation, MaXIFE aims to advance research\nand development in natural language processing.", "AI": {"tldr": "MaXIFE is a multilingual benchmark for evaluating instruction-following in LLMs across 23 languages, combining rule-based and model-based methods.", "motivation": "Existing evaluation methods for LLMs focus on single-language scenarios, neglecting multilingual challenges.", "method": "MaXIFE uses Rule-Based and Model-Based Evaluation across 23 languages with 1667 tasks.", "result": "Baseline results for leading commercial LLMs were established.", "conclusion": "MaXIFE provides a standardized tool to advance multilingual NLP research."}}
{"id": "2504.15037", "pdf": "https://arxiv.org/pdf/2504.15037", "abs": "https://arxiv.org/abs/2504.15037", "authors": ["Huanyu Zhang", "Chengzu Li", "Wenshan Wu", "Shaoguang Mao", "Yifan Zhang", "Haochen Tian", "Ivan Vuli\u0107", "Zhang Zhang", "Liang Wang", "Tieniu Tan", "Furu Wei"], "title": "Scaling and Beyond: Advancing Spatial Reasoning in MLLMs Requires New Recipes", "categories": ["cs.LG"], "comment": null, "summary": "Multimodal Large Language Models (MLLMs) have demonstrated impressive\nperformance in general vision-language tasks. However, recent studies have\nexposed critical limitations in their spatial reasoning capabilities. This\ndeficiency in spatial reasoning significantly constrains MLLMs' ability to\ninteract effectively with the physical world, thereby limiting their broader\napplications. We argue that spatial reasoning capabilities will not naturally\nemerge from merely scaling existing architectures and training methodologies.\nInstead, this challenge demands dedicated attention to fundamental\nmodifications in the current MLLM development approach. In this position paper,\nwe first establish a comprehensive framework for spatial reasoning within the\ncontext of MLLMs. We then elaborate on its pivotal role in real-world\napplications. Through systematic analysis, we examine how individual components\nof the current methodology, from training data to reasoning mechanisms,\ninfluence spatial reasoning capabilities. This examination reveals critical\nlimitations while simultaneously identifying promising avenues for advancement.\nOur work aims to direct the AI research community's attention toward these\ncrucial yet underexplored aspects. By highlighting these challenges and\nopportunities, we seek to catalyze progress toward achieving human-like spatial\nreasoning capabilities in MLLMs.", "AI": {"tldr": "The paper highlights the limitations of Multimodal Large Language Models (MLLMs) in spatial reasoning and proposes a dedicated approach to address this gap for broader real-world applications.", "motivation": "Current MLLMs lack effective spatial reasoning, limiting their interaction with the physical world. The paper argues this won't improve by scaling existing methods alone.", "method": "The authors establish a framework for spatial reasoning in MLLMs, analyze current methodologies, and identify limitations and opportunities.", "result": "The analysis reveals critical gaps in training data and reasoning mechanisms, pointing to potential improvements.", "conclusion": "The paper calls for focused research to enhance spatial reasoning in MLLMs, aiming for human-like capabilities."}}
{"id": "2308.16061", "pdf": "https://arxiv.org/pdf/2308.16061", "abs": "https://arxiv.org/abs/2308.16061", "authors": ["Estelle Ruellan", "Masarah Paquet-Clouston", "Sebastian Garcia"], "title": "Conti Inc.: Understanding the Internal Discussions of a large Ransomware-as-a-Service Operator with Machine Learning", "categories": ["cs.CR", "cs.CL", "cs.LG"], "comment": null, "summary": "Ransomware-as-a-service (RaaS) is increasing the scale and complexity of\nransomware attacks. Understanding the internal operations behind RaaS has been\na challenge due to the illegality of such activities. The recent chat leak of\nthe Conti RaaS operator, one of the most infamous ransomware operators on the\ninternational scene, offers a key opportunity to better understand the inner\nworkings of such organizations. This paper analyzes the main topic discussions\nin the Conti chat leak using machine learning techniques such as Natural\nLanguage Processing (NLP) and Latent Dirichlet Allocation (LDA), as well as\nvisualization strategies. Five discussion topics are found: 1) Business, 2)\nTechnical, 3) Internal tasking/Management, 4) Malware, and 5) Customer\nService/Problem Solving. Moreover, the distribution of topics among Conti\nmembers shows that only 4% of individuals have specialized discussions while\nalmost all individuals (96%) are all-rounders, meaning that their discussions\nrevolve around the five topics. The results also indicate that a significant\nproportion of Conti discussions are non-tech related. This study thus\nhighlights that running such large RaaS operations requires a workforce skilled\nbeyond technical abilities, with individuals involved in various tasks, from\nmanagement to customer service or problem solving. The discussion topics also\nshow that the organization behind the Conti RaaS oper5086933ator shares\nsimilarities with a large firm. We conclude that, although RaaS represents an\nexample of specialization in the cybercrime industry, only a few members are\nspecialized in one topic, while the rest runs and coordinates the RaaS\noperation.", "AI": {"tldr": "The paper analyzes the Conti RaaS chat leak using NLP and LDA, identifying five discussion topics and revealing that most members are all-rounders, not specialists.", "motivation": "To understand the inner workings of RaaS operations, leveraging the rare opportunity of the Conti chat leak.", "method": "Uses NLP, LDA, and visualization techniques to analyze chat data and categorize discussions.", "result": "Identifies five topics (Business, Technical, Management, Malware, Customer Service) and shows 96% of members discuss all topics, not specializing.", "conclusion": "RaaS operations require diverse skills, resembling large firms, with few specialists and mostly all-rounders coordinating the operation."}}
{"id": "2504.16580", "pdf": "https://arxiv.org/pdf/2504.16580", "abs": "https://arxiv.org/abs/2504.16580", "authors": ["Ignacio Peis", "Batuhan Koyuncu", "Isabel Valera", "Jes Frellsen"], "title": "Hyper-Transforming Latent Diffusion Models", "categories": ["cs.LG", "stat.ML"], "comment": "Accepted at ICML 2025", "summary": "We introduce a novel generative framework for functions by integrating\nImplicit Neural Representations (INRs) and Transformer-based hypernetworks into\nlatent variable models. Unlike prior approaches that rely on MLP-based\nhypernetworks with scalability limitations, our method employs a\nTransformer-based decoder to generate INR parameters from latent variables,\naddressing both representation capacity and computational efficiency. Our\nframework extends latent diffusion models (LDMs) to INR generation by replacing\nstandard decoders with a Transformer-based hypernetwork, which can be trained\neither from scratch or via hyper-transforming: a strategy that fine-tunes only\nthe decoder while freezing the pre-trained latent space. This enables efficient\nadaptation of existing generative models to INR-based representations without\nrequiring full retraining. We validate our approach across multiple modalities,\ndemonstrating improved scalability, expressiveness, and generalization over\nexisting INR-based generative models. Our findings establish a unified and\nflexible framework for learning structured function representations.", "AI": {"tldr": "A novel generative framework combines Implicit Neural Representations (INRs) and Transformer-based hypernetworks for scalable and efficient function generation, outperforming existing methods.", "motivation": "To overcome scalability and representation limitations of MLP-based hypernetworks in generating INRs, leveraging the strengths of Transformers and latent variable models.", "method": "Integrates Transformer-based hypernetworks into latent variable models, replacing standard decoders. Supports training from scratch or fine-tuning via hyper-transforming.", "result": "Demonstrates improved scalability, expressiveness, and generalization across multiple modalities compared to prior INR-based models.", "conclusion": "Establishes a unified, flexible framework for structured function representation learning, enabling efficient adaptation of existing generative models."}}
{"id": "2505.01660", "pdf": "https://arxiv.org/pdf/2505.01660", "abs": "https://arxiv.org/abs/2505.01660", "authors": ["Sicong Li", "Qianqian Xu", "Zhiyong Yang", "Zitai Wang", "Linchao Zhang", "Xiaochun Cao", "Qingming Huang"], "title": "Focal-SAM: Focal Sharpness-Aware Minimization for Long-Tailed Classification", "categories": ["cs.LG"], "comment": null, "summary": "Real-world datasets often follow a long-tailed distribution, making\ngeneralization to tail classes difficult. Recent methods resorted to long-tail\nvariants of Sharpness-Aware Minimization (SAM), such as ImbSAM and CC-SAM, to\nimprove generalization by flattening the loss landscape. However, these\nattempts face a trade-off between computational efficiency and control over the\nloss landscape. On the one hand, ImbSAM is efficient but offers only coarse\ncontrol as it excludes head classes from the SAM process. On the other hand,\nCC-SAM provides fine-grained control through class-dependent perturbations but\nat the cost of efficiency due to multiple backpropagations. Seeing this\ndilemma, we introduce Focal-SAM, which assigns different penalties to\nclass-wise sharpness, achieving fine-grained control without extra\nbackpropagations, thus maintaining efficiency. Furthermore, we theoretically\nanalyze Focal-SAM's generalization ability and derive a sharper generalization\nbound. Extensive experiments on both traditional and foundation models validate\nthe effectiveness of Focal-SAM.", "AI": {"tldr": "Focal-SAM improves generalization in long-tailed datasets by assigning class-wise penalties for sharpness, balancing efficiency and control without extra backpropagations.", "motivation": "Addressing the trade-off between computational efficiency and fine-grained control in existing long-tail SAM variants (ImbSAM, CC-SAM).", "method": "Introduces Focal-SAM, which penalizes class-wise sharpness differently, avoiding multiple backpropagations.", "result": "Achieves fine-grained control efficiently, validated by experiments on traditional and foundation models.", "conclusion": "Focal-SAM offers a practical solution for long-tailed datasets with theoretical and empirical support."}}
{"id": "2505.04560", "pdf": "https://arxiv.org/pdf/2505.04560", "abs": "https://arxiv.org/abs/2505.04560", "authors": ["Guanghui Wang", "Zhiyong Yang", "Zitai Wang", "Shi Wang", "Qianqian Xu", "Qingming Huang"], "title": "ABKD: Pursuing a Proper Allocation of the Probability Mass in Knowledge Distillation via $\u03b1$-$\u03b2$-Divergence", "categories": ["cs.LG"], "comment": "ICML 2025 Spotlight", "summary": "Knowledge Distillation (KD) transfers knowledge from a large teacher model to\na smaller student model by minimizing the divergence between their output\ndistributions, typically using forward Kullback-Leibler divergence (FKLD) or\nreverse KLD (RKLD). It has become an effective training paradigm due to the\nbroader supervision information provided by the teacher distribution compared\nto one-hot labels. We identify that the core challenge in KD lies in balancing\ntwo mode-concentration effects: the \\textbf{\\textit{Hardness-Concentration}}\neffect, which refers to focusing on modes with large errors, and the\n\\textbf{\\textit{Confidence-Concentration}} effect, which refers to focusing on\nmodes with high student confidence. Through an analysis of how probabilities\nare reassigned during gradient updates, we observe that these two effects are\nentangled in FKLD and RKLD, but in extreme forms. Specifically, both are too\nweak in FKLD, causing the student to fail to concentrate on the target class.\nIn contrast, both are too strong in RKLD, causing the student to overly\nemphasize the target class while ignoring the broader distributional\ninformation from the teacher. To address this imbalance, we propose ABKD, a\ngeneric framework with $\\alpha$-$\\beta$-divergence. Our theoretical results\nshow that ABKD offers a smooth interpolation between FKLD and RKLD, achieving\nan effective trade-off between these effects. Extensive experiments on 17\nlanguage/vision datasets with 12 teacher-student settings confirm its efficacy.\nThe code is available at https://github.com/ghwang-s/abkd.", "AI": {"tldr": "ABKD proposes a framework using \u03b1-\u03b2-divergence to balance Hardness-Concentration and Confidence-Concentration effects in Knowledge Distillation, outperforming FKLD and RKLD.", "motivation": "The core challenge in KD is balancing Hardness-Concentration and Confidence-Concentration effects, which are entangled in FKLD and RKLD but in extreme forms.", "method": "ABKD uses \u03b1-\u03b2-divergence to interpolate between FKLD and RKLD, achieving a trade-off between the two effects.", "result": "ABKD outperforms FKLD and RKLD across 17 datasets and 12 teacher-student settings.", "conclusion": "ABKD effectively balances mode-concentration effects, improving KD performance."}}
{"id": "2505.06892", "pdf": "https://arxiv.org/pdf/2505.06892", "abs": "https://arxiv.org/abs/2505.06892", "authors": ["Zhen Liu", "Yicheng Luo", "Boyuan Li", "Emadeldeen Eldele", "Min Wu", "Qianli Ma"], "title": "Learning Soft Sparse Shapes for Efficient Time-Series Classification", "categories": ["cs.LG"], "comment": "Accepted in ICML 2025", "summary": "Shapelets are discriminative subsequences (or shapes) with high\ninterpretability in time series classification. Due to the time-intensive\nnature of shapelet discovery, existing shapelet-based methods mainly focus on\nselecting discriminative shapes while discarding others to achieve candidate\nsubsequence sparsification. However, this approach may exclude beneficial\nshapes and overlook the varying contributions of shapelets to classification\nperformance. To this end, we propose a Soft sparse Shapes (SoftShape) model for\nefficient time series classification. Our approach mainly introduces soft shape\nsparsification and soft shape learning blocks. The former transforms shapes\ninto soft representations based on classification contribution scores, merging\nlower-scored ones into a single shape to retain and differentiate all\nsubsequence information. The latter facilitates intra- and inter-shape temporal\npattern learning, improving model efficiency by using sparsified soft shapes as\ninputs. Specifically, we employ a learnable router to activate a subset of\nclass-specific expert networks for intra-shape pattern learning. Meanwhile, a\nshared expert network learns inter-shape patterns by converting sparsified\nshapes into sequences. Extensive experiments show that SoftShape outperforms\nstate-of-the-art methods and produces interpretable results.", "AI": {"tldr": "SoftShape introduces soft shape sparsification and learning blocks for efficient time series classification, outperforming existing methods.", "motivation": "Existing shapelet-based methods discard non-discriminative shapes, potentially losing beneficial ones and ignoring varying contributions of shapelets.", "method": "Proposes soft shape sparsification (merging lower-scored shapes) and learning blocks (intra- and inter-shape pattern learning) using a learnable router and shared expert network.", "result": "SoftShape outperforms state-of-the-art methods and provides interpretable results.", "conclusion": "The SoftShape model effectively retains and differentiates all subsequence information while improving classification efficiency and interpretability."}}
{"id": "2506.00261", "pdf": "https://arxiv.org/pdf/2506.00261", "abs": "https://arxiv.org/abs/2506.00261", "authors": ["Xiaochen Wang", "Zongyu Wu", "Yuan Zhong", "Xiang Zhang", "Suhang Wang", "Fenglong Ma"], "title": "GPR: Empowering Generation with Graph-Pretrained Retriever", "categories": ["cs.IR", "cs.CL"], "comment": null, "summary": "Graph retrieval-augmented generation (GRAG) places high demands on\ngraph-specific retrievers. However, existing retrievers often rely on language\nmodels pretrained on plain text, limiting their effectiveness due to domain\nmisalignment and structure ignorance. To address these challenges, we propose\nGPR, a graph-based retriever pretrained directly on knowledge graphs. GPR\naligns natural language questions with relevant subgraphs through LLM-guided\ngraph augmentation and employs a structure-aware objective to learn\nfine-grained retrieval strategies. Experiments on two datasets, three LLM\nbackbones, and five baselines show that GPR consistently improves both\nretrieval quality and downstream generation, demonstrating its effectiveness as\na robust retrieval solution for GRAG.", "AI": {"tldr": "GPR is a graph-based retriever pretrained on knowledge graphs to improve retrieval quality and downstream generation in GRAG by addressing domain misalignment and structure ignorance.", "motivation": "Existing retrievers rely on language models pretrained on plain text, leading to domain misalignment and structure ignorance, which limits their effectiveness in GRAG.", "method": "GPR uses LLM-guided graph augmentation to align natural language questions with relevant subgraphs and employs a structure-aware objective for fine-grained retrieval.", "result": "Experiments on two datasets, three LLM backbones, and five baselines show GPR consistently improves retrieval quality and downstream generation.", "conclusion": "GPR is an effective and robust retrieval solution for GRAG, outperforming existing methods."}}
{"id": "2505.07783", "pdf": "https://arxiv.org/pdf/2505.07783", "abs": "https://arxiv.org/abs/2505.07783", "authors": ["Yanxin Liu", "Yunqi Zhang"], "title": "Relative Overfitting and Accept-Reject Framework", "categories": ["cs.LG"], "comment": null, "summary": "Currently, the scaling law of Large Language Models (LLMs) faces challenges\nand bottlenecks. This paper posits that noise effects, stemming from changes in\nthe signal-to-noise ratio under diminishing marginal returns, are the root\ncause of these issues. To control this noise, we investigated the differences\nbetween models with performance advantages and disadvantages, introducing the\nconcept of \"relative overfitting.\" Based on their complementary strengths, we\nhave proposed an application framework, Accept-Reject (AR), and the associated\nAR Law, which operates within this framework to elucidate the patterns of\nperformance changes after model integration. In Natural Language Processing\n(NLP), we use LLMs and Small Language Models (SLMs) as the medium for\ndiscussion. This framework enables SLMs to exert a universal positive influence\non LLM decision outputs, rather than the intuitively expected potential\nnegative influence. We validated our approach using self-built models based on\nmainstream architectures and pre-trained mainstream models across multiple\ndatasets, including basic language modeling, long-context tasks, subject\nexamination, and question-answering (QA) benchmarks. The results demonstrate\nthat through our framework, compared to increasing the LLM's parameters, we can\nachieve better performance improvements with significantly lower parameter and\ncomputational costs in many scenarios. These improvements are universal,\nstable, and effective. Furthermore, we explore the potential of \"relative\noverfitting\" and the AR framework in other machine learning domains, such as\ncomputer vision (CV) and AI for science. We hope the proposed approach can help\nscale laws overcome existing bottlenecks.", "AI": {"tldr": "The paper addresses scaling law bottlenecks in LLMs by identifying noise effects as the root cause and proposing the AR framework to improve performance with lower costs.", "motivation": "To overcome challenges in LLM scaling laws caused by noise effects and diminishing returns, the study explores performance differences and introduces 'relative overfitting.'", "method": "The paper proposes the Accept-Reject (AR) framework and AR Law, validated using self-built and pre-trained models across various NLP tasks.", "result": "The AR framework achieves better performance improvements with lower parameter and computational costs, demonstrating universal and stable effectiveness.", "conclusion": "The approach has potential applications beyond NLP, such as CV and AI for science, aiming to help scaling laws overcome bottlenecks."}}
{"id": "2505.13405", "pdf": "https://arxiv.org/pdf/2505.13405", "abs": "https://arxiv.org/abs/2505.13405", "authors": ["Gabriel Malikal", "Ismail Alkhouri", "Alvaro Velasquez", "Adam M Alessio", "Saiprasad Ravishankar"], "title": "A Dataless Reinforcement Learning Approach to Rounding Hyperplane Optimization for Max-Cut", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "The Maximum Cut (MaxCut) problem is NP-Complete, and obtaining its optimal\nsolution is NP-hard in the worst case. As a result, heuristic-based algorithms\nare commonly used, though their design often requires significant domain\nexpertise. More recently, learning-based methods trained on large (un)labeled\ndatasets have been proposed; however, these approaches often struggle with\ngeneralizability and scalability. A well-known approximation algorithm for\nMaxCut is the Goemans-Williamson (GW) algorithm, which relaxes the Quadratic\nUnconstrained Binary Optimization (QUBO) formulation into a semidefinite\nprogram (SDP). The GW algorithm then applies hyperplane rounding by uniformly\nsampling a random hyperplane to convert the SDP solution into binary node\nassignments. In this paper, we propose a training-data-free approach based on a\nnon-episodic reinforcement learning formulation, in which an agent learns to\nselect improved rounding hyperplanes that yield better cuts than those produced\nby the GW algorithm. By optimizing over a Markov Decision Process (MDP), our\nmethod consistently achieves better cuts across large-scale graphs with varying\ndensities and degree distributions.", "AI": {"tldr": "A reinforcement learning approach is proposed to improve hyperplane rounding in the Goemans-Williamson algorithm for MaxCut, outperforming it without requiring training data.", "motivation": "Heuristic and learning-based methods for MaxCut lack generalizability and scalability, prompting a need for a more robust solution.", "method": "A non-episodic reinforcement learning formulation optimizes hyperplane selection in the GW algorithm via a Markov Decision Process.", "result": "The method consistently achieves better cuts on large-scale graphs with diverse densities and degree distributions.", "conclusion": "The proposed approach enhances the GW algorithm's performance without relying on training data, offering a scalable solution for MaxCut."}}
{"id": "2505.16583", "pdf": "https://arxiv.org/pdf/2505.16583", "abs": "https://arxiv.org/abs/2505.16583", "authors": ["Shpresim Sadiku", "Kartikeya Chitranshi", "Hiroshi Kera", "Sebastian Pokutta"], "title": "Training on Plausible Counterfactuals Removes Spurious Correlations", "categories": ["cs.LG"], "comment": null, "summary": "Plausible counterfactual explanations (p-CFEs) are perturbations that\nminimally modify inputs to change classifier decisions while remaining\nplausible under the data distribution. In this study, we demonstrate that\nclassifiers can be trained on p-CFEs labeled with induced \\emph{incorrect}\ntarget classes to classify unperturbed inputs with the original labels. While\nprevious studies have shown that such learning is possible with adversarial\nperturbations, we extend this paradigm to p-CFEs. Interestingly, our\nexperiments reveal that learning from p-CFEs is even more effective: the\nresulting classifiers achieve not only high in-distribution accuracy but also\nexhibit significantly reduced bias with respect to spurious correlations.", "AI": {"tldr": "Training classifiers on plausible counterfactual explanations (p-CFEs) with incorrect labels improves accuracy and reduces bias compared to adversarial perturbations.", "motivation": "To explore if learning from p-CFEs, which are plausible under the data distribution, can enhance classifier performance and reduce bias.", "method": "Train classifiers on p-CFEs labeled with incorrect target classes and evaluate their performance on unperturbed inputs.", "result": "Classifiers trained on p-CFEs achieve high in-distribution accuracy and significantly reduced bias compared to those trained on adversarial perturbations.", "conclusion": "Learning from p-CFEs is more effective than adversarial perturbations for improving classifier accuracy and fairness."}}
{"id": "2505.17257", "pdf": "https://arxiv.org/pdf/2505.17257", "abs": "https://arxiv.org/abs/2505.17257", "authors": ["Qihao Duan", "Bingding Huang", "Zhenqiao Song", "Irina Lehmann", "Lei Gu", "Roland Eils", "Benjamin Wild"], "title": "JanusDNA: A Powerful Bi-directional Hybrid DNA Foundation Model", "categories": ["cs.LG", "q-bio.GN"], "comment": null, "summary": "Large language models (LLMs) have revolutionized natural language processing\nand are increasingly applied to other sequential data types, including genetic\nsequences. However, adapting LLMs to genomics presents significant challenges.\nCapturing complex genomic interactions requires modeling long-range\ndependencies within DNA sequences, where interactions often span over 10,000\nbase pairs, even within a single gene, posing substantial computational burdens\nunder conventional model architectures and training paradigms. Moreover,\nstandard LLM training approaches are suboptimal for DNA: autoregressive\ntraining, while efficient, supports only unidirectional understanding. However,\nDNA is inherently bidirectional, e.g., bidirectional promoters regulate\ntranscription in both directions and account for nearly 11% of human gene\nexpression. Masked language models (MLMs) allow bidirectional understanding but\nare inefficient, as only masked tokens contribute to the loss per step. To\naddress these limitations, we introduce JanusDNA, the first bidirectional DNA\nfoundation model built upon a novel pretraining paradigm that combines the\noptimization efficiency of autoregressive modeling with the bidirectional\ncomprehension of masked modeling. JanusDNA adopts a hybrid Mamba, Attention and\nMixture of Experts (MoE) architecture, combining long-range modeling of\nAttention with efficient sequential learning of Mamba. MoE layers further scale\nmodel capacity via sparse activation while keeping computational cost low.\nNotably, JanusDNA processes up to 1 million base pairs at single nucleotide\nresolution on a single 80GB GPU. Extensive experiments and ablations show\nJanusDNA achieves new SOTA results on three genomic representation benchmarks,\noutperforming models with 250x more activated parameters. Code:\nhttps://github.com/Qihao-Duan/JanusDNA", "AI": {"tldr": "JanusDNA is a bidirectional DNA foundation model combining autoregressive and masked modeling efficiency with a hybrid architecture (Mamba, Attention, MoE), achieving SOTA results on genomic benchmarks.", "motivation": "LLMs struggle with genomic data due to long-range dependencies and bidirectional nature of DNA, requiring efficient and bidirectional modeling.", "method": "JanusDNA uses a hybrid Mamba, Attention, and MoE architecture for efficient long-range and bidirectional DNA sequence modeling.", "result": "JanusDNA processes 1M base pairs on a single GPU and outperforms models with 250x more parameters on genomic benchmarks.", "conclusion": "JanusDNA addresses LLM limitations for genomics, offering efficient, bidirectional, and scalable DNA sequence modeling."}}
{"id": "2505.21226", "pdf": "https://arxiv.org/pdf/2505.21226", "abs": "https://arxiv.org/abs/2505.21226", "authors": ["Zijing Wang", "Xingle Xu", "Yongkang Liu", "Yiqun Zhang", "Peiqin Lin", "Shi Feng", "Xiaocui Yang", "Daling Wang", "Hinrich Sch\u00fctze"], "title": "Why Do More Experts Fail? A Theoretical Analysis of Model Merging", "categories": ["cs.LG"], "comment": null, "summary": "Model merging dramatically reduces storage and computational resources by\ncombining multiple expert models into a single multi-task model. Although\nrecent model merging methods have shown promising results, they struggle to\nmaintain performance gains as the number of merged models increases. In this\npaper, we investigate the key obstacles that limit the scalability of model\nmerging when integrating a large number of expert models. First, we prove that\nthere is an upper bound on model merging. Further theoretical analysis reveals\nthat the limited effective parameter space imposes a strict constraint on the\nnumber of models that can be successfully merged. Gaussian Width shows that the\nmarginal benefit of merging additional models diminishes according to a\nstrictly concave function. This implies that the effective parameter space\nbecomes rapidly saturated as the number of merged models increases.\nFurthermore, using Approximate Kinematics Theory, we prove the existence of a\nunique optimal threshold beyond which adding more models does not yield\nsignificant performance improvements. At the same time, we introduce a\nstraightforward Reparameterized Heavy-Tailed method (RHT) to extend the\ncoverage of the merged model, thereby enhancing its performance. Empirical\nresults on 12 benchmarks, including both knowledge-intensive and\ngeneral-purpose tasks, validate our theoretical analysis. We believe that these\nresults spark further research beyond the current scope of model merging. The\nsource code is in the Github repository:\nhttps://github.com/wzj1718/ModelMergingAnalysis.", "AI": {"tldr": "The paper explores scalability limits in model merging, identifying an upper bound and diminishing returns as more models are merged. It introduces RHT to improve performance and validates findings on 12 benchmarks.", "motivation": "To address the challenge of maintaining performance gains in model merging as the number of merged models increases.", "method": "Theoretical analysis using Gaussian Width and Approximate Kinematics Theory, plus the introduction of the Reparameterized Heavy-Tailed (RHT) method.", "result": "Empirical validation on 12 benchmarks confirms the theoretical limits and shows RHT enhances performance.", "conclusion": "The study identifies scalability constraints in model merging and proposes RHT as a solution, encouraging further research."}}
{"id": "2505.23190", "pdf": "https://arxiv.org/pdf/2505.23190", "abs": "https://arxiv.org/abs/2505.23190", "authors": ["Yekun Zhu", "Min Tang", "Zheng Ma"], "title": "DeepRTE: Pre-trained Attention-based Neural Network for Radiative Tranfer", "categories": ["cs.LG"], "comment": null, "summary": "In this paper, we propose a novel neural network approach, termed DeepRTE, to\naddress the steady-state Radiative Transfer Equation (RTE). The RTE is a\ndifferential-integral equation that governs the propagation of radiation\nthrough a participating medium, with applications spanning diverse domains such\nas neutron transport, atmospheric radiative transfer, heat transfer, and\noptical imaging. Our DeepRTE framework demonstrates superior computational\nefficiency for solving the steady-state RTE, surpassing traditional methods and\nexisting neural network approaches. This efficiency is achieved by embedding\nphysical information through derivation of the RTE and mathematically-informed\nnetwork architecture. Concurrently, DeepRTE achieves high accuracy with\nsignificantly fewer parameters, largely due to its incorporation of mechanisms\nsuch as multi-head attention. Furthermore, DeepRTE is a mesh-free neural\noperator framework with inherent zero-shot capability. This is achieved by\nincorporating Green's function theory and pre-training with delta-function\ninflow boundary conditions into both its architecture design and training data\nconstruction. The efficacy of the proposed approach is substantiated through\ncomprehensive numerical experiments.", "AI": {"tldr": "DeepRTE is a novel neural network approach for solving the steady-state Radiative Transfer Equation (RTE) efficiently and accurately, outperforming traditional methods and existing neural networks.", "motivation": "The RTE governs radiation propagation in various domains, but traditional methods are computationally expensive. DeepRTE aims to improve efficiency and accuracy.", "method": "DeepRTE embeds physical information, uses a mathematically-informed architecture, and incorporates multi-head attention and Green's function theory for a mesh-free, zero-shot capable framework.", "result": "DeepRTE achieves superior computational efficiency and high accuracy with fewer parameters, validated by numerical experiments.", "conclusion": "DeepRTE is an effective, efficient, and accurate solution for the steady-state RTE, with potential applications in diverse fields."}}
{"id": "2505.23721", "pdf": "https://arxiv.org/pdf/2505.23721", "abs": "https://arxiv.org/abs/2505.23721", "authors": ["Sean Current", "Ziqi Chen", "Daniel Adu-Ampratwum", "Xia Ning", "Srinivasan Parthasarathy"], "title": "DiffER: Categorical Diffusion for Chemical Retrosynthesis", "categories": ["cs.LG"], "comment": "25 pages, 3 figures, 3 tables", "summary": "Methods for automatic chemical retrosynthesis have found recent success\nthrough the application of models traditionally built for natural language\nprocessing, primarily through transformer neural networks. These models have\ndemonstrated significant ability to translate between the SMILES encodings of\nchemical products and reactants, but are constrained as a result of their\nautoregressive nature. We propose DiffER, an alternative template-free method\nfor retrosynthesis prediction in the form of categorical diffusion, which\nallows the entire output SMILES sequence to be predicted in unison. We\nconstruct an ensemble of diffusion models which achieves state-of-the-art\nperformance for top-1 accuracy and competitive performance for top-3, top-5,\nand top-10 accuracy among template-free methods. We prove that DiffER is a\nstrong baseline for a new class of template-free model, capable of learning a\nvariety of synthetic techniques used in laboratory settings and outperforming a\nvariety of other template-free methods on top-k accuracy metrics. By\nconstructing an ensemble of categorical diffusion models with a novel length\nprediction component with variance, our method is able to approximately sample\nfrom the posterior distribution of reactants, producing results with strong\nmetrics of confidence and likelihood. Furthermore, our analyses demonstrate\nthat accurate prediction of the SMILES sequence length is key to further\nboosting the performance of categorical diffusion models.", "AI": {"tldr": "DiffER, a template-free retrosynthesis method using categorical diffusion, outperforms autoregressive models in top-k accuracy by predicting SMILES sequences in unison.", "motivation": "Autoregressive models for chemical retrosynthesis are limited; DiffER aims to overcome these constraints with a new approach.", "method": "DiffER uses an ensemble of categorical diffusion models with a novel length prediction component to predict SMILES sequences.", "result": "Achieves state-of-the-art top-1 accuracy and competitive top-k performance, learning diverse synthetic techniques.", "conclusion": "DiffER is a strong baseline for template-free models, with SMILES length prediction being crucial for performance."}}
{"id": "2505.24360", "pdf": "https://arxiv.org/pdf/2505.24360", "abs": "https://arxiv.org/abs/2505.24360", "authors": ["Stepan Shabalin", "Ayush Panda", "Dmitrii Kharlapenko", "Abdur Raheem Ali", "Yixiong Hao", "Arthur Conmy"], "title": "Interpreting Large Text-to-Image Diffusion Models with Dictionary Learning", "categories": ["cs.LG"], "comment": "10 pages, 10 figures, Mechanistic Interpretability for Vision at CVPR\n  2025", "summary": "Sparse autoencoders are a promising new approach for decomposing language\nmodel activations for interpretation and control. They have been applied\nsuccessfully to vision transformer image encoders and to small-scale diffusion\nmodels. Inference-Time Decomposition of Activations (ITDA) is a recently\nproposed variant of dictionary learning that takes the dictionary to be a set\nof data points from the activation distribution and reconstructs them with\ngradient pursuit. We apply Sparse Autoencoders (SAEs) and ITDA to a large\ntext-to-image diffusion model, Flux 1, and consider the interpretability of\nembeddings of both by introducing a visual automated interpretation pipeline.\nWe find that SAEs accurately reconstruct residual stream embeddings and beat\nMLP neurons on interpretability. We are able to use SAE features to steer image\ngeneration through activation addition. We find that ITDA has comparable\ninterpretability to SAEs.", "AI": {"tldr": "Sparse autoencoders (SAEs) and ITDA improve interpretability and control in language models, applied successfully to text-to-image diffusion models like Flux 1.", "motivation": "To enhance the interpretability and control of language model activations, particularly in large text-to-image diffusion models.", "method": "Applied Sparse Autoencoders (SAEs) and Inference-Time Decomposition of Activations (ITDA) to Flux 1, using a visual automated interpretation pipeline.", "result": "SAEs accurately reconstruct embeddings and outperform MLP neurons in interpretability. Both SAEs and ITDA enable steering image generation.", "conclusion": "SAEs and ITDA are effective for interpretability and control in large diffusion models, with SAEs showing superior performance."}}
{"id": "2505.24779", "pdf": "https://arxiv.org/pdf/2505.24779", "abs": "https://arxiv.org/abs/2505.24779", "authors": ["Yidong Luo", "Chenguang Wang", "Jiahao Yang", "Fanzeng Xia", "Tianshu Yu"], "title": "EVA-MILP: Towards Standardized Evaluation of MILP Instance Generation", "categories": ["cs.LG"], "comment": "The code is available in\n  \\url{https://github.com/anonymous-neurips-submission-2025/EVA-MILP}", "summary": "Mixed-Integer Linear Programming (MILP) is fundamental to solving complex\ndecision-making problems. The proliferation of MILP instance generation\nmethods, driven by machine learning's demand for diverse optimization datasets\nand the limitations of static benchmarks, has significantly outpaced\nstandardized evaluation techniques. Consequently, assessing the fidelity and\nutility of synthetic MILP instances remains a critical, multifaceted challenge.\nThis paper introduces a comprehensive benchmark framework designed for the\nsystematic and objective evaluation of MILP instance generation methods. Our\nframework provides a unified and extensible methodology, assessing instance\nquality across crucial dimensions: mathematical validity, structural\nsimilarity, computational hardness, and utility in downstream machine learning\ntasks. A key innovation is its in-depth analysis of solver-internal features --\nparticularly by comparing distributions of key solver outputs including root\nnode gap, heuristic success rates, and cut plane usage -- leveraging the\nsolver's dynamic solution behavior as an `expert assessment' to reveal nuanced\ncomputational resemblances. By offering a structured approach with clearly\ndefined solver-independent and solver-dependent metrics, our benchmark aims to\nfacilitate robust comparisons among diverse generation techniques, spur the\ndevelopment of higher-quality instance generators, and ultimately enhance the\nreliability of research reliant on synthetic MILP data. The framework's\neffectiveness in systematically comparing the fidelity of instance sets is\ndemonstrated using contemporary generative models.", "AI": {"tldr": "A benchmark framework for evaluating MILP instance generation methods, assessing quality across mathematical validity, structural similarity, computational hardness, and utility in ML tasks.", "motivation": "Addressing the lack of standardized evaluation techniques for synthetic MILP instances, driven by the need for diverse optimization datasets and limitations of static benchmarks.", "method": "Introduces a unified framework with solver-independent and solver-dependent metrics, analyzing solver-internal features like root node gap and heuristic success rates.", "result": "Demonstrates effectiveness in comparing instance sets, revealing nuanced computational resemblances through solver behavior.", "conclusion": "Aims to facilitate robust comparisons, improve instance generator quality, and enhance reliability of synthetic MILP data in research."}}
{"id": "2506.01213", "pdf": "https://arxiv.org/pdf/2506.01213", "abs": "https://arxiv.org/abs/2506.01213", "authors": ["Ning Zhang", "Henry Kenlay", "Li Zhang", "Mihai Cucuringu", "Xiaowen Dong"], "title": "On the Stability of Graph Convolutional Neural Networks: A Probabilistic Perspective", "categories": ["cs.LG", "eess.SP", "stat.ML"], "comment": null, "summary": "Graph convolutional neural networks (GCNNs) have emerged as powerful tools\nfor analyzing graph-structured data, achieving remarkable success across\ndiverse applications. However, the theoretical understanding of the stability\nof these models, i.e., their sensitivity to small changes in the graph\nstructure, remains in rather limited settings, hampering the development and\ndeployment of robust and trustworthy models in practice. To fill this gap, we\nstudy how perturbations in the graph topology affect GCNN outputs and propose a\nnovel formulation for analyzing model stability. Unlike prior studies that\nfocus only on worst-case perturbations, our distribution-aware formulation\ncharacterizes output perturbations across a broad range of input data. This\nway, our framework enables, for the first time, a probabilistic perspective on\nthe interplay between the statistical properties of the node data and\nperturbations in the graph topology. We conduct extensive experiments to\nvalidate our theoretical findings and demonstrate their benefits over existing\nbaselines, in terms of both representation stability and adversarial attacks on\ndownstream tasks. Our results demonstrate the practical significance of the\nproposed formulation and highlight the importance of incorporating data\ndistribution into stability analysis.", "AI": {"tldr": "The paper proposes a novel framework for analyzing the stability of GCNNs under graph topology perturbations, introducing a distribution-aware approach for probabilistic stability analysis.", "motivation": "Existing theoretical understanding of GCNN stability is limited, hindering robust model development. The study aims to address this gap by analyzing how graph perturbations affect outputs.", "method": "A distribution-aware formulation is introduced to characterize output perturbations across a broad range of input data, providing a probabilistic perspective on stability.", "result": "Experiments validate the framework's benefits over baselines, showing improved representation stability and robustness against adversarial attacks.", "conclusion": "The study highlights the importance of incorporating data distribution into stability analysis, offering practical significance for robust GCNN deployment."}}
{"id": "2506.01897", "pdf": "https://arxiv.org/pdf/2506.01897", "abs": "https://arxiv.org/abs/2506.01897", "authors": ["Wei Shen", "Zhang Yaxiang", "Minhui Huang", "Mengfan Xu", "Jiawei Zhang", "Cong Shen"], "title": "MLorc: Momentum Low-rank Compression for Large Language Model Adaptation", "categories": ["cs.LG", "cs.IT", "math.IT", "math.OC"], "comment": null, "summary": "With increasing size of large language models (LLMs), full-parameter\nfine-tuning imposes substantial memory demands. To alleviate this, we propose a\nnovel memory-efficient training paradigm called Momentum Low-rank compression\n(MLorc). By directly compressing and reconstructing momentum rather than\ngradients, MLorc avoids imposing a fixed-rank constraint on weight update\nmatrices and better preserves the training dynamics of full-parameter\nfine-tuning, in contrast to existing low-rank approaches such as LoRA and\nGaLore. Empirically, MLorc consistently outperforms other memory-efficient\ntraining methods, matches or even exceeds the performance of full fine-tuning\nwith a small rank (e.g., $r=4$), and generalizes well across different\noptimizers -- all while not compromising time or memory efficiency.\nFurthermore, we provide a theoretical guarantee for its convergence under\nreasonable assumptions.", "AI": {"tldr": "MLorc is a memory-efficient training method for LLMs that compresses momentum instead of gradients, outperforming existing low-rank approaches like LoRA and GaLore while matching full fine-tuning performance.", "motivation": "To address the high memory demands of full-parameter fine-tuning for large language models (LLMs).", "method": "Proposes Momentum Low-rank compression (MLorc), which compresses and reconstructs momentum to avoid fixed-rank constraints on weight updates, preserving training dynamics.", "result": "MLorc outperforms other memory-efficient methods, matches full fine-tuning performance with small ranks (e.g., r=4), and generalizes across optimizers without compromising efficiency.", "conclusion": "MLorc is a theoretically guaranteed, efficient alternative to full fine-tuning, offering superior performance and memory savings."}}
{"id": "2305.05529", "pdf": "https://arxiv.org/pdf/2305.05529", "abs": "https://arxiv.org/abs/2305.05529", "authors": ["Lezhi Tan", "Jianfeng Lu"], "title": "Accelerate Langevin Sampling with Birth-Death Process and Exploration Component", "categories": ["stat.CO", "cs.LG", "math.PR", "math.ST", "stat.ML", "stat.TH", "65C05, 65C35, 60J80, 62F15"], "comment": "29 pages, 7 figures", "summary": "Sampling a probability distribution with known likelihood is a fundamental\ntask in computational science and engineering. Aiming at multimodality, we\npropose a new sampling method that takes advantage of both birth-death process\nand exploration component. The main idea of this method is look before you\nleap. We keep two sets of samplers, one at warmer temperature and one at\noriginal temperature. The former one serves as pioneer in exploring new modes\nand passing useful information to the other, while the latter one samples the\ntarget distribution after receiving the information. We derive a mean-field\nlimit and show how the exploration component accelerates the sampling process.\nMoreover, we prove exponential asymptotic convergence under mild assumption.\nFinally, we test on experiments from previous literature and compare our\nmethodology to previous ones.", "AI": {"tldr": "A new sampling method combining birth-death processes and exploration components to efficiently sample multimodal distributions, with proven convergence and experimental validation.", "motivation": "Addressing the challenge of sampling multimodal distributions efficiently by leveraging exploration and information transfer between samplers.", "method": "Uses two sets of samplers (warmer and original temperature) to explore modes and sample the target distribution, with a mean-field limit analysis.", "result": "Demonstrates accelerated sampling and exponential asymptotic convergence under mild assumptions.", "conclusion": "The proposed method outperforms previous approaches in sampling multimodal distributions, validated by experiments."}}
{"id": "2308.08247", "pdf": "https://arxiv.org/pdf/2308.08247", "abs": "https://arxiv.org/abs/2308.08247", "authors": ["Pengkun Yang", "Jingzhao Zhang"], "title": "Fast and Multiphase Rates for Nearest Neighbor Classifiers", "categories": ["stat.ML", "cs.LG", "math.ST", "stat.TH"], "comment": null, "summary": "We study the scaling of classification error rates with respect to the size\nof the training dataset. In contrast to classical results where rates are\nminimax optimal for a problem class, this work starts with the empirical\nobservation that, even for a fixed data distribution, the error scaling can\nhave \\emph{diverse} rates across different ranges of sample size. To understand\nwhen and why the error rate is non-uniform, we theoretically analyze nearest\nneighbor classifiers. We show that an error scaling law can have fine-grained\nrates: in the early phase, the test error depends polynomially on the data\ndimension and decreases fast; whereas in the later phase, the error depends\nexponentially on the data dimension and decreases slowly. Our analysis\nhighlights the complexity of the data distribution in determining the test\nerror. When the data are distributed benignly, we show that the generalization\nerror of nearest neighbor classifier can depend polynomially, instead of\nexponentially, on the data dimension.", "AI": {"tldr": "The paper examines how classification error rates scale with training dataset size, revealing non-uniform error rates across sample sizes and analyzing nearest neighbor classifiers to explain this phenomenon.", "motivation": "To understand why error rates vary non-uniformly with sample size for a fixed data distribution, challenging classical minimax optimal results.", "method": "Theoretical analysis of nearest neighbor classifiers, focusing on error scaling laws and data distribution complexity.", "result": "Error rates exhibit fine-grained scaling: fast polynomial decrease in early phases and slow exponential decrease later. Benign data distributions can lead to polynomial dependence on dimension.", "conclusion": "The study highlights the nuanced role of data distribution in determining error scaling, showing that benign distributions can mitigate exponential dimension dependence."}}
{"id": "2312.03940", "pdf": "https://arxiv.org/pdf/2312.03940", "abs": "https://arxiv.org/abs/2312.03940", "authors": ["Shangdi Yu", "Joshua Engels", "Yihao Huang", "Julian Shun"], "title": "PECANN: Parallel Efficient Clustering with Graph-Based Approximate Nearest Neighbor Search", "categories": ["cs.DS", "cs.DC", "cs.LG"], "comment": null, "summary": "This paper studies density-based clustering of point sets. These methods use\ndense regions of points to detect clusters of arbitrary shapes. In particular,\nwe study variants of density peaks clustering, a popular type of algorithm that\nhas been shown to work well in practice. Our goal is to cluster large\nhigh-dimensional datasets, which are prevalent in practice. Prior solutions are\neither sequential, and cannot scale to large data, or are specialized for\nlow-dimensional data.\n  This paper unifies the different variants of density peaks clustering into a\nsingle framework, PECANN, by abstracting out several key steps common to this\nclass of algorithms. One such key step is to find nearest neighbors that\nsatisfy a predicate function, and one of the main contributions of this paper\nis an efficient way to do this predicate search using graph-based approximate\nnearest neighbor search (ANNS). To provide ample parallelism, we propose a\ndoubling search technique that enables points to find an approximate nearest\nneighbor satisfying the predicate in a small number of rounds. Our technique\ncan be applied to many existing graph-based ANNS algorithms, which can all be\nplugged into PECANN.\n  We implement five clustering algorithms with PECANN and evaluate them on\nsynthetic and real-world datasets with up to 1.28 million points and up to 1024\ndimensions on a 30-core machine with two-way hyper-threading. Compared to the\nstate-of-the-art FASTDP algorithm for high-dimensional density peaks\nclustering, which is sequential, our best algorithm is 45x-734x faster while\nachieving competitive ARI scores. Compared to the state-of-the-art parallel\nDPC-based algorithm, which is optimized for low dimensions, we show that PECANN\nis two orders of magnitude faster. As far as we know, our work is the first to\nevaluate DPC variants on large high-dimensional real-world image and text\nembedding datasets.", "AI": {"tldr": "The paper introduces PECANN, a unified framework for density peaks clustering, optimizing for large high-dimensional datasets using graph-based ANNS and doubling search for parallelism.", "motivation": "To address the limitations of prior density peaks clustering methods, which are either sequential or specialized for low-dimensional data, and to enable efficient clustering of large high-dimensional datasets.", "method": "PECANN abstracts key steps of density peaks clustering, using graph-based ANNS for predicate search and doubling search for parallelism. It integrates with existing ANNS algorithms.", "result": "PECANN achieves 45x-734x speedup over FASTDP and two orders of magnitude faster than parallel DPC-based methods, with competitive ARI scores on datasets up to 1.28M points and 1024 dimensions.", "conclusion": "PECANN is a scalable and efficient framework for density peaks clustering, particularly effective for large high-dimensional datasets, outperforming existing methods in speed while maintaining accuracy."}}
{"id": "2403.05809", "pdf": "https://arxiv.org/pdf/2403.05809", "abs": "https://arxiv.org/abs/2403.05809", "authors": ["Pengzhan Jin"], "title": "Shallow ReLU neural networks and finite elements", "categories": ["math.NA", "cs.LG", "cs.NA"], "comment": null, "summary": "We point out that (continuous or discontinuous) piecewise linear functions on\na convex polytope mesh can be represented by two-hidden-layer ReLU neural\nnetworks in a weak sense. In addition, the numbers of neurons of the two hidden\nlayers required to weakly represent are accurately given based on the numbers\nof polytopes and hyperplanes involved in this mesh. The results naturally hold\nfor constant and linear finite element functions. Such weak representation\nestablishes a bridge between shallow ReLU neural networks and finite element\nfunctions, and leads to a perspective for analyzing approximation capability of\nReLU neural networks in $L^p$ norm via finite element functions. Moreover, we\ndiscuss the strict representation for tensor finite element functions via the\nrecent tensor neural networks.", "AI": {"tldr": "Two-hidden-layer ReLU networks can weakly represent piecewise linear functions on convex polytope meshes, with neuron counts based on mesh complexity. This bridges shallow ReLU networks and finite element functions, aiding $L^p$ norm analysis.", "motivation": "To connect ReLU neural networks with finite element functions, enabling analysis of approximation capabilities in $L^p$ norm.", "method": "Weak representation of piecewise linear functions using two-hidden-layer ReLU networks, with neuron counts derived from polytope and hyperplane numbers in the mesh.", "result": "Accurate neuron counts for weak representation are provided, extending to constant and linear finite element functions.", "conclusion": "The weak representation links shallow ReLU networks and finite element functions, offering a new perspective for approximation analysis."}}
{"id": "2403.14848", "pdf": "https://arxiv.org/pdf/2403.14848", "abs": "https://arxiv.org/abs/2403.14848", "authors": ["Philip Charles", "Deep Ray"], "title": "Learning WENO for entropy stable schemes to solve conservation laws", "categories": ["math.NA", "cs.LG", "cs.NA", "65M06, 65M12, 35L65, 68T07"], "comment": "25 pages, 11 figures, 4 tables (Supplementary Materials: 12 pages, 7\n  figures, 3 tables)", "summary": "Entropy conditions play a crucial role in the extraction of a physically\nrelevant solution for systems of conservation laws, thus motivating the\nconstruction of entropy stable schemes that satisfy a discrete analogue of such\nconditions. TeCNO schemes (Fjordholm et al. 2012) form a class of arbitrary\nhigh-order entropy stable finite difference solvers, which require specialized\nreconstruction algorithms satisfying the sign property at each cell interface.\nThird-order weighted essentially non-oscillatory (WENO) schemes called SP-WENO\n(Fjordholm and Ray, 2016) and SP-WENOc (Ray, 2018) have been designed to\nsatisfy the sign property. However, these WENO algorithms can perform poorly\nnear shocks, with the numerical solutions exhibiting large spurious\noscillations. In the present work, we propose a variant of the SP-WENO, termed\nas Deep Sign-Preserving WENO (DSP-WENO), where a neural network is trained to\nlearn the WENO weighting strategy. The sign property and third-order accuracy\nare strongly imposed in the algorithm, which constrains the WENO weight\nselection region to a convex polygon. Thereafter, a neural network is trained\nto select the WENO weights from this convex region with the goal of improving\nthe shock-capturing capabilities without sacrificing the rate of convergence in\nsmooth regions. The proposed synergistic approach retains the mathematical\nframework of the TeCNO scheme while integrating deep learning to remedy the\ncomputational issues of the WENO-based reconstruction. We present several\nnumerical experiments to demonstrate the significant improvement with DSP-WENO\nover the existing variants of WENO satisfying the sign property.", "AI": {"tldr": "The paper introduces DSP-WENO, a neural network-enhanced WENO variant for entropy stable schemes, improving shock-capturing without sacrificing accuracy.", "motivation": "Existing WENO schemes (SP-WENO, SP-WENOc) suffer from poor performance near shocks, causing spurious oscillations, motivating a better solution.", "method": "A neural network is trained to select WENO weights from a constrained convex region, ensuring sign property and third-order accuracy while improving shock handling.", "result": "DSP-WENO outperforms existing WENO variants in numerical experiments, enhancing shock-capturing without convergence loss in smooth regions.", "conclusion": "DSP-WENO combines deep learning with WENO's mathematical framework, effectively addressing computational issues while maintaining entropy stability."}}
{"id": "2403.19516", "pdf": "https://arxiv.org/pdf/2403.19516", "abs": "https://arxiv.org/abs/2403.19516", "authors": ["Ning Zhang", "Xiaowen Dong", "Mihai Cucuringu"], "title": "Spectral Clustering for Directed Graphs via Likelihood Estimation on Stochastic Block Models", "categories": ["stat.ML", "cs.LG", "cs.SI", "math.ST", "stat.TH"], "comment": null, "summary": "Graph clustering is a fundamental task in unsupervised learning with broad\nreal-world applications. While spectral clustering methods for undirected\ngraphs are well-established and guided by a minimum cut optimization consensus,\ntheir extension to directed graphs remains relatively underexplored due to the\nadditional complexity introduced by edge directions. In this paper, we leverage\nstatistical inference on stochastic block models to guide the development of a\nspectral clustering algorithm for directed graphs. Specifically, we study the\nmaximum likelihood estimation under a widely used directed stochastic block\nmodel, and derive a global objective function that aligns with the underlying\ncommunity structure. We further establish a theoretical upper bound on the\nmisclustering error of its spectral relaxation, and based on this relaxation,\nintroduce a novel, self-adaptive spectral clustering method for directed\ngraphs. Extensive experiments on synthetic and real-world datasets demonstrate\nsignificant performance gains over existing baselines.", "AI": {"tldr": "A novel spectral clustering method for directed graphs is proposed, leveraging stochastic block models and demonstrating superior performance.", "motivation": "Extending spectral clustering to directed graphs is challenging due to edge directions, and existing methods are underexplored.", "method": "Uses maximum likelihood estimation under a directed stochastic block model, derives a global objective, and introduces a self-adaptive spectral clustering algorithm.", "result": "Theoretical bounds on misclustering error are established, and experiments show significant improvements over baselines.", "conclusion": "The proposed method effectively addresses the complexity of directed graphs and outperforms existing approaches."}}
{"id": "2405.14492", "pdf": "https://arxiv.org/pdf/2405.14492", "abs": "https://arxiv.org/abs/2405.14492", "authors": ["Tim Gyger", "Reinhard Furrer", "Fabio Sigrist"], "title": "Iterative Methods for Full-Scale Gaussian Process Approximations for Large Spatial Data", "categories": ["stat.ME", "cs.LG", "stat.ML", "62M30, 60G15, 68T09, 62R07, 65F08, 65F10"], "comment": null, "summary": "Gaussian processes are flexible probabilistic regression models which are\nwidely used in statistics and machine learning. However, a drawback is their\nlimited scalability to large data sets. To alleviate this, full-scale\napproximations (FSAs) combine predictive process methods and covariance\ntapering, thus approximating both global and local structures. We show how\niterative methods can be used to reduce computational costs in calculating\nlikelihoods, gradients, and predictive distributions with FSAs. In particular,\nwe introduce a novel preconditioner and show theoretically and empirically that\nit accelerates the conjugate gradient method's convergence speed and mitigates\nits sensitivity with respect to the FSA parameters and the eigenvalue structure\nof the original covariance matrix, and we demonstrate empirically that it\noutperforms a state-of-the-art pivoted Cholesky preconditioner. Furthermore, we\nintroduce an accurate and fast way to calculate predictive variances using\nstochastic simulation and iterative methods. In addition, we show how our newly\nproposed FITC preconditioner can also be used in iterative methods for Vecchia\napproximations. In our experiments, it outperforms existing state-of-the-art\npreconditioners for Vecchia approximations. All methods are implemented in a\nfree C++ software library with high-level Python and R packages.", "AI": {"tldr": "The paper addresses scalability issues in Gaussian processes by introducing full-scale approximations (FSAs) and iterative methods, including a novel preconditioner, to improve computational efficiency and accuracy.", "motivation": "Gaussian processes are widely used but face scalability challenges with large datasets. The paper aims to enhance their efficiency through approximations and iterative methods.", "method": "The authors propose FSAs combining predictive process methods and covariance tapering, along with a new preconditioner for conjugate gradient methods. They also introduce stochastic simulation for predictive variances and extend the preconditioner to Vecchia approximations.", "result": "The novel preconditioner accelerates convergence, mitigates sensitivity, and outperforms existing methods. The approach is validated empirically and implemented in a C++ library with Python/R packages.", "conclusion": "The proposed methods significantly improve the scalability and efficiency of Gaussian processes, with practical implementations provided for broader use."}}
{"id": "2405.18373", "pdf": "https://arxiv.org/pdf/2405.18373", "abs": "https://arxiv.org/abs/2405.18373", "authors": ["Xiang Li", "Zebang Shen", "Liang Zhang", "Niao He"], "title": "A Hessian-Aware Stochastic Differential Equation for Modelling SGD", "categories": ["stat.ML", "cs.LG", "math.OC"], "comment": null, "summary": "Continuous-time approximation of Stochastic Gradient Descent (SGD) is a\ncrucial tool to study its escaping behaviors from stationary points. However,\nexisting stochastic differential equation (SDE) models fail to fully capture\nthese behaviors, even for simple quadratic objectives. Built on a novel\nstochastic backward error analysis framework, we derive the Hessian-Aware\nStochastic Modified Equation (HA-SME), an SDE that incorporates Hessian\ninformation of the objective function into both its drift and diffusion terms.\nOur analysis shows that HA-SME achieves the order-best approximation error\nguarantee among existing SDE models in the literature, while significantly\nreducing the dependence on the smoothness parameter of the objective. Empirical\nexperiments on neural network-based loss functions further validate this\nimprovement. Further, for quadratic objectives, under mild conditions, HA-SME\nis proved to be the first SDE model that recovers exactly the SGD dynamics in\nthe distributional sense. Consequently, when the local landscape near a\nstationary point can be approximated by quadratics, HA-SME provides a more\nprecise characterization of the local escaping behaviors of SGD. With the\nenhanced approximation guarantee, we further conduct an escape time analysis\nusing HA-SME, showcasing how it can be employed to analytically study the\nescaping behavior of SGD for general function classes.", "AI": {"tldr": "The paper introduces HA-SME, a Hessian-aware SDE model for SGD, improving approximation accuracy and capturing escaping behaviors better than existing models.", "motivation": "Existing SDE models for SGD fail to fully capture escaping behaviors, especially for quadratic objectives.", "method": "The authors derive HA-SME using stochastic backward error analysis, incorporating Hessian information into drift and diffusion terms.", "result": "HA-SME achieves the best approximation error guarantee, reduces dependence on smoothness, and exactly recovers SGD dynamics for quadratics.", "conclusion": "HA-SME provides a precise tool for analyzing SGD's escaping behaviors, validated empirically and theoretically."}}
{"id": "2408.08294", "pdf": "https://arxiv.org/pdf/2408.08294", "abs": "https://arxiv.org/abs/2408.08294", "authors": ["Mark K. Transtrum", "Gus L. W. Hart", "Tyler J. Jarvis", "Jared P. Whitehead"], "title": "eGAD! double descent is explained by Generalized Aliasing Decomposition", "categories": ["math.ST", "cs.LG", "math-ph", "math.MP", "stat.ML", "stat.TH"], "comment": null, "summary": "A central problem in data science is to use potentially noisy samples of an\nunknown function to predict values for unseen inputs. In classical statistics,\npredictive error is understood as a trade-off between the bias and the variance\nthat balances model simplicity with its ability to fit complex functions.\nHowever, over-parameterized models exhibit counterintuitive behaviors, such as\n\"double descent\" in which models of increasing complexity exhibit decreasing\ngeneralization error. Others may exhibit more complicated patterns of\npredictive error with multiple peaks and valleys. Neither double descent nor\nmultiple descent phenomena are well explained by the bias-variance\ndecomposition.\n  We introduce a novel decomposition that we call the generalized aliasing\ndecomposition (GAD) to explain the relationship between predictive performance\nand model complexity. The GAD decomposes the predictive error into three parts:\n1) model insufficiency, which dominates when the number of parameters is much\nsmaller than the number of data points, 2) data insufficiency, which dominates\nwhen the number of parameters is much greater than the number of data points,\nand 3) generalized aliasing, which dominates between these two extremes.\n  We demonstrate the applicability of the GAD to diverse applications,\nincluding random feature models from machine learning, Fourier transforms from\nsignal processing, solution methods for differential equations, and predictive\nformation enthalpy in materials discovery. Because key components of the GAD\ncan be explicitly calculated from the relationship between model class and\nsamples without seeing any data labels, it can answer questions related to\nexperimental design and model selection before collecting data or performing\nexperiments. We further demonstrate this approach on several examples and\ndiscuss implications for predictive modeling and data science.", "AI": {"tldr": "The paper introduces the Generalized Aliasing Decomposition (GAD) to explain predictive error in over-parameterized models, replacing the traditional bias-variance trade-off. It decomposes error into model insufficiency, data insufficiency, and generalized aliasing, applicable across diverse fields.", "motivation": "To address the limitations of the bias-variance decomposition in explaining phenomena like double descent and multiple descent in over-parameterized models.", "method": "Proposes the Generalized Aliasing Decomposition (GAD), which breaks predictive error into three components: model insufficiency, data insufficiency, and generalized aliasing.", "result": "GAD effectively explains predictive error patterns in various applications, including machine learning, signal processing, and materials science, and aids in experimental design and model selection.", "conclusion": "The GAD provides a more nuanced understanding of predictive error in complex models, with practical implications for data science and predictive modeling."}}
{"id": "2409.16052", "pdf": "https://arxiv.org/pdf/2409.16052", "abs": "https://arxiv.org/abs/2409.16052", "authors": ["Nilotpal Kakati", "Etienne Dreyer", "Eilam Gross"], "title": "Denoising Graph Super-Resolution towards Improved Collider Event Reconstruction", "categories": ["hep-ex", "cs.LG"], "comment": null, "summary": "In preparation for Higgs factories and energy-frontier facilities, future\ncolliders are moving toward high-granularity calorimeters to improve\nreconstruction quality. However, the cost and construction complexity of such\ndetectors is substantial, making software-based approaches like\nsuper-resolution an attractive alternative. This study explores integrating\nsuper-resolution techniques into an LHC-like reconstruction pipeline to\neffectively enhance calorimeter granularity and suppress noise. We find that\nthis software preprocessing step significantly improves reconstruction quality\nwithout physical changes to the detector. To demonstrate its impact, we propose\na novel transformer-based particle flow model that offers improved particle\nreconstruction quality and interpretability. Our results demonstrate that\nsuper-resolution can be readily applied at collider experiments.", "AI": {"tldr": "The paper explores using super-resolution techniques to enhance calorimeter granularity in colliders, improving reconstruction quality without hardware changes. A transformer-based model is proposed for better particle flow reconstruction.", "motivation": "Future colliders need high-granularity calorimeters, but hardware solutions are costly and complex. Software-based super-resolution offers a viable alternative.", "method": "Integration of super-resolution into an LHC-like pipeline and development of a transformer-based particle flow model.", "result": "Super-resolution preprocessing improves reconstruction quality and noise suppression. The transformer model enhances particle reconstruction and interpretability.", "conclusion": "Super-resolution is a practical solution for collider experiments, offering significant improvements without physical detector modifications."}}
{"id": "2411.05791", "pdf": "https://arxiv.org/pdf/2411.05791", "abs": "https://arxiv.org/abs/2411.05791", "authors": ["Felix Divo", "Eric Endress", "Kevin Endler", "Kristian Kersting", "Devendra Singh Dhami"], "title": "Forecasting Company Fundamentals", "categories": ["q-fin.ST", "cs.LG", "econ.GN", "q-fin.EC", "stat.AP", "I.2.6"], "comment": "See https://openreview.net/forum?id=haf78jerSt", "summary": "Company fundamentals are key to assessing companies' financial and overall\nsuccess and stability. Forecasting them is important in multiple fields,\nincluding investing and econometrics. While statistical and contemporary\nmachine learning methods have been applied to many time series tasks, there is\na lack of comparison of these approaches on this particularly challenging data\nregime. To this end, we try to bridge this gap and thoroughly evaluate the\ntheoretical properties and practical performance of 24 deterministic and\nprobabilistic company fundamentals forecasting models on real company data. We\nobserve that deep learning models provide superior forecasting performance to\nclassical models, in particular when considering uncertainty estimation. To\nvalidate the findings, we compare them to human analyst expectations and find\nthat their accuracy is comparable to the automatic forecasts. We further show\nhow these high-quality forecasts can benefit automated stock allocation. We\nclose by presenting possible ways of integrating domain experts to further\nimprove performance and increase reliability.", "AI": {"tldr": "The paper compares 24 deterministic and probabilistic models for forecasting company fundamentals, finding deep learning superior, especially in uncertainty estimation, and validates results against human analysts.", "motivation": "To bridge the gap in comparing statistical and machine learning methods for forecasting company fundamentals, a challenging task in investing and econometrics.", "method": "Thorough evaluation of 24 deterministic and probabilistic forecasting models on real company data, including deep learning and classical approaches.", "result": "Deep learning models outperform classical models, particularly in uncertainty estimation, and match human analyst accuracy. High-quality forecasts benefit automated stock allocation.", "conclusion": "Deep learning is effective for company fundamentals forecasting, with potential for further improvement by integrating domain experts."}}
{"id": "2411.15111", "pdf": "https://arxiv.org/pdf/2411.15111", "abs": "https://arxiv.org/abs/2411.15111", "authors": ["Afrah Farea", "Mustafa Serdar Celebi"], "title": "Learnable Activation Functions in Physics-Informed Neural Networks for Solving Partial Differential Equations", "categories": ["cs.NE", "cs.LG"], "comment": null, "summary": "We investigate learnable activation functions in Physics-Informed Neural\nNetworks (PINNs) for solving Partial Differential Equations (PDEs), comparing\ntraditional Multilayer Perceptrons (MLPs) with fixed and trainable activations\nagainst Kolmogorov-Arnold Networks (KANs) that employ learnable basis\nfunctions. While PINNs effectively incorporate physical laws into the learning\nprocess, they suffer from convergence and spectral bias problems, which limit\ntheir applicability to problems with rapid oscillations or sharp transitions.\nIn this work, we study and evaluate various activation and basis functions\nacross diverse PDEs, including oscillatory, nonlinear wave, mixed-physics, and\nfluid dynamics problems. Using empirical Neural Tangent Kernel (NTK) analysis\nand Hessian eigenvalue decomposition, we assess convergence behavior,\nstability, and high-frequency approximation capacity. While KANs offer improved\nexpressivity for capturing complex, high-frequency PDE solutions, they\nintroduce new optimization challenges, especially in deeper networks. Our\nfindings show that KANs face a curse of functional dimensionality, creating\nintractable optimization landscapes in deeper networks. Low spectral bias alone\ndoes not guarantee good performance; adaptive spectral bias approaches such as\nB-splines achieve optimal results by balancing global stability with local\nhigh-frequency resolution. Different PDE types require tailored strategies:\nsmooth global activation functions excel for wave phenomena, while local\nadaptive activation functions suit problems with sharp transitions.", "AI": {"tldr": "The paper explores learnable activation functions in PINNs for solving PDEs, comparing MLPs with fixed/trainable activations and KANs. It highlights challenges like convergence issues and spectral bias, and evaluates performance across various PDEs. KANs improve expressivity but face optimization difficulties in deeper networks. Adaptive spectral bias methods like B-splines are optimal.", "motivation": "PINNs struggle with convergence and spectral bias, limiting their use for PDEs with rapid oscillations or sharp transitions. The study aims to evaluate learnable activation functions to address these issues.", "method": "The study compares MLPs (fixed/trainable activations) and KANs (learnable basis functions) across diverse PDEs. It uses NTK analysis and Hessian eigenvalue decomposition to assess convergence, stability, and high-frequency approximation.", "result": "KANs improve expressivity for high-frequency PDEs but introduce optimization challenges in deeper networks. Adaptive spectral bias methods (e.g., B-splines) perform best by balancing stability and resolution. Different PDEs require tailored activation strategies.", "conclusion": "Learnable activation functions can enhance PINNs, but their effectiveness depends on the PDE type. KANs offer expressivity but face optimization hurdles, while adaptive methods like B-splines provide a balanced solution."}}
{"id": "2412.03238", "pdf": "https://arxiv.org/pdf/2412.03238", "abs": "https://arxiv.org/abs/2412.03238", "authors": ["Sebastian Forster", "Antonis Skarlatos"], "title": "Dynamic Consistent $k$-Center Clustering with Optimal Recourse", "categories": ["cs.DS", "cs.LG"], "comment": "In the Proceedings of SODA 2025", "summary": "Given points from an arbitrary metric space and a sequence of point updates\nsent by an adversary, what is the minimum recourse per update (i.e., the\nminimum number of changes needed to the set of centers after an update), in\norder to maintain a constant-factor approximation to a $k$-clustering problem?\nThis question has received attention in recent years under the name consistent\nclustering.\n  Previous works by Lattanzi and Vassilvitskii [ICLM '17] and Fichtenberger,\nLattanzi, Norouzi-Fard, and Svensson [SODA '21] studied $k$-clustering\nobjectives, including the $k$-center and the $k$-median objectives, under only\npoint insertions. In this paper we study the $k$-center objective in the fully\ndynamic setting, where the update is either a point insertion or a point\ndeletion. Before our work, {\\L}\\k{a}cki, Haeupler, Grunau, Rozho\\v{n}, and\nJayaram [SODA '24] gave a deterministic fully dynamic constant-factor\napproximation algorithm for the $k$-center objective with worst-case recourse\nof $2$ per update.\n  In this work, we prove that the $k$-center clustering problem admits optimal\nrecourse bounds by developing a deterministic fully dynamic constant-factor\napproximation algorithm with worst-case recourse of $1$ per update. Moreover\nour algorithm performs simple choices based on light data structures, and thus\nis arguably more direct and faster than the previous one which uses a\nsophisticated combinatorial structure. Additionally, we develop a new\ndeterministic decremental algorithm and a new deterministic incremental\nalgorithm, both of which maintain a $6$-approximate $k$-center solution with\nworst-case recourse of $1$ per update. Our incremental algorithm improves over\nthe $8$-approximation algorithm by Charikar, Chekuri, Feder, and Motwani [STOC\n'97]. Finally, we remark that since all three of our algorithms are\ndeterministic, they work against an adaptive adversary.", "AI": {"tldr": "The paper presents deterministic algorithms for dynamic $k$-center clustering with optimal recourse bounds, achieving a constant-factor approximation with minimal changes per update.", "motivation": "To address the challenge of maintaining consistent clustering solutions under dynamic updates (insertions/deletions) with minimal recourse, improving upon prior work.", "method": "Develops deterministic fully dynamic, incremental, and decremental algorithms for $k$-center clustering, focusing on simple data structures and optimal recourse.", "result": "Achieves a constant-factor approximation with worst-case recourse of 1 per update, outperforming previous algorithms in simplicity and efficiency.", "conclusion": "The deterministic algorithms provide optimal recourse bounds and are robust against adaptive adversaries, advancing dynamic clustering solutions."}}
{"id": "2502.03701", "pdf": "https://arxiv.org/pdf/2502.03701", "abs": "https://arxiv.org/abs/2502.03701", "authors": ["Oscar Smee", "Fred Roosta", "Stephen J. Wright"], "title": "First-ish Order Methods: Hessian-aware Scalings of Gradient Descent", "categories": ["math.OC", "cs.LG", "49"], "comment": null, "summary": "Gradient descent is the primary workhorse for optimizing large-scale problems\nin machine learning. However, its performance is highly sensitive to the choice\nof the learning rate. A key limitation of gradient descent is its lack of\nnatural scaling, which often necessitates expensive line searches or heuristic\ntuning to determine an appropriate step size. In this paper, we address this\nlimitation by incorporating Hessian information to scale the gradient\ndirection. By accounting for the curvature of the function along the gradient,\nour adaptive, Hessian-aware scaling method ensures a local unit step size\nguarantee, even in nonconvex settings. Near a local minimum that satisfies the\nsecond-order sufficient conditions, our approach achieves linear convergence\nwith a unit step size. We show that our method converges globally under a\nsignificantly weaker version of the standard Lipschitz gradient smoothness\nassumption. Even when Hessian information is inexact, the local unit step size\nguarantee and global convergence properties remain valid under mild conditions.\nFinally, we validate our theoretical results empirically on a range of convex\nand nonconvex machine learning tasks, showcasing the effectiveness of the\napproach.", "AI": {"tldr": "The paper introduces a Hessian-aware scaling method for gradient descent to address its sensitivity to learning rates, ensuring local unit step size guarantees and global convergence under weaker assumptions.", "motivation": "Gradient descent's performance is highly sensitive to learning rate choices, often requiring costly tuning. The paper aims to mitigate this by incorporating Hessian information for adaptive scaling.", "method": "The method uses Hessian information to scale the gradient direction, ensuring local unit step size guarantees and linear convergence near minima. It works even with inexact Hessian information.", "result": "The approach achieves linear convergence near minima, global convergence under weaker assumptions, and retains guarantees with inexact Hessian. Empirical validation confirms effectiveness.", "conclusion": "The Hessian-aware scaling method improves gradient descent by reducing sensitivity to learning rates, ensuring robust performance in convex and nonconvex settings."}}
{"id": "2502.06200", "pdf": "https://arxiv.org/pdf/2502.06200", "abs": "https://arxiv.org/abs/2502.06200", "authors": ["Yuchen He", "Chihao Zhang"], "title": "On the query complexity of sampling from non-log-concave distributions", "categories": ["cs.DS", "cs.LG", "stat.ML"], "comment": "An extended abstract of the paper will be presented at COLT 2025", "summary": "We study the problem of sampling from a $d$-dimensional distribution with\ndensity $p(x)\\propto e^{-f(x)}$, which does not necessarily satisfy good\nisoperimetric conditions.\n  Specifically, we show that for any $L,M$ satisfying $LM\\ge d\\ge 5$,\n$\\epsilon\\in \\left(0,\\frac{1}{32}\\right)$, and any algorithm with query\naccesses to the value of $f(x)$ and $\\nabla f(x)$, there exists an\n$L$-log-smooth distribution with second moment at most $M$ such that the\nalgorithm requires $\\left(\\frac{LM}{d\\epsilon}\\right)^{\\Omega(d)}$ queries to\ncompute a sample whose distribution is within $\\epsilon$ in total variation\ndistance to the target distribution. We complement the lower bound with an\nalgorithm requiring $\\left(\\frac{LM}{d\\epsilon}\\right)^{\\mathcal{O}(d)}$\nqueries, thereby characterizing the tight (up to the constant in the exponent)\nquery complexity for sampling from the family of non-log-concave distributions.\n  Our results are in sharp contrast with the recent work of Huang et al.\n(COLT'24), where an algorithm with quasi-polynomial query complexity was\nproposed for sampling from a non-log-concave distribution when\n$M=\\mathtt{poly}(d)$. Their algorithm works under the stronger condition that\nall distributions along the trajectory of the Ornstein-Uhlenbeck process,\nstarting from the target distribution, are $\\mathcal{O}(1)$-log-smooth. We\ninvestigate this condition and prove that it is strictly stronger than\nrequiring the target distribution to be $\\mathcal O(1)$-log-smooth.\nAdditionally, we study this condition in the context of mixtures of Gaussians.\n  Finally, we place our results within the broader theme of ``sampling versus\noptimization'', as studied in Ma et al. (PNAS'19). We show that for a wide\nrange of parameters, sampling is strictly easier than optimization by a\nsuper-exponential factor in the dimension $d$.", "AI": {"tldr": "The paper establishes tight query complexity bounds for sampling from non-log-concave distributions, contrasting with prior work, and explores the relationship between sampling and optimization.", "motivation": "To address the challenge of sampling from high-dimensional distributions lacking good isoperimetric conditions, particularly non-log-concave ones, and to compare sampling and optimization complexities.", "method": "The study provides lower and upper bounds on query complexity for sampling algorithms, analyzes conditions for log-smoothness, and examines mixtures of Gaussians.", "result": "The paper proves tight query complexity bounds for sampling, shows stricter conditions for prior work, and demonstrates sampling can be easier than optimization.", "conclusion": "The work characterizes sampling complexity for non-log-concave distributions and highlights the gap between sampling and optimization in high dimensions."}}
{"id": "2502.06536", "pdf": "https://arxiv.org/pdf/2502.06536", "abs": "https://arxiv.org/abs/2502.06536", "authors": ["Hidde Fokkema", "Tim van Erven", "Sara Magliacane"], "title": "Sample-efficient Learning of Concepts with Theoretical Guarantees: from Data to Concepts without Interventions", "categories": ["stat.ML", "cs.LG"], "comment": "55 pages, 20 figures, 12 Tables, Preprint", "summary": "Machine learning is a vital part of many real-world systems, but several\nconcerns remain about the lack of interpretability, explainability and\nrobustness of black-box AI systems. Concept Bottleneck Models (CBM) address\nsome of these challenges by learning interpretable concepts from\nhigh-dimensional data, e.g. images, which are used to predict labels. An\nimportant issue in CBMs are spurious correlation between concepts, which\neffectively lead to learning \"wrong\" concepts. Current mitigating strategies\nhave strong assumptions, e.g., they assume that the concepts are statistically\nindependent of each other, or require substantial interaction in terms of both\ninterventions and labels provided by annotators. In this paper, we describe a\nframework that provides theoretical guarantees on the correctness of the\nlearned concepts and on the number of required labels, without requiring any\ninterventions. Our framework leverages causal representation learning (CRL)\nmethods to learn latent causal variables from high-dimensional observations in\na unsupervised way, and then learns to align these variables with interpretable\nconcepts with few concept labels. We propose a linear and a non-parametric\nestimator for this mapping, providing a finite-sample high probability result\nin the linear case and an asymptotic consistency result for the non-parametric\nestimator. We evaluate our framework in synthetic and image benchmarks, showing\nthat the learned concepts have less impurities and are often more accurate than\nother CBMs, even in settings with strong correlations between concepts.", "AI": {"tldr": "The paper introduces a framework to improve Concept Bottleneck Models (CBMs) by addressing spurious correlations between concepts, using causal representation learning (CRL) to align latent variables with interpretable concepts, requiring fewer labels and no interventions.", "motivation": "To overcome limitations in CBMs, such as spurious correlations and reliance on strong assumptions or extensive annotations, by ensuring correct concept learning with theoretical guarantees.", "method": "Leverages CRL to learn latent causal variables unsupervised, then aligns them with interpretable concepts using a linear or non-parametric estimator.", "result": "The framework reduces concept impurities and improves accuracy in synthetic and image benchmarks, even with strong concept correlations.", "conclusion": "The proposed method enhances CBMs by ensuring correct concept learning with fewer labels and no interventions, validated by theoretical and empirical results."}}
{"id": "2502.11657", "pdf": "https://arxiv.org/pdf/2502.11657", "abs": "https://arxiv.org/abs/2502.11657", "authors": ["Matt Landreman", "Jong Youl Choi", "Caio Alves", "Prasanna Balaprakash", "R. Michael Churchill", "Rory Conlin", "Gareth Roberg-Clark"], "title": "How does ion temperature gradient turbulence depend on magnetic geometry? Insights from data and machine learning", "categories": ["physics.plasm-ph", "cs.LG"], "comment": "Updated version that was accepted by Journal of Plasma Physics, with\n  three new figures", "summary": "Magnetic geometry has a significant effect on the level of turbulent\ntransport in fusion plasmas. Here, we model and analyze this dependence using\nmultiple machine learning methods and a dataset of > 200,000 nonlinear\nsimulations of ion-temperature-gradient turbulence in diverse non-axisymmetric\ngeometries. The dataset is generated using a large collection of both optimized\nand randomly generated stellarator equilibria. At fixed gradients, the\nturbulent heat flux varies between geometries by several orders of magnitude.\nTrends are apparent among the configurations with particularly high or low heat\nflux. Regression and classification techniques from machine learning are then\napplied to extract patterns in the dataset. Due to a symmetry of the\ngyrokinetic equation, the heat flux and regressions thereof should be invariant\nto translations of the raw features in the parallel coordinate, similar to\ntranslation invariance in computer vision applications. Multiple regression\nmodels including convolutional neural networks (CNNs) and decision trees can\nachieve reasonable predictive power for the heat flux in held-out test\nconfigurations, with highest accuracy for the CNNs. Using Spearman correlation,\nsequential feature selection, and Shapley values to measure feature importance,\nit is consistently found that the most important geometric lever on the heat\nflux is the flux surface compression in regions of bad curvature. The second\nmost important feature relates to the magnitude of geodesic curvature. These\ntwo features align remarkably with surrogates that have been proposed based on\ntheory, while the methods here allow a natural extension to more features for\nincreased accuracy. The dataset, released with this publication, may also be\nused to test other proposed surrogates, and we find many previously published\nproxies do correlate well with both the heat flux and stability boundary.", "AI": {"tldr": "Machine learning methods analyze turbulent transport in fusion plasmas, revealing key geometric features affecting heat flux.", "motivation": "Understand how magnetic geometry impacts turbulent transport in fusion plasmas using a large dataset of simulations.", "method": "Employ machine learning (CNNs, decision trees) on 200,000+ simulations of ion-temperature-gradient turbulence in diverse stellarator geometries.", "result": "CNNs achieve highest accuracy; flux surface compression and geodesic curvature are key features influencing heat flux.", "conclusion": "Machine learning identifies critical geometric features, aligning with theory, and provides a dataset for further surrogate testing."}}
{"id": "2503.03184", "pdf": "https://arxiv.org/pdf/2503.03184", "abs": "https://arxiv.org/abs/2503.03184", "authors": ["Idan Attias", "Avrim Blum", "Keziah Naggita", "Donya Saless", "Dravyansh Sharma", "Matthew Walter"], "title": "PAC Learning with Improvements", "categories": ["stat.ML", "cs.GT", "cs.LG"], "comment": "41 pages, 13 figures, ICML 2025", "summary": "One of the most basic lower bounds in machine learning is that in nearly any\nnontrivial setting, it takes $\\textit{at least}$ $1/\\epsilon$ samples to learn\nto error $\\epsilon$ (and more, if the classifier being learned is complex).\nHowever, suppose that data points are agents who have the ability to improve by\na small amount if doing so will allow them to receive a (desired) positive\nclassification. In that case, we may actually be able to achieve\n$\\textit{zero}$ error by just being \"close enough\". For example, imagine a\nhiring test used to measure an agent's skill at some job such that for some\nthreshold $\\theta$, agents who score above $\\theta$ will be successful and\nthose who score below $\\theta$ will not (i.e., learning a threshold on the\nline). Suppose also that by putting in effort, agents can improve their skill\nlevel by some small amount $r$. In that case, if we learn an approximation\n$\\hat{\\theta}$ of $\\theta$ such that $\\theta \\leq \\hat{\\theta} \\leq \\theta + r$\nand use it for hiring, we can actually achieve error zero, in the sense that\n(a) any agent classified as positive is truly qualified, and (b) any agent who\ntruly is qualified can be classified as positive by putting in effort. Thus,\nthe ability for agents to improve has the potential to allow for a goal one\ncould not hope to achieve in standard models, namely zero error.\n  In this paper, we explore this phenomenon more broadly, giving general\nresults and examining under what conditions the ability of agents to improve\ncan allow for a reduction in the sample complexity of learning, or\nalternatively, can make learning harder. We also examine both theoretically and\nempirically what kinds of improvement-aware algorithms can take into account\nagents who have the ability to improve to a limited extent when it is in their\ninterest to do so.", "AI": {"tldr": "The paper explores how agents' ability to improve can enable zero-error learning, reducing sample complexity or complicating learning, and examines improvement-aware algorithms.", "motivation": "Traditional learning requires many samples to achieve low error, but if agents can improve to meet classification thresholds, zero error becomes possible.", "method": "The study provides general results on conditions where agent improvement reduces or complicates learning, and analyzes improvement-aware algorithms theoretically and empirically.", "result": "Agent improvement can enable zero-error learning under certain conditions, potentially reducing sample complexity or making learning harder.", "conclusion": "The ability of agents to improve can fundamentally alter learning outcomes, enabling zero error in some scenarios and requiring new algorithmic approaches."}}
{"id": "2503.05024", "pdf": "https://arxiv.org/pdf/2503.05024", "abs": "https://arxiv.org/abs/2503.05024", "authors": ["Yordan P. Raykov", "Hengrui Luo", "Justin D. Strait", "Wasiur R. KhudaBukhsh"], "title": "Kernel-based estimators for functional causal effects", "categories": ["stat.ME", "cs.LG", "math.ST", "stat.TH", "62G05", "G.3"], "comment": "Code is available at\n  https://github.com/JordanRaykov/Kernel-based-estimators-for-Functional-Causal-Effects", "summary": "We propose causal effect estimators based on empirical Fr\\'{e}chet means and\noperator-valued kernels, tailored to functional data spaces. These methods\naddress the challenges of high-dimensionality, sequential ordering, and model\ncomplexity while preserving robustness to treatment misspecification. Using\nstructural assumptions, we obtain compact representations of potential\noutcomes, enabling scalable estimation of causal effects over time and across\ncovariates. We provide both theoretical, regarding the consistency of\nfunctional causal effects, as well as empirical comparison of a range of\nproposed causal effect estimators.\n  Applications to binary treatment settings with functional outcomes illustrate\nthe framework's utility in biomedical monitoring, where outcomes exhibit\ncomplex temporal dynamics. Our estimators accommodate scenarios with registered\ncovariates and outcomes, aligning them to the Fr\\'{e}chet means, as well as\ncases requiring higher-order representations to capture intricate\ncovariate-outcome interactions. These advancements extend causal inference to\ndynamic and non-linear domains, offering new tools for understanding complex\ntreatment effects in functional data settings.", "AI": {"tldr": "Proposes causal effect estimators for functional data using Fr\u00e9chet means and operator-valued kernels, addressing high-dimensionality and model complexity while ensuring robustness.", "motivation": "To tackle challenges in functional data spaces like high-dimensionality, sequential ordering, and model complexity, while preserving robustness to treatment misspecification.", "method": "Uses empirical Fr\u00e9chet means and operator-valued kernels, leveraging structural assumptions for compact representations of potential outcomes.", "result": "Provides scalable estimation of causal effects over time and covariates, with theoretical consistency and empirical validation.", "conclusion": "Extends causal inference to dynamic, non-linear domains, offering tools for complex treatment effects in functional data, especially in biomedical monitoring."}}
{"id": "2503.14353", "pdf": "https://arxiv.org/pdf/2503.14353", "abs": "https://arxiv.org/abs/2503.14353", "authors": ["Erik G. Larsson", "Nicolo Michelusi"], "title": "Unified Analysis of Decentralized Gradient Descent: a Contraction Mapping Framework", "categories": ["eess.SP", "cs.DC", "cs.LG"], "comment": null, "summary": "The decentralized gradient descent (DGD) algorithm, and its sibling,\ndiffusion, are workhorses in decentralized machine learning, distributed\ninference and estimation, and multi-agent coordination. We propose a novel,\nprincipled framework for the analysis of DGD and diffusion for strongly convex,\nsmooth objectives, and arbitrary undirected topologies, using contraction\nmappings coupled with a result called the mean Hessian theorem (MHT). The use\nof these tools yields tight convergence bounds, both in the noise-free and\nnoisy regimes. While these bounds are qualitatively similar to results found in\nthe literature, our approach using contractions together with the MHT decouples\nthe algorithm dynamics (how quickly the algorithm converges to its fixed point)\nfrom its asymptotic convergence properties (how far the fixed point is from the\nglobal optimum). This yields a simple, intuitive analysis that is accessible to\na broader audience. Extensions are provided to multiple local gradient updates,\ntime-varying step sizes, noisy gradients (stochastic DGD and diffusion),\ncommunication noise, and random topologies.", "AI": {"tldr": "A novel framework for analyzing decentralized gradient descent (DGD) and diffusion algorithms using contraction mappings and the mean Hessian theorem (MHT), providing tight convergence bounds and intuitive insights.", "motivation": "To improve the analysis of DGD and diffusion algorithms for strongly convex, smooth objectives and arbitrary undirected topologies, making it more accessible and decoupling dynamics from asymptotic properties.", "method": "Uses contraction mappings and the MHT to derive tight convergence bounds, applicable to noise-free and noisy regimes, with extensions for multiple gradient updates, time-varying step sizes, and stochastic settings.", "result": "Tight convergence bounds are derived, qualitatively similar to existing literature but with clearer separation of dynamics and asymptotic properties.", "conclusion": "The framework simplifies analysis, broadens accessibility, and extends to various scenarios like stochastic gradients and random topologies."}}
{"id": "2505.13556", "pdf": "https://arxiv.org/pdf/2505.13556", "abs": "https://arxiv.org/abs/2505.13556", "authors": ["Yiru Jiao", "Simeon C. Calvert", "Sander van Cranenburgh", "Hans van Lint"], "title": "Learning Collision Risk from Naturalistic Driving with Generalised Surrogate Safety Measures", "categories": ["cs.RO", "cs.LG"], "comment": "18 pages, 8 figures", "summary": "Accurate and timely alerts for drivers or automated systems to unfolding\ncollisions remains a challenge in road safety, particularly in highly\ninteractive urban traffic. Existing approaches require labour-intensive\nannotation of sparse risk, struggle to consider varying contextual factors, or\nare useful only in the scenarios they are designed for. To address these\nlimits, this study introduces the generalised surrogate safety measure (GSSM),\na new approach that learns exclusively from naturalistic driving without crash\nor risk labels. GSSM captures the patterns of normal driving and estimates the\nextent to which a traffic interaction deviates from the norm towards unsafe\nextreme. Utilising neural networks, normal interactions are characterised by\ncontext-conditioned distributions of multi-directional spacing between road\nusers. In the same interaction context, a spacing closer than normal entails\nhigher risk of potential collision. Then a context-adaptive risk score and its\nassociated probability can be calculated based on the theory of extreme values.\nAny measurable factors, such as motion kinematics, weather, lighting, can serve\nas part of the context, allowing for diverse coverage of safety-critical\ninteractions. Multiple public driving datasets are used to train GSSMs, which\nare tested with 2,591 real-world crashes and near-crashes reconstructed from\nthe SHRP2 NDS. A vanilla GSSM using only instantaneous states achieves AUPRC of\n0.9 and secures a median time advance of 2.6 seconds to prevent potential\ncollisions. Additional data and contextual factors provide further performance\ngains. Across various interaction types such as rear-end, merging, and\ncrossing, the accuracy and timeliness of GSSM consistently outperforms existing\nbaselines. GSSM therefore establishes a scalable, context-aware, and\ngeneralisable foundation to proactively quantify collision risk in traffic\ninteractions.", "AI": {"tldr": "The paper introduces GSSM, a method to detect collision risks in traffic by learning from normal driving patterns without crash labels, outperforming existing baselines in accuracy and timeliness.", "motivation": "Existing collision alert systems are limited by sparse risk annotation, lack of contextual adaptability, or scenario-specific designs. GSSM addresses these by learning from naturalistic driving data.", "method": "GSSM uses neural networks to model normal driving patterns and calculates risk scores based on deviations from these norms, incorporating contextual factors like motion, weather, and lighting.", "result": "Tested on 2,591 real-world crashes, GSSM achieves an AUPRC of 0.9 and a median 2.6-second advance warning, with performance improving with additional data and context.", "conclusion": "GSSM provides a scalable, context-aware, and generalisable solution for proactive collision risk quantification in diverse traffic interactions."}}
{"id": "2505.14806", "pdf": "https://arxiv.org/pdf/2505.14806", "abs": "https://arxiv.org/abs/2505.14806", "authors": ["Minglu Zhao", "Dehong Xu", "Deqian Kong", "Wen-Hao Zhang", "Ying Nian Wu"], "title": "Place Cells as Proximity-Preserving Embeddings: From Multi-Scale Random Walk to Straight-Forward Path Planning", "categories": ["q-bio.NC", "cs.LG", "stat.ML"], "comment": null, "summary": "The hippocampus enables spatial navigation through place cell populations\nforming cognitive maps. We propose proximity-preserving neural embeddings to\nencode multi-scale random walk transitions, where the inner product $\\langle\nh(x, t), h(y, t) \\rangle = q(y|x, t)$ represents normalized transition\nprobabilities, with $h(x, t)$ as the embedding at location $x$ and $q(y|x, t)$\nas the transition probability at scale $\\sqrt{t}$. This scale hierarchy mirrors\nhippocampal dorsoventral organization. The embeddings $h(x, t)$ reduce pairwise\nspatial proximity into an environmental map, with Euclidean distances\npreserving proximity information. We use gradient ascent on $q(y|x, t)$ for\nstraight-forward path planning, employing adaptive scale selection for\ntrap-free, smooth trajectories, equivalent to minimizing embedding space\ndistances. Matrix squaring ($P_{2t} = P_t^2$) efficiently builds global\ntransitions from local ones ($P_1$), enabling preplay-like shortcut prediction.\nExperiments demonstrate localized place fields, multi-scale tuning,\nadaptability, and remapping, achieving robust navigation in complex\nenvironments. Our biologically plausible framework, extensible to theta-phase\nprecession, unifies spatial and temporal coding for scalable navigation.", "AI": {"tldr": "Proximity-preserving neural embeddings encode multi-scale random walk transitions for spatial navigation, mirroring hippocampal organization and enabling robust path planning.", "motivation": "To model hippocampal place cell activity and spatial navigation using neural embeddings that preserve proximity and transition probabilities.", "method": "Propose neural embeddings where inner products represent transition probabilities, use gradient ascent for path planning, and matrix squaring for global transitions.", "result": "Demonstrates localized place fields, multi-scale tuning, adaptability, and robust navigation in complex environments.", "conclusion": "The framework unifies spatial and temporal coding, offering a biologically plausible and scalable solution for navigation."}}
{"id": "2505.16946", "pdf": "https://arxiv.org/pdf/2505.16946", "abs": "https://arxiv.org/abs/2505.16946", "authors": ["Sanjana Chalavadi", "Andrei Pastor", "Terry Leitch"], "title": "NY Real Estate Racial Equity Analysis via Applied Machine Learning", "categories": ["cs.CY", "cs.LG"], "comment": "updated/replaced stale reference links. Added narrative covering\n  gentrification, racial capitalism, financialization of housing, and\n  segregation. Moved model details to appendices", "summary": "This study analyzes tract-level real estate ownership patterns in New York\nState (NYS) and New York City (NYC) to uncover racial disparities. We use an\nadvanced race/ethnicity imputation model (LSTM+Geo with XGBoost filtering,\nvalidated at 89.2% accuracy) to compare the predicted racial composition of\nproperty owners to the resident population from census data. We examine both a\nFull Model (statewide) and a Name-Only LSTM Model (NYC) to assess how\nincorporating geospatial context affects our predictions and disparity\nestimates. The results reveal significant inequities: White individuals hold a\ndisproportionate share of properties and property value relative to their\npopulation, while Black, Hispanic, and Asian communities are underrepresented\nas property owners. These disparities are most pronounced in minority-majority\nneighborhoods, where ownership is predominantly White despite a predominantly\nnon-White population. Corporate ownership (LLCs, trusts, etc.) exacerbates\nthese gaps by reducing owner-occupied opportunities in urban minority\ncommunities. We provide a breakdown of ownership vs. population by race for\nmajority-White, -Black, -Hispanic, and -Asian tracts, identify those with\nextreme ownership disparities, and compare patterns in urban, suburban, and\nrural contexts. The findings underscore persistent racial inequity in property\nownership, reflecting broader historical and socio-economic forces, and\nhighlight the importance of data-driven approaches to address these issues.", "AI": {"tldr": "The study reveals racial disparities in property ownership in NYS and NYC, with White individuals owning disproportionately more property than minority groups, especially in minority-majority neighborhoods. Corporate ownership worsens these gaps.", "motivation": "To uncover racial disparities in property ownership using advanced imputation models and compare ownership patterns to census data.", "method": "Uses LSTM+Geo with XGBoost filtering (89.2% accuracy) to predict racial composition of property owners, comparing Full Model (statewide) and Name-Only LSTM Model (NYC).", "result": "White individuals hold disproportionate property shares, while Black, Hispanic, and Asian communities are underrepresented. Corporate ownership reduces owner-occupied opportunities in minority areas.", "conclusion": "Persistent racial inequity in property ownership reflects historical and socio-economic forces, emphasizing the need for data-driven solutions."}}
{"id": "2505.18780", "pdf": "https://arxiv.org/pdf/2505.18780", "abs": "https://arxiv.org/abs/2505.18780", "authors": ["Yahao Fan", "Tianxiang Gui", "Kaiyang Ji", "Shutong Ding", "Chixuan Zhang", "Jiayuan Gu", "Jingyi Yu", "Jingya Wang", "Ye Shi"], "title": "One Policy but Many Worlds: A Scalable Unified Policy for Versatile Humanoid Locomotion", "categories": ["cs.RO", "cs.LG"], "comment": null, "summary": "Humanoid locomotion faces a critical scalability challenge: traditional\nreinforcement learning (RL) methods require task-specific rewards and struggle\nto leverage growing datasets, even as more training terrains are introduced. We\npropose DreamPolicy, a unified framework that enables a single policy to master\ndiverse terrains and generalize zero-shot to unseen scenarios by systematically\nintegrating offline data and diffusion-driven motion synthesis. At its core,\nDreamPolicy introduces Humanoid Motion Imagery (HMI) - future state predictions\nsynthesized through an autoregressive terrain-aware diffusion planner curated\nby aggregating rollouts from specialized policies across various distinct\nterrains. Unlike human motion datasets requiring laborious retargeting, our\ndata directly captures humanoid kinematics, enabling the diffusion planner to\nsynthesize \"dreamed\" trajectories that encode terrain-specific physical\nconstraints. These trajectories act as dynamic objectives for our\nHMI-conditioned policy, bypassing manual reward engineering and enabling\ncross-terrain generalization. DreamPolicy addresses the scalability limitations\nof prior methods: while traditional RL fails to exploit growing datasets, our\nframework scales seamlessly with more offline data. As the dataset expands, the\ndiffusion prior learns richer locomotion skills, which the policy leverages to\nmaster new terrains without retraining. Experiments demonstrate that\nDreamPolicy achieves average 90% success rates in training environments and an\naverage of 20% higher success on unseen terrains than the prevalent method. It\nalso generalizes to perturbed and composite scenarios where prior approaches\ncollapse. By unifying offline data, diffusion-based trajectory synthesis, and\npolicy optimization, DreamPolicy overcomes the \"one task, one policy\"\nbottleneck, establishing a paradigm for scalable, data-driven humanoid control.", "AI": {"tldr": "DreamPolicy is a unified framework for humanoid locomotion that integrates offline data and diffusion-driven motion synthesis to generalize across diverse terrains without task-specific rewards.", "motivation": "Traditional RL methods struggle with scalability and leveraging growing datasets for humanoid locomotion across varied terrains.", "method": "DreamPolicy uses Humanoid Motion Imagery (HMI) and a terrain-aware diffusion planner to synthesize trajectories, enabling cross-terrain generalization.", "result": "Achieves 90% success in training and 20% higher success on unseen terrains compared to prevalent methods.", "conclusion": "DreamPolicy overcomes the 'one task, one policy' bottleneck, offering scalable, data-driven humanoid control."}}
{"id": "2505.19145", "pdf": "https://arxiv.org/pdf/2505.19145", "abs": "https://arxiv.org/abs/2505.19145", "authors": ["Weijie Su"], "title": "Do Large Language Models (Really) Need Statistical Foundations?", "categories": ["stat.ME", "cs.LG", "stat.AP"], "comment": "Added some references", "summary": "Large language models (LLMs) represent a new paradigm for processing\nunstructured data, with applications across an unprecedented range of domains.\nIn this paper, we address, through two arguments, whether the development and\napplication of LLMs would genuinely benefit from foundational contributions\nfrom the statistics discipline. First, we argue affirmatively, beginning with\nthe observation that LLMs are inherently statistical models due to their\nprofound data dependency and stochastic generation processes, where statistical\ninsights are naturally essential for handling variability and uncertainty.\nSecond, we argue that the persistent black-box nature of LLMs -- stemming from\ntheir immense scale, architectural complexity, and development practices often\nprioritizing empirical performance over theoretical interpretability -- renders\nclosed-form or purely mechanistic analyses generally intractable, thereby\nnecessitating statistical approaches due to their flexibility and often\ndemonstrated effectiveness. To substantiate these arguments, the paper outlines\nseveral research areas -- including alignment, watermarking, uncertainty\nquantification, evaluation, and data mixture optimization -- where statistical\nmethodologies are critically needed and are already beginning to make valuable\ncontributions. We conclude with a discussion suggesting that statistical\nresearch concerning LLMs will likely form a diverse ``mosaic'' of specialized\ntopics rather than deriving from a single unifying theory, and highlighting the\nimportance of timely engagement by our statistics community in LLM research.", "AI": {"tldr": "The paper argues that statistics is essential for LLM development due to their data dependency and black-box nature, highlighting key areas where statistical methods are needed.", "motivation": "To demonstrate the necessity of statistical contributions in LLM development and application, given their inherent statistical nature and complexity.", "method": "Presents two arguments: LLMs are statistical models requiring statistical insights, and their black-box nature demands flexible statistical approaches.", "result": "Identifies critical research areas (alignment, watermarking, etc.) where statistics is already contributing.", "conclusion": "Statistical research for LLMs will be diverse, and the statistics community should engage promptly in LLM research."}}
{"id": "2505.23240", "pdf": "https://arxiv.org/pdf/2505.23240", "abs": "https://arxiv.org/abs/2505.23240", "authors": ["Hemant Tyagi"], "title": "Joint estimation of smooth graph signals from partial linear measurements", "categories": ["math.ST", "cs.LG", "stat.ML", "stat.TH"], "comment": "30 pages, 2 figures, added related work section on multitask learning", "summary": "Given an undirected and connected graph $G$ on $T$ vertices, suppose each\nvertex $t$ has a latent signal $x_t \\in \\mathbb{R}^n$ associated to it. Given\npartial linear measurements of the signals, for a potentially small subset of\nthe vertices, our goal is to estimate $x_t$'s. Assuming that the signals are\nsmooth w.r.t $G$, in the sense that the quadratic variation of the signals over\nthe graph is small, we obtain non-asymptotic bounds on the mean squared error\nfor jointly recovering $x_t$'s, for the smoothness penalized least squares\nestimator. In particular, this implies for certain choices of $G$ that this\nestimator is weakly consistent (as $T \\rightarrow \\infty$) under potentially\nvery stringent sampling, where only one coordinate is measured per vertex for a\nvanishingly small fraction of the vertices. The results are extended to a\n``multi-layer'' ranking problem where $x_t$ corresponds to the latent strengths\nof a collection of $n$ items, and noisy pairwise difference measurements are\nobtained at each ``layer'' $t$ via a measurement graph $G_t$. Weak consistency\nis established for certain choices of $G$ even when the individual $G_t$'s are\nvery sparse and disconnected.", "AI": {"tldr": "The paper analyzes smoothness-penalized least squares estimators for recovering latent signals on graphs, proving non-asymptotic error bounds and weak consistency under sparse sampling.", "motivation": "To estimate latent signals on graphs from partial linear measurements, leveraging smoothness assumptions for accurate recovery even with minimal data.", "method": "Uses smoothness-penalized least squares estimators, assuming small quadratic variation of signals over the graph.", "result": "Non-asymptotic bounds on mean squared error are derived, showing weak consistency under stringent sampling conditions.", "conclusion": "The estimator performs well even with very sparse measurements, extending to multi-layer ranking problems with sparse, disconnected graphs."}}
{"id": "2506.01755", "pdf": "https://arxiv.org/pdf/2506.01755", "abs": "https://arxiv.org/abs/2506.01755", "authors": ["Defne E. Ozan", "Andrea N\u00f3voa", "Georgios Rigas", "Luca Magri"], "title": "Data-assimilated model-informed reinforcement learning", "categories": ["eess.SY", "cs.LG", "cs.SY"], "comment": null, "summary": "The control of spatio-temporally chaos is challenging because of high\ndimensionality and unpredictability. Model-free reinforcement learning (RL)\ndiscovers optimal control policies by interacting with the system, typically\nrequiring observations of the full physical state. In practice, sensors often\nprovide only partial and noisy measurements (observations) of the system. The\nobjective of this paper is to develop a framework that enables the control of\nchaotic systems with partial and noisy observability. The proposed method,\ndata-assimilated model-informed reinforcement learning (DA-MIRL), integrates\n(i) low-order models to approximate high-dimensional dynamics; (ii) sequential\ndata assimilation to correct the model prediction when observations become\navailable; and (iii) an off-policy actor-critic RL algorithm to adaptively\nlearn an optimal control strategy based on the corrected state estimates. We\ntest DA-MIRL on the spatiotemporally chaotic solutions of the\nKuramoto-Sivashinsky equation. We estimate the full state of the environment\nwith (i) a physics-based model, here, a coarse-grained model; and (ii) a\ndata-driven model, here, the control-aware echo state network, which is\nproposed in this paper. We show that DA-MIRL successfully estimates and\nsuppresses the chaotic dynamics of the environment in real time from partial\nobservations and approximate models. This work opens opportunities for the\ncontrol of partially observable chaotic systems.", "AI": {"tldr": "A framework called DA-MIRL combines low-order models, data assimilation, and RL to control chaotic systems with partial/noisy observations, tested successfully on the Kuramoto-Sivashinsky equation.", "motivation": "Controlling chaotic systems is difficult due to high dimensionality and partial/noisy observations. This paper aims to develop a practical framework for such scenarios.", "method": "DA-MIRL integrates low-order models, sequential data assimilation, and actor-critic RL to learn optimal control from corrected state estimates.", "result": "DA-MIRL effectively estimates and suppresses chaotic dynamics in real time using partial observations and approximate models.", "conclusion": "The framework enables control of partially observable chaotic systems, opening new opportunities in the field."}}
