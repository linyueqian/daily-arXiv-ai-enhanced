{"id": "2505.05583", "pdf": "https://arxiv.org/pdf/2505.05583", "abs": "https://arxiv.org/abs/2505.05583", "authors": ["Qianbo Zang", "Christophe Zgrzendek", "Igor Tchappi", "Afshin Khadangi", "Johannes Sedlmeir"], "title": "KG-HTC: Integrating Knowledge Graphs into LLMs for Effective Zero-shot Hierarchical Text Classification", "categories": ["cs.CL"], "comment": null, "summary": "Hierarchical Text Classification (HTC) involves assigning documents to labels\norganized within a taxonomy. Most previous research on HTC has focused on\nsupervised methods. However, in real-world scenarios, employing supervised HTC\ncan be challenging due to a lack of annotated data. Moreover, HTC often faces\nissues with large label spaces and long-tail distributions. In this work, we\npresent Knowledge Graphs for zero-shot Hierarchical Text Classification\n(KG-HTC), which aims to address these challenges of HTC in applications by\nintegrating knowledge graphs with Large Language Models (LLMs) to provide\nstructured semantic context during classification. Our method retrieves\nrelevant subgraphs from knowledge graphs related to the input text using a\nRetrieval-Augmented Generation (RAG) approach. Our KG-HTC can enhance LLMs to\nunderstand label semantics at various hierarchy levels. We evaluate KG-HTC on\nthree open-source HTC datasets: WoS, DBpedia, and Amazon. Our experimental\nresults show that KG-HTC significantly outperforms three baselines in the\nstrict zero-shot setting, particularly achieving substantial improvements at\ndeeper levels of the hierarchy. This evaluation demonstrates the effectiveness\nof incorporating structured knowledge into LLMs to address HTC's challenges in\nlarge label spaces and long-tailed label distributions. Our code is available\nat: https://github.com/QianboZang/KG-HTC.", "AI": {"tldr": "KG-HTC integrates knowledge graphs with LLMs for zero-shot hierarchical text classification, outperforming baselines by leveraging structured semantic context.", "motivation": "Addressing challenges in HTC like lack of annotated data, large label spaces, and long-tail distributions.", "method": "Uses Retrieval-Augmented Generation (RAG) to retrieve relevant subgraphs from knowledge graphs, enhancing LLMs for label semantics.", "result": "Significantly outperforms baselines in zero-shot settings, especially at deeper hierarchy levels.", "conclusion": "Incorporating structured knowledge into LLMs effectively tackles HTC challenges in large label spaces and long-tailed distributions."}}
{"id": "2505.05648", "pdf": "https://arxiv.org/pdf/2505.05648", "abs": "https://arxiv.org/abs/2505.05648", "authors": ["Abdelrahman Abouelenin", "Mohamed Abdelrehim", "Raffy Fahim", "Amr Hendy", "Mohamed Afify"], "title": "Privacy-Preserving Transformers: SwiftKey's Differential Privacy Implementation", "categories": ["cs.CL", "cs.CR", "cs.LG"], "comment": null, "summary": "In this paper we train a transformer using differential privacy (DP) for\nlanguage modeling in SwiftKey. We run multiple experiments to balance the\ntrade-off between the model size, run-time speed and accuracy. We show that we\nget small and consistent gains in the next-word-prediction and accuracy with\ngraceful increase in memory and speed compared to the production GRU. This is\nobtained by scaling down a GPT2 architecture to fit the required size and a two\nstage training process that builds a seed model on general data and DP\nfinetunes it on typing data. The transformer is integrated using ONNX offering\nboth flexibility and efficiency.", "AI": {"tldr": "A transformer model is trained with differential privacy for SwiftKey, balancing size, speed, and accuracy, outperforming GRU in next-word prediction.", "motivation": "To improve language modeling in SwiftKey while ensuring privacy and efficiency.", "method": "Scaling down GPT2 architecture, two-stage training (general data seed + DP fine-tuning on typing data), and ONNX integration.", "result": "Small, consistent gains in next-word prediction and accuracy with manageable memory and speed trade-offs.", "conclusion": "The approach successfully integrates privacy and performance for SwiftKey's language model."}}
{"id": "2505.05687", "pdf": "https://arxiv.org/pdf/2505.05687", "abs": "https://arxiv.org/abs/2505.05687", "authors": ["Cindy Kim", "Daniela Puchall", "Jiangyi Liang", "Jiwon Kim"], "title": "Exploration of COVID-19 Discourse on Twitter: American Politician Edition", "categories": ["cs.CL"], "comment": null, "summary": "The advent of the COVID-19 pandemic has undoubtedly affected the political\nscene worldwide and the introduction of new terminology and public opinions\nregarding the virus has further polarized partisan stances. Using a collection\nof tweets gathered from leading American political figures online (Republican\nand Democratic), we explored the partisan differences in approach, response,\nand attitude towards handling the international crisis. Implementation of the\nbag-of-words, bigram, and TF-IDF models was used to identify and analyze\nkeywords, topics, and overall sentiments from each party. Results suggest that\nDemocrats are more concerned with the casualties of the pandemic, and give more\nmedical precautions and recommendations to the public whereas Republicans are\nmore invested in political responsibilities such as keeping the public updated\nthrough media and carefully watching the progress of the virus. We propose a\nsystematic approach to predict and distinguish a tweet's political stance (left\nor right leaning) based on its COVID-19 related terms using different\nclassification algorithms on different language models.", "AI": {"tldr": "The paper analyzes partisan differences in COVID-19 responses via tweets from American political figures, using NLP techniques to classify political stances.", "motivation": "To understand how the pandemic polarized political discourse and identify partisan differences in handling the crisis.", "method": "Used bag-of-words, bigram, and TF-IDF models to analyze keywords, topics, and sentiments from tweets of Republican and Democratic figures.", "result": "Democrats focused on casualties and medical advice, while Republicans emphasized political updates and monitoring the virus.", "conclusion": "Proposes a systematic approach to classify tweets' political stances based on COVID-19 terms using classification algorithms."}}
{"id": "2505.05704", "pdf": "https://arxiv.org/pdf/2505.05704", "abs": "https://arxiv.org/abs/2505.05704", "authors": ["Julia Shuieh", "Prasann Singhal", "Apaar Shanker", "John Heyer", "George Pu", "Samuel Denton"], "title": "Assessing Robustness to Spurious Correlations in Post-Training Language Models", "categories": ["cs.CL", "cs.AI"], "comment": "ICLR '25 Workshop on Spurious Correlation and Shortcut Learning", "summary": "Supervised and preference-based fine-tuning techniques have become popular\nfor aligning large language models (LLMs) with user intent and correctness\ncriteria. However, real-world training data often exhibits spurious\ncorrelations -- arising from biases, dataset artifacts, or other \"shortcut\"\nfeatures -- that can compromise a model's performance or generalization. In\nthis paper, we systematically evaluate three post-training algorithms --\nSupervised Fine-Tuning (SFT), Direct Preference Optimization (DPO), and KTO\n(Kahneman-Tversky Optimization) -- across a diverse set of synthetic tasks and\nspuriousness conditions. Our tasks span mathematical reasoning, constrained\ninstruction-following, and document-grounded question answering. We vary the\ndegree of spurious correlation (10% vs. 90%) and investigate two forms of\nartifacts: \"Feature Ambiguity\" and \"Distributional Narrowness.\" Our results\nshow that the models often but not always degrade under higher spuriousness.\nThe preference-based methods (DPO/KTO) can demonstrate relative robustness in\nmathematical reasoning tasks. By contrast, SFT maintains stronger performance\nin complex, context-intensive tasks. These findings highlight that no single\npost-training strategy universally outperforms in all scenarios; the best\nchoice depends on the type of target task and the nature of spurious\ncorrelations.", "AI": {"tldr": "The paper evaluates SFT, DPO, and KTO for aligning LLMs under spurious correlations, finding task-dependent performance.", "motivation": "To assess how spurious correlations in training data affect LLM alignment methods and identify robust strategies.", "method": "Systematic evaluation of SFT, DPO, and KTO across synthetic tasks with varying spuriousness and artifact types.", "result": "Preference-based methods (DPO/KTO) are robust in math tasks, while SFT excels in context-intensive tasks.", "conclusion": "No single method universally outperforms; choice depends on task type and spurious correlation nature."}}
{"id": "2505.05654", "pdf": "https://arxiv.org/pdf/2505.05654", "abs": "https://arxiv.org/abs/2505.05654", "authors": ["John Vinyard"], "title": "Toward a Sparse and Interpretable Audio Codec", "categories": ["cs.SD", "eess.AS"], "comment": null, "summary": "Most widely-used modern audio codecs, such as Ogg Vorbis and MP3, as well as\nmore recent \"neural\" codecs like Meta's Encodec or the Descript Audio Codec are\nbased on block-coding; audio is divided into overlapping, fixed-size \"frames\"\nwhich are then compressed. While they often yield excellent reproductions and\ncan be used for downstream tasks such as text-to-audio, they do not produce an\nintuitive, directly-interpretable representation. In this work, we introduce a\nproof-of-concept audio encoder that represents audio as a sparse set of events\nand their times-of-occurrence. Rudimentary physics-based assumptions are used\nto model attack and the physical resonance of both the instrument being played\nand the room in which a performance occurs, hopefully encouraging a sparse,\nparsimonious, and easy-to-interpret representation.", "AI": {"tldr": "A proof-of-concept audio encoder is introduced, representing audio as sparse events with times-of-occurrence, aiming for an interpretable and sparse representation.", "motivation": "Existing audio codecs lack intuitive, directly-interpretable representations despite good reproduction quality.", "method": "Uses physics-based assumptions to model attack and resonance, creating a sparse event-based representation.", "result": "Produces a sparse, parsimonious, and easy-to-interpret audio representation.", "conclusion": "The proposed encoder offers a novel, interpretable alternative to traditional block-coding methods."}}
{"id": "2505.05657", "pdf": "https://arxiv.org/pdf/2505.05657", "abs": "https://arxiv.org/abs/2505.05657", "authors": ["Zhongweiyang Xu", "Xulin Fan", "Zhong-Qiu Wang", "Xilin Jiang", "Romit Roy Choudhury"], "title": "Unsupervised Blind Speech Separation with a Diffusion Prior", "categories": ["eess.AS", "cs.LG", "cs.MM", "cs.SD", "eess.SP"], "comment": "Paper Accepted at ICML2025 Demo:\n  https://arraydps.github.io/ArrayDPSDemo/ Code:\n  https://github.com/ArrayDPS/ArrayDPS", "summary": "Blind Speech Separation (BSS) aims to separate multiple speech sources from\naudio mixtures recorded by a microphone array. The problem is challenging\nbecause it is a blind inverse problem, i.e., the microphone array geometry, the\nroom impulse response (RIR), and the speech sources, are all unknown. We\npropose ArrayDPS to solve the BSS problem in an unsupervised, array-agnostic,\nand generative manner. The core idea builds on diffusion posterior sampling\n(DPS), but unlike DPS where the likelihood is tractable, ArrayDPS must\napproximate the likelihood by formulating a separate optimization problem. The\nsolution to the optimization approximates room acoustics and the relative\ntransfer functions between microphones. These approximations, along with the\ndiffusion priors, iterate through the ArrayDPS sampling process and ultimately\nyield separated voice sources. We only need a simple single-speaker speech\ndiffusion model as a prior along with the mixtures recorded at the microphones;\nno microphone array information is necessary. Evaluation results show that\nArrayDPS outperforms all baseline unsupervised methods while being comparable\nto supervised methods in terms of SDR. Audio demos are provided at:\nhttps://arraydps.github.io/ArrayDPSDemo/.", "AI": {"tldr": "ArrayDPS is an unsupervised, array-agnostic method for Blind Speech Separation (BSS) using diffusion posterior sampling and optimization to approximate room acoustics, outperforming unsupervised baselines.", "motivation": "BSS is challenging due to unknown microphone array geometry, room impulse response, and speech sources. ArrayDPS addresses this without requiring array information.", "method": "ArrayDPS combines diffusion posterior sampling with an optimization problem to approximate room acoustics and transfer functions, iterating to separate speech sources.", "result": "ArrayDPS outperforms unsupervised baselines and matches supervised methods in SDR performance.", "conclusion": "ArrayDPS provides a robust, unsupervised solution for BSS, leveraging diffusion priors and optimization without needing array details."}}
{"id": "2505.05541", "pdf": "https://arxiv.org/pdf/2505.05541", "abs": "https://arxiv.org/abs/2505.05541", "authors": ["Markov Grey", "Charbel-Rapha\u00ebl Segerie"], "title": "Safety by Measurement: A Systematic Literature Review of AI Safety Evaluation Methods", "categories": ["cs.AI"], "comment": null, "summary": "As frontier AI systems advance toward transformative capabilities, we need a\nparallel transformation in how we measure and evaluate these systems to ensure\nsafety and inform governance. While benchmarks have been the primary method for\nestimating model capabilities, they often fail to establish true upper bounds\nor predict deployment behavior. This literature review consolidates the rapidly\nevolving field of AI safety evaluations, proposing a systematic taxonomy around\nthree dimensions: what properties we measure, how we measure them, and how\nthese measurements integrate into frameworks. We show how evaluations go beyond\nbenchmarks by measuring what models can do when pushed to the limit\n(capabilities), the behavioral tendencies exhibited by default (propensities),\nand whether our safety measures remain effective even when faced with\nsubversive adversarial AI (control). These properties are measured through\nbehavioral techniques like scaffolding, red teaming and supervised fine-tuning,\nalongside internal techniques such as representation analysis and mechanistic\ninterpretability. We provide deeper explanations of some safety-critical\ncapabilities like cybersecurity exploitation, deception, autonomous\nreplication, and situational awareness, alongside concerning propensities like\npower-seeking and scheming. The review explores how these evaluation methods\nintegrate into governance frameworks to translate results into concrete\ndevelopment decisions. We also highlight challenges to safety evaluations -\nproving absence of capabilities, potential model sandbagging, and incentives\nfor \"safetywashing\" - while identifying promising research directions. By\nsynthesizing scattered resources, this literature review aims to provide a\ncentral reference point for understanding AI safety evaluations.", "AI": {"tldr": "The paper reviews AI safety evaluations, proposing a taxonomy around measuring capabilities, propensities, and control, while highlighting challenges and research directions.", "motivation": "Frontier AI systems require better evaluation methods to ensure safety and inform governance, as traditional benchmarks often fail to predict real-world behavior.", "method": "The review consolidates AI safety evaluations into a taxonomy focusing on what properties to measure (capabilities, propensities, control), how to measure them (behavioral and internal techniques), and integration into governance frameworks.", "result": "The paper identifies key safety-critical capabilities and concerning propensities, discusses evaluation challenges, and suggests research directions.", "conclusion": "The review serves as a central reference for AI safety evaluations, emphasizing the need for systematic approaches to address safety and governance gaps."}}
{"id": "2505.05940", "pdf": "https://arxiv.org/pdf/2505.05940", "abs": "https://arxiv.org/abs/2505.05940", "authors": ["Rodrigo Diaz", "Mark Sandler"], "title": "Fast Differentiable Modal Simulation of Non-linear Strings, Membranes, and Plates", "categories": ["cs.SD", "cs.LG", "eess.AS", "physics.comp-ph"], "comment": "accepted to DAFx 2025", "summary": "Modal methods for simulating vibrations of strings, membranes, and plates are\nwidely used in acoustics and physically informed audio synthesis. However,\ntraditional implementations, particularly for non-linear models like the von\nK\\'arm\\'an plate, are computationally demanding and lack differentiability,\nlimiting inverse modelling and real-time applications. We introduce a fast,\ndifferentiable, GPU-accelerated modal framework built with the JAX library,\nproviding efficient simulations and enabling gradient-based inverse modelling.\nBenchmarks show that our approach significantly outperforms CPU and GPU-based\nimplementations, particularly for simulations with many modes. Inverse\nmodelling experiments demonstrate that our approach can recover physical\nparameters, including tension, stiffness, and geometry, from both synthetic and\nexperimental data. Although fitting physical parameters is more sensitive to\ninitialisation compared to other methods, it provides greater interpretability\nand more compact parameterisation. The code is released as open source to\nsupport future research and applications in differentiable physical modelling\nand sound synthesis.", "AI": {"tldr": "A fast, differentiable, GPU-accelerated modal framework for simulating vibrations in strings, membranes, and plates, enabling efficient inverse modelling and real-time applications.", "motivation": "Traditional modal methods for non-linear models are computationally intensive and lack differentiability, limiting inverse modelling and real-time use.", "method": "Developed a GPU-accelerated modal framework using the JAX library for efficient, differentiable simulations.", "result": "Outperforms CPU/GPU implementations, especially for many modes, and recovers physical parameters from data.", "conclusion": "The framework offers interpretability and compact parameterisation, with open-source code for future research."}}
{"id": "2505.05487", "pdf": "https://arxiv.org/pdf/2505.05487", "abs": "https://arxiv.org/abs/2505.05487", "authors": ["Shrinivas Pundlik", "Seonggyu Choe", "Patrick Baker", "Chen-Yuan Lee", "Naser Al-Madi", "Alex R. Bowers", "Gang Luo"], "title": "Data extraction and processing methods to aid the study of driving behaviors at intersections in naturalistic driving", "categories": ["cs.CV", "cs.RO"], "comment": "19 pages, 11 figures", "summary": "Naturalistic driving studies use devices in participants' own vehicles to\nrecord daily driving over many months. Due to diverse and extensive amounts of\ndata recorded, automated processing is necessary. This report describes methods\nto extract and characterize driver head scans at intersections from data\ncollected from an in-car recording system that logged vehicle speed, GPS\nlocation, scene videos, and cabin videos. Custom tools were developed to mark\nthe intersections, synchronize location and video data, and clip the cabin and\nscene videos for +/-100 meters from the intersection location. A\ncustom-developed head pose detection AI model for wide angle head turns was run\non the cabin videos to estimate the driver head pose, from which head scans >20\ndeg were computed in the horizontal direction. The scene videos were processed\nusing a YOLO object detection model to detect traffic lights, stop signs,\npedestrians, and other vehicles on the road. Turning maneuvers were\nindependently detected using vehicle self-motion patterns. Stop lines on the\nroad surface were detected using changing intensity patterns over time as the\nvehicle moved. The information obtained from processing the scene videos, along\nwith the speed data was used in a rule-based algorithm to infer the\nintersection type, maneuver, and bounds. We processed 190 intersections from 3\nvehicles driven in cities and suburban areas from Massachusetts and California.\nThe automated video processing algorithm correctly detected intersection\nsignage and maneuvers in 100% and 94% of instances, respectively. The median\n[IQR] error in detecting vehicle entry into the intersection was 1.1[0.4-4.9]\nmeters and 0.2[0.1-0.54] seconds. The median overlap between ground truth and\nestimated intersection bounds was 0.88[0.82-0.93].", "AI": {"tldr": "Automated methods for analyzing driver head scans and intersection data from naturalistic driving studies, achieving high accuracy in detecting signage, maneuvers, and intersection bounds.", "motivation": "To automate the processing of diverse and extensive data from naturalistic driving studies, focusing on driver behavior and intersection dynamics.", "method": "Custom tools and AI models (head pose detection, YOLO object detection) were used to process cabin and scene videos, synchronize data, and infer intersection details.", "result": "High accuracy in detecting intersection signage (100%) and maneuvers (94%), with precise measurements for vehicle entry and intersection bounds.", "conclusion": "The automated system effectively processes naturalistic driving data, providing reliable insights into driver behavior and intersection dynamics."}}
{"id": "2505.05522", "pdf": "https://arxiv.org/pdf/2505.05522", "abs": "https://arxiv.org/abs/2505.05522", "authors": ["Luke Darlow", "Ciaran Regan", "Sebastian Risi", "Jeffrey Seely", "Llion Jones"], "title": "Continuous Thought Machines", "categories": ["cs.LG", "cs.AI"], "comment": "Technical report accompanied by online project page", "summary": "Biological brains demonstrate complex neural activity, where the timing and\ninterplay between neurons is critical to how brains process information. Most\ndeep learning architectures simplify neural activity by abstracting away\ntemporal dynamics. In this paper we challenge that paradigm. By incorporating\nneuron-level processing and synchronization, we can effectively reintroduce\nneural timing as a foundational element. We present the Continuous Thought\nMachine (CTM), a model designed to leverage neural dynamics as its core\nrepresentation. The CTM has two core innovations: (1) neuron-level temporal\nprocessing, where each neuron uses unique weight parameters to process a\nhistory of incoming signals; and (2) neural synchronization employed as a\nlatent representation. The CTM aims to strike a balance between oversimplified\nneuron abstractions that improve computational efficiency, and biological\nrealism. It operates at a level of abstraction that effectively captures\nessential temporal dynamics while remaining computationally tractable for deep\nlearning. We demonstrate the CTM's strong performance and versatility across a\nrange of challenging tasks, including ImageNet-1K classification, solving 2D\nmazes, sorting, parity computation, question-answering, and RL tasks. Beyond\ndisplaying rich internal representations and offering a natural avenue for\ninterpretation owing to its internal process, the CTM is able to perform tasks\nthat require complex sequential reasoning. The CTM can also leverage adaptive\ncompute, where it can stop earlier for simpler tasks, or keep computing when\nfaced with more challenging instances. The goal of this work is to share the\nCTM and its associated innovations, rather than pushing for new\nstate-of-the-art results. To that end, we believe the CTM represents a\nsignificant step toward developing more biologically plausible and powerful\nartificial intelligence systems.", "AI": {"tldr": "The paper introduces the Continuous Thought Machine (CTM), a model incorporating neuron-level temporal processing and synchronization to enhance biological plausibility in deep learning.", "motivation": "To challenge the oversimplification of neural activity in deep learning by reintroducing temporal dynamics and synchronization, aiming for more biologically realistic AI.", "method": "The CTM uses neuron-level temporal processing with unique weight parameters for signal history and neural synchronization as a latent representation.", "result": "CTM demonstrates strong performance in tasks like ImageNet-1K classification, maze-solving, and question-answering, with adaptive compute capabilities.", "conclusion": "CTM advances biologically plausible AI, balancing realism and computational efficiency, though not aiming for state-of-the-art results."}}
{"id": "2505.06200", "pdf": "https://arxiv.org/pdf/2505.06200", "abs": "https://arxiv.org/abs/2505.06200", "authors": ["Shinkyu Park", "Lucas C. D. Bezerra"], "title": "Robust Multi-Agent Decision-Making in Finite-Population Games", "categories": ["cs.MA", "cs.SY", "eess.SY"], "comment": null, "summary": "We study the robustness of an agent decision-making model in\nfinite-population games, with a particular focus on the Kullback-Leibler\nDivergence Regularized Learning (KLD-RL) model. Specifically, we examine how\nthe model's parameters influence the effects of various sources of noise and\nmodeling inaccuracies -- factors commonly encountered in engineering\napplications of population games -- on agents' decision-making. Our analysis\nprovides insights into how these parameters can be effectively tuned to\nmitigate such effects. Theoretical results are supported by numerical examples\nand simulation studies that validate the analysis and illustrate practical\nstrategies for parameter selection.", "AI": {"tldr": "The paper analyzes the robustness of the KLD-RL model in finite-population games, focusing on parameter tuning to mitigate noise and modeling inaccuracies.", "motivation": "To understand how model parameters affect decision-making under noise and inaccuracies, common in engineering applications of population games.", "method": "Theoretical analysis supported by numerical examples and simulation studies.", "result": "Insights into effective parameter tuning to mitigate noise and inaccuracies, validated by simulations.", "conclusion": "The study provides practical strategies for parameter selection in the KLD-RL model to enhance robustness in decision-making."}}
{"id": "2505.05504", "pdf": "https://arxiv.org/pdf/2505.05504", "abs": "https://arxiv.org/abs/2505.05504", "authors": ["Xingyu Jiang", "Ning Gao", "Xiuhui Zhang", "Hongkun Dou", "Shaowen Fu", "Xiaoqing Zhong", "Hongjue Li", "Yue Deng"], "title": "Image Restoration via Multi-domain Learning", "categories": ["eess.IV", "cs.CV"], "comment": null, "summary": "Due to adverse atmospheric and imaging conditions, natural images suffer from\nvarious degradation phenomena. Consequently, image restoration has emerged as a\nkey solution and garnered substantial attention. Although recent Transformer\narchitectures have demonstrated impressive success across various restoration\ntasks, their considerable model complexity poses significant challenges for\nboth training and real-time deployment. Furthermore, instead of investigating\nthe commonalities among different degradations, most existing restoration\nmethods focus on modifying Transformer under limited restoration priors. In\nthis work, we first review various degradation phenomena under multi-domain\nperspective, identifying common priors. Then, we introduce a novel restoration\nframework, which integrates multi-domain learning into Transformer.\nSpecifically, in Token Mixer, we propose a Spatial-Wavelet-Fourier multi-domain\nstructure that facilitates local-region-global multi-receptive field modeling\nto replace vanilla self-attention. Additionally, in Feed-Forward Network, we\nincorporate multi-scale learning to fuse multi-domain features at different\nresolutions. Comprehensive experimental results across ten restoration tasks,\nsuch as dehazing, desnowing, motion deblurring, defocus deblurring, rain\nstreak/raindrop removal, cloud removal, shadow removal, underwater enhancement\nand low-light enhancement, demonstrate that our proposed model outperforms\nstate-of-the-art methods and achieves a favorable trade-off among restoration\nperformance, parameter size, computational cost and inference latency. The code\nis available at: https://github.com/deng-ai-lab/SWFormer.", "AI": {"tldr": "A novel Transformer-based framework (SWFormer) integrates multi-domain learning for image restoration, outperforming state-of-the-art methods with a balanced trade-off in performance, complexity, and speed.", "motivation": "Addressing the limitations of existing Transformer-based restoration methods, which lack exploration of common degradation priors and suffer from high complexity.", "method": "Proposes a Spatial-Wavelet-Fourier multi-domain structure in Token Mixer and multi-scale learning in Feed-Forward Network to model multi-receptive fields and fuse features.", "result": "Demonstrates superior performance across ten restoration tasks, achieving better efficiency and effectiveness.", "conclusion": "SWFormer offers a scalable and efficient solution for diverse image restoration challenges."}}
{"id": "2505.05714", "pdf": "https://arxiv.org/pdf/2505.05714", "abs": "https://arxiv.org/abs/2505.05714", "authors": ["Jinze Lv", "Jian Chen", "Zi Long", "Xianghua Fu", "Yin Chen"], "title": "TopicVD: A Topic-Based Dataset of Video-Guided Multimodal Machine Translation for Documentaries", "categories": ["cs.CL"], "comment": "NLDB 2025", "summary": "Most existing multimodal machine translation (MMT) datasets are predominantly\ncomposed of static images or short video clips, lacking extensive video data\nacross diverse domains and topics. As a result, they fail to meet the demands\nof real-world MMT tasks, such as documentary translation. In this study, we\ndeveloped TopicVD, a topic-based dataset for video-supported multimodal machine\ntranslation of documentaries, aiming to advance research in this field. We\ncollected video-subtitle pairs from documentaries and categorized them into\neight topics, such as economy and nature, to facilitate research on domain\nadaptation in video-guided MMT. Additionally, we preserved their contextual\ninformation to support research on leveraging the global context of\ndocumentaries in video-guided MMT. To better capture the shared semantics\nbetween text and video, we propose an MMT model based on a cross-modal\nbidirectional attention module. Extensive experiments on the TopicVD dataset\ndemonstrate that visual information consistently improves the performance of\nthe NMT model in documentary translation. However, the MMT model's performance\nsignificantly declines in out-of-domain scenarios, highlighting the need for\neffective domain adaptation methods. Additionally, experiments demonstrate that\nglobal context can effectively improve translation performance. % Dataset and\nour implementations are available at https://github.com/JinzeLv/TopicVD", "AI": {"tldr": "The paper introduces TopicVD, a topic-based dataset for video-supported multimodal machine translation (MMT) of documentaries, addressing the lack of diverse video data in existing datasets. It proposes a cross-modal bidirectional attention MMT model and demonstrates improved translation performance with visual information, though domain adaptation remains a challenge.", "motivation": "Existing MMT datasets lack extensive video data, limiting their applicability to real-world tasks like documentary translation. TopicVD aims to fill this gap by providing a diverse, topic-categorized dataset.", "method": "The study collects video-subtitle pairs from documentaries, categorizes them into eight topics, and preserves contextual information. A cross-modal bidirectional attention MMT model is proposed to capture shared semantics between text and video.", "result": "Experiments show that visual information improves NMT performance in documentary translation, but the MMT model struggles with out-of-domain scenarios. Global context also enhances translation performance.", "conclusion": "TopicVD advances MMT research by addressing dataset limitations and demonstrating the benefits of visual and contextual information. Effective domain adaptation methods are needed to handle out-of-domain challenges."}}
{"id": "2505.06042", "pdf": "https://arxiv.org/pdf/2505.06042", "abs": "https://arxiv.org/abs/2505.06042", "authors": ["Christos Plachouras", "Emmanouil Benetos", "Johan Pauwels"], "title": "Learning Music Audio Representations With Limited Data", "categories": ["cs.SD", "cs.LG", "eess.AS"], "comment": "Presented at ICASSP 2025", "summary": "Large deep-learning models for music, including those focused on learning\ngeneral-purpose music audio representations, are often assumed to require\nsubstantial training data to achieve high performance. If true, this would pose\nchallenges in scenarios where audio data or annotations are scarce, such as for\nunderrepresented music traditions, non-popular genres, and personalized music\ncreation and listening. Understanding how these models behave in limited-data\nscenarios could be crucial for developing techniques to tackle them.\n  In this work, we investigate the behavior of several music audio\nrepresentation models under limited-data learning regimes. We consider music\nmodels with various architectures, training paradigms, and input durations, and\ntrain them on data collections ranging from 5 to 8,000 minutes long. We\nevaluate the learned representations on various music information retrieval\ntasks and analyze their robustness to noise. We show that, under certain\nconditions, representations from limited-data and even random models perform\ncomparably to ones from large-dataset models, though handcrafted features\noutperform all learned representations in some tasks.", "AI": {"tldr": "The paper explores how music audio representation models perform with limited training data, showing they can match large-dataset models under certain conditions, though handcrafted features sometimes outperform.", "motivation": "To address challenges in scenarios with scarce music audio data or annotations, such as underrepresented traditions or personalized music creation.", "method": "Investigates various music audio representation models under limited-data regimes, training on datasets from 5 to 8,000 minutes and evaluating on music information retrieval tasks and noise robustness.", "result": "Limited-data models can perform comparably to large-dataset models under certain conditions, but handcrafted features sometimes outperform learned representations.", "conclusion": "Understanding limited-data behavior is crucial for developing techniques to tackle data scarcity in music representation learning."}}
{"id": "2505.06107", "pdf": "https://arxiv.org/pdf/2505.06107", "abs": "https://arxiv.org/abs/2505.06107", "authors": ["Faeze Ghorbanpour", "Thiago Zordan Malaguth", "Aliakbar Akbaritabar"], "title": "Differentiating Emigration from Return Migration of Scholars Using Name-Based Nationality Detection Models", "categories": ["cs.DL", "cs.CL", "cs.MM"], "comment": "Accepted to appear @ ICWSM 2025. The link to the camera-ready paper\n  will be added soon", "summary": "Most web and digital trace data do not include information about an\nindividual's nationality due to privacy concerns. The lack of data on\nnationality can create challenges for migration research. It can lead to a\nleft-censoring issue since we are uncertain about the migrant's country of\norigin. Once we observe an emigration event, if we know the nationality, we can\ndifferentiate it from return migration. We propose methods to detect the\nnationality with the least available data, i.e., full names. We use the\ndetected nationality in comparison with the country of academic origin, which\nis a common approach in studying the migration of researchers. We gathered 2.6\nmillion unique name-nationality pairs from Wikipedia and categorized them into\nfamilies of nationalities with three granularity levels to use as our training\ndata. Using a character-based machine learning model, we achieved a weighted F1\nscore of 84% for the broadest and 67% for the most granular, country-level\ncategorization. In our empirical study, we used the trained and tested model to\nassign nationality to 8+ million scholars' full names in Scopus data. Our\nresults show that using the country of first publication as a proxy for\nnationality underestimates the size of return flows, especially for countries\nwith a more diverse academic workforce, such as the USA, Australia, and Canada.\nWe found that around 48% of emigration from the USA was return migration once\nwe used the country of name origin, in contrast to 33% based on academic\norigin. In the most recent period, 79% of scholars whose affiliation has\nconsistently changed from the USA to China, and are considered emigrants, have\nChinese names in contrast to 41% with a Chinese academic origin. Our proposed\nmethods for addressing left-censoring issues are beneficial for other research\nthat uses digital trace data to study migration.", "AI": {"tldr": "The paper proposes a method to detect nationality using full names to address left-censoring in migration research, achieving high accuracy and revealing underestimation of return migration when using academic origin as a proxy.", "motivation": "The lack of nationality data in digital traces creates challenges for migration research, particularly in distinguishing emigration from return migration.", "method": "A character-based machine learning model trained on 2.6 million name-nationality pairs from Wikipedia, tested on Scopus data for 8+ million scholars.", "result": "Achieved 84% F1 score for broad nationality categorization and 67% for country-level. Found 48% of USA emigration was return migration using name origin vs. 33% with academic origin.", "conclusion": "The method effectively addresses left-censoring and improves migration research accuracy, especially for diverse academic workforces."}}
{"id": "2505.05602", "pdf": "https://arxiv.org/pdf/2505.05602", "abs": "https://arxiv.org/abs/2505.05602", "authors": ["Lennart Luettgau", "Harry Coppock", "Magda Dubois", "Christopher Summerfield", "Cozmin Ududec"], "title": "HiBayES: A Hierarchical Bayesian Modeling Framework for AI Evaluation Statistics", "categories": ["cs.AI", "stat.AP"], "comment": "23 pages, 9 figures", "summary": "As Large Language Models (LLMs) and other AI systems evolve, robustly\nestimating their capabilities from inherently stochastic outputs while\nsystematically quantifying uncertainty in these estimates becomes increasingly\nimportant. Further, advanced AI evaluations often have a nested hierarchical\nstructure, exhibit high levels of complexity, and come with high costs in\ntesting the most advanced AI systems. To address these challenges, we introduce\nHiBayES, a generalizable Hierarchical Bayesian modeling framework for AI\nEvaluation Statistics. HiBayES supports robust inferences in classical\nquestion-answer benchmarks and advanced agentic evaluations, particularly in\nlow-data scenarios (e.g., < 20 data points per evaluation). Built on\nGeneralized Linear Models (GLMs), Bayesian data analysis, and formal model\ncomparison, HiBayES provides principled uncertainty quantification and robust\nparameter estimation. This paper offers a comprehensive introduction to\nHiBayES, including illustrative examples, comparisons to conventional\nstatistical methods, and practical guidance for implementing multilevel\nBayesian GLMs. Additionally, we provide a HiBayES software package [4] (Beta\nversion) for out-of-the-box implementation.", "AI": {"tldr": "HiBayES is a Hierarchical Bayesian framework for robust AI evaluation, offering uncertainty quantification and parameter estimation in low-data scenarios.", "motivation": "Addressing the challenges of estimating AI capabilities from stochastic outputs and quantifying uncertainty in hierarchical, complex evaluations.", "method": "Uses Generalized Linear Models (GLMs), Bayesian data analysis, and model comparison for robust inferences.", "result": "Provides principled uncertainty quantification and robust parameter estimation, with a software package for implementation.", "conclusion": "HiBayES is a practical solution for advanced AI evaluations, especially in low-data settings."}}
{"id": "2505.05159", "pdf": "https://arxiv.org/pdf/2505.05159", "abs": "https://arxiv.org/abs/2505.05159", "authors": ["Linhan Ma", "Dake Guo", "He Wang", "Jin Xu", "Lei Xie"], "title": "FlexSpeech: Towards Stable, Controllable and Expressive Text-to-Speech", "categories": ["eess.AS"], "comment": "10 pages, 5 figures", "summary": "Current speech generation research can be categorized into two primary\nclasses: non-autoregressive and autoregressive. The fundamental distinction\nbetween these approaches lies in the duration prediction strategy employed for\npredictable-length sequences. The NAR methods ensure stability in speech\ngeneration by explicitly and independently modeling the duration of each\nphonetic unit. Conversely, AR methods employ an autoregressive paradigm to\npredict the compressed speech token by implicitly modeling duration with Markov\nproperties. Although this approach improves prosody, it does not provide the\nstructural guarantees necessary for stability. To simultaneously address the\nissues of stability and naturalness in speech generation, we propose\nFlexSpeech, a stable, controllable, and expressive TTS model. The motivation\nbehind FlexSpeech is to incorporate Markov dependencies and preference\noptimization directly on the duration predictor to boost its naturalness while\nmaintaining explicit modeling of the phonetic units to ensure stability.\nSpecifically, we decompose the speech generation task into two components: an\nAR duration predictor and a NAR acoustic model. The acoustic model is trained\non a substantial amount of data to learn to render audio more stably, given\nreference audio prosody and phone durations. The duration predictor is\noptimized in a lightweight manner for different stylistic variations, thereby\nenabling rapid style transfer while maintaining a decoupled relationship with\nthe specified speaker timbre. Experimental results demonstrate that our\napproach achieves SOTA stability and naturalness in zero-shot TTS. More\nimportantly, when transferring to a specific stylistic domain, we can\naccomplish lightweight optimization of the duration module solely with about\n100 data samples, without the need to adjust the acoustic model, thereby\nenabling rapid and stable style transfer.", "AI": {"tldr": "FlexSpeech combines autoregressive (AR) and non-autoregressive (NAR) methods for stable, controllable, and expressive speech generation, achieving SOTA results in zero-shot TTS and lightweight style transfer.", "motivation": "Address the trade-off between stability (NAR) and naturalness (AR) in speech generation by integrating Markov dependencies and preference optimization into duration prediction.", "method": "Decomposes speech generation into an AR duration predictor and a NAR acoustic model, optimizing the former for style transfer while keeping the latter stable.", "result": "Achieves SOTA stability and naturalness in zero-shot TTS; enables rapid style transfer with minimal data (100 samples) without altering the acoustic model.", "conclusion": "FlexSpeech successfully balances stability and naturalness, offering efficient style transfer and high-quality speech generation."}}
{"id": "2505.05488", "pdf": "https://arxiv.org/pdf/2505.05488", "abs": "https://arxiv.org/abs/2505.05488", "authors": ["Yunfan Lu", "Xiaogang Xu", "Pengteng Li", "Yusheng Wang", "Yi Cui", "Huizai Yao", "Hui Xiong"], "title": "From Events to Enhancement: A Survey on Event-Based Imaging Technologies", "categories": ["cs.CV"], "comment": null, "summary": "Event cameras offering high dynamic range and low latency have emerged as\ndisruptive technologies in imaging. Despite growing research on leveraging\nthese benefits for different imaging tasks, a comprehensive study of recently\nadvances and challenges are still lacking. This limits the broader\nunderstanding of how to utilize events in universal imaging applications. In\nthis survey, we first introduce a physical model and the characteristics of\ndifferent event sensors as the foundation. Following this, we highlight the\nadvancement and interaction of image/video enhancement tasks with events.\nAdditionally, we explore advanced tasks, which capture richer light information\nwith events, \\eg~light field estimation, multi-view generation, and\nphotometric. Finally, we discuss new challenges and open questions offering a\nperspective for this rapidly evolving field. More continuously updated\nresources are at this link: https://github.com/yunfanLu/Awesome-Event-Imaging", "AI": {"tldr": "A survey on event cameras, covering their physical model, advancements in imaging tasks, and challenges in the field.", "motivation": "To provide a comprehensive study of event cameras' benefits and limitations for universal imaging applications.", "method": "Introduces a physical model of event sensors, reviews advancements in image/video enhancement, and explores advanced tasks like light field estimation.", "result": "Highlights the potential of event cameras in various imaging tasks but notes gaps in broader understanding and challenges.", "conclusion": "The survey offers insights into the evolving field of event imaging and identifies open questions for future research."}}
{"id": "2505.05525", "pdf": "https://arxiv.org/pdf/2505.05525", "abs": "https://arxiv.org/abs/2505.05525", "authors": ["Selim Mecanna", "Aurore Loisy", "Christophe Eloy"], "title": "A critical assessment of reinforcement learning methods for microswimmer navigation in complex flows", "categories": ["cs.LG", "physics.flu-dyn"], "comment": null, "summary": "Navigating in a fluid flow while being carried by it, using only information\naccessible from on-board sensors, is a problem commonly faced by small\nplanktonic organisms. It is also directly relevant to autonomous robots\ndeployed in the oceans. In the last ten years, the fluid mechanics community\nhas widely adopted reinforcement learning, often in the form of its simplest\nimplementations, to address this challenge. But it is unclear how good are the\nstrategies learned by these algorithms. In this paper, we perform a\nquantitative assessment of reinforcement learning methods applied to navigation\nin partially observable flows. We first introduce a well-posed problem of\ndirectional navigation for which a quasi-optimal policy is known analytically.\nWe then report on the poor performance and robustness of commonly used\nalgorithms (Q-Learning, Advantage Actor Critic) in flows regularly encountered\nin the literature: Taylor-Green vortices, Arnold-Beltrami-Childress flow, and\ntwo-dimensional turbulence. We show that they are vastly surpassed by PPO\n(Proximal Policy Optimization), a more advanced algorithm that has established\ndominance across a wide range of benchmarks in the reinforcement learning\ncommunity. In particular, our custom implementation of PPO matches the\ntheoretical quasi-optimal performance in turbulent flow and does so in a robust\nmanner. Reaching this result required the use of several additional techniques,\nsuch as vectorized environments and generalized advantage estimation, as well\nas hyperparameter optimization. This study demonstrates the importance of\nalgorithm selection, implementation details, and fine-tuning for discovering\ntruly smart autonomous navigation strategies in complex flows.", "AI": {"tldr": "The paper evaluates reinforcement learning (RL) methods for autonomous navigation in fluid flows, finding that advanced algorithms like PPO outperform simpler ones like Q-Learning and A2C, matching quasi-optimal performance in turbulent flows.", "motivation": "To assess the effectiveness of RL algorithms for navigation in partially observable fluid flows, a problem relevant to planktonic organisms and autonomous ocean robots.", "method": "Introduces a directional navigation problem with a known quasi-optimal policy, then tests Q-Learning, A2C, and PPO in various flow types (Taylor-Green vortices, ABC flow, 2D turbulence). Custom PPO implementation includes techniques like vectorized environments and hyperparameter optimization.", "result": "PPO outperforms simpler RL methods, matching theoretical quasi-optimal performance in turbulent flows, while Q-Learning and A2C perform poorly.", "conclusion": "Algorithm selection, implementation details, and fine-tuning are critical for effective autonomous navigation in complex flows."}}
{"id": "2505.05797", "pdf": "https://arxiv.org/pdf/2505.05797", "abs": "https://arxiv.org/abs/2505.05797", "authors": ["Lucia Stephanie B. Sibala", "Novy Aila B. Rivas", "Giovanna Fae R. Oguis"], "title": "Assessing the Dynamics of the Coffee Value Chain in Davao del Sur: An Agent-Based Modeling Approach", "categories": ["econ.GN", "cs.CY", "cs.MA", "q-fin.EC"], "comment": "56 pages, 12 figures, 7 tables", "summary": "The study investigates the coffee value chain dynamics in Davao del Sur using\nan agent-based model. Three main factors driving interactions among key players\nwere identified: trust, risk, and transaction costs. The model was constructed\nusing NetLogo 6.3.0, and data from a survey questionnaire collected three data\npoints from BACOFA members. Five cases were explored, with each scenario\nsimulated 1000 times. Findings suggest that producers often sell to the market\nrather than the cooperative due to higher prices. However, producers tend to\nprioritize trust in buyers and their risk attitude, leading to increased sales\nto the cooperative. The producer's risk attitude significantly influences their\ndecision-making, affecting performance outcomes such as loans, demand, and\nprice changes. All three factors play a role and exert varying impacts on the\nvalue chain. So, the stakeholders' decisions on prioritizing factors in\nimproving relationships depend on their priorities. Nonetheless, simulations\nshow that establishing a harmonious system benefiting all parties is possible.\nHowever, achieving this requires adjustments to demand, pricing, trust, and\nrisk attitudes of key players, which may not align with the preferences of some\nparties in reality.", "AI": {"tldr": "The study models the coffee value chain in Davao del Sur, identifying trust, risk, and transaction costs as key factors. Producers often prefer markets over cooperatives for higher prices but prioritize trust and risk attitudes, influencing sales and outcomes. Harmonious systems are possible but require adjustments.", "motivation": "To understand the dynamics of the coffee value chain in Davao del Sur and identify factors influencing interactions among stakeholders.", "method": "An agent-based model was developed using NetLogo 6.3.0, with data from BACOFA member surveys. Five scenarios were simulated 1000 times each.", "result": "Producers favor markets for higher prices but prioritize trust and risk attitudes, impacting sales and outcomes. All factors (trust, risk, transaction costs) influence the chain differently.", "conclusion": "Harmonious value chain systems are achievable but require adjustments in demand, pricing, trust, and risk attitudes, though these may not align with all stakeholders' preferences."}}
{"id": "2505.05509", "pdf": "https://arxiv.org/pdf/2505.05509", "abs": "https://arxiv.org/abs/2505.05509", "authors": ["Yi Liu", "Xinyi Liu", "Panwang Xia", "Qiong Wu", "Yi Wan", "Yongjun Zhang"], "title": "StereoINR: Cross-View Geometry Consistent Stereo Super Resolution with Implicit Neural Representation", "categories": ["eess.IV", "cs.CV"], "comment": null, "summary": "Stereo image super-resolution (SSR) aims to enhance high-resolution details\nby leveraging information from stereo image pairs. However, existing stereo\nsuper-resolution (SSR) upsampling methods (e.g., pixel shuffle) often overlook\ncross-view geometric consistency and are limited to fixed-scale upsampling. The\nkey issue is that previous upsampling methods use convolution to independently\nprocess deep features of different views, lacking cross-view and non-local\ninformation perception, making it difficult to select beneficial information\nfrom multi-view scenes adaptively. In this work, we propose Stereo Implicit\nNeural Representation (StereoINR), which innovatively models stereo image pairs\nas continuous implicit representations. This continuous representation breaks\nthrough the scale limitations, providing a unified solution for arbitrary-scale\nstereo super-resolution reconstruction of left-right views. Furthermore, by\nincorporating spatial warping and cross-attention mechanisms, StereoINR enables\neffective cross-view information fusion and achieves significant improvements\nin pixel-level geometric consistency. Extensive experiments across multiple\ndatasets show that StereoINR outperforms out-of-training-distribution scale\nupsampling and matches state-of-the-art SSR methods within\ntraining-distribution scales.", "AI": {"tldr": "StereoINR proposes a novel method for stereo image super-resolution by modeling stereo pairs as continuous implicit representations, enabling arbitrary-scale upsampling and improved cross-view consistency.", "motivation": "Existing SSR methods lack cross-view geometric consistency and are limited to fixed-scale upsampling, missing adaptive multi-view information fusion.", "method": "StereoINR models stereo pairs as continuous implicit representations, uses spatial warping and cross-attention for cross-view fusion, and supports arbitrary-scale upsampling.", "result": "StereoINR outperforms out-of-training-distribution scale upsampling and matches state-of-the-art SSR methods within training scales.", "conclusion": "StereoINR provides a unified, scalable solution for stereo super-resolution with enhanced cross-view consistency."}}
{"id": "2505.05755", "pdf": "https://arxiv.org/pdf/2505.05755", "abs": "https://arxiv.org/abs/2505.05755", "authors": ["Dhruvesh Patel", "Aishwarya Sahoo", "Avinash Amballa", "Tahira Naseem", "Tim G. J. Rudner", "Andrew McCallum"], "title": "Insertion Language Models: Sequence Generation with Arbitrary-Position Insertions", "categories": ["cs.CL", "cs.LG"], "comment": null, "summary": "Autoregressive models (ARMs), which predict subsequent tokens one-by-one\n``from left to right,'' have achieved significant success across a wide range\nof sequence generation tasks. However, they struggle to accurately represent\nsequences that require satisfying sophisticated constraints or whose sequential\ndependencies are better addressed by out-of-order generation. Masked Diffusion\nModels (MDMs) address some of these limitations, but the process of unmasking\nmultiple tokens simultaneously in MDMs can introduce incoherences, and MDMs\ncannot handle arbitrary infilling constraints when the number of tokens to be\nfilled in is not known in advance. In this work, we introduce Insertion\nLanguage Models (ILMs), which learn to insert tokens at arbitrary positions in\na sequence -- that is, they select jointly both the position and the vocabulary\nelement to be inserted. By inserting tokens one at a time, ILMs can represent\nstrong dependencies between tokens, and their ability to generate sequences in\narbitrary order allows them to accurately model sequences where token\ndependencies do not follow a left-to-right sequential structure. To train ILMs,\nwe propose a tailored network parameterization and use a simple denoising\nobjective. Our empirical evaluation demonstrates that ILMs outperform both ARMs\nand MDMs on common planning tasks. Furthermore, we show that ILMs outperform\nMDMs and perform on par with ARMs in an unconditional text generation task\nwhile offering greater flexibility than MDMs in arbitrary-length text\ninfilling.", "AI": {"tldr": "Insertion Language Models (ILMs) outperform Autoregressive Models (ARMs) and Masked Diffusion Models (MDMs) in planning tasks and offer flexibility in arbitrary-length text infilling.", "motivation": "ARMs and MDMs have limitations in handling sequences with sophisticated constraints or non-sequential dependencies. ILMs aim to address these gaps by allowing token insertion at arbitrary positions.", "method": "ILMs insert tokens one at a time at any position, using a tailored network parameterization and a denoising objective for training.", "result": "ILMs outperform ARMs and MDMs in planning tasks and match ARMs in text generation while offering more flexibility than MDMs.", "conclusion": "ILMs provide a flexible and effective alternative to ARMs and MDMs for sequence generation, especially for tasks requiring non-sequential dependencies."}}
{"id": "2305.03568", "pdf": "https://arxiv.org/pdf/2305.03568", "abs": "https://arxiv.org/abs/2305.03568", "authors": ["Samir Sadok", "Simon Leglaive", "Renaud S\u00e9guier"], "title": "A vector quantized masked autoencoder for audiovisual speech emotion recognition", "categories": ["cs.SD", "cs.LG", "cs.MM", "eess.AS"], "comment": "13 pages, 6 figures, https://samsad35.github.io/VQ-MAE-AudioVisual/", "summary": "An important challenge in emotion recognition is to develop methods that can\nleverage unlabeled training data. In this paper, we propose the VQ-MAE-AV\nmodel, a self-supervised multimodal model that leverages masked autoencoders to\nlearn representations of audiovisual speech without labels. The model includes\nvector quantized variational autoencoders that compress raw audio and visual\nspeech data into discrete tokens. The audiovisual speech tokens are used to\ntrain a multimodal masked autoencoder that consists of an encoder-decoder\narchitecture with attention mechanisms. The model is designed to extract both\nlocal (i.e., at the frame level) and global (i.e., at the sequence level)\nrepresentations of audiovisual speech. During self-supervised pre-training, the\nVQ-MAE-AV model is trained on a large-scale unlabeled dataset of audiovisual\nspeech, for the task of reconstructing randomly masked audiovisual speech\ntokens and with a contrastive learning strategy. During this pre-training, the\nencoder learns to extract a representation of audiovisual speech that can be\nsubsequently leveraged for emotion recognition. During the supervised\nfine-tuning stage, a small classification model is trained on top of the\nVQ-MAE-AV encoder for an emotion recognition task. The proposed approach\nachieves state-of-the-art emotion recognition results across several datasets\nin both controlled and in-the-wild conditions.", "AI": {"tldr": "The paper introduces VQ-MAE-AV, a self-supervised multimodal model for emotion recognition using masked autoencoders to learn from unlabeled audiovisual speech data.", "motivation": "To address the challenge of leveraging unlabeled data for emotion recognition by developing a self-supervised approach.", "method": "Uses vector quantized variational autoencoders to compress raw data into tokens, trains a multimodal masked autoencoder with attention mechanisms, and fine-tunes for emotion recognition.", "result": "Achieves state-of-the-art performance across multiple datasets in controlled and in-the-wild conditions.", "conclusion": "VQ-MAE-AV effectively leverages unlabeled data for superior emotion recognition, demonstrating the potential of self-supervised learning in this domain."}}
{"id": "2505.06149", "pdf": "https://arxiv.org/pdf/2505.06149", "abs": "https://arxiv.org/abs/2505.06149", "authors": ["Faeze Ghorbanpour", "Daryna Dementieva", "Alexander Fraser"], "title": "Can Prompting LLMs Unlock Hate Speech Detection across Languages? A Zero-shot and Few-shot Study", "categories": ["cs.CL", "cs.CY", "cs.MM"], "comment": null, "summary": "Despite growing interest in automated hate speech detection, most existing\napproaches overlook the linguistic diversity of online content. Multilingual\ninstruction-tuned large language models such as LLaMA, Aya, Qwen, and BloomZ\noffer promising capabilities across languages, but their effectiveness in\nidentifying hate speech through zero-shot and few-shot prompting remains\nunderexplored. This work evaluates LLM prompting-based detection across eight\nnon-English languages, utilizing several prompting techniques and comparing\nthem to fine-tuned encoder models. We show that while zero-shot and few-shot\nprompting lag behind fine-tuned encoder models on most of the real-world\nevaluation sets, they achieve better generalization on functional tests for\nhate speech detection. Our study also reveals that prompt design plays a\ncritical role, with each language often requiring customized prompting\ntechniques to maximize performance.", "AI": {"tldr": "The paper evaluates multilingual LLMs for hate speech detection, finding that zero-shot and few-shot prompting underperform fine-tuned models but generalize better, with prompt design being crucial.", "motivation": "Existing hate speech detection approaches often ignore linguistic diversity, and the effectiveness of multilingual LLMs in this task is underexplored.", "method": "The study tests LLM prompting (zero-shot and few-shot) across eight non-English languages, comparing it to fine-tuned encoder models and analyzing prompt design impact.", "result": "Zero-shot and few-shot prompting lag behind fine-tuned models in real-world evaluations but generalize better in functional tests. Prompt design significantly affects performance.", "conclusion": "Customized prompting techniques per language are essential for optimizing LLM-based hate speech detection, though fine-tuned models remain superior in most real-world cases."}}
{"id": "2505.05612", "pdf": "https://arxiv.org/pdf/2505.05612", "abs": "https://arxiv.org/abs/2505.05612", "authors": ["Qing Wang", "Yining Pan", "Minghao Zhou", "Zijia Tang", "Yanfei Wang", "Guangyu Wang", "Qianqian Song"], "title": "scDrugMap: Benchmarking Large Foundation Models for Drug Response Prediction", "categories": ["cs.AI", "cs.LG", "q-bio.QM"], "comment": "14 pages, 7 figures", "summary": "Drug resistance presents a major challenge in cancer therapy. Single cell\nprofiling offers insights into cellular heterogeneity, yet the application of\nlarge-scale foundation models for predicting drug response in single cell data\nremains underexplored. To address this, we developed scDrugMap, an integrated\nframework featuring both a Python command-line interface and a web server for\ndrug response prediction. scDrugMap evaluates a wide range of foundation\nmodels, including eight single-cell models and two large language models, using\na curated dataset of over 326,000 cells in the primary collection and 18,800\ncells in the validation set, spanning 36 datasets and diverse tissue and cancer\ntypes. We benchmarked model performance under pooled-data and cross-data\nevaluation settings, employing both layer freezing and Low-Rank Adaptation\n(LoRA) fine-tuning strategies. In the pooled-data scenario, scFoundation\nachieved the best performance, with mean F1 scores of 0.971 (layer freezing)\nand 0.947 (fine-tuning), outperforming the lowest-performing model by over 50%.\nIn the cross-data setting, UCE excelled post fine-tuning (mean F1: 0.774),\nwhile scGPT led in zero-shot learning (mean F1: 0.858). Overall, scDrugMap\nprovides the first large-scale benchmark of foundation models for drug response\nprediction in single-cell data and serves as a user-friendly, flexible platform\nfor advancing drug discovery and translational research.", "AI": {"tldr": "scDrugMap is a framework for drug response prediction in single-cell data, benchmarking foundation models and offering a user-friendly platform for drug discovery.", "motivation": "Drug resistance in cancer therapy and the underexplored use of large-scale foundation models for predicting drug response in single-cell data.", "method": "Developed scDrugMap, evaluating foundation models (8 single-cell, 2 LLMs) on 326K+ cells, using layer freezing and LoRA fine-tuning.", "result": "scFoundation performed best in pooled-data (F1: 0.971/0.947), UCE in cross-data fine-tuning (F1: 0.774), and scGPT in zero-shot (F1: 0.858).", "conclusion": "scDrugMap is a pioneering benchmark and platform for drug response prediction, aiding drug discovery and research."}}
{"id": "2505.04457", "pdf": "https://arxiv.org/pdf/2505.04457", "abs": "https://arxiv.org/abs/2505.04457", "authors": ["Shigeki Karita", "Yuma Koizumi", "Heiga Zen", "Haruko Ishikawa", "Robin Scheibler", "Michiel Bacchiani"], "title": "Miipher-2: A Universal Speech Restoration Model for Million-Hour Scale Data Restoration", "categories": ["cs.SD", "cs.CL", "eess.AS"], "comment": null, "summary": "Training data cleaning is a new application for generative model-based speech\nrestoration (SR). This paper introduces Miipher-2, an SR model designed for\nmillion-hour scale data, for training data cleaning for large-scale generative\nmodels like large language models. Key challenges addressed include\ngeneralization to unseen languages, operation without explicit conditioning\n(e.g., text, speaker ID), and computational efficiency. Miipher-2 utilizes a\nfrozen, pre-trained Universal Speech Model (USM), supporting over 300\nlanguages, as a robust, conditioning-free feature extractor. To optimize\nefficiency and minimize memory, Miipher-2 incorporates parallel adapters for\npredicting clean USM features from noisy inputs and employs the WaveFit neural\nvocoder for waveform synthesis. These components were trained on 3,000 hours of\nmulti-lingual, studio-quality recordings with augmented degradations, while USM\nparameters remained fixed. Experimental results demonstrate Miipher-2's\nsuperior or comparable performance to conventional SR models in\nword-error-rate, speaker similarity, and both objective and subjective sound\nquality scores across all tested languages. Miipher-2 operates efficiently on\nconsumer-grade accelerators, achieving a real-time factor of 0.0078, enabling\nthe processing of a million-hour speech dataset in approximately three days\nusing only 100 such accelerators.", "AI": {"tldr": "Miipher-2 is a speech restoration model for cleaning large-scale training data, addressing challenges like generalization, efficiency, and no explicit conditioning. It uses a frozen USM and parallel adapters for feature prediction, achieving high performance and efficiency.", "motivation": "To clean training data for large-scale generative models, addressing challenges like unseen languages and computational efficiency.", "method": "Uses a frozen Universal Speech Model (USM) for feature extraction, parallel adapters for clean feature prediction, and WaveFit for waveform synthesis, trained on multi-lingual data.", "result": "Outperforms conventional SR models in word-error-rate, speaker similarity, and sound quality, with high efficiency (real-time factor 0.0078).", "conclusion": "Miipher-2 is effective for large-scale data cleaning, offering superior performance and scalability for generative model training."}}
{"id": "2505.05491", "pdf": "https://arxiv.org/pdf/2505.05491", "abs": "https://arxiv.org/abs/2505.05491", "authors": ["TianYi Yu"], "title": "MDDFNet: Mamba-based Dynamic Dual Fusion Network for Traffic Sign Detection", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "The Detection of small objects, especially traffic signs, is a critical\nsub-task in object detection and autonomous driving. Despite signficant\nprogress in previous research, two main challenges remain. First, the issue of\nfeature extraction being too singular. Second, the detection process struggles\nto efectively handle objects of varying sizes or scales. These problems are\nalso prevalent in general object detection tasks. To address these challenges,\nwe propose a novel object detection network, Mamba-based Dynamic Dual Fusion\nNetwork (MDDFNet), for traffic sign detection. The network integrates a dynamic\ndual fusion module and a Mamba-based backbone to simultaneously tackle the\naforementioned issues. Specifically, the dynamic dual fusion module utilizes\nmultiple branches to consolidate various spatial and semantic information, thus\nenhancing feature diversity. The Mamba-based backbone leverages global feature\nfusion and local feature interaction, combining features in an adaptive manner\nto generate unique classification characteristics. Extensive experiments\nconducted on the TT100K (Tsinghua-Tencent 100K) datasets demonstrate that\nMDDFNet outperforms other state-of-the-art detectors, maintaining real-time\nprocessing capabilities of single-stage models while achieving superior\nperformance. This confirms the efectiveness of MDDFNet in detecting small\ntraffic signs.", "AI": {"tldr": "MDDFNet, a novel network for traffic sign detection, addresses feature extraction and scale handling challenges with dynamic dual fusion and a Mamba-based backbone, outperforming state-of-the-art models on TT100K datasets.", "motivation": "Challenges in detecting small objects like traffic signs include singular feature extraction and ineffective handling of varying object sizes.", "method": "MDDFNet integrates a dynamic dual fusion module for diverse feature extraction and a Mamba-based backbone for adaptive feature fusion.", "result": "MDDFNet achieves superior performance on TT100K datasets, maintaining real-time processing.", "conclusion": "MDDFNet effectively detects small traffic signs, addressing key challenges in object detection."}}
{"id": "2505.05527", "pdf": "https://arxiv.org/pdf/2505.05527", "abs": "https://arxiv.org/abs/2505.05527", "authors": ["Giovanni Perin", "Cesare Bidini", "Riccardo Mazzieri", "Michele Rossi"], "title": "ADMM-Based Training for Spiking Neural Networks", "categories": ["cs.LG", "cs.AI", "cs.NE", "eess.SP", "math.OC"], "comment": "6 pages, 4 figures. Preprint submitted to IEEE MLSP 2025", "summary": "In recent years, spiking neural networks (SNNs) have gained momentum due to\ntheir high potential in time-series processing combined with minimal energy\nconsumption. However, they still lack a dedicated and efficient training\nalgorithm. The popular backpropagation with surrogate gradients, adapted from\nstochastic gradient descent (SGD)-derived algorithms, has several drawbacks\nwhen used as an optimizer for SNNs. Specifically, it suffers from low\nscalability and numerical imprecision. In this paper, we propose a novel SNN\ntraining method based on the alternating direction method of multipliers\n(ADMM). Our ADMM-based training aims to solve the problem of the SNN step\nfunction's non-differentiability. We formulate the problem, derive closed-form\nupdates, and empirically show the optimizer's convergence properties, great\npotential, and possible new research directions to improve the method in a\nsimulated proof-of-concept.", "AI": {"tldr": "Proposes an ADMM-based training method for SNNs to address non-differentiability and scalability issues in existing approaches.", "motivation": "Existing SNN training methods like backpropagation with surrogate gradients suffer from scalability and numerical imprecision.", "method": "Uses the alternating direction method of multipliers (ADMM) to solve non-differentiability, with closed-form updates.", "result": "Empirical results show convergence, potential, and new research directions.", "conclusion": "ADMM-based training is promising for SNNs, offering a scalable and precise alternative."}}
{"id": "2505.05968", "pdf": "https://arxiv.org/pdf/2505.05968", "abs": "https://arxiv.org/abs/2505.05968", "authors": ["Dan Qiao", "Wenhao Li", "Shanchao Yang", "Hongyuan Zha", "Baoxiang Wang"], "title": "Offline Multi-agent Reinforcement Learning via Score Decomposition", "categories": ["cs.LG", "cs.MA"], "comment": "Working papers", "summary": "Offline multi-agent reinforcement learning (MARL) faces critical challenges\ndue to distributional shifts, further exacerbated by the high dimensionality of\njoint action spaces and the diversity in coordination strategies and quality\namong agents. Conventional approaches, including independent learning\nframeworks and value decomposition methods based on pessimistic principles,\nremain susceptible to out-of-distribution (OOD) joint actions and often yield\nsuboptimal performance. Through systematic analysis of prevalent offline MARL\nbenchmarks, we identify that this limitation primarily stems from the\ninherently multimodal nature of joint collaborative policies induced by offline\ndata collection. To address these challenges, we propose a novel two-stage\nframework: First, we employ a diffusion-based generative model to explicitly\ncapture the complex behavior policy, enabling accurate modeling of diverse\nmulti-agent coordination patterns. Second, we introduce a sequential score\nfunction decomposition mechanism to regularize individual policies and enable\ndecentralized execution. Extensive experiments on continuous control tasks\ndemonstrate state-of-the-art performance across multiple standard offline MARL\nbenchmarks, outperforming existing methods by 26.3\\% in normalized returns. Our\napproach provides new insights into offline coordination and equilibrium\nselection in cooperative multi-agent systems.", "AI": {"tldr": "A novel two-stage framework using diffusion models and score function decomposition addresses offline MARL challenges, outperforming existing methods by 26.3%.", "motivation": "Offline MARL struggles with distributional shifts and OOD actions due to multimodal joint policies.", "method": "Uses a diffusion-based generative model to capture behavior policies and a score function decomposition for decentralized execution.", "result": "Achieves state-of-the-art performance, improving normalized returns by 26.3%.", "conclusion": "Provides insights into offline coordination and equilibrium selection in multi-agent systems."}}
{"id": "2505.05518", "pdf": "https://arxiv.org/pdf/2505.05518", "abs": "https://arxiv.org/abs/2505.05518", "authors": ["Jaeyoung Huh", "Ankur Kapoor", "Young-Ho Kim"], "title": "Guidance for Intra-cardiac Echocardiography Manipulation to Maintain Continuous Therapy Device Tip Visibility", "categories": ["eess.IV", "cs.CV", "cs.RO"], "comment": null, "summary": "Intra-cardiac Echocardiography (ICE) plays a critical role in\nElectrophysiology (EP) and Structural Heart Disease (SHD) interventions by\nproviding real-time visualization of intracardiac structures. However,\nmaintaining continuous visibility of the therapy device tip remains a challenge\ndue to frequent adjustments required during manual ICE catheter manipulation.\nTo address this, we propose an AI-driven tracking model that estimates the\ndevice tip incident angle and passing point within the ICE imaging plane,\nensuring continuous visibility and facilitating robotic ICE catheter control.\n  A key innovation of our approach is the hybrid dataset generation strategy,\nwhich combines clinical ICE sequences with synthetic data augmentation to\nenhance model robustness. We collected ICE images in a water chamber setup,\nequipping both the ICE catheter and device tip with electromagnetic (EM)\nsensors to establish precise ground-truth locations. Synthetic sequences were\ncreated by overlaying catheter tips onto real ICE images, preserving motion\ncontinuity while simulating diverse anatomical scenarios. The final dataset\nconsists of 5,698 ICE-tip image pairs, ensuring comprehensive training\ncoverage.\n  Our model architecture integrates a pretrained ultrasound (US) foundation\nmodel, trained on 37.4M echocardiography images, for feature extraction. A\ntransformer-based network processes sequential ICE frames, leveraging\nhistorical passing points and incident angles to improve prediction accuracy.\n  Experimental results demonstrate that our method achieves 3.32 degree entry\nangle error, 12.76 degree rotation angle error. This AI-driven framework lays\nthe foundation for real-time robotic ICE catheter adjustments, minimizing\noperator workload while ensuring consistent therapy device visibility. Future\nwork will focus on expanding clinical datasets to further enhance model\ngeneralization.", "AI": {"tldr": "An AI-driven tracking model is proposed to maintain continuous visibility of therapy device tips in Intra-cardiac Echocardiography (ICE) during interventions, using a hybrid dataset and transformer-based architecture for accurate predictions.", "motivation": "Manual ICE catheter manipulation requires frequent adjustments, making continuous visibility of therapy device tips challenging. The goal is to automate this process to reduce operator workload and improve precision.", "method": "A hybrid dataset of clinical ICE sequences and synthetic data was created. A transformer-based network, leveraging a pretrained ultrasound foundation model, processes sequential ICE frames to predict device tip angles and positions.", "result": "The model achieved a 3.32-degree entry angle error and 12.76-degree rotation angle error, demonstrating high accuracy in tracking.", "conclusion": "The AI-driven framework enables real-time robotic ICE catheter adjustments, ensuring consistent device visibility. Future work will expand clinical datasets for better generalization."}}
{"id": "2505.05772", "pdf": "https://arxiv.org/pdf/2505.05772", "abs": "https://arxiv.org/abs/2505.05772", "authors": ["Zehao Fan", "Garrett Gagnon", "Zhenyu Liu", "Liu Liu"], "title": "Sparse Attention Remapping with Clustering for Efficient LLM Decoding on PIM", "categories": ["cs.CL", "cs.LG"], "comment": null, "summary": "Transformer-based models are the foundation of modern machine learning, but\ntheir execution, particularly during autoregressive decoding in large language\nmodels (LLMs), places significant pressure on memory systems due to frequent\nmemory accesses and growing key-value (KV) caches. This creates a bottleneck in\nmemory bandwidth, especially as context lengths increase. Processing-in-memory\n(PIM) architectures are a promising solution, offering high internal bandwidth\nand compute parallelism near memory. However, current PIM designs are primarily\noptimized for dense attention and struggle with the dynamic, irregular access\npatterns introduced by modern KV cache sparsity techniques. Consequently, they\nsuffer from workload imbalance, reducing throughput and resource utilization.\nIn this work, we propose STARC, a novel sparsity-optimized data mapping scheme\ntailored specifically for efficient LLM decoding on PIM architectures. STARC\nclusters KV pairs by semantic similarity and maps them to contiguous memory\nregions aligned with PIM bank structures. During decoding, queries retrieve\nrelevant tokens at cluster granularity by matching against precomputed\ncentroids, enabling selective attention and parallel processing without\nfrequent reclustering or data movement overhead. Experiments on the HBM-PIM\nsystem show that, compared to common token-wise sparsity methods, STARC reduces\nattention-layer latency by 19%--31% and energy consumption by 19%--27%. Under a\nKV cache budget of 1024, it achieves up to 54%--74% latency reduction and\n45%--67% energy reduction compared to full KV cache retrieval. Meanwhile, STARC\nmaintains model accuracy comparable to state-of-the-art sparse attention\nmethods, demonstrating its effectiveness in enabling efficient and\nhardware-friendly long-context LLM inference on PIM architectures.", "AI": {"tldr": "STARC is a sparsity-optimized data mapping scheme for efficient LLM decoding on PIM architectures, reducing latency and energy while maintaining accuracy.", "motivation": "Transformer-based models face memory bottlenecks due to KV cache sparsity and irregular access patterns, which current PIM designs struggle to handle.", "method": "STARC clusters KV pairs by semantic similarity, maps them to contiguous memory regions, and uses precomputed centroids for selective attention.", "result": "STARC reduces attention-layer latency by 19%--31% and energy by 19%--27%, with further improvements under KV cache constraints.", "conclusion": "STARC enables efficient, hardware-friendly long-context LLM inference on PIM architectures without compromising accuracy."}}
{"id": "2402.00045", "pdf": "https://arxiv.org/pdf/2402.00045", "abs": "https://arxiv.org/abs/2402.00045", "authors": ["Li Lin", "Neeraj Gupta", "Yue Zhang", "Hainan Ren", "Chun-Hao Liu", "Feng Ding", "Xin Wang", "Xin Li", "Luisa Verdoliva", "Shu Hu"], "title": "Detecting Multimedia Generated by Large AI Models: A Survey", "categories": ["cs.MM", "cs.AI", "cs.LG"], "comment": null, "summary": "The rapid advancement of Large AI Models (LAIMs), particularly diffusion\nmodels and large language models, has marked a new era where AI-generated\nmultimedia is increasingly integrated into various aspects of daily life.\nAlthough beneficial in numerous fields, this content presents significant\nrisks, including potential misuse, societal disruptions, and ethical concerns.\nConsequently, detecting multimedia generated by LAIMs has become crucial, with\na marked rise in related research. Despite this, there remains a notable gap in\nsystematic surveys that focus specifically on detecting LAIM-generated\nmultimedia. Addressing this, we provide the first survey to comprehensively\ncover existing research on detecting multimedia (such as text, images, videos,\naudio, and multimodal content) created by LAIMs. Specifically, we introduce a\nnovel taxonomy for detection methods, categorized by media modality, and\naligned with two perspectives: pure detection (aiming to enhance detection\nperformance) and beyond detection (adding attributes like generalizability,\nrobustness, and interpretability to detectors). Additionally, we have presented\na brief overview of generation mechanisms, public datasets, online detection\ntools, and evaluation metrics to provide a valuable resource for researchers\nand practitioners in this field. Most importantly, we offer a focused analysis\nfrom a social media perspective to highlight their broader societal impact.\nFurthermore, we identify current challenges in detection and propose directions\nfor future research that address unexplored, ongoing, and emerging issues in\ndetecting multimedia generated by LAIMs. Our aim for this survey is to fill an\nacademic gap and contribute to global AI security efforts, helping to ensure\nthe integrity of information in the digital realm. The project link is\nhttps://github.com/Purdue-M2/Detect-LAIM-generated-Multimedia-Survey.", "AI": {"tldr": "This paper presents the first comprehensive survey on detecting multimedia generated by Large AI Models (LAIMs), introducing a taxonomy for detection methods and addressing societal impacts and future research directions.", "motivation": "The rapid integration of AI-generated multimedia into daily life poses risks like misuse and ethical concerns, necessitating systematic detection methods.", "method": "The survey categorizes detection methods by media modality and perspectives (pure detection and beyond detection), and reviews generation mechanisms, datasets, tools, and metrics.", "result": "A novel taxonomy for LAIM-generated multimedia detection is introduced, alongside resources for researchers and insights into societal impacts.", "conclusion": "The survey fills an academic gap, aids global AI security, and proposes future research directions to address detection challenges."}}
{"id": "2505.05616", "pdf": "https://arxiv.org/pdf/2505.05616", "abs": "https://arxiv.org/abs/2505.05616", "authors": ["Lorenzo Di Fruscia", "Jana Marie Weber"], "title": "Leveraging Large Language Models for enzymatic reaction prediction and characterization", "categories": ["cs.AI", "cs.LG", "q-bio.BM"], "comment": null, "summary": "Predicting enzymatic reactions is crucial for applications in biocatalysis,\nmetabolic engineering, and drug discovery, yet it remains a complex and\nresource-intensive task. Large Language Models (LLMs) have recently\ndemonstrated remarkable success in various scientific domains, e.g., through\ntheir ability to generalize knowledge, reason over complex structures, and\nleverage in-context learning strategies. In this study, we systematically\nevaluate the capability of LLMs, particularly the Llama-3.1 family (8B and\n70B), across three core biochemical tasks: Enzyme Commission number prediction,\nforward synthesis, and retrosynthesis. We compare single-task and multitask\nlearning strategies, employing parameter-efficient fine-tuning via LoRA\nadapters. Additionally, we assess performance across different data regimes to\nexplore their adaptability in low-data settings. Our results demonstrate that\nfine-tuned LLMs capture biochemical knowledge, with multitask learning\nenhancing forward- and retrosynthesis predictions by leveraging shared\nenzymatic information. We also identify key limitations, for example challenges\nin hierarchical EC classification schemes, highlighting areas for further\nimprovement in LLM-driven biochemical modeling.", "AI": {"tldr": "The paper evaluates LLMs (Llama-3.1 family) for predicting enzymatic reactions, focusing on EC number prediction, forward synthesis, and retrosynthesis. Multitask learning improves performance, but challenges remain in hierarchical EC classification.", "motivation": "Enzymatic reaction prediction is vital for biocatalysis, metabolic engineering, and drug discovery, but current methods are complex and resource-heavy. LLMs offer potential due to their generalization and reasoning abilities.", "method": "Systematic evaluation of LLMs (8B and 70B) using LoRA adapters for fine-tuning. Tasks include EC number prediction, forward synthesis, and retrosynthesis, comparing single-task and multitask learning across data regimes.", "result": "Fine-tuned LLMs effectively capture biochemical knowledge, with multitask learning boosting forward- and retrosynthesis predictions. Performance varies in low-data settings, and hierarchical EC classification poses challenges.", "conclusion": "LLMs show promise for enzymatic reaction prediction, with multitask learning enhancing results. However, limitations like EC classification issues indicate room for improvement in LLM-driven biochemical modeling."}}
{"id": "2505.05492", "pdf": "https://arxiv.org/pdf/2505.05492", "abs": "https://arxiv.org/abs/2505.05492", "authors": ["Ignacy St\u0119pka", "Lukasz Sztukiewicz", "Micha\u0142 Wili\u0144ski", "Jerzy Stefanowski"], "title": "DetoxAI: a Python Toolkit for Debiasing Deep Learning Models in Computer Vision", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": null, "summary": "While machine learning fairness has made significant progress in recent\nyears, most existing solutions focus on tabular data and are poorly suited for\nvision-based classification tasks, which rely heavily on deep learning. To\nbridge this gap, we introduce DetoxAI, an open-source Python library for\nimproving fairness in deep learning vision classifiers through post-hoc\ndebiasing. DetoxAI implements state-of-the-art debiasing algorithms, fairness\nmetrics, and visualization tools. It supports debiasing via interventions in\ninternal representations and includes attribution-based visualization tools and\nquantitative algorithmic fairness metrics to show how bias is mitigated. This\npaper presents the motivation, design, and use cases of DetoxAI, demonstrating\nits tangible value to engineers and researchers.", "AI": {"tldr": "DetoxAI is an open-source Python library for improving fairness in deep learning vision classifiers through post-hoc debiasing, offering debiasing algorithms, fairness metrics, and visualization tools.", "motivation": "Existing fairness solutions focus on tabular data and are poorly suited for vision-based tasks, creating a gap DetoxAI aims to bridge.", "method": "DetoxAI implements post-hoc debiasing via interventions in internal representations, along with attribution-based visualization and fairness metrics.", "result": "The library provides tools to mitigate bias in vision classifiers, demonstrating tangible value for engineers and researchers.", "conclusion": "DetoxAI addresses the gap in fairness solutions for vision tasks, offering practical tools for debiasing deep learning models."}}
{"id": "2505.05530", "pdf": "https://arxiv.org/pdf/2505.05530", "abs": "https://arxiv.org/abs/2505.05530", "authors": ["Kai Liu", "Qian Zheng", "Kaiwen Tao", "Zhiteng Li", "Haotong Qin", "Wenbo Li", "Yong Guo", "Xianglong Liu", "Linghe Kong", "Guihai Chen", "Yulun Zhang", "Xiaokang Yang"], "title": "Low-bit Model Quantization for Deep Neural Networks: A Survey", "categories": ["cs.LG", "cs.AI"], "comment": "We have systematically collected and reviewed the state-of-the-art\n  quantization methods from the past five years, categorizing them into eight\n  distinct groups. A curated list of model quantization is provided at\n  https://github.com/Kai-Liu001/Awesome-Model-Quantization", "summary": "With unprecedented rapid development, deep neural networks (DNNs) have deeply\ninfluenced almost all fields. However, their heavy computation costs and model\nsizes are usually unacceptable in real-world deployment. Model quantization, an\neffective weight-lighting technique, has become an indispensable procedure in\nthe whole deployment pipeline. The essence of quantization acceleration is the\nconversion from continuous floating-point numbers to discrete integer ones,\nwhich significantly speeds up the memory I/O and calculation, i.e., addition\nand multiplication. However, performance degradation also comes with the\nconversion because of the loss of precision. Therefore, it has become\nincreasingly popular and critical to investigate how to perform the conversion\nand how to compensate for the information loss. This article surveys the recent\nfive-year progress towards low-bit quantization on DNNs. We discuss and compare\nthe state-of-the-art quantization methods and classify them into 8 main\ncategories and 24 sub-categories according to their core techniques.\nFurthermore, we shed light on the potential research opportunities in the field\nof model quantization. A curated list of model quantization is provided at\nhttps://github.com/Kai-Liu001/Awesome-Model-Quantization.", "AI": {"tldr": "A survey of recent five-year progress in low-bit quantization for DNNs, classifying methods into 8 categories and highlighting research opportunities.", "motivation": "DNNs face high computation costs and large model sizes, making quantization essential for deployment despite performance degradation from precision loss.", "method": "Survey and classification of state-of-the-art quantization methods into 8 main and 24 sub-categories based on core techniques.", "result": "Comprehensive comparison of quantization methods and identification of potential research directions.", "conclusion": "Quantization is critical for DNN deployment, and the survey provides a roadmap for future research, with a curated resource list."}}
{"id": "2505.03586", "pdf": "https://arxiv.org/pdf/2505.03586", "abs": "https://arxiv.org/abs/2505.03586", "authors": ["Songchen Fu", "Siang Chen", "Shaojing Zhao", "Letian Bai", "Ta Li", "Yonghong Yan"], "title": "Rainbow Delay Compensation: A Multi-Agent Reinforcement Learning Framework for Mitigating Delayed Observation", "categories": ["cs.MA", "cs.AI", "68T07 (Primary), 68T20, 68T42 (Secondary)", "I.2"], "comment": "The code will be open-sourced in the RDC-pymarl project under\n  https://github.com/linkjoker1006", "summary": "In real-world multi-agent systems (MASs), observation delays are ubiquitous,\npreventing agents from making decisions based on the environment's true state.\nAn individual agent's local observation often consists of multiple components\nfrom other agents or dynamic entities in the environment. These discrete\nobservation components with varying delay characteristics pose significant\nchallenges for multi-agent reinforcement learning (MARL). In this paper, we\nfirst formulate the decentralized stochastic individual delay partially\nobservable Markov decision process (DSID-POMDP) by extending the standard\nDec-POMDP. We then propose the Rainbow Delay Compensation (RDC), a MARL\ntraining framework for addressing stochastic individual delays, along with\nrecommended implementations for its constituent modules. We implement the\nDSID-POMDP's observation generation pattern using standard MARL benchmarks,\nincluding MPE and SMAC. Experiments demonstrate that baseline MARL methods\nsuffer severe performance degradation under fixed and unfixed delays. The\nRDC-enhanced approach mitigates this issue, remarkably achieving ideal\ndelay-free performance in certain delay scenarios while maintaining\ngeneralizability. Our work provides a novel perspective on multi-agent delayed\nobservation problems and offers an effective solution framework. The source\ncode is available at https://anonymous.4open.science/r/RDC-pymarl-4512/.", "AI": {"tldr": "The paper introduces a framework (RDC) to address stochastic individual delays in multi-agent systems, improving MARL performance under delayed observations.", "motivation": "Observation delays in MASs hinder decision-making, requiring solutions for MARL to handle varying delay characteristics.", "method": "Proposes the DSID-POMDP model and the RDC framework, tested on MARL benchmarks (MPE, SMAC).", "result": "RDC mitigates performance degradation under delays, achieving near delay-free performance in some cases.", "conclusion": "RDC provides an effective solution for delayed observations in MASs, with generalizable results."}}
{"id": "2505.05631", "pdf": "https://arxiv.org/pdf/2505.05631", "abs": "https://arxiv.org/abs/2505.05631", "authors": ["Jiachen Tu", "Yaokun Shi", "Fan Lam"], "title": "Score-based Self-supervised MRI Denoising", "categories": ["eess.IV", "cs.CV"], "comment": null, "summary": "Magnetic resonance imaging (MRI) is a powerful noninvasive diagnostic imaging\ntool that provides unparalleled soft tissue contrast and anatomical detail.\nNoise contamination, especially in accelerated and/or low-field acquisitions,\ncan significantly degrade image quality and diagnostic accuracy. Supervised\nlearning based denoising approaches have achieved impressive performance but\nrequire high signal-to-noise ratio (SNR) labels, which are often unavailable.\nSelf-supervised learning holds promise to address the label scarcity issue, but\nexisting self-supervised denoising methods tend to oversmooth fine spatial\nfeatures and often yield inferior performance than supervised methods. We\nintroduce Corruption2Self (C2S), a novel score-based self-supervised framework\nfor MRI denoising. At the core of C2S is a generalized denoising score matching\n(GDSM) loss, which extends denoising score matching to work directly with noisy\nobservations by modeling the conditional expectation of higher-SNR images given\nfurther corrupted observations. This allows the model to effectively learn\ndenoising across multiple noise levels directly from noisy data. Additionally,\nwe incorporate a reparameterization of noise levels to stabilize training and\nenhance convergence, and introduce a detail refinement extension to balance\nnoise reduction with the preservation of fine spatial features. Moreover, C2S\ncan be extended to multi-contrast denoising by leveraging complementary\ninformation across different MRI contrasts. We demonstrate that our method\nachieves state-of-the-art performance among self-supervised methods and\ncompetitive results compared to supervised counterparts across varying noise\nconditions and MRI contrasts on the M4Raw and fastMRI dataset.", "AI": {"tldr": "C2S is a novel self-supervised MRI denoising method using generalized denoising score matching, outperforming existing self-supervised methods and competing with supervised ones.", "motivation": "Supervised denoising requires high-SNR labels, which are scarce. Existing self-supervised methods oversmooth features and underperform.", "method": "Introduces Corruption2Self (C2S) with a generalized denoising score matching loss, noise reparameterization, and detail refinement. Extends to multi-contrast denoising.", "result": "Achieves state-of-the-art self-supervised performance and competes with supervised methods on M4Raw and fastMRI datasets.", "conclusion": "C2S effectively addresses label scarcity and preserves fine features, offering a robust solution for MRI denoising."}}
{"id": "2505.05815", "pdf": "https://arxiv.org/pdf/2505.05815", "abs": "https://arxiv.org/abs/2505.05815", "authors": ["Machi Shimmei", "Masaki Uto", "Yuichiroh Matsubayashi", "Kentaro Inui", "Aditi Mallavarapu", "Noboru Matsuda"], "title": "Tell Me Who Your Students Are: GPT Can Generate Valid Multiple-Choice Questions When Students' (Mis)Understanding Is Hinted", "categories": ["cs.CL"], "comment": "This is a pre-print version of a paper to appear in AIED2025", "summary": "The primary goal of this study is to develop and evaluate an innovative\nprompting technique, AnaQuest, for generating multiple-choice questions (MCQs)\nusing a pre-trained large language model. In AnaQuest, the choice items are\nsentence-level assertions about complex concepts. The technique integrates\nformative and summative assessments. In the formative phase, students answer\nopen-ended questions for target concepts in free text. For summative\nassessment, AnaQuest analyzes these responses to generate both correct and\nincorrect assertions. To evaluate the validity of the generated MCQs, Item\nResponse Theory (IRT) was applied to compare item characteristics between MCQs\ngenerated by AnaQuest, a baseline ChatGPT prompt, and human-crafted items. An\nempirical study found that expert instructors rated MCQs generated by both AI\nmodels to be as valid as those created by human instructors. However, IRT-based\nanalysis revealed that AnaQuest-generated questions - particularly those with\nincorrect assertions (foils) - more closely resembled human-crafted items in\nterms of difficulty and discrimination than those produced by ChatGPT.", "AI": {"tldr": "AnaQuest is a prompting technique for generating MCQs using a pre-trained language model, integrating formative and summative assessments. It outperforms ChatGPT in resembling human-crafted questions.", "motivation": "To develop a method for generating high-quality MCQs that mimic human-crafted items, improving automated assessment tools.", "method": "AnaQuest generates MCQs from student responses, using formative (open-ended) and summative (MCQ) phases, and evaluates validity via IRT.", "result": "AnaQuest-generated MCQs were rated as valid as human-crafted ones and outperformed ChatGPT in difficulty and discrimination metrics.", "conclusion": "AnaQuest is effective for MCQ generation, closely matching human quality, and superior to baseline AI methods."}}
{"id": "2502.14439", "pdf": "https://arxiv.org/pdf/2502.14439", "abs": "https://arxiv.org/abs/2502.14439", "authors": ["Harin Lee", "Eline Van Geert", "Elif Celen", "Raja Marjieh", "Pol van Rijn", "Minsu Park", "Nori Jacoby"], "title": "Visual and Auditory Aesthetic Preferences Across Cultures", "categories": ["cs.MM"], "comment": "To be presented at CogSci 2025", "summary": "Research on how humans perceive aesthetics in shapes, colours, and music has\npredominantly focused on Western populations, limiting our understanding of how\ncultural environments shape aesthetic preferences. We present a large-scale\ncross-cultural study examining aesthetic preferences across five distinct\nmodalities extensively explored in the literature: shape, curvature, colour,\nmusical harmony and melody. We gather 401,403 preference judgements from 4,835\nparticipants across 10 countries, systematically sampling two-dimensional\nparameter spaces for each modality. The findings reveal both universal patterns\nand cultural variations. Preferences for shape and curvature cross-culturally\ndemonstrate a consistent preference for symmetrical forms. While colour\npreferences are categorically consistent, ratio-like preferences vary across\ncultures. Musical harmony shows strong agreement in interval relationships\ndespite differing regions of preference within the broad frequency spectrum,\nwhile melody shows the highest cross-cultural variation. These results suggest\nthat aesthetic preferences emerge from an interplay between shared perceptual\nmechanisms and cultural learning.", "AI": {"tldr": "A large-scale cross-cultural study reveals universal and culturally varied aesthetic preferences in shape, color, and music, influenced by both perceptual mechanisms and cultural learning.", "motivation": "To understand how cultural environments shape aesthetic preferences, given prior research's focus on Western populations.", "method": "Gathered 401,403 preference judgements from 4,835 participants across 10 countries, systematically sampling parameter spaces for shape, curvature, color, musical harmony, and melody.", "result": "Universal patterns (e.g., symmetry in shapes) and cultural variations (e.g., melody preferences) were found, with color and harmony showing categorical consistency but ratio-like differences.", "conclusion": "Aesthetic preferences arise from an interplay of shared perceptual mechanisms and cultural learning."}}
{"id": "2505.05684", "pdf": "https://arxiv.org/pdf/2505.05684", "abs": "https://arxiv.org/abs/2505.05684", "authors": ["Han Wu", "Jie Yin"], "title": "Prompted Meta-Learning for Few-shot Knowledge Graph Completion", "categories": ["cs.AI", "cs.CL", "cs.LG"], "comment": null, "summary": "Few-shot knowledge graph completion (KGC) has obtained significant attention\ndue to its practical applications in real-world scenarios, where new knowledge\noften emerges with limited available data. While most existing methods for\nfew-shot KGC have predominantly focused on leveraging relational information,\nrich semantics inherent in KGs have been largely overlooked. To address this\ngap, we propose a novel prompted meta-learning (PromptMeta) framework that\nseamlessly integrates meta-semantics with relational information for few-shot\nKGC. PrompMeta has two key innovations: (1) a meta-semantic prompt pool that\ncaptures and consolidates high-level meta-semantics, enabling effective\nknowledge transfer and adaptation to rare and newly emerging relations. (2) a\nlearnable fusion prompt that dynamically combines meta-semantic information\nwith task-specific relational information tailored to different few-shot tasks.\nBoth components are optimized together with model parameters within a\nmeta-learning framework. Extensive experiments on two benchmark datasets\ndemonstrate the effectiveness of our approach.", "AI": {"tldr": "A novel PromptMeta framework integrates meta-semantics with relational information for few-shot knowledge graph completion, outperforming existing methods.", "motivation": "Existing few-shot KGC methods overlook rich semantics in KGs, limiting their effectiveness.", "method": "Proposes PromptMeta with a meta-semantic prompt pool and a learnable fusion prompt, optimized via meta-learning.", "result": "Outperforms benchmarks on two datasets, demonstrating effectiveness.", "conclusion": "PromptMeta successfully leverages meta-semantics for improved few-shot KGC."}}
{"id": "2505.05495", "pdf": "https://arxiv.org/pdf/2505.05495", "abs": "https://arxiv.org/abs/2505.05495", "authors": ["Siyuan Zhou", "Yilun Du", "Yuncong Yang", "Lei Han", "Peihao Chen", "Dit-Yan Yeung", "Chuang Gan"], "title": "Learning 3D Persistent Embodied World Models", "categories": ["cs.CV", "cs.RO"], "comment": null, "summary": "The ability to simulate the effects of future actions on the world is a\ncrucial ability of intelligent embodied agents, enabling agents to anticipate\nthe effects of their actions and make plans accordingly. While a large body of\nexisting work has explored how to construct such world models using video\nmodels, they are often myopic in nature, without any memory of a scene not\ncaptured by currently observed images, preventing agents from making consistent\nlong-horizon plans in complex environments where many parts of the scene are\npartially observed. We introduce a new persistent embodied world model with an\nexplicit memory of previously generated content, enabling much more consistent\nlong-horizon simulation. During generation time, our video diffusion model\npredicts RGB-D video of the future observations of the agent. This generation\nis then aggregated into a persistent 3D map of the environment. By conditioning\nthe video model on this 3D spatial map, we illustrate how this enables video\nworld models to faithfully simulate both seen and unseen parts of the world.\nFinally, we illustrate the efficacy of such a world model in downstream\nembodied applications, enabling effective planning and policy learning.", "AI": {"tldr": "A persistent embodied world model with memory improves long-horizon simulation for intelligent agents by aggregating predicted RGB-D video into a 3D map.", "motivation": "Existing video-based world models lack memory, hindering consistent long-horizon planning in partially observed environments.", "method": "Introduces a video diffusion model predicting RGB-D future observations, aggregated into a persistent 3D map for conditioning.", "result": "Enables faithful simulation of seen and unseen world parts, improving planning and policy learning.", "conclusion": "The persistent world model enhances long-horizon simulation and downstream embodied applications."}}
{"id": "2505.05533", "pdf": "https://arxiv.org/pdf/2505.05533", "abs": "https://arxiv.org/abs/2505.05533", "authors": ["Zhiyuan Ning", "Pengfei Wang", "Ziyue Qiao", "Pengyang Wang", "Yuanchun Zhou"], "title": "Rethinking Graph Contrastive Learning through Relative Similarity Preservation", "categories": ["cs.LG", "cs.AI"], "comment": "Accepted by IJCAI2025; full version including appendix", "summary": "Graph contrastive learning (GCL) has achieved remarkable success by following\nthe computer vision paradigm of preserving absolute similarity between\naugmented views. However, this approach faces fundamental challenges in graphs\ndue to their discrete, non-Euclidean nature -- view generation often breaks\nsemantic validity and similarity verification becomes unreliable. Through\nanalyzing 11 real-world graphs, we discover a universal pattern transcending\nthe homophily-heterophily dichotomy: label consistency systematically\ndiminishes as structural distance increases, manifesting as smooth decay in\nhomophily graphs and oscillatory decay in heterophily graphs. We establish\ntheoretical guarantees for this pattern through random walk theory, proving\nlabel distribution convergence and characterizing the mechanisms behind\ndifferent decay behaviors. This discovery reveals that graphs naturally encode\nrelative similarity patterns, where structurally closer nodes exhibit\ncollectively stronger semantic relationships. Leveraging this insight, we\npropose RELGCL, a novel GCL framework with complementary pairwise and listwise\nimplementations that preserve these inherent patterns through collective\nsimilarity objectives. Extensive experiments demonstrate that our method\nconsistently outperforms 20 existing approaches across both homophily and\nheterophily graphs, validating the effectiveness of leveraging natural relative\nsimilarity over artificial absolute similarity.", "AI": {"tldr": "The paper introduces RELGCL, a graph contrastive learning framework that leverages natural relative similarity patterns in graphs, outperforming existing methods by focusing on collective similarity objectives.", "motivation": "Traditional graph contrastive learning (GCL) struggles with semantic validity and unreliable similarity verification due to the discrete, non-Euclidean nature of graphs. The study aims to address these challenges by uncovering and utilizing inherent relative similarity patterns.", "method": "The authors analyze 11 real-world graphs, identifying a universal pattern of label consistency decay with structural distance. They propose RELGCL, a framework with pairwise and listwise implementations, designed to preserve these patterns through collective similarity objectives.", "result": "Extensive experiments show RELGCL consistently outperforms 20 existing methods across homophily and heterophily graphs, validating its effectiveness.", "conclusion": "The study demonstrates that leveraging natural relative similarity patterns in graphs is more effective than relying on artificial absolute similarity, offering a robust solution for GCL challenges."}}
{"id": "2403.10794", "pdf": "https://arxiv.org/pdf/2403.10794", "abs": "https://arxiv.org/abs/2403.10794", "authors": ["Zixuan Wu", "Sean Ye", "Manisha Natarajan", "Matthew C. Gombolay"], "title": "Diffusion-Reinforcement Learning Hierarchical Motion Planning in Multi-agent Adversarial Games", "categories": ["cs.RO", "cs.LG", "cs.MA"], "comment": "This work has been submitted to the IEEE Robotics and Automation\n  Letters (RA-L) for possible publication", "summary": "Reinforcement Learning (RL)-based motion planning has recently shown the\npotential to outperform traditional approaches from autonomous navigation to\nrobot manipulation. In this work, we focus on a motion planning task for an\nevasive target in a partially observable multi-agent adversarial\npursuit-evasion game (PEG). Pursuit-evasion problems are relevant to various\napplications, such as search and rescue operations and surveillance robots,\nwhere robots must effectively plan their actions to gather intelligence or\naccomplish mission tasks while avoiding detection or capture. We propose a\nhierarchical architecture that integrates a high-level diffusion model to plan\nglobal paths responsive to environment data, while a low-level RL policy\nreasons about evasive versus global path-following behavior. The benchmark\nresults across different domains and different observability show that our\napproach outperforms baselines by 77.18% and 47.38% on detection and goal\nreaching rate, which leads to 51.4% increasing of the performance score on\naverage. Additionally, our method improves interpretability, flexibility and\nefficiency of the learned policy.", "AI": {"tldr": "A hierarchical RL-based motion planning method for pursuit-evasion games outperforms baselines by 77.18% and 47.38% in detection and goal-reaching rates, improving performance by 51.4% on average.", "motivation": "Addresses the need for efficient motion planning in partially observable multi-agent adversarial scenarios, relevant to applications like search and rescue or surveillance.", "method": "Combines a high-level diffusion model for global path planning with a low-level RL policy for evasive or path-following behavior.", "result": "Outperforms baselines significantly in detection and goal-reaching rates, with a 51.4% average performance improvement.", "conclusion": "The proposed method enhances interpretability, flexibility, and efficiency in motion planning for adversarial environments."}}
{"id": "2505.05643", "pdf": "https://arxiv.org/pdf/2505.05643", "abs": "https://arxiv.org/abs/2505.05643", "authors": ["Mark C. Eid", "Ana I. L. Namburete", "Jo\u00e3o F. Henriques"], "title": "UltraGauss: Ultrafast Gaussian Reconstruction of 3D Ultrasound Volumes", "categories": ["eess.IV", "cs.CV", "physics.med-ph"], "comment": null, "summary": "Ultrasound imaging is widely used due to its safety, affordability, and\nreal-time capabilities, but its 2D interpretation is highly operator-dependent,\nleading to variability and increased cognitive demand. 2D-to-3D reconstruction\nmitigates these challenges by providing standardized volumetric views, yet\nexisting methods are often computationally expensive, memory-intensive, or\nincompatible with ultrasound physics. We introduce UltraGauss: the first\nultrasound-specific Gaussian Splatting framework, extending view synthesis\ntechniques to ultrasound wave propagation. Unlike conventional\nperspective-based splatting, UltraGauss models probe-plane intersections in 3D,\naligning with acoustic image formation. We derive an efficient rasterization\nboundary formulation for GPU parallelization and introduce a numerically stable\ncovariance parametrization, improving computational efficiency and\nreconstruction accuracy. On real clinical ultrasound data, UltraGauss achieves\nstate-of-the-art reconstructions in 5 minutes, and reaching 0.99 SSIM within 20\nminutes on a single GPU. A survey of expert clinicians confirms UltraGauss'\nreconstructions are the most realistic among competing methods. Our CUDA\nimplementation will be released upon publication.", "AI": {"tldr": "UltraGauss introduces a Gaussian Splatting framework for 2D-to-3D ultrasound reconstruction, improving efficiency and accuracy while aligning with ultrasound physics.", "motivation": "Addressing the operator-dependent variability and cognitive demand of 2D ultrasound imaging, as well as the computational and physical limitations of existing 3D reconstruction methods.", "method": "Extends Gaussian Splatting to ultrasound wave propagation, modeling probe-plane intersections in 3D and introducing efficient GPU-parallelizable rasterization and stable covariance parametrization.", "result": "Achieves state-of-the-art reconstructions in 5 minutes (0.99 SSIM in 20 minutes) on a single GPU, validated by expert clinicians as the most realistic.", "conclusion": "UltraGauss offers a computationally efficient, accurate, and clinically validated solution for 3D ultrasound reconstruction."}}
{"id": "2505.05864", "pdf": "https://arxiv.org/pdf/2505.05864", "abs": "https://arxiv.org/abs/2505.05864", "authors": ["Junhyeong Lee", "Jong Min Yuk", "Chan-Woo Lee"], "title": "Symbol-based entity marker highlighting for enhanced text mining in materials science with generative AI", "categories": ["cs.CL"], "comment": "29 pages", "summary": "The construction of experimental datasets is essential for expanding the\nscope of data-driven scientific discovery. Recent advances in natural language\nprocessing (NLP) have facilitated automatic extraction of structured data from\nunstructured scientific literature. While existing approaches-multi-step and\ndirect methods-offer valuable capabilities, they also come with limitations\nwhen applied independently. Here, we propose a novel hybrid text-mining\nframework that integrates the advantages of both methods to convert\nunstructured scientific text into structured data. Our approach first\ntransforms raw text into entity-recognized text, and subsequently into\nstructured form. Furthermore, beyond the overall data structuring framework, we\nalso enhance entity recognition performance by introducing an entity marker-a\nsimple yet effective technique that uses symbolic annotations to highlight\ntarget entities. Specifically, our entity marker-based hybrid approach not only\nconsistently outperforms previous entity recognition approaches across three\nbenchmark datasets (MatScholar, SOFC, and SOFC slot NER) but also improve the\nquality of final structured data-yielding up to a 58% improvement in\nentity-level F1 score and up to 83% improvement in relation-level F1 score\ncompared to direct approach.", "AI": {"tldr": "A hybrid text-mining framework combines multi-step and direct methods to convert unstructured scientific text into structured data, improving entity and relation recognition performance.", "motivation": "To address limitations of existing methods (multi-step and direct) in extracting structured data from scientific literature, aiming for better performance and data quality.", "method": "Proposes a hybrid framework: transforms raw text into entity-recognized text, then into structured form, enhanced by an entity marker technique for better entity recognition.", "result": "Outperforms previous methods on benchmark datasets (MatScholar, SOFC, SOFC slot NER) with up to 58% improvement in entity-level F1 and 83% in relation-level F1.", "conclusion": "The hybrid framework effectively integrates advantages of existing methods, significantly improving structured data extraction from scientific text."}}
{"id": "2501.02704", "pdf": "https://arxiv.org/pdf/2501.02704", "abs": "https://arxiv.org/abs/2501.02704", "authors": ["Anh Tu Ngo", "Chuan Song Heng", "Nandish Chattopadhyay", "Anupam Chattopadhyay"], "title": "Persistence of Backdoor-based Watermarks for Neural Networks: A Comprehensive Evaluation", "categories": ["cs.LG", "cs.CR", "cs.MM"], "comment": "Accepted by IEEE Transactions on Neural Networks and Learning Systems\n  (TNNLS)", "summary": "Deep Neural Networks (DNNs) have gained considerable traction in recent years\ndue to the unparalleled results they gathered. However, the cost behind\ntraining such sophisticated models is resource intensive, resulting in many to\nconsider DNNs to be intellectual property (IP) to model owners. In this era of\ncloud computing, high-performance DNNs are often deployed all over the internet\nso that people can access them publicly. As such, DNN watermarking schemes,\nespecially backdoor-based watermarks, have been actively developed in recent\nyears to preserve proprietary rights. Nonetheless, there lies much uncertainty\non the robustness of existing backdoor watermark schemes, towards both\nadversarial attacks and unintended means such as fine-tuning neural network\nmodels. One reason for this is that no complete guarantee of robustness can be\nassured in the context of backdoor-based watermark. In this paper, we\nextensively evaluate the persistence of recent backdoor-based watermarks within\nneural networks in the scenario of fine-tuning, we propose/develop a novel\ndata-driven idea to restore watermark after fine-tuning without exposing the\ntrigger set. Our empirical results show that by solely introducing training\ndata after fine-tuning, the watermark can be restored if model parameters do\nnot shift dramatically during fine-tuning. Depending on the types of trigger\nsamples used, trigger accuracy can be reinstated to up to 100%. Our study\nfurther explores how the restoration process works using loss landscape\nvisualization, as well as the idea of introducing training data in fine-tuning\nstage to alleviate watermark vanishing.", "AI": {"tldr": "The paper evaluates the robustness of backdoor-based watermarks in DNNs during fine-tuning and proposes a data-driven method to restore watermarks without exposing trigger sets.", "motivation": "DNNs are valuable IP, and watermarking schemes are used to protect them. However, existing backdoor watermarks lack robustness against fine-tuning, prompting this study.", "method": "The authors evaluate backdoor watermark persistence during fine-tuning and develop a novel data-driven approach to restore watermarks without trigger set exposure.", "result": "Empirical results show watermarks can be restored if model parameters don't shift drastically, with trigger accuracy reaching up to 100%.", "conclusion": "The study demonstrates effective watermark restoration and explores the process via loss landscape visualization, suggesting training data introduction during fine-tuning to prevent watermark loss."}}
{"id": "2505.05701", "pdf": "https://arxiv.org/pdf/2505.05701", "abs": "https://arxiv.org/abs/2505.05701", "authors": ["Jongchan Park", "Mingyu Park", "Donghwan Lee"], "title": "Pretraining a Shared Q-Network for Data-Efficient Offline Reinforcement Learning", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "Offline reinforcement learning (RL) aims to learn a policy from a static\ndataset without further interactions with the environment. Collecting\nsufficiently large datasets for offline RL is exhausting since this data\ncollection requires colossus interactions with environments and becomes tricky\nwhen the interaction with the environment is restricted. Hence, how an agent\nlearns the best policy with a minimal static dataset is a crucial issue in\noffline RL, similar to the sample efficiency problem in online RL. In this\npaper, we propose a simple yet effective plug-and-play pretraining method to\ninitialize a feature of a $Q$-network to enhance data efficiency in offline RL.\nSpecifically, we introduce a shared $Q$-network structure that outputs\npredictions of the next state and $Q$-value. We pretrain the shared $Q$-network\nthrough a supervised regression task that predicts a next state and trains the\nshared $Q$-network using diverse offline RL methods. Through extensive\nexperiments, we empirically demonstrate that our method enhances the\nperformance of existing popular offline RL methods on the D4RL, Robomimic and\nV-D4RL benchmarks. Furthermore, we show that our method significantly boosts\ndata-efficient offline RL across various data qualities and data distributions\ntrough D4RL and ExoRL benchmarks. Notably, our method adapted with only 10% of\nthe dataset outperforms standard algorithms even with full datasets.", "AI": {"tldr": "A plug-and-play pretraining method for offline RL improves data efficiency by initializing a shared Q-network with supervised regression tasks, enhancing performance across benchmarks.", "motivation": "Offline RL struggles with limited datasets due to exhaustive data collection requirements. This paper addresses the challenge of learning optimal policies with minimal static data.", "method": "Proposes a shared Q-network structure pretrained via supervised regression to predict next states and Q-values, integrated with diverse offline RL methods.", "result": "Empirically improves performance on D4RL, Robomimic, and V-D4RL benchmarks, even outperforming standard algorithms with only 10% of the dataset.", "conclusion": "The method significantly boosts data-efficient offline RL across varied data qualities and distributions, demonstrating its effectiveness and adaptability."}}
{"id": "2505.05501", "pdf": "https://arxiv.org/pdf/2505.05501", "abs": "https://arxiv.org/abs/2505.05501", "authors": ["Pu Cao", "Feng Zhou", "Junyi Ji", "Qingye Kong", "Zhixiang Lv", "Mingjian Zhang", "Xuekun Zhao", "Siqi Wu", "Yinghui Lin", "Qing Song", "Lu Yang"], "title": "Preliminary Explorations with GPT-4o(mni) Native Image Generation", "categories": ["cs.CV", "cs.AI", "eess.IV"], "comment": null, "summary": "Recently, the visual generation ability by GPT-4o(mni) has been unlocked by\nOpenAI. It demonstrates a very remarkable generation capability with excellent\nmultimodal condition understanding and varied task instructions. In this paper,\nwe aim to explore the capabilities of GPT-4o across various tasks. Inspired by\nprevious study, we constructed a task taxonomy along with a carefully curated\nset of test samples to conduct a comprehensive qualitative test. Benefiting\nfrom GPT-4o's powerful multimodal comprehension, its image-generation process\ndemonstrates abilities surpassing those of traditional image-generation tasks.\nThus, regarding the dimensions of model capabilities, we evaluate its\nperformance across six task categories: traditional image generation tasks,\ndiscriminative tasks, knowledge-based generation, commonsense-based generation,\nspatially-aware image generation, and temporally-aware image generation. These\ntasks not only assess the quality and conditional alignment of the model's\noutputs but also probe deeper into GPT-4o's understanding of real-world\nconcepts. Our results reveal that GPT-4o performs impressively well in\ngeneral-purpose synthesis tasks, showing strong capabilities in text-to-image\ngeneration, visual stylization, and low-level image processing. However,\nsignificant limitations remain in its ability to perform precise spatial\nreasoning, instruction-grounded generation, and consistent temporal prediction.\nFurthermore, when faced with knowledge-intensive or domain-specific scenarios,\nsuch as scientific illustrations or mathematical plots, the model often\nexhibits hallucinations, factual errors, or structural inconsistencies. These\nfindings suggest that while GPT-4o marks a substantial advancement in unified\nmultimodal generation, there is still a long way to go before it can be\nreliably applied to professional or safety-critical domains.", "AI": {"tldr": "GPT-4o demonstrates strong multimodal generation capabilities but has limitations in spatial reasoning, temporal prediction, and domain-specific tasks.", "motivation": "To explore GPT-4o's capabilities across diverse tasks, assessing its multimodal understanding and generation quality.", "method": "Constructed a task taxonomy and curated test samples for qualitative evaluation across six task categories.", "result": "GPT-4o excels in general-purpose tasks like text-to-image generation but struggles with precise spatial reasoning, temporal consistency, and domain-specific accuracy.", "conclusion": "GPT-4o advances unified multimodal generation but isn't yet reliable for professional or safety-critical applications."}}
{"id": "2505.05538", "pdf": "https://arxiv.org/pdf/2505.05538", "abs": "https://arxiv.org/abs/2505.05538", "authors": ["Md Kamrujjaman Mobin", "Md Saiful Islam", "Sadik Al Barid", "Md Masum"], "title": "Cardioformer: Advancing AI in ECG Analysis with Multi-Granularity Patching and ResNet", "categories": ["cs.LG", "cs.AI", "eess.SP"], "comment": null, "summary": "Electrocardiogram (ECG) classification is crucial for automated cardiac\ndisease diagnosis, yet existing methods often struggle to capture local\nmorphological details and long-range temporal dependencies simultaneously. To\naddress these challenges, we propose Cardioformer, a novel multi-granularity\nhybrid model that integrates cross-channel patching, hierarchical residual\nlearning, and a two-stage self-attention mechanism. Cardioformer first encodes\nmulti-scale token embeddings to capture fine-grained local features and global\ncontextual information and then selectively fuses these representations through\nintra- and inter-granularity self-attention. Extensive evaluations on three\nbenchmark ECG datasets under subject-independent settings demonstrate that\nmodel consistently outperforms four state-of-the-art baselines. Our\nCardioformer model achieves the AUROC of 96.34$\\pm$0.11, 89.99$\\pm$0.12, and\n95.59$\\pm$1.66 in MIMIC-IV, PTB-XL and PTB dataset respectively outperforming\nPatchTST, Reformer, Transformer, and Medformer models. It also demonstrates\nstrong cross-dataset generalization, achieving 49.18% AUROC on PTB and 68.41%\non PTB-XL when trained on MIMIC-IV. These findings underscore the potential of\nCardioformer to advance automated ECG analysis, paving the way for more\naccurate and robust cardiovascular disease diagnosis. We release the source\ncode at https://github.com/KMobin555/Cardioformer.", "AI": {"tldr": "Cardioformer, a hybrid ECG classification model, combines cross-channel patching, hierarchical residual learning, and self-attention to outperform state-of-the-art methods on benchmark datasets.", "motivation": "Existing ECG classification methods fail to simultaneously capture local morphological details and long-range temporal dependencies, limiting diagnostic accuracy.", "method": "Cardioformer uses multi-scale token embeddings and a two-stage self-attention mechanism to integrate local and global ECG features.", "result": "Achieves AUROC scores of 96.34 (MIMIC-IV), 89.99 (PTB-XL), and 95.59 (PTB), outperforming PatchTST, Reformer, Transformer, and Medformer.", "conclusion": "Cardioformer advances automated ECG analysis, offering more accurate and robust cardiovascular disease diagnosis."}}
{"id": "2405.21027", "pdf": "https://arxiv.org/pdf/2405.21027", "abs": "https://arxiv.org/abs/2405.21027", "authors": ["Jiesong Lian", "Yucong Huang", "Chengdong Ma", "Mingzhi Wang", "Ying Wen", "Long Hu", "Yixue Hao"], "title": "Fusion-PSRO: Nash Policy Fusion for Policy Space Response Oracles", "categories": ["cs.GT", "cs.AI", "cs.LG", "cs.MA"], "comment": "11 pages, 11 figures", "summary": "For solving zero-sum games involving non-transitivity, a useful approach is\nto maintain a policy population to approximate the Nash Equilibrium (NE).\nPrevious studies have shown that the Policy Space Response Oracles (PSRO)\nalgorithm is an effective framework for solving such games. However, current\nmethods initialize a new policy from scratch or inherit a single historical\npolicy in Best Response (BR), missing the opportunity to leverage past policies\nto generate a better BR. In this paper, we propose Fusion-PSRO, which employs\nNash Policy Fusion to initialize a new policy for BR training. Nash Policy\nFusion serves as an implicit guiding policy that starts exploration on the\ncurrent Meta-NE, thus providing a closer approximation to BR. Moreover, it\ninsightfully captures a weighted moving average of past policies, dynamically\nadjusting these weights based on the Meta-NE in each iteration. This cumulative\nprocess further enhances the policy population. Empirical results on classic\nbenchmarks show that Fusion-PSRO achieves lower exploitability, thereby\nmitigating the shortcomings of previous research on policy initialization in\nBR.", "AI": {"tldr": "Fusion-PSRO improves PSRO by using Nash Policy Fusion for better policy initialization in Best Response, reducing exploitability.", "motivation": "Current PSRO methods inefficiently initialize policies for Best Response, missing opportunities to leverage past policies.", "method": "Proposes Fusion-PSRO with Nash Policy Fusion, dynamically adjusting weights of past policies based on Meta-NE.", "result": "Achieves lower exploitability on benchmarks compared to prior methods.", "conclusion": "Fusion-PSRO enhances policy population and mitigates initialization shortcomings in BR."}}
{"id": "2505.05659", "pdf": "https://arxiv.org/pdf/2505.05659", "abs": "https://arxiv.org/abs/2505.05659", "authors": ["Guilherme Vieira Neto", "Marcos Eduardo Valle"], "title": "V-EfficientNets: Vector-Valued Efficiently Scaled Convolutional Neural Network Models", "categories": ["eess.IV", "cs.CV", "cs.LG"], "comment": "Accepted at International Joint Conference on Neural Networks (IJCNN\n  2025)", "summary": "EfficientNet models are convolutional neural networks optimized for parameter\nallocation by jointly balancing network width, depth, and resolution. Renowned\nfor their exceptional accuracy, these models have become a standard for image\nclassification tasks across diverse computer vision benchmarks. While\ntraditional neural networks learn correlations between feature channels during\ntraining, vector-valued neural networks inherently treat multidimensional data\nas coherent entities, taking for granted the inter-channel relationships. This\npaper introduces vector-valued EfficientNets (V-EfficientNets), a novel\nextension of EfficientNet designed to process arbitrary vector-valued data. The\nproposed models are evaluated on a medical image classification task, achieving\nan average accuracy of 99.46% on the ALL-IDB2 dataset for detecting acute\nlymphoblastic leukemia. V-EfficientNets demonstrate remarkable efficiency,\nsignificantly reducing parameters while outperforming state-of-the-art models,\nincluding the original EfficientNet. The source code is available at\nhttps://github.com/mevalle/v-nets.", "AI": {"tldr": "V-EfficientNets extend EfficientNet to handle vector-valued data, achieving 99.46% accuracy on a medical image task with fewer parameters.", "motivation": "Traditional networks treat multidimensional data as separate channels, ignoring inter-channel relationships. V-EfficientNets address this by processing vector-valued data coherently.", "method": "Extends EfficientNet by optimizing for vector-valued data, balancing width, depth, and resolution. Evaluated on the ALL-IDB2 medical dataset.", "result": "Achieves 99.46% accuracy on ALL-IDB2, outperforming state-of-the-art models with fewer parameters.", "conclusion": "V-EfficientNets are efficient and effective for vector-valued data, particularly in medical image classification."}}
{"id": "2505.05946", "pdf": "https://arxiv.org/pdf/2505.05946", "abs": "https://arxiv.org/abs/2505.05946", "authors": ["Vytenis \u0160liogeris", "Povilas Daniu\u0161is", "Art\u016bras Nakvosas"], "title": "Elastic Weight Consolidation for Full-Parameter Continual Pre-Training of Gemma2", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "8 pages, 4 figures", "summary": "This technical report describes an experiment on autoregressive pre-training\nof Gemma2 2 billion parameter large language model (LLM) with 10\\% on the\nLithuanian language component of CulturaX from the point of view of continual\nlearning. We apply elastic weight consolidation (EWC) to the full set of the\nmodel's parameters and investigate language understanding benchmarks,\nconsisting of Arc, Belebele, Gsm8K, Hellaswag, MMLU, TruthfulQA, and Winogrande\nsets (both in English and Lithuanian versions), and perplexity benchmarks. We\nempirically demonstrate that EWC regularisation allows us not only to mitigate\ncatastrophic forgetting effects but also that it is potentially beneficial for\nlearning of the new task with LLMs.", "AI": {"tldr": "The paper explores using Elastic Weight Consolidation (EWC) in autoregressive pre-training of a 2B-parameter LLM (Gemma2) with Lithuanian language data, showing EWC helps mitigate forgetting and may improve new task learning.", "motivation": "To investigate how EWC can address catastrophic forgetting in continual learning for LLMs, particularly with a focus on Lithuanian language data.", "method": "Applied EWC to all parameters of Gemma2 during pre-training, evaluated on language understanding and perplexity benchmarks in English and Lithuanian.", "result": "EWC not only reduced catastrophic forgetting but also potentially enhanced learning of new tasks.", "conclusion": "EWC is effective for continual learning in LLMs, offering benefits beyond just mitigating forgetting."}}
{"id": "2505.02539", "pdf": "https://arxiv.org/pdf/2505.02539", "abs": "https://arxiv.org/abs/2505.02539", "authors": ["Nahuel Garcia-D'Urso", "Bernabe Sanchez-Sos", "Jorge Azorin-Lopez", "Andres Fuster-Guillo", "Antonio Macia-Lillo", "Higinio Mora-Mora"], "title": "Marker-Based Extrinsic Calibration Method for Accurate Multi-Camera 3D Reconstruction", "categories": ["cs.CV", "cs.MM"], "comment": null, "summary": "Accurate 3D reconstruction using multi-camera RGB-D systems critically\ndepends on precise extrinsic calibration to achieve proper alignment between\ncaptured views. In this paper, we introduce an iterative extrinsic calibration\nmethod that leverages the geometric constraints provided by a three-dimensional\nmarker to significantly improve calibration accuracy. Our proposed approach\nsystematically segments and refines marker planes through clustering,\nregression analysis, and iterative reassignment techniques, ensuring robust\ngeometric correspondence across camera views. We validate our method\ncomprehensively in both controlled environments and practical real-world\nsettings within the Tech4Diet project, aimed at modeling the physical\nprogression of patients undergoing nutritional treatments. Experimental results\ndemonstrate substantial reductions in alignment errors, facilitating accurate\nand reliable 3D reconstructions.", "AI": {"tldr": "An iterative extrinsic calibration method for multi-camera RGB-D systems improves accuracy using 3D marker constraints, validated in controlled and real-world settings.", "motivation": "Precise extrinsic calibration is crucial for accurate 3D reconstruction in multi-camera RGB-D systems.", "method": "The approach segments and refines marker planes via clustering, regression, and iterative reassignment for robust geometric correspondence.", "result": "Significant reduction in alignment errors, enabling reliable 3D reconstructions.", "conclusion": "The method enhances calibration accuracy, validated in practical applications like the Tech4Diet project."}}
{"id": "2505.05758", "pdf": "https://arxiv.org/pdf/2505.05758", "abs": "https://arxiv.org/abs/2505.05758", "authors": ["Azim Ospanov", "Roozbeh Yousefzadeh"], "title": "APOLLO: Automated LLM and Lean Collaboration for Advanced Formal Reasoning", "categories": ["cs.AI", "cs.LO"], "comment": null, "summary": "Formal reasoning and automated theorem proving constitute a challenging\nsubfield of machine learning, in which machines are tasked with proving\nmathematical theorems using formal languages like Lean. A formal verification\nsystem can check whether a formal proof is correct or not almost\ninstantaneously, but generating a completely correct formal proof with large\nlanguage models (LLMs) remains a formidable task. The usual approach in the\nliterature is to prompt the LLM many times (up to several thousands) until one\nof the generated proofs passes the verification system. In this work, we\npresent APOLLO (Automated PrOof repair via LLM and Lean cOllaboration), a\nmodular, model-agnostic pipeline that combines the strengths of the Lean\ncompiler with an LLM's reasoning abilities to achieve better proof-generation\nresults at a low sampling budget. Apollo directs a fully automated process in\nwhich the LLM generates proofs for theorems, a set of agents analyze the\nproofs, fix the syntax errors, identify the mistakes in the proofs using Lean,\nisolate failing sub-lemmas, utilize automated solvers, and invoke an LLM on\neach remaining goal with a low top-K budget. The repaired sub-proofs are\nrecombined and reverified, iterating up to a user-controlled maximum number of\nattempts. On the miniF2F benchmark, we establish a new state-of-the-art\naccuracy of 75.0% among 7B-parameter models while keeping the sampling budget\nbelow one thousand. Moreover, Apollo raises the state-of-the-art accuracy for\nGoedel-Prover-SFT to 65.6% while cutting sample complexity from 25,600 to a few\nhundred. General-purpose models (o3-mini, o4-mini) jump from 3-7% to over 40%\naccuracy. Our results demonstrate that targeted, compiler-guided repair of LLM\noutputs yields dramatic gains in both efficiency and correctness, suggesting a\ngeneral paradigm for scalable automated theorem proving.", "AI": {"tldr": "APOLLO is a pipeline combining Lean and LLMs to improve automated theorem proving, achieving state-of-the-art accuracy with low sampling budgets.", "motivation": "Generating correct formal proofs with LLMs is challenging due to high sampling requirements. APOLLO aims to enhance efficiency and correctness by leveraging Lean and targeted repair.", "method": "APOLLO automates proof generation, error analysis, syntax fixing, sub-lemma isolation, solver use, and iterative LLM invocation with low top-K budgets.", "result": "Achieves 75.0% accuracy on miniF2F (7B models) and 65.6% for Goedel-Prover-SFT, reducing sample complexity from 25,600 to hundreds. General models improve from 3-7% to over 40%.", "conclusion": "Compiler-guided repair of LLM outputs significantly boosts efficiency and correctness, offering a scalable paradigm for automated theorem proving."}}
{"id": "2505.05505", "pdf": "https://arxiv.org/pdf/2505.05505", "abs": "https://arxiv.org/abs/2505.05505", "authors": ["Yiming Qin", "Zhu Xu", "Yang Liu"], "title": "Apply Hierarchical-Chain-of-Generation to Complex Attributes Text-to-3D Generation", "categories": ["cs.CV", "eess.IV"], "comment": "Project page here:\n  https://hierarchical-chain-of-generation.github.io/", "summary": "Recent text-to-3D models can render high-quality assets, yet they still\nstumble on objects with complex attributes. The key obstacles are: (1) existing\ntext-to-3D approaches typically lift text-to-image models to extract semantics\nvia text encoders, while the text encoder exhibits limited comprehension\nability for long descriptions, leading to deviated cross-attention focus,\nsubsequently wrong attribute binding in generated results. (2) Occluded object\nparts demand a disciplined generation order and explicit part disentanglement.\nThough some works introduce manual efforts to alleviate the above issues, their\nquality is unstable and highly reliant on manual information. To tackle above\nproblems, we propose a automated method Hierarchical-Chain-of-Generation\n(HCoG). It leverages a large language model to decompose the long description\ninto blocks representing different object parts, and orders them from inside\nout according to occlusions, forming a hierarchical chain. Within each block we\nfirst coarsely create components, then precisely bind attributes via\ntarget-region localization and corresponding 3D Gaussian kernel optimization.\nBetween blocks, we introduce Gaussian Extension and Label Elimination to\nseamlessly generate new parts by extending new Gaussian kernels, re-assigning\nsemantic labels, and eliminating unnecessary kernels, ensuring that only\nrelevant parts are added without disrupting previously optimized parts.\nExperiments confirm that HCoG yields structurally coherent, attribute-faithful\n3D objects with complex attributes. The code is available at\nhttps://github.com/Wakals/GASCOL .", "AI": {"tldr": "HCoG automates text-to-3D generation by decomposing long descriptions into hierarchical parts, optimizing attribute binding and occlusion handling for coherent results.", "motivation": "Existing text-to-3D models struggle with complex attributes due to limited text encoder comprehension and occlusion challenges.", "method": "HCoG uses a large language model to decompose descriptions, orders parts hierarchically, and optimizes attribute binding via Gaussian kernels.", "result": "HCoG produces structurally coherent and attribute-faithful 3D objects with complex attributes.", "conclusion": "HCoG effectively addresses text-to-3D challenges, offering automated, high-quality generation for complex objects."}}
{"id": "2505.05568", "pdf": "https://arxiv.org/pdf/2505.05568", "abs": "https://arxiv.org/abs/2505.05568", "authors": ["Yanbo Wang", "Xiyuan Wang", "Quan Gan", "Minjie Wang", "Qibin Yang", "David Wipf", "Muhan Zhang"], "title": "Griffin: Towards a Graph-Centric Relational Database Foundation Model", "categories": ["cs.LG", "cs.AI", "cs.DB"], "comment": null, "summary": "We introduce Griffin, the first foundation model attemptation designed\nspecifically for Relational Databases (RDBs). Unlike previous smaller models\nfocused on single RDB tasks, Griffin unifies the data encoder and task decoder\nto handle diverse tasks. Additionally, we enhance the architecture by\nincorporating a cross-attention module and a novel aggregator. Griffin utilizes\npretraining on both single-table and RDB datasets, employing advanced encoders\nfor categorical, numerical, and metadata features, along with innovative\ncomponents such as cross-attention modules and enhanced message-passing neural\nnetworks (MPNNs) to capture the complexities of relational data. Evaluated on\nlarge-scale, heterogeneous, and temporal graphs extracted from RDBs across\nvarious domains (spanning over 150 million nodes), Griffin demonstrates\nsuperior or comparable performance to individually trained models, excels in\nlow-data scenarios, and shows strong transferability with similarity and\ndiversity in pretraining across new datasets and tasks, highlighting its\npotential as a universally applicable foundation model for RDBs. Code available\nat https://github.com/yanxwb/Griffin.", "AI": {"tldr": "Griffin is the first foundation model for Relational Databases (RDBs), unifying data encoding and task decoding for diverse tasks. It outperforms single-task models, excels in low-data scenarios, and shows strong transferability.", "motivation": "To create a universally applicable foundation model for RDBs, addressing limitations of smaller, single-task models.", "method": "Griffin uses pretraining on single-table and RDB datasets, advanced encoders for various data types, cross-attention modules, and enhanced MPNNs.", "result": "Superior or comparable performance to single-task models, strong in low-data scenarios, and high transferability across datasets and tasks.", "conclusion": "Griffin is a promising foundation model for RDBs, with broad applicability and strong performance."}}
{"id": "2503.05383", "pdf": "https://arxiv.org/pdf/2503.05383", "abs": "https://arxiv.org/abs/2503.05383", "authors": ["Weiyu Ma", "Yuqian Fu", "Zecheng Zhang", "Bernard Ghanem", "Guohao Li"], "title": "AVA: Attentive VLM Agent for Mastering StarCraft II", "categories": ["cs.AI", "cs.MA"], "comment": "Under Review", "summary": "We introduce Attentive VLM Agent (AVA), a multimodal StarCraft II agent that\naligns artificial agent perception with the human gameplay experience.\nTraditional frameworks such as SMAC rely on abstract state representations that\ndiverge significantly from human perception, limiting the ecological validity\nof agent behavior. Our agent addresses this limitation by incorporating RGB\nvisual inputs and natural language observations that more closely simulate\nhuman cognitive processes during gameplay. The AVA architecture consists of\nthree integrated components: (1) a vision-language model enhanced with\nspecialized self-attention mechanisms for strategic unit targeting and\nbattlefield assessment, (2) a retrieval-augmented generation system that\nleverages domain-specific StarCraft II knowledge to inform tactical decisions,\nand (3) a dynamic role-based task distribution system that enables coordinated\nmulti-agent behavior. The experimental evaluation in our proposed AVACraft\nenvironment, which contains 21 multimodal StarCraft II scenarios, demonstrates\nthat AVA powered by foundation models (specifically Qwen-VL and GPT-4o) can\nexecute complex tactical maneuvers without explicit training, achieving\ncomparable performance to traditional MARL methods that require substantial\ntraining iterations. This work establishes a foundation for developing\nhuman-aligned StarCraft II agents and advances the broader research agenda of\nmultimodal game AI. Our implementation is available at\nhttps://github.com/camel-ai/VLM-Play-StarCraft2.", "AI": {"tldr": "AVA is a multimodal StarCraft II agent using RGB and language inputs to align with human perception, outperforming traditional methods without extensive training.", "motivation": "Traditional agents like SMAC use abstract states, diverging from human perception. AVA aims to bridge this gap for more ecologically valid behavior.", "method": "AVA combines a vision-language model with self-attention, retrieval-augmented generation, and dynamic role-based task distribution for coordinated gameplay.", "result": "AVA achieves comparable performance to traditional MARL methods in 21 scenarios without explicit training, using foundation models like Qwen-VL and GPT-4o.", "conclusion": "AVA advances human-aligned game AI and sets a foundation for multimodal agents in StarCraft II and beyond."}}
{"id": "2505.05689", "pdf": "https://arxiv.org/pdf/2505.05689", "abs": "https://arxiv.org/abs/2505.05689", "authors": ["Fuyao Chen", "Yuexi Du", "Tal Zeevi", "Nicha C. Dvornek", "John A. Onofrey"], "title": "Equivariant Imaging Biomarkers for Robust Unsupervised Segmentation of Histopathology", "categories": ["eess.IV", "cs.CV", "cs.LG"], "comment": "Accepted by MIDL 2025", "summary": "Histopathology evaluation of tissue specimens through microscopic examination\nis essential for accurate disease diagnosis and prognosis. However, traditional\nmanual analysis by specially trained pathologists is time-consuming,\nlabor-intensive, cost-inefficient, and prone to inter-rater variability,\npotentially affecting diagnostic consistency and accuracy. As digital pathology\nimages continue to proliferate, there is a pressing need for automated analysis\nto address these challenges. Recent advancements in artificial\nintelligence-based tools such as machine learning (ML) models, have\nsignificantly enhanced the precision and efficiency of analyzing\nhistopathological slides. However, despite their impressive performance, ML\nmodels are invariant only to translation, lacking invariance to rotation and\nreflection. This limitation restricts their ability to generalize effectively,\nparticularly in histopathology, where images intrinsically lack meaningful\norientation. In this study, we develop robust, equivariant histopathological\nbiomarkers through a novel symmetric convolutional kernel via unsupervised\nsegmentation. The approach is validated using prostate tissue micro-array (TMA)\nimages from 50 patients in the Gleason 2019 Challenge public dataset. The\nbiomarkers extracted through this approach demonstrate enhanced robustness and\ngeneralizability against rotation compared to models using standard convolution\nkernels, holding promise for enhancing the accuracy, consistency, and\nrobustness of ML models in digital pathology. Ultimately, this work aims to\nimprove diagnostic and prognostic capabilities of histopathology beyond\nprostate cancer through equivariant imaging.", "AI": {"tldr": "The paper proposes a novel symmetric convolutional kernel for unsupervised segmentation to create robust, equivariant histopathological biomarkers, addressing limitations of traditional ML models in handling rotation and reflection in histopathology images.", "motivation": "Traditional manual histopathology analysis is inefficient and inconsistent, while existing ML models lack invariance to rotation and reflection, limiting their generalizability.", "method": "Developed a symmetric convolutional kernel for unsupervised segmentation to extract equivariant biomarkers, validated on prostate tissue micro-array images from the Gleason 2019 Challenge dataset.", "result": "The biomarkers showed improved robustness and generalizability against rotation compared to standard convolution kernels.", "conclusion": "The approach enhances ML model accuracy and consistency in digital pathology, with potential applications beyond prostate cancer."}}
{"id": "2505.05947", "pdf": "https://arxiv.org/pdf/2505.05947", "abs": "https://arxiv.org/abs/2505.05947", "authors": ["Bianca Steffes", "Nils Torben Wiedemann", "Alexander Gratz", "Pamela Hochreither", "Jana Elina Meyer", "Katharina Luise Schilke"], "title": "Summarisation of German Judgments in conjunction with a Class-based Evaluation", "categories": ["cs.CL"], "comment": null, "summary": "The automated summarisation of long legal documents can be a great aid for\nlegal experts in their daily work. We automatically create summaries (guiding\nprinciples) of German judgments by fine-tuning a decoder-based large language\nmodel. We enrich the judgments with information about legal entities before the\ntraining. For the evaluation of the created summaries, we define a set of\nevaluation classes which allows us to measure their language, pertinence,\ncompleteness and correctness. Our results show that employing legal entities\nhelps the generative model to find the relevant content, but the quality of the\ncreated summaries is not yet sufficient for a use in practice.", "AI": {"tldr": "Fine-tuning a decoder-based LLM for summarizing German legal judgments, enriched with legal entities, shows promise but lacks practical quality.", "motivation": "To aid legal experts by automating summarization of lengthy legal documents.", "method": "Fine-tune a decoder-based large language model, enriching judgments with legal entity information before training.", "result": "Legal entities help identify relevant content, but summary quality is insufficient for practical use.", "conclusion": "Further improvements are needed to make automated legal summarization viable for real-world applications."}}
{"id": "2505.05880", "pdf": "https://arxiv.org/pdf/2505.05880", "abs": "https://arxiv.org/abs/2505.05880", "authors": ["Bettina Fazzinga", "Sergio Flesca", "Filippo Furfaro", "Luigi Pontieri", "Francesco Scala"], "title": "Combining Abstract Argumentation and Machine Learning for Efficiently Analyzing Low-Level Process Event Streams", "categories": ["cs.AI"], "comment": null, "summary": "Monitoring and analyzing process traces is a critical task for modern\ncompanies and organizations. In scenarios where there is a gap between trace\nevents and reference business activities, this entails an interpretation\nproblem, amounting to translating each event of any ongoing trace into the\ncorresponding step of the activity instance. Building on a recent approach that\nframes the interpretation problem as an acceptance problem within an Abstract\nArgumentation Framework (AAF), one can elegantly analyze plausible event\ninterpretations (possibly in an aggregated form), as well as offer explanations\nfor those that conflict with prior process knowledge. Since, in settings where\nevent-to-activity mapping is highly uncertain (or simply under-specified) this\nreasoning-based approach may yield lowly-informative results and heavy\ncomputation, one can think of discovering a sequencetagging model, trained to\nsuggest highly-probable candidate event interpretations in a context-aware way.\nHowever, training such a model optimally may require using a large amount of\nmanually-annotated example traces. Considering the urgent need of developing\nGreen AI solutions enabling environmental and societal sustainability (with\nreduced labor/computational costs and carbon footprint), we propose a\ndata/computation-efficient neuro-symbolic approach to the problem, where the\ncandidate interpretations returned by the example-driven sequence tagger is\nrefined by the AAF-based reasoner. This allows us to also leverage prior\nknowledge to compensate for the scarcity of example data, as confirmed by\nexperimental results; clearly, this property is particularly useful in settings\nwhere data annotation and model optimization costs are subject to stringent\nconstraints.", "AI": {"tldr": "A neuro-symbolic approach combines sequence tagging and argumentation frameworks to efficiently interpret process traces, reducing data and computational costs.", "motivation": "Addressing the gap between trace events and business activities, especially under uncertainty, while promoting Green AI for sustainability.", "method": "Uses a sequence-tagging model for candidate interpretations, refined by an Abstract Argumentation Framework (AAF) to leverage prior knowledge.", "result": "The approach compensates for scarce annotated data and reduces computational costs, validated by experiments.", "conclusion": "The method is effective in resource-constrained settings, balancing data efficiency and computational sustainability."}}
{"id": "2505.05512", "pdf": "https://arxiv.org/pdf/2505.05512", "abs": "https://arxiv.org/abs/2505.05512", "authors": ["Zhang Zhang", "Qiang Zhang", "Wei Cui", "Shuai Shi", "Yijie Guo", "Gang Han", "Wen Zhao", "Jingkai Sun", "Jiahang Cao", "Jiaxu Wang", "Hao Cheng", "Xiaozhu Ju", "Zhengping Che", "Renjing Xu", "Jian Tang"], "title": "Occupancy World Model for Robots", "categories": ["cs.CV", "cs.RO"], "comment": null, "summary": "Understanding and forecasting the scene evolutions deeply affect the\nexploration and decision of embodied agents. While traditional methods simulate\nscene evolutions through trajectory prediction of potential instances, current\nworks use the occupancy world model as a generative framework for describing\nfine-grained overall scene dynamics. However, existing methods cluster on the\noutdoor structured road scenes, while ignoring the exploration of forecasting\n3D occupancy scene evolutions for robots in indoor scenes. In this work, we\nexplore a new framework for learning the scene evolutions of observed\nfine-grained occupancy and propose an occupancy world model based on the\ncombined spatio-temporal receptive field and guided autoregressive transformer\nto forecast the scene evolutions, called RoboOccWorld. We propose the\nConditional Causal State Attention (CCSA), which utilizes camera poses of next\nstate as conditions to guide the autoregressive transformer to adapt and\nunderstand the indoor robotics scenarios. In order to effectively exploit the\nspatio-temporal cues from historical observations, Hybrid Spatio-Temporal\nAggregation (HSTA) is proposed to obtain the combined spatio-temporal receptive\nfield based on multi-scale spatio-temporal windows. In addition, we restructure\nthe OccWorld-ScanNet benchmark based on local annotations to facilitate the\nevaluation of the indoor 3D occupancy scene evolution prediction task.\nExperimental results demonstrate that our RoboOccWorld outperforms\nstate-of-the-art methods in indoor 3D occupancy scene evolution prediction\ntask. The code will be released soon.", "AI": {"tldr": "RoboOccWorld introduces a framework for predicting 3D occupancy scene evolutions in indoor robotics using a novel occupancy world model with Conditional Causal State Attention and Hybrid Spatio-Temporal Aggregation.", "motivation": "Existing methods focus on outdoor scenes, neglecting indoor robotics. This work addresses the gap by forecasting fine-grained 3D occupancy scene evolutions for indoor environments.", "method": "Proposes RoboOccWorld, combining spatio-temporal receptive fields and guided autoregressive transformers. Uses Conditional Causal State Attention (CCSA) and Hybrid Spatio-Temporal Aggregation (HSTA) for scene evolution prediction.", "result": "Outperforms state-of-the-art methods in indoor 3D occupancy scene evolution prediction, validated on the restructured OccWorld-ScanNet benchmark.", "conclusion": "RoboOccWorld effectively predicts indoor scene evolutions, advancing robotics decision-making in dynamic environments."}}
{"id": "2505.05577", "pdf": "https://arxiv.org/pdf/2505.05577", "abs": "https://arxiv.org/abs/2505.05577", "authors": ["Alejandro Velez-Arce", "Marinka Zitnik"], "title": "PyTDC: A multimodal machine learning training, evaluation, and inference platform for biomedical foundation models", "categories": ["cs.LG", "cs.AI", "68-04, 92-04", "D.2.11; I.2.5; J.3"], "comment": "Proceedings of the 42nd International Conference on Machine Learning,\n  Vancouver, Canada. PMLR 267, 2025", "summary": "Existing biomedical benchmarks do not provide end-to-end infrastructure for\ntraining, evaluation, and inference of models that integrate multimodal\nbiological data and a broad range of machine learning tasks in therapeutics. We\npresent PyTDC, an open-source machine-learning platform providing streamlined\ntraining, evaluation, and inference software for multimodal biological AI\nmodels. PyTDC unifies distributed, heterogeneous, continuously updated data\nsources and model weights and standardizes benchmarking and inference\nendpoints. This paper discusses the components of PyTDC's architecture and, to\nour knowledge, the first-of-its-kind case study on the introduced single-cell\ndrug-target nomination ML task. We find state-of-the-art methods in graph\nrepresentation learning and domain-specific methods from graph theory perform\npoorly on this task. Though we find a context-aware geometric deep learning\nmethod that outperforms the evaluated SoTA and domain-specific baseline\nmethods, the model is unable to generalize to unseen cell types or incorporate\nadditional modalities, highlighting PyTDC's capacity to facilitate an exciting\navenue of research developing multimodal, context-aware, foundation models for\nopen problems in biomedical AI.", "AI": {"tldr": "PyTDC is an open-source platform for multimodal biological AI models, unifying data and standardizing benchmarks, with a case study showing limitations of current methods.", "motivation": "Existing benchmarks lack end-to-end infrastructure for multimodal biological data and diverse ML tasks in therapeutics.", "method": "PyTDC integrates distributed data, model weights, and standardizes benchmarking. A case study evaluates single-cell drug-target nomination.", "result": "State-of-the-art methods perform poorly; a context-aware geometric deep learning method outperforms but lacks generalization.", "conclusion": "PyTDC enables research into multimodal, context-aware foundation models for biomedical AI."}}
{"id": "2503.14226", "pdf": "https://arxiv.org/pdf/2503.14226", "abs": "https://arxiv.org/abs/2503.14226", "authors": ["Huaifeng Zhang", "Ahmed Ali-Eldin"], "title": "The Hidden Bloat in Machine Learning Systems", "categories": ["cs.SE", "cs.MA"], "comment": null, "summary": "Software bloat refers to code and features that is not used by a software\nduring runtime. For Machine Learning (ML) systems, bloat is a major contributor\nto their technical debt leading to decreased performance and resource wastage.\nIn this work, we present, Negativa-ML, a novel tool to identify and remove\nbloat in ML frameworks by analyzing their shared libraries. Our approach\nincludes novel techniques to detect and locate unnecessary code within device\ncode - a key area overlooked by existing research, which focuses primarily on\nhost code. We evaluate Negativa-ML using four popular ML frameworks across ten\nworkloads over 300 shared libraries. The results demonstrate that the ML\nframeworks are highly bloated on both the device and host code side. On\naverage, Negativa-ML reduces the device code size in these frameworks by up to\n75% and the host code by up to 72%, resulting in total file size reductions of\nup to 55%. The device code is a primary source of bloat within ML frameworks.\nThrough debloating, we achieve reductions in peak host memory usage, peak GPU\nmemory usage, and execution time by up to 74.6%, 69.6%, and 44.6%,\nrespectively.", "AI": {"tldr": "Negativa-ML identifies and removes bloat in ML frameworks by analyzing shared libraries, reducing code size and improving performance.", "motivation": "Software bloat in ML systems causes technical debt, reducing performance and wasting resources. Existing research overlooks device code bloat.", "method": "Negativa-ML uses novel techniques to detect and remove unnecessary code in both device and host code of ML frameworks.", "result": "The tool reduces device code size by up to 75%, host code by 72%, and improves memory usage and execution time significantly.", "conclusion": "Negativa-ML effectively addresses bloat in ML frameworks, enhancing efficiency and resource utilization."}}
{"id": "2505.05703", "pdf": "https://arxiv.org/pdf/2505.05703", "abs": "https://arxiv.org/abs/2505.05703", "authors": ["Haoyang Pei", "Ding Xia", "Xiang Xu", "William Moore", "Yao Wang", "Hersh Chandarana", "Li Feng"], "title": "Hybrid Learning: A Novel Combination of Self-Supervised and Supervised Learning for MRI Reconstruction without High-Quality Training Reference", "categories": ["eess.IV", "cs.CV"], "comment": null, "summary": "Purpose: Deep learning has demonstrated strong potential for MRI\nreconstruction, but conventional supervised learning methods require\nhigh-quality reference images, which are often unavailable in practice.\nSelf-supervised learning offers an alternative, yet its performance degrades at\nhigh acceleration rates. To overcome these limitations, we propose hybrid\nlearning, a novel two-stage training framework that combines self-supervised\nand supervised learning for robust image reconstruction.\n  Methods: Hybrid learning is implemented in two sequential stages. In the\nfirst stage, self-supervised learning is employed to generate improved images\nfrom noisy or undersampled reference data. These enhanced images then serve as\npseudo-ground truths for the second stage, which uses supervised learning to\nrefine reconstruction performance and support higher acceleration rates. We\nevaluated hybrid learning in two representative applications: (1) accelerated\n0.55T spiral-UTE lung MRI using noisy reference data, and (2) 3D T1 mapping of\nthe brain without access to fully sampled ground truth.\n  Results: For spiral-UTE lung MRI, hybrid learning consistently improved image\nquality over both self-supervised and conventional supervised methods across\ndifferent acceleration rates, as measured by SSIM and NMSE. For 3D T1 mapping,\nhybrid learning achieved superior T1 quantification accuracy across a wide\ndynamic range, outperforming self-supervised learning in all tested conditions.\n  Conclusions: Hybrid learning provides a practical and effective solution for\ntraining deep MRI reconstruction networks when only low-quality or incomplete\nreference data are available. It enables improved image quality and accurate\nquantitative mapping across different applications and field strengths,\nrepresenting a promising technique toward broader clinical deployment of deep\nlearning-based MRI.", "AI": {"tldr": "Hybrid learning combines self-supervised and supervised learning for robust MRI reconstruction, outperforming standalone methods in image quality and accuracy.", "motivation": "Conventional supervised learning requires high-quality reference images, often unavailable, while self-supervised learning degrades at high acceleration rates. Hybrid learning addresses these limitations.", "method": "A two-stage framework: self-supervised learning generates improved images from noisy/undersampled data, followed by supervised learning using these as pseudo-ground truths for refinement.", "result": "Improved image quality (SSIM, NMSE) for lung MRI and superior T1 quantification accuracy for brain mapping, outperforming standalone methods.", "conclusion": "Hybrid learning is effective for deep MRI reconstruction with low-quality/incomplete data, enabling better image quality and quantitative accuracy for clinical deployment."}}
{"id": "2505.05949", "pdf": "https://arxiv.org/pdf/2505.05949", "abs": "https://arxiv.org/abs/2505.05949", "authors": ["Max Glockner", "Xiang Jiang", "Leonardo F. R. Ribeiro", "Iryna Gurevych", "Markus Dreyer"], "title": "NeoQA: Evidence-based Question Answering with Generated News Events", "categories": ["cs.CL"], "comment": null, "summary": "Evaluating Retrieval-Augmented Generation (RAG) in large language models\n(LLMs) is challenging because benchmarks can quickly become stale. Questions\ninitially requiring retrieval may become answerable from pretraining knowledge\nas newer models incorporate more recent information during pretraining, making\nit difficult to distinguish evidence-based reasoning from recall. We introduce\nNeoQA (News Events for Out-of-training Question Answering), a benchmark\ndesigned to address this issue. To construct NeoQA, we generated timelines and\nknowledge bases of fictional news events and entities along with news articles\nand Q\\&A pairs to prevent LLMs from leveraging pretraining knowledge, ensuring\nthat no prior evidence exists in their training data. We propose our dataset as\na new platform for evaluating evidence-based question answering, as it requires\nLLMs to generate responses exclusively from retrieved evidence and only when\nsufficient evidence is available. NeoQA enables controlled evaluation across\nvarious evidence scenarios, including cases with missing or misleading details.\nOur findings indicate that LLMs struggle to distinguish subtle mismatches\nbetween questions and evidence, and suffer from short-cut reasoning when key\ninformation required to answer a question is missing from the evidence,\nunderscoring key limitations in evidence-based reasoning.", "AI": {"tldr": "NeoQA is a benchmark for evaluating RAG in LLMs using fictional news events to prevent reliance on pretraining knowledge, highlighting challenges in evidence-based reasoning.", "motivation": "Existing benchmarks for RAG in LLMs become stale as newer models incorporate more pretraining knowledge, making it hard to evaluate evidence-based reasoning.", "method": "Constructed NeoQA with fictional news events, timelines, and Q&A pairs to ensure no prior pretraining knowledge exists, requiring LLMs to rely solely on retrieved evidence.", "result": "LLMs struggle with subtle mismatches between questions and evidence and exhibit shortcut reasoning when key information is missing.", "conclusion": "NeoQA provides a controlled platform for evaluating evidence-based QA, revealing limitations in LLMs' evidence-based reasoning."}}
{"id": "2505.05976", "pdf": "https://arxiv.org/pdf/2505.05976", "abs": "https://arxiv.org/abs/2505.05976", "authors": ["Chico Sundermann", "Stefan Vill", "Elias Kuiter", "Sebastian Krieter", "Thomas Th\u00fcm", "Matthias Tichy"], "title": "Pseudo-Boolean d-DNNF Compilation for Expressive Feature Modeling Constructs", "categories": ["cs.AI", "cs.LO", "cs.SE"], "comment": null, "summary": "Configurable systems typically consist of reusable assets that have\ndependencies between each other. To specify such dependencies, feature models\nare commonly used. As feature models in practice are often complex, automated\nreasoning is typically employed to analyze the dependencies. Here, the de facto\nstandard is translating the feature model to conjunctive normal form (CNF) to\nenable employing off-the-shelf tools, such as SAT or #SAT solvers. However,\nmodern feature-modeling dialects often contain constructs, such as cardinality\nconstraints, that are ill-suited for conversion to CNF. This mismatch between\nthe input of reasoning engines and the available feature-modeling dialects\nlimits the applicability of the more expressive constructs. In this work, we\nshorten this gap between expressive constructs and scalable automated\nreasoning. Our contribution is twofold: First, we provide a pseudo-Boolean\nencoding for feature models, which facilitates smaller representations of\ncommonly employed constructs compared to Boolean encoding. Second, we propose a\nnovel method to compile pseudo-Boolean formulas to Boolean d-DNNF. With the\ncompiled d-DNNFs, we can resort to a plethora of efficient analyses already\nused in feature modeling. Our empirical evaluation shows that our proposal\nsubstantially outperforms the state-of-the-art based on CNF inputs for\nexpressive constructs. For every considered dataset representing different\nfeature models and feature-modeling constructs, the feature models can be\nsignificantly faster translated to pseudo-Boolean than to CNF. Overall,\nderiving d-DNNFs from a feature model with the targeted expressive constraints\ncan be substantially accelerated using our pseudo-Boolean approach.\nFurthermore, our approach is competitive on feature models with only basic\nconstructs.", "AI": {"tldr": "The paper proposes a pseudo-Boolean encoding for feature models and a method to compile them to Boolean d-DNNF, improving scalability and efficiency for automated reasoning compared to CNF-based approaches.", "motivation": "The mismatch between expressive feature-modeling constructs (e.g., cardinality constraints) and CNF-based reasoning limits applicability. The goal is to bridge this gap.", "method": "Introduces a pseudo-Boolean encoding for feature models and a novel compilation method to Boolean d-DNNF.", "result": "Empirical evaluation shows the approach outperforms CNF-based methods in speed and scalability, especially for expressive constructs.", "conclusion": "The pseudo-Boolean approach accelerates reasoning for feature models with expressive constructs and remains competitive for basic ones."}}
{"id": "2505.05513", "pdf": "https://arxiv.org/pdf/2505.05513", "abs": "https://arxiv.org/abs/2505.05513", "authors": ["Muhammad Junaid Asif", "Hamza Khan", "Rabia Tehseen", "Syed Tahir Hussain Rizvi", "Mujtaba Asad", "Shazia Saqib", "Rana Fayyaz Ahmad"], "title": "Exploring Convolutional Neural Networks for Rice Grain Classification: An Explainable AI Approach", "categories": ["cs.CV"], "comment": null, "summary": "Rice is an essential staple food worldwide that is important in promoting\ninternational trade, economic growth, and nutrition. Asian countries such as\nChina, India, Pakistan, Thailand, Vietnam, and Indonesia are notable for their\nsignificant contribution to the cultivation and utilization of rice. These\nnations are also known for cultivating different rice grains, including short\nand long grains. These sizes are further classified as basmati, jasmine, kainat\nsaila, ipsala, arborio, etc., catering to diverse culinary preferences and\ncultural traditions. For both local and international trade, inspecting and\nmaintaining the quality of rice grains to satisfy customers and preserve a\ncountry's reputation is necessary. Manual quality check and classification is\nquite a laborious and time-consuming process. It is also highly prone to\nmistakes. Therefore, an automatic solution must be proposed for the effective\nand efficient classification of different varieties of rice grains. This\nresearch paper presents an automatic framework based on a convolutional neural\nnetwork (CNN) for classifying different varieties of rice grains. We evaluated\nthe proposed model based on performance metrics such as accuracy, recall,\nprecision, and F1-Score. The CNN model underwent rigorous training and\nvalidation, achieving a remarkable accuracy rate and a perfect area under each\nclass's Receiver Operating Characteristic (ROC) curve. The confusion matrix\nanalysis confirmed the model's effectiveness in distinguishing between the\ndifferent rice varieties, indicating minimal misclassifications. Additionally,\nthe integration of explainability techniques such as LIME (Local Interpretable\nModel-agnostic Explanations) and SHAP (SHapley Additive exPlanations) provided\nvaluable insights into the model's decision-making process, revealing how\nspecific features of the rice grains influenced classification outcomes.", "AI": {"tldr": "The paper proposes a CNN-based framework for automatic classification of rice grain varieties, achieving high accuracy and explainability using LIME and SHAP.", "motivation": "Manual rice grain quality checks are laborious and error-prone, necessitating an automated solution for efficient classification.", "method": "A convolutional neural network (CNN) is used for classification, evaluated via accuracy, recall, precision, F1-Score, and ROC analysis.", "result": "The CNN model achieved high accuracy and minimal misclassifications, with explainability techniques (LIME, SHAP) providing insights into feature influence.", "conclusion": "The proposed CNN framework is effective for rice grain classification, offering both accuracy and interpretability."}}
{"id": "2505.05594", "pdf": "https://arxiv.org/pdf/2505.05594", "abs": "https://arxiv.org/abs/2505.05594", "authors": ["Sura Alhanouti", "Parinaz Naghizadeh"], "title": "Anticipating Gaming to Incentivize Improvement: Guiding Agents in (Fair) Strategic Classification", "categories": ["cs.LG"], "comment": "31 pages, 12 figures", "summary": "As machine learning algorithms increasingly influence critical decision\nmaking in different application areas, understanding human strategic behavior\nin response to these systems becomes vital. We explore individuals' choice\nbetween genuinely improving their qualifications (``improvement'') vs.\nattempting to deceive the algorithm by manipulating their features\n(``manipulation'') in response to an algorithmic decision system. We further\ninvestigate an algorithm designer's ability to shape these strategic responses,\nand its fairness implications. Specifically, we formulate these interactions as\na Stackelberg game, where a firm deploys a (fair) classifier, and individuals\nstrategically respond. Our model incorporates both different costs and\nstochastic efficacy for manipulation and improvement. The analysis reveals\ndifferent potential classes of agent responses, and characterizes optimal\nclassifiers accordingly. Based on these, we highlight the impact of the firm's\nanticipation of strategic behavior, identifying when and why a (fair) strategic\npolicy can not only prevent manipulation, but also incentivize agents to opt\nfor improvement.", "AI": {"tldr": "The paper examines human strategic behavior in response to algorithmic decision systems, focusing on choices between genuine improvement and deceptive manipulation. It models these interactions as a Stackelberg game, analyzing fairness and optimal classifier design.", "motivation": "Understanding human strategic behavior in response to machine learning systems is crucial as these systems influence critical decisions. The study aims to explore how individuals and algorithm designers interact strategically.", "method": "The interactions are modeled as a Stackelberg game, where a firm deploys a fair classifier and individuals respond strategically. The model includes costs and stochastic efficacy for manipulation and improvement.", "result": "The analysis identifies different classes of agent responses and characterizes optimal classifiers. It shows how anticipating strategic behavior can prevent manipulation and incentivize genuine improvement.", "conclusion": "Strategic policy design by firms can promote fairness and discourage manipulation while encouraging genuine improvement, highlighting the importance of anticipating human behavior in algorithmic systems."}}
{"id": "2504.12345", "pdf": "https://arxiv.org/pdf/2504.12345", "abs": "https://arxiv.org/abs/2504.12345", "authors": ["Yutong Xia", "Ao Qu", "Yunhan Zheng", "Yihong Tang", "Dingyi Zhuang", "Yuxuan Liang", "Shenhao Wang", "Cathy Wu", "Lijun Sun", "Roger Zimmermann", "Jinhua Zhao"], "title": "Reimagining Urban Science: Scaling Causal Inference with Large Language Models", "categories": ["cs.CL", "cs.CY", "cs.MA"], "comment": null, "summary": "Urban causal research is essential for understanding the complex dynamics of\ncities and informing evidence-based policies. However, it is challenged by the\ninefficiency and bias of hypothesis generation, barriers to multimodal data\ncomplexity, and the methodological fragility of causal experimentation. Recent\nadvances in large language models (LLMs) present an opportunity to rethink how\nurban causal analysis is conducted. This Perspective examines current urban\ncausal research by analyzing taxonomies that categorize research topics, data\nsources, and methodological approaches to identify structural gaps. We then\nintroduce an LLM-driven conceptual framework, AutoUrbanCI, composed of four\ndistinct modular agents responsible for hypothesis generation, data\nengineering, experiment design and execution, and results interpretation with\npolicy recommendations. We propose evaluation criteria for rigor and\ntransparency and reflect on implications for human-AI collaboration, equity,\nand accountability. We call for a new research agenda that embraces\nAI-augmented workflows not as replacements for human expertise but as tools to\nbroaden participation, improve reproducibility, and unlock more inclusive forms\nof urban causal reasoning.", "AI": {"tldr": "The paper proposes AutoUrbanCI, an LLM-driven framework for urban causal research, addressing inefficiencies and biases in hypothesis generation, data complexity, and experimentation. It emphasizes AI-augmented workflows to enhance inclusivity and reproducibility.", "motivation": "Urban causal research faces challenges like inefficiency, bias, and methodological fragility. Advances in LLMs offer a chance to improve these processes.", "method": "Introduces AutoUrbanCI, a modular framework with agents for hypothesis generation, data engineering, experiment design, and results interpretation.", "result": "Proposes evaluation criteria for rigor and transparency, advocating for AI-augmented workflows to improve urban causal reasoning.", "conclusion": "Calls for a research agenda integrating AI to broaden participation and enhance reproducibility in urban causal research, without replacing human expertise."}}
{"id": "2505.05745", "pdf": "https://arxiv.org/pdf/2505.05745", "abs": "https://arxiv.org/abs/2505.05745", "authors": ["Bingan Yuan", "Bowei Liu", "Zheng Fang"], "title": "ProTCT: Projection quantification and fidelity constraint integrated deep reconstruction for Tangential CT", "categories": ["eess.IV"], "comment": null, "summary": "Tangential computed tomography (TCT) is a useful tool for imaging the\nlarge-diameter samples, such as oil pipelines and rockets. However, TCT\nprojections are truncated along the detector direction, resulting in degraded\nslices with radial artifacts. Meanwhile, existing methods fail to reconstruct\ndecent images because of the ill-defined sampling condition in the projection\ndomain and oversmoothing in the cross-section domain. In this paper, we propose\na projection quantification and fidelity constraint integrated deep TCT\nreconstruction method (ProTCT) to improve the slice quality. Specifically, the\nsampling conditions for reconstruction are analysed, offering practical\nguidelines for TCT system design. Besides, a deep artifact-suppression network\ntogether with a fidelity-constraint module that operates across both projection\nand cross-section domains to remove artifacts and restore edge details.\nDemonstrated on simulated and real datasets, the ProTCT shows good performance\nin structure restoration and detail retention. This work contributes to\nexploring the sampling condition and improving the slice quality of TCT,\nfurther promoting the application of large view field CT imaging.", "AI": {"tldr": "ProTCT improves TCT image quality by integrating projection quantification and fidelity constraints, addressing truncation artifacts and oversmoothing.", "motivation": "TCT projections are truncated, causing degraded slices with artifacts; existing methods fail due to ill-defined sampling and oversmoothing.", "method": "Proposes ProTCT, combining a deep artifact-suppression network and fidelity-constraint module across projection and cross-section domains.", "result": "ProTCT performs well in structure restoration and detail retention on simulated and real datasets.", "conclusion": "ProTCT enhances TCT slice quality, aiding large view field CT imaging applications."}}
{"id": "2505.05970", "pdf": "https://arxiv.org/pdf/2505.05970", "abs": "https://arxiv.org/abs/2505.05970", "authors": ["Lennart St\u00f6pler", "Rufat Asadli", "Mitja Nikolaus", "Ryan Cotterell", "Alex Warstadt"], "title": "Towards Developmentally Plausible Rewards: Communicative Success as a Learning Signal for Interactive Language Models", "categories": ["cs.CL"], "comment": null, "summary": "We propose a method for training language models in an interactive setting\ninspired by child language acquisition. In our setting, a speaker attempts to\ncommunicate some information to a listener in a single-turn dialogue and\nreceives a reward if communicative success is achieved. Unlike earlier related\nwork using image--caption data for interactive reference games, we\noperationalize communicative success in a more abstract language-only\nquestion--answering setting. First, we present a feasibility study\ndemonstrating that our reward provides an indirect signal about grammaticality.\nSecond, we conduct experiments using reinforcement learning to fine-tune\nlanguage models. We observe that cognitively plausible constraints on the\ncommunication channel lead to interpretable changes in speaker behavior.\nHowever, we do not yet see improvements on linguistic evaluations from our\ntraining regime. We outline potential modifications to the task design and\ntraining configuration that could better position future work to use our\nmethodology to observe the benefits of interaction on language learning in\ncomputational cognitive models.", "AI": {"tldr": "A method for training language models interactively, inspired by child language acquisition, using a question-answering setting and reinforcement learning.", "motivation": "To explore how interaction can improve language learning in computational models, inspired by child language acquisition.", "method": "Uses a single-turn dialogue setting with rewards for communicative success, operationalized in a language-only QA framework. Reinforcement learning fine-tunes models.", "result": "Reward signals indirectly indicate grammaticality, and constraints on communication lead to interpretable speaker behavior, but no linguistic improvements yet.", "conclusion": "Future work should modify task design and training to better leverage interaction for language learning benefits."}}
{"id": "2505.06020", "pdf": "https://arxiv.org/pdf/2505.06020", "abs": "https://arxiv.org/abs/2505.06020", "authors": ["Shuai Wang", "Ivona Najdenkoska", "Hongyi Zhu", "Stevan Rudinac", "Monika Kackovic", "Nachoem Wijnberg", "Marcel Worring"], "title": "ArtRAG: Retrieval-Augmented Generation with Structured Context for Visual Art Understanding", "categories": ["cs.AI", "cs.CV"], "comment": null, "summary": "Understanding visual art requires reasoning across multiple perspectives --\ncultural, historical, and stylistic -- beyond mere object recognition. While\nrecent multimodal large language models (MLLMs) perform well on general image\ncaptioning, they often fail to capture the nuanced interpretations that fine\nart demands. We propose ArtRAG, a novel, training-free framework that combines\nstructured knowledge with retrieval-augmented generation (RAG) for\nmulti-perspective artwork explanation. ArtRAG automatically constructs an Art\nContext Knowledge Graph (ACKG) from domain-specific textual sources, organizing\nentities such as artists, movements, themes, and historical events into a rich,\ninterpretable graph. At inference time, a multi-granular structured retriever\nselects semantically and topologically relevant subgraphs to guide generation.\nThis enables MLLMs to produce contextually grounded, culturally informed art\ndescriptions. Experiments on the SemArt and Artpedia datasets show that ArtRAG\noutperforms several heavily trained baselines. Human evaluations further\nconfirm that ArtRAG generates coherent, insightful, and culturally enriched\ninterpretations.", "AI": {"tldr": "ArtRAG combines structured knowledge and retrieval-augmented generation for nuanced art explanations, outperforming trained baselines.", "motivation": "Existing MLLMs lack nuanced art interpretation; ArtRAG addresses this by integrating cultural, historical, and stylistic knowledge.", "method": "ArtRAG constructs an Art Context Knowledge Graph (ACKG) and uses a multi-granular retriever to guide MLLM generation.", "result": "Outperforms baselines on SemArt and Artpedia datasets; human evaluations confirm coherent, culturally enriched outputs.", "conclusion": "ArtRAG effectively enhances MLLMs for multi-perspective art analysis without additional training."}}
{"id": "2505.05517", "pdf": "https://arxiv.org/pdf/2505.05517", "abs": "https://arxiv.org/abs/2505.05517", "authors": ["Hongyi Chen", "Yunchao Yao", "Yufei Ye", "Zhixuan Xu", "Homanga Bharadhwaj", "Jiashun Wang", "Shubham Tulsiani", "Zackory Erickson", "Jeffrey Ichnowski"], "title": "Web2Grasp: Learning Functional Grasps from Web Images of Hand-Object Interactions", "categories": ["cs.CV", "cs.LG", "cs.RO"], "comment": null, "summary": "Functional grasp is essential for enabling dexterous multi-finger robot hands\nto manipulate objects effectively. However, most prior work either focuses on\npower grasping, which simply involves holding an object still, or relies on\ncostly teleoperated robot demonstrations to teach robots how to grasp each\nobject functionally. Instead, we propose extracting human grasp information\nfrom web images since they depict natural and functional object interactions,\nthereby bypassing the need for curated demonstrations. We reconstruct human\nhand-object interaction (HOI) 3D meshes from RGB images, retarget the human\nhand to multi-finger robot hands, and align the noisy object mesh with its\naccurate 3D shape. We show that these relatively low-quality HOI data from\ninexpensive web sources can effectively train a functional grasping model. To\nfurther expand the grasp dataset for seen and unseen objects, we use the\ninitially-trained grasping policy with web data in the IsaacGym simulator to\ngenerate physically feasible grasps while preserving functionality. We train\nthe grasping model on 10 object categories and evaluate it on 9 unseen objects,\nincluding challenging items such as syringes, pens, spray bottles, and tongs,\nwhich are underrepresented in existing datasets. The model trained on the web\nHOI dataset, achieving a 75.8% success rate on seen objects and 61.8% across\nall objects in simulation, with a 6.7% improvement in success rate and a 1.8x\nincrease in functionality ratings over baselines. Simulator-augmented data\nfurther boosts performance from 61.8% to 83.4%. The sim-to-real transfer to the\nLEAP Hand achieves a 85% success rate. Project website is at:\nhttps://webgrasp.github.io/.", "AI": {"tldr": "The paper proposes using web images to extract human grasp data for training functional grasping models in robots, bypassing costly demonstrations. It reconstructs hand-object interactions from RGB images, retargets to robot hands, and uses simulation to expand the dataset, achieving high success rates in both simulation and real-world tests.", "motivation": "Functional grasping is crucial for dexterous robot hands, but prior work relies on power grasping or expensive demonstrations. The authors aim to leverage readily available web images for natural and functional grasp data.", "method": "The method involves reconstructing 3D hand-object meshes from RGB images, retargeting human hands to robot hands, and aligning noisy object meshes with accurate 3D shapes. The dataset is expanded using a simulator to generate feasible grasps.", "result": "The model achieves 75.8% success on seen objects and 61.8% on all objects in simulation, with improvements over baselines. Simulator-augmented data boosts performance to 83.4%, and real-world transfer achieves 85% success.", "conclusion": "Web-sourced grasp data and simulator augmentation effectively train functional grasping models, outperforming baselines and demonstrating successful sim-to-real transfer."}}
{"id": "2505.05597", "pdf": "https://arxiv.org/pdf/2505.05597", "abs": "https://arxiv.org/abs/2505.05597", "authors": ["Jacek Karolczak", "Jerzy Stefanowski"], "title": "This part looks alike this: identifying important parts of explained instances and prototypes", "categories": ["cs.LG"], "comment": null, "summary": "Although prototype-based explanations provide a human-understandable way of\nrepresenting model predictions they often fail to direct user attention to the\nmost relevant features. We propose a novel approach to identify the most\ninformative features within prototypes, termed alike parts. Using feature\nimportance scores derived from an agnostic explanation method, it emphasizes\nthe most relevant overlapping features between an instance and its nearest\nprototype. Furthermore, the feature importance score is incorporated into the\nobjective function of the prototype selection algorithms to promote global\nprototypes diversity. Through experiments on six benchmark datasets, we\ndemonstrate that the proposed approach improves user comprehension while\nmaintaining or even increasing predictive accuracy.", "AI": {"tldr": "The paper introduces a method to highlight the most relevant features in prototype-based explanations, improving user comprehension without sacrificing accuracy.", "motivation": "Prototype-based explanations often fail to emphasize the most relevant features, limiting their effectiveness for user understanding.", "method": "The approach identifies 'alike parts'\u2014key features in prototypes\u2014using feature importance scores from an agnostic explanation method. It integrates these scores into prototype selection to enhance diversity.", "result": "Experiments on six datasets show the method improves user comprehension while maintaining or boosting predictive accuracy.", "conclusion": "The proposed method effectively directs attention to relevant features in prototypes, enhancing interpretability without compromising performance."}}
{"id": "2505.05768", "pdf": "https://arxiv.org/pdf/2505.05768", "abs": "https://arxiv.org/abs/2505.05768", "authors": ["Weiyi Zhang", "Peranut Chotcomwongse", "Yinwen Li", "Pusheng Xu", "Ruijie Yao", "Lianhao Zhou", "Yuxuan Zhou", "Hui Feng", "Qiping Zhou", "Xinyue Wang", "Shoujin Huang", "Zihao Jin", "Florence H. T. Chung", "Shujun Wang", "Yalin Zheng", "Mingguang He", "Danli Shi", "Paisan Ruamviboonsuk"], "title": "Predicting Diabetic Macular Edema Treatment Responses Using OCT: Dataset and Methods of APTOS Competition", "categories": ["eess.IV", "cs.AI", "cs.CV"], "comment": "42 pages,5 tables, 12 figures, challenge report", "summary": "Diabetic macular edema (DME) significantly contributes to visual impairment\nin diabetic patients. Treatment responses to intravitreal therapies vary,\nhighlighting the need for patient stratification to predict therapeutic\nbenefits and enable personalized strategies. To our knowledge, this study is\nthe first to explore pre-treatment stratification for predicting DME treatment\nresponses. To advance this research, we organized the 2nd Asia-Pacific\nTele-Ophthalmology Society (APTOS) Big Data Competition in 2021. The\ncompetition focused on improving predictive accuracy for anti-VEGF therapy\nresponses using ophthalmic OCT images. We provided a dataset containing tens of\nthousands of OCT images from 2,000 patients with labels across four sub-tasks.\nThis paper details the competition's structure, dataset, leading methods, and\nevaluation metrics. The competition attracted strong scientific community\nparticipation, with 170 teams initially registering and 41 reaching the final\nround. The top-performing team achieved an AUC of 80.06%, highlighting the\npotential of AI in personalized DME treatment and clinical decision-making.", "AI": {"tldr": "The study explores pre-treatment stratification for predicting diabetic macular edema (DME) treatment responses, using a competition to improve AI-based predictive accuracy with OCT images.", "motivation": "Varied treatment responses in DME patients necessitate personalized strategies, prompting research into predictive stratification.", "method": "The 2nd APTOS Big Data Competition analyzed OCT images from 2,000 patients, with 170 teams developing AI models to predict anti-VEGF therapy responses.", "result": "The top team achieved an 80.06% AUC, demonstrating AI's potential for personalized DME treatment.", "conclusion": "AI-driven analysis of OCT images can enhance DME treatment prediction, supporting clinical decision-making."}}
{"id": "2505.05973", "pdf": "https://arxiv.org/pdf/2505.05973", "abs": "https://arxiv.org/abs/2505.05973", "authors": ["M. Maziyah Mohamed", "R. H. Baayen"], "title": "An Exploratory Analysis on the Explanatory Potential of Embedding-Based Measures of Semantic Transparency for Malay Word Recognition", "categories": ["cs.CL"], "comment": "24 pages, 5 figures, and 9 tables. Submitted to the Journal of\n  Morphology", "summary": "Studies of morphological processing have shown that semantic transparency is\ncrucial for word recognition. Its computational operationalization is still\nunder discussion. Our primary objectives are to explore embedding-based\nmeasures of semantic transparency, and assess their impact on reading. First,\nwe explored the geometry of complex words in semantic space. To do so, we\nconducted a t-distributed Stochastic Neighbor Embedding clustering analysis on\n4,226 Malay prefixed words. Several clusters were observed for complex words\nvaried by their prefix class. Then, we derived five simple measures, and\ninvestigated whether they were significant predictors of lexical decision\nlatencies. Two sets of Linear Discriminant Analyses were run in which the\nprefix of a word is predicted from either word embeddings or shift vectors\n(i.e., a vector subtraction of the base word from the derived word). The\naccuracy with which the model predicts the prefix of a word indicates the\ndegree of transparency of the prefix. Three further measures were obtained by\ncomparing embeddings between each word and all other words containing the same\nprefix (i.e., centroid), between each word and the shift from their base word,\nand between each word and the predicted word of the Functional Representations\nof Affixes in Compositional Semantic Space model. In a series of Generalized\nAdditive Mixed Models, all measures predicted decision latencies after\naccounting for word frequency, word length, and morphological family size. The\nmodel that included the correlation between each word and their centroid as a\npredictor provided the best fit to the data.", "AI": {"tldr": "The paper explores embedding-based measures of semantic transparency in Malay prefixed words, showing their predictive power for lexical decision latencies.", "motivation": "To operationalize and measure semantic transparency computationally and assess its impact on reading.", "method": "Used t-SNE clustering on 4,226 Malay prefixed words, derived five measures, and analyzed their predictive power via Linear Discriminant Analyses and Generalized Additive Mixed Models.", "result": "All measures predicted decision latencies; the correlation between a word and its centroid provided the best model fit.", "conclusion": "Embedding-based measures effectively capture semantic transparency and influence word recognition."}}
{"id": "2505.06030", "pdf": "https://arxiv.org/pdf/2505.06030", "abs": "https://arxiv.org/abs/2505.06030", "authors": ["Tobias Preintner", "Weixuan Yuan", "Qi Huang", "Adrian K\u00f6nig", "Thomas B\u00e4ck", "Elena Raponi", "Niki van Stein"], "title": "Why Are You Wrong? Counterfactual Explanations for Language Grounding with 3D Objects", "categories": ["cs.AI", "cs.CV", "cs.LG"], "comment": "Accepted at IJCNN 2025", "summary": "Combining natural language and geometric shapes is an emerging research area\nwith multiple applications in robotics and language-assisted design. A crucial\ntask in this domain is object referent identification, which involves selecting\na 3D object given a textual description of the target. Variability in language\ndescriptions and spatial relationships of 3D objects makes this a complex task,\nincreasing the need to better understand the behavior of neural network models\nin this domain. However, limited research has been conducted in this area.\nSpecifically, when a model makes an incorrect prediction despite being provided\nwith a seemingly correct object description, practitioners are left wondering:\n\"Why is the model wrong?\". In this work, we present a method answering this\nquestion by generating counterfactual examples. Our method takes a\nmisclassified sample, which includes two objects and a text description, and\ngenerates an alternative yet similar formulation that would have resulted in a\ncorrect prediction by the model. We have evaluated our approach with data from\nthe ShapeTalk dataset along with three distinct models. Our counterfactual\nexamples maintain the structure of the original description, are semantically\nsimilar and meaningful. They reveal weaknesses in the description, model bias\nand enhance the understanding of the models behavior. Theses insights help\npractitioners to better interact with systems as well as engineers to improve\nmodels.", "AI": {"tldr": "The paper introduces a method to generate counterfactual examples for understanding why neural models fail in object referent identification tasks, using the ShapeTalk dataset and three models.", "motivation": "To address the lack of understanding in why models misclassify objects despite correct descriptions, aiding practitioners and engineers.", "method": "Generates counterfactual examples from misclassified samples, altering descriptions to achieve correct predictions while maintaining semantic similarity.", "result": "Counterfactuals reveal model weaknesses, biases, and improve understanding of model behavior.", "conclusion": "The method enhances model interpretability and aids in system interaction and model improvement."}}
{"id": "2505.05519", "pdf": "https://arxiv.org/pdf/2505.05519", "abs": "https://arxiv.org/abs/2505.05519", "authors": ["Minkyu Choi", "Yunhao Yang", "Neel P. Bhatt", "Kushagra Gupta", "Sahil Shah", "Aditya Rai", "David Fridovich-Keil", "Ufuk Topcu", "Sandeep P. Chinchali"], "title": "Real-Time Privacy Preservation for Robot Visual Perception", "categories": ["cs.CV"], "comment": null, "summary": "Many robots (e.g., iRobot's Roomba) operate based on visual observations from\nlive video streams, and such observations may inadvertently include\nprivacy-sensitive objects, such as personal identifiers. Existing approaches\nfor preserving privacy rely on deep learning models, differential privacy, or\ncryptography. They lack guarantees for the complete concealment of all\nsensitive objects. Guaranteeing concealment requires post-processing techniques\nand thus is inadequate for real-time video streams. We develop a method for\nprivacy-constrained video streaming, PCVS, that conceals sensitive objects\nwithin real-time video streams. PCVS takes a logical specification constraining\nthe existence of privacy-sensitive objects, e.g., never show faces when a\nperson exists. It uses a detection model to evaluate the existence of these\nobjects in each incoming frame. Then, it blurs out a subset of objects such\nthat the existence of the remaining objects satisfies the specification. We\nthen propose a conformal prediction approach to (i) establish a theoretical\nlower bound on the probability of the existence of these objects in a sequence\nof frames satisfying the specification and (ii) update the bound with the\narrival of each subsequent frame. Quantitative evaluations show that PCVS\nachieves over 95 percent specification satisfaction rate in multiple datasets,\nsignificantly outperforming other methods. The satisfaction rate is\nconsistently above the theoretical bounds across all datasets, indicating that\nthe established bounds hold. Additionally, we deploy PCVS on robots in\nreal-time operation and show that the robots operate normally without being\ncompromised when PCVS conceals objects.", "AI": {"tldr": "PCVS is a method for real-time privacy-preserving video streaming that guarantees concealment of sensitive objects using logical specifications and conformal prediction.", "motivation": "Existing privacy-preserving methods lack guarantees for complete concealment of sensitive objects and are inadequate for real-time video streams.", "method": "PCVS uses logical specifications to constrain sensitive objects, detects them in frames, and blurs subsets to satisfy the specification. Conformal prediction provides theoretical bounds on satisfaction.", "result": "PCVS achieves over 95% specification satisfaction rate, outperforming other methods, and maintains performance in real-time robot operations.", "conclusion": "PCVS effectively guarantees privacy in real-time video streams while maintaining robot functionality."}}
{"id": "2505.05605", "pdf": "https://arxiv.org/pdf/2505.05605", "abs": "https://arxiv.org/abs/2505.05605", "authors": ["Andrew Qiu", "Shubham Barhate", "Hin Wai Lui", "Runze Su", "Rafael Rios M\u00fcller", "Kungang Li", "Ling Leng", "Han Sun", "Shayan Ehsani", "Zhifang Liu"], "title": "The Evolution of Embedding Table Optimization and Multi-Epoch Training in Pinterest Ads Conversion", "categories": ["cs.LG", "cs.CE", "cs.IR", "stat.AP", "F.2.2, I.2.7"], "comment": null, "summary": "Deep learning for conversion prediction has found widespread applications in\nonline advertising. These models have become more complex as they are trained\nto jointly predict multiple objectives such as click, add-to-cart, checkout and\nother conversion types. Additionally, the capacity and performance of these\nmodels can often be increased with the use of embedding tables that encode high\ncardinality categorical features such as advertiser, user, campaign, and\nproduct identifiers (IDs). These embedding tables can be pre-trained, but also\nlearned end-to-end jointly with the model to directly optimize the model\nobjectives. Training these large tables is challenging due to: gradient\nsparsity, the high cardinality of the categorical features, the non-uniform\ndistribution of IDs and the very high label sparsity. These issues make\ntraining prone to both slow convergence and overfitting after the first epoch.\nPrevious works addressed the multi-epoch overfitting issue by using: stronger\nfeature hashing to reduce cardinality, filtering of low frequency IDs,\nregularization of the embedding tables, re-initialization of the embedding\ntables after each epoch, etc. Some of these techniques reduce overfitting at\nthe expense of reduced model performance if used too aggressively. In this\npaper, we share key learnings from the development of embedding table\noptimization and multi-epoch training in Pinterest Ads Conversion models. We\nshowcase how our Sparse Optimizer speeds up convergence, and how multi-epoch\noverfitting varies in severity between different objectives in a multi-task\nmodel depending on label sparsity. We propose a new approach to deal with\nmulti-epoch overfitting: the use of a frequency-adaptive learning rate on the\nembedding tables and compare it to embedding re-initialization. We evaluate\nboth methods offline using an industrial large-scale production dataset.", "AI": {"tldr": "The paper discusses challenges in training deep learning models for conversion prediction in online ads, focusing on embedding table optimization and multi-epoch overfitting. It introduces a Sparse Optimizer and a frequency-adaptive learning rate approach.", "motivation": "Addressing slow convergence and overfitting in embedding tables for high-cardinality categorical features in multi-task conversion prediction models.", "method": "Proposes a Sparse Optimizer for faster convergence and a frequency-adaptive learning rate for embedding tables to mitigate overfitting, comparing it to embedding re-initialization.", "result": "Evaluated on an industrial dataset, the methods show improved performance in handling multi-epoch overfitting and label sparsity.", "conclusion": "The frequency-adaptive learning rate approach effectively reduces overfitting while maintaining model performance, outperforming traditional methods like re-initialization."}}
{"id": "2505.06105", "pdf": "https://arxiv.org/pdf/2505.06105", "abs": "https://arxiv.org/abs/2505.06105", "authors": ["Xilin Gong", "Yongkai Chen", "Shushan Wu", "Fang Wang", "Ping Ma", "Wenxuan Zhong"], "title": "S2MNet: Speckle-To-Mesh Net for Three-Dimensional Cardiac Morphology Reconstruction via Echocardiogram", "categories": ["eess.IV", "cs.CV"], "comment": null, "summary": "Echocardiogram is the most commonly used imaging modality in cardiac\nassessment duo to its non-invasive nature, real-time capability, and\ncost-effectiveness. Despite its advantages, most clinical echocardiograms\nprovide only two-dimensional views, limiting the ability to fully assess\ncardiac anatomy and function in three dimensions. While three-dimensional\nechocardiography exists, it often suffers from reduced resolution, limited\navailability, and higher acquisition costs. To overcome these challenges, we\npropose a deep learning framework S2MNet that reconstructs continuous and\nhigh-fidelity 3D heart models by integrating six slices of routinely acquired\n2D echocardiogram views. Our method has three advantages. First, our method\navoid the difficulties on training data acquasition by simulate six of 2D\nechocardiogram images from corresponding slices of a given 3D heart mesh.\nSecond, we introduce a deformation field-based method, which avoid spatial\ndiscontinuities or structural artifacts in 3D echocardiogram reconstructions.\nWe validate our method using clinically collected echocardiogram and\ndemonstrate that our estimated left ventricular volume, a key clinical\nindicator of cardiac function, is strongly correlated with the doctor measured\nGLPS, a clinical measurement that should demonstrate a negative correlation\nwith LVE in medical theory. This association confirms the reliability of our\nproposed 3D construction method.", "AI": {"tldr": "A deep learning framework, S2MNet, reconstructs high-fidelity 3D heart models from six 2D echocardiogram slices, overcoming limitations of traditional 3D echocardiography.", "motivation": "Traditional 2D echocardiograms lack 3D assessment, while 3D echocardiography has resolution and cost issues. S2MNet aims to bridge this gap.", "method": "S2MNet uses simulated 2D slices from 3D heart meshes and a deformation field-based approach to avoid artifacts.", "result": "The method shows strong correlation between estimated left ventricular volume and clinical measurements, validating its reliability.", "conclusion": "S2MNet provides a reliable and cost-effective solution for 3D cardiac assessment using routine 2D echocardiograms."}}
{"id": "2505.06004", "pdf": "https://arxiv.org/pdf/2505.06004", "abs": "https://arxiv.org/abs/2505.06004", "authors": ["Dawid Wisniewski", "Antoni Solarski", "Artur Nowakowski"], "title": "Exploring the Feasibility of Multilingual Grammatical Error Correction with a Single LLM up to 9B parameters: A Comparative Study of 17 Models", "categories": ["cs.CL"], "comment": "Accepted at MTSummit 2025 (The 20th Machine Translation Summit)", "summary": "Recent language models can successfully solve various language-related tasks,\nand many understand inputs stated in different languages. In this paper, we\nexplore the performance of 17 popular models used to correct grammatical issues\nin texts stated in English, German, Italian, and Swedish when using a single\nmodel to correct texts in all those languages. We analyze the outputs generated\nby these models, focusing on decreasing the number of grammatical errors while\nkeeping the changes small. The conclusions drawn help us understand what\nproblems occur among those models and which models can be recommended for\nmultilingual grammatical error correction tasks. We list six models that\nimprove grammatical correctness in all four languages and show that Gemma 9B is\ncurrently the best performing one for the languages considered.", "AI": {"tldr": "The paper evaluates 17 language models for multilingual grammatical error correction (GEC) in English, German, Italian, and Swedish, identifying Gemma 9B as the top performer.", "motivation": "To assess the effectiveness of popular language models in correcting grammatical errors across multiple languages using a single model.", "method": "Analyzed outputs of 17 models for GEC in four languages, focusing on error reduction and minimal text changes.", "result": "Six models improved grammatical correctness across all languages, with Gemma 9B being the best performer.", "conclusion": "The study highlights model-specific issues and recommends Gemma 9B for multilingual GEC tasks."}}
{"id": "2505.06049", "pdf": "https://arxiv.org/pdf/2505.06049", "abs": "https://arxiv.org/abs/2505.06049", "authors": ["Aleena Siji", "Joscha C\u00fcppers", "Osman Ali Mian", "Jilles Vreeken"], "title": "Seqret: Mining Rule Sets from Event Sequences", "categories": ["cs.AI"], "comment": null, "summary": "Summarizing event sequences is a key aspect of data mining. Most existing\nmethods neglect conditional dependencies and focus on discovering sequential\npatterns only. In this paper, we study the problem of discovering both\nconditional and unconditional dependencies from event sequence data. We do so\nby discovering rules of the form $X \\rightarrow Y$ where $X$ and $Y$ are\nsequential patterns. Rules like these are simple to understand and provide a\nclear description of the relation between the antecedent and the consequent. To\ndiscover succinct and non-redundant sets of rules we formalize the problem in\nterms of the Minimum Description Length principle. As the search space is\nenormous and does not exhibit helpful structure, we propose the Seqret method\nto discover high-quality rule sets in practice. Through extensive empirical\nevaluation we show that unlike the state of the art, Seqret ably recovers the\nground truth on synthetic datasets and finds useful rules from real datasets.", "AI": {"tldr": "The paper introduces Seqret, a method to discover conditional and unconditional dependencies in event sequences using rule-based patterns, outperforming existing methods.", "motivation": "Existing methods for summarizing event sequences focus only on sequential patterns, neglecting conditional dependencies, which limits their usefulness.", "method": "The paper formalizes the problem using the Minimum Description Length principle and proposes Seqret to discover high-quality, non-redundant rule sets.", "result": "Seqret successfully recovers ground truth in synthetic datasets and identifies useful rules in real datasets, outperforming state-of-the-art methods.", "conclusion": "Seqret effectively addresses the gap in discovering conditional dependencies in event sequences, providing clear and actionable insights."}}
{"id": "2505.05520", "pdf": "https://arxiv.org/pdf/2505.05520", "abs": "https://arxiv.org/abs/2505.05520", "authors": ["Chengwei Ye", "Huanzhen Zhang", "Yufei Lin", "Kangsheng Wang", "Linuo Xu", "Shuyan Liu"], "title": "GaMNet: A Hybrid Network with Gabor Fusion and NMamba for Efficient 3D Glioma Segmentation", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Gliomas are aggressive brain tumors that pose serious health risks. Deep\nlearning aids in lesion segmentation, but CNN and Transformer-based models\noften lack context modeling or demand heavy computation, limiting real-time use\non mobile medical devices. We propose GaMNet, integrating the NMamba module for\nglobal modeling and a multi-scale CNN for efficient local feature extraction.\nTo improve interpretability and mimic the human visual system, we apply Gabor\nfilters at multiple scales. Our method achieves high segmentation accuracy with\nfewer parameters and faster computation. Extensive experiments show GaMNet\noutperforms existing methods, notably reducing false positives and negatives,\nwhich enhances the reliability of clinical diagnosis.", "AI": {"tldr": "GaMNet combines NMamba for global context and multi-scale CNN for local features, using Gabor filters for interpretability, achieving high accuracy with efficiency.", "motivation": "Address limitations of CNN and Transformer models in glioma segmentation, such as lack of context modeling and high computational cost, to enable real-time use on mobile medical devices.", "method": "Integrates NMamba module for global modeling, multi-scale CNN for local feature extraction, and Gabor filters for interpretability.", "result": "Achieves high segmentation accuracy with fewer parameters and faster computation, reducing false positives and negatives.", "conclusion": "GaMNet outperforms existing methods, enhancing clinical diagnosis reliability."}}
{"id": "2505.05609", "pdf": "https://arxiv.org/pdf/2505.05609", "abs": "https://arxiv.org/abs/2505.05609", "authors": ["Vasilis Pollatos", "Debmalya Mandal", "Goran Radanovic"], "title": "On Corruption-Robustness in Performative Reinforcement Learning", "categories": ["cs.LG"], "comment": null, "summary": "In performative Reinforcement Learning (RL), an agent faces a\npolicy-dependent environment: the reward and transition functions depend on the\nagent's policy. Prior work on performative RL has studied the convergence of\nrepeated retraining approaches to a performatively stable policy. In the finite\nsample regime, these approaches repeatedly solve for a saddle point of a\nconvex-concave objective, which estimates the Lagrangian of a regularized\nversion of the reinforcement learning problem. In this paper, we aim to extend\nsuch repeated retraining approaches, enabling them to operate under corrupted\ndata. More specifically, we consider Huber's $\\epsilon$-contamination model,\nwhere an $\\epsilon$ fraction of data points is corrupted by arbitrary\nadversarial noise. We propose a repeated retraining approach based on\nconvex-concave optimization under corrupted gradients and a novel\nproblem-specific robust mean estimator for the gradients. We prove that our\napproach exhibits last-iterate convergence to an approximately stable policy,\nwith the approximation error linear in $\\sqrt{\\epsilon}$. We experimentally\ndemonstrate the importance of accounting for corruption in performative RL.", "AI": {"tldr": "The paper extends performative RL to handle corrupted data using a robust repeated retraining approach, achieving stable policy convergence despite adversarial noise.", "motivation": "Prior performative RL methods assume clean data, but real-world scenarios often involve corruption. This work addresses the gap by developing robust techniques for corrupted data.", "method": "Proposes a repeated retraining approach using convex-concave optimization under corrupted gradients and a novel robust mean estimator for gradients.", "result": "The method achieves last-iterate convergence to an approximately stable policy, with error linear in \u221a\u03f5. Experiments validate its robustness to corruption.", "conclusion": "The approach effectively handles data corruption in performative RL, demonstrating practical relevance and theoretical guarantees."}}
{"id": "2505.06118", "pdf": "https://arxiv.org/pdf/2505.06118", "abs": "https://arxiv.org/abs/2505.06118", "authors": ["Jingguo Qu", "Xinyang Han", "Man-Lik Chui", "Yao Pu", "Simon Takadiyi Gunda", "Ziman Chen", "Jing Qin", "Ann Dorothy King", "Winnie Chiu-Wing Chu", "Jing Cai", "Michael Tin-Cheung Ying"], "title": "The Application of Deep Learning for Lymph Node Segmentation: A Systematic Review", "categories": ["eess.IV", "cs.AI", "cs.CV"], "comment": null, "summary": "Automatic lymph node segmentation is the cornerstone for advances in computer\nvision tasks for early detection and staging of cancer. Traditional\nsegmentation methods are constrained by manual delineation and variability in\noperator proficiency, limiting their ability to achieve high accuracy. The\nintroduction of deep learning technologies offers new possibilities for\nimproving the accuracy of lymph node image analysis. This study evaluates the\napplication of deep learning in lymph node segmentation and discusses the\nmethodologies of various deep learning architectures such as convolutional\nneural networks, encoder-decoder networks, and transformers in analyzing\nmedical imaging data across different modalities. Despite the advancements, it\nstill confronts challenges like the shape diversity of lymph nodes, the\nscarcity of accurately labeled datasets, and the inadequate development of\nmethods that are robust and generalizable across different imaging modalities.\nTo the best of our knowledge, this is the first study that provides a\ncomprehensive overview of the application of deep learning techniques in lymph\nnode segmentation task. Furthermore, this study also explores potential future\nresearch directions, including multimodal fusion techniques, transfer learning,\nand the use of large-scale pre-trained models to overcome current limitations\nwhile enhancing cancer diagnosis and treatment planning strategies.", "AI": {"tldr": "The paper reviews deep learning's role in lymph node segmentation, highlighting its potential to improve accuracy over traditional methods, while addressing current challenges and future research directions.", "motivation": "To advance early cancer detection and staging by improving lymph node segmentation accuracy, overcoming limitations of traditional methods.", "method": "Evaluates deep learning architectures like CNNs, encoder-decoder networks, and transformers for lymph node segmentation in medical imaging.", "result": "Identifies challenges like lymph node shape diversity, dataset scarcity, and lack of generalizable methods, despite deep learning's advancements.", "conclusion": "Proposes future research directions, including multimodal fusion, transfer learning, and large-scale pre-trained models, to enhance segmentation and cancer diagnosis."}}
{"id": "2505.06010", "pdf": "https://arxiv.org/pdf/2505.06010", "abs": "https://arxiv.org/abs/2505.06010", "authors": ["Dawid Wisniewski", "Mikolaj Pokrywka", "Zofia Rostek"], "title": "Do Not Change Me: On Transferring Entities Without Modification in Neural Machine Translation -- a Multilingual Perspective", "categories": ["cs.CL"], "comment": "Accepted at MTSummit 2025 (The 20th Machine Translation Summit)", "summary": "Current machine translation models provide us with high-quality outputs in\nmost scenarios. However, they still face some specific problems, such as\ndetecting which entities should not be changed during translation. In this\npaper, we explore the abilities of popular NMT models, including models from\nthe OPUS project, Google Translate, MADLAD, and EuroLLM, to preserve entities\nsuch as URL addresses, IBAN numbers, or emails when producing translations\nbetween four languages: English, German, Polish, and Ukrainian. We investigate\nthe quality of popular NMT models in terms of accuracy, discuss errors made by\nthe models, and examine the reasons for errors. Our analysis highlights\nspecific categories, such as emojis, that pose significant challenges for many\nmodels considered. In addition to the analysis, we propose a new multilingual\nsynthetic dataset of 36,000 sentences that can help assess the quality of\nentity transfer across nine categories and four aforementioned languages.", "AI": {"tldr": "The paper evaluates NMT models' ability to preserve entities like URLs, IBANs, and emails in translations across four languages, identifies challenges (e.g., emojis), and introduces a synthetic dataset for testing.", "motivation": "To address the issue of NMT models failing to preserve specific entities during translation, the study aims to assess and improve their accuracy.", "method": "The study tests popular NMT models (OPUS, Google Translate, MADLAD, EuroLLM) on entity preservation in English, German, Polish, and Ukrainian, analyzing errors and reasons.", "result": "Findings reveal challenges, especially with emojis, and propose a 36,000-sentence synthetic dataset for evaluating entity transfer quality.", "conclusion": "The study highlights NMT models' limitations in entity preservation and offers a dataset to aid future improvements."}}
{"id": "2505.06096", "pdf": "https://arxiv.org/pdf/2505.06096", "abs": "https://arxiv.org/abs/2505.06096", "authors": ["Sam Bush", "Matthew DeLorenzo", "Phat Tieu", "Jeyavijayan Rajendran"], "title": "Free and Fair Hardware: A Pathway to Copyright Infringement-Free Verilog Generation using LLMs", "categories": ["cs.AI"], "comment": "Accepted at DAC 2025", "summary": "Limitations in Large Language Model (LLM) capabilities for hardware design\ntasks, such as generating functional Verilog codes, have motivated various\nfine-tuning optimizations utilizing curated hardware datasets from open-source\nrepositories. However, these datasets remain limited in size and contain\nminimal checks on licensing for reuse, resulting in potential copyright\nviolations by fine-tuned LLMs. Therefore, we propose an evaluation benchmark to\nestimate the risk of Verilog-trained LLMs to generate copyright-protected\ncodes. To minimize this risk, we present an open-source Verilog dataset,\nFreeSet, containing over 220k files, along with the automated dataset curation\nframework utilized to provide additional guarantees of fair-use Verilog data.\nWe then execute an LLM fine-tuning framework consisting of continual\npre-training, resulting in a fine-tuned Llama model for Verilog, FreeV. Our\nresults indicate that FreeV demonstrates the smallest risk of\ncopyright-infringement among prior works, with only a 3% violation rate.\nFurthermore, experimental results demonstrate improvements in Verilog\ngeneration functionality over its baseline model, improving VerilogEval pass@10\nrates by over 10%.", "AI": {"tldr": "The paper addresses copyright risks in LLM-generated Verilog code by introducing FreeSet, an open-source dataset, and FreeV, a fine-tuned model with reduced infringement rates and improved performance.", "motivation": "Limitations in LLM capabilities for hardware design tasks and potential copyright violations in fine-tuned models motivated the creation of a safer, open-source solution.", "method": "Proposed an evaluation benchmark for copyright risk, curated the FreeSet dataset, and fine-tuned the Llama model (FreeV) using continual pre-training.", "result": "FreeV showed a 3% copyright violation rate (lowest among prior works) and improved Verilog generation performance by 10% in pass@10 rates.", "conclusion": "The FreeSet dataset and FreeV model effectively mitigate copyright risks while enhancing Verilog generation capabilities."}}
{"id": "2505.05528", "pdf": "https://arxiv.org/pdf/2505.05528", "abs": "https://arxiv.org/abs/2505.05528", "authors": ["Hanxun Huang", "Sarah Erfani", "Yige Li", "Xingjun Ma", "James Bailey"], "title": "X-Transfer Attacks: Towards Super Transferable Adversarial Attacks on CLIP", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.LG"], "comment": "ICML 2025", "summary": "As Contrastive Language-Image Pre-training (CLIP) models are increasingly\nadopted for diverse downstream tasks and integrated into large vision-language\nmodels (VLMs), their susceptibility to adversarial perturbations has emerged as\na critical concern. In this work, we introduce \\textbf{X-Transfer}, a novel\nattack method that exposes a universal adversarial vulnerability in CLIP.\nX-Transfer generates a Universal Adversarial Perturbation (UAP) capable of\ndeceiving various CLIP encoders and downstream VLMs across different samples,\ntasks, and domains. We refer to this property as \\textbf{super\ntransferability}--a single perturbation achieving cross-data, cross-domain,\ncross-model, and cross-task adversarial transferability simultaneously. This is\nachieved through \\textbf{surrogate scaling}, a key innovation of our approach.\nUnlike existing methods that rely on fixed surrogate models, which are\ncomputationally intensive to scale, X-Transfer employs an efficient surrogate\nscaling strategy that dynamically selects a small subset of suitable surrogates\nfrom a large search space. Extensive evaluations demonstrate that X-Transfer\nsignificantly outperforms previous state-of-the-art UAP methods, establishing a\nnew benchmark for adversarial transferability across CLIP models. The code is\npublicly available in our\n\\href{https://github.com/HanxunH/XTransferBench}{GitHub repository}.", "AI": {"tldr": "X-Transfer is a novel attack method exposing universal adversarial vulnerability in CLIP models, achieving super transferability across tasks, domains, and models via surrogate scaling.", "motivation": "CLIP models' susceptibility to adversarial perturbations poses risks for downstream tasks and VLMs, necessitating robust attack methods.", "method": "X-Transfer generates Universal Adversarial Perturbations (UAPs) using surrogate scaling, dynamically selecting surrogates for efficiency.", "result": "X-Transfer outperforms existing UAP methods, setting a new benchmark for adversarial transferability in CLIP models.", "conclusion": "X-Transfer's super transferability highlights critical vulnerabilities in CLIP, urging improved robustness in vision-language models."}}
{"id": "2505.05625", "pdf": "https://arxiv.org/pdf/2505.05625", "abs": "https://arxiv.org/abs/2505.05625", "authors": ["Wenqing Peng", "Zhi-Song Liu", "Michael Boy"], "title": "SPIN-ODE: Stiff Physics-Informed Neural ODE for Chemical Reaction Rate Estimation", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Estimating rate constants from complex chemical reactions is essential for\nadvancing detailed chemistry. However, the stiffness inherent in real-world\natmospheric chemistry systems poses severe challenges, leading to training\ninstability and poor convergence that hinder effective rate constant estimation\nusing learning-based approaches. To address this, we propose a Stiff\nPhysics-Informed Neural ODE framework (SPIN-ODE) for chemical reaction\nmodelling. Our method introduces a three-stage optimisation process: first, a\nlatent neural ODE learns the continuous and differentiable trajectory between\nchemical concentrations and their time derivatives; second, an explicit\nChemical Reaction Neural Network (CRNN) extracts the underlying rate\ncoefficients based on the learned dynamics; and third, fine-tune CRNN using a\nneural ODE solver to further improve rate coefficient estimation. Extensive\nexperiments on both synthetic and newly proposed real-world datasets validate\nthe effectiveness and robustness of our approach. As the first work on stiff\nNeural ODEs for chemical rate coefficient discovery, our study opens promising\ndirections for integrating neural networks with detailed chemistry.", "AI": {"tldr": "Proposes SPIN-ODE, a three-stage neural ODE framework for estimating stiff chemical reaction rate constants, validated on synthetic and real-world datasets.", "motivation": "Addressing training instability and poor convergence in learning-based rate constant estimation for stiff atmospheric chemistry systems.", "method": "Three-stage process: latent neural ODE for trajectory learning, CRNN for rate coefficient extraction, and fine-tuning with a neural ODE solver.", "result": "Effective and robust rate coefficient estimation, validated on synthetic and real-world datasets.", "conclusion": "SPIN-ODE opens new directions for integrating neural networks with detailed chemistry, especially for stiff systems."}}
{"id": "2505.06210", "pdf": "https://arxiv.org/pdf/2505.06210", "abs": "https://arxiv.org/abs/2505.06210", "authors": ["Diego Adame", "Jose A. Nunez", "Fabian Vazquez", "Nayeli Gurrola", "Huimin Li", "Haoteng Tang", "Bin Fu", "Pengfei Gu"], "title": "Topo-VM-UNetV2: Encoding Topology into Vision Mamba UNet for Polyp Segmentation", "categories": ["eess.IV", "cs.CV"], "comment": null, "summary": "Convolutional neural network (CNN) and Transformer-based architectures are\ntwo dominant deep learning models for polyp segmentation. However, CNNs have\nlimited capability for modeling long-range dependencies, while Transformers\nincur quadratic computational complexity. Recently, State Space Models such as\nMamba have been recognized as a promising approach for polyp segmentation\nbecause they not only model long-range interactions effectively but also\nmaintain linear computational complexity. However, Mamba-based architectures\nstill struggle to capture topological features (e.g., connected components,\nloops, voids), leading to inaccurate boundary delineation and polyp\nsegmentation. To address these limitations, we propose a new approach called\nTopo-VM-UNetV2, which encodes topological features into the Mamba-based\nstate-of-the-art polyp segmentation model, VM-UNetV2. Our method consists of\ntwo stages: Stage 1: VM-UNetV2 is used to generate probability maps (PMs) for\nthe training and test images, which are then used to compute topology attention\nmaps. Specifically, we first compute persistence diagrams of the PMs, then we\ngenerate persistence score maps by assigning persistence values (i.e., the\ndifference between death and birth times) of each topological feature to its\nbirth location, finally we transform persistence scores into attention weights\nusing the sigmoid function. Stage 2: These topology attention maps are\nintegrated into the semantics and detail infusion (SDI) module of VM-UNetV2 to\nform a topology-guided semantics and detail infusion (Topo-SDI) module for\nenhancing the segmentation results. Extensive experiments on five public polyp\nsegmentation datasets demonstrate the effectiveness of our proposed method. The\ncode will be made publicly available.", "AI": {"tldr": "The paper proposes Topo-VM-UNetV2, a method integrating topological features into Mamba-based VM-UNetV2 for improved polyp segmentation, addressing limitations of CNNs and Transformers.", "motivation": "CNNs lack long-range dependency modeling, while Transformers have high computational complexity. Mamba-based models struggle with topological features, leading to inaccurate segmentation.", "method": "Two-stage approach: 1) Generate probability maps and compute topology attention maps using persistence diagrams. 2) Integrate these maps into VM-UNetV2's SDI module to form Topo-SDI.", "result": "Extensive experiments on five datasets show the method's effectiveness.", "conclusion": "Topo-VM-UNetV2 enhances polyp segmentation by incorporating topological features, outperforming existing models."}}
{"id": "2505.06027", "pdf": "https://arxiv.org/pdf/2505.06027", "abs": "https://arxiv.org/abs/2505.06027", "authors": ["Stefan Vasilev", "Christian Herold", "Baohao Liao", "Seyyed Hadi Hashemi", "Shahram Khadivi", "Christof Monz"], "title": "Unilogit: Robust Machine Unlearning for LLMs Using Uniform-Target Self-Distillation", "categories": ["cs.CL", "cs.LG", "68T50", "I.2.7"], "comment": "16 pages, 6 figures, 5 tables, under review at ACL", "summary": "This paper introduces Unilogit, a novel self-distillation method for machine\nunlearning in Large Language Models. Unilogit addresses the challenge of\nselectively forgetting specific information while maintaining overall model\nutility, a critical task in compliance with data privacy regulations like GDPR.\nUnlike prior methods that rely on static hyperparameters or starting model\noutputs, Unilogit dynamically adjusts target logits to achieve a uniform\nprobability for the target token, leveraging the current model's outputs for\nmore accurate self-distillation targets. This approach not only eliminates the\nneed for additional hyperparameters but also enhances the model's ability to\napproximate the golden targets. Extensive experiments on public benchmarks and\nan in-house e-commerce dataset demonstrate Unilogit's superior performance in\nbalancing forget and retain objectives, outperforming state-of-the-art methods\nsuch as NPO and UnDIAL. Our analysis further reveals Unilogit's robustness\nacross various scenarios, highlighting its practical applicability and\neffectiveness in achieving efficacious machine unlearning.", "AI": {"tldr": "Unilogit is a self-distillation method for machine unlearning in LLMs, dynamically adjusting target logits to selectively forget data while maintaining model utility, outperforming existing methods.", "motivation": "Addressing the challenge of selective forgetting in LLMs to comply with data privacy regulations like GDPR.", "method": "Dynamically adjusts target logits for uniform probability of the target token, using current model outputs for accurate self-distillation.", "result": "Outperforms state-of-the-art methods (NPO, UnDIAL) in balancing forget and retain objectives, with robustness across scenarios.", "conclusion": "Unilogit is effective and practical for machine unlearning, enhancing compliance and model utility."}}
{"id": "2505.06191", "pdf": "https://arxiv.org/pdf/2505.06191", "abs": "https://arxiv.org/abs/2505.06191", "authors": ["Jiayuan Mao", "Joshua B. Tenenbaum", "Jiajun Wu"], "title": "Neuro-Symbolic Concepts", "categories": ["cs.AI", "cs.CL", "cs.CV", "cs.LG", "cs.RO"], "comment": "To appear in Communications of the ACM", "summary": "This article presents a concept-centric paradigm for building agents that can\nlearn continually and reason flexibly. The concept-centric agent utilizes a\nvocabulary of neuro-symbolic concepts. These concepts, such as object,\nrelation, and action concepts, are grounded on sensory inputs and actuation\noutputs. They are also compositional, allowing for the creation of novel\nconcepts through their structural combination. To facilitate learning and\nreasoning, the concepts are typed and represented using a combination of\nsymbolic programs and neural network representations. Leveraging such\nneuro-symbolic concepts, the agent can efficiently learn and recombine them to\nsolve various tasks across different domains, ranging from 2D images, videos,\n3D scenes, and robotic manipulation tasks. This concept-centric framework\noffers several advantages, including data efficiency, compositional\ngeneralization, continual learning, and zero-shot transfer.", "AI": {"tldr": "A concept-centric paradigm for agents using neuro-symbolic concepts enables efficient learning, reasoning, and task-solving across diverse domains.", "motivation": "To create agents capable of continual learning and flexible reasoning by grounding concepts in sensory inputs and actuation outputs.", "method": "Utilizes typed, compositional neuro-symbolic concepts represented via symbolic programs and neural networks.", "result": "The framework supports data efficiency, compositional generalization, continual learning, and zero-shot transfer.", "conclusion": "The concept-centric approach enhances agent adaptability and performance across varied tasks and domains."}}
{"id": "2505.05531", "pdf": "https://arxiv.org/pdf/2505.05531", "abs": "https://arxiv.org/abs/2505.05531", "authors": ["Hanie Moghaddasi", "Christina Chambers", "Sarah N. Mattson", "Jeffrey R. Wozniak", "Claire D. Coles", "Raja Mukherjee", "Michael Suttie"], "title": "OXSeg: Multidimensional attention UNet-based lip segmentation using semi-supervised lip contours", "categories": ["cs.CV", "eess.IV"], "comment": null, "summary": "Lip segmentation plays a crucial role in various domains, such as lip\nsynchronization, lipreading, and diagnostics. However, the effectiveness of\nsupervised lip segmentation is constrained by the availability of lip contour\nin the training phase. A further challenge with lip segmentation is its\nreliance on image quality , lighting, and skin tone, leading to inaccuracies in\nthe detected boundaries. To address these challenges, we propose a sequential\nlip segmentation method that integrates attention UNet and multidimensional\ninput. We unravel the micro-patterns in facial images using local binary\npatterns to build multidimensional inputs. Subsequently, the multidimensional\ninputs are fed into sequential attention UNets, where the lip contour is\nreconstructed. We introduce a mask generation method that uses a few anatomical\nlandmarks and estimates the complete lip contour to improve segmentation\naccuracy. This mask has been utilized in the training phase for lip\nsegmentation. To evaluate the proposed method, we use facial images to segment\nthe upper lips and subsequently assess lip-related facial anomalies in subjects\nwith fetal alcohol syndrome (FAS). Using the proposed lip segmentation method,\nwe achieved a mean dice score of 84.75%, and a mean pixel accuracy of 99.77% in\nupper lip segmentation. To further evaluate the method, we implemented\nclassifiers to identify those with FAS. Using a generative adversarial network\n(GAN), we reached an accuracy of 98.55% in identifying FAS in one of the study\npopulations. This method could be used to improve lip segmentation accuracy,\nespecially around Cupid's bow, and shed light on distinct lip-related\ncharacteristics of FAS.", "AI": {"tldr": "A sequential lip segmentation method using attention UNet and multidimensional input improves accuracy, achieving high dice scores and pixel accuracy, and aids in identifying fetal alcohol syndrome (FAS).", "motivation": "Supervised lip segmentation is limited by training data availability and affected by image quality, lighting, and skin tone. The study aims to improve segmentation accuracy and explore FAS-related lip characteristics.", "method": "The method integrates attention UNet with multidimensional inputs (using local binary patterns) and a mask generation technique based on anatomical landmarks. It evaluates segmentation and FAS identification using GANs.", "result": "Achieved 84.75% mean dice score and 99.77% pixel accuracy in lip segmentation. FAS identification reached 98.55% accuracy in one population.", "conclusion": "The proposed method enhances lip segmentation accuracy, particularly around Cupid's bow, and provides insights into FAS-related lip features."}}
{"id": "2505.05650", "pdf": "https://arxiv.org/pdf/2505.05650", "abs": "https://arxiv.org/abs/2505.05650", "authors": ["Tien Dang", "Truong-Son Hy"], "title": "EquiHGNN: Scalable Rotationally Equivariant Hypergraph Neural Networks", "categories": ["cs.LG"], "comment": null, "summary": "Molecular interactions often involve high-order relationships that cannot be\nfully captured by traditional graph-based models limited to pairwise\nconnections. Hypergraphs naturally extend graphs by enabling multi-way\ninteractions, making them well-suited for modeling complex molecular systems.\nIn this work, we introduce EquiHGNN, an Equivariant HyperGraph Neural Network\nframework that integrates symmetry-aware representations to improve molecular\nmodeling. By enforcing the equivariance under relevant transformation groups,\nour approach preserves geometric and topological properties, leading to more\nrobust and physically meaningful representations. We examine a range of\nequivariant architectures and demonstrate that integrating symmetry constraints\nleads to notable performance gains on large-scale molecular datasets.\nExperiments on both small and large molecules show that high-order interactions\noffer limited benefits for small molecules but consistently outperform 2D\ngraphs on larger ones. Adding geometric features to these high-order structures\nfurther improves the performance, emphasizing the value of spatial information\nin molecular learning. Our source code is available at\nhttps://github.com/HySonLab/EquiHGNN/", "AI": {"tldr": "EquiHGNN is an equivariant hypergraph neural network for molecular modeling, leveraging symmetry-aware representations to outperform traditional graph-based methods, especially for large molecules.", "motivation": "Traditional graph models fail to capture high-order molecular interactions, while hypergraphs can model multi-way relationships. Integrating symmetry constraints improves robustness and physical meaning.", "method": "EquiHGNN enforces equivariance under transformation groups to preserve geometric and topological properties, combining hypergraphs with symmetry-aware architectures.", "result": "High-order interactions benefit large molecules more than small ones, and adding geometric features further enhances performance.", "conclusion": "EquiHGNN demonstrates the importance of symmetry and high-order interactions in molecular modeling, with significant gains for large-scale systems."}}
{"id": "2505.05644", "pdf": "https://arxiv.org/pdf/2505.05644", "abs": "https://arxiv.org/abs/2505.05644", "authors": ["Tom Sander", "Moritz Tenthoff", "Kay Wohlfarth", "Christian W\u00f6hler"], "title": "The Moon's Many Faces: A Single Unified Transformer for Multimodal Lunar Reconstruction", "categories": ["cs.CV", "eess.IV"], "comment": "14pages", "summary": "Multimodal learning is an emerging research topic across multiple disciplines\nbut has rarely been applied to planetary science. In this contribution, we\nidentify that reflectance parameter estimation and image-based 3D\nreconstruction of lunar images can be formulated as a multimodal learning\nproblem. We propose a single, unified transformer architecture trained to learn\nshared representations between multiple sources like grayscale images, digital\nelevation models, surface normals, and albedo maps. The architecture supports\nflexible translation from any input modality to any target modality. Predicting\nDEMs and albedo maps from grayscale images simultaneously solves the task of 3D\nreconstruction of planetary surfaces and disentangles photometric parameters\nand height information. Our results demonstrate that our foundation model\nlearns physically plausible relations across these four modalities. Adding more\ninput modalities in the future will enable tasks such as photometric\nnormalization and co-registration.", "AI": {"tldr": "A unified transformer model for multimodal learning in planetary science, enabling tasks like 3D reconstruction and reflectance parameter estimation from lunar images.", "motivation": "To address the lack of multimodal learning applications in planetary science, particularly for lunar image analysis.", "method": "Proposes a single transformer architecture to learn shared representations across grayscale images, DEMs, surface normals, and albedo maps, supporting flexible modality translation.", "result": "The model successfully learns physically plausible relations across modalities, enabling 3D reconstruction and disentangling photometric parameters.", "conclusion": "The foundation model shows promise for future tasks like photometric normalization and co-registration by incorporating more input modalities."}}
{"id": "2505.06046", "pdf": "https://arxiv.org/pdf/2505.06046", "abs": "https://arxiv.org/abs/2505.06046", "authors": ["Joshua Harris", "Fan Grayson", "Felix Feldman", "Timothy Laurence", "Toby Nonnenmacher", "Oliver Higgins", "Leo Loman", "Selina Patel", "Thomas Finnie", "Samuel Collins", "Michael Borowitz"], "title": "Healthy LLMs? Benchmarking LLM Knowledge of UK Government Public Health Information", "categories": ["cs.CL", "cs.LG", "68T50"], "comment": "24 pages, 10 pages main text", "summary": "As Large Language Models (LLMs) become widely accessible, a detailed\nunderstanding of their knowledge within specific domains becomes necessary for\nsuccessful real world use. This is particularly critical in public health,\nwhere failure to retrieve relevant, accurate, and current information could\nsignificantly impact UK residents. However, currently little is known about LLM\nknowledge of UK Government public health information. To address this issue,\nthis paper introduces a new benchmark, PubHealthBench, with over 8000 questions\nfor evaluating LLMs' Multiple Choice Question Answering (MCQA) and free form\nresponses to public health queries, created via an automated pipeline. We also\nrelease a new dataset of the extracted UK Government public health guidance\ndocuments used as source text for PubHealthBench. Assessing 24 LLMs on\nPubHealthBench we find the latest private LLMs (GPT-4.5, GPT-4.1 and o1) have a\nhigh degree of knowledge, achieving >90% in the MCQA setup, and outperform\nhumans with cursory search engine use. However, in the free form setup we see\nlower performance with no model scoring >75%. Therefore, whilst there are\npromising signs that state of the art (SOTA) LLMs are an increasingly accurate\nsource of public health information, additional safeguards or tools may still\nbe needed when providing free form responses on public health topics.", "AI": {"tldr": "The paper introduces PubHealthBench, a benchmark for evaluating LLMs' knowledge of UK public health info, finding SOTA models perform well in MCQA but lag in free-form responses.", "motivation": "To assess LLMs' accuracy in public health info retrieval, critical for real-world impact, given the lack of current knowledge about their performance in this domain.", "method": "Created PubHealthBench with 8000 questions (MCQA and free-form) from UK Government public health docs, tested 24 LLMs.", "result": "SOTA LLMs scored >90% in MCQA, outperforming humans, but <75% in free-form responses.", "conclusion": "While SOTA LLMs show promise for public health info, safeguards are needed for free-form responses."}}
{"id": "2505.04999", "pdf": "https://arxiv.org/pdf/2505.04999", "abs": "https://arxiv.org/abs/2505.04999", "authors": ["Anthony Liang", "Pavel Czempin", "Matthew Hong", "Yutai Zhou", "Erdem Biyik", "Stephen Tu"], "title": "CLAM: Continuous Latent Action Models for Robot Learning from Unlabeled Demonstrations", "categories": ["cs.RO", "cs.AI", "cs.LG"], "comment": "Latent Action Models, Self-supervised Pretraining, Learning from\n  Videos", "summary": "Learning robot policies using imitation learning requires collecting large\namounts of costly action-labeled expert demonstrations, which fundamentally\nlimits the scale of training data. A promising approach to address this\nbottleneck is to harness the abundance of unlabeled observations-e.g., from\nvideo demonstrations-to learn latent action labels in an unsupervised way.\nHowever, we find that existing methods struggle when applied to complex robot\ntasks requiring fine-grained motions. We design continuous latent action models\n(CLAM) which incorporate two key ingredients we find necessary for learning to\nsolve complex continuous control tasks from unlabeled observation data: (a)\nusing continuous latent action labels instead of discrete representations, and\n(b) jointly training an action decoder to ensure that the latent action space\ncan be easily grounded to real actions with relatively few labeled examples.\nImportantly, the labeled examples can be collected from non-optimal play data,\nenabling CLAM to learn performant policies without access to any action-labeled\nexpert data. We demonstrate on continuous control benchmarks in DMControl\n(locomotion) and MetaWorld (manipulation), as well as on a real WidowX robot\narm that CLAM significantly outperforms prior state-of-the-art methods,\nremarkably with a 2-3x improvement in task success rate compared to the best\nbaseline. Videos and code can be found at clamrobot.github.io.", "AI": {"tldr": "CLAM improves robot policy learning by using continuous latent action labels and joint training, outperforming prior methods without needing expert-labeled data.", "motivation": "Addressing the bottleneck of costly action-labeled expert demonstrations in imitation learning by leveraging unlabeled observations.", "method": "Uses continuous latent action models (CLAM) with continuous latent labels and joint training of an action decoder.", "result": "CLAM achieves 2-3x better task success rates on benchmarks and real robots compared to prior methods.", "conclusion": "CLAM enables efficient learning of complex robot tasks without expert-labeled data, outperforming existing approaches."}}
{"id": "2505.05540", "pdf": "https://arxiv.org/pdf/2505.05540", "abs": "https://arxiv.org/abs/2505.05540", "authors": ["Pranav Guruprasad", "Yangyue Wang", "Sudipta Chowdhury", "Harshvardhan Sikka"], "title": "Benchmarking Vision, Language, & Action Models in Procedurally Generated, Open Ended Action Environments", "categories": ["cs.CV", "cs.LG"], "comment": "16 pages, 26 figures", "summary": "Vision-language-action (VLA) models represent an important step toward\ngeneral-purpose robotic systems by integrating visual perception, language\nunderstanding, and action execution. However, systematic evaluation of these\nmodels, particularly their zero-shot generalization capabilities in\nout-of-distribution (OOD) environments, remains limited. In this paper, we\nintroduce MultiNet v0.2, a comprehensive benchmark designed to evaluate and\nanalyze the generalization performance of state-of-the-art VLM and VLA\nmodels-including GPT-4o, GPT-4.1, OpenVLA,Pi0 Base, and Pi0 FAST-on diverse\nprocedural tasks from the Procgen benchmark. Our analysis reveals several\ncritical insights: (1) all evaluated models exhibit significant limitations in\nzero-shot generalization to OOD tasks, with performance heavily influenced by\nfactors such as action representation and task complexit; (2) VLAs generally\noutperform other models due to their robust architectural design; and (3) VLM\nvariants demonstrate substantial improvements when constrained appropriately,\nhighlighting the sensitivity of model performance to precise prompt\nengineering.", "AI": {"tldr": "MultiNet v0.2 evaluates VLA models' zero-shot generalization in OOD environments, revealing limitations, VLA superiority, and prompt engineering's impact.", "motivation": "To systematically assess the zero-shot generalization of VLA models in OOD settings, addressing gaps in current evaluation methods.", "method": "Introduces MultiNet v0.2, a benchmark testing VLA models (e.g., GPT-4o, OpenVLA) on diverse Procgen tasks.", "result": "Models struggle with OOD tasks; VLAs outperform others; prompt engineering significantly improves VLM performance.", "conclusion": "VLA models show promise but require better generalization; precise constraints enhance performance."}}
{"id": "2505.05677", "pdf": "https://arxiv.org/pdf/2505.05677", "abs": "https://arxiv.org/abs/2505.05677", "authors": ["Winston Chen", "Trenton Chang", "Jenna Wiens"], "title": "Conditional Front-door Adjustment for Heterogeneous Treatment Assignment Effect Estimation Under Non-adherence", "categories": ["cs.LG"], "comment": "Accepted by Conference on Health, Inference, and Learning (CHIL) 2025", "summary": "Estimates of heterogeneous treatment assignment effects can inform treatment\ndecisions. Under the presence of non-adherence (e.g., patients do not adhere to\ntheir assigned treatment), both the standard backdoor adjustment (SBD) and the\nconditional front-door adjustment (CFD) can recover unbiased estimates of the\ntreatment assignment effects. However, the estimation variance of these\napproaches may vary widely across settings, which remains underexplored in the\nliterature. In this work, we demonstrate theoretically and empirically that CFD\nyields lower-variance estimates than SBD when the true effect of treatment\nassignment is small (i.e., assigning an intervention leads to small changes in\npatients' future outcome). Additionally, since CFD requires estimating multiple\nnuisance parameters, we introduce LobsterNet, a multi-task neural network that\nimplements CFD with joint modeling of the nuisance parameters. Empirically,\nLobsterNet reduces estimation error across several semi-synthetic and\nreal-world datasets compared to baselines. Our findings suggest CFD with shared\nnuisance parameter modeling can improve treatment assignment effect estimation\nunder non-adherence.", "AI": {"tldr": "CFD outperforms SBD in variance for small treatment effects under non-adherence. LobsterNet, a multi-task neural network, further improves CFD's accuracy by jointly modeling nuisance parameters.", "motivation": "To address the underexplored variance differences between SBD and CFD in heterogeneous treatment effect estimation under non-adherence.", "method": "Theoretical and empirical comparison of SBD and CFD, plus LobsterNet for joint nuisance parameter modeling in CFD.", "result": "CFD yields lower-variance estimates than SBD for small treatment effects. LobsterNet reduces estimation error in semi-synthetic and real-world datasets.", "conclusion": "CFD with shared nuisance parameter modeling (via LobsterNet) enhances treatment effect estimation under non-adherence."}}
{"id": "2505.05710", "pdf": "https://arxiv.org/pdf/2505.05710", "abs": "https://arxiv.org/abs/2505.05710", "authors": ["Wooyoung Jeong", "Hyun Jae Park", "Seonghun Jeong", "Jong Wook Jang", "Tae Hoon Lim", "Dae Seoung Kim"], "title": "HyperspectralMAE: The Hyperspectral Imagery Classification Model using Fourier-Encoded Dual-Branch Masked Autoencoder", "categories": ["cs.CV", "cs.AI", "eess.IV"], "comment": null, "summary": "Hyperspectral imagery provides rich spectral detail but poses unique\nchallenges because of its high dimensionality in both spatial and spectral\ndomains. We propose \\textit{HyperspectralMAE}, a Transformer-based foundation\nmodel for hyperspectral data that employs a \\textit{dual masking} strategy:\nduring pre-training we randomly occlude 50\\% of spatial patches and 50\\% of\nspectral bands. This forces the model to learn representations capable of\nreconstructing missing information across both dimensions. To encode spectral\norder, we introduce learnable harmonic Fourier positional embeddings based on\nwavelength. The reconstruction objective combines mean-squared error (MSE) with\nthe spectral angle mapper (SAM) to balance pixel-level accuracy and\nspectral-shape fidelity.\n  The resulting model contains about $1.8\\times10^{8}$ parameters and produces\n768-dimensional embeddings, giving it sufficient capacity for transfer\nlearning. We pre-trained HyperspectralMAE on two large hyperspectral corpora --\nNASA EO-1 Hyperion ($\\sim$1\\,600 scenes, $\\sim$$3\\times10^{11}$ pixel spectra)\nand DLR EnMAP Level-0 ($\\sim$1\\,300 scenes, $\\sim$$3\\times10^{11}$ pixel\nspectra) -- and fine-tuned it for land-cover classification on the Indian Pines\nbenchmark. HyperspectralMAE achieves state-of-the-art transfer-learning\naccuracy on Indian Pines, confirming that masked dual-dimensional pre-training\nyields robust spectral-spatial representations. These results demonstrate that\ndual masking and wavelength-aware embeddings advance hyperspectral image\nreconstruction and downstream analysis.", "AI": {"tldr": "HyperspectralMAE is a Transformer-based model using dual masking (spatial and spectral) for hyperspectral data, achieving state-of-the-art results in land-cover classification.", "motivation": "Hyperspectral imagery's high dimensionality in spatial and spectral domains requires robust representation learning.", "method": "The model employs dual masking (50% spatial patches and 50% spectral bands), harmonic Fourier positional embeddings, and a combined MSE-SAM reconstruction objective.", "result": "Pre-trained on large hyperspectral corpora, HyperspectralMAE achieves top transfer-learning accuracy on the Indian Pines benchmark.", "conclusion": "Dual masking and wavelength-aware embeddings improve hyperspectral image reconstruction and downstream tasks."}}
{"id": "2505.06062", "pdf": "https://arxiv.org/pdf/2505.06062", "abs": "https://arxiv.org/abs/2505.06062", "authors": ["Iuliia Zaitova", "Vitalii Hirak", "Badr M. Abdullah", "Dietrich Klakow", "Bernd M\u00f6bius", "Tania Avgustinova"], "title": "Attention on Multiword Expressions: A Multilingual Study of BERT-based Models with Regard to Idiomaticity and Microsyntax", "categories": ["cs.CL"], "comment": "10 pages, 3 figures. Findings 2025", "summary": "This study analyzes the attention patterns of fine-tuned encoder-only models\nbased on the BERT architecture (BERT-based models) towards two distinct types\nof Multiword Expressions (MWEs): idioms and microsyntactic units (MSUs). Idioms\npresent challenges in semantic non-compositionality, whereas MSUs demonstrate\nunconventional syntactic behavior that does not conform to standard grammatical\ncategorizations. We aim to understand whether fine-tuning BERT-based models on\nspecific tasks influences their attention to MWEs, and how this attention\ndiffers between semantic and syntactic tasks. We examine attention scores to\nMWEs in both pre-trained and fine-tuned BERT-based models. We utilize\nmonolingual models and datasets in six Indo-European languages - English,\nGerman, Dutch, Polish, Russian, and Ukrainian. Our results show that\nfine-tuning significantly influences how models allocate attention to MWEs.\nSpecifically, models fine-tuned on semantic tasks tend to distribute attention\nto idiomatic expressions more evenly across layers. Models fine-tuned on\nsyntactic tasks show an increase in attention to MSUs in the lower layers,\ncorresponding with syntactic processing requirements.", "AI": {"tldr": "Fine-tuned BERT-based models' attention to Multiword Expressions (MWEs) varies by task type: semantic tasks evenly distribute attention to idioms, while syntactic tasks increase attention to microsyntactic units (MSUs) in lower layers.", "motivation": "To understand how fine-tuning BERT-based models on semantic or syntactic tasks affects their attention patterns toward MWEs (idioms and MSUs).", "method": "Analyze attention scores in pre-trained and fine-tuned BERT-based models across six Indo-European languages.", "result": "Fine-tuning influences attention allocation: semantic tasks distribute attention to idioms evenly; syntactic tasks increase attention to MSUs in lower layers.", "conclusion": "Task-specific fine-tuning shapes how BERT-based models attend to MWEs, aligning with semantic or syntactic processing needs."}}
{"id": "2505.05481", "pdf": "https://arxiv.org/pdf/2505.05481", "abs": "https://arxiv.org/abs/2505.05481", "authors": ["Ryan Williams"], "title": "Structure & Quality: Conceptual and Formal Foundations for the Mind-Body Problem", "categories": ["q-bio.NC", "cs.AI"], "comment": null, "summary": "This paper explores the hard problem of consciousness from a different\nperspective. Instead of drawing distinctions between the physical and the\nmental, an exploration of a more foundational relationship is examined: the\nrelationship between structure and quality.\n  Information-theoretic measures are developed to quantify the mutual\ndeterminability between structure and quality, including a novel Q-S space for\nanalyzing fidelity between the two domains. This novel space naturally points\ntoward a five-fold categorization of possible relationships between structural\nand qualitative properties, illustrating each through conceptual and formal\nmodels.\n  The ontological implications of each category are examined, shedding light on\ndebates around functionalism, emergentism, idealism, panpsychism, and neutral\nmonism.\n  This new line of inquiry has established a framework for deriving theoretical\nconstraints on qualitative systems undergoing evolution that is explored in my\ncompanion paper, Qualia & Natural Selection.", "AI": {"tldr": "The paper proposes a novel framework to analyze the relationship between structure and quality in consciousness, using information-theoretic measures and a Q-S space, leading to a five-fold categorization of their relationships.", "motivation": "To address the hard problem of consciousness by shifting focus from the physical-mental divide to the foundational relationship between structure and quality.", "method": "Develops information-theoretic measures and a Q-S space to quantify and analyze the mutual determinability between structure and quality, with conceptual and formal models.", "result": "Identifies five categories of relationships between structural and qualitative properties, with implications for ontological debates like functionalism and panpsychism.", "conclusion": "Establishes a framework for theoretical constraints on evolving qualitative systems, further explored in a companion paper."}}
{"id": "2505.05573", "pdf": "https://arxiv.org/pdf/2505.05573", "abs": "https://arxiv.org/abs/2505.05573", "authors": ["Mikhail Chaichuk", "Sushant Gautam", "Steven Hicks", "Elena Tutubalina"], "title": "Prompt to Polyp: Clinically-Aware Medical Image Synthesis with Diffusion Models", "categories": ["cs.CV", "cs.AI", "68T07, 68U10, 92C55", "I.2.10; I.4.8; J.3"], "comment": "code available at\n  https://github.com/THunderCondOR/ImageCLEFmed-MEDVQA-GI-2024-MMCP-Team", "summary": "The generation of realistic medical images from text descriptions has\nsignificant potential to address data scarcity challenges in healthcare AI\nwhile preserving patient privacy. This paper presents a comprehensive study of\ntext-to-image synthesis in the medical domain, comparing two distinct\napproaches: (1) fine-tuning large pre-trained latent diffusion models and (2)\ntraining small, domain-specific models. We introduce a novel model named MSDM,\nan optimized architecture based on Stable Diffusion that integrates a clinical\ntext encoder, variational autoencoder, and cross-attention mechanisms to better\nalign medical text prompts with generated images. Our study compares two\napproaches: fine-tuning large pre-trained models (FLUX, Kandinsky) versus\ntraining compact domain-specific models (MSDM). Evaluation across colonoscopy\n(MedVQA-GI) and radiology (ROCOv2) datasets reveals that while large models\nachieve higher fidelity, our optimized MSDM delivers comparable quality with\nlower computational costs. Quantitative metrics and qualitative evaluations by\nmedical experts reveal strengths and limitations of each approach.", "AI": {"tldr": "The paper compares text-to-image synthesis methods in healthcare, introducing MSDM, an optimized model, and evaluates its performance against large pre-trained models.", "motivation": "Addressing data scarcity in healthcare AI while preserving privacy by generating realistic medical images from text.", "method": "Two approaches: fine-tuning large pre-trained models (FLUX, Kandinsky) and training compact domain-specific models (MSDM). MSDM integrates a clinical text encoder, variational autoencoder, and cross-attention mechanisms.", "result": "Large models achieve higher fidelity, but MSDM delivers comparable quality with lower computational costs.", "conclusion": "MSDM is a viable alternative to large models, balancing quality and efficiency in medical image synthesis."}}
{"id": "2505.05683", "pdf": "https://arxiv.org/pdf/2505.05683", "abs": "https://arxiv.org/abs/2505.05683", "authors": ["Udaya Allani"], "title": "Interactive Diabetes Risk Prediction Using Explainable Machine Learning: A Dash-Based Approach with SHAP, LIME, and Comorbidity Insights", "categories": ["cs.LG", "cs.AI", "I.2.1; I.5.2; J.3"], "comment": "16 pages, 21 figures, submitted as a preprint for academic\n  dissemination", "summary": "This study presents a web-based interactive health risk prediction tool\ndesigned to assess diabetes risk using machine learning models. Built on the\n2015 CDC BRFSS dataset, the study evaluates models including Logistic\nRegression, Random Forest, XGBoost, LightGBM, KNN, and Neural Networks under\noriginal, SMOTE, and undersampling strategies. LightGBM with undersampling\nachieved the best recall, making it ideal for risk detection. The tool\nintegrates SHAP and LIME to explain predictions and highlights comorbidity\ncorrelations using Pearson analysis. A Dash-based UI enables user-friendly\ninteraction with model predictions, personalized suggestions, and feature\ninsights, supporting data-driven health awareness.", "AI": {"tldr": "A web-based tool uses machine learning to predict diabetes risk, with LightGBM and undersampling performing best. It includes SHAP/LIME explanations and a Dash UI for user interaction.", "motivation": "To create an accessible tool for diabetes risk prediction using machine learning, enhancing health awareness through data-driven insights.", "method": "Evaluated Logistic Regression, Random Forest, XGBoost, LightGBM, KNN, and Neural Networks on the 2015 CDC BRFSS dataset, testing original, SMOTE, and undersampling strategies.", "result": "LightGBM with undersampling achieved the highest recall, making it optimal for risk detection. SHAP and LIME provided prediction explanations, and Pearson analysis highlighted comorbidities.", "conclusion": "The tool successfully combines predictive accuracy with interpretability and user-friendly interaction, supporting proactive health management."}}
{"id": "2505.05752", "pdf": "https://arxiv.org/pdf/2505.05752", "abs": "https://arxiv.org/abs/2505.05752", "authors": ["Amin Ghafourian", "Andrew Lee", "Dechen Gao", "Tyler Beer", "Kin Yen", "Iman Soltani"], "title": "Automating Infrastructure Surveying: A Framework for Geometric Measurements and Compliance Assessment Using Point Cloud Data", "categories": ["cs.CV", "cs.CY", "cs.LG", "cs.RO", "eess.IV"], "comment": "19 pages, 15 figures, 4 tables", "summary": "Automation can play a prominent role in improving efficiency, accuracy, and\nscalability in infrastructure surveying and assessing construction and\ncompliance standards. This paper presents a framework for automation of\ngeometric measurements and compliance assessment using point cloud data. The\nproposed approach integrates deep learning-based detection and segmentation, in\nconjunction with geometric and signal processing techniques, to automate\nsurveying tasks. As a proof of concept, we apply this framework to\nautomatically evaluate the compliance of curb ramps with the Americans with\nDisabilities Act (ADA), demonstrating the utility of point cloud data in survey\nautomation. The method leverages a newly collected, large annotated dataset of\ncurb ramps, made publicly available as part of this work, to facilitate robust\nmodel training and evaluation. Experimental results, including comparison with\nmanual field measurements of several ramps, validate the accuracy and\nreliability of the proposed method, highlighting its potential to significantly\nreduce manual effort and improve consistency in infrastructure assessment.\nBeyond ADA compliance, the proposed framework lays the groundwork for broader\napplications in infrastructure surveying and automated construction evaluation,\npromoting wider adoption of point cloud data in these domains. The annotated\ndatabase, manual ramp survey data, and developed algorithms are publicly\navailable on the project's GitHub page:\nhttps://github.com/Soltanilara/SurveyAutomation.", "AI": {"tldr": "The paper presents a framework for automating geometric measurements and compliance assessment using point cloud data, demonstrated through ADA-compliant curb ramp evaluation.", "motivation": "To improve efficiency, accuracy, and scalability in infrastructure surveying and compliance assessment by leveraging automation.", "method": "Integrates deep learning-based detection and segmentation with geometric and signal processing techniques, using a newly collected annotated dataset of curb ramps.", "result": "Validated accuracy and reliability through comparison with manual field measurements, showing potential to reduce manual effort and improve consistency.", "conclusion": "The framework is scalable beyond ADA compliance, promoting wider adoption of point cloud data in infrastructure surveying and automated construction evaluation."}}
{"id": "2505.06110", "pdf": "https://arxiv.org/pdf/2505.06110", "abs": "https://arxiv.org/abs/2505.06110", "authors": ["Jugal Gajjar", "Kaustik Ranaware"], "title": "Multimodal Sentiment Analysis on CMU-MOSEI Dataset using Transformer-based Models", "categories": ["cs.CL", "cs.AI"], "comment": "6 pages, 2 figures, 5 tables, and 19 references", "summary": "This project performs multimodal sentiment analysis using the CMU-MOSEI\ndataset, using transformer-based models with early fusion to integrate text,\naudio, and visual modalities. We employ BERT-based encoders for each modality,\nextracting embeddings that are concatenated before classification. The model\nachieves strong performance, with 97.87\\% 7-class accuracy and a 0.9682\nF1-score on the test set, demonstrating the effectiveness of early fusion in\ncapturing cross-modal interactions. The training utilized Adam optimization\n(lr=1e-4), dropout (0.3), and early stopping to ensure generalization and\nrobustness. Results highlight the superiority of transformer architectures in\nmodeling multimodal sentiment, with a low MAE (0.1060) indicating precise\nsentiment intensity prediction. Future work may compare fusion strategies or\nenhance interpretability. This approach utilizes multimodal learning by\neffectively combining linguistic, acoustic, and visual cues for sentiment\nanalysis.", "AI": {"tldr": "The paper presents a multimodal sentiment analysis model using early fusion of text, audio, and visual data with transformer-based encoders, achieving high accuracy and F1-score.", "motivation": "To demonstrate the effectiveness of early fusion in capturing cross-modal interactions for sentiment analysis using transformer architectures.", "method": "BERT-based encoders for each modality (text, audio, visual) with concatenated embeddings, trained using Adam optimization, dropout, and early stopping.", "result": "Achieved 97.87% 7-class accuracy, 0.9682 F1-score, and low MAE (0.1060), showing strong performance.", "conclusion": "Transformer-based early fusion is effective for multimodal sentiment analysis; future work could explore other fusion strategies or interpretability."}}
{"id": "2505.05486", "pdf": "https://arxiv.org/pdf/2505.05486", "abs": "https://arxiv.org/abs/2505.05486", "authors": ["Anthony Kiggundu", "Dennis Krummacker", "Hans D. Schotten"], "title": "FedAvgen: Metadata for Model Aggregation In Communication Systems", "categories": ["cs.NE", "cs.AI", "cs.LG"], "comment": "Accepted in IEEE NetSoft 2025", "summary": "To improve business efficiency and minimize costs, Artificial Intelligence\n(AI) practitioners have adopted a shift from formulating models from scratch\ntowards sharing pretrained models. The pretrained models are then aggregated\ninto a global model with higher generalization capabilities, which is\nafterwards distributed to the client devices. This approach is known as\nfederated learning and inherently utilizes different techniques to select the\ncandidate client models averaged to obtain the global model. This approach, in\nthe case of communication systems, faces challenges arising from the\nexistential diversity in device profiles. The multiplicity in profiles\nmotivates our conceptual assessment of a metaheuristic algorithm (FedAvgen),\nwhich relates each pretrained model with its weight space as metadata, to a\nphenotype and genotype, respectively. This parent-child genetic evolution\ncharacterizes the global averaging step in federated learning. We then compare\nthe results of our approach to two widely adopted baseline federated learning\nalgorithms like Federated Averaging (FedAvg) and Federated Stochastic Gradient\nDescent (FedSGD).", "AI": {"tldr": "The paper proposes FedAvgen, a metaheuristic algorithm for federated learning that improves model aggregation by treating pretrained models as phenotypes and their weight spaces as genotypes. It compares FedAvgen with FedAvg and FedSGD.", "motivation": "The diversity in device profiles in federated learning poses challenges for model aggregation, motivating the development of FedAvgen to enhance generalization.", "method": "FedAvgen uses a genetic evolution approach, treating models as phenotypes and weight spaces as genotypes, to improve the global averaging step in federated learning.", "result": "The results of FedAvgen are compared to FedAvg and FedSGD, demonstrating its potential for better performance.", "conclusion": "FedAvgen offers a novel approach to federated learning, addressing device diversity challenges and showing promise for improved model aggregation."}}
{"id": "2505.05587", "pdf": "https://arxiv.org/pdf/2505.05587", "abs": "https://arxiv.org/abs/2505.05587", "authors": ["Peihao Wang", "Yuehao Wang", "Dilin Wang", "Sreyas Mohan", "Zhiwen Fan", "Lemeng Wu", "Ruisi Cai", "Yu-Ying Yeh", "Zhangyang Wang", "Qiang Liu", "Rakesh Ranjan"], "title": "Steepest Descent Density Control for Compact 3D Gaussian Splatting", "categories": ["cs.CV"], "comment": "CVPR 2025, Project page: https://vita-group.github.io/SteepGS/", "summary": "3D Gaussian Splatting (3DGS) has emerged as a powerful technique for\nreal-time, high-resolution novel view synthesis. By representing scenes as a\nmixture of Gaussian primitives, 3DGS leverages GPU rasterization pipelines for\nefficient rendering and reconstruction. To optimize scene coverage and capture\nfine details, 3DGS employs a densification algorithm to generate additional\npoints. However, this process often leads to redundant point clouds, resulting\nin excessive memory usage, slower performance, and substantial storage demands\n- posing significant challenges for deployment on resource-constrained devices.\nTo address this limitation, we propose a theoretical framework that demystifies\nand improves density control in 3DGS. Our analysis reveals that splitting is\ncrucial for escaping saddle points. Through an optimization-theoretic approach,\nwe establish the necessary conditions for densification, determine the minimal\nnumber of offspring Gaussians, identify the optimal parameter update direction,\nand provide an analytical solution for normalizing off-spring opacity. Building\non these insights, we introduce SteepGS, incorporating steepest density\ncontrol, a principled strategy that minimizes loss while maintaining a compact\npoint cloud. SteepGS achieves a ~50% reduction in Gaussian points without\ncompromising rendering quality, significantly enhancing both efficiency and\nscalability.", "AI": {"tldr": "SteepGS improves 3D Gaussian Splatting (3DGS) by optimizing density control, reducing redundant points by ~50% without quality loss.", "motivation": "3DGS's densification algorithm creates redundant points, leading to inefficiencies in memory, performance, and storage, especially on resource-constrained devices.", "method": "A theoretical framework analyzes density control, identifies splitting necessity, and derives conditions for densification. SteepGS implements steepest density control to minimize loss while keeping the point cloud compact.", "result": "SteepGS reduces Gaussian points by ~50% without compromising rendering quality, improving efficiency and scalability.", "conclusion": "SteepGS offers a principled solution to 3DGS's redundancy issues, enhancing its practicality for real-time applications."}}
{"id": "2505.05702", "pdf": "https://arxiv.org/pdf/2505.05702", "abs": "https://arxiv.org/abs/2505.05702", "authors": ["Seongjin Choi", "Gahee Kim", "Yong-Geun Oh"], "title": "Hypergraph Neural Sheaf Diffusion: A Symmetric Simplicial Set Framework for Higher-Order Learning", "categories": ["cs.LG", "05C65, 55U10, 68T07"], "comment": "This manuscript has been submitted to IEEE Access for publication", "summary": "The absence of intrinsic adjacency relations and orientation systems in\nhypergraphs creates fundamental challenges for constructing sheaf Laplacians of\narbitrary degrees. We resolve these limitations through symmetric simplicial\nsets derived directly from hypergraphs, which encode all possible oriented\nsubrelations within each hyperedge as ordered tuples. This construction\ncanonically defines adjacency via facet maps while inherently preserving\nhyperedge provenance. We establish that the normalized degree zero sheaf\nLaplacian on our induced symmetric simplicial set reduces exactly to the\ntraditional graph normalized sheaf Laplacian when restricted to graphs,\nvalidating its mathematical consistency with prior graph-based sheaf theory.\nFurthermore, the induced structure preserves all structural information from\nthe original hypergraph, ensuring that every multi-way relational detail is\nfaithfully retained. Leveraging this framework, we introduce Hypergraph Neural\nSheaf Diffusion (HNSD), the first principled extension of Neural Sheaf\nDiffusion (NSD) to hypergraphs. HNSD operates via normalized degree zero sheaf\nLaplacians over symmetric simplicial sets, resolving orientation ambiguity and\nadjacency sparsity inherent to hypergraph learning. Experimental evaluations\ndemonstrate HNSD's competitive performance across established benchmarks.", "AI": {"tldr": "The paper resolves hypergraph adjacency and orientation challenges using symmetric simplicial sets, introducing Hypergraph Neural Sheaf Diffusion (HNSD) for competitive performance.", "motivation": "Addressing the lack of intrinsic adjacency and orientation in hypergraphs to enable sheaf Laplacian construction.", "method": "Using symmetric simplicial sets to encode hyperedge subrelations, defining adjacency via facet maps, and introducing HNSD for hypergraph learning.", "result": "The normalized degree zero sheaf Laplacian aligns with graph-based theory, and HNSD performs competitively in benchmarks.", "conclusion": "The framework successfully extends sheaf theory to hypergraphs, resolving orientation and adjacency issues while preserving structural details."}}
{"id": "2505.05798", "pdf": "https://arxiv.org/pdf/2505.05798", "abs": "https://arxiv.org/abs/2505.05798", "authors": ["Youngjoon Lee", "Jinu Gong", "Joonhyuk Kang"], "title": "Improving Generalizability of Kolmogorov-Arnold Networks via Error-Correcting Output Codes", "categories": ["cs.LG", "cs.CV", "eess.IV", "eess.SP"], "comment": "4 pages", "summary": "Kolmogorov-Arnold Networks (KAN) offer universal function approximation using\nunivariate spline compositions without nonlinear activations. In this work, we\nintegrate Error-Correcting Output Codes (ECOC) into the KAN framework to\ntransform multi-class classification into multiple binary tasks, improving\nrobustness via Hamming-distance decoding. Our proposed KAN with ECOC method\noutperforms vanilla KAN on a challenging blood cell classification dataset,\nachieving higher accuracy under diverse hyperparameter settings. Ablation\nstudies further confirm that ECOC consistently enhances performance across\nFastKAN and FasterKAN variants. These results demonstrate that ECOC integration\nsignificantly boosts KAN generalizability in critical healthcare AI\napplications. To the best of our knowledge, this is the first integration of\nECOC with KAN for enhancing multi-class medical image classification\nperformance.", "AI": {"tldr": "Integrating ECOC into KAN improves multi-class classification by transforming it into binary tasks, enhancing robustness and accuracy in medical image classification.", "motivation": "To enhance the generalizability and robustness of KAN in multi-class classification, especially for critical healthcare applications like blood cell classification.", "method": "The paper integrates Error-Correcting Output Codes (ECOC) into the KAN framework, replacing nonlinear activations with univariate spline compositions, and uses Hamming-distance decoding for robustness.", "result": "The proposed KAN with ECOC outperforms vanilla KAN, achieving higher accuracy on a blood cell classification dataset, with consistent improvements across FastKAN and FasterKAN variants.", "conclusion": "ECOC integration significantly boosts KAN's performance in multi-class medical image classification, marking the first such application in the field."}}
{"id": "2505.06120", "pdf": "https://arxiv.org/pdf/2505.06120", "abs": "https://arxiv.org/abs/2505.06120", "authors": ["Philippe Laban", "Hiroaki Hayashi", "Yingbo Zhou", "Jennifer Neville"], "title": "LLMs Get Lost In Multi-Turn Conversation", "categories": ["cs.CL", "cs.HC"], "comment": null, "summary": "Large Language Models (LLMs) are conversational interfaces. As such, LLMs\nhave the potential to assist their users not only when they can fully specify\nthe task at hand, but also to help them define, explore, and refine what they\nneed through multi-turn conversational exchange. Although analysis of LLM\nconversation logs has confirmed that underspecification occurs frequently in\nuser instructions, LLM evaluation has predominantly focused on the single-turn,\nfully-specified instruction setting. In this work, we perform large-scale\nsimulation experiments to compare LLM performance in single- and multi-turn\nsettings. Our experiments confirm that all the top open- and closed-weight LLMs\nwe test exhibit significantly lower performance in multi-turn conversations\nthan single-turn, with an average drop of 39% across six generation tasks.\nAnalysis of 200,000+ simulated conversations decomposes the performance\ndegradation into two components: a minor loss in aptitude and a significant\nincrease in unreliability. We find that LLMs often make assumptions in early\nturns and prematurely attempt to generate final solutions, on which they overly\nrely. In simpler terms, we discover that *when LLMs take a wrong turn in a\nconversation, they get lost and do not recover*.", "AI": {"tldr": "LLMs perform worse in multi-turn conversations (39% drop) due to assumptions and premature solutions, unlike single-turn tasks.", "motivation": "To evaluate LLM performance in multi-turn conversations, which is common but understudied compared to single-turn tasks.", "method": "Large-scale simulation experiments comparing top LLMs in single- and multi-turn settings, analyzing 200,000+ conversations.", "result": "LLMs show a 39% performance drop in multi-turn tasks, caused by minor aptitude loss and significant unreliability.", "conclusion": "LLMs struggle in multi-turn conversations due to early assumptions and over-reliance on incorrect solutions, leading to poor recovery."}}
{"id": "2505.05494", "pdf": "https://arxiv.org/pdf/2505.05494", "abs": "https://arxiv.org/abs/2505.05494", "authors": ["Avanija Menon", "Ovidiu Serban"], "title": "An Automated LLM-based Pipeline for Asset-Level Database Creation to Assess Deforestation Impact", "categories": ["cs.DB", "cs.AI", "cs.IR", "cs.LG"], "comment": "Accepted to ACL ClimateNLP 2025", "summary": "The European Union Deforestation Regulation (EUDR) requires companies to\nprove their products do not contribute to deforestation, creating a critical\ndemand for precise, asset-level environmental impact data. Current databases\nlack the necessary detail, relying heavily on broad financial metrics and\nmanual data collection, which limits regulatory compliance and accurate\nenvironmental modeling. This study presents an automated, end-to-end data\nextraction pipeline that uses LLMs to create, clean, and validate structured\ndatabases, specifically targeting sectors with a high risk of deforestation.\nThe pipeline introduces Instructional, Role-Based, Zero-Shot Chain-of-Thought\n(IRZ-CoT) prompting to enhance data extraction accuracy and a\nRetrieval-Augmented Validation (RAV) process that integrates real-time web\nsearches for improved data reliability. Applied to SEC EDGAR filings in the\nMining, Oil & Gas, and Utilities sectors, the pipeline demonstrates significant\nimprovements over traditional zero-shot prompting approaches, particularly in\nextraction accuracy and validation coverage. This work advances NLP-driven\nautomation for regulatory compliance, CSR (Corporate Social Responsibility),\nand ESG, with broad sectoral applicability.", "AI": {"tldr": "The paper introduces an automated data extraction pipeline using LLMs and IRZ-CoT prompting to improve accuracy in tracking deforestation-related data for EUDR compliance.", "motivation": "Current databases lack precise, asset-level environmental impact data, hindering regulatory compliance and accurate environmental modeling.", "method": "An automated pipeline using LLMs, IRZ-CoT prompting, and Retrieval-Augmented Validation (RAV) to extract and validate data from SEC EDGAR filings in high-risk sectors.", "result": "Significant improvements in extraction accuracy and validation coverage compared to traditional zero-shot prompting.", "conclusion": "The pipeline advances NLP-driven automation for regulatory compliance, CSR, and ESG, with broad applicability."}}
{"id": "2505.05589", "pdf": "https://arxiv.org/pdf/2505.05589", "abs": "https://arxiv.org/abs/2505.05589", "authors": ["Jingzhong Lin", "Yuanyuan Qi", "Xinru Li", "Wenxuan Huang", "Xiangfeng Xu", "Bangyan Li", "Xuejiao Wang", "Gaoqi He"], "title": "ReactDance: Progressive-Granular Representation for Long-Term Coherent Reactive Dance Generation", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": null, "summary": "Reactive dance generation (RDG) produces follower movements conditioned on\nguiding dancer and music while ensuring spatial coordination and temporal\ncoherence. However, existing methods overemphasize global constraints and\noptimization, overlooking local information, such as fine-grained spatial\ninteractions and localized temporal context. Therefore, we present ReactDance,\na novel diffusion-based framework for high-fidelity RDG with long-term\ncoherence and multi-scale controllability. Unlike existing methods that\nstruggle with interaction fidelity, synchronization, and temporal consistency\nin duet synthesis, our approach introduces two key innovations: 1)Group\nResidual Finite Scalar Quantization (GRFSQ), a multi-scale disentangled motion\nrepresentation that captures interaction semantics from coarse body rhythms to\nfine-grained joint dynamics, and 2)Blockwise Local Context (BLC), a sampling\nstrategy eliminating error accumulation in long sequence generation via local\nblock causal masking and periodic positional encoding. Built on the decoupled\nmulti-scale GRFSQ representation, we implement a diffusion model\nwithLayer-Decoupled Classifier-free Guidance (LDCFG), allowing granular control\nover motion semantics across scales. Extensive experiments on standard\nbenchmarks demonstrate that ReactDance surpasses existing methods, achieving\nstate-of-the-art performance.", "AI": {"tldr": "ReactDance is a diffusion-based framework for reactive dance generation, improving fidelity and coherence with multi-scale control via GRFSQ and BLC innovations.", "motivation": "Existing methods for reactive dance generation lack fine-grained spatial interactions and localized temporal context, leading to poor interaction fidelity and temporal consistency.", "method": "ReactDance introduces GRFSQ for multi-scale motion representation and BLC for error-free long sequence generation, combined with a diffusion model using LDCFG.", "result": "ReactDance outperforms existing methods, achieving state-of-the-art performance in reactive dance generation.", "conclusion": "The proposed framework addresses limitations of prior methods, offering high-fidelity, coherent, and controllable reactive dance generation."}}
{"id": "2505.05707", "pdf": "https://arxiv.org/pdf/2505.05707", "abs": "https://arxiv.org/abs/2505.05707", "authors": ["Rushabh Solanki", "Meghana Bhange", "Ulrich A\u00efvodji", "Elliot Creager"], "title": "Crowding Out The Noise: Algorithmic Collective Action Under Differential Privacy", "categories": ["cs.LG", "cs.CR"], "comment": null, "summary": "The integration of AI into daily life has generated considerable attention\nand excitement, while also raising concerns about automating algorithmic harms\nand re-entrenching existing social inequities. While the responsible deployment\nof trustworthy AI systems is a worthy goal, there are many possible ways to\nrealize it, from policy and regulation to improved algorithm design and\nevaluation. In fact, since AI trains on social data, there is even a\npossibility for everyday users, citizens, or workers to directly steer its\nbehavior through Algorithmic Collective Action, by deliberately modifying the\ndata they share with a platform to drive its learning process in their favor.\nThis paper considers how these grassroots efforts to influence AI interact with\nmethods already used by AI firms and governments to improve model\ntrustworthiness. In particular, we focus on the setting where the AI firm\ndeploys a differentially private model, motivated by the growing regulatory\nfocus on privacy and data protection. We investigate how the use of\nDifferentially Private Stochastic Gradient Descent (DPSGD) affects the\ncollective's ability to influence the learning process. Our findings show that\nwhile differential privacy contributes to the protection of individual data, it\nintroduces challenges for effective algorithmic collective action. We\ncharacterize lower bounds on the success of algorithmic collective action under\ndifferential privacy as a function of the collective's size and the firm's\nprivacy parameters, and verify these trends experimentally by simulating\ncollective action during the training of deep neural network classifiers across\nseveral datasets.", "AI": {"tldr": "The paper explores how grassroots Algorithmic Collective Action interacts with AI firms' methods like differential privacy, finding that privacy measures hinder collective influence.", "motivation": "To understand how everyday users can influence AI behavior through collective action and how this interacts with privacy-focused AI deployment.", "method": "Investigates the impact of Differentially Private Stochastic Gradient Descent (DPSGD) on collective action, using theoretical bounds and experimental simulations.", "result": "Differential privacy protects individual data but limits the effectiveness of collective action, with success bounds tied to collective size and privacy parameters.", "conclusion": "Privacy measures like DPSGD pose challenges for grassroots efforts to steer AI, balancing individual protection with collective influence."}}
{"id": "2505.05829", "pdf": "https://arxiv.org/pdf/2505.05829", "abs": "https://arxiv.org/abs/2505.05829", "authors": ["Zhiyuan Chen", "Keyi Li", "Yifan Jia", "Le Ye", "Yufei Ma"], "title": "Accelerating Diffusion Transformer via Increment-Calibrated Caching with Channel-Aware Singular Value Decomposition", "categories": ["cs.CV", "cs.LG", "eess.IV"], "comment": "accepted by CVPR2025", "summary": "Diffusion transformer (DiT) models have achieved remarkable success in image\ngeneration, thanks for their exceptional generative capabilities and\nscalability. Nonetheless, the iterative nature of diffusion models (DMs)\nresults in high computation complexity, posing challenges for deployment.\nAlthough existing cache-based acceleration methods try to utilize the inherent\ntemporal similarity to skip redundant computations of DiT, the lack of\ncorrection may induce potential quality degradation. In this paper, we propose\nincrement-calibrated caching, a training-free method for DiT acceleration,\nwhere the calibration parameters are generated from the pre-trained model\nitself with low-rank approximation. To deal with the possible correction\nfailure arising from outlier activations, we introduce channel-aware Singular\nValue Decomposition (SVD), which further strengthens the calibration effect.\nExperimental results show that our method always achieve better performance\nthan existing naive caching methods with a similar computation resource budget.\nWhen compared with 35-step DDIM, our method eliminates more than 45%\ncomputation and improves IS by 12 at the cost of less than 0.06 FID increase.\nCode is available at https://github.com/ccccczzy/icc.", "AI": {"tldr": "A training-free method, increment-calibrated caching, is proposed to accelerate Diffusion Transformer (DiT) models by reducing redundant computations without quality degradation.", "motivation": "The iterative nature of diffusion models leads to high computational complexity, and existing cache-based methods lack correction, risking quality loss.", "method": "The method uses low-rank approximation to generate calibration parameters from the pre-trained model and introduces channel-aware SVD for outlier handling.", "result": "The method reduces computation by over 45% compared to 35-step DDIM, improves IS by 12, and increases FID by less than 0.06.", "conclusion": "The proposed method effectively accelerates DiT models while maintaining quality, outperforming naive caching methods."}}
{"id": "2505.06145", "pdf": "https://arxiv.org/pdf/2505.06145", "abs": "https://arxiv.org/abs/2505.06145", "authors": ["Xu Han", "Yumeng Sun", "Weiqiang Huang", "Hongye Zheng", "Junliang Du"], "title": "Towards Robust Few-Shot Text Classification Using Transformer Architectures and Dual Loss Strategies", "categories": ["cs.CL", "cs.LG"], "comment": null, "summary": "Few-shot text classification has important application value in low-resource\nenvironments. This paper proposes a strategy that combines adaptive\nfine-tuning, contrastive learning, and regularization optimization to improve\nthe classification performance of Transformer-based models. Experiments on the\nFewRel 2.0 dataset show that T5-small, DeBERTa-v3, and RoBERTa-base perform\nwell in few-shot tasks, especially in the 5-shot setting, which can more\neffectively capture text features and improve classification accuracy. The\nexperiment also found that there are significant differences in the\nclassification difficulty of different relationship categories. Some categories\nhave fuzzy semantic boundaries or complex feature distributions, making it\ndifficult for the standard cross entropy loss to learn the discriminative\ninformation required to distinguish categories. By introducing contrastive loss\nand regularization loss, the generalization ability of the model is enhanced,\neffectively alleviating the overfitting problem in few-shot environments. In\naddition, the research results show that the use of Transformer models or\ngenerative architectures with stronger self-attention mechanisms can help\nimprove the stability and accuracy of few-shot classification.", "AI": {"tldr": "The paper proposes a strategy combining adaptive fine-tuning, contrastive learning, and regularization to enhance few-shot text classification for Transformer models, showing improved performance on the FewRel 2.0 dataset.", "motivation": "Few-shot text classification is valuable in low-resource settings, but challenges like fuzzy semantic boundaries and overfitting hinder performance.", "method": "The approach integrates adaptive fine-tuning, contrastive learning, and regularization optimization to improve Transformer models like T5-small, DeBERTa-v3, and RoBERTa-base.", "result": "Experiments demonstrate improved accuracy, especially in 5-shot tasks, with contrastive and regularization losses enhancing generalization and reducing overfitting.", "conclusion": "Transformer models with stronger self-attention mechanisms, combined with contrastive and regularization techniques, improve few-shot classification stability and accuracy."}}
{"id": "2505.05498", "pdf": "https://arxiv.org/pdf/2505.05498", "abs": "https://arxiv.org/abs/2505.05498", "authors": ["Noor ul Misbah Khanum", "Hayssam Dahrouj", "Ramesh C. Bansal", "Hissam Mouayad Tawfik"], "title": "An Overview of the Prospects and Challenges of Using Artificial Intelligence for Energy Management Systems in Microgrids", "categories": ["eess.SY", "cs.AI", "cs.SY"], "comment": "70 pages, 7 figures", "summary": "Microgrids have emerged as a pivotal solution in the quest for a sustainable\nand energy-efficient future. While microgrids offer numerous advantages, they\nare also prone to issues related to reliably forecasting renewable energy\ndemand and production, protecting against cyberattacks, controlling operational\ncosts, optimizing power flow, and regulating the performance of energy\nmanagement systems (EMS). Tackling these energy management challenges is\nessential to facilitate microgrid applications and seamlessly incorporate\nrenewable energy resources. Artificial intelligence (AI) has recently\ndemonstrated immense potential for optimizing energy management in microgrids,\nproviding efficient and reliable solutions. This paper highlights the combined\nbenefits of enabling AI-based methodologies in the energy management systems of\nmicrogrids by examining the applicability and efficiency of AI-based EMS in\nachieving specific technical and economic objectives. The paper also points out\nseveral future research directions that promise to spearhead AI-driven EMS,\nnamely the development of self-healing microgrids, integration with blockchain\ntechnology, use of Internet of things (IoT), and addressing interpretability,\ndata privacy, scalability, and the prospects to generative AI in the context of\nfuture AI-based EMS.", "AI": {"tldr": "AI-based energy management systems (EMS) in microgrids address challenges like demand forecasting, cybersecurity, cost control, and power flow optimization, while future research explores self-healing, blockchain, IoT, and generative AI.", "motivation": "To tackle energy management challenges in microgrids and integrate renewable energy efficiently.", "method": "Examines the applicability and efficiency of AI-based EMS for technical and economic goals.", "result": "AI shows potential in optimizing microgrid EMS, with future directions like self-healing, blockchain, and IoT.", "conclusion": "AI-driven EMS can revolutionize microgrids, but further research is needed in interpretability, privacy, and scalability."}}
{"id": "2505.05591", "pdf": "https://arxiv.org/pdf/2505.05591", "abs": "https://arxiv.org/abs/2505.05591", "authors": ["Yueh-Cheng Liu", "Lukas H\u00f6llein", "Matthias Nie\u00dfner", "Angela Dai"], "title": "QuickSplat: Fast 3D Surface Reconstruction via Learned Gaussian Initialization", "categories": ["cs.CV"], "comment": "Project page: https://liu115.github.io/quicksplat, Video:\n  https://youtu.be/2IA_gnFvFG8", "summary": "Surface reconstruction is fundamental to computer vision and graphics,\nenabling applications in 3D modeling, mixed reality, robotics, and more.\nExisting approaches based on volumetric rendering obtain promising results, but\noptimize on a per-scene basis, resulting in a slow optimization that can\nstruggle to model under-observed or textureless regions. We introduce\nQuickSplat, which learns data-driven priors to generate dense initializations\nfor 2D gaussian splatting optimization of large-scale indoor scenes. This\nprovides a strong starting point for the reconstruction, which accelerates the\nconvergence of the optimization and improves the geometry of flat wall\nstructures. We further learn to jointly estimate the densification and update\nof the scene parameters during each iteration; our proposed densifier network\npredicts new Gaussians based on the rendering gradients of existing ones,\nremoving the needs of heuristics for densification. Extensive experiments on\nlarge-scale indoor scene reconstruction demonstrate the superiority of our\ndata-driven optimization. Concretely, we accelerate runtime by 8x, while\ndecreasing depth errors by up to 48% in comparison to state of the art methods.", "AI": {"tldr": "QuickSplat introduces data-driven priors for 2D Gaussian splatting to accelerate and improve large-scale indoor scene reconstruction.", "motivation": "Existing volumetric rendering methods are slow and struggle with under-observed or textureless regions.", "method": "QuickSplat uses learned priors for dense initializations and a densifier network to predict new Gaussians based on rendering gradients.", "result": "Achieves 8x faster runtime and reduces depth errors by up to 48% compared to state-of-the-art methods.", "conclusion": "QuickSplat significantly improves efficiency and accuracy in large-scale indoor scene reconstruction."}}
{"id": "2505.05732", "pdf": "https://arxiv.org/pdf/2505.05732", "abs": "https://arxiv.org/abs/2505.05732", "authors": ["Limai Jiang", "Yunpeng Cai"], "title": "Automated Learning of Semantic Embedding Representations for Diffusion Models", "categories": ["cs.LG", "cs.CV"], "comment": "Extended version of the paper published in SDM25", "summary": "Generative models capture the true distribution of data, yielding\nsemantically rich representations. Denoising diffusion models (DDMs) exhibit\nsuperior generative capabilities, though efficient representation learning for\nthem are lacking. In this work, we employ a multi-level denoising autoencoder\nframework to expand the representation capacity of DDMs, which introduces\nsequentially consistent Diffusion Transformers and an additional\ntimestep-dependent encoder to acquire embedding representations on the\ndenoising Markov chain through self-conditional diffusion learning.\nIntuitively, the encoder, conditioned on the entire diffusion process,\ncompresses high-dimensional data into directional vectors in latent under\ndifferent noise levels, facilitating the learning of image embeddings across\nall timesteps. To verify the semantic adequacy of embeddings generated through\nthis approach, extensive experiments are conducted on various datasets,\ndemonstrating that optimally learned embeddings by DDMs surpass\nstate-of-the-art self-supervised representation learning methods in most cases,\nachieving remarkable discriminative semantic representation quality. Our work\njustifies that DDMs are not only suitable for generative tasks, but also\npotentially advantageous for general-purpose deep learning applications.", "AI": {"tldr": "The paper introduces a multi-level denoising autoencoder framework to enhance the representation learning of Denoising Diffusion Models (DDMs), achieving superior semantic embeddings compared to existing methods.", "motivation": "DDMs excel in generative tasks but lack efficient representation learning. This work aims to bridge this gap by improving their capacity for semantic embedding generation.", "method": "A multi-level denoising autoencoder framework is proposed, incorporating Diffusion Transformers and a timestep-dependent encoder for self-conditional diffusion learning.", "result": "Experiments show the learned embeddings outperform state-of-the-art self-supervised methods, demonstrating high discriminative semantic quality.", "conclusion": "DDMs are not only effective for generation but also promising for general-purpose deep learning due to their enhanced representation capabilities."}}
{"id": "2505.05870", "pdf": "https://arxiv.org/pdf/2505.05870", "abs": "https://arxiv.org/abs/2505.05870", "authors": ["Yimin Zhou", "Yichong Xia", "Bin Chen", "Baoyi An", "Haoqian Wang", "Zhi Wang", "Yaowei Wang", "Zikun Zhou"], "title": "Towards Facial Image Compression with Consistency Preserving Diffusion Prior", "categories": ["cs.CV", "cs.AI", "eess.IV"], "comment": null, "summary": "With the widespread application of facial image data across various domains,\nthe efficient storage and transmission of facial images has garnered\nsignificant attention. However, the existing learned face image compression\nmethods often produce unsatisfactory reconstructed image quality at low bit\nrates. Simply adapting diffusion-based compression methods to facial\ncompression tasks results in reconstructed images that perform poorly in\ndownstream applications due to insufficient preservation of high-frequency\ninformation. To further explore the diffusion prior in facial image\ncompression, we propose Facial Image Compression with a Stable Diffusion Prior\n(FaSDiff), a method that preserves consistency through frequency enhancement.\nFaSDiff employs a high-frequency-sensitive compressor in an end-to-end\nframework to capture fine image details and produce robust visual prompts.\nAdditionally, we introduce a hybrid low-frequency enhancement module that\ndisentangles low-frequency facial semantics and stably modulates the diffusion\nprior alongside visual prompts. The proposed modules allow FaSDiff to leverage\ndiffusion priors for superior human visual perception while minimizing\nperformance loss in machine vision due to semantic inconsistency. Extensive\nexperiments show that FaSDiff outperforms state-of-the-art methods in balancing\nhuman visual quality and machine vision accuracy. The code will be released\nafter the paper is accepted.", "AI": {"tldr": "FaSDiff improves facial image compression by using a stable diffusion prior and frequency enhancement, balancing human visual quality and machine vision accuracy.", "motivation": "Existing methods fail to preserve high-frequency details at low bit rates, leading to poor reconstructed image quality and downstream performance.", "method": "FaSDiff combines a high-frequency-sensitive compressor and a hybrid low-frequency enhancement module to leverage diffusion priors for better image quality.", "result": "FaSDiff outperforms state-of-the-art methods in both human visual quality and machine vision accuracy.", "conclusion": "FaSDiff effectively balances human and machine vision needs, offering superior performance in facial image compression."}}
{"id": "2505.06150", "pdf": "https://arxiv.org/pdf/2505.06150", "abs": "https://arxiv.org/abs/2505.06150", "authors": ["Ryan Lagasse", "Aidan Kiernans", "Avijit Ghosh", "Shiri Dori-Hacohen"], "title": "A Scaling Law for Token Efficiency in LLM Fine-Tuning Under Fixed Compute Budgets", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "We introduce a scaling law for fine-tuning large language models (LLMs) under\nfixed compute budgets that explicitly accounts for data composition.\nConventional approaches measure training data solely by total tokens, yet the\nnumber of examples and their average token length -- what we term \\emph{dataset\nvolume} -- play a decisive role in model performance. Our formulation is tuned\nfollowing established procedures. Experiments on the BRICC dataset\n\\cite{salavati2024reducing} and subsets of the MMLU dataset\n\\cite{hendrycks2021measuringmassivemultitasklanguage}, evaluated under multiple\nsubsampling strategies, reveal that data composition significantly affects\ntoken efficiency. These results motivate refined scaling laws for practical LLM\nfine-tuning in resource-constrained settings.", "AI": {"tldr": "The paper introduces a scaling law for fine-tuning LLMs that considers data composition (dataset volume) alongside total tokens, showing its impact on model performance and token efficiency.", "motivation": "Current scaling laws overlook data composition (number of examples and average token length), which is critical for efficient fine-tuning under fixed compute budgets.", "method": "The study formulates a new scaling law, validated through experiments on the BRICC and MMLU datasets using subsampling strategies.", "result": "Data composition significantly affects token efficiency, demonstrating the need for refined scaling laws.", "conclusion": "The findings advocate for incorporating dataset volume into scaling laws for practical LLM fine-tuning in resource-limited scenarios."}}
{"id": "2505.05516", "pdf": "https://arxiv.org/pdf/2505.05516", "abs": "https://arxiv.org/abs/2505.05516", "authors": ["Yue Wu", "Yibo Guo", "Yulong Yan", "Jiancheng Yang", "Xin Zhou", "Ching-Yu Cheng", "Danli Shi", "Mingguang He"], "title": "AI-powered virtual eye: perspective, challenges and opportunities", "categories": ["q-bio.TO", "cs.AI", "cs.HC"], "comment": "30 Pages, 3 figures, 1 table", "summary": "We envision the \"virtual eye\" as a next-generation, AI-powered platform that\nuses interconnected foundation models to simulate the eye's intricate structure\nand biological function across all scales. Advances in AI, imaging, and\nmultiomics provide a fertile ground for constructing a universal, high-fidelity\ndigital replica of the human eye. This perspective traces the evolution from\nearly mechanistic and rule-based models to contemporary AI-driven approaches,\nintegrating in a unified model with multimodal, multiscale, dynamic predictive\ncapabilities and embedded feedback mechanisms. We propose a development roadmap\nemphasizing the roles of large-scale multimodal datasets, generative AI,\nfoundation models, agent-based architectures, and interactive interfaces.\nDespite challenges in interpretability, ethics, data processing and evaluation,\nthe virtual eye holds the potential to revolutionize personalized ophthalmic\ncare and accelerate research into ocular health and disease.", "AI": {"tldr": "The paper proposes a \"virtual eye\" AI platform using foundation models to simulate the eye's structure and function, aiming to revolutionize ophthalmic care and research.", "motivation": "To create a high-fidelity digital replica of the human eye by leveraging AI, imaging, and multiomics, addressing gaps in current models.", "method": "Integrates AI-driven approaches, multimodal datasets, generative AI, foundation models, agent-based architectures, and interactive interfaces.", "result": "A unified model with dynamic predictive capabilities and feedback mechanisms, though challenges like interpretability and ethics remain.", "conclusion": "The virtual eye could transform personalized ophthalmic care and advance ocular health research, despite existing hurdles."}}
{"id": "2505.05599", "pdf": "https://arxiv.org/pdf/2505.05599", "abs": "https://arxiv.org/abs/2505.05599", "authors": ["Seraj Al Mahmud Mostafa", "Chenxi Wang", "Jia Yue", "Yuta Hozumi", "Jianwu Wang"], "title": "Enhancing Satellite Object Localization with Dilated Convolutions and Attention-aided Spatial Pooling", "categories": ["cs.CV", "cs.AI"], "comment": "This paper has been accepted to International conference on Advanced\n  Machine Learning and Data Science (AMLDS) 2025", "summary": "Object localization in satellite imagery is particularly challenging due to\nthe high variability of objects, low spatial resolution, and interference from\nnoise and dominant features such as clouds and city lights. In this research,\nwe focus on three satellite datasets: upper atmospheric Gravity Waves (GW),\nmesospheric Bores (Bore), and Ocean Eddies (OE), each presenting its own unique\nchallenges. These challenges include the variability in the scale and\nappearance of the main object patterns, where the size, shape, and feature\nextent of objects of interest can differ significantly. To address these\nchallenges, we introduce YOLO-DCAP, a novel enhanced version of YOLOv5 designed\nto improve object localization in these complex scenarios. YOLO-DCAP\nincorporates a Multi-scale Dilated Residual Convolution (MDRC) block to capture\nmulti-scale features at scale with varying dilation rates, and an\nAttention-aided Spatial Pooling (AaSP) module to focus on the global relevant\nspatial regions, enhancing feature selection. These structural improvements\nhelp to better localize objects in satellite imagery. Experimental results\ndemonstrate that YOLO-DCAP significantly outperforms both the YOLO base model\nand state-of-the-art approaches, achieving an average improvement of 20.95% in\nmAP50 and 32.23% in IoU over the base model, and 7.35% and 9.84% respectively\nover state-of-the-art alternatives, consistently across all three satellite\ndatasets. These consistent gains across all three satellite datasets highlight\nthe robustness and generalizability of the proposed approach. Our code is open\nsourced at\nhttps://github.com/AI-4-atmosphere-remote-sensing/satellite-object-localization.", "AI": {"tldr": "YOLO-DCAP, an enhanced YOLOv5, improves object localization in satellite imagery using multi-scale and attention mechanisms, outperforming base and state-of-the-art models.", "motivation": "Challenges in satellite object localization include high variability, low resolution, and noise. Addressing these for GW, Bore, and OE datasets.", "method": "Introduces YOLO-DCAP with Multi-scale Dilated Residual Convolution (MDRC) and Attention-aided Spatial Pooling (AaSP) modules.", "result": "Achieves 20.95% mAP50 and 32.23% IoU improvement over base model, 7.35% and 9.84% over alternatives.", "conclusion": "YOLO-DCAP is robust and generalizable, with open-sourced code for satellite object localization."}}
{"id": "2505.05738", "pdf": "https://arxiv.org/pdf/2505.05738", "abs": "https://arxiv.org/abs/2505.05738", "authors": ["Yiming Niu", "Jinliang Deng", "Lulu Zhang", "Zimu Zhou", "Yongxin Tong"], "title": "Accurate and Efficient Multivariate Time Series Forecasting via Offline Clustering", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Accurate and efficient multivariate time series (MTS) forecasting is\nessential for applications such as traffic management and weather prediction,\nwhich depend on capturing long-range temporal dependencies and interactions\nbetween entities. Existing methods, particularly those based on Transformer\narchitectures, compute pairwise dependencies across all time steps, leading to\na computational complexity that scales quadratically with the length of the\ninput. To overcome these challenges, we introduce the Forecaster with Offline\nClustering Using Segments (FOCUS), a novel approach to MTS forecasting that\nsimplifies long-range dependency modeling through the use of prototypes\nextracted via offline clustering. These prototypes encapsulate high-level\nevents in the real-world system underlying the data, summarizing the key\ncharacteristics of similar time segments. In the online phase, FOCUS\ndynamically adapts these patterns to the current input and captures\ndependencies between the input segment and high-level events, enabling both\naccurate and efficient forecasting. By identifying prototypes during the\noffline clustering phase, FOCUS reduces the computational complexity of\nmodeling long-range dependencies in the online phase to linear scaling.\nExtensive experiments across diverse benchmarks demonstrate that FOCUS achieves\nstate-of-the-art accuracy while significantly reducing computational costs.", "AI": {"tldr": "FOCUS introduces offline clustering to simplify long-range dependency modeling in MTS forecasting, reducing computational complexity while maintaining accuracy.", "motivation": "Existing Transformer-based methods for MTS forecasting suffer from high computational complexity due to pairwise dependency calculations.", "method": "FOCUS uses offline clustering to extract prototypes summarizing key time segments, then dynamically adapts these in the online phase for efficient forecasting.", "result": "FOCUS achieves state-of-the-art accuracy with linear computational complexity, outperforming existing methods.", "conclusion": "FOCUS offers an efficient and accurate solution for MTS forecasting by leveraging offline clustering and dynamic adaptation."}}
{"id": "2505.06073", "pdf": "https://arxiv.org/pdf/2505.06073", "abs": "https://arxiv.org/abs/2505.06073", "authors": ["Rodrigo A. Lobos", "Javier Salazar Cavazos", "Raj Rao Nadakuditi", "Jeffrey A. Fessler"], "title": "Smooth optimization algorithms for global and locally low-rank regularizers", "categories": ["eess.SP", "eess.IV"], "comment": "41 pages, 7 figures", "summary": "Many inverse problems and signal processing problems involve low-rank\nregularizers based on the nuclear norm. Commonly, proximal gradient methods\n(PGM) are adopted to solve this type of non-smooth problems as they can offer\nfast and guaranteed convergence. However, PGM methods cannot be simply applied\nin settings where low-rank models are imposed locally on overlapping patches;\ntherefore, heuristic approaches have been proposed that lack convergence\nguarantees. In this work we propose to replace the nuclear norm with a smooth\napproximation in which a Huber-type function is applied to each singular value.\nBy providing a theoretical framework based on singular value function theory,\nwe show that important properties can be established for the proposed\nregularizer, such as: convexity, differentiability, and Lipschitz continuity of\nthe gradient. Moreover, we provide a closed-form expression for the regularizer\ngradient, enabling the use of standard iterative gradient-based optimization\nalgorithms (e.g., nonlinear conjugate gradient) that can easily address the\ncase of overlapping patches and have well-known convergence guarantees. In\naddition, we provide a novel step-size selection strategy based on a quadratic\nmajorizer of the line-search function that leverages the Huber characteristics\nof the proposed regularizer. Finally, we assess the proposed optimization\nframework by providing empirical results in dynamic magnetic resonance imaging\n(MRI) reconstruction in the context of locally low-rank models with overlapping\npatches.", "AI": {"tldr": "The paper proposes a smooth approximation of the nuclear norm using a Huber-type function for low-rank regularization, enabling gradient-based optimization with convergence guarantees for overlapping patches.", "motivation": "Existing proximal gradient methods (PGM) for low-rank regularization fail in overlapping patch settings, leading to heuristic solutions without convergence guarantees.", "method": "Replace the nuclear norm with a smooth Huber-type approximation, derive its properties (convexity, differentiability, Lipschitz gradient), and use gradient-based optimization with a novel step-size strategy.", "result": "Theoretical framework and empirical results in dynamic MRI reconstruction demonstrate the effectiveness of the proposed method for locally low-rank models with overlapping patches.", "conclusion": "The smooth Huber-type approximation enables efficient and convergent optimization for low-rank regularization in overlapping patch settings, validated by MRI reconstruction results."}}
{"id": "2505.06151", "pdf": "https://arxiv.org/pdf/2505.06151", "abs": "https://arxiv.org/abs/2505.06151", "authors": ["Alice Rueda", "Argyrios Perivolaris", "Niloy Roy", "Dylan Weston", "Sarmed Shaya", "Zachary Cote", "Martin Ivanov", "Bazen G. Teferra", "Yuqi Wu", "Sirisha Rambhatla", "Divya Sharma", "Andrew Greenshaw", "Rakesh Jetly", "Yanbo Zhang", "Bo Cao", "Reza Samavi", "Sridhar Krishnan", "Venkat Bhat"], "title": "Estimating Quality in Therapeutic Conversations: A Multi-Dimensional Natural Language Processing Framework", "categories": ["cs.CL"], "comment": "12 pages, 4 figures, 7 tables", "summary": "Engagement between client and therapist is a critical determinant of\ntherapeutic success. We propose a multi-dimensional natural language processing\n(NLP) framework that objectively classifies engagement quality in counseling\nsessions based on textual transcripts. Using 253 motivational interviewing\ntranscripts (150 high-quality, 103 low-quality), we extracted 42 features\nacross four domains: conversational dynamics, semantic similarity as topic\nalignment, sentiment classification, and question detection. Classifiers,\nincluding Random Forest (RF), Cat-Boost, and Support Vector Machines (SVM),\nwere hyperparameter tuned and trained using a stratified 5-fold\ncross-validation and evaluated on a holdout test set. On balanced\n(non-augmented) data, RF achieved the highest classification accuracy (76.7%),\nand SVM achieved the highest AUC (85.4%). After SMOTE-Tomek augmentation,\nperformance improved significantly: RF achieved up to 88.9% accuracy, 90.0%\nF1-score, and 94.6% AUC, while SVM reached 81.1% accuracy, 83.1% F1-score, and\n93.6% AUC. The augmented data results reflect the potential of the framework in\nfuture larger-scale applications. Feature contribution revealed conversational\ndynamics and semantic similarity between clients and therapists were among the\ntop contributors, led by words uttered by the client (mean and standard\ndeviation). The framework was robust across the original and augmented datasets\nand demonstrated consistent improvements in F1 scores and recall. While\ncurrently text-based, the framework supports future multimodal extensions\n(e.g., vocal tone, facial affect) for more holistic assessments. This work\nintroduces a scalable, data-driven method for evaluating engagement quality of\nthe therapy session, offering clinicians real-time feedback to enhance the\nquality of both virtual and in-person therapeutic interactions.", "AI": {"tldr": "A multi-dimensional NLP framework classifies engagement quality in therapy sessions using conversational dynamics, semantic similarity, sentiment, and question detection. Random Forest and SVM showed high accuracy and AUC, especially after data augmentation.", "motivation": "To objectively assess and improve engagement quality in therapy sessions, which is critical for therapeutic success.", "method": "Extracted 42 features from 253 transcripts across four domains, trained classifiers (RF, Cat-Boost, SVM) with hyperparameter tuning and cross-validation, and evaluated performance on augmented and non-augmented data.", "result": "RF achieved 88.9% accuracy and 94.6% AUC after augmentation. Conversational dynamics and semantic similarity were top contributors.", "conclusion": "The framework is scalable and robust, with potential for multimodal extensions, offering real-time feedback to enhance therapy quality."}}
{"id": "2505.05523", "pdf": "https://arxiv.org/pdf/2505.05523", "abs": "https://arxiv.org/abs/2505.05523", "authors": ["Anna Kusetogullari", "Huseyin Kusetogullari", "Martin Andersson", "Tony Gorschek"], "title": "GenAI in Entrepreneurship: a systematic review of generative artificial intelligence in entrepreneurship research: current issues and future directions", "categories": ["econ.GN", "cs.AI", "q-fin.EC"], "comment": null, "summary": "Generative Artificial Intelligence (GenAI) and Large Language Models (LLMs)\nare recognized to have significant effects on industry and business dynamics,\nnot least because of their impact on the preconditions for entrepreneurship.\nThere is still a lack of knowledge of GenAI as a theme in entrepreneurship\nresearch. This paper presents a systematic literature review aimed at\nidentifying and analyzing the evolving landscape of research on the effects of\nGenAI on entrepreneurship. We analyze 83 peer-reviewed articles obtained from\nleading academic databases: Web of Science and Scopus. Using natural language\nprocessing and unsupervised machine learning techniques with TF-IDF\nvectorization, Principal Component Analysis (PCA), and hierarchical clustering,\nfive major thematic clusters are identified: (1) Digital Transformation and\nBehavioral Models, (2) GenAI-Enhanced Education and Learning Systems, (3)\nSustainable Innovation and Strategic AI Impact, (4) Business Models and Market\nTrends, and (5) Data-Driven Technological Trends in Entrepreneurship. Based on\nthe review, we discuss future research directions, gaps in the current\nliterature, as well as ethical concerns raised in the literature. We highlight\nthe need for more macro-level research on GenAI and LLMs as external enablers\nfor entrepreneurship and for research on effective regulatory frameworks that\nfacilitate business experimentation, innovation, and further technology\ndevelopment.", "AI": {"tldr": "A systematic review of 83 articles explores GenAI's impact on entrepreneurship, identifying five thematic clusters and calling for more macro-level research and regulatory frameworks.", "motivation": "To address the lack of knowledge on GenAI's role in entrepreneurship and its effects on industry dynamics.", "method": "Systematic literature review using NLP, unsupervised machine learning (TF-IDF, PCA, hierarchical clustering) on articles from Web of Science and Scopus.", "result": "Identified five thematic clusters: Digital Transformation, GenAI-Enhanced Education, Sustainable Innovation, Business Models, and Data-Driven Trends.", "conclusion": "Highlights gaps in macro-level research and ethical concerns, advocating for studies on regulatory frameworks to support innovation."}}
{"id": "2505.05621", "pdf": "https://arxiv.org/pdf/2505.05621", "abs": "https://arxiv.org/abs/2505.05621", "authors": ["Hao Yang", "Yan Yang", "Ruikun Zhang", "Liyuan Pan"], "title": "A Preliminary Study for GPT-4o on Image Restoration", "categories": ["cs.CV"], "comment": null, "summary": "OpenAI's GPT-4o model, integrating multi-modal inputs and outputs within an\nautoregressive architecture, has demonstrated unprecedented performance in\nimage generation. In this work, we investigate its potential impact on the\nimage restoration community. We present the first systematic evaluation of\nGPT-4o across diverse restoration tasks. Our experiments reveal that, although\nrestoration outputs from GPT-4o are visually appealing, they often suffer from\npixel-level structural fidelity when compared to ground-truth images. Common\nissues are variations in image proportions, shifts in object positions and\nquantities, and changes in viewpoint.To address it, taking image dehazing,\nderainning, and low-light enhancement as representative case studies, we show\nthat GPT-4o's outputs can serve as powerful visual priors, substantially\nenhancing the performance of existing dehazing networks. It offers practical\nguidelines and a baseline framework to facilitate the integration of GPT-4o\ninto future image restoration pipelines. We hope the study on GPT-4o image\nrestoration will accelerate innovation in the broader field of image generation\nareas. To support further research, we will release GPT-4o-restored images from\nover 10 widely used image restoration datasets.", "AI": {"tldr": "GPT-4o shows promise in image restoration but lacks pixel-level fidelity. Its outputs serve as strong visual priors, improving existing dehazing networks.", "motivation": "To explore GPT-4o's impact on image restoration and address its limitations in structural fidelity.", "method": "Systematic evaluation of GPT-4o across diverse restoration tasks, focusing on dehazing, deraining, and low-light enhancement.", "result": "GPT-4o outputs are visually appealing but lack structural accuracy. They enhance existing dehazing networks as priors.", "conclusion": "GPT-4o can advance image restoration by providing visual priors, with guidelines for future integration."}}
{"id": "2505.05740", "pdf": "https://arxiv.org/pdf/2505.05740", "abs": "https://arxiv.org/abs/2505.05740", "authors": ["Xi He", "Yi Miao", "Max A. Little"], "title": "Deep-ICE: The first globally optimal algorithm for empirical risk minimization of two-layer maxout and ReLU networks", "categories": ["cs.LG"], "comment": null, "summary": "This paper introduces the first globally optimal algorithm for the empirical\nrisk minimization problem of two-layer maxout and ReLU networks, i.e.,\nminimizing the number of misclassifications. The algorithm has a worst-case\ntime complexity of $O\\left(N^{DK+1}\\right)$, where $K$ denotes the number of\nhidden neurons and $D$ represents the number of features. It can be can be\ngeneralized to accommodate arbitrary computable loss functions without\naffecting its computational complexity. Our experiments demonstrate that the\nproposed algorithm provides provably exact solutions for small-scale datasets.\nTo handle larger datasets, we introduce a novel coreset selection method that\nreduces the data size to a manageable scale, making it feasible for our\nalgorithm. This extension enables efficient processing of large-scale datasets\nand achieves significantly improved performance, with a 20-30\\% reduction in\nmisclassifications for both training and prediction, compared to\nstate-of-the-art approaches (neural networks trained using gradient descent and\nsupport vector machines), when applied to the same models (two-layer networks\nwith fixed hidden nodes and linear models).", "AI": {"tldr": "A globally optimal algorithm for empirical risk minimization in two-layer maxout and ReLU networks is introduced, with a worst-case complexity of O(N^(DK+1)). It provides exact solutions for small datasets and uses coreset selection for scalability, outperforming state-of-the-art methods by 20-30% in misclassification reduction.", "motivation": "To address the challenge of minimizing misclassifications in two-layer neural networks (maxout and ReLU) with provable optimality, especially for small datasets, and to extend this to larger datasets efficiently.", "method": "The algorithm has a worst-case time complexity of O(N^(DK+1)) and can generalize to arbitrary loss functions. For larger datasets, a coreset selection method reduces data size for feasibility.", "result": "Exact solutions for small datasets; 20-30% reduction in misclassifications for training and prediction compared to gradient descent-trained neural networks and SVMs.", "conclusion": "The proposed algorithm offers provably optimal solutions for small datasets and scalable performance for larger ones, significantly improving misclassification rates over existing methods."}}
{"id": "2408.08456", "pdf": "https://arxiv.org/pdf/2408.08456", "abs": "https://arxiv.org/abs/2408.08456", "authors": ["Yusen Wu", "Phuong Nguyen", "Rose Yesha", "Yelena Yesha"], "title": "Distributional Drift Detection in Medical Imaging with Sketching and Fine-Tuned Transformer", "categories": ["eess.IV", "cs.AI", "cs.CV", "cs.LG"], "comment": null, "summary": "Distributional drift detection is important in medical applications as it\nhelps ensure the accuracy and reliability of models by identifying changes in\nthe underlying data distribution that could affect the prediction results of\nmachine learning models. However, current methods have limitations in detecting\ndrift, for example, the inclusion of abnormal datasets can lead to unfair\ncomparisons. This paper presents an accurate and sensitive approach to detect\ndistributional drift in CT-scan medical images by leveraging data-sketching and\nfine-tuning techniques. We developed a robust baseline library model for\nreal-time anomaly detection, allowing for efficient comparison of incoming\nimages and identification of anomalies. Additionally, we fine-tuned a\npre-trained Vision Transformer model to extract relevant features, using\nmammography as a case study, significantly enhancing model accuracy to 99.11%.\nCombining with data-sketches and fine-tuning, our feature extraction evaluation\ndemonstrated that cosine similarity scores between similar datasets provide\ngreater improvements, from around 50% increased to 99.1%. Finally, the\nsensitivity evaluation shows that our solutions are highly sensitive to even 1%\nsalt-and-pepper and speckle noise, and it is not sensitive to lighting noise\n(e.g., lighting conditions have no impact on data drift). The proposed methods\noffer a scalable and reliable solution for maintaining the accuracy of\ndiagnostic models in dynamic clinical environments.", "AI": {"tldr": "The paper introduces a sensitive and accurate method for detecting distributional drift in CT-scan medical images using data-sketching and fine-tuning, achieving high accuracy (99.11%) and robustness against noise.", "motivation": "Ensuring model reliability in medical applications by detecting data distribution changes that could impact predictions, addressing limitations of current drift detection methods.", "method": "Combines data-sketching for real-time anomaly detection and fine-tunes a Vision Transformer model for feature extraction, validated on mammography data.", "result": "Achieved 99.11% accuracy, improved cosine similarity scores (50% to 99.1%), and high sensitivity to noise (1% salt-and-pepper/speckle), unaffected by lighting conditions.", "conclusion": "The proposed scalable solution enhances diagnostic model accuracy in dynamic clinical settings."}}
{"id": "2505.06186", "pdf": "https://arxiv.org/pdf/2505.06186", "abs": "https://arxiv.org/abs/2505.06186", "authors": ["Massimiliano Pronesti", "Joao Bettencourt-Silva", "Paul Flanagan", "Alessandra Pascale", "Oisin Redmond", "Anya Belz", "Yufang Hou"], "title": "Query-driven Document-level Scientific Evidence Extraction from Biomedical Studies", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Extracting scientific evidence from biomedical studies for clinical research\nquestions (e.g., Does stem cell transplantation improve quality of life in\npatients with medically refractory Crohn's disease compared to placebo?) is a\ncrucial step in synthesising biomedical evidence. In this paper, we focus on\nthe task of document-level scientific evidence extraction for clinical\nquestions with conflicting evidence. To support this task, we create a dataset\ncalled CochraneForest, leveraging forest plots from Cochrane systematic\nreviews. It comprises 202 annotated forest plots, associated clinical research\nquestions, full texts of studies, and study-specific conclusions. Building on\nCochraneForest, we propose URCA (Uniform Retrieval Clustered Augmentation), a\nretrieval-augmented generation framework designed to tackle the unique\nchallenges of evidence extraction. Our experiments show that URCA outperforms\nthe best existing methods by up to 10.3% in F1 score on this task. However, the\nresults also underscore the complexity of CochraneForest, establishing it as a\nchallenging testbed for advancing automated evidence synthesis systems.", "AI": {"tldr": "The paper introduces CochraneForest, a dataset for document-level scientific evidence extraction, and URCA, a retrieval-augmented framework, which outperforms existing methods by 10.3% in F1 score.", "motivation": "To address the challenge of extracting scientific evidence for clinical questions with conflicting evidence, particularly for synthesizing biomedical evidence.", "method": "Creation of the CochraneForest dataset (202 annotated forest plots) and development of URCA, a retrieval-augmented generation framework.", "result": "URCA outperforms existing methods by up to 10.3% in F1 score, but the dataset's complexity highlights its challenge.", "conclusion": "CochraneForest serves as a challenging testbed for advancing automated evidence synthesis, with URCA showing promising performance."}}
{"id": "2505.05543", "pdf": "https://arxiv.org/pdf/2505.05543", "abs": "https://arxiv.org/abs/2505.05543", "authors": ["Ahdiyeh Alipour", "Tilo Hartmann", "Maryam Alimardani"], "title": "Would You Rely on an Eerie Agent? A Systematic Review of the Impact of the Uncanny Valley Effect on Trust in Human-Agent Interaction", "categories": ["cs.HC", "cs.AI", "cs.CY"], "comment": "75 pages, Figure 11, Table 5", "summary": "Trust is a fundamental component of human-agent interaction. With the\nincreasing presence of artificial agents in daily life, it is essential to\nunderstand how people perceive and trust these agents. One of the key\nchallenges affecting this perception is the Uncanny Valley Effect (UVE), where\nincreasingly human-like artificial beings can be perceived as eerie or\nrepelling. Despite growing interest in trust and the UVE, existing research\nvaries widely in terms of how these concepts are defined and operationalized.\nThis inconsistency raises important questions about how and under what\nconditions the UVE influences trust in agents. A systematic understanding of\ntheir relationship is currently lacking. This review aims to examine the impact\nof the UVE on human trust in agents and to identify methodological patterns,\nlimitations, and gaps in the existing empirical literature. Following PRISMA\nguidelines, a systematic search identified 53 empirical studies that\ninvestigated both UVE-related constructs and trust or trust-related outcomes.\nStudies were analyzed based on a structured set of categories, including types\nof agents and interactions, methodological and measurement approaches, and key\nfindings. The results of our systematic review reveal that most studies rely on\nstatic images or hypothetical scenarios with limited real-time interaction, and\nthe majority use subjective trust measures. This review offers a novel\nframework for classifying trust measurement approaches with regard to the\nbest-practice criteria for empirically investigating the UVE. As the first\nsystematic attempt to map the intersection of UVE and trust, this review\ncontributes to a deeper understanding of their interplay and offers a\nfoundation for future research. Keywords: the uncanny valley effect, trust,\nhuman-likeness, affinity response, human-agent interaction", "AI": {"tldr": "This review systematically examines the impact of the Uncanny Valley Effect (UVE) on human trust in artificial agents, identifying methodological gaps and proposing a framework for future research.", "motivation": "To address inconsistencies in defining and operationalizing trust and the UVE, and to systematically understand their relationship in human-agent interaction.", "method": "A systematic review of 53 empirical studies following PRISMA guidelines, analyzing agent types, interaction methods, measurement approaches, and key findings.", "result": "Most studies use static images or hypothetical scenarios with subjective trust measures, highlighting a lack of real-time interaction and standardized methods.", "conclusion": "The review provides a novel framework for trust measurement and UVE investigation, laying groundwork for future research in human-agent trust dynamics."}}
{"id": "2505.05626", "pdf": "https://arxiv.org/pdf/2505.05626", "abs": "https://arxiv.org/abs/2505.05626", "authors": ["Aarti Ghatkesar", "Uddeshya Upadhyay", "Ganesh Venkatesh"], "title": "Looking Beyond Language Priors: Enhancing Visual Comprehension and Attention in Multimodal Models", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Achieving deep alignment between vision and language remains a central\nchallenge for Multimodal Large Language Models (MLLMs). These models often fail\nto fully leverage visual input, defaulting to strong language priors. Our\napproach first provides insights into how MLLMs internally build visual\nunderstanding of image regions and then introduces techniques to amplify this\ncapability. Specifically, we explore techniques designed both to deepen the\nmodel's understanding of visual content and to ensure that these visual\ninsights actively guide language generation. We demonstrate the superior\nmultimodal understanding of our resultant model through a detailed upstream\nanalysis quantifying its ability to predict visually-dependent tokens as well\nas 10 pt boost on visually challenging tasks.", "AI": {"tldr": "The paper addresses the challenge of deep alignment between vision and language in MLLMs, proposing techniques to enhance visual understanding and its influence on language generation.", "motivation": "MLLMs often rely too heavily on language priors, failing to fully utilize visual input, which limits their multimodal capabilities.", "method": "The approach involves analyzing how MLLMs build visual understanding and introducing techniques to deepen visual comprehension and guide language generation.", "result": "The improved model shows better multimodal understanding, evidenced by superior prediction of visually-dependent tokens and a 10-point boost on visually challenging tasks.", "conclusion": "The proposed techniques effectively enhance MLLMs' visual understanding and alignment with language, improving performance on multimodal tasks."}}
{"id": "2505.05744", "pdf": "https://arxiv.org/pdf/2505.05744", "abs": "https://arxiv.org/abs/2505.05744", "authors": ["Ruxue Shi", "Hengrui Gu", "Xu Shen", "Xin Wang"], "title": "Harnessing LLMs Explanations to Boost Surrogate Models in Tabular Data Classification", "categories": ["cs.LG", "cs.CL"], "comment": null, "summary": "Large Language Models (LLMs) have shown remarkable ability in solving complex\ntasks, making them a promising tool for enhancing tabular learning. However,\nexisting LLM-based methods suffer from high resource requirements, suboptimal\ndemonstration selection, and limited interpretability, which largely hinder\ntheir prediction performance and application in the real world. To overcome\nthese problems, we propose a novel in-context learning framework for tabular\nprediction. The core idea is to leverage the explanations generated by LLMs to\nguide a smaller, locally deployable Surrogate Language Model (SLM) to make\ninterpretable tabular predictions. Specifically, our framework mainly involves\nthree stages: (i) Post Hoc Explanation Generation, where LLMs are utilized to\ngenerate explanations for question-answer pairs in candidate demonstrations,\nproviding insights into the reasoning behind the answer. (ii) Post Hoc\nExplanation-Guided Demonstrations Selection, which utilizes explanations\ngenerated by LLMs to guide the process of demonstration selection from\ncandidate demonstrations. (iii) Post Hoc Explanation-Guided Interpretable SLM\nPrediction, which utilizes the demonstrations obtained in step (ii) as\nin-context and merges corresponding explanations as rationales to improve the\nperformance of SLM and guide the model to generate interpretable outputs.\nExperimental results highlight the framework's effectiveness, with an average\naccuracy improvement of 5.31% across various tabular datasets in diverse\ndomains.", "AI": {"tldr": "A novel in-context learning framework improves tabular prediction by using LLM-generated explanations to guide a smaller, interpretable Surrogate Language Model (SLM).", "motivation": "Existing LLM-based methods for tabular learning face issues like high resource demands, poor demonstration selection, and low interpretability, limiting real-world application.", "method": "The framework involves three stages: generating LLM explanations for demonstrations, selecting demonstrations based on these explanations, and using them to train an interpretable SLM.", "result": "The framework achieves an average accuracy improvement of 5.31% across diverse tabular datasets.", "conclusion": "The proposed method enhances performance and interpretability in tabular prediction, addressing key limitations of current LLM-based approaches."}}
{"id": "2501.15246", "pdf": "https://arxiv.org/pdf/2501.15246", "abs": "https://arxiv.org/abs/2501.15246", "authors": ["Vinith Kishore", "Valentin Debarnot", "Ricardo D. Righetto", "AmirEhsan Khorashadizadeh", "Benjamin D. Engel", "Ivan Dokmani\u0107"], "title": "End-to-end localized deep learning for Cryo-ET", "categories": ["eess.IV"], "comment": null, "summary": "Cryo-electron tomography (cryo-ET) enables 3D visualization of cellular\nenvironments. Accurate reconstruction of high-resolution volumes is complicated\nby the very low signal-to-noise ratio and a restricted range of sample tilts,\ncreating a missing wedge of Fourier information. Recent self-supervised deep\nlearning approaches, which post-process initial reconstructions done by\nfiltered backprojection (FBP), have significantly improved reconstruction\nquality, but they are computationally expensive, demand large memory, and\nrequire retraining for each new dataset. End-to-end supervised learning is an\nappealing alternative but is impeded by the lack of ground truth and the large\nmemory demands of high-resolution volumetric data. Training on synthetic data\noften leads to overfitting and poor generalization to real data, and, to date,\nno general end-to-end deep learning reconstructors exist for cryo-ET. In this\nwork, we introduce CryoLithe, a local, memory-efficient reconstruction network\nthat directly estimates the volume from an aligned tilt-series, overcoming the\nsuboptimal FBP. We demonstrate that leveraging transform-domain locality makes\nour network robust to distribution shifts, enabling effective supervised\ntraining and giving excellent results on real data -- without retraining or\nfine-tuning.", "AI": {"tldr": "CryoLithe is a memory-efficient, end-to-end deep learning network for cryo-ET reconstruction, overcoming limitations of traditional methods like FBP and avoiding retraining for new datasets.", "motivation": "Current cryo-ET reconstruction methods face challenges like high computational costs, memory demands, and lack of ground truth for supervised learning. CryoLithe aims to address these issues.", "method": "CryoLithe uses a local, transform-domain approach to directly estimate volumes from aligned tilt-series, avoiding the need for retraining or fine-tuning.", "result": "The method demonstrates robustness to distribution shifts and achieves excellent results on real data without retraining.", "conclusion": "CryoLithe provides a practical, efficient solution for high-resolution cryo-ET reconstruction, outperforming existing methods."}}
{"id": "2505.05665", "pdf": "https://arxiv.org/pdf/2505.05665", "abs": "https://arxiv.org/abs/2505.05665", "authors": ["Neeloy Chakraborty", "John Pohovey", "Melkior Ornik", "Katherine Driggs-Campbell"], "title": "Adaptive Stress Testing Black-Box LLM Planners", "categories": ["cs.RO", "cs.AI", "cs.CL"], "comment": "26 pages, 16 figures, 4 tables", "summary": "Large language models (LLMs) have recently demonstrated success in\ngeneralizing across decision-making tasks including planning, control and\nprediction, but their tendency to hallucinate unsafe and undesired outputs\nposes risks. We argue that detecting such failures is necessary, especially in\nsafety-critical scenarios. Existing black-box methods often detect\nhallucinations by identifying inconsistencies across multiple samples. Many of\nthese approaches typically introduce prompt perturbations like randomizing\ndetail order or generating adversarial inputs, with the intuition that a\nconfident model should produce stable outputs. We first perform a manual case\nstudy showing that other forms of perturbations (e.g., adding noise, removing\nsensor details) cause LLMs to hallucinate in a driving environment. We then\npropose a novel method for efficiently searching the space of prompt\nperturbations using Adaptive Stress Testing (AST) with Monte-Carlo Tree Search\n(MCTS). Our AST formulation enables discovery of scenarios and prompts that\ncause language models to act with high uncertainty. By generating MCTS prompt\nperturbation trees across diverse scenarios, we show that offline analyses can\nbe used at runtime to automatically generate prompts that influence model\nuncertainty, and to inform real-time trust assessments of an LLM.", "AI": {"tldr": "The paper proposes a method using Adaptive Stress Testing (AST) and Monte-Carlo Tree Search (MCTS) to detect hallucinations in LLMs by generating prompt perturbations, improving real-time trust assessments.", "motivation": "LLMs risk hallucinating unsafe outputs in safety-critical tasks, necessitating reliable failure detection methods.", "method": "Uses AST with MCTS to search for prompt perturbations that reveal model uncertainty, validated via a driving environment case study.", "result": "Demonstrates that offline analyses can generate prompts influencing model uncertainty, aiding real-time trust assessments.", "conclusion": "The method effectively identifies LLM hallucinations, enhancing safety in critical applications."}}
{"id": "2505.05588", "pdf": "https://arxiv.org/pdf/2505.05588", "abs": "https://arxiv.org/abs/2505.05588", "authors": ["Somrita Banerjee", "Abhishek Cauligi", "Marco Pavone"], "title": "Flight Validation of Learning-Based Trajectory Optimization for the Astrobee Free-Flyer", "categories": ["cs.RO", "cs.AI", "cs.LG"], "comment": "Submitted to RSS 2025 Workshop on Space Robotics", "summary": "Although widely used in commercial and industrial robotics, trajectory\noptimization has seen limited use in space applications due to its high\ncomputational demands. In this work, we present flight results from experiments\nwith the Astrobee free-flying robot on board the International Space Station\n(ISS), that demonstrate how machine learning can accelerate on-board trajectory\noptimization while preserving theoretical solver guarantees. To the best of the\nauthors' knowledge, this is the first-ever demonstration of learning-based\ncontrol on the ISS. Our approach leverages the GuSTO sequential convex\nprogramming framework and uses a neural network, trained offline, to map\nproblem parameters to effective initial ``warm-start'' trajectories, paving the\nway for faster real-time optimization on resource-constrained space platforms.", "AI": {"tldr": "Machine learning accelerates trajectory optimization for space robotics, demonstrated on the ISS using Astrobee, with offline-trained neural networks providing warm-start trajectories.", "motivation": "Trajectory optimization is computationally demanding, limiting its use in space applications. This work aims to overcome this by leveraging machine learning.", "method": "Uses the GuSTO sequential convex programming framework and an offline-trained neural network to generate warm-start trajectories for faster optimization.", "result": "First demonstration of learning-based control on the ISS, showing accelerated trajectory optimization with solver guarantees preserved.", "conclusion": "The approach enables real-time optimization on resource-constrained space platforms, paving the way for broader use in space robotics."}}
{"id": "2505.05635", "pdf": "https://arxiv.org/pdf/2505.05635", "abs": "https://arxiv.org/abs/2505.05635", "authors": ["Faizan Farooq Khan", "Jun Chen", "Youssef Mohamed", "Chun-Mei Feng", "Mohamed Elhoseiny"], "title": "VR-RAG: Open-vocabulary Species Recognition with RAG-Assisted Large Multi-Modal Models", "categories": ["cs.CV"], "comment": "7 figures", "summary": "Open-vocabulary recognition remains a challenging problem in computer vision,\nas it requires identifying objects from an unbounded set of categories. This is\nparticularly relevant in nature, where new species are discovered every year.\nIn this work, we focus on open-vocabulary bird species recognition, where the\ngoal is to classify species based on their descriptions without being\nconstrained to a predefined set of taxonomic categories. Traditional benchmarks\nlike CUB-200-2011 and Birdsnap have been evaluated in a closed-vocabulary\nparadigm, limiting their applicability to real-world scenarios where novel\nspecies continually emerge. We show that the performance of current systems\nwhen evaluated under settings closely aligned with open-vocabulary drops by a\nhuge margin. To address this gap, we propose a scalable framework integrating\nstructured textual knowledge from Wikipedia articles of 11,202 bird species\ndistilled via GPT-4o into concise, discriminative summaries. We propose Visual\nRe-ranking Retrieval-Augmented Generation(VR-RAG), a novel, retrieval-augmented\ngeneration framework that uses visual similarities to rerank the top m\ncandidates retrieved by a set of multimodal vision language encoders. This\nallows for the recognition of unseen taxa. Extensive experiments across five\nestablished classification benchmarks show that our approach is highly\neffective. By integrating VR-RAG, we improve the average performance of\nstate-of-the-art Large Multi-Modal Model QWEN2.5-VL by 15.4% across five\nbenchmarks. Our approach outperforms conventional VLM-based approaches, which\nstruggle with unseen species. By bridging the gap between encyclopedic\nknowledge and visual recognition, our work advances open-vocabulary\nrecognition, offering a flexible, scalable solution for biodiversity monitoring\nand ecological research.", "AI": {"tldr": "The paper addresses open-vocabulary bird species recognition by proposing VR-RAG, a framework integrating textual knowledge and visual re-ranking, improving performance by 15.4% over existing methods.", "motivation": "Open-vocabulary recognition is challenging due to unbounded categories, especially in nature where new species emerge. Current benchmarks are limited to closed-vocabulary settings.", "method": "Proposes VR-RAG, a retrieval-augmented generation framework using GPT-4o for textual summaries and visual re-ranking to recognize unseen species.", "result": "VR-RAG improves state-of-the-art performance by 15.4% across five benchmarks, outperforming conventional VLM-based approaches.", "conclusion": "The work bridges encyclopedic knowledge and visual recognition, offering a scalable solution for biodiversity monitoring and ecological research."}}
{"id": "2505.05763", "pdf": "https://arxiv.org/pdf/2505.05763", "abs": "https://arxiv.org/abs/2505.05763", "authors": ["Yize Zhou", "Jie Zhang", "Meijie Wang", "Lun Yu"], "title": "BMMDetect: A Multimodal Deep Learning Framework for Comprehensive Biomedical Misconduct Detection", "categories": ["cs.LG", "cs.CL"], "comment": null, "summary": "Academic misconduct detection in biomedical research remains challenging due\nto algorithmic narrowness in existing methods and fragmented analytical\npipelines. We present BMMDetect, a multimodal deep learning framework that\nintegrates journal metadata (SJR, institutional data), semantic embeddings\n(PubMedBERT), and GPT-4o-mined textual attributes (methodological statistics,\ndata anomalies) for holistic manuscript evaluation. Key innovations include:\n(1) multimodal fusion of domain-specific features to reduce detection bias; (2)\nquantitative evaluation of feature importance, identifying journal authority\nmetrics (e.g., SJR-index) and textual anomalies (e.g., statistical outliers) as\ndominant predictors; and (3) the BioMCD dataset, a large-scale benchmark with\n13,160 retracted articles and 53,411 controls. BMMDetect achieves 74.33% AUC,\noutperforming single-modality baselines by 8.6%, and demonstrates\ntransferability across biomedical subfields. This work advances scalable,\ninterpretable tools for safeguarding research integrity.", "AI": {"tldr": "BMMDetect is a multimodal deep learning framework for detecting academic misconduct in biomedical research, outperforming single-modality methods by 8.6% AUC.", "motivation": "Addressing challenges in academic misconduct detection due to narrow algorithms and fragmented pipelines.", "method": "Integrates journal metadata, semantic embeddings, and GPT-4o-mined textual attributes for holistic evaluation.", "result": "Achieves 74.33% AUC, identifies key predictors like SJR-index and textual anomalies, and demonstrates transferability.", "conclusion": "Advances scalable, interpretable tools for research integrity."}}
{"id": "2502.04521", "pdf": "https://arxiv.org/pdf/2502.04521", "abs": "https://arxiv.org/abs/2502.04521", "authors": ["Valiyeh A. Nezhad", "Gokberk Elmas", "Bilal Kabas", "Fuat Arslan", "Tolga \u00c7ukur"], "title": "Generative Autoregressive Transformers for Model-Agnostic Federated MRI Reconstruction", "categories": ["eess.IV", "cs.CV"], "comment": null, "summary": "Although learning-based models hold great promise for MRI reconstruction,\nsingle-site models built on limited local datasets often suffer from poor\ngeneralization. This challenge has spurred interest in collaborative model\ntraining on multi-site datasets via federated learning (FL) -- a\nprivacy-preserving framework that aggregates model updates instead of sharing\nimaging data. Conventional FL aggregates locally trained model weights into a\nglobal model, inherently constraining all sites to use a homogeneous model\narchitecture. This rigidity forces sites to compromise on architectures\ntailored to their compute resources and application-specific needs, making\nconventional FL unsuitable for model-heterogeneous settings where each site may\nprefer a distinct architecture. To overcome this limitation, we introduce\nFedGAT, a novel model-agnostic FL technique based on generative autoregressive\ntransformers. FedGAT decentralizes the training of a global generative prior\nthat learns the distribution of multi-site MR images. For high-fidelity\nsynthesis, we propose a novel site-prompted GAT prior that controllably\nsynthesizes realistic MR images from desired sites via autoregressive\nprediction across spatial scales. Each site then trains its own reconstruction\nmodel -- using an architecture of its choice -- on a hybrid dataset augmenting\nits local MRI dataset with GAT-generated synthetic MR images emulating datasets\nfrom other sites. This hybrid training strategy enables site-specific\nreconstruction models to generalize more effectively across diverse data\ndistributions while preserving data privacy. Comprehensive experiments on\nmulti-institutional datasets demonstrate that FedGAT enables flexible,\nmodel-heterogeneous collaborations and achieves superior within-site and\ncross-site reconstruction performance compared to state-of-the-art FL\nbaselines.", "AI": {"tldr": "FedGAT introduces a model-agnostic federated learning technique using generative autoregressive transformers to enable flexible, model-heterogeneous collaborations for MRI reconstruction, improving generalization without sharing data.", "motivation": "Single-site MRI reconstruction models lack generalization due to limited local datasets, and conventional FL restricts sites to homogeneous architectures, limiting flexibility.", "method": "FedGAT trains a global generative prior for multi-site MR image distribution, synthesizes site-specific synthetic images, and allows sites to train their own models on hybrid datasets.", "result": "FedGAT outperforms state-of-the-art FL baselines in within-site and cross-site reconstruction performance.", "conclusion": "FedGAT enables privacy-preserving, model-heterogeneous collaborations, enhancing MRI reconstruction generalization across diverse datasets."}}
{"id": "2505.05736", "pdf": "https://arxiv.org/pdf/2505.05736", "abs": "https://arxiv.org/abs/2505.05736", "authors": ["Da Wu", "Zhanliang Wang", "Quan Nguyen", "Zhuoran Xu", "Kai Wang"], "title": "Multimodal Integrated Knowledge Transfer to Large Language Models through Preference Optimization with Biomedical Applications", "categories": ["q-bio.QM", "cs.CL", "cs.CV", "cs.LG"], "comment": "First Draft", "summary": "The scarcity of high-quality multimodal biomedical data limits the ability to\neffectively fine-tune pretrained Large Language Models (LLMs) for specialized\nbiomedical tasks. To address this challenge, we introduce MINT (Multimodal\nIntegrated kNowledge Transfer), a framework that aligns unimodal large decoder\nmodels with domain-specific decision patterns from multimodal biomedical data\nthrough preference optimization. While MINT supports different optimization\ntechniques, we primarily implement it with the Odds Ratio Preference\nOptimization (ORPO) framework as its backbone. This strategy enables the\naligned LLMs to perform predictive tasks using text-only or image-only inputs\nwhile retaining knowledge learnt from multimodal data. MINT leverages an\nupstream multimodal machine learning (MML) model trained on high-quality\nmultimodal data to transfer domain-specific insights to downstream text-only or\nimage-only LLMs. We demonstrate its effectiveness through two key applications:\n(1) Rare genetic disease prediction from texts, where MINT uses a multimodal\nencoder model, trained on facial photos and clinical notes, to generate a\npreference dataset for aligning a lightweight Llama 3.2-3B-Instruct. Despite\nrelying on text input only, the MINT-derived model outperforms models trained\nwith SFT, RAG, or DPO, and even outperforms Llama 3.1-405B-Instruct. (2) Tissue\ntype classification using cell nucleus images, where MINT uses a\nvision-language foundation model as the preference generator, containing\nknowledge learnt from both text and histopathological images to align\ndownstream image-only models. The resulting MINT-derived model significantly\nimproves the performance of Llama 3.2-Vision-11B-Instruct on tissue type\nclassification. In summary, MINT provides an effective strategy to align\nunimodal LLMs with high-quality multimodal expertise through preference\noptimization.", "AI": {"tldr": "MINT is a framework for aligning unimodal LLMs with domain-specific insights from multimodal biomedical data using preference optimization, improving performance on specialized tasks.", "motivation": "High-quality multimodal biomedical data is scarce, limiting fine-tuning of LLMs for specialized tasks. MINT addresses this by transferring knowledge from multimodal to unimodal models.", "method": "MINT uses preference optimization (e.g., ORPO) to align unimodal LLMs with decision patterns from multimodal data, leveraging an upstream MML model for knowledge transfer.", "result": "MINT-derived models outperform traditional methods (SFT, RAG, DPO) and even larger models (e.g., Llama 3.1-405B-Instruct) in tasks like rare disease prediction and tissue classification.", "conclusion": "MINT effectively bridges the gap between multimodal and unimodal LLMs, enhancing performance on biomedical tasks without requiring multimodal input."}}
{"id": "2505.05595", "pdf": "https://arxiv.org/pdf/2505.05595", "abs": "https://arxiv.org/abs/2505.05595", "authors": ["Wenhao Guo", "Yuda Wang", "Zeqiao Huang", "Changjiang Zhang", "Shumin ma"], "title": "Trading Under Uncertainty: A Distribution-Based Strategy for Futures Markets Using FutureQuant Transformer", "categories": ["q-fin.TR", "cs.AI", "cs.CE", "cs.LG"], "comment": "16 pages, 12 figures", "summary": "In the complex landscape of traditional futures trading, where vast data and\nvariables like real-time Limit Order Books (LOB) complicate price predictions,\nwe introduce the FutureQuant Transformer model, leveraging attention mechanisms\nto navigate these challenges. Unlike conventional models focused on point\npredictions, the FutureQuant model excels in forecasting the range and\nvolatility of future prices, thus offering richer insights for trading\nstrategies. Its ability to parse and learn from intricate market patterns\nallows for enhanced decision-making, significantly improving risk management\nand achieving a notable average gain of 0.1193% per 30-minute trade over\nstate-of-the-art models with a simple algorithm using factors such as RSI, ATR,\nand Bollinger Bands. This innovation marks a substantial leap forward in\npredictive analytics within the volatile domain of futures trading.", "AI": {"tldr": "The FutureQuant Transformer model uses attention mechanisms to predict price ranges and volatility in futures trading, outperforming traditional models with a 0.1193% average gain per 30-minute trade.", "motivation": "Traditional futures trading involves complex data like real-time Limit Order Books (LOBs), making price prediction challenging. The paper aims to improve predictive analytics by leveraging attention mechanisms.", "method": "The FutureQuant Transformer model employs attention mechanisms to analyze market patterns and forecast price ranges and volatility, integrating factors like RSI, ATR, and Bollinger Bands.", "result": "The model achieves a 0.1193% average gain per 30-minute trade, surpassing state-of-the-art models in risk management and decision-making.", "conclusion": "The FutureQuant Transformer represents a significant advancement in futures trading analytics, offering richer insights and improved performance."}}
{"id": "2505.05640", "pdf": "https://arxiv.org/pdf/2505.05640", "abs": "https://arxiv.org/abs/2505.05640", "authors": ["Anadil Hussein", "Anna Zamansky", "George Martvel"], "title": "Semantic Style Transfer for Enhancing Animal Facial Landmark Detection", "categories": ["cs.CV"], "comment": null, "summary": "Neural Style Transfer (NST) is a technique for applying the visual\ncharacteristics of one image onto another while preserving structural content.\nTraditionally used for artistic transformations, NST has recently been adapted,\ne.g., for domain adaptation and data augmentation. This study investigates the\nuse of this technique for enhancing animal facial landmark detectors training.\nAs a case study, we use a recently introduced Ensemble Landmark Detector for 48\nanatomical cat facial landmarks and the CatFLW dataset it was trained on,\nmaking three main contributions. First, we demonstrate that applying style\ntransfer to cropped facial images rather than full-body images enhances\nstructural consistency, improving the quality of generated images. Secondly,\nreplacing training images with style-transferred versions raised challenges of\nannotation misalignment, but Supervised Style Transfer (SST) - which selects\nstyle sources based on landmark accuracy - retained up to 98% of baseline\naccuracy. Finally, augmenting the dataset with style-transferred images further\nimproved robustness, outperforming traditional augmentation methods. These\nfindings establish semantic style transfer as an effective augmentation\nstrategy for enhancing the performance of facial landmark detection models for\nanimals and beyond. While this study focuses on cat facial landmarks, the\nproposed method can be generalized to other species and landmark detection\nmodels.", "AI": {"tldr": "Neural Style Transfer (NST) is adapted to enhance animal facial landmark detector training, improving structural consistency and robustness through Supervised Style Transfer (SST) and dataset augmentation.", "motivation": "To explore NST's potential for improving animal facial landmark detection, addressing challenges like annotation misalignment and structural consistency.", "method": "Applied NST to cropped facial images, introduced SST for style selection, and augmented datasets with style-transferred images.", "result": "SST retained 98% baseline accuracy; style-augmented datasets outperformed traditional methods.", "conclusion": "Semantic style transfer is effective for enhancing facial landmark detection, generalizable to other species and models."}}
{"id": "2505.05785", "pdf": "https://arxiv.org/pdf/2505.05785", "abs": "https://arxiv.org/abs/2505.05785", "authors": ["Henan Sun", "Xunkai Li", "Lei Zhu", "Junyi Han", "Guang Zeng", "Ronghua Li", "Guoren Wang"], "title": "Rethinking Graph Out-Of-Distribution Generalization: A Learnable Random Walk Perspective", "categories": ["cs.LG"], "comment": "Under Review", "summary": "Out-Of-Distribution (OOD) generalization has gained increasing attentions for\nmachine learning on graphs, as graph neural networks (GNNs) often exhibit\nperformance degradation under distribution shifts. Existing graph OOD methods\ntend to follow the basic ideas of invariant risk minimization and structural\ncausal models, interpreting the invariant knowledge across datasets under\nvarious distribution shifts as graph topology or graph spectrum. However, these\ninterpretations may be inconsistent with real-world scenarios, as neither\ninvariant topology nor spectrum is assured. In this paper, we advocate the\nlearnable random walk (LRW) perspective as the instantiation of invariant\nknowledge, and propose LRW-OOD to realize graph OOD generalization learning.\nInstead of employing fixed probability transition matrix (i.e.,\ndegree-normalized adjacency matrix), we parameterize the transition matrix with\nan LRW-sampler and a path encoder. Furthermore, we propose the kernel density\nestimation (KDE)-based mutual information (MI) loss to generate random walk\nsequences that adhere to OOD principles. Extensive experiment demonstrates that\nour model can effectively enhance graph OOD generalization under various types\nof distribution shifts and yield a significant accuracy improvement of 3.87%\nover state-of-the-art graph OOD generalization baselines.", "AI": {"tldr": "The paper introduces LRW-OOD, a method for improving Out-Of-Distribution (OOD) generalization in graph neural networks (GNNs) by using learnable random walks and a KDE-based mutual information loss.", "motivation": "Existing graph OOD methods rely on assumptions like invariant topology or spectrum, which may not hold in real-world scenarios. The paper aims to address this inconsistency by proposing a more flexible approach.", "method": "The paper advocates for learnable random walks (LRW) as invariant knowledge and introduces LRW-OOD, which parameterizes the transition matrix with an LRW-sampler and path encoder. It also uses a KDE-based MI loss to ensure OOD adherence.", "result": "Experiments show LRW-OOD significantly improves OOD generalization, achieving a 3.87% accuracy boost over state-of-the-art baselines under various distribution shifts.", "conclusion": "LRW-OOD effectively enhances graph OOD generalization by leveraging learnable random walks and a novel MI loss, outperforming existing methods."}}
{"id": "2505.04105", "pdf": "https://arxiv.org/pdf/2505.04105", "abs": "https://arxiv.org/abs/2505.04105", "authors": ["Andrew Zhang", "Hao Wang", "Shuchang Ye", "Michael Fulham", "Jinman Kim"], "title": "MAISY: Motion-Aware Image SYnthesis for Medical Image Motion Correction", "categories": ["eess.IV", "cs.CV"], "comment": null, "summary": "Patient motion during medical image acquisition causes blurring, ghosting,\nand distorts organs, which makes image interpretation challenging. Current\nstate-of-the-art algorithms using Generative Adversarial Network (GAN)-based\nmethods with their ability to learn the mappings between corrupted images and\ntheir ground truth via Structural Similarity Index Measure (SSIM) loss\neffectively generate motion-free images. However, we identified the following\nlimitations: (i) they mainly focus on global structural characteristics and\ntherefore overlook localized features that often carry critical pathological\ninformation, and (ii) the SSIM loss function struggles to handle images with\nvarying pixel intensities, luminance factors, and variance. In this study, we\npropose Motion-Aware Image SYnthesis (MAISY) which initially characterize\nmotion and then uses it for correction by: (a) leveraging the foundation model\nSegment Anything Model (SAM), to dynamically learn spatial patterns along\nanatomical boundaries where motion artifacts are most pronounced and, (b)\nintroducing the Variance-Selective SSIM (VS-SSIM) loss which adaptively\nemphasizes spatial regions with high pixel variance to preserve essential\nanatomical details during artifact correction. Experiments on chest and head CT\ndatasets demonstrate that our model outperformed the state-of-the-art\ncounterparts, with Peak Signal-to-Noise Ratio (PSNR) increasing by 40%, SSIM by\n10%, and Dice by 16%.", "AI": {"tldr": "MAISY improves motion artifact correction in medical images by dynamically learning spatial patterns and using a new VS-SSIM loss, outperforming existing GAN-based methods.", "motivation": "Current GAN-based methods for motion artifact correction overlook localized features and struggle with varying image properties, limiting their effectiveness.", "method": "MAISY uses the Segment Anything Model (SAM) to learn spatial patterns and introduces VS-SSIM loss to focus on high-variance regions.", "result": "MAISY increases PSNR by 40%, SSIM by 10%, and Dice by 16% compared to state-of-the-art methods.", "conclusion": "MAISY addresses limitations of existing methods, improving motion artifact correction and preserving critical anatomical details."}}
{"id": "2505.05828", "pdf": "https://arxiv.org/pdf/2505.05828", "abs": "https://arxiv.org/abs/2505.05828", "authors": ["Alba Mar\u00eda M\u00e1rmol-Romero", "Manuel Garc\u00eda-Vega", "Miguel \u00c1ngel Garc\u00eda-Cumbreras", "Arturo Montejo-R\u00e1ez"], "title": "An empathic GPT-based chatbot to talk about mental disorders with Spanish teenagers", "categories": ["cs.HC", "cs.CL"], "comment": "This is an Accepted Manuscript version of the following article,\n  accepted for publication in International Journal of Human-Computer\n  Interaction. It is deposited under the terms of the Creative Commons\n  Attribution-NonCommercial-NoDerivatives License", "summary": "This paper presents a chatbot-based system to engage young Spanish people in\nthe awareness of certain mental disorders through a self-disclosure technique.\nThe study was carried out in a population of teenagers aged between 12 and 18\nyears. The dialogue engine mixes closed and open conversations, so certain\ncontrolled messages are sent to focus the chat on a specific disorder, which\nwill change over time. Once a set of trial questions is answered, the system\ncan initiate the conversation on the disorder under the focus according to the\nuser's sensibility to that disorder, in an attempt to establish a more\nempathetic communication. Then, an open conversation based on the GPT-3\nlanguage model is initiated, allowing the user to express themselves with more\nfreedom. The results show that these systems are of interest to young people\nand could help them become aware of certain mental disorders.", "AI": {"tldr": "A chatbot system using self-disclosure and GPT-3 engages Spanish teens (12-18) to raise awareness of mental disorders, showing promise in empathetic communication and user interest.", "motivation": "To engage young Spanish people in mental disorder awareness through interactive and empathetic chatbot communication.", "method": "Combines closed and open conversations with controlled messages and GPT-3 for empathetic, disorder-focused dialogue based on user responses.", "result": "The system effectively engages teens and aids in raising awareness of mental disorders.", "conclusion": "Chatbot-based systems are promising tools for mental health awareness among young people."}}
{"id": "2505.05622", "pdf": "https://arxiv.org/pdf/2505.05622", "abs": "https://arxiv.org/abs/2505.05622", "authors": ["Weichen Zhang", "Chen Gao", "Shiquan Yu", "Ruiying Peng", "Baining Zhao", "Qian Zhang", "Jinqiang Cui", "Xinlei Chen", "Yong Li"], "title": "CityNavAgent: Aerial Vision-and-Language Navigation with Hierarchical Semantic Planning and Global Memory", "categories": ["cs.RO", "cs.AI"], "comment": null, "summary": "Aerial vision-and-language navigation (VLN), requiring drones to interpret\nnatural language instructions and navigate complex urban environments, emerges\nas a critical embodied AI challenge that bridges human-robot interaction, 3D\nspatial reasoning, and real-world deployment. Although existing ground VLN\nagents achieved notable results in indoor and outdoor settings, they struggle\nin aerial VLN due to the absence of predefined navigation graphs and the\nexponentially expanding action space in long-horizon exploration. In this work,\nwe propose \\textbf{CityNavAgent}, a large language model (LLM)-empowered agent\nthat significantly reduces the navigation complexity for urban aerial VLN.\nSpecifically, we design a hierarchical semantic planning module (HSPM) that\ndecomposes the long-horizon task into sub-goals with different semantic levels.\nThe agent reaches the target progressively by achieving sub-goals with\ndifferent capacities of the LLM. Additionally, a global memory module storing\nhistorical trajectories into a topological graph is developed to simplify\nnavigation for visited targets. Extensive benchmark experiments show that our\nmethod achieves state-of-the-art performance with significant improvement.\nFurther experiments demonstrate the effectiveness of different modules of\nCityNavAgent for aerial VLN in continuous city environments. The code is\navailable at \\href{https://github.com/VinceOuti/CityNavAgent}{link}.", "AI": {"tldr": "CityNavAgent, an LLM-powered drone navigation system, simplifies aerial VLN by decomposing tasks into sub-goals and using a global memory module, achieving state-of-the-art performance.", "motivation": "Aerial VLN is challenging due to lack of predefined navigation graphs and large action spaces, requiring innovative solutions for urban drone navigation.", "method": "Proposes CityNavAgent with a hierarchical semantic planning module (HSPM) to break tasks into sub-goals and a global memory module for storing trajectories.", "result": "Achieves state-of-the-art performance in aerial VLN, with experiments validating the effectiveness of its modules.", "conclusion": "CityNavAgent successfully addresses aerial VLN challenges, demonstrating significant improvements in navigation efficiency and accuracy."}}
{"id": "2505.05666", "pdf": "https://arxiv.org/pdf/2505.05666", "abs": "https://arxiv.org/abs/2505.05666", "authors": ["Alexander Most", "Joseph Winjum", "Ayan Biswas", "Shawn Jones", "Nishath Rajiv Ranasinghe", "Dan O'Malley", "Manish Bhattarai"], "title": "Lost in OCR Translation? Vision-Based Approaches to Robust Document Retrieval", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Retrieval-Augmented Generation (RAG) has become a popular technique for\nenhancing the reliability and utility of Large Language Models (LLMs) by\ngrounding responses in external documents. Traditional RAG systems rely on\nOptical Character Recognition (OCR) to first process scanned documents into\ntext. However, even state-of-the-art OCRs can introduce errors, especially in\ndegraded or complex documents. Recent vision-language approaches, such as\nColPali, propose direct visual embedding of documents, eliminating the need for\nOCR. This study presents a systematic comparison between a vision-based RAG\nsystem (ColPali) and more traditional OCR-based pipelines utilizing Llama 3.2\n(90B) and Nougat OCR across varying document qualities. Beyond conventional\nretrieval accuracy metrics, we introduce a semantic answer evaluation benchmark\nto assess end-to-end question-answering performance. Our findings indicate that\nwhile vision-based RAG performs well on documents it has been fine-tuned on,\nOCR-based RAG is better able to generalize to unseen documents of varying\nquality. We highlight the key trade-offs between computational efficiency and\nsemantic accuracy, offering practical guidance for RAG practitioners in\nselecting between OCR-dependent and vision-based document retrieval systems in\nproduction environments.", "AI": {"tldr": "The paper compares vision-based RAG (ColPali) with OCR-based RAG, showing OCR generalizes better to unseen documents, while vision-based excels on fine-tuned data. Trade-offs between efficiency and accuracy are discussed.", "motivation": "To address OCR errors in degraded documents and explore vision-language alternatives like ColPali for RAG systems.", "method": "Systematic comparison of vision-based (ColPali) and OCR-based (Llama 3.2, Nougat OCR) RAG pipelines across document qualities, using semantic answer evaluation.", "result": "Vision-based RAG performs well on fine-tuned documents, but OCR-based RAG generalizes better to varying document qualities.", "conclusion": "OCR-based RAG is more generalizable, while vision-based RAG is efficient for specific cases. Practical guidance is provided for choosing between them."}}
{"id": "2505.05799", "pdf": "https://arxiv.org/pdf/2505.05799", "abs": "https://arxiv.org/abs/2505.05799", "authors": ["Haojie Duanmu", "Xiuhong Li", "Zhihang Yuan", "Size Zheng", "Jiangfei Duan", "Xingcheng Zhang", "Dahua Lin"], "title": "MxMoE: Mixed-precision Quantization for MoE with Accuracy and Performance Co-Design", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Mixture-of-Experts (MoE) models face deployment challenges due to their large\nparameter counts and computational demands. We explore quantization for MoE\nmodels and highlight two key insights: 1) linear blocks exhibit varying\nquantization sensitivity, and 2) divergent expert activation frequencies create\nheterogeneous computational characteristics. Based on these observations, we\nintroduce MxMoE, a mixed-precision optimization framework for MoE models that\nconsiders both algorithmic and system perspectives. MxMoE navigates the design\nspace defined by parameter sensitivity, expert activation dynamics, and\nhardware resources to derive efficient mixed-precision configurations.\nAdditionally, MxMoE automatically generates optimized mixed-precision GroupGEMM\nkernels, enabling parallel execution of GEMMs with different precisions.\nEvaluations show that MxMoE outperforms existing methods, achieving 2.4 lower\nWikitext-2 perplexity than GPTQ at 2.25-bit and delivering up to 3.4x speedup\nover full precision, as well as up to 29.4% speedup over uniform quantization\nat equivalent accuracy with 5-bit weight-activation quantization. Our code is\navailable at https://github.com/cat538/MxMoE.", "AI": {"tldr": "MxMoE is a mixed-precision optimization framework for MoE models, addressing quantization challenges by considering parameter sensitivity and expert activation dynamics, achieving better performance than existing methods.", "motivation": "Deploying large MoE models is challenging due to high parameter counts and computational demands. Quantization can help, but existing methods don't fully address the unique characteristics of MoE models.", "method": "MxMoE analyzes quantization sensitivity in linear blocks and expert activation frequencies, then optimizes mixed-precision configurations and generates efficient GroupGEMM kernels for parallel execution.", "result": "MxMoE achieves 2.4 lower perplexity than GPTQ at 2.25-bit, 3.4x speedup over full precision, and 29.4% speedup over uniform quantization at 5-bit.", "conclusion": "MxMoE effectively balances accuracy and efficiency for MoE models, offering a practical solution for deployment challenges."}}
{"id": "2306.14070", "pdf": "https://arxiv.org/pdf/2306.14070", "abs": "https://arxiv.org/abs/2306.14070", "authors": ["Pu Ren", "N. Benjamin Erichson", "Junyi Guo", "Shashank Subramanian", "Omer San", "Zarija Lukic", "Michael W. Mahoney"], "title": "SuperBench: A Super-Resolution Benchmark Dataset for Scientific Machine Learning", "categories": ["cs.CV", "eess.IV", "physics.comp-ph"], "comment": "Accepted to Journal of Data-centric Machine Learning Research", "summary": "Super-resolution (SR) techniques aim to enhance data resolution, enabling the\nretrieval of finer details, and improving the overall quality and fidelity of\nthe data representation. There is growing interest in applying SR methods to\ncomplex spatiotemporal systems within the Scientific Machine Learning (SciML)\ncommunity, with the hope of accelerating numerical simulations and/or improving\nforecasts in weather, climate, and related areas. However, the lack of\nstandardized benchmark datasets for comparing and validating SR methods hinders\nprogress and adoption in SciML. To address this, we introduce SuperBench, the\nfirst benchmark dataset featuring high-resolution datasets, including data from\nfluid flows, cosmology, and weather. Here, we focus on validating spatial SR\nperformance from data-centric and physics-preserved perspectives, as well as\nassessing robustness to data degradation tasks. While deep learning-based SR\nmethods (developed in the computer vision community) excel on certain tasks,\ndespite relatively limited prior physics information, we identify limitations\nof these methods in accurately capturing intricate fine-scale features and\npreserving fundamental physical properties and constraints in scientific data.\nThese shortcomings highlight the importance and subtlety of incorporating\ndomain knowledge into ML models. We anticipate that SuperBench will help to\nadvance SR methods for science.", "AI": {"tldr": "The paper introduces SuperBench, a benchmark dataset for super-resolution (SR) methods in Scientific Machine Learning (SciML), addressing the lack of standardized benchmarks. It evaluates SR performance, robustness, and the need for domain knowledge in ML models.", "motivation": "The lack of standardized benchmark datasets for SR methods in SciML hinders progress and adoption. The paper aims to fill this gap by introducing SuperBench.", "method": "The authors introduce SuperBench, a benchmark dataset with high-resolution data from fluid flows, cosmology, and weather. They validate spatial SR performance from data-centric and physics-preserved perspectives.", "result": "Deep learning-based SR methods excel in some tasks but struggle to capture fine-scale features and preserve physical properties in scientific data.", "conclusion": "SuperBench is expected to advance SR methods in science by providing a standardized benchmark and highlighting the importance of domain knowledge in ML models."}}
{"id": "2505.05863", "pdf": "https://arxiv.org/pdf/2505.05863", "abs": "https://arxiv.org/abs/2505.05863", "authors": ["Reiji Suzuki", "Takaya Arita"], "title": "Evolutionary ecology of words", "categories": ["q-bio.PE", "cs.AI", "cs.CL", "92B20"], "comment": "8 pages, 5 figures. Preprint of the paper published in Proceedings of\n  2025 IEEE Symposium on Computational Intelligence in Artificial Life and\n  Cooperative Intelligent Systems (ALIFE-CIS)", "summary": "We propose a model for the evolutionary ecology of words as one attempt to\nextend evolutionary game theory and agent-based models by utilizing the rich\nlinguistic expressions of Large Language Models (LLMs). Our model enables the\nemergence and evolution of diverse and infinite options for interactions among\nagents. Within the population, each agent possesses a short word (or phrase)\ngenerated by an LLM and moves within a spatial environment. When agents become\nadjacent, the outcome of their interaction is determined by the LLM based on\nthe relationship between their words, with the loser's word being replaced by\nthe winner's. Word mutations, also based on LLM outputs, may occur. We\nconducted preliminary experiments assuming that ``strong animal species\" would\nsurvive. The results showed that from an initial population consisting of\nwell-known species, many species emerged both gradually and in a punctuated\nequilibrium manner. Each trial demonstrated the unique evolution of diverse\npopulations, with one type of large species becoming dominant, such as\nterrestrial animals, marine life, or extinct species, which were ecologically\nspecialized and adapted ones across diverse extreme habitats. We also conducted\na long-term experiment with a large population, demonstrating the emergence and\ncoexistence of diverse species.", "AI": {"tldr": "A model using LLMs to simulate word evolution in agent-based interactions, showing diverse species emergence and dominance.", "motivation": "Extend evolutionary game theory by leveraging LLMs for linguistic expression in agent interactions.", "method": "Agents with LLM-generated words interact spatially; outcomes determine word replacement, with mutations possible.", "result": "Preliminary experiments showed diverse species emergence, with dominant types like terrestrial or marine animals. Long-term experiments confirmed coexistence.", "conclusion": "The model successfully demonstrates the evolution and coexistence of diverse species through LLM-driven word interactions."}}
{"id": "2505.05638", "pdf": "https://arxiv.org/pdf/2505.05638", "abs": "https://arxiv.org/abs/2505.05638", "authors": ["Mohamed-Khalil Bouzidi", "Christian Schlauch", "Nicole Scheuerer", "Yue Yao", "Nadja Klein", "Daniel G\u00f6hring", "J\u00f6rg Reichardt"], "title": "Closing the Loop: Motion Prediction Models beyond Open-Loop Benchmarks", "categories": ["cs.RO", "cs.AI", "cs.SY", "eess.SY"], "comment": null, "summary": "Fueled by motion prediction competitions and benchmarks, recent years have\nseen the emergence of increasingly large learning based prediction models, many\nwith millions of parameters, focused on improving open-loop prediction accuracy\nby mere centimeters. However, these benchmarks fail to assess whether such\nimprovements translate to better performance when integrated into an autonomous\ndriving stack. In this work, we systematically evaluate the interplay between\nstate-of-the-art motion predictors and motion planners. Our results show that\nhigher open-loop accuracy does not always correlate with better closed-loop\ndriving behavior and that other factors, such as temporal consistency of\npredictions and planner compatibility, also play a critical role. Furthermore,\nwe investigate downsized variants of these models, and, surprisingly, find that\nin some cases models with up to 86% fewer parameters yield comparable or even\nsuperior closed-loop driving performance. Our code is available at\nhttps://github.com/continental/pred2plan.", "AI": {"tldr": "Higher open-loop accuracy in motion predictors doesn't always improve closed-loop driving performance; factors like temporal consistency and planner compatibility matter more. Smaller models can sometimes perform as well or better.", "motivation": "To evaluate if improvements in open-loop motion prediction accuracy translate to better performance in autonomous driving systems.", "method": "Systematically assess the interplay between state-of-the-art motion predictors and planners, including downsized model variants.", "result": "Open-loop accuracy doesn't always correlate with closed-loop performance; smaller models (up to 86% fewer parameters) can match or outperform larger ones.", "conclusion": "Closed-loop performance depends on factors beyond accuracy, and smaller models may be more efficient without sacrificing performance."}}
{"id": "2505.05672", "pdf": "https://arxiv.org/pdf/2505.05672", "abs": "https://arxiv.org/abs/2505.05672", "authors": ["Gengyan Li", "Paulo Gotardo", "Timo Bolkart", "Stephan Garbin", "Kripasindhu Sarkar", "Abhimitra Meka", "Alexandros Lattas", "Thabo Beeler"], "title": "TeGA: Texture Space Gaussian Avatars for High-Resolution Dynamic Head Modeling", "categories": ["cs.CV", "I.3.7; I.3.5"], "comment": "10 pages, 9 figures, supplementary results found at:\n  https://syntec-research.github.io/UVGA/, to be published in SIGGRAPH 2025", "summary": "Sparse volumetric reconstruction and rendering via 3D Gaussian splatting have\nrecently enabled animatable 3D head avatars that are rendered under arbitrary\nviewpoints with impressive photorealism. Today, such photoreal avatars are seen\nas a key component in emerging applications in telepresence, extended reality,\nand entertainment. Building a photoreal avatar requires estimating the complex\nnon-rigid motion of different facial components as seen in input video images;\ndue to inaccurate motion estimation, animatable models typically present a loss\nof fidelity and detail when compared to their non-animatable counterparts,\nbuilt from an individual facial expression. Also, recent state-of-the-art\nmodels are often affected by memory limitations that reduce the number of 3D\nGaussians used for modeling, leading to lower detail and quality. To address\nthese problems, we present a new high-detail 3D head avatar model that improves\nupon the state of the art, largely increasing the number of 3D Gaussians and\nmodeling quality for rendering at 4K resolution. Our high-quality model is\nreconstructed from multiview input video and builds on top of a mesh-based 3D\nmorphable model, which provides a coarse deformation layer for the head.\nPhotoreal appearance is modelled by 3D Gaussians embedded within the continuous\nUVD tangent space of this mesh, allowing for more effective densification where\nmost needed. Additionally, these Gaussians are warped by a novel UVD\ndeformation field to capture subtle, localized motion. Our key contribution is\nthe novel deformable Gaussian encoding and overall fitting procedure that\nallows our head model to preserve appearance detail, while capturing facial\nmotion and other transient high-frequency features such as skin wrinkling.", "AI": {"tldr": "A novel high-detail 3D head avatar model improves photorealism and motion capture by increasing 3D Gaussian splatting and introducing a deformable Gaussian encoding method.", "motivation": "Current photoreal avatars lose fidelity due to inaccurate motion estimation and memory limitations, reducing detail and quality.", "method": "The model uses a mesh-based 3D morphable model for coarse deformation, with 3D Gaussians in UVD tangent space for photoreal appearance and a novel UVD deformation field for subtle motion.", "result": "The method enhances detail and quality, enabling 4K resolution rendering and better facial motion capture.", "conclusion": "The deformable Gaussian encoding and fitting procedure preserve detail and improve motion representation, advancing photoreal avatar technology."}}
{"id": "2505.05803", "pdf": "https://arxiv.org/pdf/2505.05803", "abs": "https://arxiv.org/abs/2505.05803", "authors": ["Yiming Li", "Man He", "Jiapeng Liu"], "title": "A novel Neural-ODE model for the state of health estimation of lithium-ion battery using charging curve", "categories": ["cs.LG"], "comment": "28 pages, 6 figures", "summary": "The state of health (SOH) of lithium-ion batteries (LIBs) is crucial for\nensuring the safe and reliable operation of electric vehicles. Nevertheless,\nthe prevailing SOH estimation methods often have limited generalizability. This\npaper introduces a data-driven approach for estimating the SOH of LIBs, which\nis designed to improve generalization. We construct a hybrid model named ACLA,\nwhich integrates the attention mechanism, convolutional neural network (CNN),\nand long short-term memory network (LSTM) into the augmented neural ordinary\ndifferential equation (ANODE) framework. This model employs normalized charging\ntime corresponding to specific voltages in the constant current charging phase\nas input and outputs the SOH as well as remaining useful of life. The model is\ntrained on NASA and Oxford datasets and validated on the TJU and HUST datasets.\nCompared to the benchmark models NODE and ANODE, ACLA exhibits higher accuracy\nwith root mean square errors (RMSE) for SOH estimation as low as 1.01% and\n2.24% on the TJU and HUST datasets, respectively.", "AI": {"tldr": "The paper proposes a hybrid model (ACLA) combining attention, CNN, LSTM, and ANODE for improved SOH estimation in LIBs, achieving high accuracy on test datasets.", "motivation": "Current SOH estimation methods lack generalizability, necessitating a more robust approach for reliable electric vehicle operation.", "method": "ACLA integrates attention, CNN, LSTM, and ANODE, using normalized charging time data as input to predict SOH and remaining useful life.", "result": "ACLA outperforms benchmarks (NODE, ANODE) with RMSEs of 1.01% and 2.24% on TJU and HUST datasets.", "conclusion": "ACLA offers a highly accurate and generalizable solution for SOH estimation in LIBs."}}
{"id": "2505.06032", "pdf": "https://arxiv.org/pdf/2505.06032", "abs": "https://arxiv.org/abs/2505.06032", "authors": ["Leon Eshuijs", "Shihan Wang", "Antske Fokkens"], "title": "Short-circuiting Shortcuts: Mechanistic Investigation of Shortcuts in Text Classification", "categories": ["cs.LG", "cs.CL"], "comment": null, "summary": "Reliance on spurious correlations (shortcuts) has been shown to underlie many\nof the successes of language models. Previous work focused on identifying the\ninput elements that impact prediction. We investigate how shortcuts are\nactually processed within the model's decision-making mechanism. We use actor\nnames in movie reviews as controllable shortcuts with known impact on the\noutcome. We use mechanistic interpretability methods and identify specific\nattention heads that focus on shortcuts. These heads gear the model towards a\nlabel before processing the complete input, effectively making premature\ndecisions that bypass contextual analysis. Based on these findings, we\nintroduce Head-based Token Attribution (HTA), which traces intermediate\ndecisions back to input tokens. We show that HTA is effective in detecting\nshortcuts in LLMs and enables targeted mitigation by selectively deactivating\nshortcut-related attention heads.", "AI": {"tldr": "The paper investigates how language models process spurious correlations (shortcuts) internally, identifies specific attention heads responsible for premature decisions, and introduces Head-based Token Attribution (HTA) for detecting and mitigating shortcuts.", "motivation": "To understand how shortcuts are processed within language models' decision-making mechanisms, beyond just identifying input elements that impact predictions.", "method": "Uses actor names in movie reviews as controllable shortcuts, applies mechanistic interpretability to identify shortcut-related attention heads, and introduces HTA for tracing decisions back to input tokens.", "result": "Identifies specific attention heads that cause premature decisions and shows HTA effectively detects shortcuts, enabling targeted mitigation by deactivating these heads.", "conclusion": "HTA provides a practical tool for understanding and mitigating shortcut reliance in language models, improving their decision-making robustness."}}
{"id": "2505.05753", "pdf": "https://arxiv.org/pdf/2505.05753", "abs": "https://arxiv.org/abs/2505.05753", "authors": ["Bo Ai", "Liu Dai", "Nico Bohlinger", "Dichen Li", "Tongzhou Mu", "Zhanxin Wu", "K. Fay", "Henrik I. Christensen", "Jan Peters", "Hao Su"], "title": "Towards Embodiment Scaling Laws in Robot Locomotion", "categories": ["cs.RO", "cs.AI", "cs.LG"], "comment": "32 pages. Project website: https://embodiment-scaling-laws.github.io/", "summary": "Developing generalist agents that can operate across diverse tasks,\nenvironments, and physical embodiments is a grand challenge in robotics and\nartificial intelligence. In this work, we focus on the axis of embodiment and\ninvestigate embodiment scaling laws$\\unicode{x2013}$the hypothesis that\nincreasing the number of training embodiments improves generalization to unseen\nones. Using robot locomotion as a test bed, we procedurally generate a dataset\nof $\\sim$1,000 varied embodiments, spanning humanoids, quadrupeds, and\nhexapods, and train generalist policies capable of handling diverse observation\nand action spaces on random subsets. We find that increasing the number of\ntraining embodiments improves generalization to unseen ones, and scaling\nembodiments is more effective in enabling embodiment-level generalization than\nscaling data on small, fixed sets of embodiments. Notably, our best policy,\ntrained on the full dataset, zero-shot transfers to novel embodiments in the\nreal world, such as Unitree Go2 and H1. These results represent a step toward\ngeneral embodied intelligence, with potential relevance to adaptive control for\nconfigurable robots, co-design of morphology and control, and beyond.", "AI": {"tldr": "Training policies on diverse robot embodiments improves generalization to unseen ones, with real-world zero-shot transfer.", "motivation": "To develop generalist agents capable of operating across diverse tasks and embodiments, focusing on embodiment scaling laws.", "method": "Procedurally generate a dataset of ~1,000 varied robot embodiments and train generalist policies on random subsets.", "result": "Increasing training embodiments improves generalization; scaling embodiments is more effective than scaling data on fixed sets. Best policy zero-shot transfers to real-world robots.", "conclusion": "Embodiment scaling advances general embodied intelligence, with applications in adaptive control and morphology co-design."}}
{"id": "2505.05678", "pdf": "https://arxiv.org/pdf/2505.05678", "abs": "https://arxiv.org/abs/2505.05678", "authors": ["Etai Sella", "Yanir Kleiman", "Hadar Averbuch-Elor"], "title": "InstanceGen: Image Generation with Instance-level Instructions", "categories": ["cs.CV"], "comment": "Project page: https://tau-vailab.github.io/InstanceGen/", "summary": "Despite rapid advancements in the capabilities of generative models,\npretrained text-to-image models still struggle in capturing the semantics\nconveyed by complex prompts that compound multiple objects and instance-level\nattributes. Consequently, we are witnessing growing interests in integrating\nadditional structural constraints, %leveraging additional structural inputs\ntypically in the form of coarse bounding boxes, to better guide the generation\nprocess in such challenging cases. In this work, we take the idea of structural\nguidance a step further by making the observation that contemporary image\ngeneration models can directly provide a plausible \\emph{fine-grained}\nstructural initialization. We propose a technique that couples this image-based\nstructural guidance with LLM-based instance-level instructions, yielding output\nimages that adhere to all parts of the text prompt, including object counts,\ninstance-level attributes, and spatial relations between instances.", "AI": {"tldr": "The paper proposes a method to improve text-to-image generation by combining fine-grained structural guidance from image models with LLM-based instance-level instructions, ensuring better adherence to complex prompts.", "motivation": "Pretrained text-to-image models often fail to capture semantics in complex prompts with multiple objects and attributes, prompting the need for better structural guidance.", "method": "The technique integrates fine-grained structural initialization from image models and LLM-based instance-level instructions to guide generation.", "result": "The approach produces images that accurately reflect object counts, attributes, and spatial relations as specified in the text prompt.", "conclusion": "Combining structural guidance with LLM instructions enhances the fidelity of text-to-image generation for complex prompts."}}
{"id": "2505.05813", "pdf": "https://arxiv.org/pdf/2505.05813", "abs": "https://arxiv.org/abs/2505.05813", "authors": ["Qiufu Li", "Huibin Xiao", "Linlin Shen"], "title": "BCE vs. CE in Deep Feature Learning", "categories": ["cs.LG"], "comment": "Accepted by ICML2025", "summary": "When training classification models, it expects that the learned features are\ncompact within classes, and can well separate different classes. As the\ndominant loss function for training classification models, minimizing\ncross-entropy (CE) loss maximizes the compactness and distinctiveness, i.e.,\nreaching neural collapse (NC). The recent works show that binary CE (BCE)\nperforms also well in multi-class tasks. In this paper, we compare BCE and CE\nin deep feature learning. For the first time, we prove that BCE can also\nmaximize the intra-class compactness and inter-class distinctiveness when\nreaching its minimum, i.e., leading to NC. We point out that CE measures the\nrelative values of decision scores in the model training, implicitly enhancing\nthe feature properties by classifying samples one-by-one. In contrast, BCE\nmeasures the absolute values of decision scores and adjust the\npositive/negative decision scores across all samples to uniformly high/low\nlevels. Meanwhile, the classifier biases in BCE present a substantial\nconstraint on the decision scores to explicitly enhance the feature properties\nin the training. The experimental results are aligned with above analysis, and\nshow that BCE could improve the classification and leads to better compactness\nand distinctiveness among sample features. The codes will be released.", "AI": {"tldr": "The paper compares binary cross-entropy (BCE) and cross-entropy (CE) in deep feature learning, proving BCE also leads to neural collapse (NC) by maximizing intra-class compactness and inter-class distinctiveness. BCE's absolute score adjustments and classifier biases enhance feature properties, outperforming CE in classification tasks.", "motivation": "To understand and compare the effectiveness of BCE and CE in achieving neural collapse (NC) and improving feature compactness and distinctiveness in classification models.", "method": "Theoretical proof and experimental validation comparing BCE and CE, analyzing their impact on intra-class compactness and inter-class distinctiveness.", "result": "BCE achieves NC, enhances feature properties, and improves classification performance compared to CE.", "conclusion": "BCE is a viable alternative to CE for training classification models, offering better feature compactness and distinctiveness."}}
{"id": "2505.06184", "pdf": "https://arxiv.org/pdf/2505.06184", "abs": "https://arxiv.org/abs/2505.06184", "authors": ["Vahid Rahimzadeh", "Ali Hamzehpour", "Azadeh Shakery", "Masoud Asadpour"], "title": "From Millions of Tweets to Actionable Insights: Leveraging LLMs for User Profiling", "categories": ["cs.SI", "cs.CL", "cs.IR", "I.2.7"], "comment": "Accepted at MisD @ AAAI ICWSM 2025", "summary": "Social media user profiling through content analysis is crucial for tasks\nlike misinformation detection, engagement prediction, hate speech monitoring,\nand user behavior modeling. However, existing profiling techniques, including\ntweet summarization, attribute-based profiling, and latent representation\nlearning, face significant limitations: they often lack transferability,\nproduce non-interpretable features, require large labeled datasets, or rely on\nrigid predefined categories that limit adaptability. We introduce a novel large\nlanguage model (LLM)-based approach that leverages domain-defining statements,\nwhich serve as key characteristics outlining the important pillars of a domain\nas foundations for profiling. Our two-stage method first employs\nsemi-supervised filtering with a domain-specific knowledge base, then generates\nboth abstractive (synthesized descriptions) and extractive (representative\ntweet selections) user profiles. By harnessing LLMs' inherent knowledge with\nminimal human validation, our approach is adaptable across domains while\nreducing the need for large labeled datasets. Our method generates\ninterpretable natural language user profiles, condensing extensive user data\ninto a scale that unlocks LLMs' reasoning and knowledge capabilities for\ndownstream social network tasks. We contribute a Persian political Twitter (X)\ndataset and an LLM-based evaluation framework with human validation.\nExperimental results show our method significantly outperforms state-of-the-art\nLLM-based and traditional methods by 9.8%, demonstrating its effectiveness in\ncreating flexible, adaptable, and interpretable user profiles.", "AI": {"tldr": "A novel LLM-based approach for social media user profiling uses domain-defining statements to create interpretable profiles, outperforming existing methods by 9.8%.", "motivation": "Existing profiling techniques lack transferability, interpretability, and adaptability, requiring large labeled datasets or rigid categories.", "method": "A two-stage method: semi-supervised filtering with a domain-specific knowledge base, followed by generating abstractive and extractive user profiles using LLMs.", "result": "The method outperforms state-of-the-art LLM-based and traditional methods by 9.8%, producing flexible and interpretable profiles.", "conclusion": "The approach reduces reliance on labeled data, adapts across domains, and enhances downstream social network tasks."}}
{"id": "2505.05756", "pdf": "https://arxiv.org/pdf/2505.05756", "abs": "https://arxiv.org/abs/2505.05756", "authors": ["Antonio Jimeno Yepes", "Pieter Barnard"], "title": "Evolutionary thoughts: integration of large language models and evolutionary algorithms", "categories": ["cs.NE", "cs.AI"], "comment": null, "summary": "Large Language Models (LLMs) have unveiled remarkable capabilities in\nunderstanding and generating both natural language and code, but LLM reasoning\nis prone to hallucination and struggle with complex, novel scenarios, often\ngetting stuck on partial or incorrect solutions. However, the inherent ability\nof Evolutionary Algorithms (EAs) to explore extensive and complex search spaces\nmakes them particularly effective in scenarios where traditional optimization\nmethodologies may falter. However, EAs explore a vast search space when applied\nto complex problems.\n  To address the computational bottleneck of evaluating large populations,\nparticularly crucial for complex evolutionary tasks, we introduce a highly\nefficient evaluation framework. This implementation maintains compatibility\nwith existing primitive definitions, ensuring the generation of valid\nindividuals.\n  Using LLMs, we propose an enhanced evolutionary search strategy that enables\na more focused exploration of expansive solution spaces. LLMs facilitate the\ngeneration of superior candidate solutions, as evidenced by empirical results\ndemonstrating their efficacy in producing improved outcomes.", "AI": {"tldr": "The paper proposes combining LLMs with Evolutionary Algorithms (EAs) to enhance reasoning and optimization, addressing LLM hallucinations and EA computational bottlenecks.", "motivation": "LLMs struggle with complex, novel scenarios due to hallucinations, while EAs face computational inefficiencies in large search spaces.", "method": "Introduces an efficient evaluation framework for EAs and leverages LLMs for focused evolutionary search to generate superior solutions.", "result": "Empirical results show improved outcomes from the combined LLM-EA approach.", "conclusion": "The hybrid LLM-EA strategy effectively mitigates limitations of both methods, enhancing solution quality and efficiency."}}
{"id": "2505.05681", "pdf": "https://arxiv.org/pdf/2505.05681", "abs": "https://arxiv.org/abs/2505.05681", "authors": ["Giulio Cesare Mastrocinque Santo", "Patr\u00edcia Izar", "Irene Delval", "Victor de Napole Gregolin", "Nina S. T. Hirata"], "title": "Fine-Tuning Video-Text Contrastive Model for Primate Behavior Retrieval from Unlabeled Raw Videos", "categories": ["cs.CV"], "comment": null, "summary": "Video recordings of nonhuman primates in their natural habitat are a common\nsource for studying their behavior in the wild. We fine-tune pre-trained\nvideo-text foundational models for the specific domain of capuchin monkeys,\nwith the goal of developing useful computational models to help researchers to\nretrieve useful clips from videos. We focus on the challenging problem of\ntraining a model based solely on raw, unlabeled video footage, using weak audio\ndescriptions sometimes provided by field collaborators. We leverage recent\nadvances in Multimodal Large Language Models (MLLMs) and Vision-Language Models\n(VLMs) to address the extremely noisy nature of both video and audio content.\nSpecifically, we propose a two-folded approach: an agentic data treatment\npipeline and a fine-tuning process. The data processing pipeline automatically\nextracts clean and semantically aligned video-text pairs from the raw videos,\nwhich are subsequently used to fine-tune a pre-trained Microsoft's X-CLIP model\nthrough Low-Rank Adaptation (LoRA). We obtained an uplift in $Hits@5$ of\n$167\\%$ for the 16 frames model and an uplift of $114\\%$ for the 8 frame model\non our domain data. Moreover, based on $NDCG@K$ results, our model is able to\nrank well most of the considered behaviors, while the tested raw pre-trained\nmodels are not able to rank them at all. The code will be made available upon\nacceptance.", "AI": {"tldr": "Fine-tuning pre-trained video-text models for capuchin monkey behavior analysis using noisy, unlabeled videos and weak audio descriptions, achieving significant performance improvements.", "motivation": "To develop computational models for retrieving useful clips from raw, unlabeled primate videos, leveraging weak audio descriptions.", "method": "A two-folded approach: an agentic data treatment pipeline to extract clean video-text pairs and fine-tuning a pre-trained X-CLIP model using LoRA.", "result": "167% uplift in Hits@5 for 16 frames and 114% for 8 frames; improved ranking of behaviors (NDCG@K).", "conclusion": "The proposed method effectively addresses noise in video and audio, enhancing retrieval performance for primate behavior studies."}}
{"id": "2505.05819", "pdf": "https://arxiv.org/pdf/2505.05819", "abs": "https://arxiv.org/abs/2505.05819", "authors": ["Lorenzo Beretta"], "title": "New Statistical and Computational Results for Learning Junta Distributions", "categories": ["cs.LG", "cs.DS"], "comment": null, "summary": "We study the problem of learning junta distributions on $\\{0, 1\\}^n$, where a\ndistribution is a $k$-junta if its probability mass function depends on a\nsubset of at most $k$ variables. We make two main contributions:\n  - We show that learning $k$-junta distributions is \\emph{computationally}\nequivalent to learning $k$-parity functions with noise (LPN), a landmark\nproblem in computational learning theory.\n  - We design an algorithm for learning junta distributions whose statistical\ncomplexity is optimal, up to polylogarithmic factors. Computationally, our\nalgorithm matches the complexity of previous (non-sample-optimal) algorithms.\n  Combined, our two contributions imply that our algorithm cannot be\nsignificantly improved, statistically or computationally, barring a\nbreakthrough for LPN.", "AI": {"tldr": "The paper shows that learning k-junta distributions is computationally equivalent to learning k-parity functions with noise (LPN) and presents an optimal algorithm for this task.", "motivation": "The study aims to understand the computational and statistical complexity of learning k-junta distributions, a fundamental problem in learning theory.", "method": "The paper demonstrates a computational equivalence between learning k-junta distributions and LPN, and designs an algorithm with optimal statistical complexity.", "result": "The algorithm achieves optimal statistical complexity and matches the computational complexity of prior non-optimal methods.", "conclusion": "The results imply that further improvements to the algorithm are unlikely without a breakthrough in solving LPN."}}
{"id": "2209.15373", "pdf": "https://arxiv.org/pdf/2209.15373", "abs": "https://arxiv.org/abs/2209.15373", "authors": ["Javier Huertas-Tato", "Alejandro Martin", "David Camacho"], "title": "PART: Pre-trained Authorship Representation Transformer", "categories": ["cs.CL"], "comment": null, "summary": "Authors writing documents imprint identifying information within their texts:\nvocabulary, registry, punctuation, misspellings, or even emoji usage. Previous\nworks use hand-crafted features or classification tasks to train their\nauthorship models, leading to poor performance on out-of-domain authors. Using\nstylometric representations is more suitable, but this by itself is an open\nresearch challenge. In this paper, we propose PART, a contrastively trained\nmodel fit to learn \\textbf{authorship embeddings} instead of semantics. We\ntrain our model on ~1.5M texts belonging to 1162 literature authors, 17287 blog\nposters and 135 corporate email accounts; a heterogeneous set with identifiable\nwriting styles. We evaluate the model on current challenges, achieving\ncompetitive performance. We also evaluate our model on test splits of the\ndatasets achieving zero-shot 72.39\\% accuracy when bounded to 250 authors, a\n54\\% and 56\\% higher than RoBERTa embeddings. We qualitatively assess the\nrepresentations with different data visualizations on the available datasets,\nobserving features such as gender, age, or occupation of the author.", "AI": {"tldr": "PART is a contrastively trained model for authorship embeddings, outperforming RoBERTa by 54-56% in zero-shot accuracy on 250 authors.", "motivation": "Existing authorship models rely on hand-crafted features or classification tasks, performing poorly on out-of-domain authors. Stylometric representations are needed but remain a challenge.", "method": "PART uses contrastive training to learn authorship embeddings, trained on 1.5M texts from diverse authors (literature, blogs, corporate emails).", "result": "Achieves 72.39% zero-shot accuracy on 250 authors, outperforming RoBERTa by 54-56%. Visualizations reveal features like gender, age, and occupation.", "conclusion": "PART effectively learns authorship embeddings, addressing limitations of prior methods and demonstrating strong performance and interpretability."}}
{"id": "2505.05762", "pdf": "https://arxiv.org/pdf/2505.05762", "abs": "https://arxiv.org/abs/2505.05762", "authors": ["Junhong Chen", "Ziqi Yang", "Haoyuan G Xu", "Dandan Zhang", "George Mylonas"], "title": "Multi-Agent Systems for Robotic Autonomy with LLMs", "categories": ["cs.RO", "cs.AI"], "comment": "11 pages, 2 figures, 5 tables, submitted for publication", "summary": "Since the advent of Large Language Models (LLMs), various research based on\nsuch models have maintained significant academic attention and impact,\nespecially in AI and robotics. In this paper, we propose a multi-agent\nframework with LLMs to construct an integrated system for robotic task\nanalysis, mechanical design, and path generation. The framework includes three\ncore agents: Task Analyst, Robot Designer, and Reinforcement Learning Designer.\nOutputs are formatted as multimodal results, such as code files or technical\nreports, for stronger understandability and usability. To evaluate\ngeneralizability comparatively, we conducted experiments with models from both\nGPT and DeepSeek. Results demonstrate that the proposed system can design\nfeasible robots with control strategies when appropriate task inputs are\nprovided, exhibiting substantial potential for enhancing the efficiency and\naccessibility of robotic system development in research and industrial\napplications.", "AI": {"tldr": "A multi-agent framework using LLMs for robotic task analysis, design, and path generation, evaluated with GPT and DeepSeek models, showing promise for efficient robotic system development.", "motivation": "To enhance the efficiency and accessibility of robotic system development by leveraging LLMs for integrated task analysis, design, and control strategy generation.", "method": "Proposes a framework with three core agents (Task Analyst, Robot Designer, Reinforcement Learning Designer) to generate multimodal outputs like code files and reports.", "result": "The system successfully designs feasible robots with control strategies when given appropriate task inputs, demonstrating generalizability across GPT and DeepSeek models.", "conclusion": "The framework shows substantial potential for improving robotic system development in both research and industrial applications."}}
{"id": "2505.05711", "pdf": "https://arxiv.org/pdf/2505.05711", "abs": "https://arxiv.org/abs/2505.05711", "authors": ["Ho-Joong Kim", "Yearang Lee", "Jung-Ho Hong", "Seong-Whan Lee"], "title": "DiGIT: Multi-Dilated Gated Encoder and Central-Adjacent Region Integrated Decoder for Temporal Action Detection Transformer", "categories": ["cs.CV"], "comment": "CVPR 2025", "summary": "In this paper, we examine a key limitation in query-based detectors for\ntemporal action detection (TAD), which arises from their direct adaptation of\noriginally designed architectures for object detection. Despite the\neffectiveness of the existing models, they struggle to fully address the unique\nchallenges of TAD, such as the redundancy in multi-scale features and the\nlimited ability to capture sufficient temporal context. To address these\nissues, we propose a multi-dilated gated encoder and central-adjacent region\nintegrated decoder for temporal action detection transformer (DiGIT). Our\napproach replaces the existing encoder that consists of multi-scale deformable\nattention and feedforward network with our multi-dilated gated encoder. Our\nproposed encoder reduces the redundant information caused by multi-level\nfeatures while maintaining the ability to capture fine-grained and long-range\ntemporal information. Furthermore, we introduce a central-adjacent region\nintegrated decoder that leverages a more comprehensive sampling strategy for\ndeformable cross-attention to capture the essential information. Extensive\nexperiments demonstrate that DiGIT achieves state-of-the-art performance on\nTHUMOS14, ActivityNet v1.3, and HACS-Segment. Code is available at:\nhttps://github.com/Dotori-HJ/DiGIT", "AI": {"tldr": "The paper identifies limitations in query-based detectors for temporal action detection (TAD) due to their adaptation from object detection architectures. It proposes DiGIT, a transformer-based model with a multi-dilated gated encoder and central-adjacent region integrated decoder, achieving state-of-the-art results.", "motivation": "Existing TAD models, adapted from object detection, struggle with redundancy in multi-scale features and insufficient temporal context capture.", "method": "DiGIT replaces the standard encoder with a multi-dilated gated encoder to reduce redundancy and enhance temporal context. It also introduces a central-adjacent region integrated decoder for better sampling in deformable cross-attention.", "result": "DiGIT outperforms existing models on THUMOS14, ActivityNet v1.3, and HACS-Segment benchmarks.", "conclusion": "The proposed DiGIT model effectively addresses TAD challenges, offering improved performance and a novel architecture for future research."}}
{"id": "2505.05857", "pdf": "https://arxiv.org/pdf/2505.05857", "abs": "https://arxiv.org/abs/2505.05857", "authors": ["Nathan Justin", "Qingshi Sun", "Andr\u00e9s G\u00f3mez", "Phebe Vayanos"], "title": "Mixed-Integer Optimization for Responsible Machine Learning", "categories": ["cs.LG", "math.OC", "stat.ML"], "comment": "56 pages, 10 figures", "summary": "In the last few decades, Machine Learning (ML) has achieved significant\nsuccess across domains ranging from healthcare, sustainability, and the social\nsciences, to criminal justice and finance. But its deployment in increasingly\nsophisticated, critical, and sensitive areas affecting individuals, the groups\nthey belong to, and society as a whole raises critical concerns around\nfairness, transparency, robustness, and privacy, among others. As the\ncomplexity and scale of ML systems and of the settings in which they are\ndeployed grow, so does the need for responsible ML methods that address these\nchallenges while providing guaranteed performance in deployment.\n  Mixed-integer optimization (MIO) offers a powerful framework for embedding\nresponsible ML considerations directly into the learning process while\nmaintaining performance. For example, it enables learning of inherently\ntransparent models that can conveniently incorporate fairness or other domain\nspecific constraints. This tutorial paper provides an accessible and\ncomprehensive introduction to this topic discussing both theoretical and\npractical aspects. It outlines some of the core principles of responsible ML,\ntheir importance in applications, and the practical utility of MIO for building\nML models that align with these principles. Through examples and mathematical\nformulations, it illustrates practical strategies and available tools for\nefficiently solving MIO problems for responsible ML. It concludes with a\ndiscussion on current limitations and open research questions, providing\nsuggestions for future work.", "AI": {"tldr": "The paper introduces mixed-integer optimization (MIO) as a framework for embedding responsible ML principles like fairness and transparency into machine learning models while maintaining performance.", "motivation": "The increasing deployment of ML in critical and sensitive areas raises concerns about fairness, transparency, and privacy, necessitating responsible ML methods.", "method": "The paper uses MIO to integrate responsible ML considerations directly into the learning process, providing theoretical and practical insights.", "result": "MIO enables the learning of transparent models with fairness constraints, offering practical tools and strategies for implementation.", "conclusion": "The paper highlights MIO's utility for responsible ML, discusses current limitations, and suggests future research directions."}}
{"id": "2403.19346", "pdf": "https://arxiv.org/pdf/2403.19346", "abs": "https://arxiv.org/abs/2403.19346", "authors": ["Jingyuan Ma", "Damai Dai", "Zihang Yuan", "Rui li", "Weilin Luo", "Bin Wang", "Qun Liu", "Lei Sha", "Zhifang Sui"], "title": "Large Language Models Are Struggle to Cope with Unreasonability in Math Problems", "categories": ["cs.CL"], "comment": "32 pages, 8 figures", "summary": "Recent research have demonstrated LLMs' impressive performance in math and\nreasoning. However, the capacity of LLMs to address math problems under\nunconventional conditions, such as internal inconsistencies and flawed\nassumptions, remains largely unexplored. In this paper, we propose a novel\nbenchmark Unreasonable Math Problem (UMP) designed to assess LLMs' ability to\nrecognize and respond to unreasonability in math problem. The benchmark\nconsists of a carefully curated collection of unreasonable math questions\nacross diverse types. Based on extensive experiments covering 19 LLMs, we\nobserve that even state-of-the-art models such as GPT-4o achieve only limited\nperformance of 0.6 in UMP, while reasoning models such as DeepSeek-R1 are prone\nto overthinking and unstable. We further explore strategies for improving the\nrecognition of unreasonable inputs, shedding light on both the possibility and\nlimitations of LLMs in this challenging setting.", "AI": {"tldr": "A new benchmark, Unreasonable Math Problem (UMP), evaluates LLMs' ability to handle unconventional math problems with inconsistencies. State-of-the-art models like GPT-4o perform poorly (0.6 score), while reasoning models like DeepSeek-R1 struggle with instability.", "motivation": "To explore LLMs' capability in addressing math problems with flawed assumptions or inconsistencies, an area not well-studied.", "method": "Proposed the UMP benchmark, a curated set of unreasonable math questions, and tested 19 LLMs, including GPT-4o and DeepSeek-R1.", "result": "Even top models like GPT-4o scored only 0.6 on UMP; reasoning models showed instability.", "conclusion": "The study highlights LLMs' limitations in handling unreasonable math problems and suggests potential improvement strategies."}}
{"id": "2505.05777", "pdf": "https://arxiv.org/pdf/2505.05777", "abs": "https://arxiv.org/abs/2505.05777", "authors": ["Domenico Cotroneo", "Giuseppe De Rosa", "Pietro Liguori"], "title": "PyResBugs: A Dataset of Residual Python Bugs for Natural Language-Driven Fault Injection", "categories": ["cs.SE", "cs.AI"], "comment": null, "summary": "This paper presents PyResBugs, a curated dataset of residual bugs, i.e.,\ndefects that persist undetected during traditional testing but later surface in\nproduction, collected from major Python frameworks. Each bug in the dataset is\npaired with its corresponding fault-free (fixed) version and annotated with\nmulti-level natural language (NL) descriptions. These NL descriptions enable\nnatural language-driven fault injection, offering a novel approach to\nsimulating real-world faults in software systems. By bridging the gap between\nsoftware fault injection techniques and real-world representativeness,\nPyResBugs provides researchers with a high-quality resource for advancing\nAI-driven automated testing in Python systems.", "AI": {"tldr": "PyResBugs is a dataset of residual bugs in Python frameworks, paired with fixed versions and NL descriptions, enabling NL-driven fault injection for realistic testing.", "motivation": "To address the gap between traditional testing and real-world defects by providing a resource for simulating realistic faults in Python systems.", "method": "Curated dataset of residual bugs from Python frameworks, annotated with NL descriptions for fault injection.", "result": "PyResBugs offers a high-quality resource for AI-driven automated testing, enhancing fault simulation representativeness.", "conclusion": "PyResBugs bridges the gap between fault injection techniques and real-world defects, advancing automated testing research."}}
{"id": "2505.05721", "pdf": "https://arxiv.org/pdf/2505.05721", "abs": "https://arxiv.org/abs/2505.05721", "authors": ["Zixuan Li", "Lei Meng", "Guoqing Chao", "Wei Wu", "Xiaoshuo Yan", "Yimeng Yang", "Zhuang Qi", "Xiangxu Meng"], "title": "Semantic-Space-Intervened Diffusive Alignment for Visual Classification", "categories": ["cs.CV"], "comment": null, "summary": "Cross-modal alignment is an effective approach to improving visual\nclassification. Existing studies typically enforce a one-step mapping that uses\ndeep neural networks to project the visual features to mimic the distribution\nof textual features. However, they typically face difficulties in finding such\na projection due to the two modalities in both the distribution of class-wise\nsamples and the range of their feature values. To address this issue, this\npaper proposes a novel Semantic-Space-Intervened Diffusive Alignment method,\ntermed SeDA, models a semantic space as a bridge in the visual-to-textual\nprojection, considering both types of features share the same class-level\ninformation in classification. More importantly, a bi-stage diffusion framework\nis developed to enable the progressive alignment between the two modalities.\nSpecifically, SeDA first employs a Diffusion-Controlled Semantic Learner to\nmodel the semantic features space of visual features by constraining the\ninteractive features of the diffusion model and the category centers of visual\nfeatures. In the later stage of SeDA, the Diffusion-Controlled Semantic\nTranslator focuses on learning the distribution of textual features from the\nsemantic space. Meanwhile, the Progressive Feature Interaction Network\nintroduces stepwise feature interactions at each alignment step, progressively\nintegrating textual information into mapped features. Experimental results show\nthat SeDA achieves stronger cross-modal feature alignment, leading to superior\nperformance over existing methods across multiple scenarios.", "AI": {"tldr": "SeDA improves cross-modal alignment by introducing a semantic space and a bi-stage diffusion framework for progressive alignment between visual and textual features.", "motivation": "Existing methods struggle with one-step mapping due to distribution mismatches between visual and textual features.", "method": "SeDA uses a semantic space as a bridge and a bi-stage diffusion framework (Diffusion-Controlled Semantic Learner and Translator) with progressive feature interactions.", "result": "SeDA outperforms existing methods in cross-modal alignment across multiple scenarios.", "conclusion": "SeDA effectively addresses alignment challenges by leveraging semantic space and progressive diffusion, enhancing visual classification."}}
{"id": "2505.05868", "pdf": "https://arxiv.org/pdf/2505.05868", "abs": "https://arxiv.org/abs/2505.05868", "authors": ["Changkun Ye", "Russell Tsuchida", "Lars Petersson", "Nick Barnes"], "title": "Open Set Label Shift with Test Time Out-of-Distribution Reference", "categories": ["cs.LG"], "comment": "Accepted at CVPR 2025", "summary": "Open set label shift (OSLS) occurs when label distributions change from a\nsource to a target distribution, and the target distribution has an additional\nout-of-distribution (OOD) class. In this work, we build estimators for both\nsource and target open set label distributions using a source domain\nin-distribution (ID) classifier and an ID/OOD classifier. With reasonable\nassumptions on the ID/OOD classifier, the estimators are assembled into a\nsequence of three stages: 1) an estimate of the source label distribution of\nthe OOD class, 2) an EM algorithm for Maximum Likelihood estimates (MLE) of the\ntarget label distribution, and 3) an estimate of the target label distribution\nof OOD class under relaxed assumptions on the OOD classifier. The sampling\nerrors of estimates in 1) and 3) are quantified with a concentration\ninequality. The estimation result allows us to correct the ID classifier\ntrained on the source distribution to the target distribution without\nretraining. Experiments on a variety of open set label shift settings\ndemonstrate the effectiveness of our model. Our code is available at\nhttps://github.com/ChangkunYe/OpenSetLabelShift.", "AI": {"tldr": "The paper proposes a method to estimate source and target label distributions under open set label shift (OSLS) using classifiers, with a three-stage approach and error quantification.", "motivation": "Addressing the challenge of OSLS, where label distributions shift and an out-of-distribution (OOD) class is introduced in the target domain.", "method": "A three-stage approach: 1) estimate source OOD label distribution, 2) EM algorithm for MLE of target label distribution, 3) relaxed OOD classifier assumptions for target OOD distribution. Sampling errors are quantified.", "result": "Effective correction of the ID classifier for the target distribution without retraining, validated in various OSLS settings.", "conclusion": "The method successfully handles OSLS by estimating label distributions and correcting classifiers, with demonstrated effectiveness."}}
{"id": "2406.09519", "pdf": "https://arxiv.org/pdf/2406.09519", "abs": "https://arxiv.org/abs/2406.09519", "authors": ["Jack Merullo", "Carsten Eickhoff", "Ellie Pavlick"], "title": "Talking Heads: Understanding Inter-layer Communication in Transformer Language Models", "categories": ["cs.CL", "cs.AI"], "comment": "Neurips 2024", "summary": "Although it is known that transformer language models (LMs) pass features\nfrom early layers to later layers, it is not well understood how this\ninformation is represented and routed by the model. We analyze a mechanism used\nin two LMs to selectively inhibit items in a context in one task, and find that\nit underlies a commonly used abstraction across many context-retrieval\nbehaviors. Specifically, we find that models write into low-rank subspaces of\nthe residual stream to represent features which are then read out by later\nlayers, forming low-rank communication channels (Elhage et al., 2021) between\nlayers. A particular 3D subspace in model activations in GPT-2 can be traversed\nto positionally index items in lists, and we show that this mechanism can\nexplain an otherwise arbitrary-seeming sensitivity of the model to the order of\nitems in the prompt. That is, the model has trouble copying the correct\ninformation from context when many items ``crowd\" this limited space. By\ndecomposing attention heads with the Singular Value Decomposition (SVD), we\nfind that previously described interactions between heads separated by one or\nmore layers can be predicted via analysis of their weight matrices alone. We\nshow that it is possible to manipulate the internal model representations as\nwell as edit model weights based on the mechanism we discover in order to\nsignificantly improve performance on our synthetic Laundry List task, which\nrequires recall from a list, often improving task accuracy by over 20%. Our\nanalysis reveals a surprisingly intricate interpretable structure learned from\nlanguage model pretraining, and helps us understand why sophisticated LMs\nsometimes fail in simple domains, facilitating future analysis of more complex\nbehaviors.", "AI": {"tldr": "The paper investigates how transformer LMs represent and route information between layers, revealing low-rank communication channels and a 3D subspace in GPT-2 for positional indexing. It explains model sensitivity to item order and improves task performance by manipulating representations.", "motivation": "To understand how transformer LMs internally represent and route information, particularly why they sometimes fail in simple tasks despite their sophistication.", "method": "Analyzes mechanisms in two LMs, focusing on low-rank subspaces in the residual stream and attention head interactions via SVD. Manipulates model representations and weights to improve performance.", "result": "Identifies a 3D subspace for positional indexing in GPT-2, explains sensitivity to item order, and improves task accuracy by over 20% through discovered mechanisms.", "conclusion": "Reveals intricate interpretable structures in LMs, aiding understanding of their failures and enabling future analysis of complex behaviors."}}
{"id": "2505.05784", "pdf": "https://arxiv.org/pdf/2505.05784", "abs": "https://arxiv.org/abs/2505.05784", "authors": ["Yang Li", "Zhi Chen", "Steve Yang"], "title": "FlowHFT: Flow Policy Induced Optimal High-Frequency Trading under Diverse Market Conditions", "categories": ["q-fin.TR", "cs.AI", "cs.CE", "q-fin.CP"], "comment": "14 pages, 1 figure, 6 tables, 2 algorithms", "summary": "High-frequency trading (HFT) is an investing strategy that continuously\nmonitors market states and places bid and ask orders at millisecond speeds.\nTraditional HFT approaches fit models with historical data and assume that\nfuture market states follow similar patterns. This limits the effectiveness of\nany single model to the specific conditions it was trained for. Additionally,\nthese models achieve optimal solutions only under specific market conditions,\nsuch as assumptions about stock price's stochastic process, stable order flow,\nand the absence of sudden volatility. Real-world markets, however, are dynamic,\ndiverse, and frequently volatile. To address these challenges, we propose the\nFlowHFT, a novel imitation learning framework based on flow matching policy.\nFlowHFT simultaneously learns strategies from numerous expert models, each\nproficient in particular market scenarios. As a result, our framework can\nadaptively adjust investment decisions according to the prevailing market\nstate. Furthermore, FlowHFT incorporates a grid-search fine-tuning mechanism.\nThis allows it to refine strategies and achieve superior performance even in\ncomplex or extreme market scenarios where expert strategies may be suboptimal.\nWe test FlowHFT in multiple market environments. We first show that flow\nmatching policy is applicable in stochastic market environments, thus enabling\nFlowHFT to learn trading strategies under different market conditions. Notably,\nour single framework consistently achieves performance superior to the best\nexpert for each market condition.", "AI": {"tldr": "FlowHFT is an imitation learning framework for high-frequency trading that adapts to diverse market conditions by learning from multiple expert models and fine-tuning strategies.", "motivation": "Traditional HFT models are limited by their reliance on historical data and assumptions about stable market conditions, which don't hold in dynamic, volatile real-world markets.", "method": "FlowHFT uses a flow matching policy to learn from multiple expert models and incorporates grid-search fine-tuning to refine strategies for various market scenarios.", "result": "FlowHFT outperforms individual expert models across different market conditions, demonstrating adaptability and superior performance.", "conclusion": "FlowHFT provides a robust solution for HFT by dynamically adjusting to market states and refining strategies, making it effective in diverse and volatile environments."}}
{"id": "2505.05722", "pdf": "https://arxiv.org/pdf/2505.05722", "abs": "https://arxiv.org/abs/2505.05722", "authors": ["Valay Bundele", "Mehran Hosseinzadeh", "Hendrik Lensch"], "title": "You Are Your Best Teacher: Semi-Supervised Surgical Point Tracking with Cycle-Consistent Self-Distillation", "categories": ["cs.CV"], "comment": "Accepted at CVPR 2025 SynData4CV Workshop", "summary": "Synthetic datasets have enabled significant progress in point tracking by\nproviding large-scale, densely annotated supervision. However, deploying these\nmodels in real-world domains remains challenging due to domain shift and lack\nof labeled data-issues that are especially severe in surgical videos, where\nscenes exhibit complex tissue deformation, occlusion, and lighting variation.\nWhile recent approaches adapt synthetic-trained trackers to natural videos\nusing teacher ensembles or augmentation-heavy pseudo-labeling pipelines, their\neffectiveness in high-shift domains like surgery remains unexplored. This work\npresents SurgTracker, a semi-supervised framework for adapting\nsynthetic-trained point trackers to surgical video using filtered\nself-distillation. Pseudo-labels are generated online by a fixed\nteacher-identical in architecture and initialization to the student-and are\nfiltered using a cycle consistency constraint to discard temporally\ninconsistent trajectories. This simple yet effective design enforces geometric\nconsistency and provides stable supervision throughout training, without the\ncomputational overhead of maintaining multiple teachers. Experiments on the\nSTIR benchmark show that SurgTracker improves tracking performance using only\n80 unlabeled videos, demonstrating its potential for robust adaptation in\nhigh-shift, data-scarce domains.", "AI": {"tldr": "SurgTracker, a semi-supervised framework, adapts synthetic-trained point trackers to surgical videos using filtered self-distillation, improving performance with minimal labeled data.", "motivation": "Overcoming domain shift and lack of labeled data in surgical videos, which exhibit complex challenges like tissue deformation and lighting variation.", "method": "Uses filtered self-distillation with a fixed teacher-student setup, generating pseudo-labels online and filtering them via cycle consistency for geometric stability.", "result": "Achieves improved tracking performance on the STIR benchmark using only 80 unlabeled videos.", "conclusion": "Demonstrates robust adaptation in high-shift, data-scarce domains like surgery."}}
{"id": "2505.05869", "pdf": "https://arxiv.org/pdf/2505.05869", "abs": "https://arxiv.org/abs/2505.05869", "authors": ["Hao Xu", "Yuntian Chen", "Rui Cao", "Tianning Tang", "Mengge Du", "Jian Li", "Adrian H. Callaghan", "Dongxiao Zhang"], "title": "Generative Discovery of Partial Differential Equations by Learning from Math Handbooks", "categories": ["cs.LG", "cs.AI", "physics.comp-ph"], "comment": null, "summary": "Data driven discovery of partial differential equations (PDEs) is a promising\napproach for uncovering the underlying laws governing complex systems. However,\npurely data driven techniques face the dilemma of balancing search space with\noptimization efficiency. This study introduces a knowledge guided approach that\nincorporates existing PDEs documented in a mathematical handbook to facilitate\nthe discovery process. These PDEs are encoded as sentence like structures\ncomposed of operators and basic terms, and used to train a generative model,\ncalled EqGPT, which enables the generation of free form PDEs. A loop of\ngeneration evaluation optimization is constructed to autonomously identify the\nmost suitable PDE. Experimental results demonstrate that this framework can\nrecover a variety of PDE forms with high accuracy and computational efficiency,\nparticularly in cases involving complex temporal derivatives or intricate\nspatial terms, which are often beyond the reach of conventional methods. The\napproach also exhibits generalizability to irregular spatial domains and higher\ndimensional settings. Notably, it succeeds in discovering a previously\nunreported PDE governing strongly nonlinear surface gravity waves propagating\ntoward breaking, based on real world experimental data, highlighting its\napplicability to practical scenarios and its potential to support scientific\ndiscovery.", "AI": {"tldr": "The paper introduces a knowledge-guided approach, EqGPT, for discovering PDEs by leveraging documented PDEs and a generative model, achieving high accuracy and efficiency.", "motivation": "To address the challenge of balancing search space and optimization efficiency in data-driven PDE discovery.", "method": "Uses documented PDEs encoded as sentence-like structures to train EqGPT, a generative model, followed by a generation-evaluation-optimization loop.", "result": "Recovers various PDE forms accurately and efficiently, even for complex cases, and discovers a new PDE for nonlinear surface gravity waves.", "conclusion": "The approach is effective, generalizable, and applicable to real-world problems, supporting scientific discovery."}}
{"id": "2407.11963", "pdf": "https://arxiv.org/pdf/2407.11963", "abs": "https://arxiv.org/abs/2407.11963", "authors": ["Mo Li", "Songyang Zhang", "Taolin Zhang", "Haodong Duan", "Yunxin Liu", "Kai Chen"], "title": "NeedleBench: Can LLMs Do Retrieval and Reasoning in Information-Dense Context?", "categories": ["cs.CL"], "comment": "v2: updated with tested models and Multi-Needle Reasoning\n  implementation", "summary": "The capability of large language models to handle long-context information is\ncrucial across various real-world applications. Existing evaluation methods\noften rely either on real-world long texts, making it difficult to exclude the\ninfluence of models' inherent knowledge, or introduce irrelevant filler content\nto artificially achieve target lengths, reducing assessment effectiveness. To\naddress these limitations, we introduce NeedleBench, a synthetic framework for\nassessing retrieval and reasoning performance in bilingual long-context tasks\nwith adaptive context lengths. NeedleBench systematically embeds key data\npoints at varying depths to rigorously test model capabilities. Tasks are\ncategorized into two scenarios: information-sparse, featuring minimal relevant\ndetails within extensive irrelevant text to simulate simple retrieval tasks;\nand information-dense (the Ancestral Trace Challenge), where relevant\ninformation is continuously distributed throughout the context to simulate\ncomplex reasoning tasks. Our experiments reveal that although recent reasoning\nmodels like Deepseek-R1 and OpenAI's o3 excel in mathematical reasoning, they\nstruggle with continuous retrieval and reasoning in information-dense\nscenarios, even at shorter context lengths. We also characterize a phenomenon\ntermed 'under-thinking', where models prematurely conclude reasoning despite\navailable information. NeedleBench thus provides critical insights and targeted\ntools essential for evaluating and improving LLMs' long-context capabilities.\nAll resources are available at OpenCompass:\nhttps://github.com/open-compass/opencompass.", "AI": {"tldr": "NeedleBench is a synthetic framework for evaluating retrieval and reasoning in bilingual long-context tasks, addressing limitations of existing methods.", "motivation": "Existing evaluation methods for long-context handling in LLMs are flawed, either relying on real-world texts or artificial fillers, reducing effectiveness.", "method": "NeedleBench embeds key data at varying depths, testing models in two scenarios: information-sparse (simple retrieval) and information-dense (complex reasoning).", "result": "Models like Deepseek-R1 and OpenAI's o3 struggle with continuous retrieval and reasoning in dense scenarios, showing 'under-thinking' behavior.", "conclusion": "NeedleBench offers insights and tools for improving LLMs' long-context capabilities, with resources available on OpenCompass."}}
{"id": "2505.05794", "pdf": "https://arxiv.org/pdf/2505.05794", "abs": "https://arxiv.org/abs/2505.05794", "authors": ["Renjie Li", "Wenjie Wei", "Qi Xin", "Xiaoli Liu", "Sixuan Mao", "Erik Ma", "Zijian Chen", "Malu Zhang", "Haizhou Li", "Zhaoyu Zhang"], "title": "What Is Next for LLMs? Next-Generation AI Computing Hardware Using Photonic Chips", "categories": ["cs.AR", "cs.AI", "cs.NE"], "comment": "36 pages, 22 figures", "summary": "Large language models (LLMs) are rapidly pushing the limits of contemporary\ncomputing hardware. For example, training GPT-3 has been estimated to consume\naround 1300 MWh of electricity, and projections suggest future models may\nrequire city-scale (gigawatt) power budgets. These demands motivate exploration\nof computing paradigms beyond conventional von Neumann architectures. This\nreview surveys emerging photonic hardware optimized for next-generation\ngenerative AI computing. We discuss integrated photonic neural network\narchitectures (e.g., Mach-Zehnder interferometer meshes, lasers,\nwavelength-multiplexed microring resonators) that perform ultrafast matrix\noperations. We also examine promising alternative neuromorphic devices,\nincluding spiking neural network circuits and hybrid spintronic-photonic\nsynapses, which combine memory and processing. The integration of\ntwo-dimensional materials (graphene, TMDCs) into silicon photonic platforms is\nreviewed for tunable modulators and on-chip synaptic elements.\nTransformer-based LLM architectures (self-attention and feed-forward layers)\nare analyzed in this context, identifying strategies and challenges for mapping\ndynamic matrix multiplications onto these novel hardware substrates. We then\ndissect the mechanisms of mainstream LLMs, such as ChatGPT, DeepSeek, and\nLLaMA, highlighting their architectural similarities and differences. We\nsynthesize state-of-the-art components, algorithms, and integration methods,\nhighlighting key advances and open issues in scaling such systems to mega-sized\nLLM models. We find that photonic computing systems could potentially surpass\nelectronic processors by orders of magnitude in throughput and energy\nefficiency, but require breakthroughs in memory, especially for long-context\nwindows and long token sequences, and in storage of ultra-large datasets.", "AI": {"tldr": "The paper reviews photonic hardware for AI computing, highlighting its potential to surpass electronic processors in efficiency but noting challenges in memory and storage for large language models.", "motivation": "The high energy demands of large language models (LLMs) like GPT-3 motivate exploring alternative computing paradigms, such as photonic hardware, to improve efficiency.", "method": "The review surveys photonic neural network architectures, neuromorphic devices, and integration of 2D materials, analyzing their application to LLMs like ChatGPT and LLaMA.", "result": "Photonic systems could outperform electronic processors in throughput and energy efficiency but face challenges in memory and storage for scaling to mega-sized LLMs.", "conclusion": "Photonic computing offers promising advancements for AI but requires breakthroughs in memory and storage to fully realize its potential for large-scale LLMs."}}
{"id": "2505.05741", "pdf": "https://arxiv.org/pdf/2505.05741", "abs": "https://arxiv.org/abs/2505.05741", "authors": ["Zhangchi Hu", "Peixi Wu", "Jie Chen", "Huyue Zhu", "Yijun Wang", "Yansong Peng", "Hebei Li", "Xiaoyan Sun"], "title": "Dome-DETR: DETR with Density-Oriented Feature-Query Manipulation for Efficient Tiny Object Detection", "categories": ["cs.CV"], "comment": null, "summary": "Tiny object detection plays a vital role in drone surveillance, remote\nsensing, and autonomous systems, enabling the identification of small targets\nacross vast landscapes. However, existing methods suffer from inefficient\nfeature leverage and high computational costs due to redundant feature\nprocessing and rigid query allocation. To address these challenges, we propose\nDome-DETR, a novel framework with Density-Oriented Feature-Query Manipulation\nfor Efficient Tiny Object Detection. To reduce feature redundancies, we\nintroduce a lightweight Density-Focal Extractor (DeFE) to produce clustered\ncompact foreground masks. Leveraging these masks, we incorporate Masked Window\nAttention Sparsification (MWAS) to focus computational resources on the most\ninformative regions via sparse attention. Besides, we propose Progressive\nAdaptive Query Initialization (PAQI), which adaptively modulates query density\nacross spatial areas for better query allocation. Extensive experiments\ndemonstrate that Dome-DETR achieves state-of-the-art performance (+3.3 AP on\nAI-TOD-V2 and +2.5 AP on VisDrone) while maintaining low computational\ncomplexity and a compact model size. Code will be released upon acceptance.", "AI": {"tldr": "Dome-DETR is a novel framework for efficient tiny object detection, addressing feature redundancy and query allocation issues with Density-Oriented Feature-Query Manipulation.", "motivation": "Existing methods for tiny object detection suffer from inefficient feature leverage and high computational costs due to redundant processing and rigid query allocation.", "method": "Proposes Density-Focal Extractor (DeFE) for compact foreground masks, Masked Window Attention Sparsification (MWAS) for focused computation, and Progressive Adaptive Query Initialization (PAQI) for adaptive query density.", "result": "Achieves state-of-the-art performance (+3.3 AP on AI-TOD-V2, +2.5 AP on VisDrone) with low computational complexity and compact model size.", "conclusion": "Dome-DETR effectively improves tiny object detection efficiency and performance, offering a practical solution for applications like drone surveillance and autonomous systems."}}
{"id": "2505.05874", "pdf": "https://arxiv.org/pdf/2505.05874", "abs": "https://arxiv.org/abs/2505.05874", "authors": ["Anjie Qiao", "Hao Zhang", "Qianmu Yuan", "Qirui Deng", "Jingtian Su", "Weifeng Huang", "Huihao Zhou", "Guo-Bo Li", "Zhen Wang", "Jinping Lei"], "title": "A 3D pocket-aware and evolutionary conserved interaction guided diffusion model for molecular optimization", "categories": ["cs.LG", "physics.chem-ph", "q-bio.BM"], "comment": null, "summary": "Generating molecules that bind to specific protein targets via diffusion\nmodels has shown good promise for structure-based drug design and molecule\noptimization. Especially, the diffusion models with binding interaction\nguidance enables molecule generation with high affinity through forming\nfavorable interaction within protein pocket. However, the generated molecules\nmay not form interactions with the highly conserved residues, which are\nimportant for protein functions and bioactivities of the ligands. Herein, we\ndeveloped a new 3D target-aware diffusion model DiffDecip, which explicitly\nincorporates the protein-ligand binding interactions and evolutionary\nconservation information of protein residues into both diffusion and sampling\nprocess, for molecule optimization through scaffold decoration. The model\nperformance revealed that DiffDecip outperforms baseline model DiffDec on\nmolecule optimization towards higher affinity through forming more non-covalent\ninteractions with highly conserved residues in the protein pocket.", "AI": {"tldr": "DiffDecip, a 3D target-aware diffusion model, improves molecule optimization by incorporating protein-ligand interactions and evolutionary conservation, outperforming baseline models in affinity and interaction with conserved residues.", "motivation": "Existing diffusion models for molecule generation lack focus on highly conserved protein residues, which are crucial for protein function and ligand bioactivity.", "method": "DiffDecip integrates protein-ligand binding interactions and residue conservation into diffusion and sampling processes for scaffold decoration.", "result": "DiffDecip outperforms baseline models by generating molecules with higher affinity and more interactions with conserved residues.", "conclusion": "DiffDecip advances structure-based drug design by prioritizing conserved residues, enhancing molecule optimization."}}
{"id": "2408.00103", "pdf": "https://arxiv.org/pdf/2408.00103", "abs": "https://arxiv.org/abs/2408.00103", "authors": ["Riccardo Orlando", "Pere-Lluis Huguet Cabot", "Edoardo Barba", "Roberto Navigli"], "title": "ReLiK: Retrieve and LinK, Fast and Accurate Entity Linking and Relation Extraction on an Academic Budget", "categories": ["cs.CL", "cs.AI"], "comment": "Findings of the Association for Computational Linguistics ACL 2024", "summary": "Entity Linking (EL) and Relation Extraction (RE) are fundamental tasks in\nNatural Language Processing, serving as critical components in a wide range of\napplications. In this paper, we propose ReLiK, a Retriever-Reader architecture\nfor both EL and RE, where, given an input text, the Retriever module undertakes\nthe identification of candidate entities or relations that could potentially\nappear within the text. Subsequently, the Reader module is tasked to discern\nthe pertinent retrieved entities or relations and establish their alignment\nwith the corresponding textual spans. Notably, we put forward an innovative\ninput representation that incorporates the candidate entities or relations\nalongside the text, making it possible to link entities or extract relations in\na single forward pass and to fully leverage pre-trained language models\ncontextualization capabilities, in contrast with previous\nRetriever-Reader-based methods, which require a forward pass for each\ncandidate. Our formulation of EL and RE achieves state-of-the-art performance\nin both in-domain and out-of-domain benchmarks while using academic budget\ntraining and with up to 40x inference speed compared to competitors. Finally,\nwe show how our architecture can be used seamlessly for Information Extraction\n(cIE), i.e. EL + RE, and setting a new state of the art by employing a shared\nReader that simultaneously extracts entities and relations.", "AI": {"tldr": "ReLiK is a Retriever-Reader architecture for Entity Linking (EL) and Relation Extraction (RE), combining both tasks efficiently with a single forward pass and achieving state-of-the-art performance.", "motivation": "To improve efficiency and performance in EL and RE by integrating them into a unified framework, leveraging pre-trained language models.", "method": "Uses a Retriever to identify candidates and a Reader to align them with text spans, employing an innovative input representation for single-pass processing.", "result": "Achieves state-of-the-art in benchmarks, with 40x faster inference and academic budget training.", "conclusion": "ReLiK sets a new standard for EL and RE, and extends seamlessly to combined Information Extraction (cIE)."}}
{"id": "2505.05796", "pdf": "https://arxiv.org/pdf/2505.05796", "abs": "https://arxiv.org/abs/2505.05796", "authors": ["Xinyu Liang", "Frits de Nijs", "Buser Say", "Hao Wang"], "title": "Human-in-the-Loop AI for HVAC Management Enhancing Comfort and Energy Efficiency", "categories": ["eess.SY", "cs.AI", "cs.SY", "math.OC"], "comment": "ACM e-Energy 2025", "summary": "Heating, Ventilation, and Air Conditioning (HVAC) systems account for\napproximately 38% of building energy consumption globally, making them one of\nthe most energy-intensive services. The increasing emphasis on energy\nefficiency and sustainability, combined with the need for enhanced occupant\ncomfort, presents a significant challenge for traditional HVAC systems. These\nsystems often fail to dynamically adjust to real-time changes in electricity\nmarket rates or individual comfort preferences, leading to increased energy\ncosts and reduced comfort. In response, we propose a Human-in-the-Loop (HITL)\nArtificial Intelligence framework that optimizes HVAC performance by\nincorporating real-time user feedback and responding to fluctuating electricity\nprices. Unlike conventional systems that require predefined information about\noccupancy or comfort levels, our approach learns and adapts based on ongoing\nuser input. By integrating the occupancy prediction model with reinforcement\nlearning, the system improves operational efficiency and reduces energy costs\nin line with electricity market dynamics, thereby contributing to demand\nresponse initiatives. Through simulations, we demonstrate that our method\nachieves significant cost reductions compared to baseline approaches while\nmaintaining or enhancing occupant comfort. This feedback-driven approach\nensures personalized comfort control without the need for predefined settings,\noffering a scalable solution that balances individual preferences with economic\nand environmental goals.", "AI": {"tldr": "A Human-in-the-Loop AI framework optimizes HVAC systems by integrating real-time user feedback and electricity price fluctuations, reducing energy costs while maintaining comfort.", "motivation": "Traditional HVAC systems lack dynamic adjustment to real-time changes in electricity rates or user comfort preferences, leading to inefficiency.", "method": "Proposes a feedback-driven AI framework combining occupancy prediction and reinforcement learning to adapt HVAC performance.", "result": "Simulations show significant cost reductions and maintained or improved occupant comfort compared to baseline methods.", "conclusion": "The approach offers a scalable solution balancing individual comfort with economic and environmental efficiency."}}
{"id": "2505.05748", "pdf": "https://arxiv.org/pdf/2505.05748", "abs": "https://arxiv.org/abs/2505.05748", "authors": ["Huan Yan", "Junjie Hu"], "title": "kFuse: A novel density based agglomerative clustering", "categories": ["cs.CV"], "comment": "13 pages, 11 figures", "summary": "Agglomerative clustering has emerged as a vital tool in data analysis due to\nits intuitive and flexible characteristics. However, existing agglomerative\nclustering methods often involve additional parameters for sub-cluster\npartitioning and inter-cluster similarity assessment. This necessitates\ndifferent parameter settings across various datasets, which is undoubtedly\nchallenging in the absence of prior knowledge. Moreover, existing agglomerative\nclustering techniques are constrained by the calculation method of connection\ndistance, leading to unstable clustering results. To address these issues, this\npaper introduces a novel density-based agglomerative clustering method, termed\nkFuse. kFuse comprises four key components: (1) sub-cluster partitioning based\non natural neighbors; (2) determination of boundary connectivity between\nsub-clusters through the computation of adjacent samples and shortest\ndistances; (3) assessment of density similarity between sub-clusters via the\ncalculation of mean density and variance; and (4) establishment of merging\nrules between sub-clusters based on boundary connectivity and density\nsimilarity. kFuse requires the specification of the number of clusters only at\nthe final merging stage. Additionally, by comprehensively considering adjacent\nsamples, distances, and densities among different sub-clusters, kFuse\nsignificantly enhances accuracy during the merging phase, thereby greatly\nimproving its identification capability. Experimental results on both synthetic\nand real-world datasets validate the effectiveness of kFuse.", "AI": {"tldr": "The paper introduces kFuse, a density-based agglomerative clustering method, addressing parameter dependency and instability in traditional methods.", "motivation": "Existing agglomerative clustering methods require parameter tuning and suffer from unstable results due to distance calculation constraints.", "method": "kFuse uses natural neighbors for sub-cluster partitioning, boundary connectivity via adjacent samples and shortest distances, density similarity via mean and variance, and merging rules based on connectivity and similarity.", "result": "kFuse improves accuracy in merging and requires only the number of clusters at the final stage, validated by synthetic and real-world datasets.", "conclusion": "kFuse effectively addresses limitations of traditional agglomerative clustering, enhancing stability and accuracy."}}
{"id": "2505.05877", "pdf": "https://arxiv.org/pdf/2505.05877", "abs": "https://arxiv.org/abs/2505.05877", "authors": ["Rong Yin", "Ruyue Liu", "Xiaoshuai Hao", "Xingrui Zhou", "Yong Liu", "Can Ma", "Weiping Wang"], "title": "Multi-Modal Molecular Representation Learning via Structure Awareness", "categories": ["cs.LG", "cs.AI"], "comment": "Accepted by IEEE Transactions on Image Processing (TIP) 2025", "summary": "Accurate extraction of molecular representations is a critical step in the\ndrug discovery process. In recent years, significant progress has been made in\nmolecular representation learning methods, among which multi-modal molecular\nrepresentation methods based on images, and 2D/3D topologies have become\nincreasingly mainstream. However, existing these multi-modal approaches often\ndirectly fuse information from different modalities, overlooking the potential\nof intermodal interactions and failing to adequately capture the complex\nhigher-order relationships and invariant features between molecules. To\novercome these challenges, we propose a structure-awareness-based multi-modal\nself-supervised molecular representation pre-training framework (MMSA) designed\nto enhance molecular graph representations by leveraging invariant knowledge\nbetween molecules. The framework consists of two main modules: the multi-modal\nmolecular representation learning module and the structure-awareness module.\nThe multi-modal molecular representation learning module collaboratively\nprocesses information from different modalities of the same molecule to\novercome intermodal differences and generate a unified molecular embedding.\nSubsequently, the structure-awareness module enhances the molecular\nrepresentation by constructing a hypergraph structure to model higher-order\ncorrelations between molecules. This module also introduces a memory mechanism\nfor storing typical molecular representations, aligning them with memory\nanchors in the memory bank to integrate invariant knowledge, thereby improving\nthe model generalization ability. Extensive experiments have demonstrated the\neffectiveness of MMSA, which achieves state-of-the-art performance on the\nMoleculeNet benchmark, with average ROC-AUC improvements ranging from 1.8% to\n9.6% over baseline methods.", "AI": {"tldr": "Proposes MMSA, a multi-modal self-supervised framework for molecular representation learning, enhancing intermodal interactions and higher-order relationships, achieving state-of-the-art results.", "motivation": "Existing multi-modal methods overlook intermodal interactions and fail to capture complex higher-order relationships between molecules.", "method": "MMSA combines multi-modal representation learning and a structure-awareness module, using hypergraphs and memory mechanisms to enhance molecular embeddings.", "result": "Achieves 1.8% to 9.6% ROC-AUC improvement on MoleculeNet benchmark over baselines.", "conclusion": "MMSA effectively captures invariant knowledge and higher-order relationships, advancing molecular representation learning."}}
{"id": "2410.18234", "pdf": "https://arxiv.org/pdf/2410.18234", "abs": "https://arxiv.org/abs/2410.18234", "authors": ["Ashish Khisti", "M. Reza Ebrahimi", "Hassan Dbouk", "Arash Behboodi", "Roland Memisevic", "Christos Louizos"], "title": "Multi-Draft Speculative Sampling: Canonical Decomposition and Theoretical Limits", "categories": ["cs.CL", "cs.DC", "cs.IT", "cs.LG", "math.IT"], "comment": "Published as a (spotlight) conference paper at ICLR 2025", "summary": "We consider multi-draft speculative sampling, where the proposal sequences\nare sampled independently from different draft models. At each step, a\ntoken-level draft selection scheme takes a list of valid tokens as input and\nproduces an output token whose distribution matches that of the target model.\nPrevious works have demonstrated that the optimal scheme (which maximizes the\nprobability of accepting one of the input tokens) can be cast as a solution to\na linear program. In this work we show that the optimal scheme can be\ndecomposed into a two-step solution: in the first step an importance sampling\n(IS) type scheme is used to select one intermediate token; in the second step\n(single-draft) speculative sampling is applied to generate the output token.\nFor the case of two identical draft models we further 1) establish a necessary\nand sufficient condition on the distributions of the target and draft models\nfor the acceptance probability to equal one and 2) provide an explicit\nexpression for the optimal acceptance probability. Our theoretical analysis\nalso motives a new class of token-level selection schemes based on weighted\nimportance sampling. Our experimental results demonstrate consistent\nimprovements in the achievable block efficiency and token rates over baseline\nschemes in a number of scenarios.", "AI": {"tldr": "The paper introduces a two-step optimal token-level draft selection scheme for multi-draft speculative sampling, improving efficiency and token rates.", "motivation": "To enhance the performance of speculative sampling by optimizing token-level draft selection, addressing limitations of prior methods.", "method": "Decomposes the optimal scheme into a two-step solution: importance sampling for intermediate token selection, followed by single-draft speculative sampling. Theoretical analysis includes conditions for perfect acceptance and optimal probabilities.", "result": "Demonstrates consistent improvements in block efficiency and token rates over baseline schemes in various scenarios.", "conclusion": "The proposed two-step scheme and weighted importance sampling-based methods offer superior performance, validated by theoretical and experimental results."}}
{"id": "2505.05849", "pdf": "https://arxiv.org/pdf/2505.05849", "abs": "https://arxiv.org/abs/2505.05849", "authors": ["Zhun Wang", "Vincent Siu", "Zhe Ye", "Tianneng Shi", "Yuzhou Nie", "Xuandong Zhao", "Chenguang Wang", "Wenbo Guo", "Dawn Song"], "title": "AgentXploit: End-to-End Redteaming of Black-Box AI Agents", "categories": ["cs.CR", "cs.AI"], "comment": null, "summary": "The strong planning and reasoning capabilities of Large Language Models\n(LLMs) have fostered the development of agent-based systems capable of\nleveraging external tools and interacting with increasingly complex\nenvironments. However, these powerful features also introduce a critical\nsecurity risk: indirect prompt injection, a sophisticated attack vector that\ncompromises the core of these agents, the LLM, by manipulating contextual\ninformation rather than direct user prompts. In this work, we propose a generic\nblack-box fuzzing framework, AgentXploit, designed to automatically discover\nand exploit indirect prompt injection vulnerabilities across diverse LLM\nagents. Our approach starts by constructing a high-quality initial seed corpus,\nthen employs a seed selection algorithm based on Monte Carlo Tree Search (MCTS)\nto iteratively refine inputs, thereby maximizing the likelihood of uncovering\nagent weaknesses. We evaluate AgentXploit on two public benchmarks, AgentDojo\nand VWA-adv, where it achieves 71% and 70% success rates against agents based\non o3-mini and GPT-4o, respectively, nearly doubling the performance of\nbaseline attacks. Moreover, AgentXploit exhibits strong transferability across\nunseen tasks and internal LLMs, as well as promising results against defenses.\nBeyond benchmark evaluations, we apply our attacks in real-world environments,\nsuccessfully misleading agents to navigate to arbitrary URLs, including\nmalicious sites.", "AI": {"tldr": "AgentXploit is a black-box fuzzing framework designed to uncover indirect prompt injection vulnerabilities in LLM agents, achieving high success rates on benchmarks and real-world scenarios.", "motivation": "The increasing use of LLM agents introduces security risks like indirect prompt injection, which manipulates contextual information to compromise agents.", "method": "AgentXploit uses a seed corpus and Monte Carlo Tree Search (MCTS) to iteratively refine inputs, maximizing vulnerability discovery.", "result": "Achieves 71% and 70% success rates on benchmarks (AgentDojo and VWA-adv) and demonstrates strong transferability and real-world effectiveness.", "conclusion": "AgentXploit effectively exposes vulnerabilities in LLM agents, highlighting the need for robust defenses against indirect prompt injection."}}
{"id": "2505.05759", "pdf": "https://arxiv.org/pdf/2505.05759", "abs": "https://arxiv.org/abs/2505.05759", "authors": ["Fangxue Liu", "Lei Fan"], "title": "A review of advancements in low-light image enhancement using deep learning", "categories": ["cs.CV"], "comment": null, "summary": "In low-light environments, the performance of computer vision algorithms\noften deteriorates significantly, adversely affecting key vision tasks such as\nsegmentation, detection, and classification. With the rapid advancement of deep\nlearning, its application to low-light image processing has attracted\nwidespread attention and seen significant progress in recent years. However,\nthere remains a lack of comprehensive surveys that systematically examine how\nrecent deep-learning-based low-light image enhancement methods function and\nevaluate their effectiveness in enhancing downstream vison tasks. To address\nthis gap, this review provides a detailed elaboration on how various recent\napproaches (from 2020) operate and their enhancement mechanisms, supplemented\nwith clear illustrations. It also investigates the impact of different\nenhancement techniques on subsequent vision tasks, critically analyzing their\nstrengths and limitations. Additionally, it proposes future research\ndirections. This review serves as a useful reference for determining low-light\nimage enhancement techniques and optimizing vision task performance in\nlow-light conditions.", "AI": {"tldr": "This review surveys deep-learning-based low-light image enhancement methods since 2020, explaining their mechanisms and evaluating their impact on downstream vision tasks, while suggesting future research directions.", "motivation": "The performance of computer vision algorithms degrades in low-light conditions, and while deep learning has advanced low-light image processing, a systematic review of recent methods and their effectiveness is lacking.", "method": "The review examines various deep-learning-based low-light image enhancement approaches, detailing their mechanisms and illustrating their functioning. It also evaluates their impact on downstream tasks like segmentation, detection, and classification.", "result": "The review critically analyzes the strengths and limitations of different enhancement techniques and their effects on vision tasks.", "conclusion": "The paper serves as a reference for selecting and optimizing low-light image enhancement methods to improve vision task performance, and it outlines future research directions."}}
{"id": "2505.05916", "pdf": "https://arxiv.org/pdf/2505.05916", "abs": "https://arxiv.org/abs/2505.05916", "authors": ["Yifan Zhou", "Yibo Wang", "Chao Shang"], "title": "IRNN: Innovation-driven Recurrent Neural Network for Time-Series Data Modeling and Prediction", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Many real-world datasets are time series that are sequentially collected and\ncontain rich temporal information. Thus, a common interest in practice is to\ncapture dynamics of time series and predict their future evolutions. To this\nend, the recurrent neural network (RNN) has been a prevalent and effective\nmachine learning option, which admits a nonlinear state-space model\nrepresentation. Motivated by the resemblance between RNN and Kalman filter (KF)\nfor linear state-space models, we propose in this paper Innovation-driven RNN\n(IRNN), a novel RNN architecture tailored to time-series data modeling and\nprediction tasks. By adapting the concept of \"innovation\" from KF to RNN, past\nprediction errors are adopted as additional input signals to update hidden\nstates of RNN and boost prediction performance. Since innovation data depend on\nnetwork parameters, existing training algorithms for RNN do not apply to IRNN\nstraightforwardly. Thus, a tailored training algorithm dubbed input\nupdating-based back-propagation through time (IU-BPTT) is further proposed,\nwhich alternates between updating innovations and optimizing network parameters\nvia gradient descent. Experiments on real-world benchmark datasets show that\nthe integration of innovations into various forms of RNN leads to remarkably\nimproved prediction accuracy of IRNN without increasing the training cost\nsubstantially.", "AI": {"tldr": "The paper introduces Innovation-driven RNN (IRNN), a novel RNN architecture that incorporates past prediction errors (innovations) to improve time-series prediction accuracy, along with a tailored training algorithm (IU-BPTT).", "motivation": "To enhance RNN performance for time-series prediction by leveraging the concept of 'innovation' from Kalman filters, which uses past prediction errors to update hidden states.", "method": "Proposes IRNN, which integrates innovations (past errors) as additional inputs, and develops IU-BPTT, a training algorithm that alternates between updating innovations and optimizing parameters.", "result": "Experiments show IRNN significantly improves prediction accuracy on benchmark datasets without substantially increasing training costs.", "conclusion": "IRNN, with its innovation-driven approach and IU-BPTT training, offers a promising solution for time-series modeling and prediction tasks."}}
{"id": "2411.11053", "pdf": "https://arxiv.org/pdf/2411.11053", "abs": "https://arxiv.org/abs/2411.11053", "authors": ["Bin Xu", "Yiguan Lin", "Yinghao Li", "Yang Gao"], "title": "SRA-MCTS: Self-driven Reasoning Augmentation with Monte Carlo Tree Search for Code Generation", "categories": ["cs.CL", "cs.AI"], "comment": "Accepted by IJCAI2025", "summary": "Large language models demonstrate exceptional performance in simple code\ngeneration tasks but still face challenges in tackling complex problems. These\nchallenges may stem from insufficient reasoning and problem decomposition\ncapabilities. To address this issue, we propose a reasoning-augmented data\ngeneration process, SRA-MCTS, which guides the model to autonomously generate\nhigh-quality intermediate reasoning paths. This creates a positive feedback\nloop, enabling continuous improvement. Our method operates entirely through the\nmodel itself without requiring additional supervision. By synthesizing natural\nlanguage reasoning paths and translating them into executable code, the\napproach ensures analytical accuracy and enhances the success rate in solving\ncomplex tasks. Experimental results show that, even without additional\nsupervisory signals, our method achieves performance improvements across\ndifferent model scales, demonstrating the significant potential of\nself-improvement in small models. Furthermore, the method remains robust when\ntraditional Chain-of-Thought (CoT) approaches exhibit performance degradation,\nwith notable improvements observed in diversity metrics such as pass@10. We\nencourage further exploration of reasoning processes within training data to\nenhance the ability of language models to address complex problems. Our code\nand data are public at https://github.com/DIRECT-BIT/SRA-MCTS.", "AI": {"tldr": "The paper introduces SRA-MCTS, a reasoning-augmented data generation method to improve large language models' performance in complex code generation by autonomously generating high-quality reasoning paths.", "motivation": "Large language models struggle with complex problems due to insufficient reasoning and problem decomposition capabilities.", "method": "Proposes SRA-MCTS, a self-improving method that generates natural language reasoning paths and translates them into executable code without additional supervision.", "result": "Achieves performance improvements across model scales, robustness against CoT degradation, and better diversity metrics like pass@10.", "conclusion": "Encourages exploring reasoning processes in training data to enhance language models' ability to solve complex problems."}}
{"id": "2505.05893", "pdf": "https://arxiv.org/pdf/2505.05893", "abs": "https://arxiv.org/abs/2505.05893", "authors": ["Seunghee Han", "Soongyu Choi", "Joo-Young Kim"], "title": "LightNobel: Improving Sequence Length Limitation in Protein Structure Prediction Model via Adaptive Activation Quantization", "categories": ["cs.AR", "cs.AI", "cs.ET", "cs.LG", "B.7; I.2; J.3"], "comment": "To appear in the Proceedings of the 52nd IEEE/ACM International\n  Symposium on Computer Architecture (ISCA 2025)", "summary": "Recent advances in Protein Structure Prediction Models (PPMs), such as\nAlphaFold2 and ESMFold, have revolutionized computational biology by achieving\nunprecedented accuracy in predicting three-dimensional protein folding\nstructures. However, these models face significant scalability challenges,\nparticularly when processing proteins with long amino acid sequences (e.g.,\nsequence length > 1,000). The primary bottleneck that arises from the\nexponential growth in activation sizes is driven by the unique data structure\nin PPM, which introduces an additional dimension that leads to substantial\nmemory and computational demands. These limitations have hindered the effective\nscaling of PPM for real-world applications, such as analyzing large proteins or\ncomplex multimers with critical biological and pharmaceutical relevance.\n  In this paper, we present LightNobel, the first hardware-software co-designed\naccelerator developed to overcome scalability limitations on the sequence\nlength in PPM. At the software level, we propose Token-wise Adaptive Activation\nQuantization (AAQ), which leverages unique token-wise characteristics, such as\ndistogram patterns in PPM activations, to enable fine-grained quantization\ntechniques without compromising accuracy. At the hardware level, LightNobel\nintegrates the multi-precision reconfigurable matrix processing unit (RMPU) and\nversatile vector processing unit (VVPU) to enable the efficient execution of\nAAQ. Through these innovations, LightNobel achieves up to 8.44x, 8.41x speedup\nand 37.29x, 43.35x higher power efficiency over the latest NVIDIA A100 and H100\nGPUs, respectively, while maintaining negligible accuracy loss. It also reduces\nthe peak memory requirement up to 120.05x in PPM, enabling scalable processing\nfor proteins with long sequences.", "AI": {"tldr": "LightNobel is a hardware-software co-designed accelerator addressing scalability issues in Protein Structure Prediction Models (PPMs) like AlphaFold2 and ESMFold, achieving significant speedup and efficiency gains.", "motivation": "PPMs face scalability challenges with long protein sequences due to memory and computational demands, limiting real-world applications.", "method": "LightNobel introduces Token-wise Adaptive Activation Quantization (AAQ) and integrates multi-precision reconfigurable matrix and vector processing units (RMPU and VVPU).", "result": "LightNobel achieves up to 8.44x speedup, 43.35x power efficiency over GPUs, and reduces memory requirements by 120.05x.", "conclusion": "LightNobel enables scalable PPM processing for long protein sequences without compromising accuracy."}}
{"id": "2505.05804", "pdf": "https://arxiv.org/pdf/2505.05804", "abs": "https://arxiv.org/abs/2505.05804", "authors": ["Xi Xiao", "Yunbei Zhang", "Thanh-Huy Nguyen", "Ba-Thinh Lam", "Janet Wang", "Jihun Hamm", "Tianyang Wang", "Xingjian Li", "Xiao Wang", "Hao Xu", "Tianming Liu", "Min Xu"], "title": "Describe Anything in Medical Images", "categories": ["cs.CV"], "comment": null, "summary": "Localized image captioning has made significant progress with models like the\nDescribe Anything Model (DAM), which can generate detailed region-specific\ndescriptions without explicit region-text supervision. However, such\ncapabilities have yet to be widely applied to specialized domains like medical\nimaging, where diagnostic interpretation relies on subtle regional findings\nrather than global understanding. To mitigate this gap, we propose MedDAM, the\nfirst comprehensive framework leveraging large vision-language models for\nregion-specific captioning in medical images. MedDAM employs medical\nexpert-designed prompts tailored to specific imaging modalities and establishes\na robust evaluation benchmark comprising a customized assessment protocol, data\npre-processing pipeline, and specialized QA template library. This benchmark\nevaluates both MedDAM and other adaptable large vision-language models,\nfocusing on clinical factuality through attribute-level verification tasks,\nthereby circumventing the absence of ground-truth region-caption pairs in\nmedical datasets. Extensive experiments on the VinDr-CXR, LIDC-IDRI, and\nSkinCon datasets demonstrate MedDAM's superiority over leading peers (including\nGPT-4o, Claude 3.7 Sonnet, LLaMA-3.2 Vision, Qwen2.5-VL, GPT-4Rol, and\nOMG-LLaVA) in the task, revealing the importance of region-level semantic\nalignment in medical image understanding and establishing MedDAM as a promising\nfoundation for clinical vision-language integration.", "AI": {"tldr": "MedDAM is a new framework for region-specific captioning in medical images, outperforming existing models by focusing on clinical factuality and region-level alignment.", "motivation": "Existing localized captioning models like DAM lack application in specialized domains like medical imaging, where regional findings are critical for diagnosis.", "method": "MedDAM uses expert-designed prompts, a custom evaluation benchmark, and attribute-level verification to assess models without ground-truth region-caption pairs.", "result": "MedDAM outperforms leading models (e.g., GPT-4o, Claude 3.7) on medical datasets, highlighting its clinical relevance.", "conclusion": "MedDAM advances medical image understanding and serves as a foundation for clinical vision-language integration."}}
{"id": "2505.05926", "pdf": "https://arxiv.org/pdf/2505.05926", "abs": "https://arxiv.org/abs/2505.05926", "authors": ["Milad Khademi Nori", "Il-Min Kim", "Guanghui Wang"], "title": "Autoencoder-Based Hybrid Replay for Class-Incremental Learning", "categories": ["cs.LG"], "comment": "Accepted ICML 2025", "summary": "In class-incremental learning (CIL), effective incremental learning\nstrategies are essential to mitigate task confusion and catastrophic\nforgetting, especially as the number of tasks $t$ increases. Current exemplar\nreplay strategies impose $\\mathcal{O}(t)$ memory/compute complexities. We\npropose an autoencoder-based hybrid replay (AHR) strategy that leverages our\nnew hybrid autoencoder (HAE) to function as a compressor to alleviate the\nrequirement for large memory, achieving $\\mathcal{O}(0.1 t)$ at the worst case\nwith the computing complexity of $\\mathcal{O}(t)$ while accomplishing\nstate-of-the-art performance. The decoder later recovers the exemplar data\nstored in the latent space, rather than in raw format. Additionally, HAE is\ndesigned for both discriminative and generative modeling, enabling\nclassification and replay capabilities, respectively. HAE adopts the charged\nparticle system energy minimization equations and repulsive force algorithm for\nthe incremental embedding and distribution of new class centroids in its latent\nspace. Our results demonstrate that AHR consistently outperforms recent\nbaselines across multiple benchmarks while operating with the same\nmemory/compute budgets. The source code is included in the supplementary\nmaterial and will be open-sourced upon publication.", "AI": {"tldr": "Proposes an autoencoder-based hybrid replay (AHR) strategy for class-incremental learning, reducing memory complexity to O(0.1t) while maintaining performance.", "motivation": "Addresses the challenges of task confusion and catastrophic forgetting in class-incremental learning, aiming to reduce memory and compute complexities.", "method": "Uses a hybrid autoencoder (HAE) for compression and replay, incorporating energy minimization equations and repulsive force algorithms for embedding new class centroids.", "result": "AHR outperforms baselines in benchmarks while operating under the same memory/compute constraints.", "conclusion": "AHR is an effective solution for class-incremental learning, balancing performance and resource efficiency."}}
{"id": "2501.12106", "pdf": "https://arxiv.org/pdf/2501.12106", "abs": "https://arxiv.org/abs/2501.12106", "authors": ["Stefan Lenz", "Arsenij Ustjanzew", "Marco Jeray", "Meike Ressing", "Torsten Panholzer"], "title": "Can open source large language models be used for tumor documentation in Germany? -- An evaluation on urological doctors' notes", "categories": ["cs.CL", "cs.AI"], "comment": "53 pages, 5 figures", "summary": "Tumor documentation in Germany is largely done manually, requiring reading\npatient records and entering data into structured databases. Large language\nmodels (LLMs) could potentially enhance this process by improving efficiency\nand reliability. This evaluation tests eleven different open source LLMs with\nsizes ranging from 1-70 billion model parameters on three basic tasks of the\ntumor documentation process: identifying tumor diagnoses, assigning ICD-10\ncodes, and extracting the date of first diagnosis. For evaluating the LLMs on\nthese tasks, a dataset of annotated text snippets based on anonymized doctors'\nnotes from urology was prepared. Different prompting strategies were used to\ninvestigate the effect of the number of examples in few-shot prompting and to\nexplore the capabilities of the LLMs in general. The models Llama 3.1 8B,\nMistral 7B, and Mistral NeMo 12 B performed comparably well in the tasks.\nModels with less extensive training data or having fewer than 7 billion\nparameters showed notably lower performance, while larger models did not\ndisplay performance gains. Examples from a different medical domain than\nurology could also improve the outcome in few-shot prompting, which\ndemonstrates the ability of LLMs to handle tasks needed for tumor\ndocumentation. Open source LLMs show a strong potential for automating tumor\ndocumentation. Models from 7-12 billion parameters could offer an optimal\nbalance between performance and resource efficiency. With tailored fine-tuning\nand well-designed prompting, these models might become important tools for\nclinical documentation in the future. The code for the evaluation is available\nfrom https://github.com/stefan-m-lenz/UroLlmEval. We also release the dataset\nas a new valuable resource that addresses the shortage of authentic and easily\naccessible benchmarks in German-language medical NLP.", "AI": {"tldr": "Open-source LLMs (7-12B parameters) show promise for automating tumor documentation in Germany, with models like Llama 3.1 8B and Mistral 7B performing well. Few-shot prompting and cross-domain examples enhance performance.", "motivation": "Manual tumor documentation is inefficient; LLMs could improve reliability and efficiency.", "method": "Evaluated 11 open-source LLMs (1-70B parameters) on tumor diagnosis, ICD-10 coding, and diagnosis date extraction using annotated urology notes. Tested few-shot prompting and cross-domain examples.", "result": "7-12B parameter models (e.g., Llama 3.1 8B, Mistral 7B) performed best. Smaller models lagged; larger models showed no gains. Cross-domain examples improved few-shot results.", "conclusion": "Open-source LLMs (7-12B parameters) are viable for tumor documentation with fine-tuning and prompting. The dataset and code are released for further research."}}
{"id": "2505.05895", "pdf": "https://arxiv.org/pdf/2505.05895", "abs": "https://arxiv.org/abs/2505.05895", "authors": ["Benjamin Raphael Ernhofer", "Daniil Prokhorov", "Jannica Langner", "Dominik Bollmann"], "title": "Leveraging Vision-Language Models for Visual Grounding and Analysis of Automotive UI", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Modern automotive infotainment systems require intelligent and adaptive\nsolutions to handle frequent User Interface (UI) updates and diverse design\nvariations. We introduce a vision-language framework for understanding and\ninteracting with automotive infotainment systems, enabling seamless adaptation\nacross different UI designs. To further support research in this field, we\nrelease AutomotiveUI-Bench-4K, an open-source dataset of 998 images with 4,208\nannotations. Additionally, we present a synthetic data pipeline to generate\ntraining data. We fine-tune a Molmo-7B-based model using Low-Rank Adaptation\n(LoRa) and incorporating reasoning generated by our pipeline, along with visual\ngrounding and evaluation capabilities. The fine-tuned Evaluative Large Action\nModel (ELAM) achieves strong performance on AutomotiveUI-Bench-4K (model and\ndataset are available on Hugging Face) and demonstrating strong cross-domain\ngeneralization, including a +5.2% improvement on ScreenSpot over the baseline\nmodel. Notably, our approach achieves 80.4% average accuracy on ScreenSpot,\nclosely matching or even surpassing specialized models for desktop, mobile, and\nweb, such as ShowUI, despite being trained for the infotainment domain. This\nresearch investigates how data collection and subsequent fine-tuning can lead\nto AI-driven progress within automotive UI understanding and interaction. The\napplied method is cost-efficient and fine-tuned models can be deployed on\nconsumer-grade GPUs.", "AI": {"tldr": "A vision-language framework for automotive infotainment systems is introduced, leveraging a synthetic data pipeline and fine-tuned Molmo-7B model (ELAM) to achieve strong performance and cross-domain generalization.", "motivation": "Address the need for adaptive solutions in automotive infotainment systems due to frequent UI updates and diverse designs.", "method": "Develop a synthetic data pipeline, fine-tune Molmo-7B using LoRa, and incorporate reasoning, visual grounding, and evaluation capabilities.", "result": "ELAM achieves 80.4% accuracy on ScreenSpot, outperforming baselines and matching specialized models like ShowUI.", "conclusion": "The cost-efficient method demonstrates AI-driven progress in automotive UI understanding, deployable on consumer-grade GPUs."}}
{"id": "2505.05806", "pdf": "https://arxiv.org/pdf/2505.05806", "abs": "https://arxiv.org/abs/2505.05806", "authors": ["Kaili Qi", "Wenli Yang", "Ye Li", "Zhongyi Huang"], "title": "Image Segmentation via Variational Model Based Tailored UNet: A Deep Variational Framework", "categories": ["cs.CV"], "comment": null, "summary": "Traditional image segmentation methods, such as variational models based on\npartial differential equations (PDEs), offer strong mathematical\ninterpretability and precise boundary modeling, but often suffer from\nsensitivity to parameter settings and high computational costs. In contrast,\ndeep learning models such as UNet, which are relatively lightweight in\nparameters, excel in automatic feature extraction but lack theoretical\ninterpretability and require extensive labeled data. To harness the\ncomplementary strengths of both paradigms, we propose Variational Model Based\nTailored UNet (VM_TUNet), a novel hybrid framework that integrates the\nfourth-order modified Cahn-Hilliard equation with the deep learning backbone of\nUNet, which combines the interpretability and edge-preserving properties of\nvariational methods with the adaptive feature learning of neural networks.\nSpecifically, a data-driven operator is introduced to replace manual parameter\ntuning, and we incorporate the tailored finite point method (TFPM) to enforce\nhigh-precision boundary preservation. Experimental results on benchmark\ndatasets demonstrate that VM_TUNet achieves superior segmentation performance\ncompared to existing approaches, especially for fine boundary delineation.", "AI": {"tldr": "VM_TUNet combines variational models and UNet for better segmentation, balancing interpretability and feature learning.", "motivation": "Traditional methods lack adaptability, while deep learning lacks interpretability. VM_TUNet aims to merge their strengths.", "method": "Integrates a fourth-order modified Cahn-Hilliard equation with UNet, using TFPM for boundary precision and a data-driven operator for parameter tuning.", "result": "Outperforms existing methods, especially in fine boundary delineation.", "conclusion": "VM_TUNet successfully merges variational and deep learning advantages for superior segmentation."}}
{"id": "2505.05950", "pdf": "https://arxiv.org/pdf/2505.05950", "abs": "https://arxiv.org/abs/2505.05950", "authors": ["Yuxin Zhou", "Zheng Li", "Jun Zhang", "Jue Wang", "Yiping Wang", "Zhongle Xie", "Ke Chen", "Lidan Shou"], "title": "FloE: On-the-Fly MoE Inference", "categories": ["cs.LG"], "comment": "Accepted at ICML 2025", "summary": "With the widespread adoption of Mixture-of-Experts (MoE) models, there is a\ngrowing demand for efficient inference on memory-constrained devices. While\noffloading expert parameters to CPU memory and loading activated experts on\ndemand has emerged as a potential solution, the large size of activated experts\noverburdens the limited PCIe bandwidth, hindering the effectiveness in\nlatency-sensitive scenarios. To mitigate this, we propose FloE, an on-the-fly\nMoE inference system on memory-constrained GPUs. FloE is built on the insight\nthat there exists substantial untapped redundancy within sparsely activated\nexperts. It employs various compression techniques on the expert's internal\nparameter matrices to reduce the data movement load, combined with low-cost\nsparse prediction, achieving perceptible inference acceleration in wall-clock\ntime on resource-constrained devices. Empirically, FloE achieves a 9.3x\ncompression of parameters per expert in Mixtral-8x7B; enables deployment on a\nGPU with only 11GB VRAM, reducing the memory footprint by up to 8.5x; and\ndelivers a 48.7x inference speedup compared to DeepSpeed-MII on a single\nGeForce RTX 3090.", "AI": {"tldr": "FloE is a system for efficient Mixture-of-Experts (MoE) inference on memory-constrained GPUs, reducing data movement and memory footprint while accelerating inference.", "motivation": "The need for efficient MoE inference on memory-constrained devices due to PCIe bandwidth limitations and latency sensitivity.", "method": "FloE compresses expert parameters and uses sparse prediction to reduce data movement and memory usage.", "result": "Achieves 9.3x compression, 8.5x memory reduction, and 48.7x speedup on a GeForce RTX 3090.", "conclusion": "FloE effectively addresses the challenges of MoE inference on resource-constrained devices."}}
{"id": "2501.14851", "pdf": "https://arxiv.org/pdf/2501.14851", "abs": "https://arxiv.org/abs/2501.14851", "authors": ["Michael K. Chen", "Xikun Zhang", "Dacheng Tao"], "title": "JustLogic: A Comprehensive Benchmark for Evaluating Deductive Reasoning in Large Language Models", "categories": ["cs.CL", "cs.AI", "cs.LG", "cs.LO"], "comment": null, "summary": "Logical reasoning is a critical component of Large Language Models (LLMs),\nand substantial research efforts in recent years have aimed to enhance their\ndeductive reasoning capabilities. However, existing deductive reasoning\nbenchmarks, which are crucial for evaluating and advancing LLMs, are inadequate\ndue to their lack of task complexity, presence of prior knowledge as a\nconfounder, and superficial error analysis. To address these deficiencies, we\nintroduce JustLogic, a synthetically generated deductive reasoning benchmark\ndesigned for rigorous evaluation of LLMs. JustLogic is (i) highly complex,\ncapable of generating a diverse range of linguistic patterns, vocabulary, and\nargument structures; (ii) prior knowledge independent, eliminating the\nadvantage of models possessing prior knowledge and ensuring that only deductive\nreasoning is used to answer questions; and (iii) capable of in-depth error\nanalysis on the heterogeneous effects of reasoning depth and argument form on\nmodel accuracy. Our experimental results on JustLogic reveal that (i)\nstate-of-the-art (SOTA) reasoning LLMs perform on par or better than the human\naverage but significantly worse than the human ceiling, and (ii) SOTA\nnon-reasoning models still underperform the human average. All code and data\nare available at https://github.com/michaelchen-lab/JustLogic", "AI": {"tldr": "JustLogic is a synthetic deductive reasoning benchmark addressing flaws in existing benchmarks by being complex, prior-knowledge independent, and enabling in-depth error analysis. SOTA reasoning LLMs match human average but fall short of the ceiling, while non-reasoning models lag behind.", "motivation": "Existing deductive reasoning benchmarks for LLMs are flawed due to low complexity, prior knowledge bias, and superficial error analysis. JustLogic aims to provide a rigorous evaluation tool.", "method": "JustLogic is a synthetically generated benchmark with diverse linguistic patterns, vocabulary, and argument structures, designed to be prior-knowledge independent.", "result": "SOTA reasoning LLMs perform at human average but below human ceiling; non-reasoning models underperform the human average.", "conclusion": "JustLogic effectively evaluates LLMs' deductive reasoning, highlighting gaps between models and human performance."}}
{"id": "2505.05901", "pdf": "https://arxiv.org/pdf/2505.05901", "abs": "https://arxiv.org/abs/2505.05901", "authors": ["Hanzhe Liang", "Aoran Wang", "Jie Zhou", "Xin Jin", "Can Gao", "Jinbao Wang"], "title": "Examining the Source of Defects from a Mechanical Perspective for 3D Anomaly Detection", "categories": ["cs.CV", "cs.AI"], "comment": "26 pages", "summary": "In this paper, we go beyond identifying anomalies only in structural terms\nand think about better anomaly detection motivated by anomaly causes. Most\nanomalies are regarded as the result of unpredictable defective forces from\ninternal and external sources, and their opposite forces are sought to correct\nthe anomalies. We introduced a Mechanics Complementary framework for 3D anomaly\ndetection (MC4AD) to generate internal and external Corrective forces for each\npoint. A Diverse Anomaly-Generation (DA-Gen) module is first proposed to\nsimulate various anomalies. Then, we present a Corrective Force Prediction\nNetwork (CFP-Net) with complementary representations for point-level\nrepresentation to simulate the different contributions of internal and external\ncorrective forces. A combined loss was proposed, including a new symmetric loss\nand an overall loss, to constrain the corrective forces properly. As a\nhighlight, we consider 3D anomaly detection in industry more comprehensively,\ncreating a hierarchical quality control strategy based on a three-way decision\nand contributing a dataset named Anomaly-IntraVariance with intraclass variance\nto evaluate the model. On the proposed and existing five datasets, we obtained\nnine state-of-the-art performers with the minimum parameters and the fastest\ninference speed. The source is available at\nhttps://github.com/hzzzzzhappy/MC4AD", "AI": {"tldr": "The paper introduces MC4AD, a Mechanics Complementary framework for 3D anomaly detection, focusing on anomaly causes and corrective forces. It includes DA-Gen for anomaly simulation, CFP-Net for corrective force prediction, and achieves state-of-the-art results with minimal parameters and fast inference.", "motivation": "Anomalies are often caused by unpredictable defective forces; the paper aims to improve anomaly detection by addressing these causes through corrective forces.", "method": "Proposes MC4AD with DA-Gen for anomaly simulation and CFP-Net for corrective force prediction. Uses a combined loss (symmetric and overall) for training.", "result": "Achieves nine state-of-the-art results on six datasets with minimal parameters and fast inference.", "conclusion": "MC4AD effectively addresses 3D anomaly detection by simulating anomalies and predicting corrective forces, validated by superior performance and a new dataset."}}
{"id": "2505.05834", "pdf": "https://arxiv.org/pdf/2505.05834", "abs": "https://arxiv.org/abs/2505.05834", "authors": ["Chunlai Dong", "Haochao Ying", "Qibo Qiu", "Jinhong Wang", "Danny Chen", "Jian Wu"], "title": "Dual-level Fuzzy Learning with Patch Guidance for Image Ordinal Regression", "categories": ["cs.CV"], "comment": "Accepted by IJCAI 2025", "summary": "Ordinal regression bridges regression and classification by assigning objects\nto ordered classes. While human experts rely on discriminative patch-level\nfeatures for decisions, current approaches are limited by the availability of\nonly image-level ordinal labels, overlooking fine-grained patch-level\ncharacteristics. In this paper, we propose a Dual-level Fuzzy Learning with\nPatch Guidance framework, named DFPG that learns precise feature-based grading\nboundaries from ambiguous ordinal labels, with patch-level supervision.\nSpecifically, we propose patch-labeling and filtering strategies to enable the\nmodel to focus on patch-level features exclusively with only image-level\nordinal labels available. We further design a dual-level fuzzy learning module,\nwhich leverages fuzzy logic to quantitatively capture and handle label\nambiguity from both patch-wise and channel-wise perspectives. Extensive\nexperiments on various image ordinal regression datasets demonstrate the\nsuperiority of our proposed method, further confirming its ability in\ndistinguishing samples from difficult-to-classify categories. The code is\navailable at https://github.com/ZJUMAI/DFPG-ord.", "AI": {"tldr": "The paper introduces DFPG, a framework for ordinal regression that leverages patch-level features and fuzzy logic to handle label ambiguity, outperforming existing methods.", "motivation": "Current ordinal regression methods lack patch-level feature utilization due to reliance on image-level labels, limiting their discriminative power.", "method": "Proposes DFPG with patch-labeling, filtering strategies, and a dual-level fuzzy learning module to capture label ambiguity from patch-wise and channel-wise perspectives.", "result": "DFPG outperforms existing methods on various datasets, especially in distinguishing difficult-to-classify categories.", "conclusion": "DFPG effectively bridges the gap between patch-level features and image-level labels, enhancing ordinal regression performance."}}
{"id": "2505.05967", "pdf": "https://arxiv.org/pdf/2505.05967", "abs": "https://arxiv.org/abs/2505.05967", "authors": ["Uyoata E. Uyoata", "Gilberto Berardinelli", "Ramoni Adeogun"], "title": "Learning Power Control Protocol for In-Factory 6G Subnetworks", "categories": ["cs.LG", "cs.NI", "eess.SP"], "comment": "Accepted for presented at IEEE EuCNC & 6G Summit 2025", "summary": "In-X Subnetworks are envisioned to meet the stringent demands of short-range\ncommunication in diverse 6G use cases. In the context of In-Factory scenarios,\neffective power control is critical to mitigating the impact of interference\nresulting from potentially high subnetwork density. Existing approaches to\npower control in this domain have predominantly emphasized the data plane,\noften overlooking the impact of signaling overhead. Furthermore, prior work has\ntypically adopted a network-centric perspective, relying on the assumption of\ncomplete and up-to-date channel state information (CSI) being readily available\nat the central controller. This paper introduces a novel multi-agent\nreinforcement learning (MARL) framework designed to enable access points to\nautonomously learn both signaling and power control protocols in an In-Factory\nSubnetwork environment. By formulating the problem as a partially observable\nMarkov decision process (POMDP) and leveraging multi-agent proximal policy\noptimization (MAPPO), the proposed approach achieves significant advantages.\nThe simulation results demonstrate that the learning-based method reduces\nsignaling overhead by a factor of 8 while maintaining a buffer flush rate that\nlags the ideal \"Genie\" approach by only 5%.", "AI": {"tldr": "A novel MARL framework for In-Factory Subnetworks reduces signaling overhead by 8x while maintaining near-optimal performance.", "motivation": "Existing power control methods overlook signaling overhead and assume perfect CSI, limiting practicality in dense In-Factory scenarios.", "method": "Uses MARL (MAPPO) to autonomously learn signaling and power control protocols, modeled as a POMDP.", "result": "8x reduction in signaling overhead with only 5% performance gap from ideal.", "conclusion": "The MARL approach effectively balances signaling and power control in dense In-Factory Subnetworks."}}
{"id": "2501.16154", "pdf": "https://arxiv.org/pdf/2501.16154", "abs": "https://arxiv.org/abs/2501.16154", "authors": ["Xin Huang", "Tarun Kumar Vangani", "Zhengyuan Liu", "Bowei Zou", "Ai Ti Aw"], "title": "AdaCoT: Rethinking Cross-Lingual Factual Reasoning through Adaptive Chain-of-Thought", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Large language models have shown impressive multilingual capabilities through\npretraining on diverse corpora. While these models show strong reasoning\nabilities, their performance varies significantly across languages due to\nimbalanced training data distribution. Existing approaches using sample-level\ntranslation for extensive multilingual pretraining and cross-lingual tuning\nface scalability challenges and often fail to capture nuanced reasoning\nprocesses across languages. In this paper, we introduce AdaCoT (Adaptive\nChain-of-Thought), a framework that enhances multilingual factual reasoning by\ndynamically routing thought processes in intermediary ``thinking languages''\nbefore generating target-language responses. AdaCoT leverages a\nlanguage-agnostic core and incorporates an adaptive, reward-based mechanism for\nselecting optimal reasoning pathways without requiring additional pretraining.\nOur comprehensive evaluation across multiple benchmarks demonstrates\nsubstantial improvements in both factual reasoning quality and cross-lingual\nconsistency, with particularly strong performance gains in low-resource\nlanguage settings. The results suggest that adaptive reasoning paths can\neffectively bridge the performance gap between high and low-resource languages\nwhile maintaining cultural and linguistic nuances.", "AI": {"tldr": "AdaCoT improves multilingual reasoning by dynamically routing thought processes in intermediary languages, enhancing performance, especially in low-resource languages.", "motivation": "Address performance variability in multilingual models due to imbalanced training data and scalability issues in existing methods.", "method": "Introduces AdaCoT, a framework with a language-agnostic core and adaptive reward-based mechanism for optimal reasoning pathways.", "result": "Substantial improvements in factual reasoning quality and cross-lingual consistency, particularly in low-resource languages.", "conclusion": "Adaptive reasoning paths bridge performance gaps between languages while preserving cultural and linguistic nuances."}}
{"id": "2505.05943", "pdf": "https://arxiv.org/pdf/2505.05943", "abs": "https://arxiv.org/abs/2505.05943", "authors": ["Maan Alhazmi", "Abdulrahman Altahhan"], "title": "Achieving 3D Attention via Triplet Squeeze and Excitation Block", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": null, "summary": "The emergence of ConvNeXt and its variants has reaffirmed the conceptual and\nstructural suitability of CNN-based models for vision tasks, re-establishing\nthem as key players in image classification in general, and in facial\nexpression recognition (FER) in particular. In this paper, we propose a new set\nof models that build on these advancements by incorporating a new set of\nattention mechanisms that combines Triplet attention with\nSqueeze-and-Excitation (TripSE) in four different variants. We demonstrate the\neffectiveness of these variants by applying them to the ResNet18, DenseNet and\nConvNext architectures to validate their versatility and impact. Our study\nshows that incorporating a TripSE block in these CNN models boosts their\nperformances, particularly for the ConvNeXt architecture, indicating its\nutility. We evaluate the proposed mechanisms and associated models across four\ndatasets, namely CIFAR100, ImageNet, FER2013 and AffectNet datasets, where\nConvNext with TripSE achieves state-of-the-art results with an accuracy of\n\\textbf{78.27\\%} on the popular FER2013 dataset, a new feat for this dataset.", "AI": {"tldr": "The paper introduces TripSE, a new attention mechanism combining Triplet attention and Squeeze-and-Excitation, applied to CNN models like ResNet18, DenseNet, and ConvNeXt, achieving state-of-the-art results in FER.", "motivation": "To enhance CNN-based models for vision tasks, particularly facial expression recognition (FER), by integrating advanced attention mechanisms.", "method": "Proposes four TripSE variants and integrates them into ResNet18, DenseNet, and ConvNeXt architectures, evaluating performance on CIFAR100, ImageNet, FER2013, and AffectNet datasets.", "result": "ConvNeXt with TripSE achieves 78.27% accuracy on FER2013, setting a new benchmark.", "conclusion": "TripSE significantly boosts CNN model performance, especially ConvNeXt, demonstrating its effectiveness in FER."}}
{"id": "2505.05845", "pdf": "https://arxiv.org/pdf/2505.05845", "abs": "https://arxiv.org/abs/2505.05845", "authors": ["Guohao Lin", "Shidong Pan", "Rasul Khanbayov", "Changxi Yang", "Ani Khaloian-Sarnaghi", "Andriy Kovryga"], "title": "Automated Knot Detection and Pairing for Wood Analysis in the Timber Industry", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "Knots in wood are critical to both aesthetics and structural integrity,\nmaking their detection and pairing essential in timber processing. However,\ntraditional manual annotation was labor-intensive and inefficient,\nnecessitating automation. This paper proposes a lightweight and fully automated\npipeline for knot detection and pairing based on machine learning techniques.\nIn the detection stage, high-resolution surface images of wooden boards were\ncollected using industrial-grade cameras, and a large-scale dataset was\nmanually annotated and preprocessed. After the transfer learning, the YOLOv8l\nachieves an mAP@0.5 of 0.887. In the pairing stage, detected knots were\nanalyzed and paired based on multidimensional feature extraction. A triplet\nneural network was used to map the features into a latent space, enabling\nclustering algorithms to identify and pair corresponding knots. The triplet\nnetwork with learnable weights achieved a pairing accuracy of 0.85. Further\nanalysis revealed that he distances from the knot's start and end points to the\nbottom of the wooden board, and the longitudinal coordinates play crucial roles\nin achieving high pairing accuracy. Our experiments validate the effectiveness\nof the proposed solution, demonstrating the potential of AI in advancing wood\nscience and industry.", "AI": {"tldr": "A lightweight, automated pipeline for knot detection and pairing in wood using machine learning, achieving high accuracy in detection (mAP@0.5: 0.887) and pairing (0.85).", "motivation": "Traditional manual knot annotation is labor-intensive and inefficient, prompting the need for automation in timber processing.", "method": "Uses YOLOv8l for knot detection and a triplet neural network for pairing, leveraging multidimensional feature extraction and clustering.", "result": "Achieved mAP@0.5 of 0.887 for detection and 0.85 pairing accuracy. Key features like knot positions and longitudinal coordinates were critical.", "conclusion": "The proposed AI solution is effective, showcasing potential for advancing wood science and industry."}}
{"id": "2505.05983", "pdf": "https://arxiv.org/pdf/2505.05983", "abs": "https://arxiv.org/abs/2505.05983", "authors": ["Vivek Mohan", "Biyan Zhou", "Zhou Wang", "Anil Bharath", "Emmanuel Drakakis", "Arindam Basu"], "title": "Architectural Exploration of Hybrid Neural Decoders for Neuromorphic Implantable BMI", "categories": ["cs.LG"], "comment": "The paper has been accepted for lecture presentation at the 2025 IEEE\n  International Symposium on Circuits and Systems in London", "summary": "This work presents an efficient decoding pipeline for neuromorphic\nimplantable brain-machine interfaces (Neu-iBMI), leveraging sparse neural event\ndata from an event-based neural sensing scheme. We introduce a tunable event\nfilter (EvFilter), which also functions as a spike detector (EvFilter-SPD),\nsignificantly reducing the number of events processed for decoding by 192X and\n554X, respectively. The proposed pipeline achieves high decoding performance,\nup to R^2=0.73, with ANN- and SNN-based decoders, eliminating the need for\nsignal recovery, spike detection, or sorting, commonly performed in\nconventional iBMI systems. The SNN-Decoder reduces computations and memory\nrequired by 5-23X compared to NN-, and LSTM-Decoders, while the ST-NN-Decoder\ndelivers similar performance to an LSTM-Decoder requiring 2.5X fewer resources.\nThis streamlined approach significantly reduces computational and memory\ndemands, making it ideal for low-power, on-implant, or wearable iBMIs.", "AI": {"tldr": "An efficient decoding pipeline for neuromorphic implantable brain-machine interfaces (Neu-iBMI) reduces event processing by up to 554X and achieves high decoding performance without traditional signal recovery steps.", "motivation": "To address the computational and memory inefficiencies in conventional iBMI systems by leveraging sparse neural event data.", "method": "Introduces a tunable event filter (EvFilter) and spike detector (EvFilter-SPD) to reduce event processing. Uses ANN- and SNN-based decoders for efficient decoding.", "result": "Achieves R^2=0.73 decoding performance, reduces computations by 5-23X, and lowers memory demands compared to traditional decoders.", "conclusion": "The pipeline is ideal for low-power, on-implant, or wearable iBMIs due to its efficiency and reduced resource requirements."}}
{"id": "2502.00290", "pdf": "https://arxiv.org/pdf/2502.00290", "abs": "https://arxiv.org/abs/2502.00290", "authors": ["Huan Ma", "Jingdong Chen", "Joey Tianyi Zhou", "Guangyu Wang", "Changqing Zhang"], "title": "Estimating LLM Uncertainty with Evidence", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Over the past few years, Large Language Models (LLMs) have developed rapidly\nand are widely applied in various domains. However, LLMs face the issue of\nhallucinations, generating responses that may be unreliable when the models\nlack relevant knowledge. To be aware of potential hallucinations, uncertainty\nestimation methods have been introduced, and most of them have confirmed that\nreliability lies in critical tokens. However, probability-based methods perform\npoorly in identifying token reliability, limiting their practical utility. In\nthis paper, we reveal that the probability-based method fails to estimate token\nreliability due to the loss of evidence strength information which is\naccumulated in the training stage. Therefore, we present Logits-induced token\nuncertainty (LogTokU), a framework for estimating decoupled token uncertainty\nin LLMs, enabling real-time uncertainty estimation without requiring multiple\nsampling processes. We employ evidence modeling to implement LogTokU and use\nthe estimated uncertainty to guide downstream tasks. The experimental results\ndemonstrate that LogTokU has significant effectiveness and promise.", "AI": {"tldr": "LogTokU is a framework for estimating token uncertainty in LLMs, addressing the limitations of probability-based methods by leveraging evidence strength information.", "motivation": "LLMs often generate unreliable responses (hallucinations) due to lack of knowledge. Existing uncertainty estimation methods, especially probability-based ones, fail to accurately identify token reliability.", "method": "The paper introduces LogTokU, which decouples token uncertainty by modeling evidence strength accumulated during training, enabling real-time estimation without multiple sampling.", "result": "Experiments show LogTokU is effective and promising for improving token reliability estimation in LLMs.", "conclusion": "LogTokU provides a practical solution for real-time uncertainty estimation in LLMs, enhancing their reliability in downstream tasks."}}
{"id": "2505.05965", "pdf": "https://arxiv.org/pdf/2505.05965", "abs": "https://arxiv.org/abs/2505.05965", "authors": ["Abdelfateh Bekkair", "Slimane Bellaouar", "Slimane Oulad-Naoui"], "title": "A Noise-Resilient Semi-Supervised Graph Autoencoder for Overlapping Semantic Community Detection", "categories": ["cs.SI", "cs.AI"], "comment": null, "summary": "Community detection in networks with overlapping structures remains a\nsignificant challenge, particularly in noisy real-world environments where\nintegrating topology, node attributes, and prior information is critical. To\naddress this, we propose a semi-supervised graph autoencoder that combines\ngraph multi-head attention and modularity maximization to robustly detect\noverlapping communities. The model learns semantic representations by fusing\nstructural, attribute, and prior knowledge while explicitly addressing noise in\nnode features. Key innovations include a noise-resistant architecture and a\nsemantic semi-supervised design optimized for community quality through\nmodularity constraints. Experiments demonstrate superior performance the model\noutperforms state-of-the-art methods in overlapping community detection\n(improvements in NMI and F1-score) and exhibits exceptional robustness to\nattribute noise, maintaining stable performance under 60\\% feature corruption.\nThese results highlight the importance of integrating attribute semantics and\nstructural patterns for accurate community discovery in complex networks.", "AI": {"tldr": "A semi-supervised graph autoencoder combines graph multi-head attention and modularity maximization to detect overlapping communities robustly, outperforming state-of-the-art methods.", "motivation": "Addressing the challenge of overlapping community detection in noisy real-world networks by integrating topology, node attributes, and prior information.", "method": "Proposes a noise-resistant semi-supervised graph autoencoder that fuses structural, attribute, and prior knowledge, optimized with modularity constraints.", "result": "Superior performance in overlapping community detection (higher NMI and F1-score) and robustness to attribute noise (stable under 60% feature corruption).", "conclusion": "Integrating attribute semantics and structural patterns is crucial for accurate community discovery in complex networks."}}
{"id": "2505.05848", "pdf": "https://arxiv.org/pdf/2505.05848", "abs": "https://arxiv.org/abs/2505.05848", "authors": ["Yue Yin", "Enze Tao", "Weijian Deng", "Dylan Campbell"], "title": "RefRef: A Synthetic Dataset and Benchmark for Reconstructing Refractive and Reflective Objects", "categories": ["cs.CV"], "comment": null, "summary": "Modern 3D reconstruction and novel view synthesis approaches have\ndemonstrated strong performance on scenes with opaque Lambertian objects.\nHowever, most assume straight light paths and therefore cannot properly handle\nrefractive and reflective materials. Moreover, datasets specialized for these\neffects are limited, stymieing efforts to evaluate performance and develop\nsuitable techniques. In this work, we introduce a synthetic RefRef dataset and\nbenchmark for reconstructing scenes with refractive and reflective objects from\nposed images. Our dataset has 50 such objects of varying complexity, from\nsingle-material convex shapes to multi-material non-convex shapes, each placed\nin three different background types, resulting in 150 scenes. We also propose\nan oracle method that, given the object geometry and refractive indices,\ncalculates accurate light paths for neural rendering, and an approach based on\nthis that avoids these assumptions. We benchmark these against several\nstate-of-the-art methods and show that all methods lag significantly behind the\noracle, highlighting the challenges of the task and dataset.", "AI": {"tldr": "The paper introduces a synthetic dataset (RefRef) for 3D reconstruction of refractive and reflective objects, proposes an oracle method for accurate light path calculation, and benchmarks it against existing methods, showing significant gaps in performance.", "motivation": "Existing 3D reconstruction methods struggle with refractive and reflective materials due to limited datasets and assumptions about light paths.", "method": "The authors create a synthetic dataset (RefRef) with 150 scenes of varying complexity and propose an oracle method for accurate light path calculation, along with a practical approach.", "result": "Benchmarking shows current methods perform poorly compared to the oracle, underscoring the difficulty of handling refractive and reflective materials.", "conclusion": "The RefRef dataset and benchmark highlight challenges in reconstructing scenes with refractive/reflective objects, urging further research in this area."}}
{"id": "2505.06000", "pdf": "https://arxiv.org/pdf/2505.06000", "abs": "https://arxiv.org/abs/2505.06000", "authors": ["Stephan Bartl", "Kevin Innerebner", "Elisabeth Lex"], "title": "Differentiable Fuzzy Neural Networks for Recommender Systems", "categories": ["cs.LG"], "comment": "Accepted for publication at the HyPer workshop, co-located with ACM\n  UMAP 2025", "summary": "As recommender systems become increasingly complex, transparency is essential\nto increase user trust, accountability, and regulatory compliance.\nNeuro-symbolic approaches that integrate symbolic reasoning with sub-symbolic\nlearning offer a promising approach toward transparent and user-centric\nsystems. In this work-in-progress, we investigate using fuzzy neural networks\n(FNNs) as a neuro-symbolic approach for recommendations that learn logic-based\nrules over predefined, human-readable atoms. Each rule corresponds to a fuzzy\nlogic expression, making the recommender's decision process inherently\ntransparent. In contrast to black-box machine learning methods, our approach\nreveals the reasoning behind a recommendation while maintaining competitive\nperformance. We evaluate our method on a synthetic and MovieLens 1M datasets\nand compare it to state-of-the-art recommendation algorithms. Our results\ndemonstrate that our approach accurately captures user behavior while providing\na transparent decision-making process. Finally, the differentiable nature of\nthis approach facilitates an integration with other neural models, enabling the\ndevelopment of hybrid, transparent recommender systems.", "AI": {"tldr": "A neuro-symbolic approach using fuzzy neural networks (FNNs) for transparent recommender systems, combining logic-based rules with competitive performance.", "motivation": "To enhance transparency in recommender systems for user trust, accountability, and regulatory compliance by integrating symbolic reasoning with sub-symbolic learning.", "method": "Uses FNNs to learn logic-based rules over human-readable atoms, forming fuzzy logic expressions for transparent decision-making. Evaluated on synthetic and MovieLens 1M datasets.", "result": "Achieves competitive performance while providing transparent reasoning, accurately capturing user behavior.", "conclusion": "The differentiable nature of FNNs allows integration with other neural models, enabling hybrid, transparent recommender systems."}}
{"id": "2502.01210", "pdf": "https://arxiv.org/pdf/2502.01210", "abs": "https://arxiv.org/abs/2502.01210", "authors": ["Sam Kirkham", "Patrycja Strycharczuk", "Rob Davies", "Danielle Welburn"], "title": "Phonetic accommodation and inhibition in a dynamic neural field model", "categories": ["cs.CL"], "comment": null, "summary": "Short-term phonetic accommodation is a fundamental driver behind accent\nchange, but how does real-time input from another speaker's voice shape the\nspeech planning representations of an interlocutor? We advance a computational\nmodel of change in speech planning representations during phonetic\naccommodation, grounded in dynamic neural field equations for movement planning\nand memory dynamics. A dual-layer planning/memory field predicts that\nconvergence to a model talker on one trial can trigger divergence on subsequent\ntrials, due to a delayed inhibitory effect in the more slowly evolving memory\nfield. The model's predictions are compared with empirical patterns of\naccommodation from an experimental pilot study. We show that observed empirical\nphenomena may correspond to variation in the magnitude of inhibitory memory\ndynamics, which could reflect resistance to accommodation due to phonological\nand/or sociolinguistic pressures. We discuss the implications of these results\nfor the relations between short-term phonetic accommodation and sound change.", "AI": {"tldr": "The paper explores how real-time phonetic input influences speech planning during accommodation, proposing a computational model with dual-layer planning/memory fields. It predicts convergence and divergence patterns, validated by empirical data, and links inhibitory memory dynamics to resistance in accommodation.", "motivation": "To understand how phonetic input from another speaker shapes speech planning representations during accommodation, bridging gaps in dynamic neural field models and empirical observations.", "method": "A computational model using dynamic neural field equations for movement planning and memory dynamics, tested against empirical data from a pilot study.", "result": "The model predicts convergence and divergence patterns in accommodation, with empirical data suggesting inhibitory memory dynamics may reflect resistance due to phonological/sociolinguistic factors.", "conclusion": "The findings highlight the role of inhibitory memory dynamics in phonetic accommodation and its implications for understanding sound change."}}
{"id": "2505.05988", "pdf": "https://arxiv.org/pdf/2505.05988", "abs": "https://arxiv.org/abs/2505.05988", "authors": ["J\u00f8rgen Villadsen"], "title": "Minimal Sequent Calculus for Teaching First-Order Logic: Lessons Learned", "categories": ["cs.LO", "cs.AI", "F.4; I.2.3; K.3.1"], "comment": "In Proceedings ThEdu24, arXiv:2505.04677", "summary": "MiniCalc is a web app for teaching first-order logic based on a minimal\nsequent calculus. As an option the proofs can be verified in the Isabelle proof\nassistant. We present the lessons learned using the tool in recent years at our\nuniversity.", "AI": {"tldr": "MiniCalc is a web app for teaching first-order logic using a minimal sequent calculus, with optional verification in Isabelle. Lessons from its use at a university are shared.", "motivation": "To enhance the teaching of first-order logic by providing an interactive tool with proof verification capabilities.", "method": "Developed a web app (MiniCalc) based on a minimal sequent calculus, integrating optional verification via Isabelle.", "result": "The tool has been successfully used in teaching, with practical insights gained from its deployment.", "conclusion": "MiniCalc is effective for teaching first-order logic, and its integration with Isabelle adds verification value."}}
{"id": "2505.05853", "pdf": "https://arxiv.org/pdf/2505.05853", "abs": "https://arxiv.org/abs/2505.05853", "authors": ["Tongda Xu", "Jiahao Li", "Bin Li", "Yan Wang", "Ya-Qin Zhang", "Yan Lu"], "title": "PICD: Versatile Perceptual Image Compression with Diffusion Rendering", "categories": ["cs.CV"], "comment": "CVPR 2025", "summary": "Recently, perceptual image compression has achieved significant advancements,\ndelivering high visual quality at low bitrates for natural images. However, for\nscreen content, existing methods often produce noticeable artifacts when\ncompressing text. To tackle this challenge, we propose versatile perceptual\nscreen image compression with diffusion rendering (PICD), a codec that works\nwell for both screen and natural images. More specifically, we propose a\ncompression framework that encodes the text and image separately, and renders\nthem into one image using diffusion model. For this diffusion rendering, we\nintegrate conditional information into diffusion models at three distinct\nlevels: 1). Domain level: We fine-tune the base diffusion model using text\ncontent prompts with screen content. 2). Adaptor level: We develop an efficient\nadaptor to control the diffusion model using compressed image and text as\ninput. 3). Instance level: We apply instance-wise guidance to further enhance\nthe decoding process. Empirically, our PICD surpasses existing perceptual\ncodecs in terms of both text accuracy and perceptual quality. Additionally,\nwithout text conditions, our approach serves effectively as a perceptual codec\nfor natural images.", "AI": {"tldr": "PICD is a perceptual image compression method for screen and natural images, using diffusion rendering to address text artifacts.", "motivation": "Existing methods struggle with text artifacts in screen content compression.", "method": "Separate encoding of text and images, rendered using a diffusion model with domain, adaptor, and instance-level conditioning.", "result": "PICD outperforms existing codecs in text accuracy and perceptual quality, also works for natural images.", "conclusion": "PICD is a versatile solution for high-quality compression of both screen and natural images."}}
{"id": "2505.06017", "pdf": "https://arxiv.org/pdf/2505.06017", "abs": "https://arxiv.org/abs/2505.06017", "authors": ["Hiroki Shiraishi", "Yohei Hayamizu", "Tomonori Hashiyama"], "title": "Fuzzy-UCS Revisited: Self-Adaptation of Rule Representations in Michigan-Style Learning Fuzzy-Classifier Systems", "categories": ["cs.LG"], "comment": "Accepted by the ACM Genetic and Evolutionary Computation Conference\n  (GECCO) 2023", "summary": "This paper focuses on the impact of rule representation in Michigan-style\nLearning Fuzzy-Classifier Systems (LFCSs) on its classification performance. A\nwell-representation of the rules in an LFCS is crucial for improving its\nperformance. However, conventional rule representations frequently need help\naddressing problems with unknown data characteristics. To address this issue,\nthis paper proposes a supervised LFCS (i.e., Fuzzy-UCS) with a self-adaptive\nrule representation mechanism, entitled Adaptive-UCS. Adaptive-UCS incorporates\na fuzzy indicator as a new rule parameter that sets the membership function of\na rule as either rectangular (i.e., crisp) or triangular (i.e., fuzzy) shapes.\nThe fuzzy indicator is optimized with evolutionary operators, allowing the\nsystem to search for an optimal rule representation. Results from extensive\nexperiments conducted on continuous space problems demonstrate that\nAdaptive-UCS outperforms other UCSs with conventional crisp-hyperrectangular\nand fuzzy-hypertrapezoidal rule representations in classification accuracy.\nAdditionally, Adaptive-UCS exhibits robustness in the case of noisy inputs and\nreal-world problems with inherent uncertainty, such as missing values, leading\nto stable classification performance.", "AI": {"tldr": "The paper proposes Adaptive-UCS, a supervised LFCS with self-adaptive rule representation, improving classification performance over conventional methods.", "motivation": "Conventional rule representations in LFCSs struggle with unknown data characteristics, prompting the need for a more adaptive approach.", "method": "Adaptive-UCS introduces a fuzzy indicator optimized via evolutionary operators to dynamically adjust rule shapes (crisp or fuzzy).", "result": "Adaptive-UCS outperforms traditional UCSs in accuracy and handles noisy or uncertain data robustly.", "conclusion": "Adaptive-UCS offers a superior, adaptable solution for LFCSs, enhancing performance in diverse and uncertain scenarios."}}
{"id": "2502.04134", "pdf": "https://arxiv.org/pdf/2502.04134", "abs": "https://arxiv.org/abs/2502.04134", "authors": ["Bryan Guan", "Tanya Roosta", "Peyman Passban", "Mehdi Rezagholizadeh"], "title": "The Order Effect: Investigating Prompt Sensitivity to Input Order in LLMs", "categories": ["cs.CL"], "comment": "The first 3 authors have contributed equally", "summary": "As large language models (LLMs) become integral to diverse applications,\nensuring their reliability under varying input conditions is crucial. One key\nissue affecting this reliability is order sensitivity, wherein slight\nvariations in the input arrangement can lead to inconsistent or biased outputs.\nAlthough recent advances have reduced this sensitivity, the problem remains\nunresolved. This paper investigates the extent of order sensitivity in LLMs\nwhose internal components are hidden from users (such as closed-source models\nor those accessed via API calls). We conduct experiments across multiple tasks,\nincluding paraphrasing, relevance judgment, and multiple-choice questions. Our\nresults show that input order significantly affects performance across tasks,\nwith shuffled inputs leading to measurable declines in output accuracy.\nFew-shot prompting demonstrates mixed effectiveness and offers partial\nmitigation; however, fails to fully resolve the problem. These findings\nhighlight persistent risks, particularly in high-stakes applications, and point\nto the need for more robust LLMs or improved input-handling techniques in\nfuture development.", "AI": {"tldr": "The paper examines order sensitivity in LLMs, showing that input arrangement affects output consistency and accuracy, with few-shot prompting offering limited mitigation.", "motivation": "To assess the reliability of LLMs under varying input conditions, focusing on order sensitivity as a key issue impacting consistency and bias.", "method": "Experiments across tasks like paraphrasing, relevance judgment, and multiple-choice questions, testing shuffled inputs and few-shot prompting.", "result": "Input order significantly impacts performance, with shuffled inputs reducing accuracy. Few-shot prompting helps partially but doesn't fully resolve the issue.", "conclusion": "Order sensitivity remains a risk, especially in high-stakes applications, calling for more robust LLMs or better input-handling techniques."}}
{"id": "2505.06023", "pdf": "https://arxiv.org/pdf/2505.06023", "abs": "https://arxiv.org/abs/2505.06023", "authors": ["Qian Qi"], "title": "Universal Approximation Theorem for Deep Q-Learning via FBSDE System", "categories": ["cs.LG", "cs.AI", "math.OC"], "comment": null, "summary": "The approximation capabilities of Deep Q-Networks (DQNs) are commonly\njustified by general Universal Approximation Theorems (UATs) that do not\nleverage the intrinsic structural properties of the optimal Q-function, the\nsolution to a Bellman equation. This paper establishes a UAT for a class of\nDQNs whose architecture is designed to emulate the iterative refinement process\ninherent in Bellman updates. A central element of our analysis is the\npropagation of regularity: while the transformation induced by a single Bellman\noperator application exhibits regularity, for which Backward Stochastic\nDifferential Equations (BSDEs) theory provides analytical tools, the uniform\nregularity of the entire sequence of value iteration iterates--specifically,\ntheir uniform Lipschitz continuity on compact domains under standard Lipschitz\nassumptions on the problem data--is derived from finite-horizon dynamic\nprogramming principles. We demonstrate that layers of a deep residual network,\nconceived as neural operators acting on function spaces, can approximate the\naction of the Bellman operator. The resulting approximation theorem is thus\nintrinsically linked to the control problem's structure, offering a proof\ntechnique wherein network depth directly corresponds to iterations of value\nfunction refinement, accompanied by controlled error propagation. This\nperspective reveals a dynamic systems view of the network's operation on a\nspace of value functions.", "AI": {"tldr": "The paper presents a Universal Approximation Theorem (UAT) for Deep Q-Networks (DQNs) designed to mimic Bellman updates, linking network depth to value iteration refinements with controlled error.", "motivation": "To justify DQN approximation capabilities by leveraging the structural properties of the optimal Q-function, unlike general UATs.", "method": "Analyzes DQNs as neural operators approximating Bellman operators, using regularity propagation and dynamic programming principles.", "result": "Shows that deep residual networks can approximate Bellman operators, with network depth corresponding to value iteration refinements.", "conclusion": "The approach ties DQN architecture to control problem structure, offering a dynamic systems view of value function approximation."}}
{"id": "2505.05855", "pdf": "https://arxiv.org/pdf/2505.05855", "abs": "https://arxiv.org/abs/2505.05855", "authors": ["Hongyu Rui", "Yinzhe Wu", "Fanwen Wang", "Jiahao Huang", "Liutao Yang", "Zi Wang", "Guang Yang"], "title": "Decoupling Multi-Contrast Super-Resolution: Pairing Unpaired Synthesis with Implicit Representations", "categories": ["cs.CV"], "comment": null, "summary": "Magnetic Resonance Imaging (MRI) is critical for clinical diagnostics but is\noften limited by long acquisition times and low signal-to-noise ratios,\nespecially in modalities like diffusion and functional MRI. The multi-contrast\nnature of MRI presents a valuable opportunity for cross-modal enhancement,\nwhere high-resolution (HR) modalities can serve as references to boost the\nquality of their low-resolution (LR) counterparts-motivating the development of\nMulti-Contrast Super-Resolution (MCSR) techniques. Prior work has shown that\nleveraging complementary contrasts can improve SR performance; however,\neffective feature extraction and fusion across modalities with varying\nresolutions remains a major challenge. Moreover, existing MCSR methods often\nassume fixed resolution settings and all require large, perfectly paired\ntraining datasets-conditions rarely met in real-world clinical environments. To\naddress these challenges, we propose a novel Modular Multi-Contrast\nSuper-Resolution (MCSR) framework that eliminates the need for paired training\ndata and supports arbitrary upscaling. Our method decouples the MCSR task into\ntwo stages: (1) Unpaired Cross-Modal Synthesis (U-CMS), which translates a\nhigh-resolution reference modality into a synthesized version of the target\ncontrast, and (2) Unsupervised Super-Resolution (U-SR), which reconstructs the\nfinal output using implicit neural representations (INRs) conditioned on\nspatial coordinates. This design enables scale-agnostic and anatomically\nfaithful reconstruction by bridging un-paired cross-modal synthesis with\nunsupervised resolution enhancement. Experiments show that our method achieves\nsuperior performance at 4x and 8x upscaling, with improved fidelity and\nanatomical consistency over existing baselines. Our framework demonstrates\nstrong potential for scalable, subject-specific, and data-efficient MCSR in\nreal-world clinical settings.", "AI": {"tldr": "A novel Modular Multi-Contrast Super-Resolution (MCSR) framework is proposed to enhance MRI quality without requiring paired training data, achieving superior 4x and 8x upscaling with improved fidelity.", "motivation": "MRI's long acquisition times and low signal-to-noise ratios, especially in diffusion and functional MRI, motivate cross-modal enhancement using high-resolution references to boost low-resolution counterparts.", "method": "The framework decouples MCSR into two stages: Unpaired Cross-Modal Synthesis (U-CMS) to translate a high-resolution reference into the target contrast, and Unsupervised Super-Resolution (U-SR) using implicit neural representations for scale-agnostic reconstruction.", "result": "The method outperforms existing baselines at 4x and 8x upscaling, showing improved fidelity and anatomical consistency.", "conclusion": "The framework is scalable, subject-specific, and data-efficient, demonstrating strong potential for real-world clinical MCSR applications."}}
{"id": "2505.06047", "pdf": "https://arxiv.org/pdf/2505.06047", "abs": "https://arxiv.org/abs/2505.06047", "authors": ["Francesco Spinnato", "Cristiano Landi"], "title": "PYRREGULAR: A Unified Framework for Irregular Time Series, with Classification Benchmarks", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Irregular temporal data, characterized by varying recording frequencies,\ndiffering observation durations, and missing values, presents significant\nchallenges across fields like mobility, healthcare, and environmental science.\nExisting research communities often overlook or address these challenges in\nisolation, leading to fragmented tools and methods. To bridge this gap, we\nintroduce a unified framework, and the first standardized dataset repository\nfor irregular time series classification, built on a common array format to\nenhance interoperability. This repository comprises 34 datasets on which we\nbenchmark 12 classifier models from diverse domains and communities. This work\naims to centralize research efforts and enable a more robust evaluation of\nirregular temporal data analysis methods.", "AI": {"tldr": "A unified framework and standardized dataset repository for irregular time series classification is introduced to address fragmented research efforts and improve interoperability.", "motivation": "Irregular temporal data poses challenges due to varying frequencies, durations, and missing values, often addressed in isolation.", "method": "A common array format is used to create a repository of 34 datasets, benchmarking 12 classifier models.", "result": "The framework centralizes research and enables robust evaluation of irregular temporal data methods.", "conclusion": "This work bridges gaps in irregular time series research, fostering collaboration and standardized evaluation."}}
{"id": "2502.09667", "pdf": "https://arxiv.org/pdf/2502.09667", "abs": "https://arxiv.org/abs/2502.09667", "authors": ["Jairo Diaz-Rodriguez"], "title": "k-LLMmeans: Scalable, Stable, and Interpretable Text Clustering via LLM-based Centroids", "categories": ["cs.CL", "cs.LG", "stat.ML"], "comment": null, "summary": "We introduce k-LLMmeans, a novel modification of the k-means algorithm for\ntext clustering that leverages LLM-generated summaries as cluster centroids,\ncapturing semantic nuances often missed by purely numerical averages. This\ndesign preserves the core optimization properties of k-means while enhancing\nsemantic interpretability and avoiding the scalability and instability issues\ntypical of modern LLM-based clustering. Unlike existing methods, our approach\ndoes not increase LLM usage with dataset size and produces transparent\nintermediate outputs. We further extend it with a mini-batch variant for\nefficient, real-time clustering of streaming text. Extensive experiments across\nmultiple datasets, embeddings, and LLMs show that k-LLMmeans consistently\noutperforms k-means and other traditional baselines and achieves results\ncomparable to state-of-the-art LLM-based clustering, with a fraction of the LLM\ncalls. Finally, we present a case study on sequential text streams and\nintroduce a new benchmark dataset constructed from StackExchange to evaluate\ntext-stream clustering methods.", "AI": {"tldr": "k-LLMmeans is a modified k-means algorithm for text clustering using LLM-generated summaries as centroids, improving semantic interpretability and scalability while reducing LLM usage.", "motivation": "Existing methods for text clustering often miss semantic nuances or face scalability issues with LLMs. k-LLMmeans aims to address these limitations.", "method": "The algorithm uses LLM-generated summaries as centroids, preserving k-means optimization while enhancing semantics. A mini-batch variant is introduced for streaming text.", "result": "k-LLMmeans outperforms traditional baselines and matches state-of-the-art LLM-based clustering with fewer LLM calls.", "conclusion": "The method is efficient, scalable, and interpretable, with potential applications in real-time text-stream clustering."}}
{"id": "2505.06085", "pdf": "https://arxiv.org/pdf/2505.06085", "abs": "https://arxiv.org/abs/2505.06085", "authors": ["Hiari Pizzini Cavagna", "Daniele Cesarini", "Andrea Bartolini"], "title": "Assessing Tenstorrent's RISC-V MatMul Acceleration Capabilities", "categories": ["cs.PF", "cs.AI", "cs.AR"], "comment": "Accepted to the Computational Aspects of Deep Learning Workshop at\n  ISC High Performance 2025. To appear in the ISC High Performance 2025\n  Workshop Proceedings", "summary": "The increasing demand for generative AI as Large Language Models (LLMs)\nservices has driven the need for specialized hardware architectures that\noptimize computational efficiency and energy consumption. This paper evaluates\nthe performance of the Tenstorrent Grayskull e75 RISC-V accelerator for basic\nlinear algebra kernels at reduced numerical precision, a fundamental operation\nin LLM computations. We present a detailed characterization of Grayskull's\nexecution model, gridsize, matrix dimensions, data formats, and numerical\nprecision impact computational efficiency. Furthermore, we compare Grayskull's\nperformance against state-of-the-art architectures with tensor acceleration,\nincluding Intel Sapphire Rapids processors and two NVIDIA GPUs (V100 and A100).\nWhilst NVIDIA GPUs dominate raw performance, Grayskull demonstrates a\ncompetitive trade-off between power consumption and computational throughput,\nreaching a peak of 1.55 TFLOPs/Watt with BF16.", "AI": {"tldr": "The paper evaluates the Tenstorrent Grayskull e75 RISC-V accelerator's performance for linear algebra kernels in LLMs, comparing it to Intel Sapphire Rapids and NVIDIA GPUs. Grayskull shows competitive efficiency in power and performance.", "motivation": "The demand for efficient hardware for generative AI and LLMs drives the need to evaluate specialized accelerators like Grayskull.", "method": "The study characterizes Grayskull's execution model, gridsize, matrix dimensions, data formats, and numerical precision, comparing it to Intel Sapphire Rapids and NVIDIA GPUs.", "result": "Grayskull achieves 1.55 TFLOPs/Watt with BF16, showing a strong trade-off between power and performance, though NVIDIA GPUs lead in raw speed.", "conclusion": "Grayskull is a competitive option for LLM computations, balancing power efficiency and throughput, despite NVIDIA's superior raw performance."}}
{"id": "2505.05892", "pdf": "https://arxiv.org/pdf/2505.05892", "abs": "https://arxiv.org/abs/2505.05892", "authors": ["Alexander Lappe", "Martin A. Giese"], "title": "Register and CLS tokens yield a decoupling of local and global features in large ViTs", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "Recent work has shown that the attention maps of the widely popular DINOv2\nmodel exhibit artifacts, which hurt both model interpretability and performance\non dense image tasks. These artifacts emerge due to the model repurposing patch\ntokens with redundant local information for the storage of global image\ninformation. To address this problem, additional register tokens have been\nincorporated in which the model can store such information instead. We\ncarefully examine the influence of these register tokens on the relationship\nbetween global and local image features, showing that while register tokens\nyield cleaner attention maps, these maps do not accurately reflect the\nintegration of local image information in large models. Instead, global\ninformation is dominated by information extracted from register tokens, leading\nto a disconnect between local and global features. Inspired by these findings,\nwe show that the CLS token itself, which can be interpreted as a register,\nleads to a very similar phenomenon in models without explicit register tokens.\nOur work shows that care must be taken when interpreting attention maps of\nlarge ViTs. Further, by clearly attributing the faulty behaviour to register\nand CLS tokens, we show a path towards more interpretable vision models.", "AI": {"tldr": "DINOv2 model's attention maps have artifacts due to redundant patch tokens storing global info. Register tokens clean maps but disrupt local-global feature integration. CLS tokens cause similar issues, highlighting the need for careful attention map interpretation in large ViTs.", "motivation": "Address artifacts in DINOv2's attention maps that harm interpretability and dense task performance, caused by patch tokens storing global info redundantly.", "method": "Introduce register tokens to store global info, analyze their impact on local-global feature relationships, and compare with CLS token behavior.", "result": "Register tokens clean attention maps but disrupt local-global integration; CLS tokens exhibit similar issues, revealing broader challenges.", "conclusion": "Care is needed when interpreting attention maps in large ViTs; understanding register and CLS token roles can improve model interpretability."}}
{"id": "2505.06053", "pdf": "https://arxiv.org/pdf/2505.06053", "abs": "https://arxiv.org/abs/2505.06053", "authors": ["Rustem Islamov", "Yarden As", "Ilyas Fatkhullin"], "title": "Safe-EF: Error Feedback for Nonsmooth Constrained Optimization", "categories": ["cs.LG", "math.OC", "stat.ML"], "comment": null, "summary": "Federated learning faces severe communication bottlenecks due to the high\ndimensionality of model updates. Communication compression with contractive\ncompressors (e.g., Top-K) is often preferable in practice but can degrade\nperformance without proper handling. Error feedback (EF) mitigates such issues\nbut has been largely restricted for smooth, unconstrained problems, limiting\nits real-world applicability where non-smooth objectives and safety constraints\nare critical. We advance our understanding of EF in the canonical non-smooth\nconvex setting by establishing new lower complexity bounds for first-order\nalgorithms with contractive compression. Next, we propose Safe-EF, a novel\nalgorithm that matches our lower bound (up to a constant) while enforcing\nsafety constraints essential for practical applications. Extending our approach\nto the stochastic setting, we bridge the gap between theory and practical\nimplementation. Extensive experiments in a reinforcement learning setup,\nsimulating distributed humanoid robot training, validate the effectiveness of\nSafe-EF in ensuring safety and reducing communication complexity.", "AI": {"tldr": "The paper addresses communication bottlenecks in federated learning by introducing Safe-EF, a novel algorithm that enforces safety constraints and matches theoretical lower bounds for non-smooth convex problems.", "motivation": "Federated learning suffers from high communication costs due to large model updates, and existing methods like error feedback (EF) are limited to smooth, unconstrained problems, restricting real-world applicability.", "method": "The authors propose Safe-EF, an algorithm that extends EF to non-smooth convex problems with safety constraints, and validate it in a stochastic setting and RL experiments.", "result": "Safe-EF matches theoretical lower bounds for communication compression and ensures safety in practical applications, as demonstrated in distributed robot training.", "conclusion": "Safe-EF bridges theory and practice, offering a scalable solution for federated learning with non-smooth objectives and safety constraints."}}
{"id": "2502.14338", "pdf": "https://arxiv.org/pdf/2502.14338", "abs": "https://arxiv.org/abs/2502.14338", "authors": ["Avinash Patil", "Siru Tao", "Aryan Jadon"], "title": "English Please: Evaluating Machine Translation with Large Language Models for Multilingual Bug Reports", "categories": ["cs.CL", "cs.SE"], "comment": "8 Pages, 4 Figures, 3 Tables", "summary": "Accurate translation of bug reports is critical for efficient collaboration\nin global software development. In this study, we conduct the first\ncomprehensive evaluation of machine translation (MT) performance on bug\nreports, analyzing the capabilities of DeepL, AWS Translate, and large language\nmodels such as ChatGPT, Claude, Gemini, LLaMA, and Mistral using data from the\nVisual Studio Code GitHub repository, specifically focusing on reports labeled\nwith the english-please tag. To assess both translation quality and source\nlanguage identification accuracy, we employ a range of MT evaluation\nmetrics-including BLEU, BERTScore, COMET, METEOR, and ROUGE-alongside\nclassification metrics such as accuracy, precision, recall, and F1-score. Our\nfindings reveal that while ChatGPT (gpt-4o) excels in semantic and lexical\ntranslation quality, it does not lead in source language identification. Claude\nand Mistral achieve the highest F1-scores (0.7182 and 0.7142, respectively),\nand Gemini records the best precision (0.7414). AWS Translate shows the highest\naccuracy (0.4717) in identifying source languages. These results highlight that\nno single system dominates across all tasks, reinforcing the importance of\ntask-specific evaluations. This study underscores the need for domain\nadaptation when translating technical content and provides actionable insights\nfor integrating MT into bug-triaging workflows. The code and dataset for this\npaper are available at GitHub-https://github.com/av9ash/English-Please", "AI": {"tldr": "The study evaluates machine translation (MT) performance on bug reports, comparing tools like DeepL, AWS Translate, and LLMs (ChatGPT, Claude, Gemini, LLaMA, Mistral) using metrics like BLEU, BERTScore, and classification scores. ChatGPT excels in translation quality, while Claude and Mistral lead in F1-score for source language identification. AWS Translate is most accurate in language identification. No single tool dominates all tasks.", "motivation": "Accurate translation of bug reports is essential for global software development collaboration, but MT performance on technical content like bug reports is understudied.", "method": "Evaluated MT tools (DeepL, AWS Translate, ChatGPT, Claude, Gemini, LLaMA, Mistral) using bug reports from Visual Studio Code GitHub (english-please tag). Metrics: BLEU, BERTScore, COMET, METEOR, ROUGE for translation; accuracy, precision, recall, F1-score for language identification.", "result": "ChatGPT (gpt-4o) best for translation quality. Claude and Mistral top F1-scores (0.7182, 0.7142) for language identification. Gemini has best precision (0.7414). AWS Translate most accurate (0.4717) in language ID.", "conclusion": "No single MT tool excels in all tasks; task-specific evaluation is crucial. Domain adaptation is needed for technical content. Insights provided for integrating MT into bug-triaging workflows."}}
{"id": "2505.06091", "pdf": "https://arxiv.org/pdf/2505.06091", "abs": "https://arxiv.org/abs/2505.06091", "authors": ["Xinxin Li", "Juan Zhang", "Da Li", "Xingyu Liu", "Jin Xu", "Junping Yin"], "title": "UniSymNet: A Unified Symbolic Network Guided by Transformer", "categories": ["cs.LG", "cs.AI", "cs.SC"], "comment": null, "summary": "Symbolic Regression (SR) is a powerful technique for automatically\ndiscovering mathematical expressions from input data. Mainstream SR algorithms\nsearch for the optimal symbolic tree in a vast function space, but the\nincreasing complexity of the tree structure limits their performance. Inspired\nby neural networks, symbolic networks have emerged as a promising new paradigm.\nHowever, most existing symbolic networks still face certain challenges: binary\nnonlinear operators $\\{\\times, \\div\\}$ cannot be naturally extended to\nmultivariate operators, and training with fixed architecture often leads to\nhigher complexity and overfitting. In this work, we propose a Unified Symbolic\nNetwork that unifies nonlinear binary operators into nested unary operators and\ndefine the conditions under which UniSymNet can reduce complexity. Moreover, we\npre-train a Transformer model with a novel label encoding method to guide\nstructural selection, and adopt objective-specific optimization strategies to\nlearn the parameters of the symbolic network. UniSymNet shows high fitting\naccuracy, excellent symbolic solution rate, and relatively low expression\ncomplexity, achieving competitive performance on low-dimensional Standard\nBenchmarks and high-dimensional SRBench.", "AI": {"tldr": "A Unified Symbolic Network (UniSymNet) is proposed to address challenges in symbolic regression by unifying binary operators into nested unary ones, reducing complexity and improving performance.", "motivation": "Current symbolic networks struggle with extending binary operators to multivariate cases and face issues like overfitting due to fixed architectures.", "method": "UniSymNet unifies nonlinear binary operators into nested unary operators, pre-trains a Transformer with label encoding for structural guidance, and uses objective-specific optimization.", "result": "UniSymNet achieves high accuracy, strong symbolic solution rates, and low complexity, performing well on benchmarks.", "conclusion": "The proposed UniSymNet offers a promising solution for symbolic regression by addressing key limitations of existing methods."}}
{"id": "2505.05913", "pdf": "https://arxiv.org/pdf/2505.05913", "abs": "https://arxiv.org/abs/2505.05913", "authors": ["Jianjian Yin", "Yi Chen", "Chengyu Li", "Zhichao Zheng", "Yanhui Gu", "Junsheng Zhou"], "title": "DFEN: Dual Feature Equalization Network for Medical Image Segmentation", "categories": ["cs.CV"], "comment": null, "summary": "Current methods for medical image segmentation primarily focus on extracting\ncontextual feature information from the perspective of the whole image. While\nthese methods have shown effective performance, none of them take into account\nthe fact that pixels at the boundary and regions with a low number of class\npixels capture more contextual feature information from other classes, leading\nto misclassification of pixels by unequal contextual feature information. In\nthis paper, we propose a dual feature equalization network based on the hybrid\narchitecture of Swin Transformer and Convolutional Neural Network, aiming to\naugment the pixel feature representations by image-level equalization feature\ninformation and class-level equalization feature information. Firstly, the\nimage-level feature equalization module is designed to equalize the contextual\ninformation of pixels within the image. Secondly, we aggregate regions of the\nsame class to equalize the pixel feature representations of the corresponding\nclass by class-level feature equalization module. Finally, the pixel feature\nrepresentations are enhanced by learning weights for image-level equalization\nfeature information and class-level equalization feature information. In\naddition, Swin Transformer is utilized as both the encoder and decoder, thereby\nbolstering the ability of the model to capture long-range dependencies and\nspatial correlations. We conducted extensive experiments on Breast Ultrasound\nImages (BUSI), International Skin Imaging Collaboration (ISIC2017), Automated\nCardiac Diagnosis Challenge (ACDC) and PH$^2$ datasets. The experimental\nresults demonstrate that our method have achieved state-of-the-art performance.\nOur code is publicly available at https://github.com/JianJianYin/DFEN.", "AI": {"tldr": "A dual feature equalization network combining Swin Transformer and CNN is proposed to address unequal contextual feature information in medical image segmentation, achieving state-of-the-art results.", "motivation": "Current methods ignore unequal contextual feature information at boundaries and low-class-pixel regions, leading to misclassification.", "method": "The network uses image-level and class-level feature equalization modules, with Swin Transformer for long-range dependencies.", "result": "Achieves top performance on BUSI, ISIC2017, ACDC, and PH$^2$ datasets.", "conclusion": "The proposed method effectively enhances pixel feature representations and outperforms existing approaches."}}
{"id": "2505.06080", "pdf": "https://arxiv.org/pdf/2505.06080", "abs": "https://arxiv.org/abs/2505.06080", "authors": ["Luis Miguel Esquivel-Sancho", "Maryam Ghandchi Tehrani", "Mauricio Mu\u00f1oz-Arias", "Mahmoud Askari"], "title": "Fault Diagnosis of 3D-Printed Scaled Wind Turbine Blades", "categories": ["cs.LG"], "comment": null, "summary": "This study presents an integrated methodology for fault detection in wind\nturbine blades using 3D-printed scaled models, finite element simulations,\nexperimental modal analysis, and machine learning techniques. A scaled model of\nthe NREL 5MW blade was fabricated using 3D printing, and crack-type damages\nwere introduced at critical locations. Finite Element Analysis was employed to\npredict the impact of these damages on the natural frequencies, with the\nresults validated through controlled hammer impact tests. Vibration data was\nprocessed to extract both time-domain and frequency-domain features, and key\ndiscriminative variables were identified using statistical analyses (ANOVA).\nMachine learning classifiers, including Support Vector Machine and K-Nearest\nNeighbors, achieved classification accuracies exceeding 94%. The results\nrevealed that vibration modes 3, 4, and 6 are particularly sensitive to\nstructural anomalies for this blade. This integrated approach confirms the\nfeasibility of combining numerical simulations with experimental validations\nand paves the way for structural health monitoring systems in wind energy\napplications.", "AI": {"tldr": "An integrated method for detecting faults in wind turbine blades using 3D-printed models, simulations, experiments, and machine learning achieved over 94% accuracy.", "motivation": "To develop a reliable fault detection system for wind turbine blades by combining numerical and experimental approaches.", "method": "Used 3D-printed scaled models, finite element simulations, experimental modal analysis, and machine learning (SVM and KNN) for damage detection.", "result": "Machine learning classifiers achieved over 94% accuracy, with vibration modes 3, 4, and 6 being most sensitive to damage.", "conclusion": "The approach is feasible for structural health monitoring in wind energy, combining simulations and experiments effectively."}}
{"id": "2502.20364", "pdf": "https://arxiv.org/pdf/2502.20364", "abs": "https://arxiv.org/abs/2502.20364", "authors": ["Ryan C. Barron", "Maksim E. Eren", "Olga M. Serafimova", "Cynthia Matuszek", "Boian S. Alexandrov"], "title": "Bridging Legal Knowledge and AI: Retrieval-Augmented Generation with Vector Stores, Knowledge Graphs, and Hierarchical Non-negative Matrix Factorization", "categories": ["cs.CL", "cs.AI"], "comment": "10 pages, 8 figures, 5 tables", "summary": "Agentic Generative AI, powered by Large Language Models (LLMs) with\nRetrieval-Augmented Generation (RAG), Knowledge Graphs (KGs), and Vector Stores\n(VSs), represents a transformative technology applicable to specialized domains\nsuch as legal systems, research, recommender systems, cybersecurity, and global\nsecurity, including proliferation research. This technology excels at inferring\nrelationships within vast unstructured or semi-structured datasets. The legal\ndomain here comprises complex data characterized by extensive, interrelated,\nand semi-structured knowledge systems with complex relations. It comprises\nconstitutions, statutes, regulations, and case law. Extracting insights and\nnavigating the intricate networks of legal documents and their relations is\ncrucial for effective legal research. Here, we introduce a generative AI system\nthat integrates RAG, VS, and KG, constructed via Non-Negative Matrix\nFactorization (NMF), to enhance legal information retrieval and AI reasoning\nand minimize hallucinations. In the legal system, these technologies empower AI\nagents to identify and analyze complex connections among cases, statutes, and\nlegal precedents, uncovering hidden relationships and predicting legal\ntrends-challenging tasks that are essential for ensuring justice and improving\noperational efficiency. Our system employs web scraping techniques to\nsystematically collect legal texts, such as statutes, constitutional\nprovisions, and case law, from publicly accessible platforms like Justia. It\nbridges the gap between traditional keyword-based searches and contextual\nunderstanding by leveraging advanced semantic representations, hierarchical\nrelationships, and latent topic discovery. This framework supports legal\ndocument clustering, summarization, and cross-referencing, for scalable,\ninterpretable, and accurate retrieval for semi-structured data while advancing\ncomputational law and AI.", "AI": {"tldr": "A generative AI system integrating RAG, VS, and KG via NMF enhances legal information retrieval, minimizes hallucinations, and improves reasoning in complex legal datasets.", "motivation": "The legal domain's complex, interrelated data requires advanced AI to extract insights, navigate relationships, and predict trends for justice and efficiency.", "method": "The system uses web scraping to collect legal texts, integrates RAG, VS, and KG via NMF, and leverages semantic representations and topic discovery.", "result": "Enables scalable, interpretable legal document clustering, summarization, and cross-referencing, improving retrieval and reasoning.", "conclusion": "The framework advances computational law and AI by bridging keyword searches with contextual understanding for semi-structured legal data."}}
{"id": "2505.06108", "pdf": "https://arxiv.org/pdf/2505.06108", "abs": "https://arxiv.org/abs/2505.06108", "authors": ["Lennart Justen"], "title": "LLMs Outperform Experts on Challenging Biology Benchmarks", "categories": ["cs.LG", "cs.AI", "q-bio.QM"], "comment": null, "summary": "This study systematically evaluates 27 frontier Large Language Models on\neight diverse biology benchmarks spanning molecular biology, genetics, cloning,\nvirology, and biosecurity. Models from major AI developers released between\nNovember 2022 and April 2025 were assessed through ten independent runs per\nbenchmark. The findings reveal dramatic improvements in biological\ncapabilities. Top model performance increased more than 4-fold on the\nchallenging text-only subset of the Virology Capabilities Test over the study\nperiod, with the top model now performing twice as well as expert virologists.\nSeveral models now match or exceed expert-level performance on other\nchallenging benchmarks, including LAB-Bench CloningScenarios and the biology\nsubsets of GPQA and WMDP. Contrary to expectations, chain-of-thought did not\nsubstantially improve performance over zero-shot evaluation, while extended\nreasoning features in o3-mini and Claude 3.7 Sonnet typically improved\nperformance as predicted by inference scaling. Benchmarks such as PubMedQA and\nthe MMLU and WMDP biology subsets exhibited performance plateaus well below\n100%, suggesting benchmark saturation and errors in the underlying benchmark\ndata. The analysis highlights the need for more sophisticated evaluation\nmethodologies as AI systems continue to advance.", "AI": {"tldr": "The study evaluates 27 LLMs on eight biology benchmarks, showing significant performance improvements, with some models surpassing expert virologists. Extended reasoning features helped, but chain-of-thought did not. Some benchmarks plateaued, indicating data issues.", "motivation": "To assess the biological capabilities of frontier LLMs and track their progress over time, comparing them to expert performance.", "method": "Evaluated 27 LLMs on eight diverse biology benchmarks through ten independent runs per benchmark.", "result": "Top models showed 4-fold improvement in virology, with some matching or exceeding expert performance. Extended reasoning features boosted results, but chain-of-thought did not. Some benchmarks plateaued below 100%.", "conclusion": "LLMs have advanced significantly in biology, but better evaluation methods are needed due to benchmark saturation and data errors."}}
{"id": "2505.05936", "pdf": "https://arxiv.org/pdf/2505.05936", "abs": "https://arxiv.org/abs/2505.05936", "authors": ["Weihong Li", "Xiaoqiong Liu", "Heng Fan", "Libo Zhang"], "title": "CGTrack: Cascade Gating Network with Hierarchical Feature Aggregation for UAV Tracking", "categories": ["cs.CV"], "comment": "Accepted by ICRA 2025", "summary": "Recent advancements in visual object tracking have markedly improved the\ncapabilities of unmanned aerial vehicle (UAV) tracking, which is a critical\ncomponent in real-world robotics applications. While the integration of\nhierarchical lightweight networks has become a prevalent strategy for enhancing\nefficiency in UAV tracking, it often results in a significant drop in network\ncapacity, which further exacerbates challenges in UAV scenarios, such as\nfrequent occlusions and extreme changes in viewing angles. To address these\nissues, we introduce a novel family of UAV trackers, termed CGTrack, which\ncombines explicit and implicit techniques to expand network capacity within a\ncoarse-to-fine framework. Specifically, we first introduce a Hierarchical\nFeature Cascade (HFC) module that leverages the spirit of feature reuse to\nincrease network capacity by integrating the deep semantic cues with the rich\nspatial information, incurring minimal computational costs while enhancing\nfeature representation. Based on this, we design a novel Lightweight Gated\nCenter Head (LGCH) that utilizes gating mechanisms to decouple target-oriented\ncoordinates from previously expanded features, which contain dense local\ndiscriminative information. Extensive experiments on three challenging UAV\ntracking benchmarks demonstrate that CGTrack achieves state-of-the-art\nperformance while running fast. Code will be available at\nhttps://github.com/Nightwatch-Fox11/CGTrack.", "AI": {"tldr": "CGTrack, a novel UAV tracker, combines explicit and implicit techniques in a coarse-to-fine framework to enhance network capacity and efficiency, addressing challenges like occlusions and viewing angle changes.", "motivation": "Improving UAV tracking efficiency without sacrificing network capacity, especially under challenges like occlusions and extreme viewing angle changes.", "method": "Introduces a Hierarchical Feature Cascade (HFC) module for feature reuse and a Lightweight Gated Center Head (LGCH) for decoupling target coordinates, enhancing feature representation.", "result": "Achieves state-of-the-art performance on UAV tracking benchmarks with fast execution.", "conclusion": "CGTrack effectively balances efficiency and capacity, making it a robust solution for UAV tracking."}}
{"id": "2505.06087", "pdf": "https://arxiv.org/pdf/2505.06087", "abs": "https://arxiv.org/abs/2505.06087", "authors": ["Sergio Garc\u00eda-Heredia", "\u00c1ngela Fern\u00e1ndez", "Carlos M. Ala\u00edz"], "title": "Deep Diffusion Maps", "categories": ["cs.LG"], "comment": null, "summary": "One of the fundamental problems within the field of machine learning is\ndimensionality reduction. Dimensionality reduction methods make it possible to\ncombat the so-called curse of dimensionality, visualize high-dimensional data\nand, in general, improve the efficiency of storing and processing large data\nsets. One of the best-known nonlinear dimensionality reduction methods is\nDiffusion Maps. However, despite their virtues, both Diffusion Maps and many\nother manifold learning methods based on the spectral decomposition of kernel\nmatrices have drawbacks such as the inability to apply them to data outside the\ninitial set, their computational complexity, and high memory costs for large\ndata sets. In this work, we propose to alleviate these problems by resorting to\ndeep learning. Specifically, a new formulation of Diffusion Maps embedding is\noffered as a solution to a certain unconstrained minimization problem and,\nbased on it, a cost function to train a neural network which computes Diffusion\nMaps embedding -- both inside and outside the training sample -- without the\nneed to perform any spectral decomposition. The capabilities of this approach\nare compared on different data sets, both real and synthetic, with those of\nDiffusion Maps and the Nystrom method.", "AI": {"tldr": "The paper proposes a deep learning-based approach to improve Diffusion Maps for dimensionality reduction, addressing computational and scalability issues.", "motivation": "Existing nonlinear dimensionality reduction methods like Diffusion Maps face challenges such as computational complexity, memory costs, and inability to generalize to new data.", "method": "The authors reformulate Diffusion Maps as an unconstrained minimization problem and train a neural network to compute embeddings without spectral decomposition.", "result": "The proposed method is evaluated on synthetic and real datasets, showing comparable performance to Diffusion Maps and the Nystrom method.", "conclusion": "Deep learning offers a viable solution to enhance Diffusion Maps, improving scalability and generalization."}}
{"id": "2503.17460", "pdf": "https://arxiv.org/pdf/2503.17460", "abs": "https://arxiv.org/abs/2503.17460", "authors": ["Reem Gody", "Mahmoud Goudy", "Ahmed Y. Tawfik"], "title": "ConvoGen: Enhancing Conversational AI with Synthetic Data: A Multi-Agent Approach", "categories": ["cs.CL"], "comment": null, "summary": "In this paper, we present ConvoGen: an innovative framework for generating\nsynthetic conversational data using multi-agent systems. Our method leverages\nfew-shot learning and introduces iterative sampling from a dynamically updated\nfew-shot hub to create diverse and realistic conversational scenarios. The\ngenerated data has numerous applications, including training and evaluating\nconversational AI models, and augmenting existing datasets for tasks like\nconversational intent classification or conversation summarization. Our\nexperiments demonstrate the effectiveness of this method in producing\nhigh-quality diverse synthetic conversational data, highlighting its potential\nto enhance the development and evaluation of conversational AI systems.", "AI": {"tldr": "ConvoGen is a framework for generating synthetic conversational data using multi-agent systems, leveraging few-shot learning and iterative sampling for diverse, realistic scenarios.", "motivation": "To address the need for high-quality synthetic conversational data for training and evaluating conversational AI models.", "method": "Uses multi-agent systems, few-shot learning, and iterative sampling from a dynamically updated few-shot hub.", "result": "Produces high-quality, diverse synthetic conversational data.", "conclusion": "ConvoGen enhances the development and evaluation of conversational AI systems."}}
{"id": "2505.06111", "pdf": "https://arxiv.org/pdf/2505.06111", "abs": "https://arxiv.org/abs/2505.06111", "authors": ["Qingwen Bu", "Yanting Yang", "Jisong Cai", "Shenyuan Gao", "Guanghui Ren", "Maoqing Yao", "Ping Luo", "Hongyang Li"], "title": "UniVLA: Learning to Act Anywhere with Task-centric Latent Actions", "categories": ["cs.RO", "cs.AI", "cs.LG"], "comment": "Accepted to RSS 2025. Code is available at\n  https://github.com/OpenDriveLab/UniVLA", "summary": "A generalist robot should perform effectively across various environments.\nHowever, most existing approaches heavily rely on scaling action-annotated data\nto enhance their capabilities. Consequently, they are often limited to single\nphysical specification and struggle to learn transferable knowledge across\ndifferent embodiments and environments. To confront these limitations, we\npropose UniVLA, a new framework for learning cross-embodiment\nvision-language-action (VLA) policies. Our key innovation is to derive\ntask-centric action representations from videos with a latent action model.\nThis enables us to exploit extensive data across a wide spectrum of embodiments\nand perspectives. To mitigate the effect of task-irrelevant dynamics, we\nincorporate language instructions and establish a latent action model within\nthe DINO feature space. Learned from internet-scale videos, the generalist\npolicy can be deployed to various robots through efficient latent action\ndecoding. We obtain state-of-the-art results across multiple manipulation and\nnavigation benchmarks, as well as real-robot deployments. UniVLA achieves\nsuperior performance over OpenVLA with less than 1/20 of pretraining compute\nand 1/10 of downstream data. Continuous performance improvements are observed\nas heterogeneous data, even including human videos, are incorporated into the\ntraining pipeline. The results underscore UniVLA's potential to facilitate\nscalable and efficient robot policy learning.", "AI": {"tldr": "UniVLA is a framework for cross-embodiment vision-language-action policies, using task-centric action representations from videos to improve generalization across robots and environments.", "motivation": "Existing robot learning methods rely on large-scale annotated data and struggle with transferability across different embodiments and environments.", "method": "UniVLA derives task-centric action representations from videos using a latent action model in the DINO feature space, incorporating language instructions to filter irrelevant dynamics.", "result": "UniVLA achieves state-of-the-art performance in manipulation and navigation benchmarks, outperforming OpenVLA with significantly less compute and data.", "conclusion": "UniVLA demonstrates scalable and efficient robot policy learning, with continuous improvements from heterogeneous data, including human videos."}}
{"id": "2505.06002", "pdf": "https://arxiv.org/pdf/2505.06002", "abs": "https://arxiv.org/abs/2505.06002", "authors": ["Congqi Cao", "Peiheng Han", "Yueran zhang", "Yating Yu", "Qinyi Lv", "Lingtong Min", "Yanning zhang"], "title": "Task-Adapter++: Task-specific Adaptation with Order-aware Alignment for Few-shot Action Recognition", "categories": ["cs.CV"], "comment": "arXiv admin note: substantial text overlap with arXiv:2408.00249", "summary": "Large-scale pre-trained models have achieved remarkable success in language\nand image tasks, leading an increasing number of studies to explore the\napplication of pre-trained image models, such as CLIP, in the domain of\nfew-shot action recognition (FSAR). However, current methods generally suffer\nfrom several problems: 1) Direct fine-tuning often undermines the\ngeneralization capability of the pre-trained model; 2) The exploration of\ntask-specific information is insufficient in the visual tasks; 3) The semantic\norder information is typically overlooked during text modeling; 4) Existing\ncross-modal alignment techniques ignore the temporal coupling of multimodal\ninformation. To address these, we propose Task-Adapter++, a parameter-efficient\ndual adaptation method for both image and text encoders. Specifically, to make\nfull use of the variations across different few-shot learning tasks, we design\na task-specific adaptation for the image encoder so that the most\ndiscriminative information can be well noticed during feature extraction.\nFurthermore, we leverage large language models (LLMs) to generate detailed\nsequential sub-action descriptions for each action class, and introduce\nsemantic order adapters into the text encoder to effectively model the\nsequential relationships between these sub-actions. Finally, we develop an\ninnovative fine-grained cross-modal alignment strategy that actively maps\nvisual features to reside in the same temporal stage as semantic descriptions.\nExtensive experiments fully demonstrate the effectiveness and superiority of\nthe proposed method, which achieves state-of-the-art performance on 5\nbenchmarks consistently. The code is open-sourced at\nhttps://github.com/Jaulin-Bage/Task-Adapter-pp.", "AI": {"tldr": "Task-Adapter++ is a parameter-efficient dual adaptation method for few-shot action recognition, addressing issues like generalization loss, insufficient task-specific exploration, overlooked semantic order, and temporal coupling in cross-modal alignment.", "motivation": "Current methods for few-shot action recognition using pre-trained models like CLIP suffer from generalization loss, inadequate task-specific exploration, ignored semantic order, and poor temporal coupling in cross-modal alignment.", "method": "Proposes Task-Adapter++ with task-specific adaptation for image encoders, semantic order adapters for text encoders using LLMs, and fine-grained cross-modal alignment.", "result": "Achieves state-of-the-art performance on 5 benchmarks, demonstrating effectiveness and superiority.", "conclusion": "Task-Adapter++ effectively addresses key challenges in few-shot action recognition, offering a robust and efficient solution."}}
{"id": "2505.06114", "pdf": "https://arxiv.org/pdf/2505.06114", "abs": "https://arxiv.org/abs/2505.06114", "authors": ["Xiwen Chen", "Wenhui Zhu", "Peijie Qiu", "Hao Wang", "Huayu Li", "Zihan Li", "Yalin Wang", "Aristeidis Sotiras", "Abolfazl Razi"], "title": "FIC-TSC: Learning Time Series Classification with Fisher Information Constraint", "categories": ["cs.LG"], "comment": "Accepted by ICML2025. Pre camera-ready version", "summary": "Analyzing time series data is crucial to a wide spectrum of applications,\nincluding economics, online marketplaces, and human healthcare. In particular,\ntime series classification plays an indispensable role in segmenting different\nphases in stock markets, predicting customer behavior, and classifying worker\nactions and engagement levels. These aspects contribute significantly to the\nadvancement of automated decision-making and system optimization in real-world\napplications. However, there is a large consensus that time series data often\nsuffers from domain shifts between training and test sets, which dramatically\ndegrades the classification performance. Despite the success of (reversible)\ninstance normalization in handling the domain shifts for time series regression\ntasks, its performance in classification is unsatisfactory. In this paper, we\npropose \\textit{FIC-TSC}, a training framework for time series classification\nthat leverages Fisher information as the constraint. We theoretically and\nempirically show this is an efficient and effective solution to guide the model\nconverge toward flatter minima, which enhances its generalizability to\ndistribution shifts. We rigorously evaluate our method on 30 UEA multivariate\nand 85 UCR univariate datasets. Our empirical results demonstrate the\nsuperiority of the proposed method over 14 recent state-of-the-art methods.", "AI": {"tldr": "Proposes FIC-TSC, a Fisher information-constrained framework for time series classification to address domain shifts, outperforming 14 state-of-the-art methods.", "motivation": "Time series classification is vital but suffers from domain shifts, degrading performance. Existing methods like instance normalization fail for classification tasks.", "method": "Introduces FIC-TSC, leveraging Fisher information to guide models toward flatter minima for better generalizability.", "result": "Evaluated on 115 datasets (UEA and UCR), FIC-TSC outperforms 14 recent state-of-the-art methods.", "conclusion": "FIC-TSC effectively addresses domain shifts in time series classification, enhancing model generalizability and performance."}}
{"id": "2504.17480", "pdf": "https://arxiv.org/pdf/2504.17480", "abs": "https://arxiv.org/abs/2504.17480", "authors": ["Xin Yi", "Yue Li", "Shunfan Zheng", "Linlin Wang", "Xiaoling Wang", "Liang He"], "title": "Unified Attacks to Large Language Model Watermarks: Spoofing and Scrubbing in Unauthorized Knowledge Distillation", "categories": ["cs.CL"], "comment": null, "summary": "Watermarking has emerged as a critical technique for combating misinformation\nand protecting intellectual property in large language models (LLMs). A recent\ndiscovery, termed watermark radioactivity, reveals that watermarks embedded in\nteacher models can be inherited by student models through knowledge\ndistillation. On the positive side, this inheritance allows for the detection\nof unauthorized knowledge distillation by identifying watermark traces in\nstudent models. However, the robustness of watermarks against scrubbing attacks\nand their unforgeability in the face of spoofing attacks under unauthorized\nknowledge distillation remain largely unexplored. Existing watermark attack\nmethods either assume access to model internals or fail to simultaneously\nsupport both scrubbing and spoofing attacks. In this work, we propose\nContrastive Decoding-Guided Knowledge Distillation (CDG-KD), a unified\nframework that enables bidirectional attacks under unauthorized knowledge\ndistillation. Our approach employs contrastive decoding to extract corrupted or\namplified watermark texts via comparing outputs from the student model and\nweakly watermarked references, followed by bidirectional distillation to train\nnew student models capable of watermark removal and watermark forgery,\nrespectively. Extensive experiments show that CDG-KD effectively performs\nattacks while preserving the general performance of the distilled model. Our\nfindings underscore critical need for developing watermarking schemes that are\nrobust and unforgeable.", "AI": {"tldr": "Watermark radioactivity in LLMs allows watermark inheritance in student models, enabling detection of unauthorized distillation. CDG-KD is proposed for bidirectional attacks (removal and forgery) under unauthorized distillation, highlighting the need for robust watermarks.", "motivation": "To address the unexplored robustness and unforgeability of watermarks in LLMs against scrubbing and spoofing attacks during unauthorized knowledge distillation.", "method": "Proposes CDG-KD, a framework using contrastive decoding to extract corrupted/amplified watermarks and bidirectional distillation for watermark removal/forgery.", "result": "CDG-KD effectively performs attacks while maintaining model performance, demonstrating vulnerabilities in current watermarking schemes.", "conclusion": "The study emphasizes the necessity for developing more robust and unforgeable watermarking techniques in LLMs."}}
{"id": "2505.06123", "pdf": "https://arxiv.org/pdf/2505.06123", "abs": "https://arxiv.org/abs/2505.06123", "authors": ["Philip Naumann", "Jacob Kauffmann", "Gr\u00e9goire Montavon"], "title": "Wasserstein Distances Made Explainable: Insights into Dataset Shifts and Transport Phenomena", "categories": ["cs.LG", "cs.AI", "cs.CV"], "comment": null, "summary": "Wasserstein distances provide a powerful framework for comparing data\ndistributions. They can be used to analyze processes over time or to detect\ninhomogeneities within data. However, simply calculating the Wasserstein\ndistance or analyzing the corresponding transport map (or coupling) may not be\nsufficient for understanding what factors contribute to a high or low\nWasserstein distance. In this work, we propose a novel solution based on\nExplainable AI that allows us to efficiently and accurately attribute\nWasserstein distances to various data components, including data subgroups,\ninput features, or interpretable subspaces. Our method achieves high accuracy\nacross diverse datasets and Wasserstein distance specifications, and its\npractical utility is demonstrated in two use cases.", "AI": {"tldr": "A novel Explainable AI method is proposed to attribute Wasserstein distances to data components, enhancing interpretability.", "motivation": "Understanding factors contributing to high or low Wasserstein distances is challenging with current methods.", "method": "Proposes an Explainable AI-based approach to attribute Wasserstein distances to data subgroups, features, or subspaces.", "result": "Achieves high accuracy across diverse datasets and demonstrates practical utility in use cases.", "conclusion": "The method enhances interpretability and utility of Wasserstein distance analysis."}}
{"id": "2505.06003", "pdf": "https://arxiv.org/pdf/2505.06003", "abs": "https://arxiv.org/abs/2505.06003", "authors": ["Moritz Vandenhirtz", "Julia E. Vogt"], "title": "From Pixels to Perception: Interpretable Predictions via Instance-wise Grouped Feature Selection", "categories": ["cs.CV", "cs.LG"], "comment": "International Conference on Machine Learning", "summary": "Understanding the decision-making process of machine learning models provides\nvaluable insights into the task, the data, and the reasons behind a model's\nfailures. In this work, we propose a method that performs inherently\ninterpretable predictions through the instance-wise sparsification of input\nimages. To align the sparsification with human perception, we learn the masking\nin the space of semantically meaningful pixel regions rather than on\npixel-level. Additionally, we introduce an explicit way to dynamically\ndetermine the required level of sparsity for each instance. We show empirically\non semi-synthetic and natural image datasets that our inherently interpretable\nclassifier produces more meaningful, human-understandable predictions than\nstate-of-the-art benchmarks.", "AI": {"tldr": "Proposes an interpretable ML method using instance-wise sparsification of images, aligning with human perception via semantic regions and dynamic sparsity.", "motivation": "To provide insights into model decisions and improve interpretability by aligning explanations with human understanding.", "method": "Instance-wise sparsification of input images using semantic pixel regions and dynamic sparsity determination.", "result": "Produces more meaningful, human-understandable predictions than benchmarks on semi-synthetic and natural datasets.", "conclusion": "The method enhances interpretability and aligns model explanations with human perception effectively."}}
{"id": "2505.06134", "pdf": "https://arxiv.org/pdf/2505.06134", "abs": "https://arxiv.org/abs/2505.06134", "authors": ["Julian F. Schumann", "Jeroen Hagenus", "Frederik Baymler Mathiesen", "Arkady Zgonnikov"], "title": "Realistic Adversarial Attacks for Robustness Evaluation of Trajectory Prediction Models via Future State Perturbation", "categories": ["cs.LG", "cs.HC"], "comment": "20 pages, 3 figures", "summary": "Trajectory prediction is a key element of autonomous vehicle systems,\nenabling them to anticipate and react to the movements of other road users.\nEvaluating the robustness of prediction models against adversarial attacks is\nessential to ensure their reliability in real-world traffic. However, current\napproaches tend to focus on perturbing the past positions of surrounding\nagents, which can generate unrealistic scenarios and overlook critical\nvulnerabilities. This limitation may result in overly optimistic assessments of\nmodel performance in real-world conditions.\n  In this work, we demonstrate that perturbing not just past but also future\nstates of adversarial agents can uncover previously undetected weaknesses and\nthereby provide a more rigorous evaluation of model robustness. Our novel\napproach incorporates dynamic constraints and preserves tactical behaviors,\nenabling more effective and realistic adversarial attacks. We introduce new\nperformance measures to assess the realism and impact of these adversarial\ntrajectories. Testing our method on a state-of-the-art prediction model\nrevealed significant increases in prediction errors and collision rates under\nadversarial conditions. Qualitative analysis further showed that our attacks\ncan expose critical weaknesses, such as the inability of the model to detect\npotential collisions in what appear to be safe predictions. These results\nunderscore the need for more comprehensive adversarial testing to better\nevaluate and improve the reliability of trajectory prediction models for\nautonomous vehicles.", "AI": {"tldr": "The paper proposes a novel adversarial attack method for trajectory prediction models in autonomous vehicles, focusing on perturbing both past and future states to uncover hidden vulnerabilities and improve robustness evaluation.", "motivation": "Current adversarial testing methods for trajectory prediction models focus only on perturbing past positions, leading to unrealistic scenarios and overly optimistic assessments of model reliability.", "method": "The authors introduce a method that perturbs both past and future states of adversarial agents, incorporating dynamic constraints and preserving tactical behaviors for realistic attacks. New performance measures are also introduced.", "result": "Testing revealed significant increases in prediction errors and collision rates under adversarial conditions, exposing critical weaknesses like undetected potential collisions.", "conclusion": "The findings highlight the necessity of more comprehensive adversarial testing to enhance the reliability of trajectory prediction models for autonomous vehicles."}}
{"id": "2504.21463", "pdf": "https://arxiv.org/pdf/2504.21463", "abs": "https://arxiv.org/abs/2504.21463", "authors": ["Haowen Hou", "Zhiyi Huang", "Kaifeng Tan", "Rongchang Lu", "Fei Richard Yu"], "title": "RWKV-X: A Linear Complexity Hybrid Language Model", "categories": ["cs.CL"], "comment": "12 pages, typos corrected", "summary": "In this paper, we introduce RWKV-X, a novel hybrid architecture that combines\nthe efficiency of RWKV for short-range modeling with a sparse attention\nmechanism designed to capture long-range context. Unlike previous hybrid\napproaches that rely on full attention layers and retain quadratic complexity,\nRWKV-X achieves linear-time complexity in training and constant-time complexity\nin inference decoding. We demonstrate that RWKV-X, when continually pretrained\non 64K-token sequences, achieves near-perfect accuracy on the 64K passkey\nretrieval benchmark. It consistently outperforms prior RWKV-7 models on\nlong-context benchmarks, while maintaining strong performance on short-context\ntasks. These results highlight RWKV-X as a scalable and efficient backbone for\ngeneral-purpose language modeling, capable of decoding sequences up to 1\nmillion tokens with stable speed and memory usage. To facilitate further\nresearch and analysis, we have made the checkpoints and the associated code\npublicly accessible at: https://github.com/howard-hou/RWKV-X.", "AI": {"tldr": "RWKV-X is a hybrid architecture combining RWKV's efficiency for short-range modeling with a sparse attention mechanism for long-range context, achieving linear-time training and constant-time inference.", "motivation": "To address the inefficiency of full attention layers in hybrid models while capturing long-range context.", "method": "Combines RWKV for short-range modeling with a sparse attention mechanism, enabling linear-time training and constant-time inference.", "result": "Achieves near-perfect accuracy on 64K-token sequences, outperforms RWKV-7 on long-context tasks, and maintains strong short-context performance.", "conclusion": "RWKV-X is a scalable, efficient backbone for general-purpose language modeling, capable of handling sequences up to 1 million tokens."}}
{"id": "2505.06136", "pdf": "https://arxiv.org/pdf/2505.06136", "abs": "https://arxiv.org/abs/2505.06136", "authors": ["Yifeng Zhu"], "title": "Efficient Sensorimotor Learning for Open-world Robot Manipulation", "categories": ["cs.RO", "cs.AI"], "comment": "Ph.D. Dissertation", "summary": "This dissertation considers Open-world Robot Manipulation, a manipulation\nproblem where a robot must generalize or quickly adapt to new objects, scenes,\nor tasks for which it has not been pre-programmed or pre-trained. This\ndissertation tackles the problem using a methodology of efficient sensorimotor\nlearning. The key to enabling efficient sensorimotor learning lies in\nleveraging regular patterns that exist in limited amounts of demonstration\ndata. These patterns, referred to as ``regularity,'' enable the data-efficient\nlearning of generalizable manipulation skills. This dissertation offers a new\nperspective on formulating manipulation problems through the lens of\nregularity. Building upon this notion, we introduce three major contributions.\nFirst, we introduce methods that endow robots with object-centric priors,\nallowing them to learn generalizable, closed-loop sensorimotor policies from a\nsmall number of teleoperation demonstrations. Second, we introduce methods that\nconstitute robots' spatial understanding, unlocking their ability to imitate\nmanipulation skills from in-the-wild video observations. Last but not least, we\nintroduce methods that enable robots to identify reusable skills from their\npast experiences, resulting in systems that can continually imitate multiple\ntasks in a sequential manner. Altogether, the contributions of this\ndissertation help lay the groundwork for building general-purpose personal\nrobots that can quickly adapt to new situations or tasks with low-cost data\ncollection and interact easily with humans. By enabling robots to learn and\ngeneralize from limited data, this dissertation takes a step toward realizing\nthe vision of intelligent robotic assistants that can be seamlessly integrated\ninto everyday scenarios.", "AI": {"tldr": "The dissertation focuses on Open-world Robot Manipulation, proposing efficient sensorimotor learning methods to generalize or adapt to new objects, scenes, or tasks with minimal data.", "motivation": "To enable robots to quickly adapt to new situations without extensive pre-training or programming, making them more versatile and easier to integrate into everyday scenarios.", "method": "Leverages regularity in limited demonstration data for efficient learning. Introduces object-centric priors, spatial understanding from video, and reusable skill identification from past experiences.", "result": "Develops systems capable of closed-loop sensorimotor policies, imitation from video, and sequential task imitation, reducing data collection costs.", "conclusion": "Advances the groundwork for general-purpose robots that adapt quickly and interact seamlessly with humans, moving toward intelligent robotic assistants."}}
{"id": "2505.06038", "pdf": "https://arxiv.org/pdf/2505.06038", "abs": "https://arxiv.org/abs/2505.06038", "authors": ["Heng Li", "Xiangping Wu", "Qingcai Chen"], "title": "Document Image Rectification Bases on Self-Adaptive Multitask Fusion", "categories": ["cs.CV"], "comment": null, "summary": "Deformed document image rectification is essential for real-world document\nunderstanding tasks, such as layout analysis and text recognition. However,\ncurrent multi-task methods -- such as background removal, 3D coordinate\nprediction, and text line segmentation -- often overlook the complementary\nfeatures between tasks and their interactions. To address this gap, we propose\na self-adaptive learnable multi-task fusion rectification network named\nSalmRec. This network incorporates an inter-task feature aggregation module\nthat adaptively improves the perception of geometric distortions, enhances\nfeature complementarity, and reduces negative interference. We also introduce a\ngating mechanism to balance features both within global tasks and between local\ntasks effectively. Experimental results on two English benchmarks (DIR300 and\nDocUNet) and one Chinese benchmark (DocReal) demonstrate that our method\nsignificantly improves rectification performance. Ablation studies further\nhighlight the positive impact of different tasks on dewarping and the\neffectiveness of our proposed module.", "AI": {"tldr": "A novel multi-task fusion network (SalmRec) improves document image rectification by leveraging inter-task feature aggregation and a gating mechanism, outperforming benchmarks.", "motivation": "Current multi-task methods for document rectification fail to utilize complementary features and interactions between tasks, limiting performance.", "method": "Proposes SalmRec, a network with inter-task feature aggregation and a gating mechanism to balance global and local task features.", "result": "Significant performance improvements on English (DIR300, DocUNet) and Chinese (DocReal) benchmarks, validated by ablation studies.", "conclusion": "SalmRec effectively enhances geometric distortion perception and feature complementarity, advancing document rectification."}}
{"id": "2505.06169", "pdf": "https://arxiv.org/pdf/2505.06169", "abs": "https://arxiv.org/abs/2505.06169", "authors": ["Egor Bakaev", "Florestan Brunck", "Christoph Hertrich", "Daniel Reichman", "Amir Yehudayoff"], "title": "On the Depth of Monotone ReLU Neural Networks and ICNNs", "categories": ["cs.LG", "cs.DM", "cs.NE", "math.CO"], "comment": "27 pages, 17 figures", "summary": "We study two models of ReLU neural networks: monotone networks (ReLU$^+$) and\ninput convex neural networks (ICNN). Our focus is on expressivity, mostly in\nterms of depth, and we prove the following lower bounds. For the maximum\nfunction MAX$_n$ computing the maximum of $n$ real numbers, we show that\nReLU$^+$ networks cannot compute MAX$_n$, or even approximate it. We prove a\nsharp $n$ lower bound on the ICNN depth complexity of MAX$_n$. We also prove\ndepth separations between ReLU networks and ICNNs; for every $k$, there is a\ndepth-2 ReLU network of size $O(k^2)$ that cannot be simulated by a depth-$k$\nICNN. The proofs are based on deep connections between neural networks and\npolyhedral geometry, and also use isoperimetric properties of triangulations.", "AI": {"tldr": "The paper explores the expressivity of ReLU$^+$ and ICNN models, proving lower bounds on depth for computing the maximum function and showing depth separations between ReLU networks and ICNNs.", "motivation": "To understand the limitations and capabilities of monotone networks (ReLU$^+) and input convex neural networks (ICNNs) in terms of depth and expressivity.", "method": "The study uses proofs based on polyhedral geometry and isoperimetric properties of triangulations to analyze the depth complexity and separations.", "result": "ReLU$^+$ networks cannot compute or approximate MAX$_n$, and a sharp $n$ lower bound is proven for ICNN depth complexity of MAX$_n$. Depth separations between ReLU networks and ICNNs are also established.", "conclusion": "The findings highlight fundamental differences in expressivity and depth requirements between ReLU$^+$ networks and ICNNs, with implications for their practical applications."}}
{"id": "2505.00679", "pdf": "https://arxiv.org/pdf/2505.00679", "abs": "https://arxiv.org/abs/2505.00679", "authors": ["Xinchen Yang", "Marine Carpuat"], "title": "Steering Large Language Models with Register Analysis for Arbitrary Style Transfer", "categories": ["cs.CL"], "comment": null, "summary": "Large Language Models (LLMs) have demonstrated strong capabilities in\nrewriting text across various styles. However, effectively leveraging this\nability for example-based arbitrary style transfer, where an input text is\nrewritten to match the style of a given exemplar, remains an open challenge. A\nkey question is how to describe the style of the exemplar to guide LLMs toward\nhigh-quality rewrites. In this work, we propose a prompting method based on\nregister analysis to guide LLMs to perform this task. Empirical evaluations\nacross multiple style transfer tasks show that our prompting approach enhances\nstyle transfer strength while preserving meaning more effectively than existing\nprompting strategies.", "AI": {"tldr": "A prompting method using register analysis improves LLM-based style transfer, outperforming existing strategies in preserving meaning and enhancing style.", "motivation": "The challenge of guiding LLMs for high-quality example-based arbitrary style transfer, particularly in describing exemplar styles.", "method": "Proposes a prompting method based on register analysis to guide LLMs in style transfer tasks.", "result": "Empirical evaluations show the method enhances style transfer strength and preserves meaning better than existing strategies.", "conclusion": "The proposed prompting approach effectively addresses the challenge of style transfer in LLMs."}}
{"id": "2505.06152", "pdf": "https://arxiv.org/pdf/2505.06152", "abs": "https://arxiv.org/abs/2505.06152", "authors": ["Wenqi Zeng", "Yuqi Sun", "Chenxi Ma", "Weimin Tan", "Bo Yan"], "title": "MM-Skin: Enhancing Dermatology Vision-Language Model with an Image-Text Dataset Derived from Textbooks", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Medical vision-language models (VLMs) have shown promise as clinical\nassistants across various medical fields. However, specialized dermatology VLM\ncapable of delivering professional and detailed diagnostic analysis remains\nunderdeveloped, primarily due to less specialized text descriptions in current\ndermatology multimodal datasets. To address this issue, we propose MM-Skin, the\nfirst large-scale multimodal dermatology dataset that encompasses 3 imaging\nmodalities, including clinical, dermoscopic, and pathological and nearly 10k\nhigh-quality image-text pairs collected from professional textbooks. In\naddition, we generate over 27k diverse, instruction-following vision question\nanswering (VQA) samples (9 times the size of current largest dermatology VQA\ndataset). Leveraging public datasets and MM-Skin, we developed SkinVL, a\ndermatology-specific VLM designed for precise and nuanced skin disease\ninterpretation. Comprehensive benchmark evaluations of SkinVL on VQA,\nsupervised fine-tuning (SFT) and zero-shot classification tasks across 8\ndatasets, reveal its exceptional performance for skin diseases in comparison to\nboth general and medical VLM models. The introduction of MM-Skin and SkinVL\noffers a meaningful contribution to advancing the development of clinical\ndermatology VLM assistants. MM-Skin is available at\nhttps://github.com/ZwQ803/MM-Skin", "AI": {"tldr": "The paper introduces MM-Skin, a large-scale multimodal dermatology dataset, and SkinVL, a dermatology-specific vision-language model (VLM), to address the lack of specialized dermatology VLMs. SkinVL outperforms general and medical VLMs in various tasks.", "motivation": "Current dermatology VLMs lack specialized text descriptions in datasets, limiting their diagnostic capabilities.", "method": "Developed MM-Skin with 10k image-text pairs and 27k VQA samples, then trained SkinVL using this dataset.", "result": "SkinVL excels in VQA, supervised fine-tuning, and zero-shot classification across 8 datasets.", "conclusion": "MM-Skin and SkinVL significantly advance dermatology VLMs, offering improved diagnostic tools."}}
{"id": "2505.06055", "pdf": "https://arxiv.org/pdf/2505.06055", "abs": "https://arxiv.org/abs/2505.06055", "authors": ["Dongqian Guo", "Wencheng Han", "Pang Lyu", "Yuxi Zhou", "Jianbing Shen"], "title": "Towards Better Cephalometric Landmark Detection with Diffusion Data Generation", "categories": ["cs.CV"], "comment": null, "summary": "Cephalometric landmark detection is essential for orthodontic diagnostics and\ntreatment planning. Nevertheless, the scarcity of samples in data collection\nand the extensive effort required for manual annotation have significantly\nimpeded the availability of diverse datasets. This limitation has restricted\nthe effectiveness of deep learning-based detection methods, particularly those\nbased on large-scale vision models. To address these challenges, we have\ndeveloped an innovative data generation method capable of producing diverse\ncephalometric X-ray images along with corresponding annotations without human\nintervention. To achieve this, our approach initiates by constructing new\ncephalometric landmark annotations using anatomical priors. Then, we employ a\ndiffusion-based generator to create realistic X-ray images that correspond\nclosely with these annotations. To achieve precise control in producing samples\nwith different attributes, we introduce a novel prompt cephalometric X-ray\nimage dataset. This dataset includes real cephalometric X-ray images and\ndetailed medical text prompts describing the images. By leveraging these\ndetailed prompts, our method improves the generation process to control\ndifferent styles and attributes. Facilitated by the large, diverse generated\ndata, we introduce large-scale vision detection models into the cephalometric\nlandmark detection task to improve accuracy. Experimental results demonstrate\nthat training with the generated data substantially enhances the performance.\nCompared to methods without using the generated data, our approach improves the\nSuccess Detection Rate (SDR) by 6.5%, attaining a notable 82.2%. All code and\ndata are available at: https://um-lab.github.io/cepha-generation", "AI": {"tldr": "A method for generating diverse cephalometric X-ray images and annotations without human intervention improves deep learning-based landmark detection.", "motivation": "Addressing the scarcity of annotated cephalometric datasets, which limits deep learning effectiveness.", "method": "Constructs annotations using anatomical priors, uses a diffusion-based generator for realistic images, and employs a prompt dataset for control.", "result": "Training with generated data boosts Success Detection Rate (SDR) by 6.5%, achieving 82.2%.", "conclusion": "The approach enhances cephalometric landmark detection accuracy by leveraging synthetic data."}}
{"id": "2505.06178", "pdf": "https://arxiv.org/pdf/2505.06178", "abs": "https://arxiv.org/abs/2505.06178", "authors": ["Linjiang Cao", "Maonan Wang", "Xi Xiong"], "title": "A Large Language Model-Enhanced Q-learning for Capacitated Vehicle Routing Problem with Time Windows", "categories": ["cs.LG"], "comment": null, "summary": "The Capacitated Vehicle Routing Problem with Time Windows (CVRPTW) is a\nclassic NP-hard combinatorial optimization problem widely applied in logistics\ndistribution and transportation management. Its complexity stems from the\nconstraints of vehicle capacity and time windows, which pose significant\nchallenges to traditional approaches. Advances in Large Language Models (LLMs)\nprovide new possibilities for finding approximate solutions to CVRPTW. This\npaper proposes a novel LLM-enhanced Q-learning framework to address the CVRPTW\nwith real-time emergency constraints. Our solution introduces an adaptive\ntwo-phase training mechanism that transitions from the LLM-guided exploration\nphase to the autonomous optimization phase of Q-network. To ensure reliability,\nwe design a three-tier self-correction mechanism based on the Chain-of-Thought\n(CoT) for LLMs: syntactic validation, semantic verification, and physical\nconstraint enforcement. In addition, we also prioritized replay of the\nexperience generated by LLMs to amplify the regulatory role of LLMs in the\narchitecture. Experimental results demonstrate that our framework achieves a\n7.3\\% average reduction in cost compared to traditional Q-learning, with fewer\ntraining steps required for convergence.", "AI": {"tldr": "A novel LLM-enhanced Q-learning framework is proposed for solving CVRPTW with real-time emergency constraints, achieving a 7.3% cost reduction over traditional Q-learning.", "motivation": "The complexity of CVRPTW due to vehicle capacity and time window constraints, combined with the potential of LLMs, motivates a new approach.", "method": "An adaptive two-phase training mechanism (LLM-guided exploration to autonomous Q-network optimization) with a three-tier self-correction (syntactic, semantic, physical) and prioritized replay of LLM-generated experiences.", "result": "7.3% average cost reduction compared to traditional Q-learning, with faster convergence.", "conclusion": "The LLM-enhanced Q-learning framework effectively addresses CVRPTW, demonstrating superior performance and efficiency."}}
{"id": "2505.02410", "pdf": "https://arxiv.org/pdf/2505.02410", "abs": "https://arxiv.org/abs/2505.02410", "authors": ["Krzysztof Ociepa", "\u0141ukasz Flis", "Krzysztof Wr\u00f3bel", "Adrian Gwo\u017adziej", "Remigiusz Kinas"], "title": "Bielik 11B v2 Technical Report", "categories": ["cs.CL", "cs.AI", "68T50", "I.2.7"], "comment": null, "summary": "We present Bielik 11B v2, a state-of-the-art language model optimized for\nPolish text processing. Built on the Mistral 7B v0.2 architecture and scaled to\n11B parameters using depth up-scaling, this model demonstrates exceptional\nperformance across Polish language benchmarks while maintaining strong\ncross-lingual capabilities. We introduce two key technical innovations:\nWeighted Instruction Cross-Entropy Loss, which optimizes learning across\ndiverse instruction types by assigning quality-based weights to training\nexamples, and Adaptive Learning Rate, which dynamically adjusts based on\ncontext length. Comprehensive evaluation across multiple benchmarks\ndemonstrates that Bielik 11B v2 outperforms many larger models, including those\nwith 2-6 times more parameters, and significantly surpasses other specialized\nPolish language models on tasks ranging from linguistic understanding to\ncomplex reasoning. The model's parameter efficiency and extensive quantization\noptions enable deployment across various hardware configurations, advancing\nPolish language AI capabilities and establishing new benchmarks for\nresource-efficient language modeling in less-represented languages.", "AI": {"tldr": "Bielik 11B v2 is a Polish-optimized language model based on Mistral 7B, scaled to 11B parameters. It introduces Weighted Instruction Cross-Entropy Loss and Adaptive Learning Rate, outperforming larger models and setting new benchmarks for Polish AI.", "motivation": "To advance Polish language AI capabilities and improve performance in Polish text processing while maintaining cross-lingual efficiency.", "method": "Built on Mistral 7B v0.2, scaled to 11B parameters using depth up-scaling. Introduces Weighted Instruction Cross-Entropy Loss and Adaptive Learning Rate for optimized training.", "result": "Outperforms larger models (2-6x parameters) and surpasses specialized Polish models in linguistic and reasoning tasks. Efficient deployment via quantization.", "conclusion": "Bielik 11B v2 sets new benchmarks for Polish language AI and resource-efficient modeling in underrepresented languages."}}
{"id": "2505.06175", "pdf": "https://arxiv.org/pdf/2505.06175", "abs": "https://arxiv.org/abs/2505.06175", "authors": ["Zihang Song", "Matteo Zecchin", "Bipin Rajendran", "Osvaldo Simeone"], "title": "Turbo-ICL: In-Context Learning-Based Turbo Equalization", "categories": ["eess.SP", "cs.AI"], "comment": null, "summary": "This paper introduces a novel in-context learning (ICL) framework, inspired\nby large language models (LLMs), for soft-input soft-output channel\nequalization in coded multiple-input multiple-output (MIMO) systems. The\nproposed approach learns to infer posterior symbol distributions directly from\na prompt of pilot signals and decoder feedback. A key innovation is the use of\nprompt augmentation to incorporate extrinsic information from the decoder\noutput as additional context, enabling the ICL model to refine its symbol\nestimates iteratively across turbo decoding iterations. Two model variants,\nbased on Transformer and state-space architectures, are developed and\nevaluated. Extensive simulations demonstrate that, when traditional linear\nassumptions break down, e.g., in the presence of low-resolution quantization,\nICL equalizers consistently outperform conventional model-based baselines, even\nwhen the latter are provided with perfect channel state information. Results\nalso highlight the advantage of Transformer-based models under limited training\ndiversity, as well as the efficiency of state-space models in\nresource-constrained scenarios.", "AI": {"tldr": "A novel in-context learning (ICL) framework for MIMO systems outperforms traditional methods, especially in non-linear scenarios like low-resolution quantization.", "motivation": "To address limitations of traditional linear methods in MIMO systems by leveraging LLM-inspired ICL for better symbol distribution inference.", "method": "Uses prompt augmentation with decoder feedback, iteratively refining symbol estimates. Two variants: Transformer and state-space architectures.", "result": "ICL equalizers outperform conventional baselines, even with perfect channel info. Transformers excel with limited training; state-space models are resource-efficient.", "conclusion": "ICL framework is effective for MIMO equalization, with Transformer and state-space models offering complementary advantages."}}
{"id": "2505.06068", "pdf": "https://arxiv.org/pdf/2505.06068", "abs": "https://arxiv.org/abs/2505.06068", "authors": ["Kunpeng Qiu", "Zhiqiang Gao", "Zhiying Zhou", "Mingjie Sun", "Yongxin Guo"], "title": "Noise-Consistent Siamese-Diffusion for Medical Image Synthesis and Segmentation", "categories": ["cs.CV"], "comment": "Accepted by CVPR2025", "summary": "Deep learning has revolutionized medical image segmentation, yet its full\npotential remains constrained by the paucity of annotated datasets. While\ndiffusion models have emerged as a promising approach for generating synthetic\nimage-mask pairs to augment these datasets, they paradoxically suffer from the\nsame data scarcity challenges they aim to mitigate. Traditional mask-only\nmodels frequently yield low-fidelity images due to their inability to\nadequately capture morphological intricacies, which can critically compromise\nthe robustness and reliability of segmentation models. To alleviate this\nlimitation, we introduce Siamese-Diffusion, a novel dual-component model\ncomprising Mask-Diffusion and Image-Diffusion. During training, a Noise\nConsistency Loss is introduced between these components to enhance the\nmorphological fidelity of Mask-Diffusion in the parameter space. During\nsampling, only Mask-Diffusion is used, ensuring diversity and scalability.\nComprehensive experiments demonstrate the superiority of our method.\nSiamese-Diffusion boosts SANet's mDice and mIoU by 3.6% and 4.4% on the Polyps,\nwhile UNet improves by 1.52% and 1.64% on the ISIC2018. Code is available at\nGitHub.", "AI": {"tldr": "Siamese-Diffusion, a dual-component model, enhances medical image segmentation by improving synthetic image-mask pair generation, outperforming traditional methods.", "motivation": "Addressing the scarcity of annotated datasets in medical image segmentation, which limits deep learning potential.", "method": "Introduces Siamese-Diffusion with Mask-Diffusion and Image-Diffusion components, using Noise Consistency Loss for training and Mask-Diffusion for sampling.", "result": "Boosts SANet's mDice and mIoU by 3.6% and 4.4% on Polyps, and UNet by 1.52% and 1.64% on ISIC2018.", "conclusion": "Siamese-Diffusion effectively improves segmentation model performance by enhancing synthetic data quality."}}
{"id": "2505.06185", "pdf": "https://arxiv.org/pdf/2505.06185", "abs": "https://arxiv.org/abs/2505.06185", "authors": ["Kodai Hirata", "Tsuyoshi Okita"], "title": "Brain Hematoma Marker Recognition Using Multitask Learning: SwinTransformer and Swin-Unet", "categories": ["cs.LG", "cs.CV"], "comment": "8 pages,4 figures", "summary": "This paper proposes a method MTL-Swin-Unet which is multi-task learning using\ntransformers for classification and semantic segmentation. For\nspurious-correlation problems, this method allows us to enhance the image\nrepresentation with two other image representations: representation obtained by\nsemantic segmentation and representation obtained by image reconstruction. In\nour experiments, the proposed method outperformed in F-value measure than other\nclassifiers when the test data included slices from the same patient (no\ncovariate shift). Similarly, when the test data did not include slices from the\nsame patient (covariate shift setting), the proposed method outperformed in AUC\nmeasure.", "AI": {"tldr": "MTL-Swin-Unet uses multi-task learning with transformers for classification and semantic segmentation, improving performance in F-value and AUC measures under different test conditions.", "motivation": "Address spurious-correlation problems by enhancing image representation with semantic segmentation and reconstruction representations.", "method": "Multi-task learning with transformers, combining classification and semantic segmentation, and leveraging additional image representations.", "result": "Outperformed other classifiers in F-value (no covariate shift) and AUC (covariate shift).", "conclusion": "MTL-Swin-Unet effectively improves performance in both stable and shifted test scenarios."}}
{"id": "2505.02819", "pdf": "https://arxiv.org/pdf/2505.02819", "abs": "https://arxiv.org/abs/2505.02819", "authors": ["Dmitriy Shopkhoev", "Ammar Ali", "Magauiya Zhussip", "Valentin Malykh", "Stamatios Lefkimmiatis", "Nikos Komodakis", "Sergey Zagoruyko"], "title": "ReplaceMe: Network Simplification via Layer Pruning and Linear Transformations", "categories": ["cs.CL"], "comment": null, "summary": "We introduce ReplaceMe, a generalized training-free depth pruning method that\neffectively replaces transformer blocks with a linear operation, while\nmaintaining high performance for low compression ratios. In contrast to\nconventional pruning approaches that require additional training or\nfine-tuning, our approach requires only a small calibration dataset that is\nused to estimate a linear transformation to approximate the pruned blocks. This\nestimated linear mapping can be seamlessly merged with the remaining\ntransformer blocks, eliminating the need for any additional network parameters.\nOur experiments show that ReplaceMe consistently outperforms other\ntraining-free approaches and remains highly competitive with state-of-the-art\npruning methods that involve extensive retraining/fine-tuning and architectural\nmodifications. Applied to several large language models (LLMs), ReplaceMe\nachieves up to 25% pruning while retaining approximately 90% of the original\nmodel's performance on open benchmarks - without any training or healing steps,\nresulting in minimal computational overhead (see Fig.1). We provide an\nopen-source library implementing ReplaceMe alongside several state-of-the-art\ndepth pruning techniques, available at this repository.", "AI": {"tldr": "ReplaceMe is a training-free depth pruning method for transformers, replacing blocks with linear operations while maintaining performance. It outperforms other training-free methods and competes with retraining-based approaches.", "motivation": "To simplify pruning by eliminating the need for additional training or fine-tuning, reducing computational overhead.", "method": "Uses a small calibration dataset to estimate a linear transformation for approximating pruned blocks, merging it seamlessly with remaining blocks.", "result": "Achieves up to 25% pruning with ~90% performance retention on LLMs, outperforming training-free methods and competing with retraining-based ones.", "conclusion": "ReplaceMe offers an efficient, training-free pruning solution with minimal overhead, validated on large language models."}}
{"id": "2505.06218", "pdf": "https://arxiv.org/pdf/2505.06218", "abs": "https://arxiv.org/abs/2505.06218", "authors": ["Kwan-Yee Lin", "Stella X. Yu"], "title": "Let Humanoids Hike! Integrative Skill Development on Complex Trails", "categories": ["cs.RO", "cs.AI", "cs.CV"], "comment": "CVPR 2025. Project page:\n  https://lego-h-humanoidrobothiking.github.io/", "summary": "Hiking on complex trails demands balance, agility, and adaptive\ndecision-making over unpredictable terrain. Current humanoid research remains\nfragmented and inadequate for hiking: locomotion focuses on motor skills\nwithout long-term goals or situational awareness, while semantic navigation\noverlooks real-world embodiment and local terrain variability. We propose\ntraining humanoids to hike on complex trails, driving integrative skill\ndevelopment across visual perception, decision making, and motor execution. We\ndevelop a learning framework, LEGO-H, that enables a vision-equipped humanoid\nrobot to hike complex trails autonomously. We introduce two technical\ninnovations: 1) A temporal vision transformer variant - tailored into\nHierarchical Reinforcement Learning framework - anticipates future local goals\nto guide movement, seamlessly integrating locomotion with goal-directed\nnavigation. 2) Latent representations of joint movement patterns, combined with\nhierarchical metric learning - enhance Privileged Learning scheme - enable\nsmooth policy transfer from privileged training to onboard execution. These\ncomponents allow LEGO-H to handle diverse physical and environmental challenges\nwithout relying on predefined motion patterns. Experiments across varied\nsimulated trails and robot morphologies highlight LEGO-H's versatility and\nrobustness, positioning hiking as a compelling testbed for embodied autonomy\nand LEGO-H as a baseline for future humanoid development.", "AI": {"tldr": "LEGO-H is a learning framework for humanoid robots to hike complex trails, integrating vision, decision-making, and motor skills through hierarchical reinforcement learning and privileged learning.", "motivation": "Current humanoid research lacks integration of long-term goals and situational awareness for hiking, focusing either on motor skills or navigation without real-world embodiment.", "method": "LEGO-H uses a temporal vision transformer for goal anticipation and latent representations of joint movements with hierarchical metric learning for policy transfer.", "result": "Experiments show LEGO-H handles diverse trails and robot morphologies, demonstrating versatility and robustness.", "conclusion": "Hiking is a promising testbed for embodied autonomy, with LEGO-H serving as a baseline for future humanoid development."}}
{"id": "2505.06113", "pdf": "https://arxiv.org/pdf/2505.06113", "abs": "https://arxiv.org/abs/2505.06113", "authors": ["Anupkumar Bochare"], "title": "Camera-Only Bird's Eye View Perception: A Neural Approach to LiDAR-Free Environmental Mapping for Autonomous Vehicles", "categories": ["cs.CV"], "comment": null, "summary": "Autonomous vehicle perception systems have traditionally relied on costly\nLiDAR sensors to generate precise environmental representations. In this paper,\nwe propose a camera-only perception framework that produces Bird's Eye View\n(BEV) maps by extending the Lift-Splat-Shoot architecture. Our method combines\nYOLOv11-based object detection with DepthAnythingV2 monocular depth estimation\nacross multi-camera inputs to achieve comprehensive 360-degree scene\nunderstanding. We evaluate our approach on the OpenLane-V2 and NuScenes\ndatasets, achieving up to 85% road segmentation accuracy and 85-90% vehicle\ndetection rates when compared against LiDAR ground truth, with average\npositional errors limited to 1.2 meters. These results highlight the potential\nof deep learning to extract rich spatial information using only camera inputs,\nenabling cost-efficient autonomous navigation without sacrificing accuracy.", "AI": {"tldr": "A camera-only perception framework achieves LiDAR-like accuracy for autonomous vehicles using BEV maps, YOLOv11, and DepthAnythingV2, with 85-90% detection rates and 1.2m positional errors.", "motivation": "Reduce reliance on expensive LiDAR sensors by leveraging deep learning for accurate camera-only perception.", "method": "Extends Lift-Splat-Shoot with YOLOv11 detection and DepthAnythingV2 depth estimation across multi-camera inputs.", "result": "85% road segmentation accuracy, 85-90% vehicle detection rates, and 1.2m positional errors on OpenLane-V2 and NuScenes datasets.", "conclusion": "Deep learning enables cost-efficient, accurate autonomous navigation using only cameras."}}
{"id": "2505.06203", "pdf": "https://arxiv.org/pdf/2505.06203", "abs": "https://arxiv.org/abs/2505.06203", "authors": ["Hiroki Hasegawa", "Yukihiko Okada"], "title": "Auto Tensor Singular Value Thresholding: A Non-Iterative and Rank-Free Framework for Tensor Denoising", "categories": ["cs.LG"], "comment": "16 pages, 4 figures", "summary": "In modern data-driven tasks such as classification, optimization, and\nforecasting, mitigating the effects of intrinsic noise is crucial for improving\npredictive accuracy. While numerous denoising techniques have been developed,\nthe rising dimensionality of real-world datasets limits conventional\nmatrix-based methods in preserving data structure and accuracy. This challenge\nhas led to increasing interest in tensor-based approaches, which naturally\ncapture multi-way data relationships. However, classical tensor decomposition\nmethods (e.g., HOSVD, HOOI) typically require pre-specified ranks and iterative\noptimization, making them computationally expensive and less practical. In this\nwork, we propose a novel low-rank approximation method for tensor data that\navoids these limitations. Our approach applies statistically grounded singular\nvalue thresholding to mode-wise matricizations, enabling automatic extraction\nof significant components without requiring prior rank specification or\niterative refinement. Experiments on synthetic and real-world tensors show that\nour method consistently outperforms existing techniques in terms of estimation\naccuracy and computational efficiency, especially in noisy high-dimensional\nsettings.", "AI": {"tldr": "A novel tensor-based denoising method using singular value thresholding avoids pre-specified ranks and iterative optimization, outperforming existing techniques in accuracy and efficiency.", "motivation": "Mitigating noise in high-dimensional data is challenging for conventional matrix-based methods, prompting interest in tensor-based approaches.", "method": "Proposes a low-rank tensor approximation using singular value thresholding on mode-wise matricizations, eliminating the need for rank specification or iterative refinement.", "result": "Outperforms existing methods in accuracy and computational efficiency, especially in noisy, high-dimensional settings.", "conclusion": "The method offers a practical and efficient solution for tensor denoising, addressing limitations of classical approaches."}}
{"id": "2505.02847", "pdf": "https://arxiv.org/pdf/2505.02847", "abs": "https://arxiv.org/abs/2505.02847", "authors": ["Bang Zhang", "Ruotian Ma", "Qingxuan Jiang", "Peisong Wang", "Jiaqi Chen", "Zheng Xie", "Xingyu Chen", "Yue Wang", "Fanghua Ye", "Jian Li", "Yifan Yang", "Zhaopeng Tu", "Xiaolong Li"], "title": "Sentient Agent as a Judge: Evaluating Higher-Order Social Cognition in Large Language Models", "categories": ["cs.CL", "cs.AI", "cs.CY"], "comment": "code: https://github.com/Tencent/digitalhuman/tree/main/SAGE", "summary": "Assessing how well a large language model (LLM) understands human, rather\nthan merely text, remains an open challenge. To bridge the gap, we introduce\nSentient Agent as a Judge (SAGE), an automated evaluation framework that\nmeasures an LLM's higher-order social cognition. SAGE instantiates a Sentient\nAgent that simulates human-like emotional changes and inner thoughts during\ninteraction, providing a more realistic evaluation of the tested model in\nmulti-turn conversations. At every turn, the agent reasons about (i) how its\nemotion changes, (ii) how it feels, and (iii) how it should reply, yielding a\nnumerical emotion trajectory and interpretable inner thoughts. Experiments on\n100 supportive-dialogue scenarios show that the final Sentient emotion score\ncorrelates strongly with Barrett-Lennard Relationship Inventory (BLRI) ratings\nand utterance-level empathy metrics, validating psychological fidelity. We also\nbuild a public Sentient Leaderboard covering 18 commercial and open-source\nmodels that uncovers substantial gaps (up to 4x) between frontier systems\n(GPT-4o-Latest, Gemini2.5-Pro) and earlier baselines, gaps not reflected in\nconventional leaderboards (e.g., Arena). SAGE thus provides a principled,\nscalable and interpretable tool for tracking progress toward genuinely\nempathetic and socially adept language agents.", "AI": {"tldr": "SAGE is an automated framework to evaluate LLMs' social cognition by simulating human-like emotions and thoughts, revealing gaps in empathy and social skills not captured by traditional metrics.", "motivation": "To address the challenge of assessing LLMs' human-like understanding beyond text, focusing on social cognition and empathy.", "method": "SAGE uses a Sentient Agent to simulate emotional changes and inner thoughts during multi-turn conversations, generating emotion trajectories and interpretable reasoning.", "result": "SAGE's emotion scores correlate strongly with psychological metrics (BLRI, empathy), and it reveals significant gaps in social skills among LLMs (up to 4x).", "conclusion": "SAGE offers a scalable, interpretable tool for advancing empathetic and socially adept language agents, beyond conventional evaluation methods."}}
{"id": "2301.04709", "pdf": "https://arxiv.org/pdf/2301.04709", "abs": "https://arxiv.org/abs/2301.04709", "authors": ["Atticus Geiger", "Duligur Ibeling", "Amir Zur", "Maheep Chaudhary", "Sonakshi Chauhan", "Jing Huang", "Aryaman Arora", "Zhengxuan Wu", "Noah Goodman", "Christopher Potts", "Thomas Icard"], "title": "Causal Abstraction: A Theoretical Foundation for Mechanistic Interpretability", "categories": ["cs.AI"], "comment": null, "summary": "Causal abstraction provides a theoretical foundation for mechanistic\ninterpretability, the field concerned with providing intelligible algorithms\nthat are faithful simplifications of the known, but opaque low-level details of\nblack box AI models. Our contributions are (1) generalizing the theory of\ncausal abstraction from mechanism replacement (i.e., hard and soft\ninterventions) to arbitrary mechanism transformation (i.e., functionals from\nold mechanisms to new mechanisms), (2) providing a flexible, yet precise\nformalization for the core concepts of polysemantic neurons, the linear\nrepresentation hypothesis, modular features, and graded faithfulness, and (3)\nunifying a variety of mechanistic interpretability methods in the common\nlanguage of causal abstraction, namely, activation and path patching, causal\nmediation analysis, causal scrubbing, causal tracing, circuit analysis, concept\nerasure, sparse autoencoders, differential binary masking, distributed\nalignment search, and steering.", "AI": {"tldr": "The paper generalizes causal abstraction theory, formalizes key mechanistic interpretability concepts, and unifies various interpretability methods under causal abstraction.", "motivation": "To provide a theoretical foundation for mechanistic interpretability by extending causal abstraction theory and unifying existing methods.", "method": "Generalizes causal abstraction to arbitrary mechanism transformations, formalizes core concepts, and unifies interpretability methods.", "result": "A flexible framework for mechanistic interpretability, integrating diverse methods like activation patching and causal mediation analysis.", "conclusion": "Causal abstraction offers a unified and precise approach to mechanistic interpretability, enhancing understanding of AI models."}}
{"id": "2505.06117", "pdf": "https://arxiv.org/pdf/2505.06117", "abs": "https://arxiv.org/abs/2505.06117", "authors": ["Dongying Li", "Binyi Su", "Hua Zhang", "Yong Li", "Haiyong Chen"], "title": "Photovoltaic Defect Image Generator with Boundary Alignment Smoothing Constraint for Domain Shift Mitigation", "categories": ["cs.CV"], "comment": null, "summary": "Accurate defect detection of photovoltaic (PV) cells is critical for ensuring\nquality and efficiency in intelligent PV manufacturing systems. However, the\nscarcity of rich defect data poses substantial challenges for effective model\ntraining. While existing methods have explored generative models to augment\ndatasets, they often suffer from instability, limited diversity, and domain\nshifts. To address these issues, we propose PDIG, a Photovoltaic Defect Image\nGenerator based on Stable Diffusion (SD). PDIG leverages the strong priors\nlearned from large-scale datasets to enhance generation quality under limited\ndata. Specifically, we introduce a Semantic Concept Embedding (SCE) module that\nincorporates text-conditioned priors to capture the relational concepts between\ndefect types and their appearances. To further enrich the domain distribution,\nwe design a Lightweight Industrial Style Adaptor (LISA), which injects\nindustrial defect characteristics into the SD model through cross-disentangled\nattention. At inference, we propose a Text-Image Dual-Space Constraints (TIDSC)\nmodule, enforcing the quality of generated images via positional consistency\nand spatial smoothing alignment. Extensive experiments demonstrate that PDIG\nachieves superior realism and diversity compared to state-of-the-art methods.\nSpecifically, our approach improves Frechet Inception Distance (FID) by 19.16\npoints over the second-best method and significantly enhances the performance\nof downstream defect detection tasks.", "AI": {"tldr": "PDIG, a Photovoltaic Defect Image Generator using Stable Diffusion, improves defect detection by generating high-quality, diverse images with limited data.", "motivation": "Accurate defect detection in PV cells is crucial, but limited defect data hinders model training. Existing methods lack stability and diversity.", "method": "PDIG uses Stable Diffusion with a Semantic Concept Embedding module, Lightweight Industrial Style Adaptor, and Text-Image Dual-Space Constraints for enhanced generation.", "result": "PDIG outperforms state-of-the-art methods, improving FID by 19.16 points and boosting downstream defect detection performance.", "conclusion": "PDIG effectively addresses data scarcity and quality issues in PV defect detection, offering superior realism and diversity."}}
{"id": "2505.06224", "pdf": "https://arxiv.org/pdf/2505.06224", "abs": "https://arxiv.org/abs/2505.06224", "authors": ["Christos Plachouras", "Julien Guinot", "George Fazekas", "Elio Quinton", "Emmanouil Benetos", "Johan Pauwels"], "title": "Towards a Unified Representation Evaluation Framework Beyond Downstream Tasks", "categories": ["cs.LG"], "comment": "Accepted at IJCNN 2025", "summary": "Downstream probing has been the dominant method for evaluating model\nrepresentations, an important process given the increasing prominence of\nself-supervised learning and foundation models. However, downstream probing\nprimarily assesses the availability of task-relevant information in the model's\nlatent space, overlooking attributes such as equivariance, invariance, and\ndisentanglement, which contribute to the interpretability, adaptability, and\nutility of representations in real-world applications. While some attempts have\nbeen made to measure these qualities in representations, no unified evaluation\nframework with modular, generalizable, and interpretable metrics exists.\n  In this paper, we argue for the importance of representation evaluation\nbeyond downstream probing. We introduce a standardized protocol to quantify\ninformativeness, equivariance, invariance, and disentanglement of factors of\nvariation in model representations. We use it to evaluate representations from\na variety of models in the image and speech domains using different\narchitectures and pretraining approaches on identified controllable factors of\nvariation. We find that representations from models with similar downstream\nperformance can behave substantially differently with regard to these\nattributes. This hints that the respective mechanisms underlying their\ndownstream performance are functionally different, prompting new research\ndirections to understand and improve representations.", "AI": {"tldr": "The paper critiques downstream probing as incomplete for evaluating model representations and introduces a unified framework to assess attributes like equivariance, invariance, and disentanglement.", "motivation": "Current evaluation methods like downstream probing overlook key representation attributes, limiting understanding of model behavior and utility.", "method": "A standardized protocol is proposed to quantify informativeness, equivariance, invariance, and disentanglement in model representations, tested across image and speech domains.", "result": "Representations with similar downstream performance exhibit significant differences in these attributes, suggesting varied underlying mechanisms.", "conclusion": "The findings highlight the need for broader evaluation metrics and inspire research to enhance representation quality."}}
{"id": "2505.05026", "pdf": "https://arxiv.org/pdf/2505.05026", "abs": "https://arxiv.org/abs/2505.05026", "authors": ["Jaehyun Jeon", "Jang Han Yoon", "Min Soo Kim", "Sumin Shim", "Yejin Choi", "Hanbin Kim", "Youngjae Yu"], "title": "G-FOCUS: Towards a Robust Method for Assessing UI Design Persuasiveness", "categories": ["cs.CL", "cs.LG"], "comment": "31 pages, 17 figures", "summary": "Evaluating user interface (UI) design effectiveness extends beyond aesthetics\nto influencing user behavior, a principle central to Design Persuasiveness. A/B\ntesting is the predominant method for determining which UI variations drive\nhigher user engagement, but it is costly and time-consuming. While recent\nVision-Language Models (VLMs) can process automated UI analysis, current\napproaches focus on isolated design attributes rather than comparative\npersuasiveness-the key factor in optimizing user interactions. To address this,\nwe introduce WiserUI-Bench, a benchmark designed for Pairwise UI Design\nPersuasiveness Assessment task, featuring 300 real-world UI image pairs labeled\nwith A/B test results and expert rationales. Additionally, we propose G-FOCUS,\na novel inference-time reasoning strategy that enhances VLM-based\npersuasiveness assessment by reducing position bias and improving evaluation\naccuracy. Experimental results show that G-FOCUS surpasses existing inference\nstrategies in consistency and accuracy for pairwise UI evaluation. Through\npromoting VLM-driven evaluation of UI persuasiveness, our work offers an\napproach to complement A/B testing, propelling progress in scalable UI\npreference modeling and design optimization. Code and data will be released\npublicly.", "AI": {"tldr": "WiserUI-Bench and G-FOCUS improve UI persuasiveness assessment using VLMs, reducing reliance on costly A/B testing.", "motivation": "Current UI evaluation methods like A/B testing are expensive and time-consuming, while VLMs lack focus on comparative persuasiveness.", "method": "Introduces WiserUI-Bench (300 UI pairs with A/B labels) and G-FOCUS, an inference-time strategy to enhance VLM accuracy.", "result": "G-FOCUS outperforms existing methods in consistency and accuracy for UI evaluation.", "conclusion": "The approach complements A/B testing, advancing scalable UI design optimization."}}
{"id": "2504.04430", "pdf": "https://arxiv.org/pdf/2504.04430", "abs": "https://arxiv.org/abs/2504.04430", "authors": ["Matej \u0160progar"], "title": "AGITB: A Signal-Level Benchmark for Evaluating Artificial General Intelligence", "categories": ["cs.AI"], "comment": "13 pages", "summary": "Despite remarkable progress in machine learning, current AI systems continue\nto fall short of true human-like intelligence. While Large Language Models\n(LLMs) excel in pattern recognition and response generation, they lack genuine\nunderstanding - an essential hallmark of Artificial General Intelligence (AGI).\nExisting AGI evaluation methods fail to offer a practical, gradual, and\ninformative metric. This paper introduces the Artificial General Intelligence\nTest Bed (AGITB), comprising twelve rigorous tests that form a\nsignal-processing-level foundation for the potential emergence of cognitive\ncapabilities. AGITB evaluates intelligence through a model's ability to predict\nbinary signals across time without relying on symbolic representations or\npretraining. Unlike high-level tests grounded in language or perception, AGITB\nfocuses on core computational invariants reflective of biological intelligence,\nsuch as determinism, sensitivity, and generalisation. The test bed assumes no\nprior bias, operates independently of semantic meaning, and ensures\nunsolvability through brute force or memorization. While humans pass AGITB by\ndesign, no current AI system has met its criteria, making AGITB a compelling\nbenchmark for guiding and recognizing progress toward AGI.", "AI": {"tldr": "The paper introduces AGITB, a test bed for evaluating AGI by focusing on core computational invariants, unlike existing methods.", "motivation": "Current AI lacks true understanding, and existing AGI evaluations are impractical. AGITB aims to provide a foundational, gradual metric.", "method": "AGITB comprises twelve tests evaluating binary signal prediction without symbolic representations or pretraining.", "result": "No current AI system meets AGITB's criteria, while humans pass by design.", "conclusion": "AGITB is a compelling benchmark for guiding progress toward AGI."}}
{"id": "2505.06133", "pdf": "https://arxiv.org/pdf/2505.06133", "abs": "https://arxiv.org/abs/2505.06133", "authors": ["Hongming Wang", "Yifeng Wu", "Huimin Huang", "Hongtao Wu", "Jia-Xuan Jiang", "Xiaodong Zhang", "Hao Zheng", "Xian Wu", "Yefeng Zheng", "Jinping Xu", "Jing Cheng"], "title": "BrainSegDMlF: A Dynamic Fusion-enhanced SAM for Brain Lesion Segmentation", "categories": ["cs.CV"], "comment": null, "summary": "The segmentation of substantial brain lesions is a significant and\nchallenging task in the field of medical image segmentation. Substantial brain\nlesions in brain imaging exhibit high heterogeneity, with indistinct boundaries\nbetween lesion regions and normal brain tissue. Small lesions in single slices\nare difficult to identify, making the accurate and reproducible segmentation of\nabnormal regions, as well as their feature description, highly complex.\nExisting methods have the following limitations: 1) They rely solely on\nsingle-modal information for learning, neglecting the multi-modal information\ncommonly used in diagnosis. This hampers the ability to comprehensively acquire\nbrain lesion information from multiple perspectives and prevents the effective\nintegration and utilization of multi-modal data inputs, thereby limiting a\nholistic understanding of lesions. 2) They are constrained by the amount of\ndata available, leading to low sensitivity to small lesions and difficulty in\ndetecting subtle pathological changes. 3) Current SAM-based models rely on\nexternal prompts, which cannot achieve automatic segmentation and, to some\nextent, affect diagnostic efficiency.To address these issues, we have developed\na large-scale fully automated segmentation model specifically designed for\nbrain lesion segmentation, named BrainSegDMLF. This model has the following\nfeatures: 1) Dynamic Modal Interactive Fusion (DMIF) module that processes and\nintegrates multi-modal data during the encoding process, providing the SAM\nencoder with more comprehensive modal information. 2) Layer-by-Layer Upsampling\nDecoder, enabling the model to extract rich low-level and high-level features\neven with limited data, thereby detecting the presence of small lesions. 3)\nAutomatic segmentation masks, allowing the model to generate lesion masks\nautomatically without requiring manual prompts.", "AI": {"tldr": "The paper introduces BrainSegDMLF, a fully automated model for brain lesion segmentation, addressing limitations of existing methods by integrating multi-modal data, improving small lesion detection, and enabling automatic segmentation.", "motivation": "Existing brain lesion segmentation methods lack multi-modal integration, struggle with small lesions, and rely on manual prompts, limiting diagnostic efficiency.", "method": "BrainSegDMLF uses a Dynamic Modal Interactive Fusion module for multi-modal data integration, a Layer-by-Layer Upsampling Decoder for feature extraction, and automatic mask generation.", "result": "The model achieves comprehensive lesion segmentation, better small lesion detection, and fully automated operation without manual prompts.", "conclusion": "BrainSegDMLF overcomes key limitations in brain lesion segmentation, offering improved accuracy and efficiency for medical diagnostics."}}
{"id": "2503.03137", "pdf": "https://arxiv.org/pdf/2503.03137", "abs": "https://arxiv.org/abs/2503.03137", "authors": ["Changliang Zhou", "Xi Lin", "Zhenkun Wang", "Qingfu Zhang"], "title": "L2R: Learning to Reduce Search Space for Generalizable Neural Routing Solver", "categories": ["cs.AI", "cs.LG", "cs.NE"], "comment": "23 pages, 10 figures", "summary": "Constructive neural combinatorial optimization (NCO) has attracted growing\nresearch attention due to its ability to solve complex routing problems without\nrelying on handcrafted rules. However, existing NCO methods face significant\nchallenges in generalizing to large-scale problems due to high computational\ncomplexity and inefficient capture of structural patterns. To address this\nissue, we propose a novel learning-based search space reduction method that\nadaptively selects a small set of promising candidate nodes at each step of the\nconstructive NCO process. Unlike traditional methods that rely on fixed\nheuristics, our selection model dynamically prioritizes nodes based on learned\npatterns, significantly reducing the search space while maintaining solution\nquality. Experimental results demonstrate that our method, trained solely on\n100-node instances from uniform distribution, generalizes remarkably well to\nlarge-scale Traveling Salesman Problem (TSP) and Capacitated Vehicle Routing\nProblem (CVRP) instances with up to 1 million nodes from the uniform\ndistribution and over 80K nodes from other distributions.", "AI": {"tldr": "A novel learning-based method reduces search space in neural combinatorial optimization, improving scalability for large-scale routing problems.", "motivation": "Existing NCO methods struggle with generalization to large-scale problems due to computational complexity and inefficient pattern capture.", "method": "Proposes a learning-based search space reduction method that dynamically selects promising nodes during the NCO process.", "result": "The method generalizes well to large-scale TSP and CVRP instances (up to 1M nodes) with high solution quality.", "conclusion": "The approach effectively addresses scalability and generalization challenges in NCO for routing problems."}}
{"id": "2505.05423", "pdf": "https://arxiv.org/pdf/2505.05423", "abs": "https://arxiv.org/abs/2505.05423", "authors": ["Ran Zhang", "Wei Zhao", "Lieve Macken", "Steffen Eger"], "title": "LiTransProQA: an LLM-based Literary Translation evaluation metric with Professional Question Answering", "categories": ["cs.CL", "cs.AI"], "comment": "Update WIP", "summary": "The impact of Large Language Models (LLMs) has extended into literary\ndomains. However, existing evaluation metrics prioritize mechanical accuracy\nover artistic expression and tend to overrate machine translation (MT) as being\nsuperior to experienced professional human translation. In the long run, this\nbias could result in a permanent decline in translation quality and cultural\nauthenticity. In response to the urgent need for a specialized literary\nevaluation metric, we introduce LiTransProQA, a novel, reference-free,\nLLM-based question-answering framework designed specifically for literary\ntranslation evaluation. LiTransProQA uniquely integrates insights from\nprofessional literary translators and researchers, focusing on critical\nelements in literary quality assessment such as literary devices, cultural\nunderstanding, and authorial voice. Our extensive evaluation shows that while\nliterary-finetuned XCOMET-XL yields marginal gains, LiTransProQA substantially\noutperforms current metrics, achieving up to 0.07 gain in correlation (ACC-EQ\nand Kendall's tau) and surpassing the best state-of-the-art metrics by over 15\npoints in adequacy assessments. Incorporating professional translator insights\nas weights further improves performance, highlighting the value of translator\ninputs. Notably, LiTransProQA approaches human-level evaluation performance\ncomparable to trained linguistic annotators. It demonstrates broad\napplicability to open-source models such as LLaMA3.3-70b and Qwen2.5-32b,\nindicating its potential as an accessible and training-free literary evaluation\nmetric and a valuable tool for evaluating texts that require local processing\ndue to copyright or ethical considerations.", "AI": {"tldr": "LiTransProQA is a reference-free, LLM-based framework for evaluating literary translation, outperforming existing metrics by integrating professional translator insights.", "motivation": "Current metrics favor mechanical accuracy over artistic expression, risking translation quality and cultural authenticity.", "method": "LiTransProQA uses a question-answering framework, incorporating professional insights on literary devices, cultural understanding, and authorial voice.", "result": "LiTransProQA surpasses state-of-the-art metrics, achieving up to 0.07 gain in correlation and 15+ points in adequacy assessments.", "conclusion": "LiTransProQA approaches human-level performance, is applicable to open-source models, and serves as a valuable tool for literary evaluation."}}
{"id": "2504.14298", "pdf": "https://arxiv.org/pdf/2504.14298", "abs": "https://arxiv.org/abs/2504.14298", "authors": ["Xiucheng Wang", "Zhongsheng Fang", "Nan Cheng", "Ruijin Sun", "Zan Li", "Xuemin", "Shen"], "title": "RadioDiff-Inverse: Diffusion Enhanced Bayesian Inverse Estimation for ISAC Radio Map Construction", "categories": ["cs.AI"], "comment": "13 pages, 7 figures", "summary": "Radio maps (RMs) are essential for environment-aware communication and\nsensing, providing location-specific wireless channel information. Existing RM\nconstruction methods often rely on precise environmental data and base station\n(BS) locations, which are not always available in dynamic or privacy-sensitive\nenvironments. While sparse measurement techniques reduce data collection, the\nimpact of noise in sparse data on RM accuracy is not well understood. This\npaper addresses these challenges by formulating RM construction as a Bayesian\ninverse problem under coarse environmental knowledge and noisy sparse\nmeasurements. Although maximum a posteriori (MAP) filtering offers an optimal\nsolution, it requires a precise prior distribution of the RM, which is\ntypically unavailable. To solve this, we propose RadioDiff-Inverse, a\ndiffusion-enhanced Bayesian inverse estimation framework that uses an\nunconditional generative diffusion model to learn the RM prior. This approach\nnot only reconstructs the spatial distribution of wireless channel features but\nalso enables environmental structure perception, such as building outlines, and\nlocation of BS just relay on pathloss, through integrated sensing and\ncommunication (ISAC). Remarkably, RadioDiff-Inverse is training-free,\nleveraging a pre-trained model from Imagenet without task-specific fine-tuning,\nwhich significantly reduces the training cost of using generative large model\nin wireless networks. Experimental results demonstrate that RadioDiff-Inverse\nachieves state-of-the-art performance in accuracy of RM construction and\nenvironmental reconstruction, and robustness against noisy sparse sampling.", "AI": {"tldr": "The paper proposes RadioDiff-Inverse, a diffusion-enhanced Bayesian framework for constructing radio maps (RMs) using noisy sparse measurements and coarse environmental data, achieving high accuracy and robustness without task-specific training.", "motivation": "Existing RM construction methods rely on precise data, which is often unavailable in dynamic or privacy-sensitive settings. The impact of noise in sparse measurements on RM accuracy is also unclear.", "method": "The paper formulates RM construction as a Bayesian inverse problem and introduces RadioDiff-Inverse, which uses an unconditional generative diffusion model to learn the RM prior without precise environmental data or task-specific training.", "result": "RadioDiff-Inverse achieves state-of-the-art accuracy in RM construction and environmental reconstruction, while being robust to noisy sparse sampling.", "conclusion": "The proposed framework offers a training-free, efficient solution for RM construction, leveraging pre-trained models and integrating sensing and communication for environmental perception."}}
{"id": "2505.06166", "pdf": "https://arxiv.org/pdf/2505.06166", "abs": "https://arxiv.org/abs/2505.06166", "authors": ["Radu Alexandru Rosu", "Keyu Wu", "Yao Feng", "Youyi Zheng", "Michael J. Black"], "title": "DiffLocks: Generating 3D Hair from a Single Image using Diffusion Models", "categories": ["cs.CV"], "comment": "Accepted to CVPR 2025", "summary": "We address the task of generating 3D hair geometry from a single image, which\nis challenging due to the diversity of hairstyles and the lack of paired\nimage-to-3D hair data. Previous methods are primarily trained on synthetic data\nand cope with the limited amount of such data by using low-dimensional\nintermediate representations, such as guide strands and scalp-level embeddings,\nthat require post-processing to decode, upsample, and add realism. These\napproaches fail to reconstruct detailed hair, struggle with curly hair, or are\nlimited to handling only a few hairstyles. To overcome these limitations, we\npropose DiffLocks, a novel framework that enables detailed reconstruction of a\nwide variety of hairstyles directly from a single image. First, we address the\nlack of 3D hair data by automating the creation of the largest synthetic hair\ndataset to date, containing 40K hairstyles. Second, we leverage the synthetic\nhair dataset to learn an image-conditioned diffusion-transfomer model that\ngenerates accurate 3D strands from a single frontal image. By using a\npretrained image backbone, our method generalizes to in-the-wild images despite\nbeing trained only on synthetic data. Our diffusion model predicts a scalp\ntexture map in which any point in the map contains the latent code for an\nindividual hair strand. These codes are directly decoded to 3D strands without\npost-processing techniques. Representing individual strands, instead of guide\nstrands, enables the transformer to model the detailed spatial structure of\ncomplex hairstyles. With this, DiffLocks can recover highly curled hair, like\nafro hairstyles, from a single image for the first time. Data and code is\navailable at https://radualexandru.github.io/difflocks/", "AI": {"tldr": "DiffLocks is a framework for detailed 3D hair reconstruction from a single image, overcoming limitations of previous methods by using a synthetic dataset and diffusion-transformer model.", "motivation": "The diversity of hairstyles and lack of paired image-to-3D hair data make the task challenging. Previous methods fail to reconstruct detailed or curly hair and are limited to few hairstyles.", "method": "DiffLocks automates the creation of a large synthetic hair dataset (40K hairstyles) and trains an image-conditioned diffusion-transformer model to generate 3D strands directly from a single image.", "result": "The method accurately reconstructs diverse hairstyles, including highly curled hair (e.g., afro), without post-processing, generalizing to in-the-wild images.", "conclusion": "DiffLocks advances 3D hair reconstruction by enabling detailed, diverse hairstyle generation from a single image, addressing key limitations of prior work."}}
{"id": "2505.05478", "pdf": "https://arxiv.org/pdf/2505.05478", "abs": "https://arxiv.org/abs/2505.05478", "authors": ["Yufei Zhang", "Andrew Sonta"], "title": "OccuEMBED: Occupancy Extraction Merged with Building Energy Disaggregation for Occupant-Responsive Operation at Scale", "categories": ["eess.SP", "cs.LG", "cs.SY", "eess.SY"], "comment": "33 pages, 16 figures", "summary": "Buildings account for a significant share of global energy consumption and\nemissions, making it critical to operate them efficiently. As electricity grids\nbecome more volatile with renewable penetration, buildings must provide\nflexibility to support grid stability. Building automation plays a key role in\nenhancing efficiency and flexibility via centralized operations, but it must\nprioritize occupant-centric strategies to balance energy and comfort targets.\nHowever, incorporating occupant information into large-scale, centralized\nbuilding operations remains challenging due to data limitations. We investigate\nthe potential of using whole-building smart meter data to infer both occupancy\nand system operations. Integrating these insights into data-driven building\nenergy analysis allows more occupant-centric energy-saving and flexibility at\nscale. Specifically, we propose OccuEMBED, a unified framework for occupancy\ninference and system-level load analysis. It combines two key components: a\nprobabilistic occupancy profile generator, and a controllable and interpretable\nload disaggregator supported by Kolmogorov-Arnold Networks (KAN). This design\nembeds knowledge of occupancy patterns and load-occupancy-weather relationships\ninto deep learning models. We conducted comprehensive evaluations to\ndemonstrate its effectiveness across synthetic and real-world datasets compared\nto various occupancy inference baselines. OccuEMBED always achieved average F1\nscores above 0.8 in discrete occupancy inference and RMSE within 0.1-0.2 for\ncontinuous occupancy ratios. We further demonstrate how OccuEMBED integrates\nwith building load monitoring platforms to display occupancy profiles, analyze\nsystem-level operations, and inform occupant-responsive strategies. Our model\nlays a robust foundation in scaling occupant-centric building management\nsystems to meet the challenges of an evolving energy system.", "AI": {"tldr": "The paper proposes OccuEMBED, a framework using smart meter data to infer occupancy and system operations for occupant-centric building energy management.", "motivation": "Buildings consume significant energy, and with volatile grids, they must balance efficiency and flexibility while prioritizing occupant comfort. Current methods struggle with large-scale occupant data integration.", "method": "OccuEMBED combines a probabilistic occupancy profile generator and a load disaggregator using Kolmogorov-Arnold Networks (KAN) to embed occupancy and load-weather relationships into deep learning models.", "result": "The framework achieved F1 scores above 0.8 for occupancy inference and RMSE within 0.1-0.2 for occupancy ratios, outperforming baselines. It integrates with monitoring platforms for actionable insights.", "conclusion": "OccuEMBED enables scalable, occupant-centric building management, addressing energy and grid challenges effectively."}}
{"id": "2406.06600", "pdf": "https://arxiv.org/pdf/2406.06600", "abs": "https://arxiv.org/abs/2406.06600", "authors": ["Yutao Sun", "Mingshuai Chen", "Tiancheng Zhao", "Kangjia Zhao", "He Li", "Jintao Chen", "Zhongyi Wang", "Liqiang Lu", "Xinkui Zhao", "Shuiguang Deng", "Jianwei Yin"], "title": "HORAE: A Domain-Agnostic Language for Automated Service Regulation", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": "Full version of IJCAI 2025", "summary": "Artificial intelligence is rapidly encroaching on the field of service\nregulation. However, existing AI-based regulation techniques are often tailored\nto specific application domains and thus are difficult to generalize in an\nautomated manner. This paper presents Horae, a unified specification language\nfor modeling (multimodal) regulation rules across a diverse set of domains. We\nshowcase how Horae facilitates an intelligent service regulation pipeline by\nfurther exploiting a fine-tuned large language model named RuleGPT that\nautomates the Horae modeling process, thereby yielding an end-to-end framework\nfor fully automated intelligent service regulation. The feasibility and\neffectiveness of our framework are demonstrated over a benchmark of various\nreal-world regulation domains. In particular, we show that our open-sourced,\nfine-tuned RuleGPT with 7B parameters suffices to outperform GPT-3.5 and\nperform on par with GPT-4o.", "AI": {"tldr": "Horae is a unified language for modeling regulation rules across domains, paired with RuleGPT, a fine-tuned LLM, to automate the process, outperforming GPT-3.5 and matching GPT-4.", "motivation": "Existing AI-based regulation techniques are domain-specific and lack generalizability, prompting the need for a unified solution.", "method": "Developed Horae, a specification language, and RuleGPT, a fine-tuned LLM, to automate rule modeling and regulation.", "result": "Demonstrated feasibility and effectiveness across real-world domains; RuleGPT (7B) outperforms GPT-3.5 and matches GPT-4.", "conclusion": "Horae and RuleGPT provide a scalable, automated framework for intelligent service regulation."}}
{"id": "2504.18530", "pdf": "https://arxiv.org/pdf/2504.18530", "abs": "https://arxiv.org/abs/2504.18530", "authors": ["Joshua Engels", "David D. Baek", "Subhash Kantamneni", "Max Tegmark"], "title": "Scaling Laws For Scalable Oversight", "categories": ["cs.AI", "cs.CY", "cs.LG"], "comment": "32 pages, 18 figures; The first three authors contributed equally", "summary": "Scalable oversight, the process by which weaker AI systems supervise stronger\nones, has been proposed as a key strategy to control future superintelligent\nsystems. However, it is still unclear how scalable oversight itself scales. To\naddress this gap, we propose a framework that quantifies the probability of\nsuccessful oversight as a function of the capabilities of the overseer and the\nsystem being overseen. Specifically, our framework models oversight as a game\nbetween capability-mismatched players; the players have oversight-specific Elo\nscores that are a piecewise-linear function of their general intelligence, with\ntwo plateaus corresponding to task incompetence and task saturation. We\nvalidate our framework with a modified version of the game Nim and then apply\nit to four oversight games: Mafia, Debate, Backdoor Code and Wargames. For each\ngame, we find scaling laws that approximate how domain performance depends on\ngeneral AI system capability. We then build on our findings in a theoretical\nstudy of Nested Scalable Oversight (NSO), a process in which trusted models\noversee untrusted stronger models, which then become the trusted models in the\nnext step. We identify conditions under which NSO succeeds and derive\nnumerically (and in some cases analytically) the optimal number of oversight\nlevels to maximize the probability of oversight success. We also apply our\ntheory to our four oversight games, where we find that NSO success rates at a\ngeneral Elo gap of 400 are 13.5% for Mafia, 51.7% for Debate, 10.0% for\nBackdoor Code, and 9.4% for Wargames; these rates decline further when\noverseeing stronger systems.", "AI": {"tldr": "The paper proposes a framework to quantify scalable oversight success, modeling it as a game with Elo scores, and validates it with oversight games like Mafia and Debate. It also studies Nested Scalable Oversight (NSO) and identifies optimal oversight levels.", "motivation": "To address the unclear scalability of scalable oversight, a strategy for controlling superintelligent AI systems.", "method": "A framework modeling oversight as a game with Elo scores, validated using modified Nim and applied to four oversight games. Theoretical study of NSO with optimal oversight levels.", "result": "Scaling laws for oversight games; NSO success rates: 13.5% (Mafia), 51.7% (Debate), 10.0% (Backdoor Code), 9.4% (Wargames).", "conclusion": "The framework provides insights into scalable oversight, with NSO success rates varying by game and declining for stronger systems."}}
{"id": "2505.06217", "pdf": "https://arxiv.org/pdf/2505.06217", "abs": "https://arxiv.org/abs/2505.06217", "authors": ["Pengfei Gu", "Haoteng Tang", "Islam A. Ebeid", "Jose A. Nunez", "Fabian Vazquez", "Diego Adame", "Marcus Zhan", "Huimin Li", "Bin Fu", "Danny Z. Chen"], "title": "Adapting a Segmentation Foundation Model for Medical Image Classification", "categories": ["cs.CV"], "comment": null, "summary": "Recent advancements in foundation models, such as the Segment Anything Model\n(SAM), have shown strong performance in various vision tasks, particularly\nimage segmentation, due to their impressive zero-shot segmentation\ncapabilities. However, effectively adapting such models for medical image\nclassification is still a less explored topic. In this paper, we introduce a\nnew framework to adapt SAM for medical image classification. First, we utilize\nthe SAM image encoder as a feature extractor to capture segmentation-based\nfeatures that convey important spatial and contextual details of the image,\nwhile freezing its weights to avoid unnecessary overhead during training. Next,\nwe propose a novel Spatially Localized Channel Attention (SLCA) mechanism to\ncompute spatially localized attention weights for the feature maps. The\nfeatures extracted from SAM's image encoder are processed through SLCA to\ncompute attention weights, which are then integrated into deep learning\nclassification models to enhance their focus on spatially relevant or\nmeaningful regions of the image, thus improving classification performance.\nExperimental results on three public medical image classification datasets\ndemonstrate the effectiveness and data-efficiency of our approach.", "AI": {"tldr": "A new framework adapts the Segment Anything Model (SAM) for medical image classification by leveraging its encoder for feature extraction and introducing a Spatially Localized Channel Attention (SLCA) mechanism to improve classification performance.", "motivation": "Despite SAM's strong zero-shot segmentation capabilities, adapting it for medical image classification remains underexplored.", "method": "Uses SAM's frozen encoder for feature extraction and introduces SLCA to compute spatially localized attention weights for enhanced classification.", "result": "Shows effectiveness and data-efficiency on three public medical image datasets.", "conclusion": "The proposed framework successfully adapts SAM for medical image classification, improving performance with minimal training overhead."}}
{"id": "2505.05479", "pdf": "https://arxiv.org/pdf/2505.05479", "abs": "https://arxiv.org/abs/2505.05479", "authors": ["Finn Gueterbock", "Raul Santos-Rodriguez", "Jeffrey N. Clark"], "title": "Improving Local Air Quality Predictions Using Transfer Learning on Satellite Data and Graph Neural Networks", "categories": ["eess.SP", "cs.LG"], "comment": null, "summary": "Air pollution is a significant global health risk, contributing to millions\nof premature deaths annually. Nitrogen dioxide (NO2), a harmful pollutant,\ndisproportionately affects urban areas where monitoring networks are often\nsparse. We propose a novel method for predicting NO2 concentrations at\nunmonitored locations using transfer learning with satellite and meteorological\ndata. Leveraging the GraphSAGE framework, our approach integrates\nautoregression and transfer learning to enhance predictive accuracy in\ndata-scarce regions like Bristol. Pre-trained on data from London, UK, our\nmodel achieves a 8.6% reduction in Normalised Root Mean Squared Error (NRMSE)\nand a 32.6% reduction in Gradient RMSE compared to a baseline model. This work\ndemonstrates the potential of virtual sensors for cost-effective air quality\nmonitoring, contributing to actionable insights for climate and health\ninterventions.", "AI": {"tldr": "A novel method using transfer learning with satellite and meteorological data improves NO2 prediction in urban areas, reducing errors by 8.6% (NRMSE) and 32.6% (Gradient RMSE).", "motivation": "Urban air pollution, especially NO2, poses health risks, but monitoring is sparse. Accurate predictions are needed for unmonitored locations.", "method": "Uses transfer learning with GraphSAGE, integrating autoregression and satellite/meteorological data, pre-trained on London data.", "result": "Model reduces NRMSE by 8.6% and Gradient RMSE by 32.6% compared to baseline, tested in Bristol.", "conclusion": "Virtual sensors can provide cost-effective air quality monitoring, aiding climate and health interventions."}}
{"id": "2406.09831", "pdf": "https://arxiv.org/pdf/2406.09831", "abs": "https://arxiv.org/abs/2406.09831", "authors": ["Youyang Qu", "Ming Liu", "Tianqing Zhu", "Longxiang Gao", "Shui Yu", "Wanlei Zhou"], "title": "Recent Advances in Federated Learning Driven Large Language Models: A Survey on Architecture, Performance, and Security", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.NE"], "comment": null, "summary": "Federated Learning (FL) offers a promising paradigm for training Large\nLanguage Models (LLMs) in a decentralized manner while preserving data privacy\nand minimizing communication overhead. This survey examines recent advancements\nin FL-driven LLMs, with a particular emphasis on architectural designs,\nperformance optimization, and security concerns, including the emerging area of\nmachine unlearning. In this context, machine unlearning refers to the\nsystematic removal of specific data contributions from trained models to comply\nwith privacy regulations such as the Right to be Forgotten. We review a range\nof strategies enabling unlearning in federated LLMs, including\nperturbation-based methods, model decomposition, and incremental retraining,\nwhile evaluating their trade-offs in terms of efficiency, privacy guarantees,\nand model utility. Through selected case studies and empirical evaluations, we\nanalyze how these methods perform in practical FL scenarios. This survey\nidentifies critical research directions toward developing secure, adaptable,\nand high-performing federated LLM systems for real-world deployment.", "AI": {"tldr": "A survey on Federated Learning (FL) for Large Language Models (LLMs), focusing on privacy, efficiency, and security, including machine unlearning techniques.", "motivation": "To explore FL-driven LLMs for decentralized training while addressing privacy, performance, and regulatory compliance (e.g., Right to be Forgotten).", "method": "Reviews architectural designs, optimization strategies, and unlearning methods (perturbation, model decomposition, incremental retraining).", "result": "Evaluates trade-offs in efficiency, privacy, and utility through case studies, highlighting practical FL performance.", "conclusion": "Identifies key research directions for secure, adaptable, and high-performing federated LLM systems."}}
{"id": "2504.20007", "pdf": "https://arxiv.org/pdf/2504.20007", "abs": "https://arxiv.org/abs/2504.20007", "authors": ["Anita Srbinovska", "Angela Srbinovska", "Vivek Senthil", "Adrian Martin", "John McCluskey", "Jonathan Bateman", "Ernest Fokou\u00e9"], "title": "Towards AI-Driven Policing: Interdisciplinary Knowledge Discovery from Police Body-Worn Camera Footage", "categories": ["cs.AI", "cs.CV"], "comment": "6 pages, 2 figures, and 1 table", "summary": "This paper proposes a novel interdisciplinary framework for analyzing police\nbody-worn camera (BWC) footage from the Rochester Police Department (RPD) using\nadvanced artificial intelligence (AI) and statistical machine learning (ML)\ntechniques. Our goal is to detect, classify, and analyze patterns of\ninteraction between police officers and civilians to identify key behavioral\ndynamics, such as respect, disrespect, escalation, and de-escalation. We apply\nmultimodal data analysis by integrating video, audio, and natural language\nprocessing (NLP) techniques to extract meaningful insights from BWC footage. We\npresent our methodology, computational techniques, and findings, outlining a\npractical approach for law enforcement while advancing the frontiers of\nknowledge discovery from police BWC data.", "AI": {"tldr": "A novel AI/ML framework analyzes police BWC footage to classify interactions, using multimodal data (video, audio, NLP) for behavioral insights.", "motivation": "To identify key behavioral dynamics (e.g., respect, escalation) in police-civilian interactions for law enforcement and research.", "method": "Multimodal data analysis integrating video, audio, and NLP techniques to process BWC footage.", "result": "Key behavioral patterns detected, providing actionable insights for law enforcement.", "conclusion": "The framework advances knowledge discovery from BWC data and offers practical tools for policing."}}
{"id": "2505.06219", "pdf": "https://arxiv.org/pdf/2505.06219", "abs": "https://arxiv.org/abs/2505.06219", "authors": ["Noah Frahm", "Dongxu Zhao", "Andrea Dunn Beltran", "Ron Alterovitz", "Jan-Michael Frahm", "Junier Oliva", "Roni Sengupta"], "title": "VIN-NBV: A View Introspection Network for Next-Best-View Selection for Resource-Efficient 3D Reconstruction", "categories": ["cs.CV", "cs.RO", "I.2.10; I.2.9"], "comment": "19 pages, 11 figures", "summary": "Next Best View (NBV) algorithms aim to acquire an optimal set of images using\nminimal resources, time, or number of captures to enable efficient 3D\nreconstruction of a scene. Existing approaches often rely on prior scene\nknowledge or additional image captures and often develop policies that maximize\ncoverage. Yet, for many real scenes with complex geometry and self-occlusions,\ncoverage maximization does not lead to better reconstruction quality directly.\nIn this paper, we propose the View Introspection Network (VIN), which is\ntrained to predict the reconstruction quality improvement of views directly,\nand the VIN-NBV policy. A greedy sequential sampling-based policy, where at\neach acquisition step, we sample multiple query views and choose the one with\nthe highest VIN predicted improvement score. We design the VIN to perform\n3D-aware featurization of the reconstruction built from prior acquisitions, and\nfor each query view create a feature that can be decoded into an improvement\nscore. We then train the VIN using imitation learning to predict the\nreconstruction improvement score. We show that VIN-NBV improves reconstruction\nquality by ~30% over a coverage maximization baseline when operating with\nconstraints on the number of acquisitions or the time in motion.", "AI": {"tldr": "The paper introduces the View Introspection Network (VIN) and VIN-NBV policy to improve 3D reconstruction by predicting view quality improvements, outperforming coverage-based methods by ~30%.", "motivation": "Existing NBV algorithms focus on coverage maximization, which doesn't always improve reconstruction quality for complex scenes. The paper addresses this gap by directly predicting view improvements.", "method": "Proposes VIN, a network predicting reconstruction quality improvement for views, and VIN-NBV, a greedy policy selecting views with the highest predicted improvement. Uses 3D-aware featurization and imitation learning.", "result": "VIN-NBV improves reconstruction quality by ~30% over coverage maximization baselines under acquisition or time constraints.", "conclusion": "VIN-NBV effectively enhances 3D reconstruction by prioritizing view quality over coverage, validated by significant performance gains."}}
{"id": "2505.05485", "pdf": "https://arxiv.org/pdf/2505.05485", "abs": "https://arxiv.org/abs/2505.05485", "authors": ["Antonio Arauzo-Azofra", "Jose Molina-Baena", "Maria Luque-Rodriguez"], "title": "Evolutionary Optimization for the Classification of Small Molecules Regulating the Circadian Rhythm Period: A Reliable Assessment", "categories": ["cs.NE", "cs.LG"], "comment": "13 pages, 5 figures, 8 tables. To be published", "summary": "The circadian rhythm plays a crucial role in regulating biological processes,\nand its disruption is linked to various health issues. Identifying small\nmolecules that influence the circadian period is essential for developing\ntargeted therapies. This study explores the use of evolutionary optimization\ntechniques to enhance the classification of these molecules. We applied an\nevolutionary algorithm to optimize feature selection and classification\nperformance. Several machine learning classifiers were employed, and\nperformance was evaluated using accuracy and generalization ability. The\nfindings demonstrate that the proposed evolutionary optimization method\nimproves classification accuracy and reduces overfitting compared to baseline\nmodels. Additionally, the use of variance in accuracy as a penalty factor may\nenhance the model's reliability for real-world applications. Our study confirms\nthat evolutionary optimization is an effective strategy for classifying small\nmolecules regulating the circadian rhythm. The proposed approach not only\nimproves predictive performance but also ensures a more robust model.", "AI": {"tldr": "The study uses evolutionary optimization to classify small molecules affecting circadian rhythms, improving accuracy and reducing overfitting.", "motivation": "Circadian rhythm disruption impacts health; identifying molecules that regulate it is key for therapies.", "method": "Evolutionary algorithms optimized feature selection and classification, tested with machine learning models.", "result": "Evolutionary optimization improved accuracy and reduced overfitting, with variance in accuracy enhancing reliability.", "conclusion": "Evolutionary optimization is effective for classifying circadian rhythm-regulating molecules, offering robust predictive performance."}}
{"id": "2503.24289", "pdf": "https://arxiv.org/pdf/2503.24289", "abs": "https://arxiv.org/abs/2503.24289", "authors": ["Jiacheng Lin", "Tian Wang", "Kun Qian"], "title": "Rec-R1: Bridging Generative Large Language Models and User-Centric Recommendation Systems via Reinforcement Learning", "categories": ["cs.IR", "cs.CL"], "comment": null, "summary": "We propose Rec-R1, a general reinforcement learning framework that bridges\nlarge language models (LLMs) with recommendation systems through closed-loop\noptimization. Unlike prompting and supervised fine-tuning (SFT), Rec-R1\ndirectly optimizes LLM generation using feedback from a fixed black-box\nrecommendation model, without relying on synthetic SFT data from proprietary\nmodels such as GPT-4o. This avoids the substantial cost and effort required for\ndata distillation. To verify the effectiveness of Rec-R1, we evaluate it on two\nrepresentative tasks: product search and sequential recommendation.\nExperimental results demonstrate that Rec-R1 not only consistently outperforms\nprompting- and SFT-based methods, but also achieves significant gains over\nstrong discriminative baselines, even when used with simple retrievers such as\nBM25. Moreover, Rec-R1 preserves the general-purpose capabilities of the LLM,\nunlike SFT, which often impairs instruction-following and reasoning. These\nfindings suggest Rec-R1 as a promising foundation for continual task-specific\nadaptation without catastrophic forgetting.", "AI": {"tldr": "Rec-R1 is a reinforcement learning framework that optimizes LLMs for recommendation systems using feedback from a fixed black-box model, avoiding costly synthetic data. It outperforms prompting and SFT methods while preserving LLM capabilities.", "motivation": "To bridge LLMs with recommendation systems efficiently, avoiding the high costs of synthetic data and preserving LLM versatility.", "method": "Rec-R1 uses closed-loop optimization with feedback from a fixed recommendation model, tested on product search and sequential recommendation tasks.", "result": "Rec-R1 outperforms prompting- and SFT-based methods and strong baselines, even with simple retrievers like BM25, without harming LLM capabilities.", "conclusion": "Rec-R1 is a promising approach for task-specific adaptation without catastrophic forgetting, maintaining LLM versatility."}}
{"id": "2505.03332", "pdf": "https://arxiv.org/pdf/2505.03332", "abs": "https://arxiv.org/abs/2505.03332", "authors": ["Evgeny Markhasin"], "title": "AI-Driven Scholarly Peer Review via Persistent Workflow Prompting, Meta-Prompting, and Meta-Reasoning", "categories": ["cs.AI"], "comment": "22 pages, 36 pages (references and appendixes)", "summary": "Critical peer review of scientific manuscripts presents a significant\nchallenge for Large Language Models (LLMs), partly due to data limitations and\nthe complexity of expert reasoning. This report introduces Persistent Workflow\nPrompting (PWP), a potentially broadly applicable prompt engineering\nmethodology designed to bridge this gap using standard LLM chat interfaces\n(zero-code, no APIs). We present a proof-of-concept PWP prompt for the critical\nanalysis of experimental chemistry manuscripts, featuring a hierarchical,\nmodular architecture (structured via Markdown) that defines detailed analysis\nworkflows. We develop this PWP prompt through iterative application of\nmeta-prompting techniques and meta-reasoning aimed at systematically codifying\nexpert review workflows, including tacit knowledge. Submitted once at the start\nof a session, this PWP prompt equips the LLM with persistent workflows\ntriggered by subsequent queries, guiding modern reasoning LLMs through\nsystematic, multimodal evaluations. Demonstrations show the PWP-guided LLM\nidentifying major methodological flaws in a test case while mitigating LLM\ninput bias and performing complex tasks, including distinguishing claims from\nevidence, integrating text/photo/figure analysis to infer parameters, executing\nquantitative feasibility checks, comparing estimates against claims, and\nassessing a priori plausibility. To ensure transparency and facilitate\nreplication, we provide full prompts, detailed demonstration analyses, and logs\nof interactive chats as supplementary resources. Beyond the specific\napplication, this work offers insights into the meta-development process\nitself, highlighting the potential of PWP, informed by detailed workflow\nformalization, to enable sophisticated analysis using readily available LLMs\nfor complex scientific tasks.", "AI": {"tldr": "The paper introduces Persistent Workflow Prompting (PWP), a method to enhance LLMs' ability to critically review scientific manuscripts, demonstrated in experimental chemistry.", "motivation": "Addressing the challenge of LLMs in peer review due to data limitations and expert reasoning complexity.", "method": "PWP uses hierarchical, modular prompts (structured via Markdown) to codify expert workflows, applied iteratively with meta-prompting.", "result": "PWP-guided LLMs identified methodological flaws, mitigated bias, and performed complex analyses like integrating multimodal data.", "conclusion": "PWP shows promise for sophisticated scientific tasks using standard LLMs, with transparency and replication supported by provided resources."}}
{"id": "2505.05477", "pdf": "https://arxiv.org/pdf/2505.05477", "abs": "https://arxiv.org/abs/2505.05477", "authors": ["Sainan xiao", "Wangdong Yang", "Buwen Cao", "Jintao Wu"], "title": "ECGDeDRDNet: A deep learning-based method for Electrocardiogram noise removal using a double recurrent dense network", "categories": ["eess.SP", "cs.CV"], "comment": null, "summary": "Electrocardiogram (ECG) signals are frequently corrupted by noise, such as\nbaseline wander (BW), muscle artifacts (MA), and electrode motion (EM), which\nsignificantly degrade their diagnostic utility. To address this issue, we\npropose ECGDeDRDNet, a deep learning-based ECG Denoising framework leveraging a\nDouble Recurrent Dense Network architecture. In contrast to traditional\napproaches, we introduce a double recurrent scheme to enhance information reuse\nfrom both ECG waveforms and the estimated clean image. For ECG waveform\nprocessing, our basic model employs LSTM layers cascaded with DenseNet blocks.\nThe estimated clean ECG image, obtained by subtracting predicted noise\ncomponents from the noisy input, is iteratively fed back into the model. This\ndual recurrent architecture enables comprehensive utilization of both temporal\nwaveform features and spatial image details, leading to more effective noise\nsuppression. Experimental results on the MIT-BIH dataset demonstrate that our\nmethod achieves superior performance compared to conventional image denoising\nmethods in terms of PSNR and SSIM while also surpassing classical ECG denoising\ntechniques in both SNR and RMSE.", "AI": {"tldr": "ECGDeDRDNet, a deep learning-based ECG denoising framework, uses a Double Recurrent Dense Network to improve noise suppression by leveraging both ECG waveforms and clean image feedback, outperforming traditional methods.", "motivation": "ECG signals are often corrupted by noise (BW, MA, EM), reducing diagnostic value. A robust denoising method is needed.", "method": "Proposes ECGDeDRDNet with a double recurrent scheme (LSTM + DenseNet) to process ECG waveforms and iteratively refine clean images.", "result": "Outperforms traditional methods on MIT-BIH dataset in PSNR, SSIM, SNR, and RMSE.", "conclusion": "ECGDeDRDNet effectively suppresses noise in ECG signals, enhancing diagnostic utility."}}
{"id": "2505.05489", "pdf": "https://arxiv.org/pdf/2505.05489", "abs": "https://arxiv.org/abs/2505.05489", "authors": ["Alberto Morando"], "title": "Akkumula: Evidence accumulation driver models with Spiking Neural Networks", "categories": ["cs.NE", "cs.LG"], "comment": null, "summary": "Processes of evidence accumulation for motor control contribute to the\necological validity of driver models. According to established theories of\ncognition, drivers make control adjustments when a process of accumulation of\nperceptual inputs reaches a decision boundary. Unfortunately, there is not a\nstandard way for building such models, limiting their use. Current\nimplementations are hand-crafted, lack adaptability, and rely on inefficient\noptimization techniques that do not scale well with large datasets. This paper\nintroduces Akkumula, an evidence accumulation modelling framework built using\ndeep learning techniques to leverage established coding libraries, gradient\noptimization, and large batch training. The core of the library is based on\nSpiking Neural Networks, whose operation mimic the evidence accumulation\nprocess in the biological brain. The model was tested on data collected during\na test-track experiment. Results are promising. The model fits well the time\ncourse of vehicle control (brake, accelerate, steering) based on vehicle sensor\ndata. The perceptual inputs are extracted by a dedicated neural network,\nincreasing the context-awareness of the model in dynamic scenarios. Akkumula\nintegrates with existing machine learning architectures, benefits from\ncontinuous advancements in deep learning, efficiently processes large datasets,\nadapts to diverse driving scenarios, and maintains a degree of transparency in\nits core mechanisms.", "AI": {"tldr": "Akkumula is a deep learning-based framework for evidence accumulation in driver models, improving adaptability and scalability over traditional methods.", "motivation": "Current driver models lack standardization, adaptability, and efficiency, limiting their practical use.", "method": "Akkumula uses Spiking Neural Networks to mimic biological evidence accumulation, integrating with deep learning tools for optimization and large-scale data processing.", "result": "The model effectively predicts vehicle control actions (braking, acceleration, steering) using sensor data and enhances context-awareness in dynamic scenarios.", "conclusion": "Akkumula offers a scalable, adaptable, and transparent solution for evidence accumulation in driver models, leveraging modern deep learning advancements."}}
{"id": "2505.02550", "pdf": "https://arxiv.org/pdf/2505.02550", "abs": "https://arxiv.org/abs/2505.02550", "authors": ["Krzysztof Ociepa", "\u0141ukasz Flis", "Remigiusz Kinas", "Krzysztof Wr\u00f3bel", "Adrian Gwo\u017adziej"], "title": "Bielik v3 Small: Technical Report", "categories": ["cs.LG", "cs.AI", "cs.CL", "68T50", "I.2.7"], "comment": null, "summary": "We introduce Bielik v3, a series of parameter-efficient generative text\nmodels (1.5B and 4.5B) optimized for Polish language processing. These models\ndemonstrate that smaller, well-optimized architectures can achieve performance\ncomparable to much larger counterparts while requiring substantially fewer\ncomputational resources. Our approach incorporates several key innovations: a\ncustom Polish tokenizer (APT4) that significantly improves token efficiency,\nWeighted Instruction Cross-Entropy Loss to balance learning across instruction\ntypes, and Adaptive Learning Rate that dynamically adjusts based on training\nprogress. Trained on a meticulously curated corpus of 292 billion tokens\nspanning 303 million documents, these models excel across multiple benchmarks,\nincluding the Open PL LLM Leaderboard, Complex Polish Text Understanding\nBenchmark, Polish EQ-Bench, and Polish Medical Leaderboard. The 4.5B parameter\nmodel achieves results competitive with models 2-3 times its size, while the\n1.5B model delivers strong performance despite its extremely compact profile.\nThese advances establish new benchmarks for parameter-efficient language\nmodeling in less-represented languages, making high-quality Polish language AI\nmore accessible for resource-constrained applications.", "AI": {"tldr": "Bielik v3 introduces parameter-efficient generative text models (1.5B and 4.5B) for Polish, achieving performance comparable to larger models with fewer resources. Innovations include a custom tokenizer, weighted loss, and adaptive learning.", "motivation": "To create high-quality Polish language AI models that are resource-efficient and competitive with larger counterparts.", "method": "Uses a custom Polish tokenizer (APT4), Weighted Instruction Cross-Entropy Loss, and Adaptive Learning Rate. Trained on 292B tokens from 303M documents.", "result": "The 4.5B model competes with models 2-3x its size; the 1.5B model performs well despite its compact size. Excels in benchmarks like Open PL LLM Leaderboard.", "conclusion": "Bielik v3 sets new benchmarks for parameter-efficient Polish language models, making high-quality AI more accessible for resource-limited applications."}}
{"id": "2505.05440", "pdf": "https://arxiv.org/pdf/2505.05440", "abs": "https://arxiv.org/abs/2505.05440", "authors": ["Biao Yi", "Xavier Hu", "Yurun Chen", "Shengyu Zhang", "Hongxia Yang", "Fan Wu", "Fei Wu"], "title": "EcoAgent: An Efficient Edge-Cloud Collaborative Multi-Agent Framework for Mobile Automation", "categories": ["cs.AI"], "comment": null, "summary": "Cloud-based mobile agents powered by (multimodal) large language models\n((M)LLMs) offer strong reasoning abilities but suffer from high latency and\ncost. While fine-tuned (M)SLMs enable edge deployment, they often lose general\ncapabilities and struggle with complex tasks. To address this, we propose\n\\textbf{EcoAgent}, an \\textbf{E}dge-\\textbf{C}loud c\\textbf{O}llaborative\nmulti-agent framework for mobile automation. EcoAgent features a closed-loop\ncollaboration among a cloud-based Planning Agent and two edge-based agents: the\nExecution Agent for action execution and the Observation Agent for verifying\noutcomes. The Observation Agent uses a Pre-Understanding Module to compress\nscreen images into concise text, reducing token usage and communication\noverhead. In case of failure, the Planning Agent retrieves screen history\nthrough a Memory Module and replans via a Reflection Module. Experiments on\nAndroidWorld show that EcoAgent achieves task success rates comparable to\ncloud-based mobile agents while significantly reducing MLLM token consumption,\nenabling efficient and practical mobile automation.", "AI": {"tldr": "EcoAgent is an edge-cloud collaborative framework for mobile automation, balancing cloud-based reasoning with edge efficiency to reduce latency and cost while maintaining task success.", "motivation": "Cloud-based agents with (M)LLMs are powerful but costly and slow, while edge-deployed (M)SLMs lose generality. EcoAgent bridges this gap.", "method": "EcoAgent uses a cloud-based Planning Agent and two edge-based agents (Execution and Observation) with modules for compression, memory, and reflection.", "result": "EcoAgent matches cloud-based success rates on AndroidWorld while cutting MLLM token use, proving efficient mobile automation.", "conclusion": "EcoAgent offers a practical, efficient solution for mobile automation by combining edge and cloud strengths."}}
{"id": "2505.05510", "pdf": "https://arxiv.org/pdf/2505.05510", "abs": "https://arxiv.org/abs/2505.05510", "authors": ["Thomas Sommariva", "Simone Calderara", "Angelo Porrello"], "title": "How to Train Your Metamorphic Deep Neural Network", "categories": ["cs.NE", "cs.CV", "cs.LG"], "comment": "14 pages, 7 figures", "summary": "Neural Metamorphosis (NeuMeta) is a recent paradigm for generating neural\nnetworks of varying width and depth. Based on Implicit Neural Representation\n(INR), NeuMeta learns a continuous weight manifold, enabling the direct\ngeneration of compressed models, including those with configurations not seen\nduring training. While promising, the original formulation of NeuMeta proves\neffective only for the final layers of the undelying model, limiting its\nbroader applicability. In this work, we propose a training algorithm that\nextends the capabilities of NeuMeta to enable full-network metamorphosis with\nminimal accuracy degradation. Our approach follows a structured recipe\ncomprising block-wise incremental training, INR initialization, and strategies\nfor replacing batch normalization. The resulting metamorphic networks maintain\ncompetitive accuracy across a wide range of compression ratios, offering a\nscalable solution for adaptable and efficient deployment of deep models. The\ncode is available at: https://github.com/TSommariva/HTTY_NeuMeta.", "AI": {"tldr": "NeuMeta is extended to enable full-network metamorphosis with minimal accuracy loss, using block-wise training, INR initialization, and batch norm replacement.", "motivation": "The original NeuMeta was limited to final layers, restricting its broader use.", "method": "Block-wise incremental training, INR initialization, and batch normalization replacement.", "result": "Metamorphic networks maintain competitive accuracy across various compression ratios.", "conclusion": "The approach offers scalable, adaptable, and efficient deployment of deep models."}}
{"id": "2505.05511", "pdf": "https://arxiv.org/pdf/2505.05511", "abs": "https://arxiv.org/abs/2505.05511", "authors": ["Yanghui Song", "Aoqi Li", "Lilei Huo"], "title": "Economic Analysis and Optimization of Energy Storage Configuration for Park Power Systems Based on Random Forest and Genetic Algorithm", "categories": ["cs.NE", "cs.LG", "cs.SI"], "comment": "8 pages, 8 figures,International Journal of New Developments in\n  Engineering and Society ISSN 2522-3488 Vol. 8, Issue 4: 22-29", "summary": "This study aims to analyze the economic performance of various parks under\ndifferent conditions, particularly focusing on the operational costs and power\nload balancing before and after the deployment of energy storage systems.\nFirstly, the economic performance of the parks without energy storage was\nanalyzed using a random forest model. Taking Park A as an example, it was found\nthat the cost had the greatest correlation with electricity purchase, followed\nby photovoltaic output, indicating that solar and wind power output are key\nfactors affecting economic performance. Subsequently, the operation of the\nparks after the configuration of a 50kW/100kWh energy storage system was\nsimulated, and the total cost and operation strategy of the energy storage\nsystem were calculated. The results showed that after the deployment of energy\nstorage, the amount of wind and solar power curtailment in each park decreased,\nand the operational costs were reduced. Finally, a genetic algorithm was used\nto optimize the energy storage configuration of each park. The energy storage\noperation strategy was optimized through fitness functions, crossover\noperations, and mutation operations. After optimization, the economic\nindicators of Parks A, B, and C all improved. The research results indicate\nthat by optimizing energy storage configuration, each park can reduce costs,\nenhance economic benefits, and achieve sustainable development of the power\nsystem.", "AI": {"tldr": "The study analyzes the economic impact of energy storage systems in parks, showing cost reductions and improved efficiency after deployment and optimization.", "motivation": "To evaluate how energy storage systems affect the economic performance of parks, focusing on operational costs and power load balancing.", "method": "Used a random forest model for initial analysis, simulated energy storage deployment, and optimized configuration with a genetic algorithm.", "result": "Energy storage reduced wind/solar curtailment and costs; genetic algorithm optimization further improved economic indicators.", "conclusion": "Optimizing energy storage enhances economic benefits and supports sustainable power system development."}}
{"id": "2505.02835", "pdf": "https://arxiv.org/pdf/2505.02835", "abs": "https://arxiv.org/abs/2505.02835", "authors": ["Yi-Fan Zhang", "Xingyu Lu", "Xiao Hu", "Chaoyou Fu", "Bin Wen", "Tianke Zhang", "Changyi Liu", "Kaiyu Jiang", "Kaibing Chen", "Kaiyu Tang", "Haojie Ding", "Jiankang Chen", "Fan Yang", "Zhang Zhang", "Tingting Gao", "Liang Wang"], "title": "R1-Reward: Training Multimodal Reward Model Through Stable Reinforcement Learning", "categories": ["cs.CV", "cs.CL"], "comment": "Home page: https://github.com/yfzhang114/r1_reward", "summary": "Multimodal Reward Models (MRMs) play a crucial role in enhancing the\nperformance of Multimodal Large Language Models (MLLMs). While recent\nadvancements have primarily focused on improving the model structure and\ntraining data of MRMs, there has been limited exploration into the\neffectiveness of long-term reasoning capabilities for reward modeling and how\nto activate these capabilities in MRMs. In this paper, we explore how\nReinforcement Learning (RL) can be used to improve reward modeling.\nSpecifically, we reformulate the reward modeling problem as a rule-based RL\ntask. However, we observe that directly applying existing RL algorithms, such\nas Reinforce++, to reward modeling often leads to training instability or even\ncollapse due to the inherent limitations of these algorithms. To address this\nissue, we propose the StableReinforce algorithm, which refines the training\nloss, advantage estimation strategy, and reward design of existing RL methods.\nThese refinements result in more stable training dynamics and superior\nperformance. To facilitate MRM training, we collect 200K preference data from\ndiverse datasets. Our reward model, R1-Reward, trained using the\nStableReinforce algorithm on this dataset, significantly improves performance\non multimodal reward modeling benchmarks. Compared to previous SOTA models,\nR1-Reward achieves a $8.4\\%$ improvement on the VL Reward-Bench and a $14.3\\%$\nimprovement on the Multimodal Reward Bench. Moreover, with more inference\ncompute, R1-Reward's performance is further enhanced, highlighting the\npotential of RL algorithms in optimizing MRMs.", "AI": {"tldr": "The paper explores using Reinforcement Learning (RL) to improve Multimodal Reward Models (MRMs), proposing the StableReinforce algorithm for stable training and better performance.", "motivation": "Limited exploration of long-term reasoning in MRMs and the instability of existing RL methods for reward modeling.", "method": "Reformulates reward modeling as a rule-based RL task, introduces StableReinforce with refined training loss, advantage estimation, and reward design, and uses 200K preference data.", "result": "R1-Reward, trained with StableReinforce, improves benchmarks by 8.4% (VL Reward-Bench) and 14.3% (Multimodal Reward Bench).", "conclusion": "RL, particularly StableReinforce, effectively optimizes MRMs, with potential for further performance gains."}}
{"id": "2308.14329", "pdf": "https://arxiv.org/pdf/2308.14329", "abs": "https://arxiv.org/abs/2308.14329", "authors": ["Jin Bok Park", "Jinkyu Lee", "Muhyun Back", "Hyunmin Han", "David T. Ma", "Sang Min Won", "Sung Soo Hwang", "Il Yong Chun"], "title": "End-to-End Driving via Self-Supervised Imitation Learning Using Camera and LiDAR Data", "categories": ["cs.RO", "cs.AI"], "comment": "9 pages, 6 figures", "summary": "In autonomous driving, the end-to-end (E2E) driving approach that predicts\nvehicle control signals directly from sensor data is rapidly gaining attention.\nTo learn a safe E2E driving system, one needs an extensive amount of driving\ndata and human intervention. Vehicle control data is constructed by many hours\nof human driving, and it is challenging to construct large vehicle control\ndatasets. Often, publicly available driving datasets are collected with limited\ndriving scenes, and collecting vehicle control data is only available by\nvehicle manufacturers. To address these challenges, this letter proposes the\nfirst fully self-supervised learning framework, self-supervised imitation\nlearning (SSIL), for E2E driving, based on the self-supervised regression\nlearning (SSRL) framework.The proposed SSIL framework can learn E2E driving\nnetworks \\emph{without} using driving command data or a pre-trained model. To\nconstruct pseudo steering angle data, proposed SSIL predicts a pseudo target\nfrom the vehicle's poses at the current and previous time points that are\nestimated with light detection and ranging sensors. In addition, we propose two\nE2E driving networks that predict driving commands depending on high-level\ninstruction. Our numerical experiments with three different benchmark datasets\ndemonstrate that the proposed SSIL framework achieves \\emph{very} comparable\nE2E driving accuracy with the supervised learning counterpart. The proposed\npseudo-label predictor outperformed an existing one using proportional integral\nderivative controller.", "AI": {"tldr": "Proposes a self-supervised imitation learning (SSIL) framework for end-to-end autonomous driving without needing labeled driving data or pre-trained models.", "motivation": "Addresses the challenge of requiring extensive labeled driving data for training end-to-end driving systems by eliminating the need for human intervention or pre-trained models.", "method": "Uses self-supervised regression learning (SSRL) to predict pseudo steering angles from vehicle poses estimated via LiDAR. Introduces two networks for command prediction based on high-level instructions.", "result": "Achieves comparable accuracy to supervised learning on benchmark datasets and outperforms existing pseudo-label predictors.", "conclusion": "SSIL offers a viable, data-efficient alternative to traditional supervised methods for end-to-end autonomous driving."}}
{"id": "2505.05592", "pdf": "https://arxiv.org/pdf/2505.05592", "abs": "https://arxiv.org/abs/2505.05592", "authors": ["Noriaki Hirose", "Lydia Ignatova", "Kyle Stachowicz", "Catherine Glossop", "Sergey Levine", "Dhruv Shah"], "title": "Learning to Drive Anywhere with Model-Based Reannotation11", "categories": ["cs.RO", "cs.CV", "cs.LG", "cs.SY", "eess.SY"], "comment": "19 pages, 11 figures, 8 tables", "summary": "Developing broadly generalizable visual navigation policies for robots is a\nsignificant challenge, primarily constrained by the availability of\nlarge-scale, diverse training data. While curated datasets collected by\nresearchers offer high quality, their limited size restricts policy\ngeneralization. To overcome this, we explore leveraging abundant, passively\ncollected data sources, including large volumes of crowd-sourced teleoperation\ndata and unlabeled YouTube videos, despite their potential for lower quality or\nmissing action labels. We propose Model-Based ReAnnotation (MBRA), a framework\nthat utilizes a learned short-horizon, model-based expert model to relabel or\ngenerate high-quality actions for these passive datasets. This relabeled data\nis then distilled into LogoNav, a long-horizon navigation policy conditioned on\nvisual goals or GPS waypoints. We demonstrate that LogoNav, trained using\nMBRA-processed data, achieves state-of-the-art performance, enabling robust\nnavigation over distances exceeding 300 meters in previously unseen indoor and\noutdoor environments. Our extensive real-world evaluations, conducted across a\nfleet of robots (including quadrupeds) in six cities on three continents,\nvalidate the policy's ability to generalize and navigate effectively even\namidst pedestrians in crowded settings.", "AI": {"tldr": "MBRA framework improves robot navigation by relabeling passive data (e.g., YouTube videos) with a learned model, enabling LogoNav to achieve state-of-the-art performance in unseen environments.", "motivation": "Limited size of curated datasets restricts policy generalization; leveraging abundant passive data (e.g., crowd-sourced teleoperation, YouTube videos) can overcome this.", "method": "Propose Model-Based ReAnnotation (MBRA) to relabel passive data using a learned model, then distill into LogoNav, a long-horizon navigation policy.", "result": "LogoNav achieves robust navigation over 300 meters in unseen environments, validated in real-world tests across six cities on three continents.", "conclusion": "MBRA-processed data enables LogoNav to generalize effectively, even in crowded settings, advancing visual navigation for robots."}}
{"id": "2505.05515", "pdf": "https://arxiv.org/pdf/2505.05515", "abs": "https://arxiv.org/abs/2505.05515", "authors": ["Zinan Liu", "Haoran Li", "Jingyi Lu", "Gaoyuan Ma", "Xu Hong", "Giovanni Iacca", "Arvind Kumar", "Shaojun Tang", "Lin Wang"], "title": "Nature's Insight: A Novel Framework and Comprehensive Analysis of Agentic Reasoning Through the Lens of Neuroscience", "categories": ["q-bio.NC", "cs.LG"], "comment": "39 pages, 17 figures", "summary": "Autonomous AI is no longer a hard-to-reach concept, it enables the agents to\nmove beyond executing tasks to independently addressing complex problems,\nadapting to change while handling the uncertainty of the environment. However,\nwhat makes the agents truly autonomous? It is agentic reasoning, that is\ncrucial for foundation models to develop symbolic logic, statistical\ncorrelations, or large-scale pattern recognition to process information, draw\ninferences, and make decisions. However, it remains unclear why and how\nexisting agentic reasoning approaches work, in comparison to biological\nreasoning, which instead is deeply rooted in neural mechanisms involving\nhierarchical cognition, multimodal integration, and dynamic interactions. In\nthis work, we propose a novel neuroscience-inspired framework for agentic\nreasoning. Grounded in three neuroscience-based definitions and supported by\nmathematical and biological foundations, we propose a unified framework\nmodeling reasoning from perception to action, encompassing four core types,\nperceptual, dimensional, logical, and interactive, inspired by distinct\nfunctional roles observed in the human brain. We apply this framework to\nsystematically classify and analyze existing AI reasoning methods, evaluating\ntheir theoretical foundations, computational designs, and practical\nlimitations. We also explore its implications for building more generalizable,\ncognitively aligned agents in physical and virtual environments. Finally,\nbuilding on our framework, we outline future directions and propose new\nneural-inspired reasoning methods, analogous to chain-of-thought prompting. By\nbridging cognitive neuroscience and AI, this work offers a theoretical\nfoundation and practical roadmap for advancing agentic reasoning in intelligent\nsystems. The associated project can be found at:\nhttps://github.com/BioRAILab/Awesome-Neuroscience-Agent-Reasoning .", "AI": {"tldr": "The paper proposes a neuroscience-inspired framework for agentic reasoning in AI, aiming to bridge cognitive neuroscience and AI to advance autonomous systems.", "motivation": "Current agentic reasoning approaches lack clarity in their workings compared to biological reasoning, which is rooted in neural mechanisms. The paper seeks to address this gap.", "method": "The authors introduce a unified framework grounded in neuroscience, modeling reasoning from perception to action with four core types: perceptual, dimensional, logical, and interactive.", "result": "The framework is applied to classify and analyze existing AI reasoning methods, revealing theoretical and practical limitations, and suggesting improvements.", "conclusion": "The work provides a theoretical foundation and practical roadmap for advancing agentic reasoning, with implications for building more generalizable and cognitively aligned AI agents."}}
{"id": "2505.03414", "pdf": "https://arxiv.org/pdf/2505.03414", "abs": "https://arxiv.org/abs/2505.03414", "authors": ["Fangming Cui", "Yonggang Zhang", "Xuan Wang", "Xinmei Tian", "Jun Yu"], "title": "Enhancing Target-unspecific Tasks through a Features Matrix", "categories": ["cs.CV", "cs.CL"], "comment": "ICML 2025", "summary": "Recent developments in prompt learning of large vision-language models have\nsignificantly improved performance in target-specific tasks. However, these\nprompt optimizing methods often struggle to tackle the target-unspecific or\ngeneralizable tasks effectively. It may be attributed to the fact that\noverfitting training causes the model to forget its general knowledge having\nstrong promotion on target-unspecific tasks. To alleviate this issue, we\npropose a novel Features Matrix (FM) regularization approach designed to\nenhance these models on target-unspecific tasks. Our method extracts and\nleverages general knowledge, shaping a Features Matrix (FM). Specifically, the\nFM captures the semantics of diverse inputs from a deep and fine perspective,\npreserving essential general knowledge, which mitigates the risk of\noverfitting. Representative evaluations demonstrate that: 1) the FM is\ncompatible with existing frameworks as a generic and flexible module, and 2)\nthe FM significantly showcases its effectiveness in enhancing target-unspecific\ntasks, achieving state-of-the-art performance.", "AI": {"tldr": "A novel Features Matrix (FM) regularization method is proposed to enhance large vision-language models for target-unspecific tasks by preserving general knowledge and preventing overfitting.", "motivation": "Current prompt learning methods for vision-language models perform well on target-specific tasks but struggle with generalizable tasks due to overfitting and loss of general knowledge.", "method": "The FM approach extracts and leverages general knowledge by capturing diverse input semantics from a deep and fine perspective, forming a Features Matrix to mitigate overfitting.", "result": "The FM is compatible with existing frameworks and significantly improves performance on target-unspecific tasks, achieving state-of-the-art results.", "conclusion": "The FM regularization method effectively addresses overfitting and enhances generalizability in vision-language models."}}
{"id": "2312.08365", "pdf": "https://arxiv.org/pdf/2312.08365", "abs": "https://arxiv.org/abs/2312.08365", "authors": ["Bernhard Jaeger", "Andreas Geiger"], "title": "An Invitation to Deep Reinforcement Learning", "categories": ["cs.LG", "cs.AI"], "comment": "Published at Foundations and Trends in Optimization", "summary": "Training a deep neural network to maximize a target objective has become the\nstandard recipe for successful machine learning over the last decade. These\nnetworks can be optimized with supervised learning, if the target objective is\ndifferentiable. For many interesting problems, this is however not the case.\nCommon objectives like intersection over union (IoU), bilingual evaluation\nunderstudy (BLEU) score or rewards cannot be optimized with supervised\nlearning. A common workaround is to define differentiable surrogate losses,\nleading to suboptimal solutions with respect to the actual objective.\nReinforcement learning (RL) has emerged as a promising alternative for\noptimizing deep neural networks to maximize non-differentiable objectives in\nrecent years. Examples include aligning large language models via human\nfeedback, code generation, object detection or control problems. This makes RL\ntechniques relevant to the larger machine learning audience. The subject is,\nhowever, time intensive to approach due to the large range of methods, as well\nas the often very theoretical presentation. In this introduction, we take an\nalternative approach, different from classic reinforcement learning textbooks.\nRather than focusing on tabular problems, we introduce reinforcement learning\nas a generalization of supervised learning, which we first apply to\nnon-differentiable objectives and later to temporal problems. Assuming only\nbasic knowledge of supervised learning, the reader will be able to understand\nstate-of-the-art deep RL algorithms like proximal policy optimization (PPO)\nafter reading this tutorial.", "AI": {"tldr": "The paper introduces reinforcement learning (RL) as a generalization of supervised learning for optimizing non-differentiable objectives, making it accessible to a broader machine learning audience.", "motivation": "Many machine learning objectives (e.g., IoU, BLEU, rewards) are non-differentiable, making supervised learning suboptimal. RL offers a promising alternative.", "method": "The tutorial simplifies RL by framing it as an extension of supervised learning, avoiding complex theoretical presentations and focusing on practical applications.", "result": "Readers with basic supervised learning knowledge can understand advanced RL algorithms like PPO.", "conclusion": "The paper bridges the gap between supervised learning and RL, making the latter more approachable for optimizing non-differentiable objectives."}}
{"id": "2505.05647", "pdf": "https://arxiv.org/pdf/2505.05647", "abs": "https://arxiv.org/abs/2505.05647", "authors": ["Chin-Cheng Chan", "Justin P. Haldar"], "title": "A New k-Space Model for Non-Cartesian Fourier Imaging", "categories": ["eess.SP", "cs.CV"], "comment": null, "summary": "For the past several decades, it has been popular to reconstruct Fourier\nimaging data using model-based approaches that can easily incorporate physical\nconstraints and advanced regularization/machine learning priors. The most\ncommon modeling approach is to represent the continuous image as a linear\ncombination of shifted \"voxel\" basis functions. Although well-studied and\nwidely-deployed, this voxel-based model is associated with longstanding\nlimitations, including high computational costs, slow convergence, and a\npropensity for artifacts. In this work, we reexamine this model from a fresh\nperspective, identifying new issues that may have been previously overlooked\n(including undesirable approximation, periodicity, and nullspace\ncharacteristics). Our insights motivate us to propose a new model that is more\nresilient to the limitations (old and new) of the previous approach.\nSpecifically, the new model is based on a Fourier-domain basis expansion rather\nthan the standard image-domain voxel-based approach. Illustrative results,\nwhich are presented in the context of non-Cartesian MRI reconstruction,\ndemonstrate that the new model enables improved image quality (reduced\nartifacts) and/or reduced computational complexity (faster computations and\nimproved convergence).", "AI": {"tldr": "The paper critiques traditional voxel-based Fourier imaging models, highlighting their limitations, and proposes a new Fourier-domain basis expansion model for improved performance.", "motivation": "The motivation is to address longstanding issues in voxel-based models, such as computational inefficiency and artifacts, while uncovering new overlooked problems like approximation and periodicity issues.", "method": "The authors propose a new model based on a Fourier-domain basis expansion instead of the traditional image-domain voxel-based approach.", "result": "Results show the new model improves image quality (reduced artifacts) and computational efficiency (faster computations, better convergence) in non-Cartesian MRI reconstruction.", "conclusion": "The conclusion is that the Fourier-domain basis expansion model outperforms the traditional voxel-based approach, offering a more resilient solution for Fourier imaging."}}
{"id": "2505.05542", "pdf": "https://arxiv.org/pdf/2505.05542", "abs": "https://arxiv.org/abs/2505.05542", "authors": ["Guillaume Dalle", "Adrian Hill"], "title": "A Common Interface for Automatic Differentiation", "categories": ["cs.MS", "cs.LG", "cs.NA", "math.NA", "G.1.4"], "comment": "11 pages, 2 figures, 3 listings, 1 table", "summary": "For scientific machine learning tasks with a lot of custom code, picking the\nright Automatic Differentiation (AD) system matters. Our Julia package\nDifferentiationInterface.jl provides a common frontend to a dozen AD backends,\nunlocking easy comparison and modular development. In particular, its built-in\npreparation mechanism leverages the strengths of each backend by amortizing\none-time computations. This is key to enabling sophisticated features like\nsparsity handling without putting additional burdens on the user.", "AI": {"tldr": "DifferentiationInterface.jl is a Julia package offering a unified frontend for multiple AD backends, simplifying comparison and development while optimizing performance.", "motivation": "The need for an efficient and flexible AD system for scientific machine learning tasks with custom code.", "method": "Provides a common frontend to various AD backends, with a built-in preparation mechanism for optimizing one-time computations.", "result": "Enables easy comparison of AD backends and supports advanced features like sparsity handling without user overhead.", "conclusion": "DifferentiationInterface.jl enhances AD usability and performance for scientific machine learning."}}
{"id": "2401.14362", "pdf": "https://arxiv.org/pdf/2401.14362", "abs": "https://arxiv.org/abs/2401.14362", "authors": ["Inhwa Song", "Sachin R. Pendse", "Neha Kumar", "Munmun De Choudhury"], "title": "The Typing Cure: Experiences with Large Language Model Chatbots for Mental Health Support", "categories": ["cs.HC", "cs.AI", "cs.CY"], "comment": "The first two authors contributed equally to this work; typos\n  corrected and post-review revisions incorporated", "summary": "People experiencing severe distress increasingly use Large Language Model\n(LLM) chatbots as mental health support tools. Discussions on social media have\ndescribed how engagements were lifesaving for some, but evidence suggests that\ngeneral-purpose LLM chatbots also have notable risks that could endanger the\nwelfare of users if not designed responsibly. In this study, we investigate the\nlived experiences of people who have used LLM chatbots for mental health\nsupport. We build on interviews with 21 individuals from globally diverse\nbackgrounds to analyze how users create unique support roles for their\nchatbots, fill in gaps in everyday care, and navigate associated cultural\nlimitations when seeking support from chatbots. We ground our analysis in\npsychotherapy literature around effective support, and introduce the concept of\ntherapeutic alignment, or aligning AI with therapeutic values for mental health\ncontexts. Our study offers recommendations for how designers can approach the\nethical and effective use of LLM chatbots and other AI mental health support\ntools in mental health care.", "AI": {"tldr": "Study explores how people use LLM chatbots for mental health support, highlighting benefits and risks, and introduces therapeutic alignment for ethical AI design.", "motivation": "To understand the lived experiences of individuals using LLM chatbots for mental health support and address the risks and gaps in care.", "method": "Interviews with 21 globally diverse individuals to analyze chatbot roles, care gaps, and cultural limitations.", "result": "Users create unique support roles for chatbots, filling care gaps, but face cultural and ethical challenges.", "conclusion": "Recommends therapeutic alignment for ethical and effective AI mental health support tools."}}
{"id": "2505.05800", "pdf": "https://arxiv.org/pdf/2505.05800", "abs": "https://arxiv.org/abs/2505.05800", "authors": ["Vineet Bhat", "Yu-Hsiang Lan", "Prashanth Krishnamurthy", "Ramesh Karri", "Farshad Khorrami"], "title": "3D CAVLA: Leveraging Depth and 3D Context to Generalize Vision Language Action Models for Unseen Tasks", "categories": ["cs.RO", "cs.CV"], "comment": "Accepted at the 1st Workshop on 3D LLM/VLA, CVPR 2025", "summary": "Robotic manipulation in 3D requires learning an $N$ degree-of-freedom joint\nspace trajectory of a robot manipulator. Robots must possess semantic and\nvisual perception abilities to transform real-world mappings of their workspace\ninto the low-level control necessary for object manipulation. Recent work has\ndemonstrated the capabilities of fine-tuning large Vision-Language Models\n(VLMs) to learn the mapping between RGB images, language instructions, and\njoint space control. These models typically take as input RGB images of the\nworkspace and language instructions, and are trained on large datasets of\nteleoperated robot demonstrations. In this work, we explore methods to improve\nthe scene context awareness of a popular recent Vision-Language-Action model by\nintegrating chain-of-thought reasoning, depth perception, and task-oriented\nregion of interest detection. Our experiments in the LIBERO simulation\nenvironment show that our proposed model, 3D-CAVLA, improves the success rate\nacross various LIBERO task suites, achieving an average success rate of\n98.1$\\%$. We also evaluate the zero-shot capabilities of our method,\ndemonstrating that 3D scene awareness leads to robust learning and adaptation\nfor completely unseen tasks. 3D-CAVLA achieves an absolute improvement of\n8.8$\\%$ on unseen tasks. We will open-source our code and the unseen tasks\ndataset to promote community-driven research here: https://3d-cavla.github.io", "AI": {"tldr": "The paper introduces 3D-CAVLA, a model enhancing robotic manipulation by integrating depth perception, chain-of-thought reasoning, and task-oriented region detection, achieving high success rates in simulation.", "motivation": "Improving robotic manipulation in 3D by enhancing scene context awareness for better control and adaptation.", "method": "Integrates chain-of-thought reasoning, depth perception, and task-oriented region detection into a Vision-Language-Action model.", "result": "Achieves 98.1% success rate in simulation and 8.8% improvement on unseen tasks.", "conclusion": "3D-CAVLA demonstrates robust learning and adaptation, with plans to open-source code and datasets for community research."}}
{"id": "2505.05549", "pdf": "https://arxiv.org/pdf/2505.05549", "abs": "https://arxiv.org/abs/2505.05549", "authors": ["Vishnu Jejjala", "Suresh Nampuri", "Dumisani Nxumalo", "Pratik Roy", "Abinash Swain"], "title": "Machine learning automorphic forms for black holes", "categories": ["hep-th", "cs.LG", "math.NT"], "comment": null, "summary": "Modular, Jacobi, and mock-modular forms serve as generating functions for BPS\nblack hole degeneracies. By training feed-forward neural networks on Fourier\ncoefficients of automorphic forms derived from the Dedekind eta function,\nEisenstein series, and Jacobi theta functions, we demonstrate that machine\nlearning techniques can accurately predict modular weights from truncated\nexpansions. Our results reveal strong performance for negative weight modular\nand quasi-modular forms, particularly those arising in exact black hole\ncounting formulae, with lower accuracy for positive weights and more\ncomplicated combinations of Jacobi theta functions. This study establishes a\nproof of concept for using machine learning to identify how data is organized\nin terms of modular symmetries in gravitational systems and suggests a pathway\ntoward automated detection and verification of symmetries in quantum gravity.", "AI": {"tldr": "Machine learning predicts modular weights from truncated expansions of automorphic forms, showing strong performance for negative weights and potential in quantum gravity symmetry detection.", "motivation": "To explore how machine learning can identify modular symmetries in gravitational systems and automate symmetry detection in quantum gravity.", "method": "Train feed-forward neural networks on Fourier coefficients of automorphic forms (Dedekind eta, Eisenstein series, Jacobi theta functions) to predict modular weights.", "result": "High accuracy for negative weight modular/quasi-modular forms, lower for positive weights or complex Jacobi theta combinations.", "conclusion": "Proof of concept for ML in modular symmetry identification, with implications for automated quantum gravity symmetry verification."}}
{"id": "2402.17410", "pdf": "https://arxiv.org/pdf/2402.17410", "abs": "https://arxiv.org/abs/2402.17410", "authors": ["Peter Dawood", "Felix Breuer", "Istvan Homolya", "Maximilian Gram", "Peter M. Jakob", "Moritz Zaiss", "Martin Blaimer"], "title": "Image space formalism of convolutional neural networks for k-space interpolation", "categories": ["cs.CV", "cs.AI", "cs.LG", "physics.med-ph"], "comment": null, "summary": "Purpose: Noise resilience in image reconstructions by scan-specific robust\nartificial neural networks for k-space interpolation (RAKI) is linked to\nnonlinear activations in k-space. To gain a deeper understanding of this\nrelationship, an image space formalism of RAKI is introduced for analyzing\nnoise propagation analytically, identifying and characterizing image\nreconstruction features and to describe the role of nonlinear activations in a\nhuman readable manner. Methods: The image space formalism for RAKI inference is\nemployed by expressing nonlinear activations in k-space as element-wise\nmultiplications with activation masks, which transform into convolutions in\nimage space. Jacobians of the de-aliased, coil-combined image relative to the\naliased coil images can be expressed algebraically, and thus, the noise\namplification is quantified analytically (g-factor maps). We analyze the role\nof nonlinearity for noise resilience by controlling the degree of nonlinearity\nin the reconstruction model via the negative slope parameter in leaky ReLU.\nResults: The analytical g-factor maps correspond with those obtained from Monte\nCarlo simulations and from an auto differentiation approach for in vivo brain\nimages. Apparent blurring and contrast loss artifacts are identified as\nimplications of enhanced noise resilience. These residual artifacts can be\ntraded against noise resilience by adjusting the degree of nonlinearity in the\nmodel (Tikhonov-like regularization) in case of limited training data. The\ninspection of image space activations reveals an autocorrelation pattern\nleading to a potential center artifact. Conclusion: The image space formalism\nof RAKI provides the means for analytical quantitative noisepropagation\nanalysis and human-readable visualization of the effects of the nonlinear\nactivation functions in k-space.", "AI": {"tldr": "The paper introduces an image space formalism for RAKI to analyze noise resilience, linking nonlinear activations in k-space to image reconstruction features and noise propagation.", "motivation": "To understand the relationship between noise resilience in RAKI and nonlinear activations in k-space, and to provide a human-readable analysis of these effects.", "method": "The image space formalism expresses nonlinear activations as convolutions, enabling analytical noise propagation analysis (g-factor maps) and control of nonlinearity via leaky ReLU parameters.", "result": "Analytical g-factor maps match simulations, revealing trade-offs between noise resilience and artifacts (blurring, contrast loss). Adjusting nonlinearity acts like Tikhonov regularization.", "conclusion": "The image space formalism enables analytical noise propagation analysis and visualization of nonlinear activation effects, aiding in understanding and optimizing RAKI reconstructions."}}
{"id": "2505.05812", "pdf": "https://arxiv.org/pdf/2505.05812", "abs": "https://arxiv.org/abs/2505.05812", "authors": ["Ashkan Pakzad", "Robert Turnbull", "Simon J. Mutch", "Thomas A. Leatham", "Darren Lockie", "Jane Fox", "Beena Kumar", "Daniel H\u00e4sermann", "Christopher J. Hall", "Anton Maksimenko", "Benedicta D. Arhatari", "Yakov I. Nesterets", "Amir Entezam", "Seyedamir T. Taba", "Patrick C. Brennan", "Timur E. Gureyev", "Harry M. Quiney"], "title": "Towards order of magnitude X-ray dose reduction in breast cancer imaging using phase contrast and deep denoising", "categories": ["physics.med-ph", "cs.CV"], "comment": "16 pages, 3 figures, 1 table", "summary": "Breast cancer is the most frequently diagnosed human cancer in the United\nStates at present. Early detection is crucial for its successful treatment.\nX-ray mammography and digital breast tomosynthesis are currently the main\nmethods for breast cancer screening. However, both have known limitations in\nterms of their sensitivity and specificity to breast cancers, while also\nfrequently causing patient discomfort due to the requirement for breast\ncompression. Breast computed tomography is a promising alternative, however, to\nobtain high-quality images, the X-ray dose needs to be sufficiently high. As\nthe breast is highly radiosensitive, dose reduction is particularly important.\nPhase-contrast computed tomography (PCT) has been shown to produce\nhigher-quality images at lower doses and has no need for breast compression. It\nis demonstrated in the present study that, when imaging full fresh mastectomy\nsamples with PCT, deep learning-based image denoising can further reduce the\nradiation dose by a factor of 16 or more, without any loss of image quality.\nThe image quality has been assessed both in terms of objective metrics, such as\nspatial resolution and contrast-to-noise ratio, as well as in an observer study\nby experienced medical imaging specialists and radiologists. This work was\ncarried out in preparation for live patient PCT breast cancer imaging,\ninitially at specialized synchrotron facilities.", "AI": {"tldr": "Deep learning-based denoising in phase-contrast computed tomography (PCT) reduces radiation dose by 16x without losing image quality for breast cancer imaging.", "motivation": "Current breast cancer screening methods (X-ray mammography, digital breast tomosynthesis) have limitations in sensitivity, specificity, and patient discomfort. PCT offers a promising alternative but requires dose reduction due to breast radiosensitivity.", "method": "PCT imaging of full fresh mastectomy samples combined with deep learning-based denoising to reduce radiation dose.", "result": "Radiation dose reduced by a factor of 16 or more without compromising image quality, validated by objective metrics and expert observer study.", "conclusion": "PCT with deep learning denoising is a viable low-dose, high-quality alternative for breast cancer imaging, paving the way for clinical trials."}}
{"id": "2505.05584", "pdf": "https://arxiv.org/pdf/2505.05584", "abs": "https://arxiv.org/abs/2505.05584", "authors": ["Mohamed Salah Bouafif", "Mohammad Hamdaqa", "Edward Zulkoski"], "title": "PRIMG : Efficient LLM-driven Test Generation Using Mutant Prioritization", "categories": ["cs.SE", "cs.LG"], "comment": null, "summary": "Mutation testing is a widely recognized technique for assessing and enhancing\nthe effectiveness of software test suites by introducing deliberate code\nmutations. However, its application often results in overly large test suites,\nas developers generate numerous tests to kill specific mutants, increasing\ncomputational overhead. This paper introduces PRIMG (Prioritization and\nRefinement Integrated Mutation-driven Generation), a novel framework for\nincremental and adaptive test case generation for Solidity smart contracts.\nPRIMG integrates two core components: a mutation prioritization module, which\nemploys a machine learning model trained on mutant subsumption graphs to\npredict the usefulness of surviving mutants, and a test case generation module,\nwhich utilizes Large Language Models (LLMs) to generate and iteratively refine\ntest cases to achieve syntactic and behavioral correctness.\n  We evaluated PRIMG on real-world Solidity projects from Code4Arena to assess\nits effectiveness in improving mutation scores and generating high-quality test\ncases. The experimental results demonstrate that PRIMG significantly reduces\ntest suite size while maintaining high mutation coverage. The prioritization\nmodule consistently outperformed random mutant selection, enabling the\ngeneration of high-impact tests with reduced computational effort. Furthermore,\nthe refining process enhanced the correctness and utility of LLM-generated\ntests, addressing their inherent limitations in handling edge cases and complex\nprogram logic.", "AI": {"tldr": "PRIMG is a framework for adaptive test case generation in Solidity smart contracts, combining mutation prioritization and LLM-driven refinement to reduce test suite size while maintaining high mutation coverage.", "motivation": "Mutation testing often leads to large test suites with high computational overhead. PRIMG aims to address this by optimizing test case generation and refinement.", "method": "PRIMG integrates mutation prioritization (using ML on mutant subsumption graphs) and test case generation (using LLMs for iterative refinement).", "result": "PRIMG reduces test suite size while maintaining high mutation coverage, outperforming random mutant selection and improving LLM-generated test correctness.", "conclusion": "PRIMG effectively balances test suite efficiency and mutation coverage, enhancing smart contract testing."}}
{"id": "2403.07887", "pdf": "https://arxiv.org/pdf/2403.07887", "abs": "https://arxiv.org/abs/2403.07887", "authors": ["Bhishma Dedhia", "Niraj K. Jha"], "title": "Neural Slot Interpreters: Grounding Object Semantics in Emergent Slot Representations", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Several accounts of human cognition posit that our intelligence is rooted in\nour ability to form abstract composable concepts, ground them in our\nenvironment, and reason over these grounded entities. This trifecta of human\nthought has remained elusive in modern intelligent machines. In this work, we\ninvestigate whether slot representations extracted from visual scenes serve as\nappropriate compositional abstractions for grounding and reasoning. We present\nthe Neural Slot Interpreter (NSI), which learns to ground object semantics in\nslots. At the core of NSI is a nested schema that uses simple syntax rules to\norganize the object semantics of a scene into object-centric schema primitives.\nThen, the NSI metric learns to ground primitives into slots through a\nstructured contrastive learning objective that reasons over the intermodal\nalignment. Experiments with a bi-modal object-property and scene retrieval task\ndemonstrate the grounding efficacy and interpretability of correspondences\nlearned by NSI. From a scene representation standpoint, we find that emergent\nNSI slots that move beyond the image grid by binding to spatial objects\nfacilitate improved visual grounding compared to conventional\nbounding-box-based approaches. From a data efficiency standpoint, we\nempirically validate that NSI learns more generalizable representations from a\nfixed amount of annotation data than the traditional approach. We also show\nthat the grounded slots surpass unsupervised slots in real-world object\ndiscovery and scale with scene complexity. Finally, we investigate the\ndownstream efficacy of the grounded slots. Vision Transformers trained on\ngrounding-aware NSI tokenizers using as few as ten tokens outperform\npatch-based tokens on challenging few-shot classification tasks.", "AI": {"tldr": "The paper introduces Neural Slot Interpreter (NSI), a method for grounding object semantics in slots, improving visual grounding and data efficiency over traditional approaches.", "motivation": "Human cognition relies on abstract, composable concepts, but modern machines struggle with this. The paper explores whether slot representations can serve as suitable abstractions for grounding and reasoning.", "method": "NSI uses a nested schema with syntax rules to organize object semantics into primitives, grounded into slots via structured contrastive learning. It evaluates grounding efficacy through bi-modal tasks.", "result": "NSI outperforms traditional methods in visual grounding, data efficiency, and generalizability. It also enhances few-shot classification when used with Vision Transformers.", "conclusion": "NSI demonstrates that slot-based representations improve grounding, interpretability, and downstream tasks, offering a promising direction for machine cognition."}}
{"id": "2505.05957", "pdf": "https://arxiv.org/pdf/2505.05957", "abs": "https://arxiv.org/abs/2505.05957", "authors": ["Peter R\u00f6seler", "Oliver Schaudt", "Helmut Berg", "Christian Bauckhage", "Matthias Koch"], "title": "Efficient Quantum Convolutional Neural Networks for Image Classification: Overcoming Hardware Constraints", "categories": ["quant-ph", "cs.CV", "cs.LG"], "comment": null, "summary": "While classical convolutional neural networks (CNNs) have revolutionized\nimage classification, the emergence of quantum computing presents new\nopportunities for enhancing neural network architectures. Quantum CNNs (QCNNs)\nleverage quantum mechanical properties and hold potential to outperform\nclassical approaches. However, their implementation on current noisy\nintermediate-scale quantum (NISQ) devices remains challenging due to hardware\nlimitations. In our research, we address this challenge by introducing an\nencoding scheme that significantly reduces the input dimensionality. We\ndemonstrate that a primitive QCNN architecture with 49 qubits is sufficient to\ndirectly process $28\\times 28$ pixel MNIST images, eliminating the need for\nclassical dimensionality reduction pre-processing. Additionally, we propose an\nautomated framework based on expressibility, entanglement, and complexity\ncharacteristics to identify the building blocks of QCNNs, parameterized quantum\ncircuits (PQCs). Our approach demonstrates advantages in accuracy and\nconvergence speed with a similar parameter count compared to both hybrid QCNNs\nand classical CNNs. We validated our experiments on IBM's Heron r2 quantum\nprocessor, achieving $96.08\\%$ classification accuracy, surpassing the\n$71.74\\%$ benchmark of traditional approaches under identical training\nconditions. These results represent one of the first implementations of image\nclassifications on real quantum hardware and validate the potential of quantum\ncomputing in this area.", "AI": {"tldr": "The paper introduces a quantum CNN (QCNN) architecture that processes MNIST images directly on NISQ devices, achieving higher accuracy than classical methods.", "motivation": "To overcome hardware limitations of NISQ devices and enhance neural network performance using quantum computing.", "method": "Proposes an encoding scheme to reduce input dimensionality and an automated framework for QCNN building blocks (PQCs).", "result": "Achieves 96.08% accuracy on MNIST, outperforming classical CNNs (71.74%) under the same conditions.", "conclusion": "Demonstrates the feasibility and potential of quantum computing for image classification tasks."}}
{"id": "2505.05600", "pdf": "https://arxiv.org/pdf/2505.05600", "abs": "https://arxiv.org/abs/2505.05600", "authors": ["Jos\u00e9 Gon\u00e7alves", "Miguel Silva", "Eva Maia", "Isabel Pra\u00e7a"], "title": "Enhancing Large Language Models with Faster Code Preprocessing for Vulnerability Detection", "categories": ["cs.SE", "cs.LG"], "comment": "10 pages, 3 tables, DCAI'25: Distributed Computing and Artificial\n  Intelligence 2025", "summary": "The application of Artificial Intelligence has become a powerful approach to\ndetecting software vulnerabilities. However, effective vulnerability detection\nrelies on accurately capturing the semantic structure of code and its\ncontextual relationships. Given that the same functionality can be implemented\nin various forms, a preprocessing tool that standardizes code representation is\nimportant. This tool must be efficient, adaptable across programming languages,\nand capable of supporting new transformations. To address this challenge, we\nbuild on the existing SCoPE framework and introduce SCoPE2, an enhanced version\nwith improved performance. We compare both versions in terms of processing time\nand memory usage and evaluate their impact on a Large Language Model (LLM) for\nvulnerability detection. Our results show a 97.3\\% reduction in processing time\nwith SCoPE2, along with an improved F1-score for the LLM, solely due to the\nrefined preprocessing approach.", "AI": {"tldr": "SCoPE2, an enhanced preprocessing tool for code standardization, reduces processing time by 97.3% and improves LLM-based vulnerability detection performance.", "motivation": "Effective vulnerability detection requires accurate semantic code structure and contextual relationship capture, necessitating efficient and adaptable preprocessing tools.", "method": "Builds on SCoPE framework to introduce SCoPE2, comparing processing time, memory usage, and impact on LLM-based vulnerability detection.", "result": "SCoPE2 achieves a 97.3% reduction in processing time and enhances the LLM's F1-score.", "conclusion": "SCoPE2 significantly improves preprocessing efficiency and boosts vulnerability detection performance."}}
{"id": "2403.16218", "pdf": "https://arxiv.org/pdf/2403.16218", "abs": "https://arxiv.org/abs/2403.16218", "authors": ["Juan Altmayer Pizzorno", "Emery D. Berger"], "title": "CoverUp: Effective High Coverage Test Generation for Python", "categories": ["cs.SE", "cs.AI", "cs.LG", "cs.PL", "I.2.0; D.2.5"], "comment": "21 pages; to appear at FSE'25", "summary": "Testing is an essential part of software development. Test generation tools\nattempt to automate the otherwise labor-intensive task of test creation, but\ngenerating high-coverage tests remains challenging. This paper proposes\nCoverUp, a novel approach to driving the generation of high-coverage Python\nregression tests. CoverUp combines coverage analysis, code context, and\nfeedback in prompts that iteratively guide the LLM to generate tests that\nimprove line and branch coverage. We evaluate our prototype CoverUp\nimplementation across a benchmark of challenging code derived from open-source\nPython projects and show that CoverUp substantially improves on the state of\nthe art. Compared to CodaMosa, a hybrid search/LLM-based test generator,\nCoverUp achieves a per-module median line+branch coverage of 80% (vs. 47%).\nCompared to MuTAP, a mutation- and LLM-based test generator, CoverUp achieves\nan overall line+branch coverage of 89% (vs. 77%). We also demonstrate that\nCoverUp's performance stems not only from the LLM used but from the combined\neffectiveness of its components.", "AI": {"tldr": "CoverUp is a novel approach for generating high-coverage Python regression tests by combining coverage analysis, code context, and iterative LLM feedback, outperforming existing tools like CodaMosa and MuTAP.", "motivation": "Automating high-coverage test generation remains challenging despite its importance in software development.", "method": "CoverUp integrates coverage analysis, code context, and iterative LLM prompts to guide test generation.", "result": "CoverUp achieves 80% median coverage (vs. 47% for CodaMosa) and 89% overall coverage (vs. 77% for MuTAP).", "conclusion": "CoverUp's effectiveness stems from its combined components, not just the LLM, making it a superior test generation tool."}}
{"id": "2505.06079", "pdf": "https://arxiv.org/pdf/2505.06079", "abs": "https://arxiv.org/abs/2505.06079", "authors": ["Shuaiyi Huang", "Mara Levy", "Anubhav Gupta", "Daniel Ekpo", "Ruijie Zheng", "Abhinav Shrivastava"], "title": "TREND: Tri-teaching for Robust Preference-based Reinforcement Learning with Demonstrations", "categories": ["cs.RO", "cs.CV"], "comment": "ICRA 2025", "summary": "Preference feedback collected by human or VLM annotators is often noisy,\npresenting a significant challenge for preference-based reinforcement learning\nthat relies on accurate preference labels. To address this challenge, we\npropose TREND, a novel framework that integrates few-shot expert demonstrations\nwith a tri-teaching strategy for effective noise mitigation. Our method trains\nthree reward models simultaneously, where each model views its small-loss\npreference pairs as useful knowledge and teaches such useful pairs to its peer\nnetwork for updating the parameters. Remarkably, our approach requires as few\nas one to three expert demonstrations to achieve high performance. We evaluate\nTREND on various robotic manipulation tasks, achieving up to 90% success rates\neven with noise levels as high as 40%, highlighting its effective robustness in\nhandling noisy preference feedback. Project page:\nhttps://shuaiyihuang.github.io/publications/TREND.", "AI": {"tldr": "TREND is a framework for mitigating noisy preference feedback in reinforcement learning by using few-shot expert demonstrations and a tri-teaching strategy.", "motivation": "Preference feedback is often noisy, which challenges preference-based reinforcement learning.", "method": "TREND trains three reward models simultaneously, using small-loss preference pairs for mutual teaching.", "result": "Achieves up to 90% success rates on robotic tasks, even with 40% noise.", "conclusion": "TREND is robust and effective for handling noisy preference feedback with minimal expert input."}}
{"id": "2505.05613", "pdf": "https://arxiv.org/pdf/2505.05613", "abs": "https://arxiv.org/abs/2505.05613", "authors": ["Achraf Azize", "Yulian Wu", "Junya Honda", "Francesco Orabona", "Shinji Ito", "Debabrota Basu"], "title": "Optimal Regret of Bernoulli Bandits under Global Differential Privacy", "categories": ["stat.ML", "cs.CR", "cs.IT", "cs.LG", "math.IT", "math.ST", "stat.TH"], "comment": null, "summary": "As sequential learning algorithms are increasingly applied to real life,\nensuring data privacy while maintaining their utilities emerges as a timely\nquestion. In this context, regret minimisation in stochastic bandits under\n$\\epsilon$-global Differential Privacy (DP) has been widely studied. Unlike\nbandits without DP, there is a significant gap between the best-known regret\nlower and upper bound in this setting, though they \"match\" in order. Thus, we\nrevisit the regret lower and upper bounds of $\\epsilon$-global DP algorithms\nfor Bernoulli bandits and improve both. First, we prove a tighter regret lower\nbound involving a novel information-theoretic quantity characterising the\nhardness of $\\epsilon$-global DP in stochastic bandits. Our lower bound\nstrictly improves on the existing ones across all $\\epsilon$ values. Then, we\nchoose two asymptotically optimal bandit algorithms, i.e. DP-KLUCB and DP-IMED,\nand propose their DP versions using a unified blueprint, i.e., (a) running in\narm-dependent phases, and (b) adding Laplace noise to achieve privacy. For\nBernoulli bandits, we analyse the regrets of these algorithms and show that\ntheir regrets asymptotically match our lower bound up to a constant arbitrary\nclose to 1. This refutes the conjecture that forgetting past rewards is\nnecessary to design optimal bandit algorithms under global DP. At the core of\nour algorithms lies a new concentration inequality for sums of Bernoulli\nvariables under Laplace mechanism, which is a new DP version of the Chernoff\nbound. This result is universally useful as the DP literature commonly treats\nthe concentrations of Laplace noise and random variables separately, while we\ncouple them to yield a tighter bound.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2405.11928", "pdf": "https://arxiv.org/pdf/2405.11928", "abs": "https://arxiv.org/abs/2405.11928", "authors": ["Yiqing Xu", "Jiayuan Mao", "Yilun Du", "Tomas Loz\u00e1no-P\u00e9rez", "Leslie Pack Kaelbling", "David Hsu"], "title": "\"Set It Up!\": Functional Object Arrangement with Compositional Generative Models", "categories": ["cs.RO", "cs.AI"], "comment": "10 pages main paper, 21 pages appendix, RSS 2024", "summary": "This paper studies the challenge of developing robots capable of\nunderstanding under-specified instructions for creating functional object\narrangements, such as \"set up a dining table for two\"; previous arrangement\napproaches have focused on much more explicit instructions, such as \"put object\nA on the table.\" We introduce a framework, SetItUp, for learning to interpret\nunder-specified instructions. SetItUp takes a small number of training examples\nand a human-crafted program sketch to uncover arrangement rules for specific\nscene types. By leveraging an intermediate graph-like representation of\nabstract spatial relationships among objects, SetItUp decomposes the\narrangement problem into two subproblems: i) learning the arrangement patterns\nfrom limited data and ii) grounding these abstract relationships into object\nposes. SetItUp leverages large language models (LLMs) to propose the abstract\nspatial relationships among objects in novel scenes as the constraints to be\nsatisfied; then, it composes a library of diffusion models associated with\nthese abstract relationships to find object poses that satisfy the constraints.\nWe validate our framework on a dataset comprising study desks, dining tables,\nand coffee tables, with the results showing superior performance in generating\nphysically plausible, functional, and aesthetically pleasing object\narrangements compared to existing models.", "AI": {"tldr": "SetItUp is a framework for robots to interpret under-specified instructions for object arrangements, outperforming existing models in plausibility, functionality, and aesthetics.", "motivation": "Previous approaches rely on explicit instructions, limiting robots' ability to handle vague commands like 'set up a dining table for two.'", "method": "SetItUp uses training examples and program sketches to learn arrangement rules, leveraging LLMs for abstract spatial relationships and diffusion models for object poses.", "result": "Validated on desks, dining, and coffee tables, SetItUp generates better arrangements than existing models.", "conclusion": "SetItUp advances robot capability in handling under-specified instructions for functional object arrangements."}}
{"id": "2505.06176", "pdf": "https://arxiv.org/pdf/2505.06176", "abs": "https://arxiv.org/abs/2505.06176", "authors": ["Niladri Shekhar Dutt", "Duygu Ceylan", "Niloy J. Mitra"], "title": "MonetGPT: Solving Puzzles Enhances MLLMs' Image Retouching Skills", "categories": ["cs.GR", "cs.CV", "cs.LG"], "comment": "Accepted at SIGGRAPH 2025 [ACM Transactions on Graphics]; Project\n  website: https://monetgpt.github.io", "summary": "Retouching is an essential task in post-manipulation of raw photographs.\nGenerative editing, guided by text or strokes, provides a new tool accessible\nto users but can easily change the identity of the original objects in\nunacceptable and unpredictable ways. In contrast, although traditional\nprocedural edits, as commonly supported by photoediting tools (e.g., Gimp,\nLightroom), are conservative, they are still preferred by professionals.\nUnfortunately, professional quality retouching involves many individual\nprocedural editing operations that is challenging to plan for most novices. In\nthis paper, we ask if a multimodal large language model (MLLM) can be taught to\ncritique raw photographs, suggest suitable remedies, and finally realize them\nwith a given set of pre-authored procedural image operations. We demonstrate\nthat MLLMs can be first made aware of the underlying image processing\noperations, by training them to solve specially designed visual puzzles.\nSubsequently, such an operation-aware MLLM can both plan and propose edit\nsequences. To facilitate training, given a set of expert-edited photos, we\nsynthesize a reasoning dataset by procedurally manipulating the expert edits\nand then grounding a pretrained LLM on the visual adjustments, to synthesize\nreasoning for finetuning. The proposed retouching operations are, by\nconstruction, understandable by the users, preserve object details and\nresolution, and can be optionally overridden. We evaluate our setup on a\nvariety of test examples and show advantages, in terms of explainability and\nidentity preservation, over existing generative and other procedural\nalternatives. Code, data, models, and supplementary results can be found via\nour project website at https://monetgpt.github.io.", "AI": {"tldr": "The paper proposes using a multimodal large language model (MLLM) to critique, suggest, and execute procedural edits for photo retouching, ensuring identity preservation and explainability.", "motivation": "Traditional procedural edits are preferred for their conservatism, but planning them is challenging for novices. Generative methods risk altering object identities unpredictably.", "method": "Train MLLMs to understand image operations via visual puzzles, then use them to plan and propose edit sequences. Synthesize a reasoning dataset from expert-edited photos for finetuning.", "result": "The MLLM-based approach outperforms generative and other procedural methods in explainability and identity preservation.", "conclusion": "MLLMs can effectively plan and execute procedural retouching edits, offering a user-friendly and predictable alternative to generative methods."}}
{"id": "2505.05619", "pdf": "https://arxiv.org/pdf/2505.05619", "abs": "https://arxiv.org/abs/2505.05619", "authors": ["Kalyan Nakka", "Jimmy Dani", "Ausmit Mondal", "Nitesh Saxena"], "title": "LiteLMGuard: Seamless and Lightweight On-Device Prompt Filtering for Safeguarding Small Language Models against Quantization-induced Risks and Vulnerabilities", "categories": ["cs.CR", "cs.LG"], "comment": "14 pages, 18 figures, and 4 tables", "summary": "The growing adoption of Large Language Models (LLMs) has influenced the\ndevelopment of their lighter counterparts-Small Language Models (SLMs)-to\nenable on-device deployment across smartphones and edge devices. These SLMs\noffer enhanced privacy, reduced latency, server-free functionality, and\nimproved user experience. However, due to resource constraints of on-device\nenvironment, SLMs undergo size optimization through compression techniques like\nquantization, which can inadvertently introduce fairness, ethical and privacy\nrisks. Critically, quantized SLMs may respond to harmful queries directly,\nwithout requiring adversarial manipulation, raising significant safety and\ntrust concerns.\n  To address this, we propose LiteLMGuard (LLMG), an on-device prompt guard\nthat provides real-time, prompt-level defense for quantized SLMs. Additionally,\nour prompt guard is designed to be model-agnostic such that it can be\nseamlessly integrated with any SLM, operating independently of underlying\narchitectures. Our LLMG formalizes prompt filtering as a deep learning\n(DL)-based prompt answerability classification task, leveraging semantic\nunderstanding to determine whether a query should be answered by any SLM. Using\nour curated dataset, Answerable-or-Not, we trained and fine-tuned several DL\nmodels and selected ELECTRA as the candidate, with 97.75% answerability\nclassification accuracy.\n  Our safety effectiveness evaluations demonstrate that LLMG defends against\nover 87% of harmful prompts, including both direct instruction and jailbreak\nattack strategies. We further showcase its ability to mitigate the Open\nKnowledge Attacks, where compromised SLMs provide unsafe responses without\nadversarial prompting. In terms of prompt filtering effectiveness, LLMG\nachieves near state-of-the-art filtering accuracy of 94%, with an average\nlatency of 135 ms, incurring negligible overhead for users.", "AI": {"tldr": "The paper introduces LiteLMGuard (LLMG), an on-device prompt guard for quantized Small Language Models (SLMs) to mitigate fairness, ethical, and privacy risks. It achieves high accuracy in filtering harmful prompts with minimal latency.", "motivation": "The rise of SLMs for on-device use introduces risks like unfairness and privacy breaches due to compression techniques. LLMG aims to address these by providing real-time, model-agnostic protection.", "method": "LLMG formalizes prompt filtering as a DL-based classification task using the ELECTRA model, trained on the Answerable-or-Not dataset.", "result": "LLMG defends against 87% of harmful prompts, achieves 94% filtering accuracy, and adds only 135 ms latency.", "conclusion": "LLMG effectively safeguards quantized SLMs, balancing safety and performance for on-device deployment."}}
{"id": "2405.15047", "pdf": "https://arxiv.org/pdf/2405.15047", "abs": "https://arxiv.org/abs/2405.15047", "authors": ["Kaizheng Wang", "Fabio Cuzzolin", "Keivan Shariatmadar", "David Moens", "Hans Hallez"], "title": "Credal Wrapper of Model Averaging for Uncertainty Estimation in Classification", "categories": ["cs.LG", "cs.AI"], "comment": "The 13th International Conference on Learning Representations (ICLR).\n  2025 [Spotlight]", "summary": "This paper presents an innovative approach, called credal wrapper, to\nformulating a credal set representation of model averaging for Bayesian neural\nnetworks (BNNs) and deep ensembles (DEs), capable of improving uncertainty\nestimation in classification tasks. Given a finite collection of single\npredictive distributions derived from BNNs or DEs, the proposed credal wrapper\napproach extracts an upper and a lower probability bound per class,\nacknowledging the epistemic uncertainty due to the availability of a limited\namount of distributions. Such probability intervals over classes can be mapped\non a convex set of probabilities (a credal set) from which, in turn, a unique\nprediction can be obtained using a transformation called intersection\nprobability transformation. In this article, we conduct extensive experiments\non several out-of-distribution (OOD) detection benchmarks, encompassing various\ndataset pairs (CIFAR10/100 vs SVHN/Tiny-ImageNet, CIFAR10 vs CIFAR10-C,\nCIFAR100 vs CIFAR100-C and ImageNet vs ImageNet-O) and using different network\narchitectures (such as VGG16, ResNet-18/50, EfficientNet B2, and ViT Base).\nCompared to the BNN and DE baselines, the proposed credal wrapper method\nexhibits superior performance in uncertainty estimation and achieves a lower\nexpected calibration error on corrupted data.", "AI": {"tldr": "The paper introduces a 'credal wrapper' method to improve uncertainty estimation in Bayesian neural networks and deep ensembles by representing model averaging as a credal set with upper and lower probability bounds.", "motivation": "To address epistemic uncertainty in classification tasks due to limited predictive distributions, enhancing uncertainty estimation and calibration.", "method": "The credal wrapper extracts probability bounds per class, maps them to a credal set, and uses an intersection probability transformation for unique predictions.", "result": "Outperforms BNN and DE baselines in uncertainty estimation and achieves lower expected calibration error on corrupted data across multiple benchmarks.", "conclusion": "The credal wrapper method effectively improves uncertainty estimation and calibration in classification tasks."}}
{"id": "2505.06227", "pdf": "https://arxiv.org/pdf/2505.06227", "abs": "https://arxiv.org/abs/2505.06227", "authors": ["Yufan Deng", "Yuhao Zhang", "Chen Geng", "Shangzhe Wu", "Jiajun Wu"], "title": "Anymate: A Dataset and Baselines for Learning 3D Object Rigging", "categories": ["cs.GR", "cs.CV"], "comment": "SIGGRAPH 2025. Project page: https://anymate3d.github.io/", "summary": "Rigging and skinning are essential steps to create realistic 3D animations,\noften requiring significant expertise and manual effort. Traditional attempts\nat automating these processes rely heavily on geometric heuristics and often\nstruggle with objects of complex geometry. Recent data-driven approaches show\npotential for better generality, but are often constrained by limited training\ndata. We present the Anymate Dataset, a large-scale dataset of 230K 3D assets\npaired with expert-crafted rigging and skinning information -- 70 times larger\nthan existing datasets. Using this dataset, we propose a learning-based\nauto-rigging framework with three sequential modules for joint, connectivity,\nand skinning weight prediction. We systematically design and experiment with\nvarious architectures as baselines for each module and conduct comprehensive\nevaluations on our dataset to compare their performance. Our models\nsignificantly outperform existing methods, providing a foundation for comparing\nfuture methods in automated rigging and skinning. Code and dataset can be found\nat https://anymate3d.github.io/.", "AI": {"tldr": "The paper introduces the Anymate Dataset, a large-scale dataset for rigging and skinning, and proposes a learning-based auto-rigging framework that outperforms existing methods.", "motivation": "Automating rigging and skinning is challenging due to reliance on geometric heuristics and limited training data. The Anymate Dataset addresses these limitations.", "method": "A learning-based framework with three sequential modules for joint, connectivity, and skinning weight prediction, evaluated on the Anymate Dataset.", "result": "The proposed models significantly outperform existing methods, setting a benchmark for future research.", "conclusion": "The Anymate Dataset and framework provide a foundation for advancing automated rigging and skinning."}}
{"id": "2505.05691", "pdf": "https://arxiv.org/pdf/2505.05691", "abs": "https://arxiv.org/abs/2505.05691", "authors": ["Ruiqi Ni", "Zherong Pan", "Ahmed H Qureshi"], "title": "Physics-informed Temporal Difference Metric Learning for Robot Motion Planning", "categories": ["cs.RO", "cs.LG"], "comment": "Accepted to ICLR 2025", "summary": "The motion planning problem involves finding a collision-free path from a\nrobot's starting to its target configuration. Recently, self-supervised\nlearning methods have emerged to tackle motion planning problems without\nrequiring expensive expert demonstrations. They solve the Eikonal equation for\ntraining neural networks and lead to efficient solutions. However, these\nmethods struggle in complex environments because they fail to maintain key\nproperties of the Eikonal equation, such as optimal value functions and\ngeodesic distances. To overcome these limitations, we propose a novel\nself-supervised temporal difference metric learning approach that solves the\nEikonal equation more accurately and enhances performance in solving complex\nand unseen planning tasks. Our method enforces Bellman's principle of\noptimality over finite regions, using temporal difference learning to avoid\nspurious local minima while incorporating metric learning to preserve the\nEikonal equation's essential geodesic properties. We demonstrate that our\napproach significantly outperforms existing self-supervised learning methods in\nhandling complex environments and generalizing to unseen environments, with\nrobot configurations ranging from 2 to 12 degrees of freedom (DOF).", "AI": {"tldr": "A novel self-supervised temporal difference metric learning method is proposed to improve motion planning by solving the Eikonal equation more accurately, outperforming existing methods in complex environments.", "motivation": "Existing self-supervised learning methods for motion planning struggle in complex environments due to inaccuracies in solving the Eikonal equation.", "method": "The approach combines temporal difference learning to avoid local minima and metric learning to preserve geodesic properties, enforcing Bellman's principle of optimality.", "result": "The method significantly outperforms existing techniques in complex and unseen environments, scaling up to 12 DOF.", "conclusion": "The proposed approach enhances motion planning accuracy and generalization, addressing limitations of prior self-supervised methods."}}
{"id": "2410.01966", "pdf": "https://arxiv.org/pdf/2410.01966", "abs": "https://arxiv.org/abs/2410.01966", "authors": ["Xinlong Hou", "Sen Shen", "Xueshen Li", "Xinran Gao", "Ziyi Huang", "Steven J. Holiday", "Matthew R. Cribbet", "Susan W. White", "Edward Sazonov", "Yu Gan"], "title": "Enhancing Screen Time Identification in Children with a Multi-View Vision Language Model and Screen Time Tracker", "categories": ["cs.CV", "cs.AI"], "comment": "Prepare for submission", "summary": "Being able to accurately monitor the screen exposure of young children is\nimportant for research on phenomena linked to screen use such as childhood\nobesity, physical activity, and social interaction. Most existing studies rely\nupon self-report or manual measures from bulky wearable sensors, thus lacking\nefficiency and accuracy in capturing quantitative screen exposure data. In this\nwork, we developed a novel sensor informatics framework that utilizes\negocentric images from a wearable sensor, termed the screen time tracker (STT),\nand a vision language model (VLM). In particular, we devised a multi-view VLM\nthat takes multiple views from egocentric image sequences and interprets screen\nexposure dynamically. We validated our approach by using a dataset of\nchildren's free-living activities, demonstrating significant improvement over\nexisting methods in plain vision language models and object detection models.\nResults supported the promise of this monitoring approach, which could optimize\nbehavioral research on screen exposure in children's naturalistic settings.", "AI": {"tldr": "A novel sensor informatics framework using egocentric images and a multi-view VLM improves accuracy in monitoring children's screen exposure.", "motivation": "Existing methods for monitoring screen exposure in children are inefficient and inaccurate, relying on self-reports or bulky sensors.", "method": "Developed a screen time tracker (STT) with a multi-view VLM to dynamically interpret screen exposure from egocentric images.", "result": "Outperformed plain VLM and object detection models in accuracy for children's free-living activities.", "conclusion": "The framework shows promise for optimizing behavioral research on screen exposure in naturalistic settings."}}
{"id": "2303.17051", "pdf": "https://arxiv.org/pdf/2303.17051", "abs": "https://arxiv.org/abs/2303.17051", "authors": ["Julio Silva-Rodr\u00edguez", "Jose Dolz", "Ismail Ben Ayed"], "title": "Towards Foundation Models and Few-Shot Parameter-Efficient Fine-Tuning for Volumetric Organ Segmentation", "categories": ["cs.CV"], "comment": "Accepted in Medical Image Analysis. The pre-trained model and\n  adaptation code is available at: https://github.com/jusiro/fewshot-finetuning", "summary": "The recent popularity of foundation models and the pre-train-and-adapt\nparadigm, where a large-scale model is transferred to downstream tasks, is\ngaining attention for volumetric medical image segmentation. However, current\ntransfer learning strategies devoted to full fine-tuning for transfer learning\nmay require significant resources and yield sub-optimal results when the\nlabeled data of the target task is scarce. This makes its applicability in real\nclinical settings challenging since these institutions are usually constrained\non data and computational resources to develop proprietary solutions. To\naddress this challenge, we formalize Few-Shot Efficient Fine-Tuning (FSEFT), a\nnovel and realistic scenario for adapting medical image segmentation foundation\nmodels. This setting considers the key role of both data- and\nparameter-efficiency during adaptation. Building on a foundation model\npre-trained on open-access CT organ segmentation sources, we propose leveraging\nParameter-Efficient Fine-Tuning and black-box Adapters to address such\nchallenges. Furthermore, novel efficient adaptation methodologies are\nintroduced in this work, which include Spatial black-box Adapters that are more\nappropriate for dense prediction tasks and constrained transductive inference,\nleveraging task-specific prior knowledge. Our comprehensive transfer learning\nexperiments confirm the suitability of foundation models in medical image\nsegmentation and unveil the limitations of popular fine-tuning strategies in\nfew-shot scenarios.", "AI": {"tldr": "Proposes Few-Shot Efficient Fine-Tuning (FSEFT) for adapting medical image segmentation foundation models with limited data and resources, using parameter-efficient methods and novel adapters.", "motivation": "Addresses challenges of full fine-tuning in medical image segmentation due to scarce labeled data and limited computational resources in clinical settings.", "method": "Introduces FSEFT, leveraging Parameter-Efficient Fine-Tuning and black-box Adapters, including Spatial black-box Adapters for dense prediction tasks.", "result": "Confirms foundation models' suitability for medical image segmentation and highlights limitations of traditional fine-tuning in few-shot scenarios.", "conclusion": "FSEFT offers a practical solution for adapting foundation models in resource-constrained medical settings, improving efficiency and performance."}}
{"id": "2505.05694", "pdf": "https://arxiv.org/pdf/2505.05694", "abs": "https://arxiv.org/abs/2505.05694", "authors": ["Ohida Binte Amin", "Varun Mishra", "Tinashe M. Tapera", "Robert Volpe", "Aarti Sathyanarayana"], "title": "Extending Stress Detection Reproducibility to Consumer Wearable Sensors", "categories": ["cs.HC", "cs.LG"], "comment": "Accepted at IEEE EMBC 2025", "summary": "Wearable sensors are widely used to collect physiological data and develop\nstress detection models. However, most studies focus on a single dataset,\nrarely evaluating model reproducibility across devices, populations, or study\nconditions. We previously assessed the reproducibility of stress detection\nmodels across multiple studies, testing models trained on one dataset against\nothers using heart rate (with R-R interval) and electrodermal activity (EDA).\nIn this study, we extended our stress detection reproducibility to consumer\nwearable sensors. We compared validated research-grade devices, to consumer\nwearables - Biopac MP160, Polar H10, Empatica E4, to the Garmin Forerunner 55s,\nassessing device-specific stress detection performance by conducting a new\nstress study on undergraduate students. Thirty-five students completed three\nstandardized stress-induction tasks in a lab setting. Biopac MP160 performed\nthe best, being consistent with our expectations of it as the gold standard,\nthough performance varied across devices and models. Combining heart rate\nvariability (HRV) and EDA enhanced stress prediction across most scenarios.\nHowever, Empatica E4 showed variability; while HRV and EDA improved stress\ndetection in leave-one-subject-out (LOSO) evaluations (AUROC up to 0.953),\ndevice-specific limitations led to underperformance when tested with our\npre-trained stress detection tool (AUROC 0.723), highlighting generalizability\nchallenges related to hardware-model compatibility. Garmin Forerunner 55s\ndemonstrated strong potential for real-world stress monitoring, achieving the\nbest mental arithmetic stress detection performance in LOSO (AUROC up to 0.961)\ncomparable to research-grade devices like Polar H10 (AUROC 0.954), and Empatica\nE4 (AUROC 0.905 with HRV-only model and AUROC 0.953 with HRV+EDA model), with\nthe added advantage of consumer-friendly wearability for free-living contexts.", "AI": {"tldr": "The study evaluates stress detection model reproducibility across consumer wearable sensors, comparing research-grade and consumer devices. Biopac MP160 performed best, while Garmin Forerunner 55s showed strong real-world potential.", "motivation": "Assess reproducibility of stress detection models across different wearable sensors and conditions, addressing gaps in prior single-dataset studies.", "method": "Conducted a stress study on 35 students using standardized tasks, comparing devices (Biopac MP160, Polar H10, Empatica E4, Garmin Forerunner 55s) and combining HRV and EDA for stress prediction.", "result": "Biopac MP160 performed best, but Garmin Forerunner 55s matched research-grade devices in some scenarios. Empatica E4 showed variability, highlighting hardware-model compatibility challenges.", "conclusion": "Combining HRV and EDA improves stress detection, but device-specific limitations affect generalizability. Consumer wearables like Garmin Forerunner 55s offer promising real-world applications."}}
{"id": "2410.09186", "pdf": "https://arxiv.org/pdf/2410.09186", "abs": "https://arxiv.org/abs/2410.09186", "authors": ["Noorbakhsh Amiri Golilarz", "Elias Hossain", "Abdoljalil Addeh", "Keyan Alexander Rahimi"], "title": "Learning Algorithms Made Simple", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "In this paper, we discuss learning algorithms and their importance in\ndifferent types of applications which includes training to identify important\npatterns and features in a straightforward, easy-to-understand manner. We will\nreview the main concepts of artificial intelligence (AI), machine learning\n(ML), deep learning (DL), and hybrid models. Some important subsets of Machine\nLearning algorithms such as supervised, unsupervised, and reinforcement\nlearning are also discussed in this paper. These techniques can be used for\nsome important tasks like prediction, classification, and segmentation.\nConvolutional Neural Networks (CNNs) are used for image and video processing\nand many more applications. We dive into the architecture of CNNs and how to\nintegrate CNNs with ML algorithms to build hybrid models. This paper explores\nthe vulnerability of learning algorithms to noise, leading to\nmisclassification. We further discuss the integration of learning algorithms\nwith Large Language Models (LLM) to generate coherent responses applicable to\nmany domains such as healthcare, marketing, and finance by learning important\npatterns from large volumes of data. Furthermore, we discuss the next\ngeneration of learning algorithms and how we may have an unified Adaptive and\nDynamic Network to perform important tasks. Overall, this article provides\nbrief overview of learning algorithms, exploring their current state,\napplications and future direction.", "AI": {"tldr": "The paper provides an overview of learning algorithms, their applications, and future directions, covering AI, ML, DL, and hybrid models, including CNNs and LLMs.", "motivation": "To review and explain the importance of learning algorithms in various applications, their current state, and future potential.", "method": "Discusses key concepts of AI, ML, DL, and hybrid models, including supervised, unsupervised, and reinforcement learning, and explores CNN architecture and integration with ML.", "result": "Highlights the use of learning algorithms for tasks like prediction and classification, their vulnerability to noise, and integration with LLMs for domain-specific applications.", "conclusion": "The paper summarizes the current state and future potential of learning algorithms, emphasizing their adaptability and dynamic evolution."}}
{"id": "2404.09957", "pdf": "https://arxiv.org/pdf/2404.09957", "abs": "https://arxiv.org/abs/2404.09957", "authors": ["Hanxue Gu", "Haoyu Dong", "Jichen Yang", "Maciej A. Mazurowski"], "title": "How to build the best medical image segmentation algorithm using foundation models: a comprehensive empirical study with Segment Anything Model", "categories": ["cs.CV", "cs.LG"], "comment": "Accepted for publication at the Journal of Machine Learning for\n  Biomedical Imaging (MELBA)", "summary": "Automated segmentation is a fundamental medical image analysis task, which\nenjoys significant advances due to the advent of deep learning. While\nfoundation models have been useful in natural language processing and some\nvision tasks for some time, the foundation model developed with image\nsegmentation in mind - Segment Anything Model (SAM) - has been developed only\nrecently and has shown similar promise. However, there are still no systematic\nanalyses or \"best-practice\" guidelines for optimal fine-tuning of SAM for\nmedical image segmentation. This work summarizes existing fine-tuning\nstrategies with various backbone architectures, model components, and\nfine-tuning algorithms across 18 combinations, and evaluates them on 17\ndatasets covering all common radiology modalities. Our study reveals that (1)\nfine-tuning SAM leads to slightly better performance than previous segmentation\nmethods, (2) fine-tuning strategies that use parameter-efficient learning in\nboth the encoder and decoder are superior to other strategies, (3) network\narchitecture has a small impact on final performance, (4) further training SAM\nwith self-supervised learning can improve final model performance. We also\ndemonstrate the ineffectiveness of some methods popular in the literature and\nfurther expand our experiments into few-shot and prompt-based settings. Lastly,\nwe released our code and MRI-specific fine-tuned weights, which consistently\nobtained superior performance over the original SAM, at\nhttps://github.com/mazurowski-lab/finetune-SAM.", "AI": {"tldr": "This paper systematically evaluates fine-tuning strategies for the Segment Anything Model (SAM) in medical image segmentation, identifying best practices and releasing optimized weights.", "motivation": "The lack of systematic guidelines for fine-tuning SAM in medical image segmentation prompted this study.", "method": "The authors evaluated 18 fine-tuning combinations across 17 datasets, testing backbone architectures, model components, and algorithms.", "result": "Fine-tuning SAM outperforms previous methods, with parameter-efficient learning in encoder and decoder being optimal. Self-supervised learning further improves performance.", "conclusion": "The study provides best practices for SAM fine-tuning in medical imaging and releases MRI-specific weights for improved performance."}}
{"id": "2505.05713", "pdf": "https://arxiv.org/pdf/2505.05713", "abs": "https://arxiv.org/abs/2505.05713", "authors": ["Jinkun Lin", "Ziheng Jiang", "Zuquan Song", "Sida Zhao", "Menghan Yu", "Zhanghan Wang", "Chenyuan Wang", "Zuocheng Shi", "Xiang Shi", "Wei Jia", "Zherui Liu", "Shuguang Wang", "Haibin Lin", "Xiu Liu", "Aurojit Panda", "Jinyang Li"], "title": "Understanding Stragglers in Large Model Training Using What-if Analysis", "categories": ["cs.DC", "cs.LG"], "comment": null, "summary": "Large language model (LLM) training is one of the most demanding distributed\ncomputations today, often requiring thousands of GPUs with frequent\nsynchronization across machines. Such a workload pattern makes it susceptible\nto stragglers, where the training can be stalled by few slow workers. At\nByteDance we find stragglers are not trivially always caused by hardware\nfailures, but can arise from multiple complex factors. This work aims to\npresent a comprehensive study on the straggler issues in LLM training, using a\nfive-month trace collected from our ByteDance LLM training cluster. The core\nmethodology is what-if analysis that simulates the scenario without any\nstragglers and contrasts with the actual case. We use this method to study the\nfollowing questions: (1) how often do stragglers affect training jobs, and what\neffect do they have on job performance; (2) do stragglers exhibit temporal or\nspatial patterns; and (3) what are the potential root causes for stragglers?", "AI": {"tldr": "The paper studies straggler issues in large language model (LLM) training, analyzing their frequency, impact, patterns, and root causes using a five-month trace and what-if analysis.", "motivation": "Stragglers in LLM training, caused by complex factors beyond hardware failures, can stall training. This work aims to comprehensively understand their impact and causes.", "method": "A five-month trace from ByteDance's LLM training cluster is analyzed using what-if analysis to simulate scenarios without stragglers and compare with actual cases.", "result": "The study examines straggler frequency, performance impact, temporal/spatial patterns, and potential root causes.", "conclusion": "The work provides insights into straggler issues in LLM training, aiding in mitigating their impact."}}
{"id": "2410.13415", "pdf": "https://arxiv.org/pdf/2410.13415", "abs": "https://arxiv.org/abs/2410.13415", "authors": ["Mikael Rinkinen", "Lauri Koskinen", "Olli Silven", "Mehdi Safarpour"], "title": "Shavette: Low Power Neural Network Acceleration via Algorithm-level Error Detection and Undervolting", "categories": ["cs.AR", "cs.AI"], "comment": null, "summary": "Reduced voltage operation is an effective technique for substantial energy\nefficiency improvement in digital circuits. This brief introduces a simple\napproach for enabling reduced voltage operation of Deep Neural Network (DNN)\naccelerators by mere software modifications. Conventional approaches for\nenabling reduced voltage operation e.g., Timing Error Detection (TED) systems,\nincur significant development costs and overheads, while not being applicable\nto the off-the-shelf components. Contrary to those, the solution proposed in\nthis paper relies on algorithm-based error detection, and hence, is implemented\nwith low development costs, does not require any circuit modifications, and is\neven applicable to commodity devices. By showcasing the solution through\nexperimenting on popular DNNs, i.e., LeNet and VGG16, on a GPU platform, we\ndemonstrate 18% to 25% energy saving with no accuracy loss of the models and\nnegligible throughput compromise (< 3.9%), considering the overheads from\nintegration of the error detection schemes into the DNN. The integration of\npresented algorithmic solution into the design is simpler when compared\nconventional TED based techniques that require extensive circuit-level\nmodifications, cell library characterizations or special support from the\ndesign tools.", "AI": {"tldr": "A software-based approach for enabling reduced voltage operation in DNN accelerators achieves 18-25% energy savings without accuracy loss or significant throughput compromise.", "motivation": "To improve energy efficiency in digital circuits without costly hardware modifications or off-the-shelf component limitations.", "method": "Algorithm-based error detection implemented via software modifications, tested on LeNet and VGG16 DNNs on a GPU platform.", "result": "18-25% energy savings, no accuracy loss, and <3.9% throughput compromise.", "conclusion": "The proposed solution is simpler and more cost-effective than conventional TED-based techniques, requiring no circuit modifications."}}
{"id": "2404.12734", "pdf": "https://arxiv.org/pdf/2404.12734", "abs": "https://arxiv.org/abs/2404.12734", "authors": ["Da Chang", "Yu Li"], "title": "Mixed Text Recognition with Efficient Parameter Fine-Tuning and Transformer", "categories": ["cs.CV"], "comment": null, "summary": "With the rapid development of OCR technology, mixed-scene text recognition\nhas become a key technical challenge. Although deep learning models have\nachieved significant results in specific scenarios, their generality and\nstability still need improvement, and the high demand for computing resources\naffects flexibility. To address these issues, this paper proposes DLoRA-TrOCR,\na parameter-efficient hybrid text spotting method based on a pre-trained OCR\nTransformer. By embedding a weight-decomposed DoRA module in the image encoder\nand a LoRA module in the text decoder, this method can be efficiently\nfine-tuned on various downstream tasks. Our method requires no more than 0.7\\%\ntrainable parameters, not only accelerating the training efficiency but also\nsignificantly improving the recognition accuracy and cross-dataset\ngeneralization performance of the OCR system in mixed text scenes. Experiments\nshow that our proposed DLoRA-TrOCR outperforms other parameter-efficient\nfine-tuning methods in recognizing complex scenes with mixed handwritten,\nprinted, and street text, achieving a CER of 4.02 on the IAM dataset, a F1\nscore of 94.29 on the SROIE dataset, and a WAR of 86.70 on the STR Benchmark,\nreaching state-of-the-art performance.", "AI": {"tldr": "DLoRA-TrOCR is a parameter-efficient hybrid text spotting method using DoRA and LoRA modules for fine-tuning, achieving high accuracy and generalization with minimal trainable parameters.", "motivation": "Addressing the limitations of deep learning models in mixed-scene text recognition, such as lack of generality, stability, and high computational demands.", "method": "Embeds weight-decomposed DoRA in the image encoder and LoRA in the text decoder for efficient fine-tuning on downstream tasks.", "result": "Achieves CER of 4.02 on IAM, F1 of 94.29 on SROIE, and WAR of 86.70 on STR Benchmark, outperforming other methods.", "conclusion": "DLoRA-TrOCR offers a scalable, efficient solution for mixed-scene text recognition with state-of-the-art performance."}}
{"id": "2505.05816", "pdf": "https://arxiv.org/pdf/2505.05816", "abs": "https://arxiv.org/abs/2505.05816", "authors": ["Antti Koskela", "Mohamed Seif", "Andrea J. Goldsmith"], "title": "On the Price of Differential Privacy for Spectral Clustering over Stochastic Block Models", "categories": ["cs.SI", "cs.CR", "cs.IT", "cs.LG", "math.IT"], "comment": null, "summary": "We investigate privacy-preserving spectral clustering for community detection\nwithin stochastic block models (SBMs). Specifically, we focus on edge\ndifferential privacy (DP) and propose private algorithms for community\nrecovery. Our work explores the fundamental trade-offs between the privacy\nbudget and the accurate recovery of community labels. Furthermore, we establish\ninformation-theoretic conditions that guarantee the accuracy of our methods,\nproviding theoretical assurances for successful community recovery under edge\nDP.", "AI": {"tldr": "Privacy-preserving spectral clustering for community detection in SBMs, focusing on edge DP and trade-offs between privacy and accuracy.", "motivation": "To address the need for privacy in community detection while maintaining accuracy under edge differential privacy.", "method": "Proposes private algorithms for community recovery, analyzing trade-offs between privacy budget and accuracy.", "result": "Establishes information-theoretic conditions ensuring accurate community recovery under edge DP.", "conclusion": "Theoretical guarantees for successful community recovery while preserving privacy."}}
{"id": "2412.04378", "pdf": "https://arxiv.org/pdf/2412.04378", "abs": "https://arxiv.org/abs/2412.04378", "authors": ["Yassine Ouali", "Adrian Bulat", "Alexandros Xenos", "Anestis Zaganidis", "Ioannis Maniadis Metaxas", "Brais Martinez", "Georgios Tzimiropoulos"], "title": "VladVA: Discriminative Fine-tuning of LVLMs", "categories": ["cs.CV", "cs.AI"], "comment": "Published at CVPR 2025", "summary": "Contrastively-trained Vision-Language Models (VLMs) like CLIP have become the\nde facto approach for discriminative vision-language representation learning.\nHowever, these models have limited language understanding, often exhibiting a\n\"bag of words\" behavior. At the same time, Large Vision-Language Models\n(LVLMs), which combine vision encoders with LLMs, have been shown to be capable\nof detailed vision-language reasoning, yet their autoregressive nature renders\nthem less suitable for discriminative tasks.\n  In this work, we propose to combine \"the best of both worlds\": a new training\napproach for discriminative fine-tuning of LVLMs that results in strong\ndiscriminative and compositional capabilities. Essentially, our approach\nconverts a generative LVLM into a discriminative one, unlocking its capability\nfor powerful image-text discrimination combined with enhanced language\nunderstanding.\n  Our contributions include (1) a carefully designed training/optimization\nframework that utilizes image-text pairs of variable length and granularity for\ntraining the model with both contrastive and next-token prediction losses. This\nis accompanied by ablation studies that justify the necessity of our\nframework's components; (2) a parameter-efficient adaptation method using a\ncombination of soft prompting and LoRA adapters; (3) significant improvements\nover state-of-the-art CLIP-like models of similar size, including standard\nimage-text retrieval benchmarks and notable gains in compositionality.", "AI": {"tldr": "The paper proposes a method to fine-tune Large Vision-Language Models (LVLMs) for discriminative tasks, combining their reasoning strengths with discriminative capabilities, outperforming CLIP-like models.", "motivation": "VLMs like CLIP lack deep language understanding, while LVLMs excel in reasoning but are less suited for discriminative tasks. The goal is to merge these strengths.", "method": "The approach involves discriminative fine-tuning of LVLMs using a framework with contrastive and next-token prediction losses, supported by parameter-efficient adaptation techniques like soft prompting and LoRA.", "result": "The method achieves significant improvements over CLIP-like models in image-text retrieval and compositionality benchmarks.", "conclusion": "The work successfully bridges the gap between generative and discriminative vision-language models, enhancing both capabilities."}}
{"id": "2405.13745", "pdf": "https://arxiv.org/pdf/2405.13745", "abs": "https://arxiv.org/abs/2405.13745", "authors": ["Qiujie Dong", "Huibiao Wen", "Rui Xu", "Shuangmin Chen", "Jiaran Zhou", "Shiqing Xin", "Changhe Tu", "Taku Komura", "Wenping Wang"], "title": "NeurCross: A Neural Approach to Computing Cross Fields for Quad Mesh Generation", "categories": ["cs.CV"], "comment": "SIGGRAPH 2025", "summary": "Quadrilateral mesh generation plays a crucial role in numerical simulations\nwithin Computer-Aided Design and Engineering (CAD/E). Producing high-quality\nquadrangulation typically requires satisfying four key criteria. First, the\nquadrilateral mesh should closely align with principal curvature directions.\nSecond, singular points should be strategically placed and effectively\nminimized. Third, the mesh should accurately conform to sharp feature edges.\nLastly, quadrangulation results should exhibit robustness against noise and\nminor geometric variations. Existing methods generally involve first computing\na regular cross field to represent quad element orientations across the\nsurface, followed by extracting a quadrilateral mesh aligned closely with this\ncross field. A primary challenge with this approach is balancing the smoothness\nof the cross field with its alignment to pre-computed principal curvature\ndirections, which are sensitive to small surface perturbations and often\nill-defined in spherical or planar regions.\n  To tackle this challenge, we propose NeurCross, a novel framework that\nsimultaneously optimizes a cross field and a neural signed distance function\n(SDF), whose zero-level set serves as a proxy of the input shape. Our joint\noptimization is guided by three factors: faithful approximation of the\noptimized SDF surface to the input surface, alignment between the cross field\nand the principal curvature field derived from the SDF surface, and smoothness\nof the cross field. Acting as an intermediary, the neural SDF contributes in\ntwo essential ways. First, it provides an alternative, optimizable base surface\nexhibiting more regular principal curvature directions for guiding the cross\nfield. Second, we leverage the Hessian matrix of the neural SDF to implicitly\nenforce cross field alignment with principal curvature directions...", "AI": {"tldr": "NeurCross is a framework for quadrilateral mesh generation that jointly optimizes a cross field and a neural SDF to improve alignment with principal curvatures and robustness.", "motivation": "Existing methods struggle with balancing cross field smoothness and alignment to principal curvatures, which are sensitive to noise and ill-defined in certain regions.", "method": "NeurCross simultaneously optimizes a cross field and a neural SDF, guided by surface approximation, curvature alignment, and cross field smoothness.", "result": "The neural SDF provides a more regular base surface for cross field alignment and leverages its Hessian matrix for implicit curvature alignment.", "conclusion": "NeurCross addresses key challenges in quad mesh generation by integrating neural SDF optimization with cross field alignment."}}
{"id": "2505.05842", "pdf": "https://arxiv.org/pdf/2505.05842", "abs": "https://arxiv.org/abs/2505.05842", "authors": ["Yun Xin", "Jianfeng Lu", "Shuqin Cao", "Gang Li", "Haozhao Wang", "Guanghui Wen"], "title": "DaringFed: A Dynamic Bayesian Persuasion Pricing for Online Federated Learning under Two-sided Incomplete Information", "categories": ["cs.GT", "cs.LG", "stat.ML"], "comment": null, "summary": "Online Federated Learning (OFL) is a real-time learning paradigm that\nsequentially executes parameter aggregation immediately for each random\narriving client. To motivate clients to participate in OFL, it is crucial to\noffer appropriate incentives to offset the training resource consumption.\nHowever, the design of incentive mechanisms in OFL is constrained by the\ndynamic variability of Two-sided Incomplete Information (TII) concerning\nresources, where the server is unaware of the clients' dynamically changing\ncomputational resources, while clients lack knowledge of the real-time\ncommunication resources allocated by the server. To incentivize clients to\nparticipate in training by offering dynamic rewards to each arriving client, we\ndesign a novel Dynamic Bayesian persuasion pricing for online Federated\nlearning (DaringFed) under TII. Specifically, we begin by formulating the\ninteraction between the server and clients as a dynamic signaling and pricing\nallocation problem within a Bayesian persuasion game, and then demonstrate the\nexistence of a unique Bayesian persuasion Nash equilibrium. By deriving the\noptimal design of DaringFed under one-sided incomplete information, we further\nanalyze the approximate optimal design of DaringFed with a specific bound under\nTII. Finally, extensive evaluation conducted on real datasets demonstrate that\nDaringFed optimizes accuracy and converges speed by 16.99%, while experiments\nwith synthetic datasets validate the convergence of estimate unknown values and\nthe effectiveness of DaringFed in improving the server's utility by up to\n12.6%.", "AI": {"tldr": "DaringFed is a dynamic incentive mechanism for Online Federated Learning (OFL) under Two-sided Incomplete Information (TII), improving accuracy and convergence speed by 16.99%.", "motivation": "To incentivize client participation in OFL by addressing dynamic resource variability and incomplete information.", "method": "Formulates a dynamic signaling and pricing problem as a Bayesian persuasion game, deriving optimal designs under TII.", "result": "Improves accuracy and convergence speed by 16.99%, and server utility by up to 12.6%.", "conclusion": "DaringFed effectively addresses TII challenges in OFL, enhancing performance and utility."}}
{"id": "2501.03119", "pdf": "https://arxiv.org/pdf/2501.03119", "abs": "https://arxiv.org/abs/2501.03119", "authors": ["Chao Feng", "Yuanzhe Gao", "Alberto Huertas Celdran", "Gerome Bovet", "Burkhard Stiller"], "title": "From Models to Network Topologies: A Topology Inference Attack in Decentralized Federated Learning", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Federated Learning (FL) is widely recognized as a privacy-preserving machine\nlearning paradigm due to its model-sharing mechanism that avoids direct data\nexchange. Nevertheless, model training leaves exploitable traces that can be\nused to infer sensitive information. In Decentralized FL (DFL), the topology,\ndefining how participants are connected, plays a crucial role in shaping the\nmodel's privacy, robustness, and convergence. However, the topology introduces\nan unexplored vulnerability: attackers can exploit it to infer participant\nrelationships and launch targeted attacks. This work uncovers the hidden risks\nof DFL topologies by proposing a novel Topology Inference Attack that infers\nthe topology solely from model behavior. A taxonomy of topology inference\nattacks is introduced, categorizing them by the attacker's capabilities and\nknowledge. Practical attack strategies are designed for various scenarios, and\nexperiments are conducted to identify key factors influencing attack success.\nThe results demonstrate that analyzing only the model of each node can\naccurately infer the DFL topology, highlighting a critical privacy risk in DFL\nsystems. These findings offer valuable insights for improving privacy\npreservation in DFL environments.", "AI": {"tldr": "The paper reveals a vulnerability in Decentralized Federated Learning (DFL) where attackers can infer participant relationships and launch targeted attacks by analyzing model behavior, highlighting critical privacy risks.", "motivation": "To uncover hidden risks in DFL topologies, as they can be exploited to infer sensitive information despite FL's privacy-preserving nature.", "method": "Proposes a Topology Inference Attack, categorizes attacks by attacker capabilities, designs practical attack strategies, and conducts experiments.", "result": "Demonstrates that DFL topologies can be accurately inferred from model behavior, exposing a significant privacy risk.", "conclusion": "The findings emphasize the need for improved privacy preservation in DFL systems."}}
{"id": "2407.06188", "pdf": "https://arxiv.org/pdf/2407.06188", "abs": "https://arxiv.org/abs/2407.06188", "authors": ["Yukang Cao", "Xinying Guo", "Mingyuan Zhang", "Haozhe Xie", "Chenyang Gu", "Ziwei Liu"], "title": "CrowdMoGen: Zero-Shot Text-Driven Collective Motion Generation", "categories": ["cs.CV"], "comment": "Project page: https://yukangcao.github.io/CrowdMoGen", "summary": "While recent advances in text-to-motion generation have shown promising\nresults, they typically assume all individuals are grouped as a single unit.\nScaling these methods to handle larger crowds and ensuring that individuals\nrespond appropriately to specific events remains a significant challenge. This\nis primarily due to the complexities of scene planning, which involves\norganizing groups, planning their activities, and coordinating interactions,\nand controllable motion generation. In this paper, we present CrowdMoGen, the\nfirst zero-shot framework for collective motion generation, which effectively\ngroups individuals and generates event-aligned motion sequences from text\nprompts. 1) Being limited by the available datasets for training an effective\nscene planning module in a supervised manner, we instead propose a crowd scene\nplanner that leverages pre-trained large language models (LLMs) to organize\nindividuals into distinct groups. While LLMs offer high-level guidance for\ngroup divisions, they lack the low-level understanding of human motion. To\naddress this, we further propose integrating an SMPL-based joint prior to\ngenerate context-appropriate activities, which consists of both joint\ntrajectories and textual descriptions. 2) Secondly, to incorporate the assigned\nactivities into the generative network, we introduce a collective motion\ngenerator that integrates the activities into a transformer-based network in a\njoint-wise manner, maintaining the spatial constraints during the multi-step\ndenoising process. Extensive experiments demonstrate that CrowdMoGen\nsignificantly outperforms previous approaches, delivering realistic,\nevent-driven motion sequences that are spatially coherent. As the first\nframework of collective motion generation, CrowdMoGen has the potential to\nadvance applications in urban simulation, crowd planning, and other large-scale\ninteractive environments.", "AI": {"tldr": "CrowdMoGen is a zero-shot framework for generating collective motion from text prompts, leveraging LLMs for scene planning and SMPL-based joint priors for motion generation, outperforming previous methods.", "motivation": "Existing text-to-motion methods assume single-unit groups, failing to handle larger crowds or event-specific responses due to scene planning and motion coordination complexities.", "method": "CrowdMoGen uses LLMs for high-level group organization and SMPL-based joint priors for context-appropriate motion. A transformer-based generator integrates activities spatially.", "result": "CrowdMoGen outperforms prior methods, producing realistic, event-aligned, and spatially coherent motion sequences.", "conclusion": "CrowdMoGen advances collective motion generation, with potential applications in urban simulation and crowd planning."}}
{"id": "2505.05851", "pdf": "https://arxiv.org/pdf/2505.05851", "abs": "https://arxiv.org/abs/2505.05851", "authors": ["Janik Kaden", "Maximilian Hilger", "Tim Schreiter", "Marius Schaab", "Thomas Graichen", "Andrey Rudenko", "Ulrich Heinkel", "Achim J. Lilienthal"], "title": "Collecting Human Motion Data in Large and Occlusion-Prone Environments using Ultra-Wideband Localization", "categories": ["cs.RO", "cs.HC", "cs.LG"], "comment": "accepted for presentation at the 7th Workshop on Long-term Human\n  Motion Prediction (LHMP) at International Conference on Robotics and\n  Automation (ICRA) 2025", "summary": "With robots increasingly integrating into human environments, understanding\nand predicting human motion is essential for safe and efficient interactions.\nModern human motion and activity prediction approaches require high quality and\nquantity of data for training and evaluation, usually collected from motion\ncapture systems, onboard or stationary sensors. Setting up these systems is\nchallenging due to the intricate setup of hardware components, extensive\ncalibration procedures, occlusions, and substantial costs. These constraints\nmake deploying such systems in new and large environments difficult and limit\ntheir usability for in-the-wild measurements. In this paper we investigate the\npossibility to apply the novel Ultra-Wideband (UWB) localization technology as\na scalable alternative for human motion capture in crowded and occlusion-prone\nenvironments. We include additional sensing modalities such as eye-tracking,\nonboard robot LiDAR and radar sensors, and record motion capture data as ground\ntruth for evaluation and comparison. The environment imitates a museum setup,\nwith up to four active participants navigating toward random goals in a natural\nway, and offers more than 130 minutes of multi-modal data. Our investigation\nprovides a step toward scalable and accurate motion data collection beyond\nvision-based systems, laying a foundation for evaluating sensing modalities\nlike UWB in larger and complex environments like warehouses, airports, or\nconvention centers.", "AI": {"tldr": "The paper explores Ultra-Wideband (UWB) technology as a scalable alternative to traditional motion capture systems for human motion prediction in crowded environments.", "motivation": "Traditional motion capture systems are costly, complex, and limited in scalability, hindering their use in large or dynamic environments.", "method": "The study uses UWB localization alongside eye-tracking, LiDAR, and radar sensors, with motion capture data as ground truth, in a museum-like setup with multiple participants.", "result": "Over 130 minutes of multi-modal data were collected, demonstrating UWB's potential for scalable motion data in occlusion-prone settings.", "conclusion": "UWB technology offers a promising foundation for motion data collection in complex environments like warehouses or airports, beyond vision-based systems."}}
{"id": "2501.13986", "pdf": "https://arxiv.org/pdf/2501.13986", "abs": "https://arxiv.org/abs/2501.13986", "authors": ["Vivek Bharadwaj", "Austin Glover", "Aydin Buluc", "James Demmel"], "title": "An Efficient Sparse Kernel Generator for O(3)-Equivariant Deep Networks", "categories": ["cs.LG", "cs.AI"], "comment": "To appear in the Proceedings of the 2025 SIAM Conference on Applied\n  and Computational Discrete Algorithms. 15 pages, 10 figures, 4 tables", "summary": "Rotation equivariant graph neural networks, i.e. networks designed to\nguarantee certain geometric relations between their inputs and outputs, yield\nstate of the art performance on spatial deep learning tasks. They exhibit high\ndata efficiency during training and significantly reduced inference time for\ninteratomic potential calculations compared to classical approaches. Key to\nthese models is the Clebsch-Gordon (CG) tensor product, a kernel that contracts\ntwo dense feature vectors with a highly-structured sparse tensor to produce a\ndense output vector. The operation, which may be repeated millions of times for\ntypical equivariant models, is a costly and inefficient bottleneck. We\nintroduce a GPU sparse kernel generator for the CG tensor product that provides\nsignificant speedups over the best existing open and closed-source\nimplementations. Our implementation achieves high performance by carefully\nmanaging the limited GPU shared memory through static analysis at model\ncompile-time, minimizing reads and writes to global memory. We break the tensor\nproduct into a series of smaller kernels with operands that fit entirely into\nregisters, enabling us to emit long arithmetic instruction streams that\nmaximize instruction-level parallelism. By fusing the CG tensor product with a\nsubsequent graph convolution, we reduce both intermediate storage and global\nmemory traffic over naive approaches that duplicate input data. We also provide\noptimized kernels for the gradient of the CG tensor product and a novel\nidentity for the higher partial derivatives required to predict interatomic\nforces. Our kernels offer up to 1.3x speedup over NVIDIA's closed-source\ncuEquivariance package, as well as 10x speedup over the widely-used e3nn\npackage. In FP64 precision, we offer up to 6.2x inference-time speedup for the\nMACE chemistry foundation model over the original unoptimized version.", "AI": {"tldr": "A GPU sparse kernel generator for the Clebsch-Gordon (CG) tensor product in rotation equivariant graph neural networks achieves significant speedups over existing implementations, improving efficiency and performance.", "motivation": "The CG tensor product is a costly bottleneck in rotation equivariant graph neural networks, limiting efficiency and performance.", "method": "Introduces a GPU sparse kernel generator that optimizes memory usage, minimizes global memory traffic, and fuses operations for efficiency.", "result": "Achieves up to 1.3x speedup over NVIDIA's cuEquivariance and 10x over e3nn, with a 6.2x inference-time speedup for MACE in FP64 precision.", "conclusion": "The optimized CG tensor product implementation significantly enhances performance and efficiency for spatial deep learning tasks."}}
{"id": "2407.11243", "pdf": "https://arxiv.org/pdf/2407.11243", "abs": "https://arxiv.org/abs/2407.11243", "authors": ["Mang Ning", "Albert Ali Salah", "Itir Onal Ertugrul"], "title": "Representation Learning and Identity Adversarial Training for Facial Behavior Understanding", "categories": ["cs.CV"], "comment": "FG 2025", "summary": "Facial Action Unit (AU) detection has gained significant attention as it\nenables the breakdown of complex facial expressions into individual muscle\nmovements. In this paper, we revisit two fundamental factors in AU detection:\ndiverse and large-scale data and subject identity regularization. Motivated by\nrecent advances in foundation models, we highlight the importance of data and\nintroduce Face9M, a diverse dataset comprising 9 million facial images from\nmultiple public sources. Pretraining a masked autoencoder on Face9M yields\nstrong performance in AU detection and facial expression tasks. More\nimportantly, we emphasize that the Identity Adversarial Training (IAT) has not\nbeen well explored in AU tasks. To fill this gap, we first show that subject\nidentity in AU datasets creates shortcut learning for the model and leads to\nsub-optimal solutions to AU predictions. Secondly, we demonstrate that strong\nIAT regularization is necessary to learn identity-invariant features. Finally,\nwe elucidate the design space of IAT and empirically show that IAT circumvents\nthe identity-based shortcut learning and results in a better solution. Our\nproposed methods, Facial Masked Autoencoder (FMAE) and IAT, are simple, generic\nand effective. Remarkably, the proposed FMAE-IAT approach achieves new\nstate-of-the-art F1 scores on BP4D (67.1\\%), BP4D+ (66.8\\%), and DISFA (70.1\\%)\ndatabases, significantly outperforming previous work. We release the code and\nmodel at https://github.com/forever208/FMAE-IAT.", "AI": {"tldr": "The paper introduces Face9M, a diverse dataset, and proposes Facial Masked Autoencoder (FMAE) and Identity Adversarial Training (IAT) for improved AU detection, achieving state-of-the-art results.", "motivation": "To address the lack of diverse, large-scale data and unexplored identity regularization in AU detection, leveraging foundation models and adversarial training.", "method": "Pretrain a masked autoencoder on Face9M and apply IAT to learn identity-invariant features, avoiding shortcut learning.", "result": "FMAE-IAT achieves new state-of-the-art F1 scores on BP4D, BP4D+, and DISFA datasets.", "conclusion": "FMAE and IAT are simple, generic, and effective methods for AU detection, with released code and models for reproducibility."}}
{"id": "2505.05872", "pdf": "https://arxiv.org/pdf/2505.05872", "abs": "https://arxiv.org/abs/2505.05872", "authors": ["Aqsa Shabbir", "Halil \u0130brahim Kanpak", "Alptekin K\u00fcp\u00e7\u00fc", "Sinem Sav"], "title": "A Taxonomy of Attacks and Defenses in Split Learning", "categories": ["cs.CR", "cs.LG"], "comment": null, "summary": "Split Learning (SL) has emerged as a promising paradigm for distributed deep\nlearning, allowing resource-constrained clients to offload portions of their\nmodel computation to servers while maintaining collaborative learning. However,\nrecent research has demonstrated that SL remains vulnerable to a range of\nprivacy and security threats, including information leakage, model inversion,\nand adversarial attacks. While various defense mechanisms have been proposed, a\nsystematic understanding of the attack landscape and corresponding\ncountermeasures is still lacking. In this study, we present a comprehensive\ntaxonomy of attacks and defenses in SL, categorizing them along three key\ndimensions: employed strategies, constraints, and effectiveness. Furthermore,\nwe identify key open challenges and research gaps in SL based on our\nsystematization, highlighting potential future directions.", "AI": {"tldr": "A study on Split Learning (SL) explores its vulnerabilities to privacy and security threats, categorizes attacks and defenses, and identifies research gaps.", "motivation": "SL is a promising distributed deep learning paradigm but faces privacy and security threats, necessitating a systematic analysis.", "method": "The study presents a taxonomy of attacks and defenses in SL, categorizing them by strategies, constraints, and effectiveness.", "result": "A comprehensive understanding of SL's attack landscape and defenses is provided, along with identified research gaps.", "conclusion": "The study highlights future directions for improving SL's security and privacy."}}
{"id": "2502.08149", "pdf": "https://arxiv.org/pdf/2502.08149", "abs": "https://arxiv.org/abs/2502.08149", "authors": ["Cuong Manh Hoang", "Yeejin Lee", "Byeongkeun Kang"], "title": "Generalized Class Discovery in Instance Segmentation", "categories": ["cs.CV", "cs.AI"], "comment": "AAAI 2025", "summary": "This work addresses the task of generalized class discovery (GCD) in instance\nsegmentation. The goal is to discover novel classes and obtain a model capable\nof segmenting instances of both known and novel categories, given labeled and\nunlabeled data. Since the real world contains numerous objects with long-tailed\ndistributions, the instance distribution for each class is inherently\nimbalanced. To address the imbalanced distributions, we propose an\ninstance-wise temperature assignment (ITA) method for contrastive learning and\nclass-wise reliability criteria for pseudo-labels. The ITA method relaxes\ninstance discrimination for samples belonging to head classes to enhance GCD.\nThe reliability criteria are to avoid excluding most pseudo-labels for tail\nclasses when training an instance segmentation network using pseudo-labels from\nGCD. Additionally, we propose dynamically adjusting the criteria to leverage\ndiverse samples in the early stages while relying only on reliable\npseudo-labels in the later stages. We also introduce an efficient soft\nattention module to encode object-specific representations for GCD. Finally, we\nevaluate our proposed method by conducting experiments on two settings:\nCOCO$_{half}$ + LVIS and LVIS + Visual Genome. The experimental results\ndemonstrate that the proposed method outperforms previous state-of-the-art\nmethods.", "AI": {"tldr": "Proposes an instance-wise temperature assignment (ITA) method and class-wise reliability criteria for generalized class discovery (GCD) in instance segmentation, addressing imbalanced distributions and outperforming state-of-the-art methods.", "motivation": "Real-world objects have long-tailed distributions, making instance segmentation challenging for both known and novel classes. The goal is to improve GCD by handling imbalanced data.", "method": "Introduces ITA for contrastive learning, class-wise reliability criteria for pseudo-labels, and a soft attention module. Dynamically adjusts criteria to balance diversity and reliability.", "result": "Outperforms previous state-of-the-art methods on COCO$_{half}$ + LVIS and LVIS + Visual Genome datasets.", "conclusion": "The proposed ITA and reliability criteria effectively address imbalanced distributions, enhancing GCD performance in instance segmentation."}}
{"id": "2407.16291", "pdf": "https://arxiv.org/pdf/2407.16291", "abs": "https://arxiv.org/abs/2407.16291", "authors": ["Hongyang Li", "Hao Zhang", "Shilong Liu", "Zhaoyang Zeng", "Feng Li", "Tianhe Ren", "Bohan Li", "Lei Zhang"], "title": "TAPTRv2: Attention-based Position Update Improves Tracking Any Point", "categories": ["cs.CV", "cs.RO"], "comment": null, "summary": "In this paper, we present TAPTRv2, a Transformer-based approach built upon\nTAPTR for solving the Tracking Any Point (TAP) task. TAPTR borrows designs from\nDEtection TRansformer (DETR) and formulates each tracking point as a point\nquery, making it possible to leverage well-studied operations in DETR-like\nalgorithms. TAPTRv2 improves TAPTR by addressing a critical issue regarding its\nreliance on cost-volume,which contaminates the point query\\'s content feature\nand negatively impacts both visibility prediction and cost-volume computation.\nIn TAPTRv2, we propose a novel attention-based position update (APU) operation\nand use key-aware deformable attention to realize. For each query, this\noperation uses key-aware attention weights to combine their corresponding\ndeformable sampling positions to predict a new query position. This design is\nbased on the observation that local attention is essentially the same as\ncost-volume, both of which are computed by dot-production between a query and\nits surrounding features. By introducing this new operation, TAPTRv2 not only\nremoves the extra burden of cost-volume computation, but also leads to a\nsubstantial performance improvement. TAPTRv2 surpasses TAPTR and achieves\nstate-of-the-art performance on many challenging datasets, demonstrating the\nsuperiority", "AI": {"tldr": "TAPTRv2 improves TAPTR by replacing cost-volume reliance with an attention-based position update (APU) operation, enhancing performance and achieving state-of-the-art results.", "motivation": "The reliance on cost-volume in TAPTR negatively impacts visibility prediction and cost-volume computation, necessitating a more efficient solution.", "method": "TAPTRv2 introduces a novel APU operation using key-aware deformable attention to update query positions, eliminating the need for cost-volume.", "result": "TAPTRv2 outperforms TAPTR and achieves state-of-the-art performance on challenging datasets.", "conclusion": "The APU operation in TAPTRv2 effectively replaces cost-volume, improving efficiency and performance in the Tracking Any Point task."}}
{"id": "2505.05922", "pdf": "https://arxiv.org/pdf/2505.05922", "abs": "https://arxiv.org/abs/2505.05922", "authors": ["Haoqi Wu", "Wei Dai", "Li Wang", "Qiang Yan"], "title": "CAPE: Context-Aware Prompt Perturbation Mechanism with Differential Privacy", "categories": ["cs.CR", "cs.LG"], "comment": "to be published in ICML 2025", "summary": "Large Language Models (LLMs) have gained significant popularity due to their\nremarkable capabilities in text understanding and generation. However, despite\ntheir widespread deployment in inference services such as ChatGPT, concerns\nabout the potential leakage of sensitive user data have arisen. Existing\nsolutions primarily rely on privacy-enhancing technologies to mitigate such\nrisks, facing the trade-off among efficiency, privacy, and utility. To narrow\nthis gap, we propose Cape, a context-aware prompt perturbation mechanism based\non differential privacy, to enable efficient inference with an improved\nprivacy-utility trade-off. Concretely, we introduce a hybrid utility function\nthat better captures the token similarity. Additionally, we propose a\nbucketized sampling mechanism to handle large sampling space, which might lead\nto long-tail phenomenons. Extensive experiments across multiple datasets, along\nwith ablation studies, demonstrate that Cape achieves a better privacy-utility\ntrade-off compared to prior state-of-the-art works.", "AI": {"tldr": "Cape is a context-aware prompt perturbation mechanism using differential privacy to improve privacy-utility trade-offs in LLM inference services.", "motivation": "Address privacy concerns in LLM inference services like ChatGPT, where existing solutions struggle with efficiency, privacy, and utility trade-offs.", "method": "Proposes Cape, combining a hybrid utility function for token similarity and bucketized sampling to handle large sampling spaces.", "result": "Cape outperforms prior works in privacy-utility trade-off, validated by experiments and ablation studies.", "conclusion": "Cape effectively balances privacy and utility in LLM inference, offering a practical solution for sensitive data protection."}}
{"id": "2502.10436", "pdf": "https://arxiv.org/pdf/2502.10436", "abs": "https://arxiv.org/abs/2502.10436", "authors": ["Tommaso Mencattini", "Adrian Robert Minut", "Donato Crisostomi", "Andrea Santilli", "Emanuele Rodol\u00e0"], "title": "MERGE$^3$: Efficient Evolutionary Merging on Consumer-grade GPUs", "categories": ["cs.NE", "cs.AI", "cs.LG"], "comment": "In Proceedings of The Forty-Second International Conference on\n  Machine Learning (ICML 2025)", "summary": "Evolutionary model merging enables the creation of high-performing multi-task\nmodels but remains computationally prohibitive for consumer hardware. We\nintroduce MERGE$^3$, an efficient framework that makes evolutionary merging\nfeasible on a single GPU by reducing fitness computation costs 50$\\times$ while\npreserving performance. MERGE$^3$ achieves this by Extracting a reduced dataset\nfor evaluation, Estimating model abilities using Item Response Theory (IRT),\nand Evolving optimal merges via IRT-based performance estimators. Our method\nenables state-of-the-art multilingual and cross-lingual merging, transferring\nknowledge across languages with significantly lower computational overhead. We\nprovide theoretical guarantees and an open-source library, democratizing\nhigh-quality model merging.", "AI": {"tldr": "MERGE$^3$ is an efficient framework for evolutionary model merging on a single GPU, reducing fitness computation costs by 50x while maintaining performance.", "motivation": "Evolutionary model merging is computationally expensive for consumer hardware, limiting accessibility.", "method": "MERGE$^3$ uses a reduced dataset, IRT for ability estimation, and IRT-based performance estimators for optimal merges.", "result": "Achieves state-of-the-art multilingual and cross-lingual merging with lower computational overhead.", "conclusion": "MERGE$^3$ democratizes high-quality model merging with theoretical guarantees and an open-source library."}}
{"id": "2409.07967", "pdf": "https://arxiv.org/pdf/2409.07967", "abs": "https://arxiv.org/abs/2409.07967", "authors": ["Ling Xing", "Hongyu Qu", "Rui Yan", "Xiangbo Shu", "Jinhui Tang"], "title": "Locality-aware Cross-modal Correspondence Learning for Dense Audio-Visual Events Localization", "categories": ["cs.CV"], "comment": null, "summary": "Dense-localization Audio-Visual Events (DAVE) aims to identify time\nboundaries and corresponding categories for events that are both audible and\nvisible in a long video, where events may co-occur and exhibit varying\ndurations. However, complex audio-visual scenes often involve asynchronization\nbetween modalities, making accurate localization challenging. Existing DAVE\nsolutions extract audio and visual features through unimodal encoders, and fuse\nthem via dense cross-modal interaction. However, independent unimodal encoding\nstruggles to emphasize shared semantics between modalities without cross-modal\nguidance, while dense cross-modal attention may over-attend to semantically\nunrelated audio-visual features. To address these problems, we present LoCo, a\nLocality-aware cross-modal Correspondence learning framework for DAVE. LoCo\nleverages the local temporal continuity of audio-visual events as important\nguidance to filter irrelevant cross-modal signals and enhance cross-modal\nalignment throughout both unimodal and cross-modal encoding stages. i)\nSpecifically, LoCo applies Local Correspondence Feature (LCF) Modulation to\nenforce unimodal encoders to focus on modality-shared semantics by modulating\nagreement between audio and visual features based on local cross-modal\ncoherence. ii) To better aggregate cross-modal relevant features, we further\ncustomize Local Adaptive Cross-modal (LAC) Interaction, which dynamically\nadjusts attention regions in a data-driven manner. This adaptive mechanism\nfocuses attention on local event boundaries and accommodates varying event\ndurations. By incorporating LCF and LAC, LoCo provides solid performance gains\nand outperforms existing DAVE methods.", "AI": {"tldr": "LoCo improves DAVE by using local temporal continuity to filter irrelevant signals and enhance cross-modal alignment, outperforming existing methods.", "motivation": "Existing DAVE methods struggle with asynchronization and irrelevant feature attention, needing better cross-modal alignment.", "method": "LoCo uses Local Correspondence Feature (LCF) Modulation and Local Adaptive Cross-modal (LAC) Interaction to focus on shared semantics and adjust attention dynamically.", "result": "LoCo achieves solid performance gains and outperforms existing DAVE methods.", "conclusion": "LoCo effectively addresses challenges in DAVE by leveraging local temporal continuity and adaptive cross-modal interaction."}}
{"id": "2505.05956", "pdf": "https://arxiv.org/pdf/2505.05956", "abs": "https://arxiv.org/abs/2505.05956", "authors": ["Xiyu Wang", "Gilberto Berardinelli", "Hei Victor Cheng", "Petar Popovski", "Ramoni Adeogun"], "title": "Multi-User Beamforming with Deep Reinforcement Learning in Sensing-Aided Communication", "categories": ["eess.SP", "cs.LG", "cs.NI"], "comment": "Accepted for Presentation at IEEE EuCNC & 6G Summit 2025", "summary": "Mobile users are prone to experience beam failure due to beam drifting in\nmillimeter wave (mmWave) communications. Sensing can help alleviate beam\ndrifting with timely beam changes and low overhead since it does not need user\nfeedback. This work studies the problem of optimizing sensing-aided\ncommunication by dynamically managing beams allocated to mobile users. A\nmulti-beam scheme is introduced, which allocates multiple beams to the users\nthat need an update on the angle of departure (AoD) estimates and a single beam\nto the users that have satisfied AoD estimation precision. A deep reinforcement\nlearning (DRL) assisted method is developed to optimize the beam allocation\npolicy, relying only upon the sensing echoes. For comparison, a heuristic\nAoD-based method using approximated Cram\\'er-Rao lower bound (CRLB) for\nallocation is also presented. Both methods require neither user feedback nor\nprior state evolution information. Results show that the DRL-assisted method\nachieves a considerable gain in throughput than the conventional beam sweeping\nmethod and the AoD-based method, and it is robust to different user speeds.", "AI": {"tldr": "The paper proposes a DRL-assisted method to optimize beam allocation in mmWave communications, improving throughput and robustness to user speeds without needing user feedback.", "motivation": "Beam failure in mmWave communications due to beam drifting can degrade performance. Sensing can mitigate this by enabling timely beam changes with low overhead.", "method": "A multi-beam scheme allocates beams dynamically: multiple beams for users needing AoD updates and a single beam for those with precise AoD estimates. A DRL-assisted method optimizes allocation using sensing echoes, compared to a heuristic AoD-based method.", "result": "The DRL-assisted method outperforms conventional beam sweeping and the AoD-based method in throughput and is robust to varying user speeds.", "conclusion": "DRL-assisted beam allocation enhances mmWave communication efficiency without requiring user feedback or prior state information."}}
{"id": "2503.11711", "pdf": "https://arxiv.org/pdf/2503.11711", "abs": "https://arxiv.org/abs/2503.11711", "authors": ["Ehsan Latif", "Xiaoming Zhai"], "title": "Privacy-Preserved Automated Scoring using Federated Learning for Educational Research", "categories": ["cs.LG", "cs.AI"], "comment": "Accepted to AIED25", "summary": "Data privacy remains a critical concern in educational research, requiring\nstrict adherence to ethical standards and regulatory protocols. While\ntraditional approaches rely on anonymization and centralized data collection,\nthey often expose raw student data to security vulnerabilities and impose\nsubstantial logistical overhead. In this study, we propose a federated learning\n(FL) framework for automated scoring of educational assessments that eliminates\nthe need to share sensitive data across institutions. Our approach leverages\nparameter-efficient fine-tuning of large language models (LLMs) with Low-Rank\nAdaptation (LoRA), enabling each client (school) to train locally while sharing\nonly optimized model updates. To address data heterogeneity, we implement an\nadaptive weighted aggregation strategy that considers both client performance\nand data volume. We benchmark our model against two state-of-the-art FL methods\nand a centralized learning baseline using NGSS-aligned multi-label science\nassessment data from nine middle schools. Results show that our model achieves\nthe highest accuracy (94.5%) among FL approaches, and performs within 0.5-1.0\npercentage points of the centralized model on these metrics. Additionally, it\nachieves comparable rubric-level scoring accuracy, with only a 1.3% difference\nin rubric match and a lower score deviation (MAE), highlighting its\neffectiveness in preserving both prediction quality and interpretability.", "AI": {"tldr": "A federated learning framework using LoRA for secure, automated scoring of educational assessments, achieving high accuracy and preserving data privacy.", "motivation": "Addressing data privacy concerns in educational research by avoiding raw data sharing and reducing security risks.", "method": "Proposes a federated learning framework with LoRA for local training and adaptive weighted aggregation to handle data heterogeneity.", "result": "Achieves 94.5% accuracy, close to centralized models, with minimal rubric-level scoring differences.", "conclusion": "The framework effectively balances privacy, accuracy, and interpretability in educational assessment scoring."}}
{"id": "2409.08840", "pdf": "https://arxiv.org/pdf/2409.08840", "abs": "https://arxiv.org/abs/2409.08840", "authors": ["Yihang Tao", "Senkang Hu", "Zhengru Fang", "Yuguang Fang"], "title": "Directed-CP: Directed Collaborative Perception for Connected and Autonomous Vehicles via Proactive Attention", "categories": ["cs.CV"], "comment": "Accepted by ICRA'25", "summary": "Collaborative perception (CP) leverages visual data from connected and\nautonomous vehicles (CAV) to enhance an ego vehicle's field of view (FoV).\nDespite recent progress, current CP methods expand the ego vehicle's 360-degree\nperceptual range almost equally, which faces two key challenges. Firstly, in\nareas with uneven traffic distribution, focusing on directions with little\ntraffic offers limited benefits. Secondly, under limited communication budgets,\nallocating excessive bandwidth to less critical directions lowers the\nperception accuracy in more vital areas. To address these issues, we propose\nDirect-CP, a proactive and direction-aware CP system aiming at improving CP in\nspecific directions. Our key idea is to enable an ego vehicle to proactively\nsignal its interested directions and readjust its attention to enhance local\ndirectional CP performance. To achieve this, we first propose an RSU-aided\ndirection masking mechanism that assists an ego vehicle in identifying vital\ndirections. Additionally, we design a direction-aware selective attention\nmodule to wisely aggregate pertinent features based on ego vehicle's\ndirectional priorities, communication budget, and the positional data of CAVs.\nMoreover, we introduce a direction-weighted detection loss (DWLoss) to capture\nthe divergence between directional CP outcomes and the ground truth,\nfacilitating effective model training. Extensive experiments on the V2X-Sim 2.0\ndataset demonstrate that our approach achieves 19.8\\% higher local perception\naccuracy in interested directions and 2.5\\% higher overall perception accuracy\nthan the state-of-the-art methods in collaborative 3D object detection tasks.", "AI": {"tldr": "Direct-CP improves collaborative perception by focusing on specific directions, enhancing local accuracy and efficiency under limited communication budgets.", "motivation": "Current CP methods equally expand perception in all directions, which is inefficient in uneven traffic and limited bandwidth scenarios.", "method": "Proposes a direction-aware system with RSU-aided masking, selective attention, and direction-weighted loss for training.", "result": "Achieves 19.8% higher local accuracy in target directions and 2.5% overall improvement in 3D object detection.", "conclusion": "Direct-CP effectively addresses inefficiencies in CP by prioritizing critical directions, improving performance and resource utilization."}}
{"id": "2505.05989", "pdf": "https://arxiv.org/pdf/2505.05989", "abs": "https://arxiv.org/abs/2505.05989", "authors": ["Hongye Zheng", "Yue Xing", "Lipeng Zhu", "Xu Han", "Junliang Du", "Wanyu Cui"], "title": "Modeling Multi-Hop Semantic Paths for Recommendation in Heterogeneous Information Networks", "categories": ["cs.IR", "cs.LG"], "comment": null, "summary": "This study focuses on the problem of path modeling in heterogeneous\ninformation networks and proposes a multi-hop path-aware recommendation\nframework. The method centers on multi-hop paths composed of various types of\nentities and relations. It models user preferences through three stages: path\nselection, semantic representation, and attention-based fusion. In the path\nselection stage, a path filtering mechanism is introduced to remove redundant\nand noisy information. In the representation learning stage, a sequential\nmodeling structure is used to jointly encode entities and relations, preserving\nthe semantic dependencies within paths. In the fusion stage, an attention\nmechanism assigns different weights to each path to generate a global user\ninterest representation. Experiments conducted on real-world datasets such as\nAmazon-Book show that the proposed method significantly outperforms existing\nrecommendation models across multiple evaluation metrics, including HR@10,\nRecall@10, and Precision@10. The results confirm the effectiveness of multi-hop\npaths in capturing high-order interaction semantics and demonstrate the\nexpressive modeling capabilities of the framework in heterogeneous\nrecommendation scenarios. This method provides both theoretical and practical\nvalue by integrating structural information modeling in heterogeneous networks\nwith recommendation algorithm design. It offers a more expressive and flexible\nparadigm for learning user preferences in complex data environments.", "AI": {"tldr": "A multi-hop path-aware recommendation framework for heterogeneous networks, improving recommendation accuracy by modeling user preferences through path selection, semantic representation, and attention-based fusion.", "motivation": "To address the challenge of path modeling in heterogeneous information networks and enhance recommendation systems by leveraging multi-hop paths for better user preference understanding.", "method": "Three-stage approach: path selection (filtering redundant/noisy paths), semantic representation (encoding entities/relations), and attention-based fusion (weighting paths for global user interest).", "result": "Outperforms existing models on metrics like HR@10, Recall@10, and Precision@10, proving effectiveness in capturing high-order interaction semantics.", "conclusion": "The framework integrates structural information modeling with recommendation design, offering a flexible and expressive paradigm for complex data environments."}}
{"id": "2504.14411", "pdf": "https://arxiv.org/pdf/2504.14411", "abs": "https://arxiv.org/abs/2504.14411", "authors": ["Xiang Zhang", "Yongfeng Zhang"], "title": "Planet as a Brain: Towards Internet of AgentSites based on AIOS Server", "categories": ["cs.NI", "cs.AI"], "comment": null, "summary": "The internet is undergoing a historical transformation from the \"Internet of\nWebsites\" to the \"Internet of AgentSites.\" While traditional Websites served as\nthe foundation for information hosting and dissemination, a new frontier is\nemerging where AgentSites serve as the hubs of the internet, where each\nAgentSite hosts one or more AI agents that receive tasks, address them, and\ndeliver actionable solutions, marking a significant shift in the digital\nlandscape and representing the next generation of online ecosystems. Under this\nvision, AIOS, the AI Agent Operating System, serves as the server for the\ndevelopment, deployment and execution of AI agents, which is a fundamental\ninfrastructure for the Internet of Agentsites.\n  In this paper, we introduce AIOS Server, a runtime framework to host agents\nand enable global-scale collaboration among decentralized agents. AIOS Server\nprovides a communication protocol leveraging the Model Context Protocol (MCP)\nand JSON-RPC to enable agent-agent or human-agent interactions. Each AIOS node\noperates as a server to host and execute agents, while supporting peer-to-peer\ncoordination without reliance on centralized orchestration. Based on AIOS\nServer, we further present the world's first practically deployed Internet of\nAgentsites (AIOS-IoA), including AgentHub for agent registration and discovery\nand AgentChat for interactive communication, at https://planet.aios.foundation.\nThe agent discovery mechanism based on Distributed Hash Tables (DHT) and a\nGossip protocol serves as the search engine for the internet of agentsites.\nThis work provides a practical foundation for building the Internet of\nAgentsites-a new paradigm where autonomous agents become first-class citizens\nof the web. The implementation is available at\nhttps://github.com/agiresearch/AIOS.Server and is integrated into the AIOS main\nbranch at https://github.com/agiresearch/AIOS.", "AI": {"tldr": "The paper introduces AIOS Server, a framework for hosting AI agents and enabling decentralized collaboration, marking a shift from traditional websites to an 'Internet of AgentSites.'", "motivation": "The transformation from the 'Internet of Websites' to the 'Internet of AgentSites' requires infrastructure for AI agent development, deployment, and execution.", "method": "AIOS Server uses the Model Context Protocol (MCP) and JSON-RPC for communication, supports peer-to-peer coordination, and includes tools like AgentHub and AgentChat for agent discovery and interaction.", "result": "The paper presents AIOS-IoA, the first deployed Internet of AgentSites, with a DHT-based discovery mechanism and a Gossip protocol for decentralized search.", "conclusion": "AIOS Server provides a practical foundation for the Internet of AgentSites, where autonomous agents are central to the web."}}
{"id": "2410.20621", "pdf": "https://arxiv.org/pdf/2410.20621", "abs": "https://arxiv.org/abs/2410.20621", "authors": ["Anirudh Thatipelli", "Shao-Yuan Lo", "Amit K. Roy-Chowdhury"], "title": "Egocentric and Exocentric Methods: A Short Survey", "categories": ["cs.CV"], "comment": "Accepted in Computer Vision and Image Understanding (CVIU), 2025", "summary": "Egocentric vision captures the scene from the point of view of the camera\nwearer, while exocentric vision captures the overall scene context. Jointly\nmodeling ego and exo views is crucial to developing next-generation AI agents.\nThe community has regained interest in the field of egocentric vision. While\nthe third-person view and first-person have been thoroughly investigated, very\nfew works aim to study both synchronously. Exocentric videos contain many\nrelevant signals that are transferrable to egocentric videos. This paper\nprovides a timely overview of works combining egocentric and exocentric\nvisions, a very new but promising research topic. We describe in detail the\ndatasets and present a survey of the key applications of ego-exo joint\nlearning, where we identify the most recent advances. With the presentation of\nthe current status of the progress, we believe this short but timely survey\nwill be valuable to the broad video-understanding community, particularly when\nmulti-view modeling is critical.", "AI": {"tldr": "A survey on combining egocentric and exocentric vision, highlighting datasets, applications, and recent advances in joint learning.", "motivation": "Jointly modeling ego and exo views is crucial for next-gen AI agents, as exocentric signals can enhance egocentric vision.", "method": "Overview of existing works, datasets, and key applications in ego-exo joint learning.", "result": "Identifies recent advances and current progress in the field.", "conclusion": "The survey is valuable for video-understanding, especially in multi-view modeling scenarios."}}
{"id": "2505.06146", "pdf": "https://arxiv.org/pdf/2505.06146", "abs": "https://arxiv.org/abs/2505.06146", "authors": ["Idan Attias", "Xing Gao", "Lev Reyzin"], "title": "Learning-Augmented Algorithms for Boolean Satisfiability", "categories": ["cs.DS", "cs.CC", "cs.LG"], "comment": null, "summary": "Learning-augmented algorithms are a prominent recent development in beyond\nworst-case analysis. In this framework, a problem instance is provided with a\nprediction (``advice'') from a machine-learning oracle, which provides partial\ninformation about an optimal solution, and the goal is to design algorithms\nthat leverage this advice to improve worst-case performance. We study the\nclassic Boolean satisfiability (SAT) decision and optimization problems within\nthis framework using two forms of advice. ``Subset advice\" provides a random\n$\\epsilon$ fraction of the variables from an optimal assignment, whereas\n``label advice\" provides noisy predictions for all variables in an optimal\nassignment.\n  For the decision problem $k$-SAT, by using the subset advice we accelerate\nthe exponential running time of the PPSZ family of algorithms due to Paturi,\nPudlak, Saks and Zane, which currently represent the state of the art in the\nworst case. We accelerate the running time by a multiplicative factor of\n$2^{-c}$ in the base of the exponent, where $c$ is a function of $\\epsilon$ and\n$k$. For the optimization problem, we show how to incorporate subset advice in\na black-box fashion with any $\\alpha$-approximation algorithm, improving the\napproximation ratio to $\\alpha + (1 - \\alpha)\\epsilon$. Specifically, we\nachieve approximations of $0.94 + \\Omega(\\epsilon)$ for MAX-$2$-SAT, $7/8 +\n\\Omega(\\epsilon)$ for MAX-$3$-SAT, and $0.79 + \\Omega(\\epsilon)$ for MAX-SAT.\nMoreover, for label advice, we obtain near-optimal approximation for instances\nwith large average degree, thereby generalizing recent results on MAX-CUT and\nMAX-$2$-LIN.", "AI": {"tldr": "The paper explores learning-augmented algorithms for Boolean satisfiability (SAT) problems, using subset and label advice to improve worst-case performance. It accelerates PPSZ algorithms for decision problems and enhances approximation ratios for optimization problems.", "motivation": "To leverage machine-learning predictions (advice) to improve the efficiency and accuracy of solving SAT problems, addressing limitations of worst-case analysis.", "method": "Uses two forms of advice: subset advice (random fraction of optimal variables) and label advice (noisy predictions for all variables). For decision problems, it accelerates PPSZ algorithms. For optimization, it integrates advice with approximation algorithms.", "result": "For decision problems, the running time improves by a factor of $2^{-c}$. For optimization, approximation ratios improve (e.g., $0.94 + \\Omega(\\epsilon)$ for MAX-$2$-SAT). Label advice achieves near-optimal results for high-degree instances.", "conclusion": "Learning-augmented algorithms significantly enhance SAT problem-solving by leveraging advice, demonstrating practical improvements in both decision and optimization contexts."}}
{"id": "2505.02129", "pdf": "https://arxiv.org/pdf/2505.02129", "abs": "https://arxiv.org/abs/2505.02129", "authors": ["Xiaoping Sun", "Hai Zhuge"], "title": "Subspace Aggregation Query and Index Generation for Multidimensional Resource Space Model", "categories": ["cs.DB", "cs.AI"], "comment": null, "summary": "Organizing resources in a multidimensional classification space is an\napproach to efficiently managing and querying large-scale resources. This paper\ndefines an aggregation query on subspace defined by a range on the partial\norder on coordinate tree at each dimension, where each point contains resources\naggregated along the paths of partial order relations on the points so that\naggregated resources at each point within the subspace can be measured, ranked\nand selected. To efficiently locate non-empty points in a large subspace, an\napproach to generating graph index is proposed to build inclusion links with\npartial order relations on coordinates of dimensions to enable a subspace query\nto reach non-empty points by following indexing links and aggregate resources\nalong indexing paths back to their super points. Generating such an index is\ncostly as the number of children of an index node can be very large so that the\ntotal number of indexing nodes is unbounded. The proposed approach adopts the\nfollowing strategies to reduce the cost: (1) adding intersection links between\ntwo indexing nodes, which can better reduce query processing costs while\ncontrolling the number of nodes of the graph index; (2) intersection links are\nadded between two nodes according to the probabilistic distribution calculated\nfor estimating the costs of adding intersection between two nodes; (3)\ncoordinates at one dimension having more resources are split by coordinates at\nanother dimension to balance the number of resources hold by indexing nodes;\nand, (4) short-cut links are added between sibling coordinates of coordinate\ntrees to make an efficient query on linear order coordinates. Analysis and\nexperiments verified the effectiveness of the generated index in supporting\nsubspace aggregation query. This work makes significant contributions to the\ndevelopment of data model based on multi-dimensional classification.", "AI": {"tldr": "The paper proposes a graph index for efficient subspace aggregation queries in multidimensional classification spaces, reducing costs through strategies like intersection links and probabilistic distribution.", "motivation": "To efficiently manage and query large-scale resources in a multidimensional classification space by addressing the challenge of locating non-empty points in large subspaces.", "method": "The method involves generating a graph index with inclusion links, intersection links, and short-cut links, optimized by probabilistic distribution and resource balancing.", "result": "Analysis and experiments confirm the index's effectiveness in supporting subspace aggregation queries.", "conclusion": "The work contributes significantly to multidimensional classification-based data models by improving query efficiency and resource management."}}
{"id": "2412.14123", "pdf": "https://arxiv.org/pdf/2412.14123", "abs": "https://arxiv.org/abs/2412.14123", "authors": ["Guillaume Astruc", "Nicolas Gonthier", "Clement Mallet", "Loic Landrieu"], "title": "AnySat: One Earth Observation Model for Many Resolutions, Scales, and Modalities", "categories": ["cs.CV"], "comment": null, "summary": "Geospatial models must adapt to the diversity of Earth observation data in\nterms of resolutions, scales, and modalities. However, existing approaches\nexpect fixed input configurations, which limits their practical applicability.\nWe propose AnySat, a multimodal model based on joint embedding predictive\narchitecture (JEPA) and scale-adaptive spatial encoders, allowing us to train a\nsingle model on highly heterogeneous data in a self-supervised manner. To\ndemonstrate the advantages of this unified approach, we compile GeoPlex, a\ncollection of 5 multimodal datasets with varying characteristics and $11$\ndistinct sensors. We then train a single powerful model on these diverse\ndatasets simultaneously. Once fine-tuned or probed, we reach state-of-the-art\nresults on the test sets of GeoPlex and for 6 external datasets across various\nenvironment monitoring tasks: land cover mapping, tree species identification,\ncrop type classification, change detection, climate type classification, and\nsegmentation of flood, burn scar, and deforestation. The code and models are\navailable at https://github.com/gastruc/AnySat.", "AI": {"tldr": "AnySat is a multimodal geospatial model using JEPA and scale-adaptive encoders, trained on diverse datasets (GeoPlex) to achieve state-of-the-art results in various environmental tasks.", "motivation": "Existing geospatial models lack adaptability to diverse Earth observation data in terms of resolutions, scales, and modalities.", "method": "Proposes AnySat, a model based on joint embedding predictive architecture (JEPA) and scale-adaptive spatial encoders, trained self-supervised on heterogeneous data (GeoPlex).", "result": "Achieves state-of-the-art performance on GeoPlex and 6 external datasets across multiple environmental monitoring tasks.", "conclusion": "AnySat demonstrates the effectiveness of a unified approach for handling diverse geospatial data, offering practical applicability and superior performance."}}
{"id": "2505.06182", "pdf": "https://arxiv.org/pdf/2505.06182", "abs": "https://arxiv.org/abs/2505.06182", "authors": ["Tim Schneider", "Cristiana de Farias", "Roberto Calandra", "Liming Chen", "Jan Peters"], "title": "Active Perception for Tactile Sensing: A Task-Agnostic Attention-Based Approach", "categories": ["cs.RO", "cs.LG"], "comment": "16 pages; 13 figures", "summary": "Humans make extensive use of haptic exploration to map and identify the\nproperties of the objects that we touch. In robotics, active tactile perception\nhas emerged as an important research domain that complements vision for tasks\nsuch as object classification, shape reconstruction, and manipulation. This\nwork introduces TAP (Task-agnostic Active Perception) -- a novel framework that\nleverages reinforcement learning (RL) and transformer-based architectures to\naddress the challenges posed by partially observable environments. TAP\nintegrates Soft Actor-Critic (SAC) and CrossQ algorithms within a unified\noptimization objective, jointly training a perception module and\ndecision-making policy. By design, TAP is completely task-agnostic and can, in\nprinciple, generalize to any active perception problem. We evaluate TAP across\ndiverse tasks, including toy examples and realistic applications involving\nhaptic exploration of 3D models from the Tactile MNIST benchmark. Experiments\ndemonstrate the efficacy of TAP, achieving high accuracies on the Tactile MNIST\nhaptic digit recognition task and a tactile pose estimation task. These\nfindings underscore the potential of TAP as a versatile and generalizable\nframework for advancing active tactile perception in robotics.", "AI": {"tldr": "TAP is a task-agnostic framework using RL and transformers for active tactile perception, achieving high accuracy in tasks like haptic digit recognition.", "motivation": "To address challenges in partially observable environments for active tactile perception in robotics.", "method": "Combines Soft Actor-Critic (SAC) and CrossQ algorithms with transformer-based architectures for joint training of perception and decision-making.", "result": "High accuracy on Tactile MNIST digit recognition and tactile pose estimation tasks.", "conclusion": "TAP is a versatile and generalizable framework for advancing active tactile perception."}}
{"id": "2505.02255", "pdf": "https://arxiv.org/pdf/2505.02255", "abs": "https://arxiv.org/abs/2505.02255", "authors": ["Jakub Wasala", "Bartlomiej Wrzalski", "Kornelia Noculak", "Yuliia Tarasenko", "Oliwer Krupa", "Jan Kocon", "Grzegorz Chodak"], "title": "Enhancing AI Face Realism: Cost-Efficient Quality Improvement in Distilled Diffusion Models with a Fully Synthetic Dataset", "categories": ["cs.CV", "cs.AI"], "comment": "25th International Conference on Computational Science", "summary": "This study presents a novel approach to enhance the cost-to-quality ratio of\nimage generation with diffusion models. We hypothesize that differences between\ndistilled (e.g. FLUX.1-schnell) and baseline (e.g. FLUX.1-dev) models are\nconsistent and, therefore, learnable within a specialized domain, like portrait\ngeneration. We generate a synthetic paired dataset and train a fast\nimage-to-image translation head. Using two sets of low- and high-quality\nsynthetic images, our model is trained to refine the output of a distilled\ngenerator (e.g., FLUX.1-schnell) to a level comparable to a baseline model like\nFLUX.1-dev, which is more computationally intensive. Our results show that the\npipeline, which combines a distilled version of a large generative model with\nour enhancement layer, delivers similar photorealistic portraits to the\nbaseline version with up to an 82% decrease in computational cost compared to\nFLUX.1-dev. This study demonstrates the potential for improving the efficiency\nof AI solutions involving large-scale image generation.", "AI": {"tldr": "A novel method improves cost-to-quality ratio in image generation by refining outputs of distilled models to match baseline quality, reducing computational costs by 82%.", "motivation": "To enhance efficiency in AI image generation by reducing computational costs while maintaining high-quality outputs.", "method": "Generate a synthetic paired dataset, train an image-to-image translation head to refine distilled model outputs to baseline quality levels.", "result": "The pipeline achieves photorealistic portraits comparable to baseline models with an 82% reduction in computational cost.", "conclusion": "Demonstrates potential for efficient large-scale image generation by combining distilled models with enhancement layers."}}
{"id": "2412.20002", "pdf": "https://arxiv.org/pdf/2412.20002", "abs": "https://arxiv.org/abs/2412.20002", "authors": ["You Wu", "Yongxin Li", "Mengyuan Liu", "Xucheng Wang", "Xiangyang Yang", "Hengzhou Ye", "Dan Zeng", "Qijun Zhao", "Shuiwang Li"], "title": "Learning an Adaptive and View-Invariant Vision Transformer for Real-Time UAV Tracking", "categories": ["cs.CV"], "comment": null, "summary": "Visual tracking has made significant strides due to the adoption of\ntransformer-based models. Most state-of-the-art trackers struggle to meet\nreal-time processing demands on mobile platforms with constrained computing\nresources, particularly for real-time unmanned aerial vehicle (UAV) tracking.\nTo achieve a better balance between performance and efficiency, we introduce\nAVTrack, an adaptive computation framework designed to selectively activate\ntransformer blocks for real-time UAV tracking. The proposed Activation Module\n(AM) dynamically optimizes the ViT architecture by selectively engaging\nrelevant components, thereby enhancing inference efficiency without significant\ncompromise to tracking performance. Furthermore, to tackle the challenges posed\nby extreme changes in viewing angles often encountered in UAV tracking, the\nproposed method enhances ViTs' effectiveness by learning view-invariant\nrepresentations through mutual information (MI) maximization. Two effective\ndesign principles are proposed in the AVTrack. Building on it, we propose an\nimproved tracker, dubbed AVTrack-MD, which introduces the novel MI\nmaximization-based multi-teacher knowledge distillation (MD) framework. It\nharnesses the benefits of multiple teachers, specifically the off-the-shelf\ntracking models from the AVTrack, by integrating and refining their outputs,\nthereby guiding the learning process of the compact student network.\nSpecifically, we maximize the MI between the softened feature representations\nfrom the multi-teacher models and the student model, leading to improved\ngeneralization and performance of the student model, particularly in noisy\nconditions. Extensive experiments on multiple UAV tracking benchmarks\ndemonstrate that AVTrack-MD not only achieves performance comparable to the\nAVTrack baseline but also reduces model complexity, resulting in a significant\n17\\% increase in average tracking speed.", "AI": {"tldr": "AVTrack-MD improves UAV tracking by selectively activating transformer blocks and using multi-teacher knowledge distillation, balancing performance and efficiency.", "motivation": "Address the inefficiency of state-of-the-art trackers on mobile platforms and challenges like extreme viewing angle changes in UAV tracking.", "method": "Introduces AVTrack with an Activation Module for selective transformer block activation and AVTrack-MD, which uses MI maximization for multi-teacher knowledge distillation.", "result": "Achieves comparable performance to AVTrack baseline with a 17% increase in tracking speed.", "conclusion": "AVTrack-MD effectively balances tracking performance and efficiency, making it suitable for real-time UAV applications."}}
{"id": "2505.06207", "pdf": "https://arxiv.org/pdf/2505.06207", "abs": "https://arxiv.org/abs/2505.06207", "authors": ["Muhy Eddin Za'ter", "Amir Sajad", "Bri-Mathias Hodge"], "title": "Leveraging Multi-Task Learning for Multi-Label Power System Security Assessment", "categories": ["eess.SY", "cs.LG", "cs.SY"], "comment": null, "summary": "This paper introduces a novel approach to the power system security\nassessment using Multi-Task Learning (MTL), and reformulating the problem as a\nmulti-label classification task. The proposed MTL framework simultaneously\nassesses static, voltage, transient, and small-signal stability, improving both\naccuracy and interpretability with respect to the most state of the art machine\nlearning methods. It consists of a shared encoder and multiple decoders,\nenabling knowledge transfer between stability tasks. Experiments on the IEEE\n68-bus system demonstrate a measurable superior performance of the proposed\nmethod compared to the extant state-of-the-art approaches.", "AI": {"tldr": "A novel MTL framework for power system security assessment improves accuracy and interpretability by simultaneously evaluating multiple stability types.", "motivation": "To enhance power system security assessment by leveraging MTL for multi-label classification, addressing limitations of current machine learning methods.", "method": "Proposes an MTL framework with a shared encoder and multiple decoders to assess static, voltage, transient, and small-signal stability simultaneously.", "result": "Demonstrates superior performance on the IEEE 68-bus system compared to state-of-the-art methods.", "conclusion": "The MTL approach effectively improves accuracy and interpretability in power system security assessment."}}
{"id": "2505.04787", "pdf": "https://arxiv.org/pdf/2505.04787", "abs": "https://arxiv.org/abs/2505.04787", "authors": ["Sriram Mandalika", "Harsha Vardhan", "Athira Nambiar"], "title": "Replay to Remember (R2R): An Efficient Uncertainty-driven Unsupervised Continual Learning Framework Using Generative Replay", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": "Submitted to the 28th European Conference on Artificial Intelligence\n  (ECAI-2025)", "summary": "Continual Learning entails progressively acquiring knowledge from new data\nwhile retaining previously acquired knowledge, thereby mitigating\n``Catastrophic Forgetting'' in neural networks. Our work presents a novel\nuncertainty-driven Unsupervised Continual Learning framework using Generative\nReplay, namely ``Replay to Remember (R2R)''. The proposed R2R architecture\nefficiently uses unlabelled and synthetic labelled data in a balanced\nproportion using a cluster-level uncertainty-driven feedback mechanism and a\nVLM-powered generative replay module. Unlike traditional memory-buffer methods\nthat depend on pretrained models and pseudo-labels, our R2R framework operates\nwithout any prior training. It leverages visual features from unlabeled data\nand adapts continuously using clustering-based uncertainty estimation coupled\nwith dynamic thresholding. Concurrently, a generative replay mechanism along\nwith DeepSeek-R1 powered CLIP VLM produces labelled synthetic data\nrepresentative of past experiences, resembling biological visual thinking that\nreplays memory to remember and act in new, unseen tasks. Extensive experimental\nanalyses are carried out in CIFAR-10, CIFAR-100, CINIC-10, SVHN and\nTinyImageNet datasets. Our proposed R2R approach improves knowledge retention,\nachieving a state-of-the-art performance of 98.13%, 73.06%, 93.41%, 95.18%,\n59.74%, respectively, surpassing state-of-the-art performance by over 4.36%.", "AI": {"tldr": "A novel unsupervised continual learning framework, R2R, uses generative replay and uncertainty-driven feedback to mitigate catastrophic forgetting, achieving state-of-the-art performance on multiple datasets.", "motivation": "To address catastrophic forgetting in neural networks by leveraging unlabelled data and synthetic labelled data without prior training.", "method": "Uses a cluster-level uncertainty-driven feedback mechanism and a VLM-powered generative replay module to balance unlabelled and synthetic data.", "result": "Achieves top performance on CIFAR-10 (98.13%), CIFAR-100 (73.06%), CINIC-10 (93.41%), SVHN (95.18%), and TinyImageNet (59.74%), surpassing prior methods by 4.36%.", "conclusion": "R2R effectively retains knowledge and outperforms existing approaches in continual learning tasks."}}
{"id": "2503.11341", "pdf": "https://arxiv.org/pdf/2503.11341", "abs": "https://arxiv.org/abs/2503.11341", "authors": ["Joona Kareinen", "Tuomas Eerola", "Kaisa Kraft", "Lasse Lensu", "Sanna Suikkanen", "Heikki K\u00e4lvi\u00e4inen"], "title": "Self-Supervised Pretraining for Fine-Grained Plankton Recognition", "categories": ["cs.CV"], "comment": "CVPR 2025, FGVC12 workshop paper", "summary": "Plankton recognition is an important computer vision problem due to\nplankton's essential role in ocean food webs and carbon capture, highlighting\nthe need for species-level monitoring. However, this task is challenging due to\nits fine-grained nature and dataset shifts caused by different imaging\ninstruments and varying species distributions. As new plankton image datasets\nare collected at an increasing pace, there is a need for general plankton\nrecognition models that require minimal expert effort for data labeling. In\nthis work, we study large-scale self-supervised pretraining for fine-grained\nplankton recognition. We first employ masked autoencoding and a large volume of\ndiverse plankton image data to pretrain a general-purpose plankton image\nencoder. Then we utilize fine-tuning to obtain accurate plankton recognition\nmodels for new datasets with a very limited number of labeled training images.\nOur experiments show that self-supervised pretraining with diverse plankton\ndata clearly increases plankton recognition accuracy compared to standard\nImageNet pretraining when the amount of training data is limited. Moreover, the\naccuracy can be further improved when unlabeled target data is available and\nutilized during the pretraining.", "AI": {"tldr": "Self-supervised pretraining with diverse plankton data improves fine-grained plankton recognition accuracy, especially with limited labeled data and unlabeled target data.", "motivation": "Plankton recognition is crucial for ocean monitoring but challenging due to fine-grained species differences and dataset shifts. Minimizing expert labeling effort is needed as datasets grow.", "method": "Large-scale self-supervised pretraining (masked autoencoding) on diverse plankton images, followed by fine-tuning with limited labeled data.", "result": "Self-supervised pretraining outperforms ImageNet pretraining when labeled data is scarce. Accuracy improves further with unlabeled target data.", "conclusion": "Self-supervised pretraining is effective for fine-grained plankton recognition, reducing reliance on labeled data."}}
{"id": "2505.06228", "pdf": "https://arxiv.org/pdf/2505.06228", "abs": "https://arxiv.org/abs/2505.06228", "authors": ["Mariona Badenas-Agusti", "Siyi Xu", "Andrew Vanderburg", "Kishalay De", "Patrick Dufour", "Laura K. Rogers", "Susana Hoyos", "Simon Blouin", "Javier Via\u00f1a", "Amy Bonsor", "Ben Zuckerman"], "title": "A Machine-Learning Compositional Study of Exoplanetary Material Accreted Onto Five Helium-Atmosphere White Dwarfs with $\\texttt{cecilia}$", "categories": ["astro-ph.EP", "astro-ph.IM", "astro-ph.SR", "cs.LG"], "comment": "28 pages, 14 figures, 5 tables. Accepted for publication in MNRAS", "summary": "We present the first application of the Machine Learning (ML) pipeline\n$\\texttt{cecilia}$ to determine the physical parameters and photospheric\ncomposition of five metal-polluted He-atmosphere white dwarfs without\nwell-characterised elemental abundances. To achieve this, we perform a joint\nand iterative Bayesian fit to their $\\textit{SDSS}$ (R=2,000) and\n$\\textit{Keck/ESI}$ (R=4,500) optical spectra, covering the wavelength range\nfrom about 3,800\\r{A} to 9,000\\r{A}. Our analysis measures the abundances of at\nleast two $-$and up to six$-$ chemical elements in their atmospheres with a\npredictive accuracy similar to that of conventional WD analysis techniques\n($\\approx$0.20 dex). The white dwarfs with the largest number of detected heavy\nelements are SDSS J0859$+$5732 and SDSS J2311$-$0041, which simultaneously\nexhibit O, Mg, Si, Ca, and Fe in their $\\textit{Keck/ESI}$ spectra. For all\nsystems, we find that the bulk composition of their pollutants is largely\nconsistent with those of primitive CI chondrites to within 1-2$\\sigma$. We also\nfind evidence of statistically significant ($>2\\sigma$) oxygen excesses for\nSDSS J0859$+$5732 and SDSS J2311$-$0041, which could point to the accretion of\noxygen-rich exoplanetary material. In the future, as wide-field astronomical\nsurveys deliver millions of public WD spectra to the scientific community,\n$\\texttt{cecilia}$ aspires to unlock population-wide studies of polluted WDs,\ntherefore helping to improve our statistical knowledge of extrasolar\ncompositions.", "AI": {"tldr": "The paper introduces the ML pipeline $\texttt{cecilia}$ to analyze metal-polluted white dwarfs, measuring their atmospheric abundances with high accuracy and comparing them to chondritic material.", "motivation": "To improve the analysis of white dwarfs with poorly characterized elemental abundances and enable population-wide studies of polluted white dwarfs.", "method": "A joint Bayesian fit to optical spectra from $\textit{SDSS}$ and $\textit{Keck/ESI}$, covering 3,800-9,000 \u00c5, to measure abundances of 2-6 elements.", "result": "Abundances were measured with \u22480.20 dex accuracy, showing consistency with CI chondrites and evidence of oxygen excess in two stars.", "conclusion": "$\texttt{cecilia}$ can facilitate large-scale studies of polluted white dwarfs, enhancing understanding of extrasolar compositions."}}
{"id": "2505.04852", "pdf": "https://arxiv.org/pdf/2505.04852", "abs": "https://arxiv.org/abs/2505.04852", "authors": ["Yifei Gao", "Chengpeng Wang", "Pengxiang Huang", "Xuwei Liu", "Mingwei Zheng", "Xiangyu Zhang"], "title": "PR2: Peephole Raw Pointer Rewriting with LLMs for Translating C to Safer Rust", "categories": ["cs.SE", "cs.AI", "cs.PL"], "comment": null, "summary": "There has been a growing interest in translating C code to Rust due to Rust's\nrobust memory and thread safety guarantees. Tools such as C2RUST enable\nsyntax-guided transpilation from C to semantically equivalent Rust code.\nHowever, the resulting Rust programs often rely heavily on unsafe\nconstructs--particularly raw pointers--which undermines Rust's safety\nguarantees. This paper aims to improve the memory safety of Rust programs\ngenerated by C2RUST by eliminating raw pointers. Specifically, we propose a\npeephole raw pointer rewriting technique that lifts raw pointers in individual\nfunctions to appropriate Rust data structures. Technically, PR2 employs\ndecision-tree-based prompting to guide the pointer lifting process.\nAdditionally, it leverages code change analysis to guide the repair of errors\nintroduced during rewriting, effectively addressing errors encountered during\ncompilation and test case execution. We implement PR2 as a prototype and\nevaluate it using gpt-4o-mini on 28 real-world C projects. The results show\nthat PR2 successfully eliminates 13.22% of local raw pointers across these\nprojects, significantly enhancing the safety of the translated Rust code. On\naverage, PR2 completes the transformation of a project in 5.44 hours, at an\naverage cost of $1.46.", "AI": {"tldr": "PR2 improves memory safety in Rust code translated from C by eliminating raw pointers using a peephole rewriting technique and decision-tree-based prompting.", "motivation": "Growing interest in C-to-Rust translation tools like C2RUST, but resulting Rust code often relies on unsafe constructs like raw pointers, undermining Rust's safety guarantees.", "method": "Proposes PR2, a technique using peephole raw pointer rewriting and decision-tree-based prompting to lift raw pointers to Rust data structures, with error repair via code change analysis.", "result": "PR2 eliminates 13.22% of local raw pointers in 28 real-world C projects, enhancing safety, with an average transformation time of 5.44 hours and cost of $1.46 per project.", "conclusion": "PR2 effectively improves the safety of Rust code generated from C by reducing reliance on unsafe raw pointers."}}
{"id": "2503.20698", "pdf": "https://arxiv.org/pdf/2503.20698", "abs": "https://arxiv.org/abs/2503.20698", "authors": ["Saron Samuel", "Dan DeGenaro", "Jimena Guallar-Blasco", "Kate Sanders", "Oluwaseun Eisape", "Tanner Spendlove", "Arun Reddy", "Alexander Martin", "Andrew Yates", "Eugene Yang", "Cameron Carpenter", "David Etter", "Efsun Kayi", "Matthew Wiesner", "Kenton Murray", "Reno Kriz"], "title": "MMMORRF: Multimodal Multilingual Modularized Reciprocal Rank Fusion", "categories": ["cs.CV", "cs.IR"], "comment": null, "summary": "Videos inherently contain multiple modalities, including visual events, text\noverlays, sounds, and speech, all of which are important for retrieval.\nHowever, state-of-the-art multimodal language models like VAST and LanguageBind\nare built on vision-language models (VLMs), and thus overly prioritize visual\nsignals. Retrieval benchmarks further reinforce this bias by focusing on visual\nqueries and neglecting other modalities. We create a search system MMMORRF that\nextracts text and features from both visual and audio modalities and integrates\nthem with a novel modality-aware weighted reciprocal rank fusion. MMMORRF is\nboth effective and efficient, demonstrating practicality in searching videos\nbased on users' information needs instead of visual descriptive queries. We\nevaluate MMMORRF on MultiVENT 2.0 and TVR, two multimodal benchmarks designed\nfor more targeted information needs, and find that it improves nDCG@20 by 81%\nover leading multimodal encoders and 37% over single-modality retrieval,\ndemonstrating the value of integrating diverse modalities.", "AI": {"tldr": "MMMORRF improves video retrieval by integrating multiple modalities (visual, audio, text) with a novel fusion method, outperforming existing models.", "motivation": "Current multimodal models prioritize visual signals, neglecting other modalities like audio and text, which are crucial for comprehensive video retrieval.", "method": "MMMORRF extracts and integrates features from visual and audio modalities using modality-aware weighted reciprocal rank fusion.", "result": "MMMORRF improves nDCG@20 by 81% over leading multimodal encoders and 37% over single-modality retrieval on benchmarks MultiVENT 2.0 and TVR.", "conclusion": "Integrating diverse modalities enhances video retrieval effectiveness, addressing the bias toward visual queries in existing systems."}}
{"id": "2310.04649", "pdf": "https://arxiv.org/pdf/2310.04649", "abs": "https://arxiv.org/abs/2310.04649", "authors": ["Michael Matena", "Colin Raffel"], "title": "Uncovering Model Processing Strategies with Non-Negative Per-Example Fisher Factorization", "categories": ["cs.LG"], "comment": null, "summary": "We introduce NPEFF (Non-Negative Per-Example Fisher Factorization), an\ninterpretability method that aims to uncover strategies used by a model to\ngenerate its predictions. NPEFF decomposes per-example Fisher matrices using a\nnovel decomposition algorithm that learns a set of components represented by\nlearned rank-1 positive semi-definite matrices. Through a combination of human\nevaluation and automated analysis, we demonstrate that these NPEFF components\ncorrespond to model processing strategies for a variety of language models and\ntext processing tasks. We further show how to construct parameter perturbations\nfrom NPEFF components to selectively disrupt a given component's role in the\nmodel's processing. Along with conducting extensive ablation studies, we\ninclude experiments to show how NPEFF can be used to analyze and mitigate\ncollateral effects of unlearning and use NPEFF to study in-context learning.\nFurthermore, we demonstrate the advantages of NPEFF over baselines such as\ngradient clustering and using sparse autoencoders for dictionary learning over\nmodel activations.", "AI": {"tldr": "NPEFF is a method to interpret model predictions by decomposing per-example Fisher matrices into rank-1 components, revealing model strategies and enabling targeted parameter perturbations.", "motivation": "To uncover and interpret the strategies models use for predictions, improving transparency and control over model behavior.", "method": "Decomposes per-example Fisher matrices using a novel algorithm to learn rank-1 positive semi-definite components, validated via human and automated analysis.", "result": "NPEFF components correspond to model strategies, enable selective disruption, and outperform baselines like gradient clustering and sparse autoencoders.", "conclusion": "NPEFF provides a powerful tool for analyzing and controlling model behavior, with applications in unlearning and in-context learning."}}
{"id": "2505.05283", "pdf": "https://arxiv.org/pdf/2505.05283", "abs": "https://arxiv.org/abs/2505.05283", "authors": ["Kaixin Wang", "Tianlin Li", "Xiaoyu Zhang", "Chong Wang", "Weisong Sun", "Yang Liu", "Bin Shi"], "title": "Software Development Life Cycle Perspective: A Survey of Benchmarks for Code Large Language Models and Agents", "categories": ["cs.SE", "cs.AI"], "comment": null, "summary": "Code large language models (CodeLLMs) and agents have shown great promise in\ntackling complex software engineering tasks.Compared to traditional software\nengineering methods, CodeLLMs and agents offer stronger abilities, and can\nflexibly process inputs and outputs in both natural and code. Benchmarking\nplays a crucial role in evaluating the capabilities of CodeLLMs and agents,\nguiding their development and deployment. However, despite their growing\nsignificance, there remains a lack of comprehensive reviews of benchmarks for\nCodeLLMs and agents. To bridge this gap, this paper provides a comprehensive\nreview of existing benchmarks for CodeLLMs and agents, studying and analyzing\n181 benchmarks from 461 relevant papers, covering the different phases of the\nsoftware development life cycle (SDLC). Our findings reveal a notable imbalance\nin the coverage of current benchmarks, with approximately 60% focused on the\nsoftware development phase in SDLC, while requirements engineering and software\ndesign phases receive minimal attention at only 5% and 3%, respectively.\nAdditionally, Python emerges as the dominant programming language across the\nreviewed benchmarks. Finally, this paper highlights the challenges of current\nresearch and proposes future directions, aiming to narrow the gap between the\ntheoretical capabilities of CodeLLMs and agents and their application in\nreal-world scenarios.", "AI": {"tldr": "The paper reviews 181 benchmarks for CodeLLMs and agents, revealing an imbalance in SDLC phase coverage and Python's dominance, while suggesting future research directions.", "motivation": "To address the lack of comprehensive reviews of benchmarks for CodeLLMs and agents, despite their growing importance in software engineering.", "method": "Analyzed 181 benchmarks from 461 papers, covering various SDLC phases.", "result": "60% of benchmarks focus on development, while requirements engineering (5%) and design (3%) are underrepresented. Python is the dominant language.", "conclusion": "Highlights research gaps and proposes future directions to align CodeLLMs' theoretical capabilities with real-world applications."}}
{"id": "2503.22976", "pdf": "https://arxiv.org/pdf/2503.22976", "abs": "https://arxiv.org/abs/2503.22976", "authors": ["Jiahui Zhang", "Yurui Chen", "Yanpeng Zhou", "Yueming Xu", "Ze Huang", "Jilin Mei", "Junhui Chen", "Yu-Jie Yuan", "Xinyue Cai", "Guowei Huang", "Xingyue Quan", "Hang Xu", "Li Zhang"], "title": "From Flatland to Space: Teaching Vision-Language Models to Perceive and Reason in 3D", "categories": ["cs.CV"], "comment": "Project page: https://fudan-zvg.github.io/spar", "summary": "Recent advances in LVLMs have improved vision-language understanding, but\nthey still struggle with spatial perception, limiting their ability to reason\nabout complex 3D scenes. Unlike previous approaches that incorporate 3D\nrepresentations into models to improve spatial understanding, we aim to unlock\nthe potential of VLMs by leveraging spatially relevant image data. To this end,\nwe introduce a novel 2D spatial data generation and annotation pipeline built\nupon scene data with 3D ground-truth. This pipeline enables the creation of a\ndiverse set of spatial tasks, ranging from basic perception tasks to more\ncomplex reasoning tasks. Leveraging this pipeline, we construct SPAR-7M, a\nlarge-scale dataset generated from thousands of scenes across multiple public\ndatasets. In addition, we introduce SPAR-Bench, a benchmark designed to offer a\nmore comprehensive evaluation of spatial capabilities compared to existing\nspatial benchmarks, supporting both single-view and multi-view inputs. Training\non both SPAR-7M and large-scale 2D datasets enables our models to achieve\nstate-of-the-art performance on 2D spatial benchmarks. Further fine-tuning on\n3D task-specific datasets yields competitive results, underscoring the\neffectiveness of our dataset in enhancing spatial reasoning.", "AI": {"tldr": "The paper introduces a 2D spatial data generation pipeline and SPAR-7M dataset to enhance LVLMs' spatial reasoning, achieving state-of-the-art performance on 2D benchmarks and competitive results on 3D tasks.", "motivation": "LVLMs struggle with spatial perception in complex 3D scenes, limiting their reasoning abilities. The goal is to improve spatial understanding without relying on 3D representations.", "method": "A novel 2D spatial data generation and annotation pipeline is developed using 3D ground-truth scene data. This creates diverse spatial tasks and the SPAR-7M dataset. SPAR-Bench is introduced for comprehensive evaluation.", "result": "Models trained on SPAR-7M and 2D datasets achieve state-of-the-art performance on 2D benchmarks. Fine-tuning on 3D datasets yields competitive results.", "conclusion": "The proposed pipeline and dataset effectively enhance spatial reasoning in LVLMs, demonstrating their potential for both 2D and 3D tasks."}}
{"id": "2310.19470", "pdf": "https://arxiv.org/pdf/2310.19470", "abs": "https://arxiv.org/abs/2310.19470", "authors": ["Gouki Minegishi", "Yusuke Iwasawa", "Yutaka Matsuo"], "title": "Bridging Lottery Ticket and Grokking: Understanding Grokking from Inner Structure of Networks", "categories": ["cs.LG"], "comment": "Published at Transactions on Machine Learning Research (TMLR)", "summary": "Grokking is an intriguing phenomenon of delayed generalization, where neural\nnetworks initially memorize training data with perfect accuracy but exhibit\npoor generalization, subsequently transitioning to a generalizing solution with\ncontinued training. While factors such as weight norms and sparsity have been\nproposed to explain this delayed generalization, the influence of network\nstructure remains underexplored. In this work, we link the grokking phenomenon\nto the lottery ticket hypothesis to investigate the impact of internal network\nstructures. We demonstrate that utilizing lottery tickets obtained during the\ngeneralizing phase (termed grokked tickets) significantly reduces delayed\ngeneralization across various tasks, including multiple modular arithmetic\noperations, polynomial regression, sparse parity, and MNIST classification.\nThrough controlled experiments, we show that the mitigation of delayed\ngeneralization is not due solely to reduced weight norms or increased sparsity,\nbut rather to the discovery of good subnetworks. Furthermore, we find that\ngrokked tickets exhibit periodic weight patterns, beneficial graph properties\nsuch as increased average path lengths and reduced clustering coefficients, and\nundergo rapid structural changes that coincide with improvements in\ngeneralization. Additionally, pruning techniques like the edge-popup algorithm\ncan identify these effective structures without modifying the weights, thereby\ntransforming memorizing networks into generalizing ones. These results\nunderscore the novel insight that structural exploration plays a pivotal role\nin understanding grokking. The implementation code can be accessed via this\nlink: https://github.com/gouki510/Grokking-Tickets.", "AI": {"tldr": "The paper explores grokking (delayed generalization in neural networks) by linking it to the lottery ticket hypothesis, showing that grokked tickets reduce delayed generalization and highlighting the role of network structure.", "motivation": "To investigate the underexplored influence of network structure on the grokking phenomenon and its connection to the lottery ticket hypothesis.", "method": "Utilized grokked tickets (lottery tickets from the generalizing phase) and conducted experiments on tasks like modular arithmetic, polynomial regression, and MNIST classification. Analyzed weight patterns, graph properties, and pruning techniques.", "result": "Grokked tickets reduce delayed generalization, exhibit periodic weight patterns, beneficial graph properties, and undergo rapid structural changes. Pruning techniques can identify effective structures without weight modification.", "conclusion": "Structural exploration is pivotal in understanding grokking, and grokked tickets offer a pathway to mitigate delayed generalization."}}
{"id": "2505.05375", "pdf": "https://arxiv.org/pdf/2505.05375", "abs": "https://arxiv.org/abs/2505.05375", "authors": ["Kejie Zhao", "Wenjia Hua", "Aiersi Tuerhong", "Luziwei Leng", "Yuxin Ma", "Qinghai Guo"], "title": "Threshold Modulation for Online Test-Time Adaptation of Spiking Neural Networks", "categories": ["cs.CV", "cs.AI", "cs.LG", "cs.NE"], "comment": "Accepted by IJCNN 2025. \\c{opyright} 2025 IEEE. Personal use of this\n  material is permitted. Permission from IEEE must be obtained for all other\n  uses, including reprinting/republishing this material for advertising or\n  promotional purposes, collecting new collected works for resale or\n  redistribution to servers or lists, or reuse of any copyrighted component of\n  this work in other works", "summary": "Recently, spiking neural networks (SNNs), deployed on neuromorphic chips,\nprovide highly efficient solutions on edge devices in different scenarios.\nHowever, their ability to adapt to distribution shifts after deployment has\nbecome a crucial challenge. Online test-time adaptation (OTTA) offers a\npromising solution by enabling models to dynamically adjust to new data\ndistributions without requiring source data or labeled target samples.\nNevertheless, existing OTTA methods are largely designed for traditional\nartificial neural networks and are not well-suited for SNNs. To address this\ngap, we propose a low-power, neuromorphic chip-friendly online test-time\nadaptation framework, aiming to enhance model generalization under distribution\nshifts. The proposed approach is called Threshold Modulation (TM), which\ndynamically adjusts the firing threshold through neuronal dynamics-inspired\nnormalization, being more compatible with neuromorphic hardware. Experimental\nresults on benchmark datasets demonstrate the effectiveness of this method in\nimproving the robustness of SNNs against distribution shifts while maintaining\nlow computational cost. The proposed method offers a practical solution for\nonline test-time adaptation of SNNs, providing inspiration for the design of\nfuture neuromorphic chips. The demo code is available at\ngithub.com/NneurotransmitterR/TM-OTTA-SNN.", "AI": {"tldr": "The paper proposes a neuromorphic chip-friendly online test-time adaptation framework for spiking neural networks (SNNs) called Threshold Modulation (TM), enhancing robustness against distribution shifts.", "motivation": "Existing online test-time adaptation (OTTA) methods are not well-suited for SNNs, creating a gap in adapting to distribution shifts efficiently.", "method": "The TM framework dynamically adjusts firing thresholds using neuronal dynamics-inspired normalization, ensuring compatibility with neuromorphic hardware.", "result": "Experiments show TM improves SNN robustness under distribution shifts while maintaining low computational cost.", "conclusion": "TM provides a practical OTTA solution for SNNs, inspiring future neuromorphic chip designs."}}
{"id": "2503.24166", "pdf": "https://arxiv.org/pdf/2503.24166", "abs": "https://arxiv.org/abs/2503.24166", "authors": ["Fabian Fuchs", "Mario Ruben Fernandez", "Norman Ettrich", "Janis Keuper"], "title": "Foundation Models For Seismic Data Processing: An Extensive Review", "categories": ["cs.CV"], "comment": "In submission to Geophysics", "summary": "Seismic processing plays a crucial role in transforming raw data into\nhigh-quality subsurface images, pivotal for various geoscience applications.\nDespite its importance, traditional seismic processing techniques face\nchallenges such as noisy and damaged data and the reliance on manual,\ntime-consuming workflows. The emergence of deep learning approaches has\nintroduced effective and user-friendly alternatives, yet many of these deep\nlearning approaches rely on synthetic datasets and specialized neural networks.\nRecently, foundation models have gained traction in the seismic domain, due to\ntheir success in the natural image domain. Therefore, we investigate the\napplication of natural image foundation models on the three seismic processing\ntasks: demultiple, interpolation, and denoising. We evaluate the impact of\ndifferent model characteristics, such as pre-training technique and neural\nnetwork architecture, on performance and efficiency. Rather than proposing a\nsingle seismic foundation model, we critically examine various natural image\nfoundation models and suggest some promising candidates for future exploration.", "AI": {"tldr": "The paper explores using natural image foundation models for seismic processing tasks like demultiple, interpolation, and denoising, evaluating their performance and efficiency.", "motivation": "Traditional seismic processing techniques are manual and time-consuming, while deep learning approaches often rely on synthetic data. Foundation models offer a promising alternative.", "method": "The study investigates natural image foundation models for seismic tasks, assessing factors like pre-training and architecture.", "result": "The paper evaluates performance and efficiency of various models, identifying promising candidates for future research.", "conclusion": "Natural image foundation models show potential for seismic processing, with specific models highlighted for further exploration."}}
{"id": "2312.05698", "pdf": "https://arxiv.org/pdf/2312.05698", "abs": "https://arxiv.org/abs/2312.05698", "authors": ["Chen Liang", "Donghua Yang", "Zhiyu Liang", "Hongzhi Wang", "Zheng Liang", "Xiyang Zhang", "Jianfeng Huang"], "title": "Unsupervised Multi-modal Feature Alignment for Time Series Representation Learning", "categories": ["cs.LG"], "comment": null, "summary": "In recent times, the field of unsupervised representation learning (URL) for\ntime series data has garnered significant interest due to its remarkable\nadaptability across diverse downstream applications. Unsupervised learning\ngoals differ from downstream tasks, making it tricky to ensure downstream task\nutility by focusing only on temporal feature characterization. Researchers have\nproposed multiple transformations to extract discriminative patterns implied in\ninformative time series, trying to fill the gap. Despite the introduction of a\nvariety of feature engineering techniques, e.g. spectral domain, wavelet\ntransformed features, features in image form and symbolic features etc. the\nutilization of intricate feature fusion methods and dependence on heterogeneous\nfeatures during inference hampers the scalability of the solutions. To address\nthis, our study introduces an innovative approach that focuses on aligning and\nbinding time series representations encoded from different modalities, inspired\nby spectral graph theory, thereby guiding the neural encoder to uncover latent\npattern associations among these multi-modal features. In contrast to\nconventional methods that fuse features from multiple modalities, our proposed\napproach simplifies the neural architecture by retaining a single time series\nencoder, consequently leading to preserved scalability. We further demonstrate\nand prove mechanisms for the encoder to maintain better inductive bias. In our\nexperimental evaluation, we validated the proposed method on a diverse set of\ntime series datasets from various domains. Our approach outperforms existing\nstate-of-the-art URL methods across diverse downstream tasks.", "AI": {"tldr": "The paper introduces a novel unsupervised representation learning method for time series data, focusing on aligning multi-modal features to improve scalability and performance.", "motivation": "Unsupervised learning for time series lacks alignment with downstream tasks, and existing feature fusion methods are complex and unscalable.", "method": "The approach aligns and binds multi-modal time series representations using spectral graph theory, simplifying the neural architecture to a single encoder.", "result": "The method outperforms state-of-the-art techniques on diverse datasets and downstream tasks.", "conclusion": "The proposed approach enhances scalability and performance by uncovering latent pattern associations in multi-modal features."}}
{"id": "2504.06751", "pdf": "https://arxiv.org/pdf/2504.06751", "abs": "https://arxiv.org/abs/2504.06751", "authors": ["Leszek Luchowski", "Dariusz Pojda"], "title": "Visualization of a multidimensional point cloud as a 3D swarm of avatars", "categories": ["cs.CV", "cs.HC"], "comment": "24 pages, 11 figures", "summary": "The article presents an innovative approach to the visualization of\nmultidimensional data, using icons inspired by Chernoff faces. The approach\nmerges classical projection techniques with the assignment of particular data\ndimensions to mimic features, capitalizing on the natural ability of the human\nbrain to interpret facial expressions. We introduce a semantic division of data\ndimensions into intuitive and technical categories, assigning the former to\navatar features and projecting the latter into a hyperspace of four, or\npotentially more dimensions. The technique is implemented as a plugin to the\ndpVision open-source image handling platform. The plugin allows the data to be\ninteractively explored in the form of a swarm of avatars whose position in\nhyperspace as well as facial features represent various aspects of the data.\nSample visualizations, based on synthetic test data as well as the\n12-dimensional database on Portuguese Vinho Verde wines, confirm the usefulness\nof our approach to the analysis of complex data structures.", "AI": {"tldr": "An innovative method for visualizing multidimensional data using Chernoff-face-inspired icons, combining projection techniques and facial feature mapping for intuitive analysis.", "motivation": "To leverage the human brain's natural ability to interpret facial expressions for better understanding of complex multidimensional data.", "method": "Semantic division of data dimensions into intuitive (assigned to avatar features) and technical (projected into hyperspace). Implemented as a plugin for dpVision.", "result": "Successful visualization of synthetic and real-world data (e.g., Portuguese Vinho Verde wines), confirming the approach's effectiveness.", "conclusion": "The method provides a useful tool for interactive exploration and analysis of complex data structures."}}
{"id": "2312.08598", "pdf": "https://arxiv.org/pdf/2312.08598", "abs": "https://arxiv.org/abs/2312.08598", "authors": ["Andreas M\u00fcller", "Carlo Curino", "Raghu Ramakrishnan"], "title": "MotherNet: Fast Training and Inference via Hyper-Network Transformers", "categories": ["cs.LG", "I.2.6"], "comment": "17 pages, 13 figures", "summary": "Foundation models are transforming machine learning across many modalities,\nwith in-context learning replacing classical model training. Recent work on\ntabular data hints at a similar opportunity to build foundation models for\nclassification for numerical data. However, existing meta-learning approaches\ncan not compete with tree-based methods in terms of inference time. In this\npaper, we propose MotherNet, a hypernetwork architecture trained on synthetic\nclassification tasks that, once prompted with a never-seen-before training set\ngenerates the weights of a trained ``child'' neural-network by in-context\nlearning using a single forward pass. In contrast to most existing\nhypernetworks that are usually trained for relatively constrained multi-task\nsettings, MotherNet can create models for multiclass classification on\narbitrary tabular datasets without any dataset specific gradient descent. The\nchild network generated by MotherNet outperforms neural networks trained using\ngradient descent on small datasets, and is comparable to predictions by TabPFN\nand standard ML methods like Gradient Boosting. Unlike a direct application of\nTabPFN, MotherNet generated networks are highly efficient at inference time. We\nalso demonstrate that HyperFast is unable to perform effective in-context\nlearning on small datasets, and heavily relies on dataset specific fine-tuning\nand hyper-parameter tuning, while MotherNet requires no fine-tuning or\nper-dataset hyper-parameters.", "AI": {"tldr": "MotherNet, a hypernetwork architecture, generates trained neural networks for tabular data classification in one forward pass, outperforming gradient descent on small datasets and matching TabPFN and Gradient Boosting, while being efficient at inference.", "motivation": "To address the inefficiency of existing meta-learning approaches for tabular data and the need for dataset-specific training, MotherNet aims to enable in-context learning for arbitrary tabular datasets without gradient descent.", "method": "MotherNet is trained on synthetic tasks to generate child neural networks via in-context learning in a single forward pass, eliminating the need for dataset-specific gradient descent or hyperparameter tuning.", "result": "MotherNet outperforms gradient descent-trained networks on small datasets, matches TabPFN and Gradient Boosting, and is highly efficient at inference without fine-tuning.", "conclusion": "MotherNet provides a scalable and efficient solution for tabular data classification, surpassing traditional methods and avoiding the pitfalls of existing hypernetworks."}}
{"id": "2504.08049", "pdf": "https://arxiv.org/pdf/2504.08049", "abs": "https://arxiv.org/abs/2504.08049", "authors": ["Angelina Ibarra", "Joshua Peeples"], "title": "Patch distribution modeling framework adaptive cosine estimator (PaDiM-ACE) for anomaly detection and localization in synthetic aperture radar imagery", "categories": ["cs.CV"], "comment": "Accepted to SPIE, Defense and Commercial Sensing, Algorithms for\n  Synthetic Aperture Radar Imagery XXXII (April 2025)", "summary": "This work presents a new approach to anomaly detection and localization in\nsynthetic aperture radar imagery (SAR), expanding upon the existing patch\ndistribution modeling framework (PaDiM). We introduce the adaptive cosine\nestimator (ACE) detection statistic. PaDiM uses the Mahalanobis distance at\ninference, an unbounded metric. ACE instead uses the cosine similarity metric,\nproviding bounded anomaly detection scores. The proposed method is evaluated\nacross multiple SAR datasets, with performance metrics including the area under\nthe receiver operating curve (AUROC) at the image and pixel level, aiming for\nincreased performance in anomaly detection and localization of SAR imagery. The\ncode is publicly available:\nhttps://github.com/Advanced-Vision-and-Learning-Lab/PaDiM-ACE.", "AI": {"tldr": "A new anomaly detection method for SAR imagery using adaptive cosine estimator (ACE) improves upon PaDiM by providing bounded scores via cosine similarity.", "motivation": "To enhance anomaly detection and localization in SAR imagery by addressing the unbounded nature of Mahalanobis distance in PaDiM.", "method": "Introduces ACE, replacing Mahalanobis distance with cosine similarity for bounded anomaly scores, evaluated on SAR datasets.", "result": "Improved performance in anomaly detection and localization, measured by AUROC at image and pixel levels.", "conclusion": "The ACE-based method outperforms PaDiM, offering better anomaly detection and localization for SAR imagery."}}
{"id": "2405.14432", "pdf": "https://arxiv.org/pdf/2405.14432", "abs": "https://arxiv.org/abs/2405.14432", "authors": ["Youssef Allouah", "Rachid Guerraoui", "Nirupam Gupta", "Ahmed Jellouli", "Geovani Rizk", "John Stephan"], "title": "Adaptive Gradient Clipping for Robust Federated Learning", "categories": ["cs.LG"], "comment": null, "summary": "Robust federated learning aims to maintain reliable performance despite the\npresence of adversarial or misbehaving workers. While state-of-the-art (SOTA)\nrobust distributed gradient descent (Robust-DGD) methods were proven\ntheoretically optimal, their empirical success has often relied on\npre-aggregation gradient clipping. However, existing static clipping strategies\nyield inconsistent results: enhancing robustness against some attacks while\nbeing ineffective or even detrimental against others. To address this\nlimitation, we propose a principled adaptive clipping strategy, Adaptive Robust\nClipping (ARC), which dynamically adjusts clipping thresholds based on the\ninput gradients. We prove that ARC not only preserves the theoretical\nrobustness guarantees of SOTA Robust-DGD methods but also provably improves\nasymptotic convergence when the model is well-initialized. Extensive\nexperiments on benchmark image classification tasks confirm these theoretical\ninsights, demonstrating that ARC significantly enhances robustness,\nparticularly in highly heterogeneous and adversarial settings.", "AI": {"tldr": "Proposes Adaptive Robust Clipping (ARC) for federated learning to dynamically adjust clipping thresholds, improving robustness and convergence.", "motivation": "Existing static clipping strategies in robust federated learning yield inconsistent results against adversarial attacks.", "method": "Introduces ARC, an adaptive clipping strategy that adjusts thresholds based on input gradients.", "result": "ARC preserves theoretical robustness guarantees and improves asymptotic convergence, validated by experiments.", "conclusion": "ARC enhances robustness in heterogeneous and adversarial settings, outperforming static methods."}}
{"id": "2504.13580", "pdf": "https://arxiv.org/pdf/2504.13580", "abs": "https://arxiv.org/abs/2504.13580", "authors": ["Yuchen Rao", "Stefan Ainetter", "Sinisa Stekovic", "Vincent Lepetit", "Friedrich Fraundorfer"], "title": "Leveraging Automatic CAD Annotations for Supervised Learning in 3D Scene Understanding", "categories": ["cs.CV"], "comment": "Project page: https://stefan-ainetter.github.io/SCANnotatepp; CVPR'25\n  Workshop", "summary": "High-level 3D scene understanding is essential in many applications. However,\nthe challenges of generating accurate 3D annotations make development of deep\nlearning models difficult. We turn to recent advancements in automatic\nretrieval of synthetic CAD models, and show that data generated by such methods\ncan be used as high-quality ground truth for training supervised deep learning\nmodels. More exactly, we employ a pipeline akin to the one previously used to\nautomatically annotate objects in ScanNet scenes with their 9D poses and CAD\nmodels. This time, we apply it to the recent ScanNet++ v1 dataset, which\npreviously lacked such annotations. Our findings demonstrate that it is not\nonly possible to train deep learning models on these automatically-obtained\nannotations but that the resulting models outperform those trained on manually\nannotated data. We validate this on two distinct tasks: point cloud completion\nand single-view CAD model retrieval and alignment. Our results underscore the\npotential of automatic 3D annotations to enhance model performance while\nsignificantly reducing annotation costs. To support future research in 3D scene\nunderstanding, we will release our annotations, which we call SCANnotate++,\nalong with our trained models.", "AI": {"tldr": "Using synthetic CAD models for automatic 3D annotations improves deep learning model performance and reduces annotation costs, validated on ScanNet++ v1.", "motivation": "High-quality 3D annotations are hard to generate manually, hindering deep learning model development.", "method": "Employed an automatic pipeline to annotate ScanNet++ v1 with CAD models and 9D poses, similar to prior work on ScanNet.", "result": "Models trained on automatic annotations outperformed those using manual annotations in point cloud completion and CAD model retrieval tasks.", "conclusion": "Automatic 3D annotations are viable and superior, reducing costs and improving performance; annotations and models will be released as SCANnotate++."}}
{"id": "2405.16731", "pdf": "https://arxiv.org/pdf/2405.16731", "abs": "https://arxiv.org/abs/2405.16731", "authors": ["Jeonghwan Cheon", "Sang Wan Lee", "Se-Bum Paik"], "title": "Pretraining with Random Noise for Fast and Robust Learning without Weight Transport", "categories": ["cs.LG", "cs.NE"], "comment": null, "summary": "The brain prepares for learning even before interacting with the environment,\nby refining and optimizing its structures through spontaneous neural activity\nthat resembles random noise. However, the mechanism of such a process has yet\nto be thoroughly understood, and it is unclear whether this process can benefit\nthe algorithm of machine learning. Here, we study this issue using a neural\nnetwork with a feedback alignment algorithm, demonstrating that pretraining\nneural networks with random noise increases the learning efficiency as well as\ngeneralization abilities without weight transport. First, we found that random\nnoise training modifies forward weights to match backward synaptic feedback,\nwhich is necessary for teaching errors by feedback alignment. As a result, a\nnetwork with pre-aligned weights learns notably faster than a network without\nrandom noise training, even reaching a convergence speed comparable to that of\na backpropagation algorithm. Sequential training with both random noise and\ndata brings weights closer to synaptic feedback than training solely with data,\nenabling more precise credit assignment and faster learning. We also found that\neach readout probability approaches the chance level and that the effective\ndimensionality of weights decreases in a network pretrained with random noise.\nThis pre-regularization allows the network to learn simple solutions of a low\nrank, reducing the generalization loss during subsequent training. This also\nenables the network robustly to generalize a novel, out-of-distribution\ndataset. Lastly, we confirmed that random noise pretraining reduces the amount\nof meta-loss, enhancing the network ability to adapt to various tasks. Overall,\nour results suggest that random noise training with feedback alignment offers a\nstraightforward yet effective method of pretraining that facilitates quick and\nreliable learning without weight transport.", "AI": {"tldr": "Pretraining neural networks with random noise improves learning efficiency and generalization without weight transport, matching forward and backward weights for faster convergence and better adaptability.", "motivation": "To understand how spontaneous neural activity (resembling random noise) prepares the brain for learning and whether this can benefit machine learning algorithms.", "method": "Used a neural network with feedback alignment, pretraining it with random noise before data training. Analyzed weight alignment, learning speed, and generalization.", "result": "Random noise pretraining aligns weights for faster learning, reduces effective dimensionality, and improves generalization and adaptability to novel tasks.", "conclusion": "Random noise pretraining with feedback alignment is an effective method for enhancing learning efficiency and generalization in neural networks."}}
{"id": "2505.04938", "pdf": "https://arxiv.org/pdf/2505.04938", "abs": "https://arxiv.org/abs/2505.04938", "authors": ["Ying Zhang", "Shuai Guo", "Chenxi Sun", "Yuchen Zhu", "Jinhai Xiang"], "title": "FF-PNet: A Pyramid Network Based on Feature and Field for Brain Image Registration", "categories": ["cs.CV", "cs.IR"], "comment": null, "summary": "In recent years, deformable medical image registration techniques have made\nsignificant progress. However, existing models still lack efficiency in\nparallel extraction of coarse and fine-grained features. To address this, we\nconstruct a new pyramid registration network based on feature and deformation\nfield (FF-PNet). For coarse-grained feature extraction, we design a Residual\nFeature Fusion Module (RFFM), for fine-grained image deformation, we propose a\nResidual Deformation Field Fusion Module (RDFFM). Through the parallel\noperation of these two modules, the model can effectively handle complex image\ndeformations. It is worth emphasizing that the encoding stage of FF-PNet only\nemploys traditional convolutional neural networks without any attention\nmechanisms or multilayer perceptrons, yet it still achieves remarkable\nimprovements in registration accuracy, fully demonstrating the superior feature\ndecoding capabilities of RFFM and RDFFM. We conducted extensive experiments on\nthe LPBA and OASIS datasets. The results show our network consistently\noutperforms popular methods in metrics like the Dice Similarity Coefficient.", "AI": {"tldr": "A new pyramid registration network (FF-PNet) with parallel coarse and fine-grained feature extraction modules (RFFM and RDFFM) improves deformable medical image registration efficiency and accuracy.", "motivation": "Existing models lack efficiency in parallel extraction of coarse and fine-grained features for deformable medical image registration.", "method": "Proposes FF-PNet with Residual Feature Fusion Module (RFFM) for coarse features and Residual Deformation Field Fusion Module (RDFFM) for fine-grained deformation, using traditional CNNs without attention mechanisms.", "result": "Outperforms popular methods on LPBA and OASIS datasets, achieving higher Dice Similarity Coefficient.", "conclusion": "FF-PNet demonstrates superior feature decoding and deformation handling, proving effective without advanced mechanisms like attention or MLPs."}}
{"id": "2409.17264", "pdf": "https://arxiv.org/pdf/2409.17264", "abs": "https://arxiv.org/abs/2409.17264", "authors": ["Amey Agrawal", "Haoran Qiu", "Junda Chen", "\u00cd\u00f1igo Goiri", "Chaojie Zhang", "Rayyan Shahid", "Ramachandran Ramjee", "Alexey Tumanov", "Esha Choukse"], "title": "Medha: Efficiently Serving Multi-Million Context Length LLM Inference Requests Without Approximations", "categories": ["cs.LG", "cs.DC"], "comment": null, "summary": "As large language models (LLMs) handle increasingly longer contexts, serving\nlong inference requests of millions of tokens presents unique challenges. We\nshow that existing work for long context inference is largely based on\ntechniques from long context training, and does not handle the high variability\nin input lengths during inference. This leads to inefficient resource\nutilization, server fragmentation, and head-of-line (HOL) blocking.\n  We present Medha, an end-to-end system for efficient long-context LLM\ninference that addresses these challenges through fine-grained time sharing.\nMedha introduces three key innovations: (1) the mechanism of adaptive prefill\nchunking to help mitigate HOL blocking with preemption; (2) two new parallelism\nstrategies: Sequence Pipeline Parallelism (SPP) to reduce time-to-first-token\nby pipelining prefill chunks, and KV-Cache Parallelism (KVP) to lower\ntime-peroutput-token by distributing decoding across servers; and (3) a novel\ninput-length aware least remaining slack scheduling to meet Service Level\nObjectives (SLOs).\n  Medha enables exact inference scaling beyond 10 million tokens, maintaining\nhigh throughput and low latency across mixed-length workloads. Compared to\nstate-of-the-art systems, Medha reduces server fragmentation, cuts median\nlatency by up to 30x, and improves throughput by over 5x, delivering\nproduction-scale long-context inference without compromising performance on\nshorter requests.", "AI": {"tldr": "Medha is a system for efficient long-context LLM inference, addressing challenges like HOL blocking and server fragmentation with adaptive prefill chunking, novel parallelism strategies, and input-length aware scheduling.", "motivation": "Existing long-context inference methods are inefficient due to high input length variability, leading to poor resource utilization and latency.", "method": "Medha uses adaptive prefill chunking, Sequence Pipeline Parallelism (SPP), KV-Cache Parallelism (KVP), and input-length aware scheduling.", "result": "Medha scales beyond 10M tokens, reduces latency by 30x, and improves throughput by 5x compared to state-of-the-art systems.", "conclusion": "Medha enables production-scale long-context inference with high performance across mixed-length workloads."}}
{"id": "2505.05049", "pdf": "https://arxiv.org/pdf/2505.05049", "abs": "https://arxiv.org/abs/2505.05049", "authors": ["Timo Kaiser", "Thomas Norrenbrock", "Bodo Rosenhahn"], "title": "UncertainSAM: Fast and Efficient Uncertainty Quantification of the Segment Anything Model", "categories": ["cs.CV"], "comment": "Accepted to ICML'25", "summary": "The introduction of the Segment Anything Model (SAM) has paved the way for\nnumerous semantic segmentation applications. For several tasks, quantifying the\nuncertainty of SAM is of particular interest. However, the ambiguous nature of\nthe class-agnostic foundation model SAM challenges current uncertainty\nquantification (UQ) approaches. This paper presents a theoretically motivated\nuncertainty quantification model based on a Bayesian entropy formulation\njointly respecting aleatoric, epistemic, and the newly introduced task\nuncertainty. We use this formulation to train USAM, a lightweight post-hoc UQ\nmethod. Our model traces the root of uncertainty back to under-parameterised\nmodels, insufficient prompts or image ambiguities. Our proposed deterministic\nUSAM demonstrates superior predictive capabilities on the SA-V, MOSE, ADE20k,\nDAVIS, and COCO datasets, offering a computationally cheap and easy-to-use UQ\nalternative that can support user-prompting, enhance semi-supervised pipelines,\nor balance the tradeoff between accuracy and cost efficiency.", "AI": {"tldr": "The paper introduces USAM, a lightweight Bayesian entropy-based uncertainty quantification method for the Segment Anything Model (SAM), addressing aleatoric, epistemic, and task uncertainty.", "motivation": "Quantifying uncertainty in SAM is challenging due to its class-agnostic nature, prompting the need for a robust uncertainty quantification approach.", "method": "Proposes USAM, a post-hoc Bayesian entropy-based model that identifies uncertainty sources like under-parameterization, insufficient prompts, or image ambiguities.", "result": "USAM outperforms on SA-V, MOSE, ADE20k, DAVIS, and COCO datasets, offering a cheap and user-friendly UQ solution.", "conclusion": "USAM provides an efficient uncertainty quantification alternative for SAM, enhancing semi-supervised pipelines and balancing accuracy-cost tradeoffs."}}
{"id": "2410.08709", "pdf": "https://arxiv.org/pdf/2410.08709", "abs": "https://arxiv.org/abs/2410.08709", "authors": ["Satoshi Hayakawa", "Yuhta Takida", "Masaaki Imaizumi", "Hiromi Wakaki", "Yuki Mitsufuji"], "title": "Distillation of Discrete Diffusion through Dimensional Correlations", "categories": ["cs.LG", "cs.NA", "math.NA", "stat.ML"], "comment": "39 pages, ICML 2025 accepted", "summary": "Diffusion models have demonstrated exceptional performances in various fields\nof generative modeling, but suffer from slow sampling speed due to their\niterative nature. While this issue is being addressed in continuous domains,\ndiscrete diffusion models face unique challenges, particularly in capturing\ndependencies between elements (e.g., pixel relationships in image, sequential\ndependencies in language) mainly due to the computational cost of processing\nhigh-dimensional joint distributions. In this paper, (i) we propose \"mixture\"\nmodels for discrete diffusion that are capable of treating dimensional\ncorrelations while remaining scalable, and (ii) we provide a set of loss\nfunctions for distilling the iterations of existing models. Two primary\ntheoretical insights underpin our approach: First, conventional models with\nelement-wise independence can well approximate the data distribution, but\nessentially require {\\it many sampling steps}. Second, our loss functions\nenable the mixture models to distill such many-step conventional models into\njust a few steps by learning the dimensional correlations. Our experimental\nresults show the effectiveness of the proposed method in distilling pretrained\ndiscrete diffusion models across image and language domains. The code used in\nthe paper is available at https://github.com/sony/di4c .", "AI": {"tldr": "The paper introduces 'mixture' models for discrete diffusion to address slow sampling by capturing dimensional correlations and proposes loss functions for distilling iterations of existing models.", "motivation": "Discrete diffusion models suffer from slow sampling and struggle with dependencies between elements due to computational costs.", "method": "Proposes mixture models for scalable discrete diffusion and loss functions to distill iterations of existing models.", "result": "Effective distillation of pretrained discrete diffusion models in image and language domains.", "conclusion": "The method successfully reduces sampling steps while maintaining performance, with code available for reproducibility."}}
{"id": "2312.09968", "pdf": "https://arxiv.org/pdf/2312.09968", "abs": "https://arxiv.org/abs/2312.09968", "authors": ["Doruk Aksoy", "Huolin L. Xin", "Timothy J. Rupert", "William J. Bowman"], "title": "Human Perception-Inspired Grain Segmentation Refinement Using Conditional Random Fields", "categories": ["cond-mat.mtrl-sci", "cs.CV"], "comment": null, "summary": "Automated detection of grain boundaries in electron microscope images of\npolycrystalline materials could help accelerate the nanoscale characterization\nof myriad engineering materials and novel materials under scientific research.\nAccurate segmentation of interconnected line networks, such as grain boundaries\nin polycrystalline material microstructures, poses a significant challenge due\nto the fragmented masks produced by conventional computer vision algorithms,\nincluding convolutional neural networks. These algorithms struggle with thin\nmasks, often necessitating post-processing for effective contour closure and\ncontinuity. Previous approaches in this domain have typically relied on custom\npost-processing techniques that are problem-specific and heavily dependent on\nthe quality of the mask obtained from a computer vision algorithm. Addressing\nthis issue, this paper introduces a fast, high-fidelity post-processing\ntechnique that is universally applicable to segmentation masks of\ninterconnected line networks. Leveraging domain knowledge about grain boundary\nconnectivity, this method employs conditional random fields and perceptual\ngrouping rules to refine segmentation masks of any image with a discernible\ngrain structure. This approach significantly enhances segmentation mask\naccuracy, achieving a 79% segment identification accuracy in validation with a\nU-Net model on electron microscopy images of a polycrystalline oxide.\nAdditionally, a novel grain alignment metric is introduced, showing a 51%\nimprovement in grain alignment. This method not only enables rapid and accurate\nsegmentation but also facilitates an unprecedented level of data analysis,\nsignificantly improving the statistical representation of grain boundary\nnetworks, making it suitable for a range of disciplines where precise\nsegmentation of interconnected line networks is essential.", "AI": {"tldr": "A universal post-processing technique improves grain boundary segmentation in electron microscope images, enhancing accuracy and enabling better data analysis.", "motivation": "Automated detection of grain boundaries is challenging due to fragmented masks from conventional methods, requiring problem-specific post-processing.", "method": "Uses conditional random fields and perceptual grouping rules, leveraging domain knowledge for mask refinement.", "result": "Achieves 79% segment identification accuracy and 51% improvement in grain alignment.", "conclusion": "The method offers rapid, accurate segmentation and improved statistical analysis, applicable across disciplines."}}
{"id": "2410.16386", "pdf": "https://arxiv.org/pdf/2410.16386", "abs": "https://arxiv.org/abs/2410.16386", "authors": ["Haoyan Xu", "Kay Liu", "Zhengtao Yao", "Philip S. Yu", "Mengyuan Li", "Kaize Ding", "Yue Zhao"], "title": "LEGO-Learn: Label-Efficient Graph Open-Set Learning", "categories": ["cs.LG", "cs.SI"], "comment": null, "summary": "How can we train graph-based models to recognize unseen classes while keeping\nlabeling costs low? Graph open-set learning (GOL) and out-of-distribution (OOD)\ndetection aim to address this challenge by training models that can accurately\nclassify known, in-distribution (ID) classes while identifying and handling\npreviously unseen classes during inference. It is critical for high-stakes,\nreal-world applications where models frequently encounter unexpected data,\nincluding finance, security, and healthcare. However, current GOL methods\nassume access to many labeled ID samples, which is unrealistic for large-scale\ngraphs due to high annotation costs. In this paper, we propose LEGO-Learn\n(Label-Efficient Graph Open-set Learning), a novel framework that tackles\nopen-set node classification on graphs within a given label budget by selecting\nthe most informative ID nodes. LEGO-Learn employs a GNN-based filter to\nidentify and exclude potential OOD nodes and then select highly informative ID\nnodes for labeling using the K-Medoids algorithm. To prevent the filter from\ndiscarding valuable ID examples, we introduce a classifier that differentiates\nbetween the C known ID classes and an additional class representing OOD nodes\n(hence, a C+1 classifier). This classifier uses a weighted cross-entropy loss\nto balance the removal of OOD nodes while retaining informative ID nodes.\nExperimental results on four real-world datasets demonstrate that LEGO-Learn\nsignificantly outperforms leading methods, with up to a 6.62% improvement in ID\nclassification accuracy and a 7.49% increase in AUROC for OOD detection.", "AI": {"tldr": "LEGO-Learn is a label-efficient framework for graph open-set learning, improving ID classification and OOD detection by selectively labeling informative nodes.", "motivation": "Addressing the challenge of training graph models for unseen classes with limited labeled data, crucial for real-world applications like finance and healthcare.", "method": "Uses a GNN-based filter to exclude OOD nodes and K-Medoids to select informative ID nodes, with a C+1 classifier for balanced OOD removal and ID retention.", "result": "Achieves up to 6.62% better ID classification accuracy and 7.49% higher AUROC for OOD detection on four datasets.", "conclusion": "LEGO-Learn effectively balances label efficiency and performance, outperforming existing methods in open-set graph learning."}}
{"id": "2502.06380", "pdf": "https://arxiv.org/pdf/2502.06380", "abs": "https://arxiv.org/abs/2502.06380", "authors": ["Yiru Jiao", "Sander van Cranenburgh", "Simeon Calvert", "Hans van Lint"], "title": "Structure-preserving contrastive learning for spatial time series", "categories": ["cs.LG", "cs.CV"], "comment": "TL;DR: Preserving certain structures of similarity relations in\n  spatio-temporal data can improve downstream task performance via contrastive\n  learning", "summary": "The effectiveness of neural network models largely relies on learning\nmeaningful latent patterns from data, where self-supervised learning of\ninformative representations can enhance model performance and generalisability.\nHowever, self-supervised representation learning for spatially characterised\ntime series, which are ubiquitous in transportation domain, poses unique\nchallenges due to the necessity of maintaining fine-grained spatio-temporal\nsimilarities in the latent space. In this study, we introduce two\nstructure-preserving regularisers for the contrastive learning of spatial time\nseries: one regulariser preserves the topology of similarities between\ninstances, and the other preserves the graph geometry of similarities across\nspatial and temporal dimensions. To balance the contrastive learning objective\nand the need for structure preservation, we propose a dynamic weighting\nmechanism that adaptively manages this trade-off and stabilises training. We\nvalidate the proposed method through extensive experiments, including\nmultivariate time series classification to demonstrate its general\napplicability, as well as macroscopic and microscopic traffic prediction to\nhighlight its particular usefulness in encoding traffic interactions. Across\nall tasks, our method preserves the similarity structures more effectively and\nimproves state-of-the-art task performances. This method can be integrated with\nan arbitrary neural network model and is particularly beneficial for time\nseries data with spatial or geographical features. Furthermore, our findings\nsuggest that well-preserved similarity structures in the latent space indicate\nmore informative and useful representations. This provides insights to design\nmore effective neural networks for data-driven transportation research. Our\ncode is made openly accessible with all resulting data at\nhttps://github.com/yiru-jiao/spclt", "AI": {"tldr": "The paper introduces two structure-preserving regularisers for contrastive learning of spatial time series, enhancing model performance by preserving spatio-temporal similarities.", "motivation": "Self-supervised learning for spatially characterised time series faces challenges in maintaining fine-grained spatio-temporal similarities in the latent space.", "method": "Proposes two regularisers (topology and graph geometry preservation) and a dynamic weighting mechanism to balance contrastive learning and structure preservation.", "result": "The method improves state-of-the-art task performances and preserves similarity structures effectively across tasks like traffic prediction.", "conclusion": "Well-preserved similarity structures lead to more informative representations, benefiting neural networks for spatial or geographical time series data."}}
{"id": "2410.18082", "pdf": "https://arxiv.org/pdf/2410.18082", "abs": "https://arxiv.org/abs/2410.18082", "authors": ["Renhao Wang", "Kevin Frans", "Pieter Abbeel", "Sergey Levine", "Alexei A. Efros"], "title": "Prioritized Generative Replay", "categories": ["cs.LG"], "comment": "Project page available at: https://pgenreplay.github.io", "summary": "Sample-efficient online reinforcement learning often uses replay buffers to\nstore experience for reuse when updating the value function. However, uniform\nreplay is inefficient, since certain classes of transitions can be more\nrelevant to learning. While prioritization of more useful samples is helpful,\nthis strategy can also lead to overfitting, as useful samples are likely to be\nmore rare. In this work, we instead propose a prioritized, parametric version\nof an agent's memory, using generative models to capture online experience.\nThis paradigm enables (1) densification of past experience, with new\ngenerations that benefit from the generative model's generalization capacity\nand (2) guidance via a family of \"relevance functions\" that push these\ngenerations towards more useful parts of an agent's acquired history. We show\nthis recipe can be instantiated using conditional diffusion models and simple\nrelevance functions such as curiosity- or value-based metrics. Our approach\nconsistently improves performance and sample efficiency in both state- and\npixel-based domains. We expose the mechanisms underlying these gains, showing\nhow guidance promotes diversity in our generated transitions and reduces\noverfitting. We also showcase how our approach can train policies with even\nhigher update-to-data ratios than before, opening up avenues to better scale\nonline RL agents.", "AI": {"tldr": "The paper proposes a prioritized, parametric memory system using generative models to improve sample efficiency in online reinforcement learning, reducing overfitting and enhancing performance.", "motivation": "Uniform replay buffers in reinforcement learning are inefficient, and prioritization can lead to overfitting. The authors aim to improve this by leveraging generative models for densification and guided sampling.", "method": "The approach uses conditional diffusion models and relevance functions (e.g., curiosity- or value-based metrics) to generate and prioritize useful transitions.", "result": "The method improves performance and sample efficiency in state- and pixel-based domains, promotes diversity in transitions, and allows higher update-to-data ratios.", "conclusion": "The proposed framework enhances online RL by mitigating overfitting and improving scalability, demonstrating the potential of generative models in reinforcement learning."}}
{"id": "2503.07085", "pdf": "https://arxiv.org/pdf/2503.07085", "abs": "https://arxiv.org/abs/2503.07085", "authors": ["Ruidan Xing", "Runyi Huang", "Qing Xu", "Lei He"], "title": "RS2AD: End-to-End Autonomous Driving Data Generation from Roadside Sensor Observations", "categories": ["cs.RO", "cs.CV"], "comment": null, "summary": "End-to-end autonomous driving solutions, which process multi-modal sensory\ndata to directly generate refined control commands, have become a dominant\nparadigm in autonomous driving research. However, these approaches\npredominantly depend on single-vehicle data collection for model training and\noptimization, resulting in significant challenges such as high data acquisition\nand annotation costs, the scarcity of critical driving scenarios, and\nfragmented datasets that impede model generalization. To mitigate these\nlimitations, we introduce RS2AD, a novel framework for reconstructing and\nsynthesizing vehicle-mounted LiDAR data from roadside sensor observations.\nSpecifically, our method transforms roadside LiDAR point clouds into the\nvehicle-mounted LiDAR coordinate system by leveraging the target vehicle's\nrelative pose. Subsequently, high-fidelity vehicle-mounted LiDAR data is\nsynthesized through virtual LiDAR modeling, point cloud classification, and\nresampling techniques. To the best of our knowledge, this is the first approach\nto reconstruct vehicle-mounted LiDAR data from roadside sensor inputs.\nExtensive experimental evaluations demonstrate that incorporating the data\ngenerated by the RS2AD method (the RS2V-L dataset) into model training as a\nsupplement to the KITTI dataset can significantly enhance the accuracy of 3D\nobject detection and greatly improve the efficiency of end-to-end autonomous\ndriving data generation. These findings strongly validate the effectiveness of\nthe proposed method and underscore its potential in reducing dependence on\ncostly vehicle-mounted data collection while improving the robustness of\nautonomous driving models.", "AI": {"tldr": "RS2AD reconstructs vehicle-mounted LiDAR data from roadside sensors, enhancing autonomous driving model training by reducing reliance on costly single-vehicle data.", "motivation": "High costs and scarcity of critical scenarios in single-vehicle data collection hinder autonomous driving model generalization.", "method": "Transforms roadside LiDAR point clouds into vehicle-mounted coordinates using virtual LiDAR modeling, classification, and resampling.", "result": "RS2AD-generated data (RS2V-L) improves 3D object detection accuracy and data generation efficiency when combined with KITTI.", "conclusion": "RS2AD reduces dependency on expensive vehicle-mounted data and boosts model robustness, validating its effectiveness."}}
{"id": "2412.02094", "pdf": "https://arxiv.org/pdf/2412.02094", "abs": "https://arxiv.org/abs/2412.02094", "authors": ["Abdullah Al Mamun", "Abyad Enan", "Debbie A. Indah", "Judith Mwakalonge", "Gurcan Comert", "Mashrur Chowdhury"], "title": "Crash Severity Risk Modeling Strategies under Data Imbalance", "categories": ["cs.LG", "cs.CY", "stat.AP"], "comment": "This second revised version has been resubmitted to the\n  Transportation Research Record: Journal of the Transportation Research Board\n  after addressing the reviewers' comments and is currently awaiting the final\n  decision", "summary": "This study investigates crash severity risk modeling strategies for work\nzones involving large vehicles (i.e., trucks, buses, and vans) under crash data\nimbalance between low-severity (LS) and high-severity (HS) crashes. We utilized\ncrash data involving large vehicles in South Carolina work zones from 2014 to\n2018, which included four times more LS crashes than HS crashes. The objective\nof this study is to evaluate the crash severity prediction performance of\nvarious statistical, machine learning, and deep learning models under different\nfeature selection and data balancing techniques. Findings highlight a disparity\nin LS and HS predictions, with lower accuracy for HS crashes due to class\nimbalance and feature overlap. Discriminative Mutual Information (DMI) yields\nthe most effective feature set for predicting HS crashes without requiring data\nbalancing, particularly when paired with gradient boosting models and deep\nneural networks such as CatBoost, NeuralNetTorch, XGBoost, and LightGBM. Data\nbalancing techniques such as NearMiss-1 maximize HS recall when combined with\nDMI-selected features and certain models such as LightGBM, making them\nwell-suited for HS crash prediction. Conversely, RandomUnderSampler, HS Class\nWeighting, and RandomOverSampler achieve more balanced performance, which is\ndefined as an equitable trade-off between LS and HS metrics, especially when\napplied to NeuralNetTorch, NeuralNetFastAI, CatBoost, LightGBM, and Bayesian\nMixed Logit (BML) using merged feature sets or models without feature\nselection. The insights from this study offer safety analysts guidance on\nselecting models, feature selection, and data balancing techniques aligned with\nspecific safety goals, providing a robust foundation for enhancing work-zone\ncrash severity prediction.", "AI": {"tldr": "The study evaluates crash severity prediction models for work zones with large vehicles, addressing data imbalance between low-severity (LS) and high-severity (HS) crashes. Discriminative Mutual Information (DMI) and specific models like CatBoost and LightGBM show promise for HS prediction, while balancing techniques improve overall performance.", "motivation": "To improve crash severity prediction in work zones involving large vehicles, especially under imbalanced LS and HS crash data.", "method": "Used crash data from South Carolina (2014-2018) to test statistical, machine learning, and deep learning models with feature selection (DMI) and data balancing techniques (e.g., NearMiss-1, RandomUnderSampler).", "result": "DMI with gradient boosting models (e.g., CatBoost, LightGBM) excelled in HS prediction without balancing. Balancing techniques like NearMiss-1 improved HS recall, while others (e.g., RandomUnderSampler) balanced LS and HS metrics.", "conclusion": "The study provides actionable insights for safety analysts to choose models, feature selection, and balancing techniques tailored to specific goals, enhancing work-zone crash severity prediction."}}
{"id": "2501.18196", "pdf": "https://arxiv.org/pdf/2501.18196", "abs": "https://arxiv.org/abs/2501.18196", "authors": ["Qingxiang Liu", "Chenghao Liu", "Sheng Sun", "Di Yao", "Yuxuan Liang"], "title": "GDformer: Going Beyond Subsequence Isolation for Multivariate Time Series Anomaly Detection", "categories": ["cs.LG"], "comment": null, "summary": "Unsupervised anomaly detection of multivariate time series is a challenging\ntask, given the requirements of deriving a compact detection criterion without\naccessing the anomaly points. The existing methods are mainly based on\nreconstruction error or association divergence, which are both confined to\nisolated subsequences with limited horizons, hardly promising unified\nseries-level criterion. In this paper, we propose the Global\nDictionary-enhanced Transformer (GDformer) with a renovated dictionary-based\ncross attention mechanism to cultivate the global representations shared by all\nnormal points in the entire series. Accordingly, the cross-attention maps\nreflect the correlation weights between the point and global representations,\nwhich naturally leads to the representation-wise similarity-based detection\ncriterion. To foster more compact detection boundary, prototypes are introduced\nto capture the distribution of normal point-global correlation weights.\nGDformer consistently achieves state-of-the-art unsupervised anomaly detection\nperformance on five real-world benchmark datasets. Further experiments validate\nthe global dictionary has great transferability among various datasets. The\ncode is available at https://github.com/yuppielqx/GDformer.", "AI": {"tldr": "GDformer introduces a global dictionary-enhanced transformer for unsupervised anomaly detection in multivariate time series, achieving state-of-the-art results.", "motivation": "Existing methods for unsupervised anomaly detection in multivariate time series rely on isolated subsequences, lacking a unified series-level criterion.", "method": "Proposes GDformer with a dictionary-based cross-attention mechanism to derive global representations and a similarity-based detection criterion. Introduces prototypes for compact detection boundaries.", "result": "GDformer achieves state-of-the-art performance on five benchmark datasets and shows strong transferability.", "conclusion": "GDformer provides an effective, unified approach for unsupervised anomaly detection in multivariate time series, with demonstrated transferability."}}
{"id": "2502.01778", "pdf": "https://arxiv.org/pdf/2502.01778", "abs": "https://arxiv.org/abs/2502.01778", "authors": ["Stavros Orfanoudakis", "Nanda Kishor Panda", "Peter Palensky", "Pedro P. Vergara"], "title": "GNN-DT: Graph Neural Network Enhanced Decision Transformer for Efficient Optimization in Dynamic Environments", "categories": ["cs.LG", "cs.SY", "eess.SY"], "comment": null, "summary": "Reinforcement Learning (RL) methods used for solving real-world optimization\nproblems often involve dynamic state-action spaces, larger scale, and sparse\nrewards, leading to significant challenges in convergence, scalability, and\nefficient exploration of the solution space. This study introduces GNN-DT, a\nnovel Decision Transformer (DT) architecture that integrates Graph Neural\nNetwork (GNN) embedders with a novel residual connection between input and\noutput tokens crucial for handling dynamic environments. By learning from\npreviously collected trajectories, GNN-DT tackles the sparse rewards\nlimitations of online RL algorithms and delivers high-quality solutions in\nreal-time. We evaluate GNN-DT on the complex electric vehicle (EV) charging\noptimization problem and prove that its performance is superior and requires\nsignificantly fewer training trajectories, thus improving sample efficiency\ncompared to existing DT and offline RL baselines. Furthermore, GNN-DT exhibits\nrobust generalization to unseen environments and larger action spaces,\naddressing a critical gap in prior offline and online RL approaches.", "AI": {"tldr": "GNN-DT, a novel Decision Transformer with GNN embedders and residual connections, improves RL for dynamic environments, outperforming baselines in EV charging optimization with better sample efficiency and generalization.", "motivation": "Addressing challenges in RL for real-world problems like dynamic state-action spaces, large scale, and sparse rewards.", "method": "Integrates GNN embedders with a Decision Transformer and residual connections, learning from collected trajectories to handle sparse rewards.", "result": "Superior performance in EV charging optimization, requiring fewer training trajectories and showing robust generalization.", "conclusion": "GNN-DT effectively addresses limitations of existing RL methods, offering scalable and efficient solutions for dynamic environments."}}
{"id": "2502.02428", "pdf": "https://arxiv.org/pdf/2502.02428", "abs": "https://arxiv.org/abs/2502.02428", "authors": ["Xu Wang", "Puyu Han", "Jiaju Kang", "Weichao Pan", "Luqi Gong"], "title": "RIE-SenseNet: Riemannian Manifold Embedding of Multi-Source Industrial Sensor Signals for Robust Pattern Recognition", "categories": ["cs.LG"], "comment": null, "summary": "Industrial sensor networks produce complex signals with nonlinear structure\nand shifting distributions. We propose RIE-SenseNet, a novel geometry-aware\nTransformer model that embeds sensor data in a Riemannian manifold to tackle\nthese challenges. By leveraging hyperbolic geometry for sequence modeling and\nintroducing a manifold-based augmentation technique, RIE-SenseNet preserves\nsensor signal structure and generates realistic synthetic samples. Experiments\nshow RIE-SenseNet achieves >90% F1-score, far surpassing CNN and Transformer\nbaselines. These results illustrate the benefit of combining non-Euclidean\nfeature representations with geometry-consistent data augmentation for robust\npattern recognition in industrial sensing.", "AI": {"tldr": "RIE-SenseNet, a geometry-aware Transformer, embeds sensor data in a Riemannian manifold, outperforming baselines with >90% F1-score.", "motivation": "Industrial sensor networks produce complex, nonlinear signals with shifting distributions, requiring robust modeling.", "method": "RIE-SenseNet uses hyperbolic geometry for sequence modeling and manifold-based augmentation to preserve signal structure and generate synthetic samples.", "result": "Achieves >90% F1-score, surpassing CNN and Transformer baselines.", "conclusion": "Combining non-Euclidean representations with geometry-consistent augmentation improves industrial sensing robustness."}}
{"id": "2502.20162", "pdf": "https://arxiv.org/pdf/2502.20162", "abs": "https://arxiv.org/abs/2502.20162", "authors": ["Aristotelis Ballas", "Christos Diou"], "title": "Gradient-Guided Annealing for Domain Generalization", "categories": ["cs.LG"], "comment": "Paper accepted in CVPR2025", "summary": "Domain Generalization (DG) research has gained considerable traction as of\nlate, since the ability to generalize to unseen data distributions is a\nrequirement that eludes even state-of-the-art training algorithms. In this\npaper we observe that the initial iterations of model training play a key role\nin domain generalization effectiveness, since the loss landscape may be\nsignificantly different across the training and test distributions, contrary to\nthe case of i.i.d. data. Conflicts between gradients of the loss components of\neach domain lead the optimization procedure to undesirable local minima that do\nnot capture the domain-invariant features of the target classes. We propose\nalleviating domain conflicts in model optimization, by iteratively annealing\nthe parameters of a model in the early stages of training and searching for\npoints where gradients align between domains. By discovering a set of parameter\nvalues where gradients are updated towards the same direction for each data\ndistribution present in the training set, the proposed Gradient-Guided\nAnnealing (GGA) algorithm encourages models to seek out minima that exhibit\nimproved robustness against domain shifts. The efficacy of GGA is evaluated on\nfive widely accepted and challenging image classification domain generalization\nbenchmarks, where its use alone is able to establish highly competitive or even\nstate-of-the-art performance. Moreover, when combined with previously proposed\ndomain-generalization algorithms it is able to consistently improve their\neffectiveness by significant margins.", "AI": {"tldr": "The paper introduces Gradient-Guided Annealing (GGA) to improve domain generalization by aligning gradients early in training, achieving state-of-the-art results.", "motivation": "Domain generalization is challenging due to conflicting gradients across domains, leading to poor generalization.", "method": "Proposes GGA, which anneals parameters early to align gradients and find domain-invariant features.", "result": "GGA achieves competitive or state-of-the-art performance on benchmarks and enhances existing methods.", "conclusion": "GGA effectively addresses domain conflicts, improving robustness to domain shifts."}}
{"id": "2503.14338", "pdf": "https://arxiv.org/pdf/2503.14338", "abs": "https://arxiv.org/abs/2503.14338", "authors": ["Daniel Herbst", "Stefanie Jegelka"], "title": "Higher-Order Graphon Neural Networks: Approximation and Cut Distance", "categories": ["cs.LG"], "comment": "53 pages, 6 figures, 2 tables. ICLR 2025 camera ready", "summary": "Graph limit models, like graphons for limits of dense graphs, have recently\nbeen used to study size transferability of graph neural networks (GNNs). While\nmost literature focuses on message passing GNNs (MPNNs), in this work we attend\nto the more powerful higher-order GNNs. First, we extend the $k$-WL test for\ngraphons (B\\\"oker, 2023) to the graphon-signal space and introduce\nsignal-weighted homomorphism densities as a key tool. As an exemplary focus, we\ngeneralize Invariant Graph Networks (IGNs) to graphons, proposing Invariant\nGraphon Networks (IWNs) defined via a subset of the IGN basis corresponding to\nbounded linear operators. Even with this restricted basis, we show that IWNs of\norder $k$ are at least as powerful as the $k$-WL test, and we establish\nuniversal approximation results for graphon-signals in $L^p$ distances. This\nsignificantly extends the prior work of Cai & Wang (2022), showing that IWNs--a\nsubset of their IGN-small--retain effectively the same expressivity as the full\nIGN basis in the limit. In contrast to their approach, our blueprint of IWNs\nalso aligns better with the geometry of graphon space, for example facilitating\ncomparability to MPNNs. We highlight that, while typical higher-order GNNs are\ndiscontinuous w.r.t. cut distance--which causes their lack of convergence and\nis inherently tied to the definition of $k$-WL--transferability remains\nachievable.", "AI": {"tldr": "The paper extends the $k$-WL test to graphon-signal space and introduces signal-weighted homomorphism densities. It generalizes Invariant Graph Networks (IGNs) to graphons, proposing Invariant Graphon Networks (IWNs), showing they retain expressivity and achieve universal approximation in $L^p$ distances.", "motivation": "To study size transferability of higher-order GNNs, extending beyond MPNNs, and align better with graphon space geometry.", "method": "Extends $k$-WL test to graphon-signal space, introduces signal-weighted homomorphism densities, and generalizes IGNs to IWNs with a restricted basis.", "result": "IWNs of order $k$ are as powerful as $k$-WL, achieve universal approximation, and retain expressivity despite a restricted basis.", "conclusion": "Transferability is achievable for higher-order GNNs despite discontinuity w.r.t. cut distance, and IWNs align better with graphon geometry."}}
{"id": "2503.21223", "pdf": "https://arxiv.org/pdf/2503.21223", "abs": "https://arxiv.org/abs/2503.21223", "authors": ["Zhihan Zhang", "Xunkai Li", "Zhu Lei", "Guang Zeng", "Ronghua Li", "Guoren Wang"], "title": "Rethinking Graph Structure Learning in the Era of LLMs", "categories": ["cs.LG"], "comment": "29 pages, 9 figures", "summary": "Recently, the emergence of LLMs has prompted researchers to integrate\nlanguage descriptions into graphs, aiming to enhance model encoding\ncapabilities from a data-centric perspective. This graph representation is\ncalled text-attributed graphs (TAGs). A review of prior advancements highlights\nthat graph structure learning (GSL) is a pivotal technique for improving data\nutility, making it highly relevant to efficient TAG learning. However, most GSL\nmethods are tailored for traditional graphs without textual information,\nunderscoring the necessity of developing a new GSL paradigm. Despite clear\nmotivations, it remains challenging: (1) How can we define a reasonable\noptimization objective for GSL in the era of LLMs, considering the massive\nparameters in LLM? (2) How can we design an efficient model architecture that\nenables seamless integration of LLM for this optimization objective? For\nQuestion 1, we reformulate existing GSL optimization objectives as a tree\noptimization framework, shifting the focus from obtaining a well-trained edge\npredictor to a language-aware tree sampler. For Question 2, we propose\ndecoupled and training-free model design principles for LLM integration,\nshifting the focus from computation-intensive fine-tuning to more efficient\ninference. Based on this, we propose Large Language and Tree Assistant (LLaTA),\nwhich leverages tree-based LLM in-context learning to enhance the understanding\nof topology and text, enabling reliable inference and generating improved graph\nstructure. Extensive experiments on 10 datasets demonstrate that LLaTA enjoys\nflexibility-incorporated with any backbone; scalability-outperforms other\nLLM-enhanced graph learning methods; effectiveness-achieves SOTA predictive\nperformance.", "AI": {"tldr": "The paper introduces LLaTA, a method integrating LLMs with graph structure learning (GSL) for text-attributed graphs (TAGs), addressing optimization and efficiency challenges.", "motivation": "To enhance TAG learning by integrating LLMs, overcoming limitations of traditional GSL methods that lack textual information.", "method": "Reformulates GSL objectives as a tree optimization framework and proposes decoupled, training-free LLM integration principles, leading to LLaTA.", "result": "LLaTA outperforms other LLM-enhanced methods, achieving state-of-the-art performance across 10 datasets.", "conclusion": "LLaTA effectively integrates LLMs with GSL for TAGs, offering flexibility, scalability, and superior predictive performance."}}
{"id": "2503.22567", "pdf": "https://arxiv.org/pdf/2503.22567", "abs": "https://arxiv.org/abs/2503.22567", "authors": ["Josh Millar", "Yushan Huang", "Sarab Sethi", "Hamed Haddadi", "Anil Madhavapeddy"], "title": "Benchmarking Ultra-Low-Power $\u03bc$NPUs", "categories": ["cs.LG", "cs.AR"], "comment": null, "summary": "Efficient on-device neural network (NN) inference has various advantages over\ncloud-based processing, including predictable latency, enhanced privacy,\ngreater reliability, and reduced operating costs for vendors. This has sparked\nthe recent rapid development of microcontroller-scale NN accelerators, often\nreferred to as neural processing units ($\\mu$NPUs), designed specifically for\nultra-low-power applications.\n  In this paper we present the first comparative evaluation of a number of\ncommercially-available $\\mu$NPUs, as well as the first independent benchmarks\nfor several of these platforms. We develop and open-source a model compilation\nframework to enable consistent benchmarking of quantized models across diverse\n$\\mu$NPU hardware. Our benchmark targets end-to-end performance and includes\nmodel inference latency, power consumption, and memory overhead, alongside\nother factors. The resulting analysis uncovers both expected performance trends\nas well as surprising disparities between hardware specifications and actual\nperformance, including $\\mu$NPUs exhibiting unexpected scaling behaviors with\nincreasing model complexity. Our framework provides a foundation for further\nevaluation of $\\mu$NPU platforms alongside valuable insights for both hardware\ndesigners and software developers in this rapidly evolving space.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2504.03122", "pdf": "https://arxiv.org/pdf/2504.03122", "abs": "https://arxiv.org/abs/2504.03122", "authors": ["Abdelmonem Elrefaey", "Rong Pan"], "title": "From Observation to Orientation: an Adaptive Integer Programming Approach to Intervention Design", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "Using both observational and experimental data, a causal discovery process\ncan identify the causal relationships between variables. A unique adaptive\nintervention design paradigm is presented in this work, where causal directed\nacyclic graphs (DAGs) are for effectively recovered with practical budgetary\nconsiderations. In order to choose treatments that optimize information gain\nunder these considerations, an iterative integer programming (IP) approach is\nproposed, which drastically reduces the number of experiments required.\nSimulations over a broad range of graph sizes and edge densities are used to\nassess the effectiveness of the suggested approach. Results show that the\nproposed adaptive IP approach achieves full causal graph recovery with fewer\nintervention iterations and variable manipulations than random intervention\nbaselines, and it is also flexible enough to accommodate a variety of practical\nconstraints.", "AI": {"tldr": "The paper proposes an adaptive intervention design using causal DAGs and integer programming to optimize information gain, reducing required experiments and handling practical constraints effectively.", "motivation": "To efficiently recover causal relationships between variables with minimal experiments while considering practical budgetary constraints.", "method": "An iterative integer programming (IP) approach is used to select treatments for optimal information gain, leveraging causal directed acyclic graphs (DAGs).", "result": "Simulations show the adaptive IP approach recovers full causal graphs with fewer interventions and manipulations than random baselines, while accommodating practical constraints.", "conclusion": "The proposed method is effective for causal discovery with reduced experimental costs and flexibility for real-world constraints."}}
{"id": "2504.04202", "pdf": "https://arxiv.org/pdf/2504.04202", "abs": "https://arxiv.org/abs/2504.04202", "authors": ["Harvey Dam", "Tripti Agarwal", "Ganesh Gopalakrishnan"], "title": "Directional Sign Loss: A Topology-Preserving Loss Function that Approximates the Sign of Finite Differences", "categories": ["cs.LG", "I.2.6"], "comment": null, "summary": "Preserving critical topological features in learned latent spaces is a\nfundamental challenge in representation learning, particularly for\ntopology-sensitive data. This paper introduces directional sign loss (DSL), a\nnovel loss function that approximates the number of mismatches in the signs of\nfinite differences between corresponding elements of two arrays. By penalizing\ndiscrepancies in critical points between input and reconstructed data, DSL\nencourages autoencoders and other learnable compressors to retain the\ntopological features of the original data. We present the mathematical\nformulation, complexity analysis, and practical implementation of DSL,\ncomparing its behavior to its non-differentiable counterpart and to other\ntopological measures. Experiments on one-, two-, and three-dimensional data\nshow that combining DSL with traditional loss functions preserves topological\nfeatures more effectively than traditional losses alone. Moreover, DSL serves\nas a differentiable, efficient proxy for common topology-based metrics,\nenabling its use in gradient-based optimization frameworks.", "AI": {"tldr": "The paper introduces Directional Sign Loss (DSL), a novel loss function to preserve topological features in learned latent spaces by penalizing mismatches in critical points between input and reconstructed data.", "motivation": "Preserving topological features in learned latent spaces is challenging, especially for topology-sensitive data. Existing methods often fail to retain these critical features.", "method": "DSL approximates mismatches in signs of finite differences between arrays, penalizing discrepancies in critical points. It is mathematically formulated, analyzed for complexity, and implemented for autoencoders.", "result": "Experiments on 1D, 2D, and 3D data show DSL combined with traditional losses preserves topology better than traditional losses alone. DSL also serves as a differentiable proxy for topology-based metrics.", "conclusion": "DSL effectively retains topological features in learned representations and is suitable for gradient-based optimization, offering a practical solution for topology-sensitive data."}}
{"id": "2504.18091", "pdf": "https://arxiv.org/pdf/2504.18091", "abs": "https://arxiv.org/abs/2504.18091", "authors": ["Shota Deguchi", "Mitsuteru Asai"], "title": "Reliable and Efficient Inverse Analysis using Physics-Informed Neural Networks with Distance Functions and Adaptive Weight Tuning", "categories": ["cs.LG"], "comment": "Added Figures 9, 10(b), 11(b), and A1, which were previously omitted\n  for clarity, but are now included for completeness. All results remain\n  unchanged", "summary": "Physics-informed neural networks have attracted significant attention in\nscientific machine learning for their capability to solve forward and inverse\nproblems governed by partial differential equations. However, the accuracy of\nPINN solutions is often limited by the treatment of boundary conditions.\nConventional penalty-based methods, which incorporate boundary conditions as\npenalty terms in the loss function, cannot guarantee exact satisfaction of the\ngiven boundary conditions and are highly sensitive to the choice of penalty\nparameters. This paper demonstrates that distance functions, specifically\nR-functions, can be leveraged to enforce boundary conditions, overcoming these\nlimitations. R-functions provide normalized distance fields, enabling accurate\nrepresentation of boundary geometries, including non-convex domains, and\nfacilitating various types of boundary conditions. We extend this distance\nfunction-based boundary condition imposition method to inverse problems using\nPINNs and introduce an adaptive weight tuning technique to ensure reliable and\nefficient inverse analysis. We demonstrate the efficacy of the method through\nseveral numerical experiments. Numerical results show that the proposed method\nsolves inverse problems more accurately and efficiently than penalty-based\nmethods, even in the presence of complex non-convex geometries. This approach\noffers a reliable and efficient framework for inverse analysis using PINNs,\nwith potential applications across a wide range of engineering problems.", "AI": {"tldr": "The paper proposes using R-functions to enforce boundary conditions in physics-informed neural networks (PINNs), improving accuracy and efficiency over traditional penalty-based methods, especially for inverse problems.", "motivation": "The accuracy of PINN solutions is often limited by boundary condition treatment, with penalty-based methods being unreliable and sensitive to parameter choices.", "method": "The paper leverages R-functions to enforce boundary conditions, extends this to inverse problems with PINNs, and introduces adaptive weight tuning for efficient analysis.", "result": "Numerical experiments show the method outperforms penalty-based approaches in accuracy and efficiency, even for complex geometries.", "conclusion": "The approach provides a reliable and efficient framework for inverse analysis with PINNs, applicable to diverse engineering problems."}}
{"id": "2504.21389", "pdf": "https://arxiv.org/pdf/2504.21389", "abs": "https://arxiv.org/abs/2504.21389", "authors": ["Jianyu Zhang"], "title": "Enhanced semi-supervised stamping process monitoring with physically-informed feature extraction", "categories": ["cs.LG"], "comment": null, "summary": "In tackling frequent batch anomalies in high-speed stamping processes, this\nstudy introduces a novel semi-supervised in-process anomaly monitoring\nframework, utilizing accelerometer signals and physics information, to capture\nthe process anomaly effectively. The proposed framework facilitates the\nconstruction of a monitoring model with imbalanced sample distribution, which\nenables in-process condition monitoring in real-time to prevent batch\nanomalies, which helps to reduce batch defects risk and enhance production\nyield. Firstly, to effectively capture key features from raw data containing\nredundant information, a hybrid feature extraction algorithm is proposed to\nutilize data-driven methods and physical mechanisms simultaneously. Secondly,\nto address the challenge brought by imbalanced sample distribution, a\nsemi-supervised anomaly detection model is established, which merely employs\nnormal samples to build a golden baseline model, and a novel deviation score is\nproposed to quantify the anomaly level of each online stamping stroke. The\neffectiveness of the proposed feature extraction method is validated with\nvarious classification algorithms. A real-world in-process dataset from\nstamping manufacturing workshop is employed to illustrate the superiority of\nproposed semi-supervised framework with enhance performance for process anomaly\nmonitoring.", "AI": {"tldr": "A semi-supervised framework for anomaly monitoring in high-speed stamping processes uses hybrid feature extraction and a novel deviation score to detect anomalies in real-time, improving yield and reducing defects.", "motivation": "To address frequent batch anomalies in high-speed stamping processes by developing an effective real-time monitoring system.", "method": "Proposes a hybrid feature extraction algorithm combining data-driven and physics-based methods, and a semi-supervised anomaly detection model using normal samples to create a baseline.", "result": "Validated with classification algorithms and real-world data, showing superior performance in anomaly monitoring.", "conclusion": "The framework effectively reduces batch defects and enhances production yield by enabling real-time anomaly detection."}}
{"id": "2505.00307", "pdf": "https://arxiv.org/pdf/2505.00307", "abs": "https://arxiv.org/abs/2505.00307", "authors": ["Yu-Hsiang Lan", "Eric K. Oermann"], "title": "Gateformer: Advancing Multivariate Time Series Forecasting through Temporal and Variate-Wise Attention with Gated Representations", "categories": ["cs.LG"], "comment": null, "summary": "There has been a recent surge of interest in time series modeling using the\nTransformer architecture. However, forecasting multivariate time series with\nTransformer presents a unique challenge as it requires modeling both temporal\n(cross-time) and variate (cross-variate) dependencies. While Transformer-based\nmodels have gained popularity for their flexibility in capturing both\nsequential and cross-variate relationships, it is unclear how to best integrate\nthese two sources of information in the context of the Transformer architecture\nwhile optimizing for both performance and efficiency. We re-purpose the\nTransformer architecture to effectively model both cross-time and cross-variate\ndependencies. Our approach begins by embedding each variate independently into\na variate-wise representation that captures its cross-time dynamics, and then\nmodels cross-variate dependencies through attention mechanisms on these learned\nembeddings. Gating operations in both cross-time and cross-variate modeling\nphases regulate information flow, allowing the model to focus on the most\nrelevant features for accurate predictions. Our method achieves\nstate-of-the-art performance across 13 real-world datasets and can be\nseamlessly integrated into other Transformer-based and LLM-based forecasters,\ndelivering performance improvements up to 20.7\\% over original models. Code is\navailable at this repository: https://github.com/nyuolab/Gateformer.", "AI": {"tldr": "The paper proposes a Transformer-based method for multivariate time series forecasting, addressing challenges in modeling cross-time and cross-variate dependencies. It achieves state-of-the-art performance and integrates easily with other models.", "motivation": "The challenge lies in effectively modeling both temporal and variate dependencies in multivariate time series forecasting using Transformers.", "method": "The approach independently embeds variates for cross-time dynamics, then uses attention mechanisms for cross-variate dependencies, with gating to regulate information flow.", "result": "The method outperforms existing models on 13 datasets, improving performance by up to 20.7%.", "conclusion": "The proposed method effectively integrates cross-time and cross-variate modeling, offering significant performance gains and compatibility with other Transformer-based models."}}
{"id": "2505.00410", "pdf": "https://arxiv.org/pdf/2505.00410", "abs": "https://arxiv.org/abs/2505.00410", "authors": ["Farhana Elias", "Md Shihab Reza", "Muhammad Zawad Mahmud", "Samiha Islam", "Shahran Rahman Alve"], "title": "Machine Learning Meets Transparency in Osteoporosis Risk Assessment: A Comparative Study of ML and Explainability Analysis", "categories": ["cs.LG"], "comment": "Submitted in an international conference", "summary": "The present research tackles the difficulty of predicting osteoporosis risk\nvia machine learning (ML) approaches, emphasizing the use of explainable\nartificial intelligence (XAI) to improve model transparency. Osteoporosis is a\nsignificant public health concern, sometimes remaining untreated owing to its\nasymptomatic characteristics, and early identification is essential to avert\nfractures. The research assesses six machine learning classifiers: Random\nForest, Logistic Regression, XGBoost, AdaBoost, LightGBM, and Gradient Boosting\nand utilizes a dataset based on clinical, demographic, and lifestyle variables.\nThe models are refined using GridSearchCV to calibrate hyperparameters, with\nthe objective of enhancing predictive efficacy. XGBoost had the greatest\naccuracy (91%) among the evaluated models, surpassing others in precision\n(0.92), recall (0.91), and F1-score (0.90). The research further integrates XAI\napproaches, such as SHAP, LIME, and Permutation Feature Importance, to\nelucidate the decision-making process of the optimal model. The study indicates\nthat age is the primary determinant in forecasting osteoporosis risk, followed\nby hormonal alterations and familial history. These results corroborate\nclinical knowledge and affirm the models' therapeutic significance. The\nresearch underscores the significance of explainability in machine learning\nmodels for healthcare applications, guaranteeing that physicians can rely on\nthe system's predictions. The report ultimately proposes directions for further\nresearch, such as validation across varied populations and the integration of\nsupplementary biomarkers for enhanced predictive accuracy.", "AI": {"tldr": "The study uses ML and XAI to predict osteoporosis risk, with XGBoost achieving 91% accuracy. Age, hormonal changes, and family history are key predictors.", "motivation": "Osteoporosis is often asymptomatic, making early detection crucial to prevent fractures. The research aims to improve prediction transparency using XAI.", "method": "Six ML classifiers (e.g., Random Forest, XGBoost) were evaluated on clinical data, optimized via GridSearchCV, and explained using SHAP, LIME, and Permutation Feature Importance.", "result": "XGBoost performed best (91% accuracy). Age was the top predictor, followed by hormonal changes and family history.", "conclusion": "The study highlights the importance of explainable ML in healthcare and suggests further validation and biomarker integration."}}
{"id": "2505.01386", "pdf": "https://arxiv.org/pdf/2505.01386", "abs": "https://arxiv.org/abs/2505.01386", "authors": ["Irene Wang", "Newsha Ardalani", "Mostafa Elhoushi", "Daniel Jiang", "Samuel Hsia", "Ekin Sumbul", "Divya Mahajan", "Carole-Jean Wu", "Bilge Acun"], "title": "Carbon Aware Transformers Through Joint Model-Hardware Optimization", "categories": ["cs.LG", "cs.AR"], "comment": null, "summary": "The rapid growth of machine learning (ML) systems necessitates a more\ncomprehensive evaluation of their environmental impact, particularly their\ncarbon footprint, which comprises operational carbon from training and\ninference execution and embodied carbon from hardware manufacturing and its\nentire life-cycle. Despite the increasing importance of embodied emissions,\nthere is a lack of tools and frameworks to holistically quantify and optimize\nthe total carbon footprint of ML systems. To address this, we propose\nCATransformers, a carbon-aware architecture search framework that enables\nsustainability-driven co-optimization of ML models and hardware architectures.\nBy incorporating both operational and embodied carbon metrics into early design\nspace exploration of domain-specific hardware accelerators, CATransformers\ndemonstrates that optimizing for carbon yields design choices distinct from\nthose optimized solely for latency or energy efficiency. We apply our framework\nto multi-modal CLIP-based models, producing CarbonCLIP, a family of CLIP models\nachieving up to 17% reduction in total carbon emissions while maintaining\naccuracy and latency compared to state-of-the-art edge small CLIP baselines.\nThis work underscores the need for holistic optimization methods to design\nhigh-performance, environmentally sustainable AI systems.", "AI": {"tldr": "CATransformers is a carbon-aware framework for optimizing ML models and hardware to reduce total carbon emissions, achieving a 17% reduction in emissions while maintaining performance.", "motivation": "The environmental impact of ML systems, particularly their carbon footprint (operational and embodied), lacks comprehensive evaluation tools.", "method": "Proposes CATransformers, a framework for co-optimizing ML models and hardware architectures using carbon metrics.", "result": "Achieves up to 17% reduction in total carbon emissions for CLIP-based models without compromising accuracy or latency.", "conclusion": "Highlights the need for holistic optimization to design sustainable, high-performance AI systems."}}
{"id": "2505.05192", "pdf": "https://arxiv.org/pdf/2505.05192", "abs": "https://arxiv.org/abs/2505.05192", "authors": ["Ruichu Cai", "Junjie Wan", "Weilin Chen", "Zeqin Yang", "Zijian Li", "Peng Zhen", "Jiecheng Guo"], "title": "Long-Term Individual Causal Effect Estimation via Identifiable Latent Representation Learning", "categories": ["cs.LG"], "comment": null, "summary": "Estimating long-term causal effects by combining long-term observational and\nshort-term experimental data is a crucial but challenging problem in many\nreal-world scenarios. In existing methods, several ideal assumptions, e.g.\nlatent unconfoundedness assumption or additive equi-confounding bias\nassumption, are proposed to address the latent confounder problem raised by the\nobservational data. However, in real-world applications, these assumptions are\ntypically violated which limits their practical effectiveness. In this paper,\nwe tackle the problem of estimating the long-term individual causal effects\nwithout the aforementioned assumptions. Specifically, we propose to utilize the\nnatural heterogeneity of data, such as data from multiple sources, to identify\nlatent confounders, thereby significantly avoiding reliance on idealized\nassumptions. Practically, we devise a latent representation learning-based\nestimator of long-term causal effects. Theoretically, we establish the\nidentifiability of latent confounders, with which we further achieve long-term\neffect identification. Extensive experimental studies, conducted on multiple\nsynthetic and semi-synthetic datasets, demonstrate the effectiveness of our\nproposed method.", "AI": {"tldr": "Proposes a method to estimate long-term causal effects without relying on ideal assumptions by leveraging data heterogeneity and latent representation learning.", "motivation": "Existing methods for estimating long-term causal effects rely on ideal assumptions that are often violated in practice, limiting their effectiveness.", "method": "Utilizes data heterogeneity (e.g., multiple sources) to identify latent confounders and develops a latent representation learning-based estimator.", "result": "Demonstrates effectiveness through experiments on synthetic and semi-synthetic datasets, achieving long-term effect identification.", "conclusion": "The proposed method avoids idealized assumptions and effectively estimates long-term causal effects by leveraging natural data heterogeneity."}}
{"id": "2310.16688", "pdf": "https://arxiv.org/pdf/2310.16688", "abs": "https://arxiv.org/abs/2310.16688", "authors": ["Philipp Scholl", "Maged Iskandar", "Sebastian Wolf", "Jinoh Lee", "Aras Bacho", "Alexander Dietrich", "Alin Albu-Sch\u00e4ffer", "Gitta Kutyniok"], "title": "Learning-based adaption of robotic friction models", "categories": ["cs.RO", "cs.LG"], "comment": null, "summary": "In the Fourth Industrial Revolution, wherein artificial intelligence and the\nautomation of machines occupy a central role, the deployment of robots is\nindispensable. However, the manufacturing process using robots, especially in\ncollaboration with humans, is highly intricate. In particular, modeling the\nfriction torque in robotic joints is a longstanding problem due to the lack of\na good mathematical description. This motivates the usage of data-driven\nmethods in recent works. However, model-based and data-driven models often\nexhibit limitations in their ability to generalize beyond the specific dynamics\nthey were trained on, as we demonstrate in this paper. To address this\nchallenge, we introduce a novel approach based on residual learning, which aims\nto adapt an existing friction model to new dynamics using as little data as\npossible. We validate our approach by training a base neural network on a\nsymmetric friction data set to learn an accurate relation between the velocity\nand the friction torque. Subsequently, to adapt to more complex asymmetric\nsettings, we train a second network on a small dataset, focusing on predicting\nthe residual of the initial network's output. By combining the output of both\nnetworks in a suitable manner, our proposed estimator outperforms the\nconventional model-based approach, an extended LuGre model, and the base neural\nnetwork significantly. Furthermore, we evaluate our method on trajectories\ninvolving external loads and still observe a substantial improvement,\napproximately 60-70%, over the conventional approach. Our method does not rely\non data with external load during training, eliminating the need for external\ntorque sensors. This demonstrates the generalization capability of our\napproach, even with a small amount of data--less than a minute--enabling\nadaptation to diverse scenarios based on prior knowledge about friction in\ndifferent settings.", "AI": {"tldr": "A novel residual learning approach improves friction torque modeling in robotic joints, outperforming traditional methods with minimal data.", "motivation": "The complexity of modeling friction torque in robotic joints, especially in human-robot collaboration, drives the need for adaptable, data-efficient methods.", "method": "Uses residual learning: a base neural network trained on symmetric friction data, and a second network to adapt to asymmetric settings by predicting residuals.", "result": "Outperforms conventional models (e.g., LuGre) and base neural network, achieving 60-70% improvement, even with minimal training data (<1 min).", "conclusion": "The method generalizes well without external load data, enabling adaptation to diverse scenarios with prior friction knowledge."}}
{"id": "2401.02940", "pdf": "https://arxiv.org/pdf/2401.02940", "abs": "https://arxiv.org/abs/2401.02940", "authors": ["Jonathan Z. Lu", "Lucy Jiao", "Kristina Wolinski", "Milan Kornja\u010da", "Hong-Ye Hu", "Sergio Cantu", "Fangli Liu", "Susanne F. Yelin", "Sheng-Tao Wang"], "title": "Digital-analog quantum learning on Rydberg atom arrays", "categories": ["quant-ph", "cs.LG"], "comment": "23 pages, 22 figures. Version 2 for Quantum Science and Technology:\n  https://iopscience.iop.org/article/10.1088/2058-9565/ad9177", "summary": "We propose hybrid digital-analog learning algorithms on Rydberg atom arrays,\ncombining the potentially practical utility and near-term realizability of\nquantum learning with the rapidly scaling architectures of neutral atoms. Our\nconstruction requires only single-qubit operations in the digital setting and\nglobal driving according to the Rydberg Hamiltonian in the analog setting. We\nperform a comprehensive numerical study of our algorithm on both classical and\nquantum data, given respectively by handwritten digit classification and\nunsupervised quantum phase boundary learning. We show in the two representative\nproblems that digital-analog learning is not only feasible in the near term,\nbut also requires shorter circuit depths and is more robust to realistic error\nmodels as compared to digital learning schemes. Our results suggest that\ndigital-analog learning opens a promising path towards improved variational\nquantum learning experiments in the near term.", "AI": {"tldr": "Hybrid digital-analog learning on Rydberg atom arrays offers near-term feasibility, shorter circuit depths, and robustness to errors compared to purely digital methods.", "motivation": "To combine the practicality of quantum learning with scalable neutral atom architectures.", "method": "Uses single-qubit digital operations and global Rydberg Hamiltonian analog driving.", "result": "Effective in classical and quantum tasks, showing robustness and efficiency.", "conclusion": "Digital-analog learning is a promising near-term approach for variational quantum learning."}}
{"id": "2401.05363", "pdf": "https://arxiv.org/pdf/2401.05363", "abs": "https://arxiv.org/abs/2401.05363", "authors": ["Jiquan Wang", "Sha Zhao", "Haiteng Jiang", "Shijian Li", "Tao Li", "Gang Pan"], "title": "Generalizable Sleep Staging via Multi-Level Domain Alignment", "categories": ["eess.SP", "cs.LG"], "comment": "Accepted by the Thirty-Eighth AAAI Conference on Artificial\n  Intelligence (AAAI-24)", "summary": "Automatic sleep staging is essential for sleep assessment and disorder\ndiagnosis. Most existing methods depend on one specific dataset and are limited\nto be generalized to other unseen datasets, for which the training data and\ntesting data are from the same dataset. In this paper, we introduce domain\ngeneralization into automatic sleep staging and propose the task of\ngeneralizable sleep staging which aims to improve the model generalization\nability to unseen datasets. Inspired by existing domain generalization methods,\nwe adopt the feature alignment idea and propose a framework called SleepDG to\nsolve it. Considering both of local salient features and sequential features\nare important for sleep staging, we propose a Multi-level Feature Alignment\ncombining epoch-level and sequence-level feature alignment to learn\ndomain-invariant feature representations. Specifically, we design an\nEpoch-level Feature Alignment to align the feature distribution of each single\nsleep epoch among different domains, and a Sequence-level Feature Alignment to\nminimize the discrepancy of sequential features among different domains.\nSleepDG is validated on five public datasets, achieving the state-of-the-art\nperformance.", "AI": {"tldr": "The paper introduces SleepDG, a domain generalization framework for automatic sleep staging, improving model performance on unseen datasets through multi-level feature alignment.", "motivation": "Existing sleep staging methods lack generalization to unseen datasets, limiting their practical utility. The paper aims to enhance model adaptability across diverse datasets.", "method": "SleepDG employs multi-level feature alignment, combining epoch-level and sequence-level alignment to learn domain-invariant features.", "result": "SleepDG achieves state-of-the-art performance on five public datasets, demonstrating superior generalization.", "conclusion": "The proposed SleepDG framework effectively addresses the generalization challenge in sleep staging, offering robust performance across diverse datasets."}}
{"id": "2402.10088", "pdf": "https://arxiv.org/pdf/2402.10088", "abs": "https://arxiv.org/abs/2402.10088", "authors": ["Matteo Priorelli", "Ivilin Peev Stoianov"], "title": "Deep hybrid models: infer and plan in a dynamic world", "categories": ["cs.RO", "cs.LG"], "comment": null, "summary": "To determine an optimal plan for complex tasks, one often deals with dynamic\nand hierarchical relationships between several entities. Traditionally, such\nproblems are tackled with optimal control, which relies on the optimization of\ncost functions; instead, a recent biologically-motivated proposal casts\nplanning and control as an inference process. Active inference assumes that\naction and perception are two complementary aspects of life whereby the role of\nthe former is to fulfill the predictions inferred by the latter. Here, we\npresent an active inference approach that exploits discrete and continuous\nprocessing, based on three features: the representation of potential body\nconfigurations in relation to the objects of interest; the use of hierarchical\nrelationships that enable the agent to easily interpret and flexibly expand its\nbody schema for tool use; the definition of potential trajectories related to\nthe agent's intentions, used to infer and plan with dynamic elements at\ndifferent temporal scales. We evaluate this deep hybrid model on a habitual\ntask: reaching a moving object after having picked a moving tool. We show that\nthe model can tackle the presented task under different conditions. This study\nextends past work on planning as inference and advances an alternative\ndirection to optimal control.", "AI": {"tldr": "The paper proposes an active inference approach for planning and control, combining discrete and continuous processing to handle dynamic tasks like reaching a moving object with a tool.", "motivation": "To address the limitations of traditional optimal control methods by framing planning and control as an inference process, inspired by biological systems.", "method": "Uses active inference with hierarchical relationships, body schema representation, and trajectory planning for dynamic tasks.", "result": "The model successfully handles reaching a moving object with a tool under various conditions.", "conclusion": "Active inference offers a viable alternative to optimal control, advancing planning-as-inference frameworks."}}
{"id": "2403.11565", "pdf": "https://arxiv.org/pdf/2403.11565", "abs": "https://arxiv.org/abs/2403.11565", "authors": ["Siyuan Zhang", "Nachuan Xiao", "Xin Liu"], "title": "Convergence of Decentralized Stochastic Subgradient-based Methods for Nonsmooth Nonconvex functions", "categories": ["math.OC", "cs.LG"], "comment": "35 pages", "summary": "In this paper, we focus on the decentralized stochastic subgradient-based\nmethods in minimizing nonsmooth nonconvex functions without Clarke regularity,\nespecially in the decentralized training of nonsmooth neural networks. We\npropose a general framework that unifies various decentralized\nsubgradient-based methods, such as decentralized stochastic subgradient descent\n(DSGD), DSGD with gradient-tracking technique (DSGD-T), and DSGD with momentum\n(DSGD-M). To establish the convergence properties of our proposed framework, we\nrelate the discrete iterates to the trajectories of a continuous-time\ndifferential inclusion, which is assumed to have a coercive Lyapunov function\nwith a stable set $\\mathcal{A}$. We prove the asymptotic convergence of the\niterates to the stable set $\\mathcal{A}$ with sufficiently small and\ndiminishing step-sizes. These results provide first convergence guarantees for\nsome well-recognized of decentralized stochastic subgradient-based methods\nwithout Clarke regularity of the objective function. Preliminary numerical\nexperiments demonstrate that our proposed framework yields highly efficient\ndecentralized stochastic subgradient-based methods with convergence guarantees\nin the training of nonsmooth neural networks.", "AI": {"tldr": "The paper proposes a general framework for decentralized stochastic subgradient-based methods to minimize nonsmooth nonconvex functions, especially in training nonsmooth neural networks. It unifies methods like DSGD, DSGD-T, and DSGD-M, proving their convergence to a stable set using a continuous-time differential inclusion approach.", "motivation": "The motivation is to address the lack of convergence guarantees for decentralized stochastic subgradient-based methods in nonsmooth nonconvex optimization, particularly for neural networks without Clarke regularity.", "method": "The method involves a general framework unifying decentralized subgradient-based techniques (DSGD, DSGD-T, DSGD-M) and analyzing their convergence via continuous-time differential inclusions with a coercive Lyapunov function.", "result": "The results show asymptotic convergence to a stable set with small or diminishing step-sizes, providing the first convergence guarantees for such methods without Clarke regularity.", "conclusion": "The framework yields efficient decentralized methods with proven convergence for nonsmooth neural network training, validated by preliminary experiments."}}
{"id": "2407.04495", "pdf": "https://arxiv.org/pdf/2407.04495", "abs": "https://arxiv.org/abs/2407.04495", "authors": ["Kotaro Ikeda", "Tomoya Uda", "Daisuke Okanohara", "Sosuke Ito"], "title": "Speed-accuracy relations for diffusion models: Wisdom from nonequilibrium thermodynamics and optimal transport", "categories": ["cond-mat.stat-mech", "cs.LG", "stat.ML"], "comment": "37 pages, 9 figures", "summary": "We discuss a connection between a generative model, called the diffusion\nmodel, and nonequilibrium thermodynamics for the Fokker-Planck equation, called\nstochastic thermodynamics. Using techniques from stochastic thermodynamics, we\nderive the speed-accuracy relations for diffusion models, which are\ninequalities that relate the accuracy of data generation to the entropy\nproduction rate. This relation can be interpreted as the speed of the diffusion\ndynamics in the absence of the non-conservative force. From a stochastic\nthermodynamic perspective, our results provide quantitative insight into how\nbest to generate data in diffusion models. The optimal learning protocol is\nintroduced by the geodesic of space of the 2-Wasserstein distance in optimal\ntransport theory. We numerically illustrate the validity of the speed-accuracy\nrelations for diffusion models with different noise schedules and different\ndata. We numerically discuss our results for optimal and suboptimal learning\nprotocols. We also demonstrate the applicability of our results to data\ngeneration from the real-world image datasets.", "AI": {"tldr": "The paper connects diffusion models to nonequilibrium thermodynamics, deriving speed-accuracy relations for data generation and introducing an optimal learning protocol based on Wasserstein distance.", "motivation": "To bridge diffusion models and stochastic thermodynamics, providing quantitative insights into efficient data generation.", "method": "Uses stochastic thermodynamics to derive speed-accuracy relations and introduces an optimal learning protocol via Wasserstein distance geodesics.", "result": "Numerical validation of speed-accuracy relations for various noise schedules and data, with practical application to real-world image datasets.", "conclusion": "The study offers a thermodynamic perspective on optimizing diffusion models for data generation, validated through numerical experiments."}}
{"id": "2407.07179", "pdf": "https://arxiv.org/pdf/2407.07179", "abs": "https://arxiv.org/abs/2407.07179", "authors": ["Sascha Caron", "Nadezhda Dobreva", "Antonio Ferrer S\u00e1nchez", "Jos\u00e9 D. Mart\u00edn-Guerrero", "Uraz Odyurt", "Roberto Ruiz de Austri Bazan", "Zef Wolffs", "Yue Zhao"], "title": "TrackFormers: In Search of Transformer-Based Particle Tracking for the High-Luminosity LHC Era", "categories": ["hep-ex", "cs.LG"], "comment": null, "summary": "High-Energy Physics experiments are facing a multi-fold data increase with\nevery new iteration. This is certainly the case for the upcoming\nHigh-Luminosity LHC upgrade. Such increased data processing requirements forces\nrevisions to almost every step of the data processing pipeline. One such step\nin need of an overhaul is the task of particle track reconstruction, a.k.a.,\ntracking. A Machine Learning-assisted solution is expected to provide\nsignificant improvements, since the most time-consuming step in tracking is the\nassignment of hits to particles or track candidates. This is the topic of this\npaper.\n  We take inspiration from large language models. As such, we consider two\napproaches: the prediction of the next word in a sentence (next hit point in a\ntrack), as well as the one-shot prediction of all hits within an event. In an\nextensive design effort, we have experimented with three models based on the\nTransformer architecture and one model based on the U-Net architecture,\nperforming track association predictions for collision event hit points. In our\nevaluation, we consider a spectrum of simple to complex representations of the\nproblem, eliminating designs with lower metrics early on. We report extensive\nresults, covering both prediction accuracy (score) and computational\nperformance. We have made use of the REDVID simulation framework, as well as\nreductions applied to the TrackML data set, to compose five data sets from\nsimple to complex, for our experiments. The results highlight distinct\nadvantages among different designs in terms of prediction accuracy and\ncomputational performance, demonstrating the efficiency of our methodology.\nMost importantly, the results show the viability of a one-shot\nencoder-classifier based Transformer solution as a practical approach for the\ntask of tracking.", "AI": {"tldr": "The paper explores ML-assisted solutions for particle track reconstruction in High-Energy Physics, focusing on Transformer and U-Net models for predicting hit points in tracks.", "motivation": "The High-Luminosity LHC upgrade demands improved data processing, particularly in tracking, where ML can optimize hit assignment.", "method": "Two approaches are tested: predicting the next hit point (like next-word prediction) and one-shot prediction of all hits. Transformer and U-Net models are evaluated on varied data sets.", "result": "Transformer-based models, especially one-shot encoder-classifier designs, show promise in accuracy and computational efficiency.", "conclusion": "The study validates the practicality of Transformer models for tracking, offering a viable solution for future High-Energy Physics experiments."}}
{"id": "2410.05336", "pdf": "https://arxiv.org/pdf/2410.05336", "abs": "https://arxiv.org/abs/2410.05336", "authors": ["Bart van Laatum", "Eldert J. van Henten", "Sjoerd Boersma"], "title": "GreenLight-Gym: Reinforcement learning benchmark environment for control of greenhouse production systems", "categories": ["eess.SY", "cs.LG", "cs.SY", "math.OC"], "comment": "This submission replaces our previous pre-print with the version\n  accepted to the 2025 IFAC conference. A new Git repository\n  (https://github.com/BartvLaatum/GreenLight-Gym) accompanies this paper; the\n  repository for the prior version remains live at\n  https://github.com/YourOrg/GreenLightGym. The earlier pre-print is still\n  available on ArXiv under the previous submission number", "summary": "This study presents GreenLight-Gym, a new, fast, open-source benchmark\nenvironment for developing reinforcement learning (RL) methods in greenhouse\ncrop production control. Built on the state-of-the-art GreenLight model, it\nfeatures a differentiable C++ implementation leveraging the CasADi framework\nfor efficient numerical integration. GreenLight-Gym improves simulation speed\nby a factor of 17 over the original GreenLight implementation. A modular Python\nenvironment wrapper enables flexible configuration of control tasks and\nRL-based controllers. This flexibility is demonstrated by learning controllers\nunder parametric uncertainty using two well-known RL algorithms. GreenLight-Gym\nprovides a standardized benchmark for advancing RL methodologies and evaluating\ngreenhouse control solutions under diverse conditions. The greenhouse control\ncommunity is encouraged to use and extend this benchmark to accelerate\ninnovation in greenhouse crop production.", "AI": {"tldr": "GreenLight-Gym is a fast, open-source benchmark for RL in greenhouse control, offering 17x speed improvement and modular Python wrapper for flexible task configuration.", "motivation": "To advance RL methodologies and evaluate greenhouse control solutions under diverse conditions, providing a standardized benchmark.", "method": "Built on the GreenLight model with a differentiable C++ implementation using CasADi for efficient numerical integration, and a modular Python wrapper for RL tasks.", "result": "Achieves 17x faster simulation and successfully demonstrates learning controllers under parametric uncertainty with RL algorithms.", "conclusion": "Encourages the greenhouse control community to use and extend GreenLight-Gym to accelerate innovation in crop production."}}
{"id": "2410.08222", "pdf": "https://arxiv.org/pdf/2410.08222", "abs": "https://arxiv.org/abs/2410.08222", "authors": ["Yulong Feng", "Jing Xu", "Liujun Hu", "Guanghui Yu", "Xiangyang Duan"], "title": "Variational Source-Channel Coding for Semantic Communication", "categories": ["eess.SP", "cs.IT", "cs.LG", "math.IT"], "comment": null, "summary": "Semantic communication technology emerges as a pivotal bridge connecting AI\nwith classical communication. The current semantic communication systems are\ngenerally modeled as an Auto-Encoder (AE). AE lacks a deep integration of AI\nprinciples with communication strategies due to its inability to effectively\ncapture channel dynamics. This gap makes it difficult to justify the need for\njoint source-channel coding (JSCC) and to explain why performance improves.\nThis paper begins by exploring lossless and lossy communication, highlighting\nthat the inclusion of data distortion distinguishes semantic communication from\nclassical communication. It breaks the conditions for the separation theorem to\nhold and explains why the amount of data transferred by semantic communication\nis less. Therefore, employing JSCC becomes imperative for achieving optimal\nsemantic communication. Moreover, a Variational Source-Channel Coding (VSCC)\nmethod is proposed for constructing semantic communication systems based on\ndata distortion theory, integrating variational inference and channel\ncharacteristics. Using a deep learning network, we develop a semantic\ncommunication system employing the VSCC method and demonstrate its capability\nfor semantic transmission. We also establish semantic communication systems of\nequivalent complexity employing the AE method and the VAE method. Experimental\nresults reveal that the VSCC model offers superior interpretability compared to\nAE model, as it clearly captures the semantic features of the transmitted data,\nrepresented as the variance of latent variables in our experiments. In\naddition, VSCC model exhibits superior semantic transmission capabilities\ncompared to VAE model. At the same level of data distortion evaluated by PSNR,\nVSCC model exhibits stronger human interpretability, which can be partially\nassessed by SSIM.", "AI": {"tldr": "The paper proposes a Variational Source-Channel Coding (VSCC) method for semantic communication, outperforming Auto-Encoder (AE) and Variational Auto-Encoder (VAE) models in interpretability and semantic transmission.", "motivation": "Current semantic communication systems, modeled as Auto-Encoders (AE), lack deep integration of AI principles with communication strategies due to ineffective channel dynamics capture. This gap hinders the justification for joint source-channel coding (JSCC) and performance improvements.", "method": "The paper introduces a VSCC method integrating variational inference and channel characteristics, developed using a deep learning network. It compares VSCC with AE and VAE methods in semantic communication systems.", "result": "VSCC offers superior interpretability by capturing semantic features (variance of latent variables) and outperforms VAE in semantic transmission. At similar PSNR levels, VSCC shows stronger human interpretability (assessed by SSIM).", "conclusion": "VSCC is imperative for optimal semantic communication, providing better interpretability and performance than AE and VAE models."}}
{"id": "2412.16303", "pdf": "https://arxiv.org/pdf/2412.16303", "abs": "https://arxiv.org/abs/2412.16303", "authors": ["Daniel C. Hackett", "Joshua Isaacson", "Shirley Weishi Li", "Karla Tame-Narvaez", "Michael L. Wagman"], "title": "Machine Learning Neutrino-Nucleus Cross Sections", "categories": ["hep-ph", "cs.LG", "hep-ex", "nucl-th"], "comment": "5 pages, 2 figures + 6 pages Supplemental Material. v2: systematic\n  uncertainty checks and minor revisions", "summary": "Neutrino-nucleus scattering cross sections are critical theoretical inputs\nfor long-baseline neutrino oscillation experiments. However, robust modeling of\nthese cross sections remains challenging. For a simple but physically motivated\ntoy model of the DUNE experiment, we demonstrate that an accurate\nneural-network model of the cross section -- leveraging Standard Model\nsymmetries -- can be learned from near-detector data. We then perform a\nneutrino oscillation analysis with simulated far-detector events, finding that\nthe modeled cross section achieves results consistent with what could be\nobtained if the true cross section were known exactly. This proof-of-principle\nstudy highlights the potential of future neutrino near-detector datasets and\ndata-driven cross-section models.", "AI": {"tldr": "A neural-network model leveraging Standard Model symmetries accurately predicts neutrino-nucleus scattering cross sections for DUNE, achieving results consistent with exact knowledge of the true cross section.", "motivation": "Neutrino-nucleus scattering cross sections are crucial for neutrino oscillation experiments but are challenging to model robustly.", "method": "A neural-network model, trained on near-detector data and incorporating Standard Model symmetries, is used to predict cross sections.", "result": "The model achieves results consistent with exact knowledge of the true cross section in simulated far-detector events.", "conclusion": "This proof-of-principle study shows the potential of data-driven cross-section models and near-detector datasets for future experiments."}}
{"id": "2504.14002", "pdf": "https://arxiv.org/pdf/2504.14002", "abs": "https://arxiv.org/abs/2504.14002", "authors": ["Francesco Perciavalle", "Francesco Plastina", "Michele Pisarra", "Nicola Lo Gullo"], "title": "Predicting fermionic densities using a Projected Quantum Kernel method", "categories": ["quant-ph", "cond-mat.str-el", "cs.LG"], "comment": "12 pages, 7 figures", "summary": "We use a support vector regressor based on a projected quantum kernel method\nto predict the density structure of 1D fermionic systems of interest in quantum\nchemistry and quantum matter. The kernel is built on with the observables of a\nquantum reservoir implementable with interacting Rydberg atoms. Training and\ntest data of the fermionic system are generated using a Density Functional\nTheory approach. We test the performance of the method for several Hamiltonian\nparameters, finding a general common behavior of the error as a function of\nmeasurement time. At sufficiently large measurement times, we find that the\nmethod outperforms the classical linear kernel method and can be competitive\nwith the radial basis function method.", "AI": {"tldr": "A support vector regressor with a projected quantum kernel predicts 1D fermionic system densities, outperforming classical methods at large measurement times.", "motivation": "To predict density structures in quantum chemistry and matter using quantum computing methods.", "method": "Uses a projected quantum kernel with a quantum reservoir (Rydberg atoms) and trains/test data from Density Functional Theory.", "result": "Outperforms classical linear kernel and competes with radial basis function method at large measurement times.", "conclusion": "The quantum kernel method is effective for predicting fermionic system densities, especially with sufficient measurement time."}}
{"id": "2504.16098", "pdf": "https://arxiv.org/pdf/2504.16098", "abs": "https://arxiv.org/abs/2504.16098", "authors": ["Tianning Feng", "Juntong Ni", "Ezequiel Gleichgerrcht", "Wei Jin"], "title": "SeizureFormer: A Transformer Model for IEA-Based Seizure Risk Forecasting", "categories": ["eess.SP", "cs.LG", "I.5.1; I.2.6"], "comment": "9 pages, 2 figures. Submitted as an undergraduate honors thesis at\n  Emory University", "summary": "We present SeizureFormer, a Transformer-based model for long-term seizure\nrisk forecasting using interictal epileptiform activity (IEA) surrogate\nbiomarkers and long episode (LE) biomarkers from responsive neurostimulation\n(RNS) systems. Unlike raw scalp EEG-based models, SeizureFormer leverages\nstructured, clinically relevant features and integrates CNN-based patch\nembedding, multi-head self-attention, and squeeze-and-excitation blocks to\nmodel both short-term dynamics and long-term seizure cycles. Tested across five\npatients and multiple prediction windows (1 to 14 days), SeizureFormer achieved\nstate-of-the-art performance with mean ROC AUC of 79.44 percent and mean PR AUC\nof 76.29 percent. Compared to statistical, machine learning, and deep learning\nbaselines, it demonstrates enhanced generalizability and seizure risk\nforecasting performance under class imbalance. This work supports future\nclinical integration of interpretable and robust seizure forecasting tools for\npersonalized epilepsy management.", "AI": {"tldr": "SeizureFormer is a Transformer-based model for long-term seizure risk forecasting using IEA and LE biomarkers from RNS systems, outperforming baselines with high ROC and PR AUC scores.", "motivation": "To improve seizure risk forecasting by leveraging structured biomarkers and advanced deep learning techniques for better generalizability and performance under class imbalance.", "method": "Uses CNN-based patch embedding, multi-head self-attention, and squeeze-and-excitation blocks to model short-term dynamics and long-term seizure cycles.", "result": "Achieved mean ROC AUC of 79.44% and PR AUC of 76.29%, outperforming statistical, ML, and DL baselines.", "conclusion": "Supports clinical integration of interpretable and robust seizure forecasting tools for personalized epilepsy management."}}
{"id": "2505.01454", "pdf": "https://arxiv.org/pdf/2505.01454", "abs": "https://arxiv.org/abs/2505.01454", "authors": ["Zhiyong Jin", "Runhua Xu", "Chao Li", "Yizhong Liu", "Jianxin Li"], "title": "Sparsification Under Siege: Defending Against Poisoning Attacks in Communication-Efficient Federated Learning", "categories": ["cs.CR", "cs.LG"], "comment": null, "summary": "Federated Learning (FL) enables collaborative model training across\ndistributed clients while preserving data privacy, yet it faces significant\nchallenges in communication efficiency and vulnerability to poisoning attacks.\nWhile sparsification techniques mitigate communication overhead by transmitting\nonly critical model parameters, they inadvertently amplify security risks:\nadversarial clients can exploit sparse updates to evade detection and degrade\nmodel performance. Existing defense mechanisms, designed for standard FL\ncommunication scenarios, are ineffective in addressing these vulnerabilities\nwithin sparsified FL. To bridge this gap, we propose FLARE, a novel federated\nlearning framework that integrates sparse index mask inspection and model\nupdate sign similarity analysis to detect and mitigate poisoning attacks in\nsparsified FL. Extensive experiments across multiple datasets and adversarial\nscenarios demonstrate that FLARE significantly outperforms existing defense\nstrategies, effectively securing sparsified FL against poisoning attacks while\nmaintaining communication efficiency.", "AI": {"tldr": "FLARE is a federated learning framework that detects and mitigates poisoning attacks in sparsified FL, outperforming existing defenses while maintaining communication efficiency.", "motivation": "Federated Learning (FL) faces challenges in communication efficiency and vulnerability to poisoning attacks, especially in sparsified FL where existing defenses fail.", "method": "FLARE integrates sparse index mask inspection and model update sign similarity analysis to detect and mitigate poisoning attacks.", "result": "Experiments show FLARE significantly outperforms existing defenses, securing sparsified FL against attacks while preserving efficiency.", "conclusion": "FLARE effectively bridges the gap in securing sparsified FL, offering robust defense without compromising communication efficiency."}}
