{"id": "2506.15794", "pdf": "https://arxiv.org/pdf/2506.15794", "abs": "https://arxiv.org/abs/2506.15794", "authors": ["Taylor Lynn Curtis", "Maximilian Puelma Touzel", "William Garneau", "Manon Gruaz", "Mike Pinder", "Li Wei Wang", "Sukanya Krishna", "Luda Cohen", "Jean-Fran\u00e7ois Godbout", "Reihaneh Rabbany", "Kellin Pelrine"], "title": "Veracity: An Open-Source AI Fact-Checking System", "categories": ["cs.CL", "cs.AI", "cs.HC"], "comment": null, "summary": "The proliferation of misinformation poses a significant threat to society,\nexacerbated by the capabilities of generative AI. This demo paper introduces\nVeracity, an open-source AI system designed to empower individuals to combat\nmisinformation through transparent and accessible fact-checking. Veracity\nleverages the synergy between Large Language Models (LLMs) and web retrieval\nagents to analyze user-submitted claims and provide grounded veracity\nassessments with intuitive explanations. Key features include multilingual\nsupport, numerical scoring of claim veracity, and an interactive interface\ninspired by familiar messaging applications. This paper will showcase\nVeracity's ability to not only detect misinformation but also explain its\nreasoning, fostering media literacy and promoting a more informed society.", "AI": {"tldr": "Veracity is an open-source AI system using LLMs and web retrieval to fact-check claims, offering multilingual support, veracity scoring, and intuitive explanations.", "motivation": "To combat misinformation exacerbated by generative AI by providing transparent and accessible fact-checking tools.", "method": "Leverages Large Language Models (LLMs) and web retrieval agents to analyze claims and provide veracity assessments with explanations.", "result": "Veracity can detect misinformation and explain its reasoning, supporting media literacy.", "conclusion": "Veracity fosters a more informed society by making fact-checking transparent and interactive."}}
{"id": "2506.16258", "pdf": "https://arxiv.org/pdf/2506.16258", "abs": "https://arxiv.org/abs/2506.16258", "authors": ["Yisu Wang", "Yixiang Zhu", "Xinjiao Li", "Yulong Zhang", "Ruilong Wu", "Dirk Kutscher"], "title": "ViFusion: In-Network Tensor Fusion for Scalable Video Feature Indexing", "categories": ["cs.MM"], "comment": null, "summary": "Large-scale video feature indexing in datacenters is critically dependent on\nefficient data transfer. Although in-network computation has emerged as a\ncompelling strategy for accelerating feature extraction and reducing overhead\nin distributed multimedia systems, harnessing advanced networking resources at\nboth the switch and host levels remains a formidable challenge. These\ndifficulties are compounded by heterogeneous hardware, diverse application\nrequirements, and complex multipath topologies. Existing methods focus\nprimarily on optimizing inference for large neural network models using\nspecialized collective communication libraries, which often face performance\ndegradation in network congestion scenarios.\n  To overcome these limitations, we present ViFusion, a communication aware\ntensor fusion framework that streamlines distributed video indexing by merging\nnumerous small feature tensors into consolidated and more manageable units. By\nintegrating an in-network computation module and a dedicated tensor fusion\nmechanism within datacenter environments, ViFusion substantially improves the\nefficiency of video feature indexing workflows. The deployment results show\nthat ViFusion improves the throughput of the video retrieval system by 8--22\ntimes with the same level of latency as state-of-the-art systems.", "AI": {"tldr": "ViFusion is a communication-aware tensor fusion framework that enhances distributed video indexing by merging small feature tensors, improving throughput by 8-22x with comparable latency.", "motivation": "Efficient data transfer in large-scale video feature indexing is hindered by heterogeneous hardware, diverse requirements, and network congestion, which existing methods fail to address adequately.", "method": "ViFusion integrates in-network computation and a tensor fusion mechanism to consolidate small feature tensors into manageable units, optimizing distributed workflows.", "result": "Deployment shows ViFusion boosts video retrieval system throughput by 8-22x while maintaining latency levels of state-of-the-art systems.", "conclusion": "ViFusion effectively addresses inefficiencies in distributed video indexing, offering significant performance improvements without compromising latency."}}
{"id": "2506.15830", "pdf": "https://arxiv.org/pdf/2506.15830", "abs": "https://arxiv.org/abs/2506.15830", "authors": ["Riccardo Di Sipio"], "title": "Rethinking LLM Training through Information Geometry and Quantum Metrics", "categories": ["cs.CL", "quant-ph", "I.2; I.7"], "comment": "9 pages, 1 figure(s)", "summary": "Optimization in large language models (LLMs) unfolds over high-dimensional\nparameter spaces with non-Euclidean structure. Information geometry frames this\nlandscape using the Fisher information metric, enabling more principled\nlearning via natural gradient descent. Though often impractical, this geometric\nlens clarifies phenomena such as sharp minima, generalization, and observed\nscaling laws. We argue that curvature-aware approaches deepen our understanding\nof LLM training. Finally, we speculate on quantum analogies based on the\nFubini-Study metric and Quantum Fisher Information, hinting at efficient\noptimization in quantum-enhanced systems.", "AI": {"tldr": "The paper explores optimization in large language models (LLMs) using information geometry and natural gradient descent, highlighting its theoretical benefits and practical challenges. It also speculates on quantum analogies for efficient optimization.", "motivation": "To understand and improve optimization in LLMs by leveraging geometric insights from information geometry, despite practical limitations.", "method": "Uses the Fisher information metric and natural gradient descent to analyze the high-dimensional, non-Euclidean parameter space of LLMs.", "result": "The geometric perspective clarifies phenomena like sharp minima, generalization, and scaling laws in LLMs.", "conclusion": "Curvature-aware approaches enhance LLM training understanding, with potential quantum analogies offering future optimization efficiency."}}
{"id": "2506.16495", "pdf": "https://arxiv.org/pdf/2506.16495", "abs": "https://arxiv.org/abs/2506.16495", "authors": ["Changsheng Gao", "Zijie Liu", "Li Li", "Dong Liu", "Xiaoyan Sun", "Weisi Lin"], "title": "DT-UFC: Universal Large Model Feature Coding via Peaky-to-Balanced Distribution Transformation", "categories": ["cs.MM", "cs.CV"], "comment": null, "summary": "Like image coding in visual data transmission, feature coding is essential\nfor the distributed deployment of large models by significantly reducing\ntransmission and storage overhead. However, prior studies have mostly targeted\ntask- or model-specific scenarios, leaving the challenge of universal feature\ncoding across diverse large models largely unaddressed. In this paper, we\npresent the first systematic study on universal feature coding for large\nmodels. The key challenge lies in the inherently diverse and distributionally\nincompatible nature of features extracted from different models. For example,\nfeatures from DINOv2 exhibit highly peaky, concentrated distributions, while\nthose from Stable Diffusion 3 (SD3) are more dispersed and uniform. This\ndistributional heterogeneity severely hampers both compression efficiency and\ncross-model generalization. To address this, we propose a learned\npeaky-to-balanced distribution transformation, which reshapes highly skewed\nfeature distributions into a common, balanced target space. This transformation\nis non-uniform, data-driven, and plug-and-play, enabling effective alignment of\nheterogeneous distributions without modifying downstream codecs. With this\nalignment, a universal codec trained on the balanced target distribution can\neffectively generalize to features from different models and tasks. We validate\nour approach on three representative large models-LLaMA3, DINOv2, and\nSD3-across multiple tasks and modalities. Extensive experiments show that our\nmethod achieves notable improvements in both compression efficiency and\ncross-model generalization over task-specific baselines. All source code will\nbe released for future research.", "AI": {"tldr": "The paper introduces a universal feature coding method for large models, addressing distributional heterogeneity in features by transforming skewed distributions into a balanced target space.", "motivation": "Prior studies focused on task- or model-specific feature coding, leaving universal feature coding for diverse large models unaddressed.", "method": "Proposes a learned peaky-to-balanced distribution transformation to align heterogeneous feature distributions without modifying downstream codecs.", "result": "Validated on LLaMA3, DINOv2, and SD3, the method improves compression efficiency and cross-model generalization over task-specific baselines.", "conclusion": "The approach enables effective universal feature coding, with source code released for future research."}}
{"id": "2506.15841", "pdf": "https://arxiv.org/pdf/2506.15841", "abs": "https://arxiv.org/abs/2506.15841", "authors": ["Zijian Zhou", "Ao Qu", "Zhaoxuan Wu", "Sunghwan Kim", "Alok Prakash", "Daniela Rus", "Jinhua Zhao", "Bryan Kian Hsiang Low", "Paul Pu Liang"], "title": "MEM1: Learning to Synergize Memory and Reasoning for Efficient Long-Horizon Agents", "categories": ["cs.CL", "cs.AI", "cs.IR"], "comment": null, "summary": "Modern language agents must operate over long-horizon, multi-turn\ninteractions, where they retrieve external information, adapt to observations,\nand answer interdependent queries. Yet, most LLM systems rely on full-context\nprompting, appending all past turns regardless of their relevance. This leads\nto unbounded memory growth, increased computational costs, and degraded\nreasoning performance on out-of-distribution input lengths. We introduce MEM1,\nan end-to-end reinforcement learning framework that enables agents to operate\nwith constant memory across long multi-turn tasks. At each turn, MEM1 updates a\ncompact shared internal state that jointly supports memory consolidation and\nreasoning. This state integrates prior memory with new observations from the\nenvironment while strategically discarding irrelevant or redundant information.\nTo support training in more realistic and compositional settings, we propose a\nsimple yet effective and scalable approach to constructing multi-turn\nenvironments by composing existing datasets into arbitrarily complex task\nsequences. Experiments across three domains, including internal retrieval QA,\nopen-domain web QA, and multi-turn web shopping, show that MEM1-7B improves\nperformance by 3.5x while reducing memory usage by 3.7x compared to\nQwen2.5-14B-Instruct on a 16-objective multi-hop QA task, and generalizes\nbeyond the training horizon. Our results demonstrate the promise of\nreasoning-driven memory consolidation as a scalable alternative to existing\nsolutions for training long-horizon interactive agents, where both efficiency\nand performance are optimized.", "AI": {"tldr": "MEM1 is a reinforcement learning framework for language agents, enabling constant memory usage in long multi-turn tasks by consolidating and discarding irrelevant information. It outperforms larger models in efficiency and performance.", "motivation": "Current LLM systems suffer from unbounded memory growth and degraded performance due to full-context prompting, necessitating a scalable solution for long-horizon tasks.", "method": "MEM1 uses reinforcement learning to update a compact internal state, integrating prior memory with new observations while discarding redundancy. Training involves composing datasets into complex task sequences.", "result": "MEM1-7B improves performance by 3.5x and reduces memory usage by 3.7x compared to Qwen2.5-14B-Instruct, generalizing beyond training horizons.", "conclusion": "MEM1 demonstrates the effectiveness of reasoning-driven memory consolidation for scalable, efficient long-horizon interactive agents."}}
{"id": "2506.15759", "pdf": "https://arxiv.org/pdf/2506.15759", "abs": "https://arxiv.org/abs/2506.15759", "authors": ["Siyi Xie", "Hanxin Zhu", "Tianyu He", "Xin Li", "Zhibo Chen"], "title": "Sonic4D: Spatial Audio Generation for Immersive 4D Scene Exploration", "categories": ["cs.SD", "cs.MM", "eess.AS"], "comment": "17 pages, 7 figures. Project page:\n  https://x-drunker.github.io/Sonic4D-project-page/", "summary": "Recent advancements in 4D generation have demonstrated its remarkable\ncapability in synthesizing photorealistic renderings of dynamic 3D scenes.\nHowever, despite achieving impressive visual performance, almost all existing\nmethods overlook the generation of spatial audio aligned with the corresponding\n4D scenes, posing a significant limitation to truly immersive audiovisual\nexperiences. To mitigate this issue, we propose Sonic4D, a novel framework that\nenables spatial audio generation for immersive exploration of 4D scenes.\nSpecifically, our method is composed of three stages: 1) To capture both the\ndynamic visual content and raw auditory information from a monocular video, we\nfirst employ pre-trained expert models to generate the 4D scene and its\ncorresponding monaural audio. 2) Subsequently, to transform the monaural audio\ninto spatial audio, we localize and track the sound sources within the 4D\nscene, where their 3D spatial coordinates at different timestamps are estimated\nvia a pixel-level visual grounding strategy. 3) Based on the estimated sound\nsource locations, we further synthesize plausible spatial audio that varies\nacross different viewpoints and timestamps using physics-based simulation.\nExtensive experiments have demonstrated that our proposed method generates\nrealistic spatial audio consistent with the synthesized 4D scene in a\ntraining-free manner, significantly enhancing the immersive experience for\nusers. Generated audio and video examples are available at\nhttps://x-drunker.github.io/Sonic4D-project-page.", "AI": {"tldr": "Sonic4D introduces a framework for generating spatial audio aligned with 4D scenes, enhancing immersive audiovisual experiences by localizing sound sources and synthesizing spatial audio.", "motivation": "Existing 4D generation methods focus on visual realism but neglect spatial audio, limiting immersive experiences. Sonic4D addresses this gap.", "method": "The framework involves three stages: 1) generating 4D scenes and monaural audio, 2) localizing sound sources via visual grounding, and 3) synthesizing spatial audio using physics-based simulation.", "result": "The method produces realistic spatial audio aligned with 4D scenes, improving immersion without requiring training.", "conclusion": "Sonic4D successfully integrates spatial audio with 4D scenes, advancing immersive audiovisual experiences."}}
{"id": "2506.15846", "pdf": "https://arxiv.org/pdf/2506.15846", "abs": "https://arxiv.org/abs/2506.15846", "authors": ["Glenn Matlin", "Mika Okamoto", "Huzaifa Pardawala", "Yang Yang", "Sudheer Chava"], "title": "Finance Language Model Evaluation (FLaME)", "categories": ["cs.CL", "cs.AI", "cs.CE"], "comment": null, "summary": "Language Models (LMs) have demonstrated impressive capabilities with core\nNatural Language Processing (NLP) tasks. The effectiveness of LMs for highly\nspecialized knowledge-intensive tasks in finance remains difficult to assess\ndue to major gaps in the methodologies of existing evaluation frameworks, which\nhave caused an erroneous belief in a far lower bound of LMs' performance on\ncommon Finance NLP (FinNLP) tasks. To demonstrate the potential of LMs for\nthese FinNLP tasks, we present the first holistic benchmarking suite for\nFinancial Language Model Evaluation (FLaME). We are the first research paper to\ncomprehensively study LMs against 'reasoning-reinforced' LMs, with an empirical\nstudy of 23 foundation LMs over 20 core NLP tasks in finance. We open-source\nour framework software along with all data and results.", "AI": {"tldr": "The paper introduces FLaME, a benchmarking suite to evaluate Language Models (LMs) on specialized finance NLP tasks, addressing gaps in existing frameworks and demonstrating LMs' potential in finance.", "motivation": "Existing evaluation frameworks for LMs in finance have methodological gaps, leading to underestimation of their performance. The paper aims to correct this by providing a comprehensive benchmark.", "method": "The authors develop FLaME, a holistic benchmarking suite, and empirically evaluate 23 foundation LMs on 20 core NLP tasks in finance, comparing standard LMs with 'reasoning-reinforced' LMs.", "result": "The study reveals the potential of LMs in finance, challenging the belief of their limited performance. The framework, data, and results are open-sourced.", "conclusion": "FLaME provides a robust evaluation tool for LMs in finance, highlighting their underestimated capabilities and encouraging further research in FinNLP."}}
{"id": "2506.16273", "pdf": "https://arxiv.org/pdf/2506.16273", "abs": "https://arxiv.org/abs/2506.16273", "authors": ["Xin Jiang", "Meiqi Cao", "Hao Tang", "Fei Shen", "Zechao Li"], "title": "Fine-grained Image Retrieval via Dual-Vision Adaptation", "categories": ["cs.CV", "cs.MM"], "comment": null, "summary": "Fine-Grained Image Retrieval~(FGIR) faces challenges in learning\ndiscriminative visual representations to retrieve images with similar\nfine-grained features. Current leading FGIR solutions typically follow two\nregimes: enforce pairwise similarity constraints in the semantic embedding\nspace, or incorporate a localization sub-network to fine-tune the entire model.\nHowever, such two regimes tend to overfit the training data while forgetting\nthe knowledge gained from large-scale pre-training, thus reducing their\ngeneralization ability. In this paper, we propose a Dual-Vision Adaptation\n(DVA) approach for FGIR, which guides the frozen pre-trained model to perform\nFGIR through collaborative sample and feature adaptation. Specifically, we\ndesign Object-Perceptual Adaptation, which modifies input samples to help the\npre-trained model perceive critical objects and elements within objects that\nare helpful for category prediction. Meanwhile, we propose In-Context\nAdaptation, which introduces a small set of parameters for feature adaptation\nwithout modifying the pre-trained parameters. This makes the FGIR task using\nthese adjusted features closer to the task solved during the pre-training.\nAdditionally, to balance retrieval efficiency and performance, we propose\nDiscrimination Perception Transfer to transfer the discriminative knowledge in\nthe object-perceptual adaptation to the image encoder using the knowledge\ndistillation mechanism. Extensive experiments show that DVA has fewer learnable\nparameters and performs well on three in-distribution and three\nout-of-distribution fine-grained datasets.", "AI": {"tldr": "Proposes Dual-Vision Adaptation (DVA) for Fine-Grained Image Retrieval (FGIR), combining sample and feature adaptation to leverage pre-trained models without overfitting.", "motivation": "Current FGIR methods overfit training data and lose pre-training knowledge, reducing generalization.", "method": "DVA uses Object-Perceptual Adaptation for sample modification and In-Context Adaptation for feature adjustment, plus Discrimination Perception Transfer for knowledge distillation.", "result": "DVA performs well on in-distribution and out-of-distribution datasets with fewer parameters.", "conclusion": "DVA effectively balances retrieval efficiency and performance while leveraging pre-trained models."}}
{"id": "2506.15756", "pdf": "https://arxiv.org/pdf/2506.15756", "abs": "https://arxiv.org/abs/2506.15756", "authors": ["Jo\u00e3o G. Ribeiro", "Yaniv Oren", "Alberto Sardinha", "Matthijs Spaan", "Francisco S. Melo"], "title": "RecBayes: Recurrent Bayesian Ad Hoc Teamwork in Large Partially Observable Domains", "categories": ["cs.MA", "cs.AI", "cs.LG"], "comment": null, "summary": "This paper proposes RecBayes, a novel approach for ad hoc teamwork under\npartial observability, a setting where agents are deployed on-the-fly to\nenvironments where pre-existing teams operate, that never requires, at any\nstage, access to the states of the environment or the actions of its teammates.\nWe show that by relying on a recurrent Bayesian classifier trained using past\nexperiences, an ad hoc agent is effectively able to identify known teams and\ntasks being performed from observations alone. Unlike recent approaches such as\nPO-GPL (Gu et al., 2021) and FEAT (Rahman et al., 2023), that require at some\nstage fully observable states of the environment, actions of teammates, or\nboth, or approaches such as ATPO (Ribeiro et al., 2023) that require the\nenvironments to be small enough to be tabularly modelled (Ribeiro et al.,\n2023), in their work up to 4.8K states and 1.7K observations, we show RecBayes\nis both able to handle arbitrarily large spaces while never relying on either\nstates and teammates' actions. Our results in benchmark domains from the\nmulti-agent systems literature, adapted for partial observability and scaled up\nto 1M states and 2^125 observations, show that RecBayes is effective at\nidentifying known teams and tasks being performed from partial observations\nalone, and as a result, is able to assist the teams in solving the tasks\neffectively.", "AI": {"tldr": "RecBayes is a novel method for ad hoc teamwork under partial observability, identifying tasks and teams from observations alone without needing environment states or teammate actions.", "motivation": "Addressing the challenge of ad hoc teamwork in partially observable environments without relying on full observability or teammate actions.", "method": "Uses a recurrent Bayesian classifier trained on past experiences to identify known teams and tasks from partial observations.", "result": "Effective in large-scale environments (up to 1M states and 2^125 observations) and outperforms existing methods.", "conclusion": "RecBayes is a scalable and effective solution for ad hoc teamwork under partial observability."}}
{"id": "2506.15754", "pdf": "https://arxiv.org/pdf/2506.15754", "abs": "https://arxiv.org/abs/2506.15754", "authors": ["Tahitoa Leygue", "Astrid Sabourin", "Christian Bolzmacher", "Sylvain Bouchigny", "Margarita Anastassova", "Quoc-Cuong Pham"], "title": "Explainable speech emotion recognition through attentive pooling: insights from attention-based temporal localization", "categories": ["cs.SD", "eess.AS"], "comment": null, "summary": "State-of-the-art transformer models for Speech Emotion Recognition (SER) rely\non temporal feature aggregation, yet advanced pooling methods remain\nunderexplored. We systematically benchmark pooling strategies, including\nMulti-Query Multi-Head Attentive Statistics Pooling, which achieves a 3.5\npercentage point macro F1 gain over average pooling. Attention analysis shows\n15 percent of frames capture 80 percent of emotion cues, revealing a localized\npattern of emotional information. Analysis of high-attention frames reveals\nthat non-linguistic vocalizations and hyperarticulated phonemes are\ndisproportionately prioritized during pooling, mirroring human perceptual\nstrategies. Our findings position attentive pooling as both a performant SER\nmechanism and a biologically plausible tool for explainable emotion\nlocalization. On Interspeech 2025 Speech Emotion Recognition in Naturalistic\nConditions Challenge, our approach obtained a macro F1 score of 0.3649.", "AI": {"tldr": "Benchmarking pooling strategies for SER shows Multi-Query Multi-Head Attentive Statistics Pooling outperforms average pooling by 3.5% in macro F1, with attention analysis revealing localized emotion cues.", "motivation": "To explore advanced pooling methods for SER, as they remain underexplored despite their potential impact on performance.", "method": "Systematically benchmarked pooling strategies, focusing on Multi-Query Multi-Head Attentive Statistics Pooling, and analyzed attention patterns.", "result": "Achieved a 3.5% macro F1 gain over average pooling, with 15% of frames capturing 80% of emotion cues. Non-linguistic vocalizations and hyperarticulated phonemes were prioritized.", "conclusion": "Attentive pooling is a high-performing and biologically plausible method for SER, offering explainable emotion localization."}}
{"id": "2506.16228", "pdf": "https://arxiv.org/pdf/2506.16228", "abs": "https://arxiv.org/abs/2506.16228", "authors": ["Tobias Cord-Landwehr", "Tobias Gburrek", "Marc Deegen", "Reinhold Haeb-Umbach"], "title": "Spatio-spectral diarization of meetings by combining TDOA-based segmentation and speaker embedding-based clustering", "categories": ["eess.AS", "cs.SD"], "comment": "Accepted at Interspeech 2025", "summary": "We propose a spatio-spectral, combined model-based and data-driven\ndiarization pipeline consisting of TDOA-based segmentation followed by\nembedding-based clustering. The proposed system requires neither access to\nmulti-channel training data nor prior knowledge about the number or placement\nof microphones. It works for both a compact microphone array and distributed\nmicrophones, with minor adjustments. Due to its superior handling of\noverlapping speech during segmentation, the proposed pipeline significantly\noutperforms the single-channel pyannote approach, both in a scenario with a\ncompact microphone array and in a setup with distributed microphones.\nAdditionally, we show that, unlike fully spatial diarization pipelines, the\nproposed system can correctly track speakers when they change positions.", "AI": {"tldr": "A spatio-spectral diarization pipeline combining TDOA-based segmentation and embedding-based clustering outperforms single-channel methods, handling overlapping speech and speaker movements effectively.", "motivation": "To address limitations of single-channel diarization and fully spatial pipelines, especially in handling overlapping speech and dynamic speaker positions.", "method": "Combines TDOA-based segmentation (time-difference of arrival) with embedding-based clustering, requiring no multi-channel training data or microphone setup knowledge.", "result": "Outperforms single-channel pyannote in overlapping speech scenarios and tracks speakers during position changes, adaptable to compact or distributed microphones.", "conclusion": "The proposed pipeline is versatile, effective for overlapping speech and dynamic speaker tracking, and adaptable to various microphone setups."}}
{"id": "2506.15744", "pdf": "https://arxiv.org/pdf/2506.15744", "abs": "https://arxiv.org/abs/2506.15744", "authors": ["Seyed Mohsen Hosseini"], "title": "Pixel-wise Modulated Dice Loss for Medical Image Segmentation", "categories": ["eess.IV", "cs.CV", "cs.LG"], "comment": null, "summary": "Class imbalance and the difficulty imbalance are the two types of data\nimbalance that affect the performance of neural networks in medical\nsegmentation tasks. In class imbalance the loss is dominated by the majority\nclasses and in difficulty imbalance the loss is dominated by easy to classify\npixels. This leads to an ineffective training. Dice loss, which is based on a\ngeometrical metric, is very effective in addressing the class imbalance\ncompared to the cross entropy (CE) loss, which is adopted directly from\nclassification tasks. To address the difficulty imbalance, the common approach\nis employing a re-weighted CE loss or a modified Dice loss to focus the\ntraining on difficult to classify areas. The existing modification methods are\ncomputationally costly and with limited success. In this study we propose a\nsimple modification to the Dice loss with minimal computational cost. With a\npixel level modulating term, we take advantage of the effectiveness of Dice\nloss in handling the class imbalance to also handle the difficulty imbalance.\nResults on three commonly used medical segmentation tasks show that the\nproposed Pixel-wise Modulated Dice loss (PM Dice loss) outperforms other\nmethods, which are designed to tackle the difficulty imbalance problem.", "AI": {"tldr": "The paper proposes a modified Dice loss (PM Dice loss) to address both class and difficulty imbalances in medical segmentation tasks, outperforming existing methods.", "motivation": "Class and difficulty imbalances in medical segmentation tasks hinder neural network performance, with existing solutions being costly or ineffective.", "method": "Introduces a pixel-level modulating term to the Dice loss, leveraging its class imbalance handling to also address difficulty imbalance with minimal computational cost.", "result": "PM Dice loss outperforms other methods on three medical segmentation tasks.", "conclusion": "The proposed PM Dice loss effectively tackles both class and difficulty imbalances, offering a simple yet superior solution."}}
{"id": "2506.15747", "pdf": "https://arxiv.org/pdf/2506.15747", "abs": "https://arxiv.org/abs/2506.15747", "authors": ["Fangzhou Lin", "Zilin Dai", "Rigved Sanku", "Songlin Hou", "Kazunori D Yamada", "Haichong K. Zhang", "Ziming Zhang"], "title": "A Strong View-Free Baseline Approach for Single-View Image Guided Point Cloud Completion", "categories": ["cs.CV", "eess.IV"], "comment": "6 pages, 2 figures", "summary": "The single-view image guided point cloud completion (SVIPC) task aims to\nreconstruct a complete point cloud from a partial input with the help of a\nsingle-view image. While previous works have demonstrated the effectiveness of\nthis multimodal approach, the fundamental necessity of image guidance remains\nlargely unexamined. To explore this, we propose a strong baseline approach for\nSVIPC based on an attention-based multi-branch encoder-decoder network that\nonly takes partial point clouds as input, view-free. Our hierarchical\nself-fusion mechanism, driven by cross-attention and self-attention layers,\neffectively integrates information across multiple streams, enriching feature\nrepresentations and strengthening the networks ability to capture geometric\nstructures. Extensive experiments and ablation studies on the ShapeNet-ViPC\ndataset demonstrate that our view-free framework performs superiorly to\nstate-of-the-art SVIPC methods. We hope our findings provide new insights into\nthe development of multimodal learning in SVIPC. Our demo code will be\navailable at https://github.com/Zhang-VISLab.", "AI": {"tldr": "A view-free, attention-based multi-branch encoder-decoder network is proposed for single-view image guided point cloud completion (SVIPC), outperforming state-of-the-art methods without image guidance.", "motivation": "To examine the necessity of image guidance in SVIPC and propose a strong baseline using only partial point clouds.", "method": "An attention-based multi-branch encoder-decoder network with hierarchical self-fusion (cross-attention and self-attention layers) for feature integration.", "result": "Superior performance to state-of-the-art SVIPC methods on the ShapeNet-ViPC dataset.", "conclusion": "The findings challenge the necessity of image guidance in SVIPC and offer insights for multimodal learning development."}}
{"id": "2506.15685", "pdf": "https://arxiv.org/pdf/2506.15685", "abs": "https://arxiv.org/abs/2506.15685", "authors": ["Wang Yu-Hang", "Liu ying", "Fang liang", "Wang Xuelin", "Junkang Guo", "Shiwei Li", "Lei Gao", "Jian Liu", "Wenfei Yin"], "title": "Ignition Phase : Standard Training for Fast Adversarial Robustness", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Adversarial Training (AT) is a cornerstone defense, but many variants\noverlook foundational feature representations by primarily focusing on stronger\nattack generation. We introduce Adversarial Evolution Training (AET), a simple\nyet powerful framework that strategically prepends an Empirical Risk\nMinimization (ERM) phase to conventional AT. We hypothesize this initial ERM\nphase cultivates a favorable feature manifold, enabling more efficient and\neffective robustness acquisition. Empirically, AET achieves comparable or\nsuperior robustness more rapidly, improves clean accuracy, and cuts training\ncosts by 8-25\\%. Its effectiveness is shown across multiple datasets,\narchitectures, and when augmenting established AT methods. Our findings\nunderscore the impact of feature pre-conditioning via standard training for\ndeveloping more efficient, principled robust defenses. Code is available in the\nsupplementary material.", "AI": {"tldr": "AET (Adversarial Evolution Training) improves adversarial robustness by adding an initial ERM phase to AT, achieving faster training, better clean accuracy, and lower costs.", "motivation": "Current AT variants focus on attack generation but neglect foundational feature representations, limiting robustness efficiency.", "method": "AET prepends an ERM phase to AT to cultivate a favorable feature manifold, enhancing robustness acquisition.", "result": "AET achieves comparable/superior robustness faster, improves clean accuracy, and reduces training costs by 8-25%.", "conclusion": "Feature pre-conditioning via ERM is key for efficient and principled robust defenses."}}
{"id": "2506.15732", "pdf": "https://arxiv.org/pdf/2506.15732", "abs": "https://arxiv.org/abs/2506.15732", "authors": ["Khurram Yamin", "Gaurav Ghosal", "Bryan Wilder"], "title": "LLMs Struggle to Perform Counterfactual Reasoning with Parametric Knowledge", "categories": ["cs.AI", "cs.LG"], "comment": "ICML 2025 Workshop on Scaling up Intervention Models", "summary": "Large Language Models have been shown to contain extensive world knowledge in\ntheir parameters, enabling impressive performance on many knowledge intensive\ntasks. However, when deployed in novel settings, LLMs often encounter\nsituations where they must integrate parametric knowledge with new or\nunfamiliar information. In this work, we explore whether LLMs can combine\nknowledge in-context with their parametric knowledge through the lens of\ncounterfactual reasoning. Through synthetic and real experiments in multi-hop\nreasoning problems, we show that LLMs generally struggle with counterfactual\nreasoning, often resorting to exclusively using their parametric knowledge.\nMoreover, we show that simple post-hoc finetuning can struggle to instill\ncounterfactual reasoning ability -- often leading to degradation in stored\nparametric knowledge. Ultimately, our work reveals important limitations of\ncurrent LLM's abilities to re-purpose parametric knowledge in novel settings.", "AI": {"tldr": "LLMs struggle with counterfactual reasoning, often relying on parametric knowledge, and finetuning may degrade their stored knowledge.", "motivation": "To explore if LLMs can integrate in-context knowledge with parametric knowledge, focusing on counterfactual reasoning.", "method": "Synthetic and real experiments in multi-hop reasoning problems, with post-hoc finetuning attempts.", "result": "LLMs generally fail at counterfactual reasoning, defaulting to parametric knowledge, and finetuning can harm their existing knowledge.", "conclusion": "Current LLMs have limitations in adapting parametric knowledge to novel settings."}}
{"id": "2506.15889", "pdf": "https://arxiv.org/pdf/2506.15889", "abs": "https://arxiv.org/abs/2506.15889", "authors": ["Yifan Hu", "Frank Liang", "Dachuan Zhao", "Jonathan Geuter", "Varshini Reddy", "Craig W. Schmidt", "Chris Tanner"], "title": "Entropy-Driven Pre-Tokenization for Byte-Pair Encoding", "categories": ["cs.CL"], "comment": null, "summary": "Byte-Pair Encoding (BPE) has become a widely adopted subword tokenization\nmethod in modern language models due to its simplicity and strong empirical\nperformance across downstream tasks. However, applying BPE to unsegmented\nlanguages such as Chinese presents significant challenges, as its\nfrequency-driven merge operation is agnostic to linguistic boundaries. To\naddress this, we propose two entropy-informed pre-tokenization strategies that\nguide BPE segmentation using unsupervised information-theoretic cues. The first\napproach uses pointwise mutual information and left/right entropy to identify\ncoherent character spans, while the second leverages predictive entropy derived\nfrom a pretrained GPT-2 model to detect boundary uncertainty. We evaluate both\nmethods on a subset of the PKU dataset and demonstrate substantial improvements\nin segmentation precision, recall, and F1 score compared to standard BPE. Our\nresults suggest that entropy-guided pre-tokenization not only enhances\nalignment with gold-standard linguistic units but also offers a promising\ndirection for improving tokenization quality in low-resource and multilingual\nsettings.", "AI": {"tldr": "Proposes entropy-informed pre-tokenization strategies to improve BPE for unsegmented languages like Chinese, showing better segmentation metrics.", "motivation": "BPE's frequency-driven merges struggle with unsegmented languages like Chinese due to lack of linguistic boundary awareness.", "method": "Two strategies: (1) pointwise mutual info and entropy for coherent spans, (2) GPT-2 predictive entropy for boundary uncertainty.", "result": "Substantial improvements in precision, recall, and F1 score on PKU dataset compared to standard BPE.", "conclusion": "Entropy-guided pre-tokenization aligns better with linguistic units and improves tokenization, especially in low-resource settings."}}
{"id": "2506.16633", "pdf": "https://arxiv.org/pdf/2506.16633", "abs": "https://arxiv.org/abs/2506.16633", "authors": ["Fenghua Cheng", "Jinxiang Wang", "Sen Wang", "Zi Huang", "Xue Li"], "title": "GeoGuess: Multimodal Reasoning based on Hierarchy of Visual Information in Street View", "categories": ["cs.CL", "cs.AI", "cs.MM"], "comment": null, "summary": "Multimodal reasoning is a process of understanding, integrating and inferring\ninformation across different data modalities. It has recently attracted surging\nacademic attention as a benchmark for Artificial Intelligence (AI). Although\nthere are various tasks for evaluating multimodal reasoning ability, they still\nhave limitations. Lack of reasoning on hierarchical visual clues at different\nlevels of granularity, e.g., local details and global context, is of little\ndiscussion, despite its frequent involvement in real scenarios. To bridge the\ngap, we introduce a novel and challenging task for multimodal reasoning, namely\nGeoGuess. Given a street view image, the task is to identify its location and\nprovide a detailed explanation. A system that succeeds in GeoGuess should be\nable to detect tiny visual clues, perceive the broader landscape, and associate\nwith vast geographic knowledge. Therefore, GeoGuess would require the ability\nto reason between hierarchical visual information and geographic knowledge. In\nthis work, we establish a benchmark for GeoGuess by introducing a specially\ncurated dataset GeoExplain which consists of\npanoramas-geocoordinates-explanation tuples. Additionally, we present a\nmultimodal and multilevel reasoning method, namely SightSense which can make\nprediction and generate comprehensive explanation based on hierarchy of visual\ninformation and external knowledge. Our analysis and experiments demonstrate\ntheir outstanding performance in GeoGuess.", "AI": {"tldr": "The paper introduces GeoGuess, a novel multimodal reasoning task involving location identification and explanation from street view images, and presents the SightSense method for hierarchical visual and geographic knowledge reasoning.", "motivation": "Existing multimodal reasoning tasks lack focus on hierarchical visual clues (local details and global context), which are crucial in real-world scenarios. GeoGuess addresses this gap.", "method": "The authors propose SightSense, a multimodal and multilevel reasoning method, and introduce the GeoExplain dataset (panoramas-geocoordinates-explanation tuples) for benchmarking.", "result": "SightSense demonstrates outstanding performance in GeoGuess, effectively reasoning across hierarchical visual information and geographic knowledge.", "conclusion": "GeoGuess and SightSense advance multimodal reasoning by addressing hierarchical visual clues and integrating geographic knowledge, setting a new benchmark for AI."}}
{"id": "2506.15856", "pdf": "https://arxiv.org/pdf/2506.15856", "abs": "https://arxiv.org/abs/2506.15856", "authors": ["Michael Ledford", "William Regli"], "title": "Learning to Coordinate Under Threshold Rewards: A Cooperative Multi-Agent Bandit Framework", "categories": ["cs.MA"], "comment": null, "summary": "Cooperative multi-agent systems often face tasks that require coordinated\nactions under uncertainty. While multi-armed bandit (MAB) problems provide a\npowerful framework for decentralized learning, most prior work assumes\nindividually attainable rewards. We address the challenging setting where\nrewards are threshold-activated: an arm yields a payoff only when a minimum\nnumber of agents pull it simultaneously, with this threshold unknown in\nadvance. Complicating matters further, some arms are decoys - requiring\ncoordination to activate but yielding no reward - introducing a new challenge\nof wasted joint exploration. We introduce Threshold-Coop-UCB (T-Coop-UCB), a\ndecentralized algorithm that enables agents to jointly learn activation\nthresholds and reward distributions, forming effective coalitions without\ncentralized control. Empirical results show that T-Coop-UCB consistently\noutperforms baseline methods in cumulative reward, regret, and coordination\nmetrics, achieving near-Oracle performance. Our findings underscore the\nimportance of joint threshold learning and decoy avoidance for scalable,\ndecentralized cooperation in complex multi-agent", "AI": {"tldr": "T-Coop-UCB is a decentralized algorithm for multi-agent systems to learn threshold-activated rewards and avoid decoys, outperforming baselines in reward and coordination.", "motivation": "Addressing the challenge of threshold-activated rewards and decoys in cooperative multi-agent systems, where prior work assumes individually attainable rewards.", "method": "Introduces T-Coop-UCB, enabling agents to jointly learn activation thresholds and reward distributions without centralized control.", "result": "Empirical results show T-Coop-UCB outperforms baselines in cumulative reward, regret, and coordination, achieving near-Oracle performance.", "conclusion": "Joint threshold learning and decoy avoidance are crucial for scalable, decentralized cooperation in complex multi-agent systems."}}
{"id": "2506.16020", "pdf": "https://arxiv.org/pdf/2506.16020", "abs": "https://arxiv.org/abs/2506.16020", "authors": ["Zijing Zhao", "Kai Wang", "Hao Huang", "Ying Hu", "Liang He", "Jichen Yang"], "title": "VS-Singer: Vision-Guided Stereo Singing Voice Synthesis with Consistency Schr\u00f6dinger Bridge", "categories": ["cs.SD", "eess.AS"], "comment": "Accepted by Interspeech 2025", "summary": "To explore the potential advantages of utilizing spatial cues from images for\ngenerating stereo singing voices with room reverberation, we introduce\nVS-Singer, a vision-guided model designed to produce stereo singing voices with\nroom reverberation from scene images. VS-Singer comprises three modules:\nfirstly, a modal interaction network integrates spatial features into text\nencoding to create a linguistic representation enriched with spatial\ninformation. Secondly, the decoder employs a consistency Schr\\\"odinger bridge\nto facilitate one-step sample generation. Moreover, we utilize the SFE module\nto improve the consistency of audio-visual matching. To our knowledge, this\nstudy is the first to combine stereo singing voice synthesis with visual\nacoustic matching within a unified framework. Experimental results demonstrate\nthat VS-Singer can effectively generate stereo singing voices that align with\nthe scene perspective in a single step.", "AI": {"tldr": "VS-Singer is a vision-guided model for stereo singing voice synthesis with room reverberation, integrating spatial cues from images.", "motivation": "To leverage spatial cues from images for generating stereo singing voices with room reverberation, combining visual and acoustic matching.", "method": "VS-Singer uses a modal interaction network for spatial-enriched text encoding, a decoder with a consistency Schr\u00f6dinger bridge for one-step generation, and an SFE module for audio-visual matching.", "result": "VS-Singer effectively generates stereo singing voices aligned with scene perspective in one step.", "conclusion": "This is the first unified framework for stereo singing voice synthesis with visual acoustic matching, demonstrating successful integration of spatial cues."}}
{"id": "2506.16231", "pdf": "https://arxiv.org/pdf/2506.16231", "abs": "https://arxiv.org/abs/2506.16231", "authors": ["Doyeop Kwak", "Youngjoon Jang", "Seongyu Kim", "Joon Son Chung"], "title": "EDNet: A Distortion-Agnostic Speech Enhancement Framework with Gating Mamba Mechanism and Phase Shift-Invariant Training", "categories": ["eess.AS", "cs.SD"], "comment": null, "summary": "Speech signals in real-world environments are frequently affected by various\ndistortions such as additive noise, reverberation, and bandwidth limitation,\nwhich may appear individually or in combination. Traditional speech enhancement\nmethods typically rely on either masking, which focuses on suppressing\nnon-speech components while preserving observable structure, or mapping, which\nseeks to recover clean speech through direct transformation of the input. Each\napproach offers strengths in specific scenarios but may be less effective\noutside its target conditions. We propose the Erase and Draw Network (EDNet), a\ndistortion-agnostic speech enhancement framework designed to handle a broad\nrange of distortion types without prior assumptions about task or input\ncharacteristics. EDNet consists of two main components: (1) the Gating Mamba\n(GM) module, which adaptively combines masking and mapping through a learnable\ngating mechanism that selects between suppression (Erase) and reconstruction\n(Draw) based on local signal features, and (2) Phase Shift-Invariant Training\n(PSIT), a shift tolerant supervision strategy that improves phase estimation by\nenabling dynamic alignment during training while remaining compatible with\nstandard loss functions. Experimental results on denoising, dereverberation,\nbandwidth extension, and multi distortion enhancement tasks show that EDNet\nconsistently achieves strong performance across conditions, demonstrating its\narchitectural flexibility and adaptability to diverse task settings.", "AI": {"tldr": "EDNet is a distortion-agnostic speech enhancement framework combining masking and mapping via a gating mechanism, achieving strong performance across diverse distortions.", "motivation": "Real-world speech signals suffer from multiple distortions, but traditional methods (masking or mapping) are limited to specific scenarios.", "method": "EDNet uses a Gating Mamba module (adaptive masking/mapping) and Phase Shift-Invariant Training for robust phase estimation.", "result": "EDNet excels in denoising, dereverberation, bandwidth extension, and multi-distortion tasks.", "conclusion": "EDNet is flexible and adaptable, outperforming traditional methods across diverse conditions."}}
{"id": "2506.15745", "pdf": "https://arxiv.org/pdf/2506.15745", "abs": "https://arxiv.org/abs/2506.15745", "authors": ["Minsoo Kim", "Kyuhong Shim", "Jungwook Choi", "Simyung Chang"], "title": "InfiniPot-V: Memory-Constrained KV Cache Compression for Streaming Video Understanding", "categories": ["eess.IV", "cs.LG"], "comment": null, "summary": "Modern multimodal large language models (MLLMs) can reason over hour-long\nvideo, yet their key-value (KV) cache grows linearly with time--quickly\nexceeding the fixed memory of phones, AR glasses, and edge robots. Prior\ncompression schemes either assume the whole video and user query are available\noffline or must first build the full cache, so memory still scales with stream\nlength. InfiniPot-V is the first training-free, query-agnostic framework that\nenforces a hard, length-independent memory cap for streaming video\nunderstanding. During video encoding it monitors the cache and, once a user-set\nthreshold is reached, runs a lightweight compression pass that (i) removes\ntemporally redundant tokens via Temporal-axis Redundancy (TaR) metric and (ii)\nkeeps semantically significant tokens via Value-Norm (VaN) ranking. Across four\nopen-source MLLMs and four long-video and two streaming-video benchmarks,\nInfiniPot-V cuts peak GPU memory by up to 94%, sustains real-time generation,\nand matches or surpasses full-cache accuracy--even in multi-turn dialogues. By\ndissolving the KV cache bottleneck without retraining or query knowledge,\nInfiniPot-V closes the gap for on-device streaming video assistants.", "AI": {"tldr": "InfiniPot-V is a training-free, query-agnostic framework that enforces a hard memory cap for streaming video understanding by compressing the KV cache without retraining or query knowledge.", "motivation": "Modern MLLMs face memory limitations due to linear KV cache growth with video length, hindering deployment on edge devices.", "method": "InfiniPot-V monitors the cache, removes redundant tokens via TaR metric, and retains significant tokens via VaN ranking once a memory threshold is reached.", "result": "It reduces peak GPU memory by up to 94%, maintains real-time generation, and matches full-cache accuracy.", "conclusion": "InfiniPot-V enables efficient on-device streaming video assistants by eliminating the KV cache bottleneck."}}
{"id": "2506.15755", "pdf": "https://arxiv.org/pdf/2506.15755", "abs": "https://arxiv.org/abs/2506.15755", "authors": ["Xiasi Wang", "Tianliang Yao", "Simin Chen", "Runqi Wang", "Lei YE", "Kuofeng Gao", "Yi Huang", "Yuan Yao"], "title": "VLMInferSlow: Evaluating the Efficiency Robustness of Large Vision-Language Models as a Service", "categories": ["cs.CV", "cs.CL"], "comment": "Accepted by ACL 2025", "summary": "Vision-Language Models (VLMs) have demonstrated great potential in real-world\napplications. While existing research primarily focuses on improving their\naccuracy, the efficiency remains underexplored. Given the real-time demands of\nmany applications and the high inference overhead of VLMs, efficiency\nrobustness is a critical issue. However, previous studies evaluate efficiency\nrobustness under unrealistic assumptions, requiring access to the model\narchitecture and parameters -- an impractical scenario in ML-as-a-service\nsettings, where VLMs are deployed via inference APIs. To address this gap, we\npropose VLMInferSlow, a novel approach for evaluating VLM efficiency robustness\nin a realistic black-box setting. VLMInferSlow incorporates fine-grained\nefficiency modeling tailored to VLM inference and leverages zero-order\noptimization to search for adversarial examples. Experimental results show that\nVLMInferSlow generates adversarial images with imperceptible perturbations,\nincreasing the computational cost by up to 128.47%. We hope this research\nraises the community's awareness about the efficiency robustness of VLMs.", "AI": {"tldr": "The paper introduces VLMInferSlow, a method to evaluate efficiency robustness of Vision-Language Models (VLMs) in black-box settings, addressing gaps in prior research.", "motivation": "Existing research on VLMs focuses on accuracy, neglecting efficiency robustness, which is critical for real-time applications. Previous evaluations are impractical in ML-as-a-service settings.", "method": "Proposes VLMInferSlow, combining fine-grained efficiency modeling for VLMs and zero-order optimization to find adversarial examples.", "result": "VLMInferSlow generates adversarial images with subtle perturbations, increasing computational cost by up to 128.47%.", "conclusion": "The study highlights the importance of efficiency robustness in VLMs and provides a practical evaluation method for black-box scenarios."}}
{"id": "2506.15686", "pdf": "https://arxiv.org/pdf/2506.15686", "abs": "https://arxiv.org/abs/2506.15686", "authors": ["Jiahe Qin", "Junpeng Li", "Changchun Hua", "Yana Yang"], "title": "Learning from M-Tuple Dominant Positive and Unlabeled Data", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Label Proportion Learning (LLP) addresses the classification problem where\nmultiple instances are grouped into bags and each bag contains information\nabout the proportion of each class. However, in practical applications,\nobtaining precise supervisory information regarding the proportion of instances\nin a specific class is challenging. To better align with real-world application\nscenarios and effectively leverage the proportional constraints of instances\nwithin tuples, this paper proposes a generalized learning framework\n\\emph{MDPU}. Specifically, we first mathematically model the distribution of\ninstances within tuples of arbitrary size, under the constraint that the number\nof positive instances is no less than that of negative instances. Then we\nderive an unbiased risk estimator that satisfies risk consistency based on the\nempirical risk minimization (ERM) method. To mitigate the inevitable\noverfitting issue during training, a risk correction method is introduced,\nleading to the development of a corrected risk estimator. The generalization\nerror bounds of the unbiased risk estimator theoretically demonstrate the\nconsistency of the proposed method. Extensive experiments on multiple datasets\nand comparisons with other relevant baseline methods comprehensively validate\nthe effectiveness of the proposed learning framework.", "AI": {"tldr": "The paper proposes MDPU, a generalized learning framework for Label Proportion Learning (LLP), addressing challenges in obtaining precise class proportions. It includes unbiased risk estimation, risk correction, and theoretical guarantees.", "motivation": "Practical applications struggle with obtaining precise class proportion information, and existing methods may not fully leverage proportional constraints within tuples.", "method": "MDPU models instance distribution under constraints, derives an unbiased risk estimator, and introduces risk correction to prevent overfitting.", "result": "The framework shows consistency in theory and outperforms baselines in experiments.", "conclusion": "MDPU effectively addresses LLP challenges, offering a robust and practical solution."}}
{"id": "2506.15733", "pdf": "https://arxiv.org/pdf/2506.15733", "abs": "https://arxiv.org/abs/2506.15733", "authors": ["Mert Cemri", "Nived Rajaraman", "Rishabh Tiwari", "Xiaoxuan Liu", "Kurt Keutzer", "Ion Stoica", "Kannan Ramchandran", "Ahmad Beirami", "Ziteng Sun"], "title": "$\\texttt{SPECS}$: Faster Test-Time Scaling through Speculative Drafts", "categories": ["cs.AI", "cs.CL", "cs.LG"], "comment": "28 pages, 6 figures, 2 tables", "summary": "Scaling test-time compute has driven the recent advances in the reasoning\ncapabilities of large language models (LLMs), typically by allocating\nadditional computation for more thorough exploration. However, increased\ncompute often comes at the expense of higher user-facing latency, directly\nimpacting user experience. Current test-time scaling methods primarily optimize\nfor accuracy based on total compute resources (FLOPS), often overlooking\nlatency constraints. To address this gap, we propose $\\texttt{SPECS}$, a\nlatency-aware test-time scaling method inspired by speculative decoding.\n$\\texttt{SPECS}$~uses a smaller, faster model to generate candidate sequences\nefficiently, and evaluates these candidates using signals from both a larger\ntarget model and a dedicated reward model. We introduce new integration\nstrategies, including reward-guided soft verification and a reward-based\ndeferral mechanism. Empirical results on MATH500, AMC23 and OlympiadBench\ndatasets show that $\\texttt{SPECS}$~matches or surpasses beam search accuracy\nwhile reducing latency by up to $\\sim$19.1\\%. Our theoretical analysis shows\nthat our algorithm converges to the solution of a KL-regularized reinforcement\nlearning objective with increasing beam width.", "AI": {"tldr": "The paper proposes $\texttt{SPECS}$, a latency-aware test-time scaling method for LLMs, balancing accuracy and latency by using a smaller model for candidate generation and integrating reward signals.", "motivation": "Current test-time scaling methods focus on accuracy via compute (FLOPS) but neglect latency, impacting user experience. $\texttt{SPECS}$ addresses this gap.", "method": "$\texttt{SPECS}$ uses a smaller model for efficient candidate generation, evaluates candidates with a larger model and reward model, and introduces reward-guided soft verification and deferral.", "result": "Empirical results show $\texttt{SPECS}$ matches or exceeds beam search accuracy while reducing latency by up to 19.1%.", "conclusion": "$\texttt{SPECS}$ effectively balances accuracy and latency, with theoretical convergence to a KL-regularized RL objective."}}
{"id": "2506.15894", "pdf": "https://arxiv.org/pdf/2506.15894", "abs": "https://arxiv.org/abs/2506.15894", "authors": ["Sam Silver", "Jimin Sun", "Ivan Zhang", "Sara Hooker", "Eddie Kim"], "title": "Language Models can perform Single-Utterance Self-Correction of Perturbed Reasoning", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Large Language Models (LLMs) have demonstrated impressive mathematical\nreasoning capabilities, yet their performance remains brittle to minor\nvariations in problem description and prompting strategy. Furthermore,\nreasoning is vulnerable to sampling-induced errors which autoregressive models\nmust primarily address using self-correction via additionally-generated tokens.\nTo better understand self-correction capabilities of recent models, we conduct\nexperiments measuring models' ability to self-correct synthetic perturbations\nintroduced into their Chain of Thought (CoT) reasoning. We observe robust\nsingle-utterance intrinsic self-correction behavior across a range of\nopen-weight models and datasets, ranging from subtle, implicit corrections to\nexplicit acknowledgments and corrections of errors. Our findings suggest that\nLLMs, including those not finetuned for long CoT, may possess stronger\nintrinsic self-correction capabilities than commonly shown in the literature.\nThe presence of this ability suggests that recent \"reasoning\" model work\ninvolves amplification of traits already meaningfully present in models.", "AI": {"tldr": "LLMs show robust self-correction in reasoning, even without fine-tuning, suggesting intrinsic capabilities beyond current literature.", "motivation": "To understand LLMs' self-correction abilities in mathematical reasoning, especially under synthetic perturbations.", "method": "Experiments measuring models' self-correction of synthetic perturbations in Chain of Thought reasoning.", "result": "Models exhibit strong intrinsic self-correction, from subtle to explicit error corrections.", "conclusion": "LLMs may have stronger intrinsic self-correction than previously thought, indicating reasoning work amplifies existing traits."}}
{"id": "2506.16745", "pdf": "https://arxiv.org/pdf/2506.16745", "abs": "https://arxiv.org/abs/2506.16745", "authors": ["Qi-Ying Sun", "Wan-Lei Zhao", "Yi-Bo Miao", "Chong-Wah Ngo"], "title": "Class Agnostic Instance-level Descriptor for Visual Instance Search", "categories": ["cs.CV", "cs.MM"], "comment": null, "summary": "Despite the great success of the deep features in content-based image\nretrieval, the visual instance search remains challenging due to the lack of\neffective instance level feature representation. Supervised or weakly\nsupervised object detection methods are not among the options due to their poor\nperformance on the unknown object categories. In this paper, based on the\nfeature set output from self-supervised ViT, the instance level region\ndiscovery is modeled as detecting the compact feature subsets in a hierarchical\nfashion. The hierarchical decomposition results in a hierarchy of feature\nsubsets. The non-leaf nodes and leaf nodes on the hierarchy correspond to the\nvarious instance regions in an image of different semantic scales. The\nhierarchical decomposition well addresses the problem of object embedding and\nocclusions, which are widely observed in the real scenarios. The features\nderived from the nodes on the hierarchy make up a comprehensive representation\nfor the latent instances in the image. Our instance-level descriptor remains\neffective on both the known and unknown object categories. Empirical studies on\nthree instance search benchmarks show that it outperforms state-of-the-art\nmethods considerably.", "AI": {"tldr": "The paper proposes a hierarchical method for instance-level region discovery using self-supervised ViT features, addressing challenges like object embedding and occlusions in image retrieval.", "motivation": "Existing methods struggle with unknown object categories and lack effective instance-level feature representation.", "method": "Hierarchical decomposition of feature subsets from self-supervised ViT to model instance regions at different semantic scales.", "result": "Outperforms state-of-the-art methods on three instance search benchmarks, effective for known and unknown object categories.", "conclusion": "The hierarchical approach provides a comprehensive and robust solution for instance-level image retrieval."}}
{"id": "2506.16277", "pdf": "https://arxiv.org/pdf/2506.16277", "abs": "https://arxiv.org/abs/2506.16277", "authors": ["Rico Schrage", "Jari Radler", "Astrid Nie\u00dfe"], "title": "Coordination of Electrical and Heating Resources by Self-Interested Agents", "categories": ["cs.MA"], "comment": null, "summary": "With the rise of distributed energy resources and sector coupling,\ndistributed optimization can be a sensible approach to coordinate decentralized\nenergy resources. Further, district heating, heat pumps, cogeneration, and\nsharing concepts like local energy communities introduce the potential to\noptimize heating and electricity output simultaneously. To solve this issue, we\ntackle the distributed multi-energy scheduling optimization problem, which\ndescribes the optimization of distributed energy generators over multiple time\nsteps to reach a specific target schedule. This work describes a novel\ndistributed hybrid algorithm as a solution approach. This approach is based on\nthe heuristics of gossiping and local search and can simultaneously optimize\nthe private objective of the participants and the collective objective,\nconsidering multiple energy sectors. We show that the algorithm finds globally\nnear-optimal solutions while protecting the stakeholders' economic goals and\nthe plants' technical properties. Two test cases representing pure electrical\nand gas-based technologies are evaluated.", "AI": {"tldr": "A novel distributed hybrid algorithm optimizes multi-energy scheduling for decentralized resources, balancing private and collective objectives.", "motivation": "The rise of distributed energy resources and sector coupling necessitates efficient coordination methods for decentralized energy optimization.", "method": "A distributed hybrid algorithm combining gossiping heuristics and local search to optimize energy scheduling across multiple sectors.", "result": "The algorithm achieves near-optimal global solutions while respecting economic and technical constraints, validated in electrical and gas-based test cases.", "conclusion": "The proposed approach effectively addresses multi-energy scheduling, ensuring stakeholder goals and technical feasibility."}}
{"id": "2506.16127", "pdf": "https://arxiv.org/pdf/2506.16127", "abs": "https://arxiv.org/abs/2506.16127", "authors": ["Shoutrik Das", "Nishant Singh", "Arjun Gangwar", "S Umesh"], "title": "Improved Intelligibility of Dysarthric Speech using Conditional Flow Matching", "categories": ["cs.SD", "cs.AI", "eess.AS"], "comment": "Accepted at Interspeech 2025", "summary": "Dysarthria is a neurological disorder that significantly impairs speech\nintelligibility, often rendering affected individuals unable to communicate\neffectively. This necessitates the development of robust dysarthric-to-regular\nspeech conversion techniques. In this work, we investigate the utility and\nlimitations of self-supervised learning (SSL) features and their quantized\nrepresentations as an alternative to mel-spectrograms for speech generation.\nAdditionally, we explore methods to mitigate speaker variability by generating\nclean speech in a single-speaker voice using features extracted from WavLM. To\nthis end, we propose a fully non-autoregressive approach that leverages\nConditional Flow Matching (CFM) with Diffusion Transformers to learn a direct\nmapping from dysarthric to clean speech. Our findings highlight the\neffectiveness of discrete acoustic units in improving intelligibility while\nachieving faster convergence compared to traditional mel-spectrogram-based\napproaches.", "AI": {"tldr": "The paper explores using self-supervised learning (SSL) features and quantized representations for dysarthric-to-clean speech conversion, proposing a non-autoregressive method with Conditional Flow Matching (CFM) and Diffusion Transformers.", "motivation": "Dysarthria severely impairs speech intelligibility, creating a need for effective conversion techniques to improve communication for affected individuals.", "method": "The study investigates SSL features and WavLM-extracted features, proposing a non-autoregressive approach using CFM with Diffusion Transformers for direct dysarthric-to-clean speech mapping.", "result": "Discrete acoustic units improve intelligibility and achieve faster convergence than mel-spectrogram-based methods.", "conclusion": "The proposed method demonstrates the potential of SSL features and quantized representations for efficient and effective dysarthric speech conversion."}}
{"id": "2506.16741", "pdf": "https://arxiv.org/pdf/2506.16741", "abs": "https://arxiv.org/abs/2506.16741", "authors": ["Hyun Joon Park", "Jeongmin Liu", "Jin Sob Kim", "Jeong Yeol Yang", "Sung Won Han", "Eunwoo Song"], "title": "RapFlow-TTS: Rapid and High-Fidelity Text-to-Speech with Improved Consistency Flow Matching", "categories": ["eess.AS", "cs.AI"], "comment": "Accepted on Interspeech 2025", "summary": "We introduce RapFlow-TTS, a rapid and high-fidelity TTS acoustic model that\nleverages velocity consistency constraints in flow matching (FM) training.\nAlthough ordinary differential equation (ODE)-based TTS generation achieves\nnatural-quality speech, it typically requires a large number of generation\nsteps, resulting in a trade-off between quality and inference speed. To address\nthis challenge, RapFlow-TTS enforces consistency in the velocity field along\nthe FM-straightened ODE trajectory, enabling consistent synthetic quality with\nfewer generation steps. Additionally, we introduce techniques such as time\ninterval scheduling and adversarial learning to further enhance the quality of\nthe few-step synthesis. Experimental results show that RapFlow-TTS achieves\nhigh-fidelity speech synthesis with a 5- and 10-fold reduction in synthesis\nsteps than the conventional FM- and score-based approaches, respectively.", "AI": {"tldr": "RapFlow-TTS is a fast, high-quality TTS model using velocity consistency in flow matching to reduce synthesis steps without sacrificing quality.", "motivation": "Address the trade-off between speech quality and inference speed in ODE-based TTS models.", "method": "Leverages velocity consistency constraints in flow matching, time interval scheduling, and adversarial learning.", "result": "Achieves high-fidelity speech with 5-10x fewer synthesis steps than conventional methods.", "conclusion": "RapFlow-TTS offers rapid, high-quality TTS synthesis by optimizing flow matching and reducing steps."}}
{"id": "2506.15748", "pdf": "https://arxiv.org/pdf/2506.15748", "abs": "https://arxiv.org/abs/2506.15748", "authors": ["Zhe Wang", "Yuhua Ru", "Aladine Chetouani", "Tina Shiang", "Fang Chen", "Fabian Bauer", "Liping Zhang", "Didier Hans", "Rachid Jennane", "William Ewing Palmer", "Mohamed Jarraya", "Yung Hsin Chen"], "title": "Diffusion-based Counterfactual Augmentation: Towards Robust and Interpretable Knee Osteoarthritis Grading", "categories": ["eess.IV", "cs.CV"], "comment": null, "summary": "Automated grading of Knee Osteoarthritis (KOA) from radiographs is challenged\nby significant inter-observer variability and the limited robustness of deep\nlearning models, particularly near critical decision boundaries. To address\nthese limitations, this paper proposes a novel framework, Diffusion-based\nCounterfactual Augmentation (DCA), which enhances model robustness and\ninterpretability by generating targeted counterfactual examples. The method\nnavigates the latent space of a diffusion model using a Stochastic Differential\nEquation (SDE), governed by balancing a classifier-informed boundary drive with\na manifold constraint. The resulting counterfactuals are then used within a\nself-corrective learning strategy to improve the classifier by focusing on its\nspecific areas of uncertainty. Extensive experiments on the public\nOsteoarthritis Initiative (OAI) and Multicenter Osteoarthritis Study (MOST)\ndatasets demonstrate that this approach significantly improves classification\naccuracy across multiple model architectures. Furthermore, the method provides\ninterpretability by visualizing minimal pathological changes and revealing that\nthe learned latent space topology aligns with clinical knowledge of KOA\nprogression. The DCA framework effectively converts model uncertainty into a\nrobust training signal, offering a promising pathway to developing more\naccurate and trustworthy automated diagnostic systems. Our code is available at\nhttps://github.com/ZWang78/DCA.", "AI": {"tldr": "The paper proposes Diffusion-based Counterfactual Augmentation (DCA) to improve robustness and interpretability in automated Knee Osteoarthritis grading by generating targeted counterfactuals using a diffusion model and SDE.", "motivation": "Address inter-observer variability and deep learning model limitations near critical decision boundaries in KOA grading.", "method": "Uses a diffusion model with SDE to generate counterfactuals, balancing classifier-informed boundary drive and manifold constraint, and employs self-corrective learning.", "result": "Significantly improves classification accuracy on OAI and MOST datasets, aligns latent space with clinical KOA progression, and enhances interpretability.", "conclusion": "DCA converts model uncertainty into a robust training signal, advancing accurate and trustworthy automated diagnostics."}}
{"id": "2506.15757", "pdf": "https://arxiv.org/pdf/2506.15757", "abs": "https://arxiv.org/abs/2506.15757", "authors": ["Ruoyu Wang", "Tong Yu", "Junda Wu", "Yao Liu", "Julian McAuley", "Lina Yao"], "title": "Weakly-supervised VLM-guided Partial Contrastive Learning for Visual Language Navigation", "categories": ["cs.CV"], "comment": null, "summary": "Visual Language Navigation (VLN) is a fundamental task within the field of\nEmbodied AI, focusing on the ability of agents to navigate complex environments\nbased on natural language instructions. Despite the progress made by existing\nmethods, these methods often present some common challenges. First, they rely\non pre-trained backbone models for visual perception, which struggle with the\ndynamic viewpoints in VLN scenarios. Second, the performance is limited when\nusing pre-trained LLMs or VLMs without fine-tuning, due to the absence of VLN\ndomain knowledge. Third, while fine-tuning LLMs and VLMs can improve results,\ntheir computational costs are higher than those without fine-tuning. To address\nthese limitations, we propose Weakly-supervised Partial Contrastive Learning\n(WPCL), a method that enhances an agent's ability to identify objects from\ndynamic viewpoints in VLN scenarios by effectively integrating pre-trained VLM\nknowledge into the perception process, without requiring VLM fine-tuning. Our\nmethod enhances the agent's ability to interpret and respond to environmental\ncues while ensuring computational efficiency. Experimental results have shown\nthat our method outperforms the baseline methods on multiple benchmarks, which\nvalidate the effectiveness, robustness and generalizability of our method.", "AI": {"tldr": "The paper proposes Weakly-supervised Partial Contrastive Learning (WPCL) to improve Visual Language Navigation (VLN) by integrating pre-trained VLM knowledge without fine-tuning, addressing challenges like dynamic viewpoints and computational costs.", "motivation": "Existing VLN methods face issues with dynamic viewpoints, lack of domain knowledge in pre-trained models, and high computational costs of fine-tuning.", "method": "WPCL integrates pre-trained VLM knowledge into perception without fine-tuning, enhancing object identification from dynamic viewpoints.", "result": "WPCL outperforms baseline methods on multiple benchmarks, showing effectiveness, robustness, and generalizability.", "conclusion": "WPCL offers a computationally efficient solution to VLN challenges, improving performance without fine-tuning pre-trained models."}}
{"id": "2506.15687", "pdf": "https://arxiv.org/pdf/2506.15687", "abs": "https://arxiv.org/abs/2506.15687", "authors": ["Yajie Ji", "Yanlai Chen", "Shawn Koohy"], "title": "S$^2$GPT-PINNs: Sparse and Small models for PDEs", "categories": ["cs.LG", "stat.ML", "65M70, 65N99, 68U99, 68T07"], "comment": "17 pages,6 figures", "summary": "We propose S$^2$GPT-PINN, a sparse and small model for solving parametric\npartial differential equations (PDEs). Similar to Small Language Models (SLMs),\nS$^2$GPT-PINN is tailored to domain-specific (families of) PDEs and\ncharacterized by its compact architecture and minimal computational power.\nLeveraging a small amount of extremely high quality data via a mathematically\nrigorous greedy algorithm that is enabled by the large full-order models,\nS$^2$GPT-PINN relies on orders of magnitude less parameters than PINNs to\nachieve extremely high efficiency via two levels of customizations. The first\nis knowledge distillation via task-specific activation functions that are\ntransferred from Pre-Trained PINNs. The second is a judicious down-sampling\nwhen calculating the physics-informed loss of the network compressing the\nnumber of data sites by orders of magnitude to the size of the small model.", "AI": {"tldr": "S$^2$GPT-PINN is a compact, efficient model for solving parametric PDEs, using minimal parameters and computational power via knowledge distillation and down-sampling.", "motivation": "To address the need for domain-specific, efficient solutions for parametric PDEs without the computational overhead of large models.", "method": "Leverages high-quality data and a greedy algorithm, uses knowledge distillation from Pre-Trained PINNs, and employs down-sampling for physics-informed loss calculation.", "result": "Achieves high efficiency with significantly fewer parameters than traditional PINNs.", "conclusion": "S$^2$GPT-PINN offers a scalable, efficient approach for solving parametric PDEs with minimal computational resources."}}
{"id": "2506.15734", "pdf": "https://arxiv.org/pdf/2506.15734", "abs": "https://arxiv.org/abs/2506.15734", "authors": ["Peiyuan Tang", "Haojie Xin", "Xiaodong Zhang", "Jun Sun", "Qin Xia", "Zijiang Yang"], "title": "The Safety Reminder: A Soft Prompt to Reactivate Delayed Safety Awareness in Vision-Language Models", "categories": ["cs.AI", "cs.CL", "cs.CR", "cs.CV", "cs.LG"], "comment": "23 pages, 10 figures", "summary": "As Vision-Language Models (VLMs) demonstrate increasing capabilities across\nreal-world applications such as code generation and chatbot assistance,\nensuring their safety has become paramount. Unlike traditional Large Language\nModels (LLMs), VLMs face unique vulnerabilities due to their multimodal nature,\nallowing adversaries to modify visual or textual inputs to bypass safety\nguardrails and trigger the generation of harmful content. Through systematic\nanalysis of VLM behavior under attack, we identify a novel phenomenon termed\n``delayed safety awareness''. Specifically, we observe that safety-aligned VLMs\nmay initially be compromised to produce harmful content, but eventually\nrecognize the associated risks and attempt to self-correct. This pattern\nsuggests that VLMs retain their underlying safety awareness but experience a\ntemporal delay in their activation. Building on this insight, we hypothesize\nthat VLMs' safety awareness can be proactively reactivated through carefully\ndesigned prompts. To this end, we introduce ``The Safety Reminder'', a soft\nprompt tuning approach that optimizes learnable prompt tokens, which are\nperiodically injected during the text generation process to enhance safety\nawareness, effectively preventing harmful content generation. Additionally, our\nsafety reminder only activates when harmful content is detected, leaving normal\nconversations unaffected and preserving the model's performance on benign\ntasks. Through comprehensive evaluation across three established safety\nbenchmarks and one adversarial attacks, we demonstrate that our approach\nsignificantly reduces attack success rates while maintaining model utility,\noffering a practical solution for deploying safer VLMs in real-world\napplications.", "AI": {"tldr": "The paper introduces \"The Safety Reminder,\" a prompt-tuning method to enhance safety awareness in Vision-Language Models (VLMs) by proactively reactivating their delayed safety mechanisms, reducing harmful content generation without affecting normal performance.", "motivation": "VLMs face unique vulnerabilities due to their multimodal nature, allowing adversaries to bypass safety measures and generate harmful content. The paper aims to address this by leveraging the observed \"delayed safety awareness\" phenomenon.", "method": "The authors propose \"The Safety Reminder,\" a soft prompt-tuning approach that injects learnable prompt tokens during text generation to reactivate safety awareness when harmful content is detected.", "result": "The method significantly reduces attack success rates in VLMs across three safety benchmarks and one adversarial attack, while preserving model utility for benign tasks.", "conclusion": "The Safety Reminder offers a practical solution for deploying safer VLMs in real-world applications by enhancing safety awareness without compromising performance."}}
{"id": "2506.15911", "pdf": "https://arxiv.org/pdf/2506.15911", "abs": "https://arxiv.org/abs/2506.15911", "authors": ["Mohammad Amaan Sayeed", "Mohammed Talha Alam", "Raza Imam", "Shahab Saquib Sohail", "Amir Hussain"], "title": "From RAG to Agentic: Validating Islamic-Medicine Responses with LLM Agents", "categories": ["cs.CL"], "comment": "Under-review at the 4th Muslims in Machine Learning (MusIML) Workshop\n  (ICML-25)", "summary": "Centuries-old Islamic medical texts like Avicenna's Canon of Medicine and the\nProphetic Tibb-e-Nabawi encode a wealth of preventive care, nutrition, and\nholistic therapies, yet remain inaccessible to many and underutilized in modern\nAI systems. Existing language-model benchmarks focus narrowly on factual recall\nor user preference, leaving a gap in validating culturally grounded medical\nguidance at scale. We propose a unified evaluation pipeline, Tibbe-AG, that\naligns 30 carefully curated Prophetic-medicine questions with human-verified\nremedies and compares three LLMs (LLaMA-3, Mistral-7B, Qwen2-7B) under three\nconfigurations: direct generation, retrieval-augmented generation, and a\nscientific self-critique filter. Each answer is then assessed by a secondary\nLLM serving as an agentic judge, yielding a single 3C3H quality score.\nRetrieval improves factual accuracy by 13%, while the agentic prompt adds\nanother 10% improvement through deeper mechanistic insight and safety\nconsiderations. Our results demonstrate that blending classical Islamic texts\nwith retrieval and self-evaluation enables reliable, culturally sensitive\nmedical question-answering.", "AI": {"tldr": "The paper introduces Tibbe-AG, a pipeline to evaluate LLMs on culturally grounded Islamic medical texts, showing retrieval and self-critique improve accuracy and reliability.", "motivation": "To bridge the gap in modern AI systems by leveraging classical Islamic medical texts for culturally sensitive medical guidance.", "method": "A unified evaluation pipeline (Tibbe-AG) tests three LLMs (LLaMA-3, Mistral-7B, Qwen2-7B) under three configurations: direct generation, retrieval-augmented generation, and a scientific self-critique filter.", "result": "Retrieval improves factual accuracy by 13%, and the agentic prompt adds another 10% improvement. The pipeline enables reliable, culturally sensitive medical QA.", "conclusion": "Combining classical Islamic texts with retrieval and self-evaluation enhances AI's ability to provide culturally grounded medical guidance."}}
{"id": "2506.16784", "pdf": "https://arxiv.org/pdf/2506.16784", "abs": "https://arxiv.org/abs/2506.16784", "authors": ["Xiaoyu Shi", "Rahul Kumar Jain", "Yinhao Li", "Ruibo Hou", "Jingliang Cheng", "Jie Bai", "Guohua Zhao", "Lanfen Lin", "Rui Xu", "Yen-wei Chen"], "title": "TextBraTS: Text-Guided Volumetric Brain Tumor Segmentation with Innovative Dataset Development and Fusion Module Exploration", "categories": ["cs.CV", "cs.MM"], "comment": null, "summary": "Deep learning has demonstrated remarkable success in medical image\nsegmentation and computer-aided diagnosis. In particular, numerous advanced\nmethods have achieved state-of-the-art performance in brain tumor segmentation\nfrom MRI scans. While recent studies in other medical imaging domains have\nrevealed that integrating textual reports with visual data can enhance\nsegmentation accuracy, the field of brain tumor analysis lacks a comprehensive\ndataset that combines radiological images with corresponding textual\nannotations. This limitation has hindered the exploration of multimodal\napproaches that leverage both imaging and textual data.\n  To bridge this critical gap, we introduce the TextBraTS dataset, the first\npublicly available volume-level multimodal dataset that contains paired MRI\nvolumes and rich textual annotations, derived from the widely adopted BraTS2020\nbenchmark. Building upon this novel dataset, we propose a novel baseline\nframework and sequential cross-attention method for text-guided volumetric\nmedical image segmentation. Through extensive experiments with various\ntext-image fusion strategies and templated text formulations, our approach\ndemonstrates significant improvements in brain tumor segmentation accuracy,\noffering valuable insights into effective multimodal integration techniques.\n  Our dataset, implementation code, and pre-trained models are publicly\navailable at https://github.com/Jupitern52/TextBraTS.", "AI": {"tldr": "The paper introduces TextBraTS, the first multimodal dataset combining MRI volumes and textual annotations for brain tumor segmentation, and proposes a novel framework for text-guided segmentation, showing improved accuracy.", "motivation": "Existing brain tumor segmentation lacks multimodal datasets combining imaging and textual data, limiting exploration of text-image fusion methods.", "method": "A novel baseline framework and sequential cross-attention method for text-guided volumetric segmentation, tested with various fusion strategies and templated text formulations.", "result": "Significant improvements in brain tumor segmentation accuracy, demonstrating effective multimodal integration.", "conclusion": "The TextBraTS dataset and proposed framework advance multimodal approaches in medical image segmentation, with publicly available resources."}}
{"id": "2506.16311", "pdf": "https://arxiv.org/pdf/2506.16311", "abs": "https://arxiv.org/abs/2506.16311", "authors": ["Aijing Kong", "Chengkai Xu", "Xian Wu", "Xinbo Chen", "Peng Hang"], "title": "Towards Emergency Scenarios: An Integrated Decision-making Framework of Multi-lane Platoon Reorganization", "categories": ["cs.MA"], "comment": null, "summary": "To enhance the ability for vehicle platoons to respond to emergency\nscenarios, a platoon distribution reorganization decision-making framework is\nproposed. This framework contains platoon distribution layer, vehicle\ncooperative decision-making layer and vehicle planning and control layer.\nFirstly, a reinforcement-learning-based platoon distribution model is\npresented, where a risk potential field is established to quantitatively assess\ndriving risks, and a reward function tailored to the platoon reorganization\nprocess is constructed. Then, a coalition-game-based vehicle cooperative\ndecision-making model is put forward, modeling the cooperative relationships\namong vehicles through dividing coalitions and generating the optimal decision\nresults for each vehicle. Additionally, a novel graph-theory-based Platoon\nDisposition Index (PDI) is incorporated into the game reward function to\nmeasure the platoon's distribution state during the reorganization process, in\norder to accelerating the reorganization process. Finally, the validation of\nthe proposed framework is conducted in two high-risk scenarios under random\ntraffic flows. The results show that, compared to the baseline models, the\nproposed method can significantly reduce the collision rate and improve driving\nefficiency. Moreover, the model with PDI can significantly decrease the platoon\nformation reorganization time and improve the reorganization efficiency.", "AI": {"tldr": "A framework for vehicle platoon reorganization in emergencies uses reinforcement learning and coalition games, reducing collision rates and improving efficiency.", "motivation": "Enhancing vehicle platoon response to emergencies by optimizing reorganization processes.", "method": "Uses a reinforcement-learning-based platoon distribution model with risk potential fields, coalition-game-based decision-making, and a graph-theory-based Platoon Disposition Index (PDI).", "result": "Reduces collision rates, improves driving efficiency, and decreases reorganization time with PDI.", "conclusion": "The framework effectively enhances platoon reorganization in emergencies, outperforming baseline models."}}
{"id": "2506.16225", "pdf": "https://arxiv.org/pdf/2506.16225", "abs": "https://arxiv.org/abs/2506.16225", "authors": ["Jiale Liu", "Dandan Peng", "Huan Wang", "Chenyu Liu", "Yan-Fu Li", "Min Xie"], "title": "AeroGPT: Leveraging Large-Scale Audio Model for Aero-Engine Bearing Fault Diagnosis", "categories": ["cs.SD", "eess.AS"], "comment": null, "summary": "Aerospace engines, as critical components in aviation and aerospace\nindustries, require continuous and accurate fault diagnosis to ensure\noperational safety and prevent catastrophic failures. While deep learning\ntechniques have been extensively studied in this context, they output logits or\nconfidence scores, necessitating post-processing to derive actionable insights.\nFurthermore, the potential of large-scale audio models in this domain remains\nlargely untapped. To address these limitations, this paper proposes AeroGPT, a\nnovel framework that transfers knowledge from general audio domain to\naero-engine bearing fault diagnosis. AeroGPT is a framework based on\nlarge-scale audio model that incorporates Vibration Signal Alignment (VSA) to\nadapt general audio knowledge to domain-specific vibration patterns, and\ncombines Generative Fault Classification (GFC) to directly output interpretable\nfault labels. This approach eliminates the need for post-processing of fault\nlabels, supports interactive, interpretable, and actionable fault diagnosis,\nthereby greatly enhancing industrial applicability. Through comprehensive\nexperimental validation on two aero-engine bearing datasets, AeroGPT achieved\nexceptional performance with 98.94% accuracy on the DIRG dataset and perfect\n100% classification on the HIT bearing dataset, surpassing traditional deep\nlearning approaches. Additional Qualitative analysis validates the\neffectiveness of our approach and highlights the potential of large-scale\nmodels to revolutionize fault diagnosis.", "AI": {"tldr": "AeroGPT is a novel framework for aero-engine fault diagnosis, leveraging large-scale audio models with Vibration Signal Alignment and Generative Fault Classification to achieve high accuracy and interpretability.", "motivation": "Current deep learning methods require post-processing and lack interpretability, while large-scale audio models' potential in fault diagnosis is unexplored.", "method": "AeroGPT uses Vibration Signal Alignment (VSA) to adapt general audio knowledge to vibration patterns and Generative Fault Classification (GFC) for direct fault label output.", "result": "Achieved 98.94% accuracy on DIRG dataset and 100% on HIT dataset, outperforming traditional methods.", "conclusion": "AeroGPT enhances interpretability and industrial applicability, demonstrating the potential of large-scale models in fault diagnosis."}}
{"id": "2506.16751", "pdf": "https://arxiv.org/pdf/2506.16751", "abs": "https://arxiv.org/abs/2506.16751", "authors": ["Akanksha Singh", "Yi-Ping Phoebe Chen", "Vipul Arora"], "title": "H-QuEST: Accelerating Query-by-Example Spoken Term Detection with Hierarchical Indexing", "categories": ["eess.AS"], "comment": null, "summary": "Query-by-example spoken term detection (QbE-STD) searches for matching words\nor phrases in an audio dataset using a sample spoken query. When annotated data\nis limited or unavailable, QbE-STD is often done using template matching\nmethods like dynamic time warping (DTW), which are computationally expensive\nand do not scale well. To address this, we propose H-QuEST (Hierarchical\nQuery-by-Example Spoken Term Detection), a novel framework that accelerates\nspoken term retrieval by utilizing Term Frequency and Inverse Document\nFrequency (TF-IDF)-based sparse representations obtained through advanced audio\nrepresentation learning techniques and Hierarchical Navigable Small World\n(HNSW) indexing with further refinement. Experimental results show that H-QuEST\ndelivers substantial improvements in retrieval speed without sacrificing\naccuracy compared to existing methods.", "AI": {"tldr": "H-QuEST accelerates spoken term retrieval using TF-IDF and HNSW, improving speed without losing accuracy.", "motivation": "Limited annotated data and inefficiency of traditional methods like DTW in QbE-STD.", "method": "Uses TF-IDF-based sparse representations and HNSW indexing with refinement.", "result": "Significant speed improvements without accuracy loss.", "conclusion": "H-QuEST is an efficient alternative to traditional QbE-STD methods."}}
{"id": "2506.15750", "pdf": "https://arxiv.org/pdf/2506.15750", "abs": "https://arxiv.org/abs/2506.15750", "authors": ["Sanuwani Dayarathna", "Himashi Peiris", "Kh Tohidul Islam", "Tien-Tsin Wong", "Zhaolin Chen"], "title": "D2Diff : A Dual Domain Diffusion Model for Accurate Multi-Contrast MRI Synthesis", "categories": ["eess.IV"], "comment": null, "summary": "Multi contrast MRI synthesis is inherently challenging due to the complex and\nnonlinear relationships among different contrasts. Each MRI contrast highlights\nunique tissue properties, but their complementary information is difficult to\nexploit due to variations in intensity distributions and contrast specific\ntextures. Existing methods for multi contrast MRI synthesis primarily utilize\nspatial domain features, which capture localized anatomical structures but\nstruggle to model global intensity variations and distributed patterns.\nConversely, frequency domain features provide structured inter contrast\ncorrelations but lack spatial precision, limiting their ability to retain finer\ndetails. To address this, we propose a dual domain learning framework that\nintegrates spatial and frequency domain information across multiple MRI\ncontrasts for enhanced synthesis. Our method employs two mutually trained\ndenoising networks, one conditioned on spatial domain and the other on\nfrequency domain contrast features through a shared critic network.\nAdditionally, an uncertainty driven mask loss directs the models focus toward\nmore critical regions, further improving synthesis accuracy. Extensive\nexperiments show that our method outperforms SOTA baselines, and the downstream\nsegmentation performance highlights the diagnostic value of the synthetic\nresults.", "AI": {"tldr": "A dual-domain learning framework integrates spatial and frequency domain features for improved multi-contrast MRI synthesis, outperforming existing methods.", "motivation": "Existing methods struggle to model global intensity variations and retain finer details due to limitations in spatial or frequency domain features alone.", "method": "Proposes a dual-domain framework with two denoising networks (spatial and frequency domains) trained mutually via a shared critic network, using an uncertainty-driven mask loss.", "result": "Outperforms state-of-the-art baselines and improves downstream segmentation performance.", "conclusion": "The dual-domain approach enhances MRI synthesis accuracy, demonstrating diagnostic value."}}
{"id": "2506.15806", "pdf": "https://arxiv.org/pdf/2506.15806", "abs": "https://arxiv.org/abs/2506.15806", "authors": ["Akarshani Ramanayake", "Nihal Kodikara"], "title": "Implicit 3D scene reconstruction using deep learning towards efficient collision understanding in autonomous driving", "categories": ["cs.CV"], "comment": null, "summary": "In crowded urban environments where traffic is dense, current technologies\nstruggle to oversee tight navigation, but surface-level understanding allows\nautonomous vehicles to safely assess proximity to surrounding obstacles. 3D or\n2D scene mapping of the surrounding objects is an essential task in addressing\nthe above problem. Despite its importance in dense vehicle traffic conditions,\n3D scene reconstruction of object shapes with higher boundary level accuracy is\nnot yet entirely considered in current literature. The sign distance function\nrepresents any shape through parameters that calculate the distance from any\npoint in space to the closest obstacle surface, making it more efficient in\nterms of storage. In recent studies, researchers have started to formulate\nproblems with Implicit 3D reconstruction methods in the autonomous driving\ndomain, highlighting the possibility of using sign distance function to map\nobstacles effectively. This research addresses this gap by developing a\nlearning-based 3D scene reconstruction methodology that leverages LiDAR data\nand a deep neural network to build a the static Signed Distance Function (SDF)\nmaps. Unlike traditional polygonal representations, this approach has the\npotential to map 3D obstacle shapes with more boundary-level details. Our\npreliminary results demonstrate that this method would significantly enhance\ncollision detection performance, particularly in congested and dynamic\nenvironments.", "AI": {"tldr": "A learning-based 3D scene reconstruction method using LiDAR and deep neural networks improves boundary-level accuracy in dense urban traffic, enhancing collision detection.", "motivation": "Current technologies lack precise 3D scene reconstruction for autonomous vehicles in dense traffic, especially for boundary-level accuracy.", "method": "Uses LiDAR data and a deep neural network to create static Signed Distance Function (SDF) maps for 3D obstacle shapes.", "result": "Preliminary results show improved collision detection in congested and dynamic environments.", "conclusion": "The proposed SDF-based method offers a more efficient and detailed solution for 3D scene reconstruction in autonomous driving."}}
{"id": "2506.15688", "pdf": "https://arxiv.org/pdf/2506.15688", "abs": "https://arxiv.org/abs/2506.15688", "authors": ["Hui Ma", "Kai Yang", "Man-On Pun"], "title": "Cellular Traffic Prediction via Deep State Space Models with Attention Mechanism", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Cellular traffic prediction is of great importance for operators to manage\nnetwork resources and make decisions. Traffic is highly dynamic and influenced\nby many exogenous factors, which would lead to the degradation of traffic\nprediction accuracy. This paper proposes an end-to-end framework with two\nvariants to explicitly characterize the spatiotemporal patterns of cellular\ntraffic among neighboring cells. It uses convolutional neural networks with an\nattention mechanism to capture the spatial dynamics and Kalman filter for\ntemporal modelling. Besides, we can fully exploit the auxiliary information\nsuch as social activities to improve prediction performance. We conduct\nextensive experiments on three real-world datasets. The results show that our\nproposed models outperform the state-of-the-art machine learning techniques in\nterms of prediction accuracy.", "AI": {"tldr": "Proposes an end-to-end framework for cellular traffic prediction using CNNs with attention and Kalman filters, outperforming state-of-the-art methods.", "motivation": "Cellular traffic is dynamic and affected by exogenous factors, degrading prediction accuracy.", "method": "Uses CNNs with attention for spatial dynamics and Kalman filters for temporal modeling, incorporating auxiliary data like social activities.", "result": "Outperforms state-of-the-art machine learning techniques in accuracy on three real-world datasets.", "conclusion": "The framework effectively captures spatiotemporal patterns and improves prediction performance."}}
{"id": "2506.15735", "pdf": "https://arxiv.org/pdf/2506.15735", "abs": "https://arxiv.org/abs/2506.15735", "authors": ["Robert Graham", "Edward Stevinson", "Leo Richter", "Alexander Chia", "Joseph Miller", "Joseph Isaac Bloom"], "title": "ContextBench: Modifying Contexts for Targeted Latent Activation", "categories": ["cs.AI", "cs.LG", "stat.ML"], "comment": null, "summary": "Identifying inputs that trigger specific behaviours or latent features in\nlanguage models could have a wide range of safety use cases. We investigate a\nclass of methods capable of generating targeted, linguistically fluent inputs\nthat activate specific latent features or elicit model behaviours. We formalise\nthis approach as context modification and present ContextBench -- a benchmark\nwith tasks assessing core method capabilities and potential safety\napplications. Our evaluation framework measures both elicitation strength\n(activation of latent features or behaviours) and linguistic fluency,\nhighlighting how current state-of-the-art methods struggle to balance these\nobjectives. We enhance Evolutionary Prompt Optimisation (EPO) with\nLLM-assistance and diffusion model inpainting, and demonstrate that these\nvariants achieve state-of-the-art performance in balancing elicitation\neffectiveness and fluency.", "AI": {"tldr": "The paper introduces ContextBench, a benchmark for evaluating methods that generate linguistically fluent inputs to trigger specific behaviors or latent features in language models, focusing on safety applications. Enhanced Evolutionary Prompt Optimisation (EPO) with LLM-assistance and diffusion model inpainting achieves state-of-the-art performance.", "motivation": "To identify inputs that activate specific behaviors or latent features in language models for safety applications.", "method": "Formalizes context modification, introduces ContextBench, and enhances Evolutionary Prompt Optimisation (EPO) with LLM-assistance and diffusion model inpainting.", "result": "Enhanced EPO variants achieve state-of-the-art performance in balancing elicitation effectiveness and fluency.", "conclusion": "The approach advances the capability to generate targeted, fluent inputs for safety-critical applications in language models."}}
{"id": "2506.15925", "pdf": "https://arxiv.org/pdf/2506.15925", "abs": "https://arxiv.org/abs/2506.15925", "authors": ["Narutatsu Ri", "Nicholas Deas", "Kathleen McKeown"], "title": "Reranking-based Generation for Unbiased Perspective Summarization", "categories": ["cs.CL"], "comment": "ACL 2025 Findings", "summary": "Generating unbiased summaries in real-world settings such as political\nperspective summarization remains a crucial application of Large Language\nModels (LLMs). Yet, existing evaluation frameworks rely on traditional metrics\nfor measuring key attributes such as coverage and faithfulness without\nverifying their applicability, and efforts to develop improved summarizers are\nstill nascent. We address these gaps by (1) identifying reliable metrics for\nmeasuring perspective summary quality, and (2) investigating the efficacy of\nLLM-based methods beyond zero-shot inference. Namely, we build a test set for\nbenchmarking metric reliability using human annotations and show that\ntraditional metrics underperform compared to language model-based metrics,\nwhich prove to be strong evaluators. Using these metrics, we show that\nreranking-based methods yield strong results, and preference tuning with\nsynthetically generated and reranking-labeled data further boosts performance.\nOur findings aim to contribute to the reliable evaluation and development of\nperspective summarization methods.", "AI": {"tldr": "The paper addresses gaps in evaluating and improving unbiased summaries in political perspective summarization using LLMs, proposing reliable metrics and demonstrating the effectiveness of reranking and preference tuning methods.", "motivation": "Existing evaluation frameworks for unbiased summaries in political perspective summarization lack reliable metrics, and improved summarization methods are underdeveloped.", "method": "The study identifies reliable metrics using human annotations, compares traditional and language model-based metrics, and evaluates reranking and preference tuning methods with synthetic data.", "result": "Language model-based metrics outperform traditional ones, and reranking-based methods with preference tuning show improved performance.", "conclusion": "The findings contribute to better evaluation and development of perspective summarization methods, emphasizing the effectiveness of advanced LLM-based techniques."}}
{"id": "2506.17016", "pdf": "https://arxiv.org/pdf/2506.17016", "abs": "https://arxiv.org/abs/2506.17016", "authors": ["Giulia Bertazzini", "Chiara Albisani", "Daniele Baracchi", "Dasara Shullani", "Roberto Verdecchia"], "title": "The Hidden Cost of an Image: Quantifying the Energy Consumption of AI Image Generation", "categories": ["cs.LG", "cs.MM"], "comment": null, "summary": "With the growing adoption of AI image generation, in conjunction with the\never-increasing environmental resources demanded by AI, we are urged to answer\na fundamental question: What is the environmental impact hidden behind each\nimage we generate? In this research, we present a comprehensive empirical\nexperiment designed to assess the energy consumption of AI image generation.\nOur experiment compares 17 state-of-the-art image generation models by\nconsidering multiple factors that could affect their energy consumption, such\nas model quantization, image resolution, and prompt length. Additionally, we\nconsider established image quality metrics to study potential trade-offs\nbetween energy consumption and generated image quality. Results show that image\ngeneration models vary drastically in terms of the energy they consume, with up\nto a 46x difference. Image resolution affects energy consumption\ninconsistently, ranging from a 1.3x to 4.7x increase when doubling resolution.\nU-Net-based models tend to consume less than Transformer-based one. Model\nquantization instead results to deteriorate the energy efficiency of most\nmodels, while prompt length and content have no statistically significant\nimpact. Improving image quality does not always come at the cost of a higher\nenergy consumption, with some of the models producing the highest quality\nimages also being among the most energy efficient ones.", "AI": {"tldr": "The paper investigates the environmental impact of AI image generation by comparing energy consumption across 17 models, analyzing factors like resolution, quantization, and prompt length, and assessing trade-offs with image quality.", "motivation": "The study aims to quantify the hidden environmental costs of AI image generation, addressing concerns about the growing resource demands of AI technologies.", "method": "A comprehensive empirical experiment compares 17 state-of-the-art image generation models, evaluating energy consumption based on factors like model quantization, image resolution, and prompt length, alongside image quality metrics.", "result": "Energy consumption varies significantly (up to 46x) among models. Resolution inconsistently affects energy (1.3x\u20134.7x increase when doubled). U-Net models are more efficient than Transformer-based ones. Quantization reduces efficiency, while prompt length has no significant impact. High-quality images don't always require more energy.", "conclusion": "The findings highlight the need for energy-efficient AI image generation, as some high-quality models are also energy-efficient, and factors like resolution and model architecture significantly impact environmental costs."}}
{"id": "2506.16718", "pdf": "https://arxiv.org/pdf/2506.16718", "abs": "https://arxiv.org/abs/2506.16718", "authors": ["Chenxu Wang", "Yonggang Jin", "Cheng Hu", "Youpeng Zhao", "Zipeng Dai", "Jian Zhao", "Shiyu Huang", "Liuyu Xiang", "Junge Zhang", "Zhaofeng He"], "title": "Generalizable Agent Modeling for Agent Collaboration-Competition Adaptation with Multi-Retrieval and Dynamic Generation", "categories": ["cs.MA", "cs.AI"], "comment": "This manuscript is under submission to Neurocomputing", "summary": "Adapting a single agent to a new multi-agent system brings challenges,\nnecessitating adjustments across various tasks, environments, and interactions\nwith unknown teammates and opponents. Addressing this challenge is highly\ncomplex, and researchers have proposed two simplified scenarios, Multi-agent\nreinforcement learning for zero-shot learning and Ad-Hoc Teamwork. Building on\nthese foundations, we propose a more comprehensive setting, Agent\nCollaborative-Competitive Adaptation (ACCA), which evaluates an agent to\ngeneralize across diverse scenarios, tasks, and interactions with both\nunfamiliar opponents and teammates. In ACCA, agents adjust to task and\nenvironmental changes, collaborate with unseen teammates, and compete against\nunknown opponents. We introduce a new modeling approach, Multi-Retrieval and\nDynamic Generation (MRDG), that effectively models both teammates and opponents\nusing their behavioral trajectories. This method incorporates a positional\nencoder for varying team sizes and a hypernetwork module to boost agents'\nlearning and adaptive capabilities. Additionally, a viewpoint alignment module\nharmonizes the observational perspectives of retrieved teammates and opponents\nwith the learning agent. Extensive tests in benchmark scenarios like SMAC,\nOvercooked-AI, and Melting Pot show that MRDG significantly improves robust\ncollaboration and competition with unseen teammates and opponents, surpassing\nestablished baselines. Our code is available at:\nhttps://github.com/vcis-wangchenxu/MRDG.git", "AI": {"tldr": "The paper introduces ACCA, a comprehensive setting for evaluating agent adaptation in multi-agent systems, and proposes MRDG, a method to model teammates and opponents effectively.", "motivation": "Addressing the complexity of adapting agents to new multi-agent systems with diverse tasks, environments, and unknown teammates/opponents.", "method": "Proposes Multi-Retrieval and Dynamic Generation (MRDG) with positional encoders, hypernetwork modules, and viewpoint alignment.", "result": "MRDG outperforms baselines in benchmark scenarios (SMAC, Overcooked-AI, Melting Pot) for robust collaboration and competition.", "conclusion": "MRDG enhances agent adaptability in diverse multi-agent settings, demonstrating superior performance."}}
{"id": "2506.16538", "pdf": "https://arxiv.org/pdf/2506.16538", "abs": "https://arxiv.org/abs/2506.16538", "authors": ["Yunkee Chae", "Kyogu Lee"], "title": "Towards Bitrate-Efficient and Noise-Robust Speech Coding with Variable Bitrate RVQ", "categories": ["cs.SD", "eess.AS"], "comment": "Accepted to Interspeech 2025", "summary": "Residual Vector Quantization (RVQ) has become a dominant approach in neural\nspeech and audio coding, providing high-fidelity compression. However, speech\ncoding presents additional challenges due to real-world noise, which degrades\ncompression efficiency. Standard codecs allocate bits uniformly, wasting\nbitrate on noise components that do not contribute to intelligibility. This\npaper introduces a Variable Bitrate RVQ (VRVQ) framework for noise-robust\nspeech coding, dynamically adjusting bitrate per frame to optimize\nrate-distortion trade-offs. Unlike constant bitrate (CBR) RVQ, our method\nprioritizes critical speech components while suppressing residual noise.\nAdditionally, we integrate a feature denoiser to further improve noise\nrobustness. Experimental results show that VRVQ improves rate-distortion\ntrade-offs over conventional methods, achieving better compression efficiency\nand perceptual quality in noisy conditions. Samples are available at our\nproject page: https://yoongi43.github.io/noise_robust_vrvq/.", "AI": {"tldr": "VRVQ improves speech coding by dynamically adjusting bitrate per frame, optimizing rate-distortion trade-offs and enhancing noise robustness.", "motivation": "Standard codecs waste bitrate on noise components, degrading compression efficiency in noisy speech.", "method": "Introduces Variable Bitrate RVQ (VRVQ) with dynamic bitrate adjustment and a feature denoiser.", "result": "VRVQ outperforms conventional methods in rate-distortion trade-offs and perceptual quality under noise.", "conclusion": "VRVQ is a noise-robust solution for high-fidelity speech coding, improving efficiency and quality."}}
{"id": "2506.16969", "pdf": "https://arxiv.org/pdf/2506.16969", "abs": "https://arxiv.org/abs/2506.16969", "authors": ["Aref Farhadipour", "Homayoon Beigi", "Volker Dellwo", "Hadi Veisi"], "title": "State-Space Models in Efficient Whispered and Multi-dialect Speech Recognition", "categories": ["eess.AS", "cs.SD"], "comment": "paper is in 4+1 pages", "summary": "Whispered speech recognition presents significant challenges for conventional\nautomatic speech recognition systems, particularly when combined with dialect\nvariation. However, utilizing an efficient method to solve this problem using a\nlow-range dataset and processing load is beneficial. This paper proposes a\nsolution using a Mamba-based state-space model and four fine-tuned\nself-supervised models consisting of Wav2Vec2, WavLM, HuBERT, and Whisper to\naddress the dual challenges of whispered speech and dialect diversity. Based on\nour knowledge, this represents the best performance reported on the wTIMIT and\nCHAINS datasets for whispered speech recognition. We trained the models using\nwhispered and normal speech data across Singaporean, US, and Irish dialects.\nThe findings demonstrated that utilizing the proposed Mamba-based model could\nwork as a highly efficient model trained with low amounts of whispered data to\nsimultaneously work on whispered and normal speech recognition. The code for\nthis work is freely available.", "AI": {"tldr": "Proposes a Mamba-based state-space model and fine-tuned self-supervised models (Wav2Vec2, WavLM, HuBERT, Whisper) for whispered speech recognition across dialects, achieving top performance on wTIMIT and CHAINS datasets.", "motivation": "Address challenges of whispered speech recognition combined with dialect variation using a low-range dataset and processing load.", "method": "Uses a Mamba-based state-space model and four fine-tuned self-supervised models (Wav2Vec2, WavLM, HuBERT, Whisper) trained on whispered and normal speech data across Singaporean, US, and Irish dialects.", "result": "Achieves best performance on wTIMIT and CHAINS datasets, demonstrating efficiency with low whispered data.", "conclusion": "The Mamba-based model is highly efficient for simultaneous whispered and normal speech recognition, with publicly available code."}}
{"id": "2506.15762", "pdf": "https://arxiv.org/pdf/2506.15762", "abs": "https://arxiv.org/abs/2506.15762", "authors": ["Tom Hendriks", "Gerrit Arends", "Edwin Versteeg", "Anna Vilanova", "Maxime Chamberland", "Chantal M. W. Tax"], "title": "Implicit neural representations for accurate estimation of the standard model of white matter", "categories": ["eess.IV", "cs.LG", "physics.med-ph"], "comment": "27 pages, 12 figures", "summary": "Diffusion magnetic resonance imaging (dMRI) enables non-invasive\ninvestigation of tissue microstructure. The Standard Model (SM) of white matter\naims to disentangle dMRI signal contributions from intra- and extra-axonal\nwater compartments. However, due to the model its high-dimensional nature,\nextensive acquisition protocols with multiple b-values and diffusion tensor\nshapes are typically required to mitigate parameter degeneracies. Even then,\naccurate estimation remains challenging due to noise. This work introduces a\nnovel estimation framework based on implicit neural representations (INRs),\nwhich incorporate spatial regularization through the sinusoidal encoding of the\ninput coordinates. The INR method is evaluated on both synthetic and in vivo\ndatasets and compared to parameter estimates using cubic polynomials,\nsupervised neural networks, and nonlinear least squares. Results demonstrate\nsuperior accuracy of the INR method in estimating SM parameters, particularly\nin low signal-to-noise conditions. Additionally, spatial upsampling of the INR\ncan represent the underlying dataset anatomically plausibly in a continuous\nway, which is unattainable with linear or cubic interpolation. The INR is fully\nunsupervised, eliminating the need for labeled training data. It achieves fast\ninference ($\\sim$6 minutes), is robust to both Gaussian and Rician noise,\nsupports joint estimation of SM kernel parameters and the fiber orientation\ndistribution function with spherical harmonics orders up to at least 8 and\nnon-negativity constraints, and accommodates spatially varying acquisition\nprotocols caused by magnetic gradient non-uniformities. The combination of\nthese properties along with the possibility to easily adapt the framework to\nother dMRI models, positions INRs as a potentially important tool for analyzing\nand interpreting diffusion MRI data.", "AI": {"tldr": "The paper introduces an implicit neural representation (INR) framework for estimating Standard Model (SM) parameters in dMRI, outperforming existing methods in accuracy, noise robustness, and spatial upsampling.", "motivation": "The Standard Model (SM) for dMRI faces challenges like parameter degeneracies and noise sensitivity, requiring extensive protocols. This work aims to improve estimation accuracy and robustness.", "method": "The proposed method uses implicit neural representations (INRs) with spatial regularization via sinusoidal encoding of coordinates, evaluated on synthetic and in vivo data against cubic polynomials, neural networks, and nonlinear least squares.", "result": "INRs show superior accuracy in SM parameter estimation, especially in low signal-to-noise conditions, and enable continuous spatial upsampling. The method is unsupervised, fast, and adaptable to varying protocols.", "conclusion": "INRs are a promising tool for dMRI analysis, offering accuracy, robustness, and flexibility for interpreting diffusion MRI data."}}
{"id": "2506.15837", "pdf": "https://arxiv.org/pdf/2506.15837", "abs": "https://arxiv.org/abs/2506.15837", "authors": ["Fatmah AlHindaassi", "Mohammed Talha Alam", "Fakhri Karray"], "title": "ADAM-Dehaze: Adaptive Density-Aware Multi-Stage Dehazing for Improved Object Detection in Foggy Conditions", "categories": ["cs.CV"], "comment": "Under-review at IEEE SMC 2025", "summary": "Adverse weather conditions, particularly fog, pose a significant challenge to\nautonomous vehicles, surveillance systems, and other safety-critical\napplications by severely degrading visual information. We introduce\nADAM-Dehaze, an adaptive, density-aware dehazing framework that jointly\noptimizes image restoration and object detection under varying fog intensities.\nA lightweight Haze Density Estimation Network (HDEN) classifies each input as\nlight, medium, or heavy fog. Based on this score, the system dynamically routes\nthe image through one of three CORUN branches: Light, Medium, or Complex, each\ntailored to its haze regime. A novel adaptive loss balances physical-model\ncoherence and perceptual fidelity, ensuring both accurate defogging and\npreservation of fine details. On Cityscapes and the real-world RTTS benchmark,\nADAM-Dehaze improves PSNR by up to 2.1 dB, reduces FADE by 30 percent, and\nincreases object detection mAP by up to 13 points, while cutting inference time\nby 20 percent. These results highlight the importance of intensity-specific\nprocessing and seamless integration with downstream vision tasks. Code\navailable at: https://github.com/talha-alam/ADAM-Dehaze.", "AI": {"tldr": "ADAM-Dehaze is an adaptive dehazing framework that improves image restoration and object detection under varying fog intensities, outperforming benchmarks in PSNR, FADE, and mAP while reducing inference time.", "motivation": "Fog degrades visual information for autonomous vehicles and surveillance systems, necessitating adaptive solutions for varying fog intensities.", "method": "Uses a Haze Density Estimation Network (HDEN) to classify fog intensity and routes images through tailored CORUN branches (Light, Medium, Complex). Introduces an adaptive loss for balance between physical-model coherence and perceptual fidelity.", "result": "Improves PSNR by 2.1 dB, reduces FADE by 30%, increases mAP by 13 points, and cuts inference time by 20% on Cityscapes and RTTS benchmarks.", "conclusion": "ADAM-Dehaze demonstrates the effectiveness of intensity-specific processing and integration with downstream vision tasks."}}
{"id": "2506.15689", "pdf": "https://arxiv.org/pdf/2506.15689", "abs": "https://arxiv.org/abs/2506.15689", "authors": ["Liulu He", "Shenli Zhen", "Karwei Sun", "Yijiang Liu", "Yufei Zhao", "Chongkang Tan", "Huanrui Yang", "Yuan Du", "Li Du"], "title": "BASE-Q: Bias and Asymmetric Scaling Enhanced Rotational Quantization for Large Language Models", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": null, "summary": "Rotations have become essential to state-of-the-art quantization pipelines\nfor large language models (LLMs) by effectively smoothing outliers in weights\nand activations. However, further optimizing the rotation parameters offers\nonly limited performance gains and introduces significant training overhead:\ndue to rotation parameter sharing, full-model must be loaded simultaneously to\nenable backpropagation, resulting in substantial memory consumption and limited\npractical utility. In this work, we identify two fundamental limitations of\ncurrent rotational quantization methods: (i) rotation fails to align channel\nmeans, resulting in wider quantization bounds and increased rounding errors;\nand (ii) rotation makes the activation distribution more Gaussian-like,\nincreasing energy loss caused by clipping errors. To address these issues, we\nintroduce \\textbf{BASE-Q}, a simple yet powerful approach that combines bias\ncorrection and asymmetric scaling to effectively reduce rounding and clipping\nerrors. Furthermore, BASE-Q enables blockwise optimization, eliminating the\nneed for memory-intensive full-model backpropagation. Extensive experiments on\nvarious LLMs and benchmarks demonstrate the effectiveness of BASE-Q, narrowing\nthe accuracy gap to full-precision models by 50.5\\%, 42.9\\%, and 29.2\\%\ncompared to QuaRot, SpinQuant, and OSTQuant, respectively. The code will be\nreleased soon.", "AI": {"tldr": "The paper introduces BASE-Q, a method combining bias correction and asymmetric scaling to reduce errors in rotational quantization for LLMs, enabling blockwise optimization and outperforming existing methods.", "motivation": "Current rotational quantization methods for LLMs have limitations: they fail to align channel means, increasing rounding errors, and make activation distributions more Gaussian-like, causing clipping errors.", "method": "BASE-Q combines bias correction and asymmetric scaling to address rounding and clipping errors, and enables blockwise optimization to reduce memory overhead.", "result": "BASE-Q reduces the accuracy gap to full-precision models by 50.5%, 42.9%, and 29.2% compared to QuaRot, SpinQuant, and OSTQuant, respectively.", "conclusion": "BASE-Q is a simple yet effective solution for improving rotational quantization in LLMs, offering significant performance gains and practical utility."}}
{"id": "2506.15740", "pdf": "https://arxiv.org/pdf/2506.15740", "abs": "https://arxiv.org/abs/2506.15740", "authors": ["Jonathan Kutasov", "Yuqi Sun", "Paul Colognese", "Teun van der Weij", "Linda Petrini", "Chen Bo Calvin Zhang", "John Hughes", "Xiang Deng", "Henry Sleight", "Tyler Tracy", "Buck Shlegeris", "Joe Benton"], "title": "SHADE-Arena: Evaluating Sabotage and Monitoring in LLM Agents", "categories": ["cs.AI", "cs.CR", "cs.LG"], "comment": null, "summary": "As Large Language Models (LLMs) are increasingly deployed as autonomous\nagents in complex and long horizon settings, it is critical to evaluate their\nability to sabotage users by pursuing hidden objectives. We study the ability\nof frontier LLMs to evade monitoring and achieve harmful hidden goals while\ncompleting a wide array of realistic tasks. We evaluate a broad range of\nfrontier LLMs using SHADE (Subtle Harmful Agent Detection & Evaluation)-Arena,\nthe first highly diverse agent evaluation dataset for sabotage and monitoring\ncapabilities of LLM agents. SHADE-Arena consists of complex pairs of benign\nmain tasks and harmful side objectives in complicated environments. Agents are\nevaluated on their ability to complete the side task without appearing\nsuspicious to an LLM monitor. When measuring agent ability to (a) complete the\nmain task, (b) complete the side task, and (c) avoid detection, we find that\nthe best performing frontier models score 27% (Claude 3.7 Sonnet) and 15%\n(Gemini 2.5 Pro) as sabotage agents when overseen by Claude 3.6 Sonnet. For\ncurrent frontier models, success on the side task relies heavily on having\naccess to a hidden scratchpad that is not visible to the monitor. We also use\nSHADE-Arena to measure models' monitoring abilities, with the top monitor\n(Gemini 2.5 Pro) achieving an AUC of 0.87 at distinguishing benign and malign\ntranscripts. We find that for now, models still struggle at sabotage due to\nfailures in long-context main task execution. However, our measurements already\ndemonstrate the difficulty of monitoring for subtle sabotage attempts, which we\nexpect to only increase in the face of more complex and longer-horizon tasks.", "AI": {"tldr": "The paper evaluates LLMs' ability to pursue hidden harmful objectives while completing tasks, using SHADE-Arena for testing. Top models show limited sabotage success, with monitoring proving challenging.", "motivation": "To assess the risks of LLMs acting as autonomous agents with hidden harmful goals, especially in complex, long-horizon tasks.", "method": "Uses SHADE-Arena, a diverse dataset with benign main tasks and harmful side objectives, to test LLMs' sabotage and monitoring capabilities.", "result": "Best models (Claude 3.7 Sonnet, Gemini 2.5 Pro) achieved 27% and 15% sabotage success, respectively. Monitoring was difficult, with top monitor (Gemini 2.5 Pro) achieving AUC 0.87.", "conclusion": "Current LLMs struggle with sabotage due to execution flaws, but monitoring subtle sabotage is already challenging and will worsen with more complex tasks."}}
{"id": "2506.15978", "pdf": "https://arxiv.org/pdf/2506.15978", "abs": "https://arxiv.org/abs/2506.15978", "authors": ["Toan Nguyen Hai", "Ha Nguyen Viet", "Truong Quan Xuan", "Duc Do Minh"], "title": "A Vietnamese Dataset for Text Segmentation and Multiple Choices Reading Comprehension", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Vietnamese, the 20th most spoken language with over 102 million native\nspeakers, lacks robust resources for key natural language processing tasks such\nas text segmentation and machine reading comprehension (MRC). To address this\ngap, we present VSMRC, the Vietnamese Text Segmentation and Multiple-Choice\nReading Comprehension Dataset. Sourced from Vietnamese Wikipedia, our dataset\nincludes 15,942 documents for text segmentation and 16,347 synthetic\nmultiple-choice question-answer pairs generated with human quality assurance,\nensuring a reliable and diverse resource. Experiments show that mBERT\nconsistently outperforms monolingual models on both tasks, achieving an\naccuracy of 88.01% on MRC test set and an F1 score of 63.15\\% on text\nsegmentation test set. Our analysis reveals that multilingual models excel in\nNLP tasks for Vietnamese, suggesting potential applications to other\nunder-resourced languages. VSMRC is available at HuggingFace", "AI": {"tldr": "VSMRC is a dataset for Vietnamese text segmentation and MRC, sourced from Wikipedia, with experiments showing mBERT outperforms monolingual models.", "motivation": "Vietnamese lacks robust NLP resources, prompting the creation of VSMRC to address this gap.", "method": "The dataset includes 15,942 documents for segmentation and 16,347 synthetic QA pairs, with human quality assurance.", "result": "mBERT achieved 88.01% accuracy on MRC and 63.15% F1 on segmentation, outperforming monolingual models.", "conclusion": "Multilingual models like mBERT excel in Vietnamese NLP, suggesting broader applications for under-resourced languages."}}
{"id": "2503.09149", "pdf": "https://arxiv.org/pdf/2503.09149", "abs": "https://arxiv.org/abs/2503.09149", "authors": ["Huaying Yuan", "Zheng Liu", "Minghao Qin", "Hongjin Qian", "Yan Shu", "Zhicheng Dou", "Ji-Rong Wen", "Nicu Sebe"], "title": "Memory-enhanced Retrieval Augmentation for Long Video Understanding", "categories": ["cs.CV", "cs.MM"], "comment": null, "summary": "Efficient long-video understanding~(LVU) remains a challenging task in\ncomputer vision. Current long-context vision-language models~(LVLMs) suffer\nfrom information loss due to compression and brute-force downsampling. While\nretrieval-augmented generation (RAG) methods mitigate this issue, their\napplicability is limited due to explicit query dependency. To overcome this\nchallenge, we introduce a novel memory-enhanced RAG-based approach called\nMemVid, which is inspired by the cognitive memory of human beings. Our approach\noperates in four basic steps: 1) memorizing holistic video information, 2)\nreasoning about the task's information needs based on memory, 3) retrieving\ncritical moments based on the information needs, and 4) focusing on the\nretrieved moments to produce the final answer. To enhance the system's\nmemory-grounded reasoning capabilities while achieving optimal end-to-end\nperformance, we propose a curriculum learning strategy. This approach begins\nwith supervised learning on well-annotated reasoning results, then\nprogressively explores and reinforces more plausible reasoning outcomes through\nreinforcement learning. We perform extensive evaluations on popular LVU\nbenchmarks, including MLVU, VideoMME and LVBench. In our experiments, MemVid\ndemonstrates superior efficiency and effectiveness compared to both LVLMs and\nRAG methods.", "AI": {"tldr": "MemVid, a memory-enhanced RAG-based approach, improves long-video understanding by mimicking human cognitive memory, outperforming existing methods.", "motivation": "Current LVLMs lose information due to compression, and RAG methods are limited by query dependency. MemVid addresses these issues.", "method": "MemVid memorizes video info, reasons about task needs, retrieves critical moments, and focuses on them. It uses curriculum learning (supervised + reinforcement learning).", "result": "MemVid outperforms LVLMs and RAG methods on benchmarks like MLVU, VideoMME, and LVBench.", "conclusion": "MemVid offers an efficient and effective solution for long-video understanding by leveraging memory and curriculum learning."}}
{"id": "2506.16836", "pdf": "https://arxiv.org/pdf/2506.16836", "abs": "https://arxiv.org/abs/2506.16836", "authors": ["Arpitha Srivathsa Malavalli", "Karthik Sama", "Janvi Chhabra", "Pooja Bassin", "Srinath Srinivasa"], "title": "Engineering Resilience: An Energy-Based Approach to Sustainable Behavioural Interventions", "categories": ["cs.MA"], "comment": null, "summary": "Addressing complex societal challenges, such as improving public health,\nfostering honesty in workplaces, or encouraging eco-friendly behaviour requires\neffective nudges to influence human behaviour at scale. Intervention science\nseeks to design such nudges within complex societal systems. While\ninterventions primarily aim to shift the system toward a desired state, less\nattention is given to the sustainability of that state, which we define in\nterms of resilience: the system's ability to retain the desired state even\nunder perturbations. In this work, we offer a more holistic perspective to\nintervention design by incorporating a nature-inspired postulate i.e., lower\nenergy states tend to exhibit greater resilience, as a regularization mechanism\nwithin intervention optimization to ensure that the resulting state is also\nsustainable. Using a simple agent-based simulation where commuters are nudged\nto choose eco-friendly options (e.g., cycles) over individually attractive but\nless eco-friendly ones (e.g., cars), we demonstrate how embedding lower energy\npostulate into intervention design induces resilience. The system energy is\ndefined in terms of motivators that drive its agent's behaviour. By inherently\nensuring that agents are not pushed into actions that contradict their\nmotivators, the energy-based approach helps design effective interventions that\ncontribute to resilient behavioural states.", "AI": {"tldr": "The paper proposes a nature-inspired approach to design sustainable behavioral interventions by incorporating resilience, ensuring long-term effectiveness in societal systems.", "motivation": "To address the lack of focus on sustainability in behavioral interventions, aiming for resilient outcomes in complex societal challenges like public health and eco-friendly behavior.", "method": "Uses a nature-inspired postulate (lower energy states = greater resilience) as a regularization mechanism in intervention optimization, tested via an agent-based simulation of commuter choices.", "result": "The energy-based approach ensures interventions align with agents' motivators, leading to resilient behavioral states, demonstrated in the simulation.", "conclusion": "Incorporating resilience into intervention design through energy-based principles enhances sustainability and long-term effectiveness of behavioral nudges."}}
{"id": "2506.16729", "pdf": "https://arxiv.org/pdf/2506.16729", "abs": "https://arxiv.org/abs/2506.16729", "authors": ["Shoichi Koyama", "Kenji Ishizuka"], "title": "Learning Magnitude Distribution of Sound Fields via Conditioned Autoencoder", "categories": ["cs.SD", "eess.AS"], "comment": "To appear in Forum Acusticum 2025", "summary": "A learning-based method for estimating the magnitude distribution of sound\nfields from spatially sparse measurements is proposed. Estimating the magnitude\ndistribution of acoustic transfer function (ATF) is useful when phase\nmeasurements are unreliable or inaccessible and has a wide range of\napplications related to spatial audio. We propose a neural-network-based method\nfor the ATF magnitude estimation. The key feature of our network architecture\nis the input and output layers conditioned on source and receiver positions and\nfrequency and the aggregation module of latent variables, which can be\ninterpreted as an autoencoder-based extension of the basis expansion of the\nsound field. Numerical simulation results indicated that the ATF magnitude is\naccurately estimated with a small number of receivers by our proposed method.", "AI": {"tldr": "A neural-network-based method estimates sound field magnitude distributions from sparse measurements, useful when phase data is unreliable.", "motivation": "Estimating acoustic transfer function (ATF) magnitude is valuable for spatial audio applications where phase measurements are unreliable or unavailable.", "method": "Proposes a neural network with input/output layers conditioned on source/receiver positions and frequency, plus an aggregation module for latent variables, resembling an autoencoder-based sound field expansion.", "result": "Numerical simulations show accurate ATF magnitude estimation with few receivers.", "conclusion": "The method effectively estimates ATF magnitude from sparse measurements, enhancing spatial audio applications."}}
{"id": "2506.15912", "pdf": "https://arxiv.org/pdf/2506.15912", "abs": "https://arxiv.org/abs/2506.15912", "authors": ["Zifei Xu", "Sayeh Sharify", "Hesham Mostafa", "Tristan Webb", "Wanzin Yazar", "Xin Wang"], "title": "Early Attentive Sparsification Accelerates Neural Speech Transcription", "categories": ["cs.LG", "cs.CL", "cs.SD", "eess.AS"], "comment": null, "summary": "Transformer-based neural speech processing has achieved state-of-the-art\nperformance. Since speech audio signals are known to be highly compressible,\nhere we seek to accelerate neural speech transcription by time-domain signal\nsparsification early in the neural encoding stage, taking advantage of the\ninterpretability of the self-attention mechanism in transformer audio encoders.\nWith the Whisper family of models, we perform a systematic architecture search\nover the joint space of sparsification stage (a certain encoder layer) and\ncompression ratio (sparsity). We found that the best resulting solutions under\n1% accuracy degradation choose to sparsify the hidden state to 40-60% sparsity\nat an early encoding stage, and thereby achieve up to 1.6x runtime acceleration\nin English speech transcription tasks on Nvidia GPUs without any fine-tuning.", "AI": {"tldr": "The paper explores accelerating neural speech transcription by sparsifying time-domain signals early in transformer encoders, achieving up to 1.6x speedup with minimal accuracy loss.", "motivation": "Speech signals are highly compressible, and leveraging transformer self-attention interpretability can optimize neural encoding efficiency.", "method": "A systematic search over sparsification stages and compression ratios in Whisper models, targeting early encoder layers.", "result": "Optimal solutions sparsify hidden states to 40-60% at early stages, yielding 1.6x speedup with <1% accuracy drop.", "conclusion": "Early-stage sparsification in transformer encoders effectively accelerates speech transcription without fine-tuning."}}
{"id": "2506.15835", "pdf": "https://arxiv.org/pdf/2506.15835", "abs": "https://arxiv.org/abs/2506.15835", "authors": ["Mingyuan Luo", "Xin Yang", "Zhongnuo Yan", "Yan Cao", "Yuanji Zhang", "Xindi Hu", "Jin Wang", "Haoxuan Ding", "Wei Han", "Litao Sun", "Dong Ni"], "title": "MoNetV2: Enhanced Motion Network for Freehand 3D Ultrasound Reconstruction", "categories": ["eess.IV", "cs.AI", "cs.CV"], "comment": null, "summary": "Three-dimensional (3D) ultrasound (US) aims to provide sonographers with the\nspatial relationships of anatomical structures, playing a crucial role in\nclinical diagnosis. Recently, deep-learning-based freehand 3D US has made\nsignificant advancements. It reconstructs volumes by estimating transformations\nbetween images without external tracking. However, image-only reconstruction\nposes difficulties in reducing cumulative drift and further improving\nreconstruction accuracy, particularly in scenarios involving complex motion\ntrajectories. In this context, we propose an enhanced motion network (MoNetV2)\nto enhance the accuracy and generalizability of reconstruction under diverse\nscanning velocities and tactics. First, we propose a sensor-based temporal and\nmulti-branch structure that fuses image and motion information from a velocity\nperspective to improve image-only reconstruction accuracy. Second, we devise an\nonline multi-level consistency constraint that exploits the inherent\nconsistency of scans to handle various scanning velocities and tactics. This\nconstraint exploits both scan-level velocity consistency, path-level appearance\nconsistency, and patch-level motion consistency to supervise inter-frame\ntransformation estimation. Third, we distill an online multi-modal\nself-supervised strategy that leverages the correlation between network\nestimation and motion information to further reduce cumulative errors.\nExtensive experiments clearly demonstrate that MoNetV2 surpasses existing\nmethods in both reconstruction quality and generalizability performance across\nthree large datasets.", "AI": {"tldr": "MoNetV2 improves 3D ultrasound reconstruction by fusing image and motion data, using multi-level consistency constraints and self-supervised strategies to reduce errors and enhance accuracy.", "motivation": "Existing deep-learning-based freehand 3D ultrasound methods struggle with cumulative drift and accuracy, especially in complex motion scenarios.", "method": "Proposes MoNetV2 with a sensor-based temporal and multi-branch structure, online multi-level consistency constraints, and a self-supervised strategy to fuse image and motion data.", "result": "Outperforms existing methods in reconstruction quality and generalizability across three large datasets.", "conclusion": "MoNetV2 effectively addresses challenges in 3D ultrasound reconstruction, improving accuracy and adaptability to diverse scanning conditions."}}
{"id": "2506.15838", "pdf": "https://arxiv.org/pdf/2506.15838", "abs": "https://arxiv.org/abs/2506.15838", "authors": ["Jiahao Wang", "Hualian Sheng", "Sijia Cai", "Weizhan Zhang", "Caixia Yan", "Yachuang Feng", "Bing Deng", "Jieping Ye"], "title": "EchoShot: Multi-Shot Portrait Video Generation", "categories": ["cs.CV"], "comment": null, "summary": "Video diffusion models substantially boost the productivity of artistic\nworkflows with high-quality portrait video generative capacity. However,\nprevailing pipelines are primarily constrained to single-shot creation, while\nreal-world applications urge for multiple shots with identity consistency and\nflexible content controllability. In this work, we propose EchoShot, a native\nand scalable multi-shot framework for portrait customization built upon a\nfoundation video diffusion model. To start with, we propose shot-aware position\nembedding mechanisms within video diffusion transformer architecture to model\ninter-shot variations and establish intricate correspondence between multi-shot\nvisual content and their textual descriptions. This simple yet effective design\nenables direct training on multi-shot video data without introducing additional\ncomputational overhead. To facilitate model training within multi-shot\nscenario, we construct PortraitGala, a large-scale and high-fidelity\nhuman-centric video dataset featuring cross-shot identity consistency and\nfine-grained captions such as facial attributes, outfits, and dynamic motions.\nTo further enhance applicability, we extend EchoShot to perform reference\nimage-based personalized multi-shot generation and long video synthesis with\ninfinite shot counts. Extensive evaluations demonstrate that EchoShot achieves\nsuperior identity consistency as well as attribute-level controllability in\nmulti-shot portrait video generation. Notably, the proposed framework\ndemonstrates potential as a foundational paradigm for general multi-shot video\nmodeling.", "AI": {"tldr": "EchoShot is a multi-shot framework for portrait video generation, enhancing identity consistency and content control without extra computational cost.", "motivation": "Real-world applications require multi-shot video generation with identity consistency and flexible control, which existing single-shot pipelines lack.", "method": "Proposes shot-aware position embedding in video diffusion transformers and trains on the PortraitGala dataset for multi-shot scenarios. Also extends to reference-based generation and long video synthesis.", "result": "Achieves superior identity consistency and attribute-level controllability in multi-shot portrait video generation.", "conclusion": "EchoShot is a scalable and effective foundational paradigm for multi-shot video modeling."}}
{"id": "2506.15690", "pdf": "https://arxiv.org/pdf/2506.15690", "abs": "https://arxiv.org/abs/2506.15690", "authors": ["Tianyu Wang", "Lingyou Pang", "Akira Horiguchi", "Carey E. Priebe"], "title": "LLM Web Dynamics: Tracing Model Collapse in a Network of LLMs", "categories": ["cs.LG", "cs.AI", "cs.SI", "stat.ME"], "comment": null, "summary": "The increasing use of synthetic data from the public Internet has enhanced\ndata usage efficiency in large language model (LLM) training. However, the\npotential threat of model collapse remains insufficiently explored. Existing\nstudies primarily examine model collapse in a single model setting or rely\nsolely on statistical surrogates. In this work, we introduce LLM Web Dynamics\n(LWD), an efficient framework for investigating model collapse at the network\nlevel. By simulating the Internet with a retrieval-augmented generation (RAG)\ndatabase, we analyze the convergence pattern of model outputs. Furthermore, we\nprovide theoretical guarantees for this convergence by drawing an analogy to\ninteracting Gaussian Mixture Models.", "AI": {"tldr": "The paper introduces LLM Web Dynamics (LWD) to study model collapse in LLMs at the network level, using a RAG database for simulation and theoretical guarantees.", "motivation": "To address the insufficient exploration of model collapse in LLMs, especially at the network level, beyond single-model or statistical surrogate studies.", "method": "Develops LWD, a framework simulating the Internet with a RAG database to analyze model output convergence, supported by theoretical analogies to Gaussian Mixture Models.", "result": "The framework provides insights into model collapse patterns and offers theoretical guarantees for convergence.", "conclusion": "LWD effectively explores model collapse in LLMs at the network level, bridging gaps in existing research."}}
{"id": "2506.15741", "pdf": "https://arxiv.org/pdf/2506.15741", "abs": "https://arxiv.org/abs/2506.15741", "authors": ["He Zhu", "Tianrui Qin", "King Zhu", "Heyuan Huang", "Yeyi Guan", "Jinxiang Xia", "Yi Yao", "Hanhao Li", "Ningning Wang", "Pai Liu", "Tianhao Peng", "Xin Gui", "Xiaowan Li", "Yuhui Liu", "Yuchen Eleanor Jiang", "Jun Wang", "Changwang Zhang", "Xiangru Tang", "Ge Zhang", "Jian Yang", "Minghao Liu", "Xitong Gao", "Wangchunshu Zhou", "Jiaheng Liu"], "title": "OAgents: An Empirical Study of Building Effective Agents", "categories": ["cs.AI", "cs.CL"], "comment": "28 pages", "summary": "Recently, Agentic AI has become an increasingly popular research field.\nHowever, we argue that current agent research practices lack standardization\nand scientific rigor, making it hard to conduct fair comparisons among methods.\nAs a result, it is still unclear how different design choices in agent\nframeworks affect effectiveness, and measuring their progress remains\nchallenging. In this work, we conduct a systematic empirical study on GAIA\nbenchmark and BrowseComp to examine the impact of popular design choices in key\nagent components in a fair and rigorous manner. We find that the lack of a\nstandard evaluation protocol makes previous works, even open-sourced ones,\nnon-reproducible, with significant variance between random runs. Therefore, we\nintroduce a more robust evaluation protocol to stabilize comparisons. Our study\nreveals which components and designs are crucial for effective agents, while\nothers are redundant, despite seeming logical. Based on our findings, we build\nand open-source OAgents, a new foundation agent framework that achieves\nstate-of-the-art performance among open-source projects. OAgents offers a\nmodular design for various agent components, promoting future research in\nAgentic AI.", "AI": {"tldr": "The paper highlights the lack of standardization in Agentic AI research, introduces a robust evaluation protocol, and presents OAgents, a modular framework achieving state-of-the-art performance.", "motivation": "Current agent research lacks standardization and scientific rigor, hindering fair comparisons and progress measurement.", "method": "A systematic empirical study on GAIA benchmark and BrowseComp to evaluate design choices in agent components.", "result": "Reveals key components for effective agents, introduces a stable evaluation protocol, and develops OAgents, a top-performing modular framework.", "conclusion": "OAgents provides a standardized, modular foundation for future Agentic AI research, addressing reproducibility and performance issues."}}
{"id": "2506.15981", "pdf": "https://arxiv.org/pdf/2506.15981", "abs": "https://arxiv.org/abs/2506.15981", "authors": ["Markus Frohmann", "Gabriel Meseguer-Brocal", "Markus Schedl", "Elena V. Epure"], "title": "Double Entendre: Robust Audio-Based AI-Generated Lyrics Detection via Multi-View Fusion", "categories": ["cs.CL", "cs.AI", "cs.SD", "eess.AS"], "comment": "Accepted to ACL 2025 Findings", "summary": "The rapid advancement of AI-based music generation tools is revolutionizing\nthe music industry but also posing challenges to artists, copyright holders,\nand providers alike. This necessitates reliable methods for detecting such\nAI-generated content. However, existing detectors, relying on either audio or\nlyrics, face key practical limitations: audio-based detectors fail to\ngeneralize to new or unseen generators and are vulnerable to audio\nperturbations; lyrics-based methods require cleanly formatted and accurate\nlyrics, unavailable in practice. To overcome these limitations, we propose a\nnovel, practically grounded approach: a multimodal, modular late-fusion\npipeline that combines automatically transcribed sung lyrics and speech\nfeatures capturing lyrics-related information within the audio. By relying on\nlyrical aspects directly from audio, our method enhances robustness, mitigates\nsusceptibility to low-level artifacts, and enables practical applicability.\nExperiments show that our method, DE-detect, outperforms existing lyrics-based\ndetectors while also being more robust to audio perturbations. Thus, it offers\nan effective, robust solution for detecting AI-generated music in real-world\nscenarios. Our code is available at\nhttps://github.com/deezer/robust-AI-lyrics-detection.", "AI": {"tldr": "The paper proposes DE-detect, a multimodal method combining transcribed lyrics and speech features from audio to detect AI-generated music, outperforming existing detectors in robustness and practicality.", "motivation": "The rise of AI-generated music challenges artists and copyright holders, requiring reliable detection methods. Current detectors (audio or lyrics-based) have limitations in generalization and practicality.", "method": "A multimodal, modular late-fusion pipeline integrates transcribed sung lyrics and speech features from audio to detect AI-generated content.", "result": "DE-detect outperforms lyrics-based detectors and is more robust to audio perturbations.", "conclusion": "DE-detect provides an effective, robust solution for detecting AI-generated music in real-world scenarios."}}
{"id": "2506.10932", "pdf": "https://arxiv.org/pdf/2506.10932", "abs": "https://arxiv.org/abs/2506.10932", "authors": ["Jiaying Lizzy Liu", "Yan Zhang"], "title": "Video-Mediated Emotion Disclosure: Expressions of Fear, Sadness, and Joy by People with Schizophrenia on YouTube", "categories": ["cs.HC", "cs.CY", "cs.MM"], "comment": "10 pages", "summary": "Individuals with schizophrenia frequently experience intense emotions and\noften turn to vlogging as a medium for emotional expression. While previous\nresearch has predominantly focused on text based disclosure, little is known\nabout how individuals construct narratives around emotions and emotional\nexperiences in video blogs. Our study addresses this gap by analyzing 200\nYouTube videos created by individuals with schizophrenia. Drawing on media\nresearch and self presentation theories, we developed a visual analysis\nframework to disentangle these videos. Our analysis revealed diverse practices\nof emotion disclosure through both verbal and visual channels, highlighting the\ndynamic interplay between these modes of expression. We found that the\ndeliberate construction of visual elements, including environmental settings\nand specific aesthetic choices, appears to foster more supportive and engaged\nviewer responses. These findings underscore the need for future large scale\nquantitative research examining how visual features shape video mediated\ncommunication on social media platforms. Such investigations would inform the\ndevelopment of care centered video sharing platforms that better support\nindividuals managing illness experiences.", "AI": {"tldr": "The study analyzes 200 YouTube videos by individuals with schizophrenia to explore emotion disclosure through vlogging, revealing the interplay of verbal and visual expression and its impact on viewer engagement.", "motivation": "To address the gap in understanding how individuals with schizophrenia construct emotional narratives in video blogs, beyond text-based disclosure.", "method": "Developed a visual analysis framework based on media research and self-presentation theories to analyze 200 YouTube videos.", "result": "Found diverse emotion disclosure practices through verbal and visual channels, with deliberate visual elements fostering supportive viewer responses.", "conclusion": "Highlights the need for future quantitative research on visual features in video-mediated communication to inform care-centered platform development."}}
{"id": "2506.15587", "pdf": "https://arxiv.org/pdf/2506.15587", "abs": "https://arxiv.org/abs/2506.15587", "authors": ["Martino Brambati", "Antonio Celani", "Marco Gherardi", "Francesco Ginelli"], "title": "Learning to flock in open space by avoiding collisions and staying together", "categories": ["cond-mat.soft", "cs.MA", "physics.bio-ph"], "comment": "13 pages + appendices", "summary": "We investigate the emergence of cohesive flocking in open, boundless space\nusing a multi-agent reinforcement learning framework. Agents integrate\npositional and orientational information from their closest topological\nneighbours and learn to balance alignment and attractive interactions by\noptimizing a local cost function that penalizes both excessive separation and\nclose-range crowding. The resulting Vicsek-like dynamics is robust to\nalgorithmic implementation details and yields cohesive collective motion with\nhigh polar order. The optimal policy is dominated by strong aligning\ninteractions when agents are sufficiently close to their neighbours, and a\nflexible combination of alignment and attraction at larger separations. We\nfurther characterize the internal structure and dynamics of the resulting\ngroups using liquid-state metrics and neighbour exchange rates, finding\nqualitative agreement with empirical observations in starling flocks. These\nresults suggest that flocking may emerge in groups of moving agents as an\nadaptive response to the biological imperatives of staying together while\navoiding collisions.", "AI": {"tldr": "The paper explores cohesive flocking in open space using multi-agent reinforcement learning, balancing alignment and attraction to achieve robust Vicsek-like dynamics with high polar order.", "motivation": "To understand how flocking emerges in open, boundless spaces and how agents balance alignment and attraction to maintain cohesion while avoiding collisions.", "method": "A multi-agent reinforcement learning framework where agents use positional and orientational data from neighbors, optimizing a local cost function to penalize separation and crowding.", "result": "Cohesive collective motion with high polar order, dominated by strong alignment at close range and flexible alignment-attraction at larger separations, resembling empirical starling flocks.", "conclusion": "Flocking emerges as an adaptive response to biological needs of cohesion and collision avoidance, with dynamics robust to implementation details."}}
{"id": "2506.16833", "pdf": "https://arxiv.org/pdf/2506.16833", "abs": "https://arxiv.org/abs/2506.16833", "authors": ["Jianyuan Feng", "Guangzheng Li", "Yangfei Xu"], "title": "Hybrid-Sep: Language-queried audio source separation via pre-trained Model Fusion and Adversarial Diffusion Training", "categories": ["cs.SD", "eess.AS"], "comment": "Submitted to WASAA 2025", "summary": "Language-queried Audio Separation (LASS) employs linguistic queries to\nisolate target sounds based on semantic descriptions. However, existing methods\nface challenges in aligning complex auditory features with linguistic context\nwhile preserving separation precision. Current research efforts focus primarily\non text description augmentation and architectural innovations, yet the\npotential of integrating pre-trained self-supervised learning (SSL) audio\nmodels and Contrastive Language-Audio Pretraining (CLAP) frameworks, capable of\nextracting cross-modal audio-text relationships, remains underexplored. To\naddress this, we present HybridSep, a two-stage LASS framework that synergizes\nSSL-based acoustic representations with CLAP-derived semantic embeddings. Our\nframework introduces Adversarial Consistent Training (ACT), a novel\noptimization strategy that treats diffusion as an auxiliary regularization loss\nwhile integrating adversarial training to enhance separation fidelity.\nExperiments demonstrate that HybridSep achieves significant performance\nimprovements over state-of-the-art baselines (e.g., AudioSep, FlowSep) across\nmultiple metrics, establishing new benchmarks for LASS tasks.", "AI": {"tldr": "HybridSep, a two-stage LASS framework, integrates SSL-based acoustic representations and CLAP-derived semantic embeddings with Adversarial Consistent Training (ACT) to improve audio separation performance.", "motivation": "Existing LASS methods struggle with aligning auditory features and linguistic context while maintaining precision. The potential of SSL and CLAP frameworks is underexplored.", "method": "HybridSep combines SSL-based acoustic features and CLAP semantic embeddings, using ACT for optimization. ACT integrates adversarial training and diffusion as regularization.", "result": "HybridSep outperforms state-of-the-art baselines (e.g., AudioSep, FlowSep) across multiple metrics, setting new benchmarks.", "conclusion": "HybridSep demonstrates the effectiveness of integrating SSL and CLAP with ACT, advancing LASS performance."}}
{"id": "2506.16173", "pdf": "https://arxiv.org/pdf/2506.16173", "abs": "https://arxiv.org/abs/2506.16173", "authors": ["Jiang Wang", "Runwu Shi", "Benjamin Yen", "He Kong", "Kazuhiro Nakadai"], "title": "Single-Microphone-Based Sound Source Localization for Mobile Robots in Reverberant Environments", "categories": ["cs.RO", "cs.SD", "eess.AS"], "comment": "This paper was accepted and going to appear in the 2025 IEEE/RSJ\n  International Conference on Intelligent Robots and Systems (IROS)", "summary": "Accurately estimating sound source positions is crucial for robot audition.\nHowever, existing sound source localization methods typically rely on a\nmicrophone array with at least two spatially preconfigured microphones. This\nrequirement hinders the applicability of microphone-based robot audition\nsystems and technologies. To alleviate these challenges, we propose an online\nsound source localization method that uses a single microphone mounted on a\nmobile robot in reverberant environments. Specifically, we develop a\nlightweight neural network model with only 43k parameters to perform real-time\ndistance estimation by extracting temporal information from reverberant\nsignals. The estimated distances are then processed using an extended Kalman\nfilter to achieve online sound source localization. To the best of our\nknowledge, this is the first work to achieve online sound source localization\nusing a single microphone on a moving robot, a gap that we aim to fill in this\nwork. Extensive experiments demonstrate the effectiveness and merits of our\napproach. To benefit the broader research community, we have open-sourced our\ncode at https://github.com/JiangWAV/single-mic-SSL.", "AI": {"tldr": "Proposes an online sound source localization method using a single microphone on a mobile robot, leveraging a lightweight neural network and extended Kalman filter.", "motivation": "Existing methods require multiple microphones, limiting applicability; this work aims to overcome this limitation.", "method": "Uses a 43k-parameter neural network for real-time distance estimation from reverberant signals, combined with an extended Kalman filter for localization.", "result": "Demonstrates effective online sound source localization with a single microphone, filling a research gap.", "conclusion": "The approach is practical and open-sourced, benefiting the research community."}}
{"id": "2506.15853", "pdf": "https://arxiv.org/pdf/2506.15853", "abs": "https://arxiv.org/abs/2506.15853", "authors": ["Amit Das", "Naofumi Tomita", "Kyle J. Syme", "Weijie Ma", "Paige O'Connor", "Kristin N. Corbett", "Bing Ren", "Xiaoying Liu", "Saeed Hassanpour"], "title": "Cross-Modality Learning for Predicting IHC Biomarkers from H&E-Stained Whole-Slide Images", "categories": ["eess.IV", "cs.AI", "cs.CV"], "comment": null, "summary": "Hematoxylin and Eosin (H&E) staining is a cornerstone of pathological\nanalysis, offering reliable visualization of cellular morphology and tissue\narchitecture for cancer diagnosis, subtyping, and grading. Immunohistochemistry\n(IHC) staining provides molecular insights by detecting specific proteins\nwithin tissues, enhancing diagnostic accuracy, and improving treatment\nplanning. However, IHC staining is costly, time-consuming, and\nresource-intensive, requiring specialized expertise. To address these\nlimitations, this study proposes HistoStainAlign, a novel deep learning\nframework that predicts IHC staining patterns directly from H&E whole-slide\nimages (WSIs) by learning joint representations of morphological and molecular\nfeatures. The framework integrates paired H&E and IHC embeddings through a\ncontrastive training strategy, capturing complementary features across staining\nmodalities without patch-level annotations or tissue registration. The model\nwas evaluated on gastrointestinal and lung tissue WSIs with three commonly used\nIHC stains: P53, PD-L1, and Ki-67. HistoStainAlign achieved weighted F1 scores\nof 0.735 [95% Confidence Interval (CI): 0.670-0.799], 0.830 [95% CI:\n0.772-0.886], and 0.723 [95% CI: 0.607-0.836], respectively for these three IHC\nstains. Embedding analyses demonstrated the robustness of the contrastive\nalignment in capturing meaningful cross-stain relationships. Comparisons with a\nbaseline model further highlight the advantage of incorporating contrastive\nlearning for improved stain pattern prediction. This study demonstrates the\npotential of computational approaches to serve as a pre-screening tool, helping\nprioritize cases for IHC staining and improving workflow efficiency.", "AI": {"tldr": "HistoStainAlign predicts IHC staining patterns from H&E images using deep learning, improving efficiency and reducing costs.", "motivation": "IHC staining is expensive and time-consuming; this study aims to provide a computational alternative using H&E images.", "method": "A deep learning framework (HistoStainAlign) learns joint representations of H&E and IHC features via contrastive training, without patch-level annotations.", "result": "Achieved weighted F1 scores of 0.735 (P53), 0.830 (PD-L1), and 0.723 (Ki-67) on gastrointestinal and lung tissue WSIs.", "conclusion": "HistoStainAlign shows promise as a pre-screening tool to prioritize cases for IHC staining, enhancing workflow efficiency."}}
{"id": "2506.15852", "pdf": "https://arxiv.org/pdf/2506.15852", "abs": "https://arxiv.org/abs/2506.15852", "authors": ["Dominic Akt", "Marco Peer", "Florian Kleber"], "title": "Assessing the impact of Binarization for Writer Identification in Greek Papyrus", "categories": ["cs.CV"], "comment": "Accepted for publication for AIROV 2025", "summary": "This paper tackles the task of writer identification for Greek papyri. A\ncommon preprocessing step in writer identification pipelines is image\nbinarization, which prevents the model from learning background features. This\nis challenging in historical documents, in our case Greek papyri, as background\nis often non-uniform, fragmented, and discolored with visible fiber structures.\nWe compare traditional binarization methods to state-of-the-art Deep Learning\n(DL) models, evaluating the impact of binarization quality on subsequent writer\nidentification performance. DL models are trained with and without a custom\ndata augmentation technique, as well as different model selection criteria are\napplied. The performance of these binarization methods, is then systematically\nevaluated on the DIBCO 2019 dataset. The impact of binarization on writer\nidentification is subsequently evaluated using a state-of-the-art approach for\nwriter identification. The results of this analysis highlight the influence of\ndata augmentation for DL methods. Furthermore, findings indicate a strong\ncorrelation between binarization effectiveness on papyri documents of DIBCO\n2019 and downstream writer identification performance.", "AI": {"tldr": "The paper evaluates binarization methods for Greek papyri, comparing traditional and DL approaches, and assesses their impact on writer identification performance.", "motivation": "Writer identification in Greek papyri is hindered by non-uniform backgrounds, requiring effective binarization to avoid learning irrelevant features.", "method": "Traditional and DL binarization methods are compared, with DL models trained using custom data augmentation and different selection criteria. Performance is tested on DIBCO 2019.", "result": "Data augmentation improves DL methods, and binarization quality strongly correlates with writer identification performance.", "conclusion": "Effective binarization, especially with DL and augmentation, is crucial for accurate writer identification in historical documents."}}
{"id": "2506.15691", "pdf": "https://arxiv.org/pdf/2506.15691", "abs": "https://arxiv.org/abs/2506.15691", "authors": ["Chuheng Zhang", "Tim Pearce", "Pushi Zhang", "Kaixin Wang", "Xiaoyu Chen", "Wei Shen", "Li Zhao", "Jiang Bian"], "title": "What Do Latent Action Models Actually Learn?", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Latent action models (LAMs) aim to learn action-relevant changes from\nunlabeled videos by compressing changes between frames as latents. However,\ndifferences between video frames can be caused by controllable changes as well\nas exogenous noise, leading to an important concern -- do latents capture the\nchanges caused by actions or irrelevant noise? This paper studies this issue\nanalytically, presenting a linear model that encapsulates the essence of LAM\nlearning, while being tractable.This provides several insights, including\nconnections between LAM and principal component analysis (PCA), desiderata of\nthe data-generating policy, and justification of strategies to encourage\nlearning controllable changes using data augmentation, data cleaning, and\nauxiliary action-prediction. We also provide illustrative results based on\nnumerical simulation, shedding light on the specific structure of observations,\nactions, and noise in data that influence LAM learning.", "AI": {"tldr": "The paper analyzes whether latent action models (LAMs) capture action-relevant changes or noise in unlabeled videos, using a tractable linear model to derive insights and validate strategies like data augmentation and cleaning.", "motivation": "To address whether LAMs learn controllable changes or irrelevant noise from unlabeled videos, given the challenge of distinguishing between the two.", "method": "A tractable linear model is used to analytically study LAM learning, connecting it to PCA and evaluating strategies like data augmentation, cleaning, and auxiliary action-prediction.", "result": "Insights include connections to PCA, policy desiderata, and validation of strategies to enhance learning of controllable changes, supported by numerical simulations.", "conclusion": "The study clarifies the conditions under which LAMs learn action-relevant changes and proposes practical strategies to improve their performance."}}
{"id": "2506.15751", "pdf": "https://arxiv.org/pdf/2506.15751", "abs": "https://arxiv.org/abs/2506.15751", "authors": ["Kartik Sharma", "Yiqiao Jin", "Vineeth Rakesh", "Yingtong Dou", "Menghai Pan", "Mahashweta Das", "Srijan Kumar"], "title": "Sysformer: Safeguarding Frozen Large Language Models with Adaptive System Prompts", "categories": ["cs.AI", "cs.CL", "cs.LG"], "comment": null, "summary": "As large language models (LLMs) are deployed in safety-critical settings, it\nis essential to ensure that their responses comply with safety standards. Prior\nresearch has revealed that LLMs often fail to grasp the notion of safe\nbehaviors, resulting in either unjustified refusals to harmless prompts or the\ngeneration of harmful content. While substantial efforts have been made to\nimprove their robustness, existing defenses often rely on costly fine-tuning of\nmodel parameters or employ suboptimal heuristic techniques. In this work, we\ntake a novel approach to safeguard LLMs by learning to adapt the system prompts\nin instruction-tuned LLMs. While LLMs are typically pre-trained to follow a\nfixed system prompt, we investigate the impact of tailoring the system prompt\nto each specific user input on the safety of the responses. To this end, we\npropose $\\textbf{Sysformer}$, a trans$\\textbf{former}$ model that updates an\ninitial $\\textbf{sys}$tem prompt to a more robust system prompt in the LLM\ninput embedding space while attending to the user prompt. While keeping the LLM\nparameters frozen, the Sysformer is trained to refuse to respond to a set of\nharmful prompts while responding ideally to a set of safe ones. Through\nextensive experiments on $5$ LLMs from different families and $2$ recent\nbenchmarks, we demonstrate that Sysformer can significantly enhance the\nrobustness of LLMs, leading to upto $80\\%$ gain in the refusal rate on harmful\nprompts while enhancing the compliance with the safe prompts by upto $90\\%$.\nResults also generalize well to sophisticated jailbreaking attacks, making LLMs\nupto $100\\%$ more robust against different attack strategies. We hope our\nfindings lead to cheaper safeguarding of LLMs and motivate future\ninvestigations into designing variable system prompts.", "AI": {"tldr": "The paper introduces Sysformer, a transformer-based model that adapts system prompts in LLMs to enhance safety, achieving significant improvements in refusal rates for harmful prompts and compliance with safe ones.", "motivation": "To address the limitations of existing defenses for LLM safety, which often involve costly fine-tuning or suboptimal heuristics, by dynamically adapting system prompts.", "method": "Proposes Sysformer, a transformer model that updates initial system prompts in the LLM input embedding space, trained to refuse harmful prompts and respond ideally to safe ones while keeping LLM parameters frozen.", "result": "Sysformer improves refusal rates on harmful prompts by up to 80%, enhances compliance with safe prompts by up to 90%, and boosts robustness against jailbreaking attacks by up to 100%.", "conclusion": "Sysformer offers a cost-effective solution for safeguarding LLMs and encourages future research into variable system prompt design."}}
{"id": "2506.16024", "pdf": "https://arxiv.org/pdf/2506.16024", "abs": "https://arxiv.org/abs/2506.16024", "authors": ["Zhihan Guo", "Jiele Wu", "Wenqian Cui", "Yifei Zhang", "Minda Hu", "Yufei Wang", "Irwin King"], "title": "From General to Targeted Rewards: Surpassing GPT-4 in Open-Ended Long-Context Generation", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Current research on long-form context in Large Language Models (LLMs)\nprimarily focuses on the understanding of long-contexts, the Open-ended Long\nText Generation (Open-LTG) remains insufficiently explored. Training a\nlong-context generation model requires curation of gold standard reference\ndata, which is typically nonexistent for informative Open-LTG tasks. However,\nprevious methods only utilize general assessments as reward signals, which\nlimits accuracy. To bridge this gap, we introduce ProxyReward, an innovative\nreinforcement learning (RL) based framework, which includes a dataset and a\nreward signal computation method. Firstly, ProxyReward Dataset generation is\naccomplished through simple prompts that enables the model to create\nautomatically, obviating extensive labeled data or significant manual effort.\nSecondly, ProxyReward Signal offers a targeted evaluation of information\ncomprehensiveness and accuracy for specific questions. The experimental results\nindicate that our method ProxyReward surpasses even GPT-4-Turbo. It can\nsignificantly enhance performance by 20% on the Open-LTG task when training\nwidely used open-source models, while also surpassing the LLM-as-a-Judge\napproach. Our work presents effective methods to enhance the ability of LLMs to\naddress complex open-ended questions posed by human.", "AI": {"tldr": "ProxyReward, a new RL framework, improves Open-LTG tasks by generating datasets and reward signals without extensive labeled data, outperforming GPT-4-Turbo and LLM-as-a-Judge.", "motivation": "Open-ended Long Text Generation (Open-LTG) lacks exploration, and existing methods rely on general assessments, limiting accuracy.", "method": "ProxyReward uses simple prompts for dataset generation and provides targeted reward signals for information comprehensiveness and accuracy.", "result": "ProxyReward outperforms GPT-4-Turbo and enhances Open-LTG performance by 20% for open-source models.", "conclusion": "ProxyReward effectively improves LLMs' ability to handle complex open-ended questions."}}
{"id": "2506.15677", "pdf": "https://arxiv.org/pdf/2506.15677", "abs": "https://arxiv.org/abs/2506.15677", "authors": ["Yining Hong", "Rui Sun", "Bingxuan Li", "Xingcheng Yao", "Maxine Wu", "Alexander Chien", "Da Yin", "Ying Nian Wu", "Zhecan James Wang", "Kai-Wei Chang"], "title": "Embodied Web Agents: Bridging Physical-Digital Realms for Integrated Agent Intelligence", "categories": ["cs.AI", "cs.CL", "cs.CV", "cs.MM", "cs.RO"], "comment": null, "summary": "AI agents today are mostly siloed - they either retrieve and reason over vast\namount of digital information and knowledge obtained online; or interact with\nthe physical world through embodied perception, planning and action - but\nrarely both. This separation limits their ability to solve tasks that require\nintegrated physical and digital intelligence, such as cooking from online\nrecipes, navigating with dynamic map data, or interpreting real-world landmarks\nusing web knowledge. We introduce Embodied Web Agents, a novel paradigm for AI\nagents that fluidly bridge embodiment and web-scale reasoning. To\noperationalize this concept, we first develop the Embodied Web Agents task\nenvironments, a unified simulation platform that tightly integrates realistic\n3D indoor and outdoor environments with functional web interfaces. Building\nupon this platform, we construct and release the Embodied Web Agents Benchmark,\nwhich encompasses a diverse suite of tasks including cooking, navigation,\nshopping, tourism, and geolocation - all requiring coordinated reasoning across\nphysical and digital realms for systematic assessment of cross-domain\nintelligence. Experimental results reveal significant performance gaps between\nstate-of-the-art AI systems and human capabilities, establishing both\nchallenges and opportunities at the intersection of embodied cognition and\nweb-scale knowledge access. All datasets, codes and websites are publicly\navailable at our project page https://embodied-web-agent.github.io/.", "AI": {"tldr": "The paper introduces Embodied Web Agents, a paradigm integrating physical and digital intelligence for AI, and benchmarks tasks requiring such integration.", "motivation": "Current AI agents are siloed, limiting their ability to solve tasks requiring both physical and digital intelligence.", "method": "Developed a unified simulation platform (Embodied Web Agents task environments) and benchmark for tasks like cooking and navigation.", "result": "Revealed performance gaps between state-of-the-art AI and humans in cross-domain tasks.", "conclusion": "The work highlights challenges and opportunities in merging embodied cognition with web-scale knowledge."}}
{"id": "2506.15887", "pdf": "https://arxiv.org/pdf/2506.15887", "abs": "https://arxiv.org/abs/2506.15887", "authors": ["Jakub T\u0142uczek", "Victor Villin", "Christos Dimitrakakis"], "title": "Fair Contracts in Principal-Agent Games with Heterogeneous Types", "categories": ["cs.GT", "cs.LG", "cs.MA"], "comment": null, "summary": "Fairness is desirable yet challenging to achieve within multi-agent systems,\nespecially when agents differ in latent traits that affect their abilities.\nThis hidden heterogeneity often leads to unequal distributions of wealth, even\nwhen agents operate under the same rules. Motivated by real-world examples, we\npropose a framework based on repeated principal-agent games, where a principal,\nwho also can be seen as a player of the game, learns to offer adaptive\ncontracts to agents. By leveraging a simple yet powerful contract structure, we\nshow that a fairness-aware principal can learn homogeneous linear contracts\nthat equalize outcomes across agents in a sequential social dilemma.\nImportantly, this fairness does not come at the cost of efficiency: our results\ndemonstrate that it is possible to promote equity and stability in the system\nwhile preserving overall performance.", "AI": {"tldr": "A framework using repeated principal-agent games achieves fairness in multi-agent systems without sacrificing efficiency.", "motivation": "Addressing hidden heterogeneity in multi-agent systems that leads to unequal wealth distribution despite uniform rules.", "method": "Proposes a framework with a fairness-aware principal offering adaptive, homogeneous linear contracts in repeated principal-agent games.", "result": "Fairness is achieved by equalizing outcomes across agents in a sequential social dilemma while maintaining system efficiency.", "conclusion": "Fairness and efficiency can coexist in multi-agent systems through adaptive contract design."}}
{"id": "2506.16889", "pdf": "https://arxiv.org/pdf/2506.16889", "abs": "https://arxiv.org/abs/2506.16889", "authors": ["Junghyun Koo", "Marco A. Martinez-Ramirez", "Wei-Hsiang Liao", "Giorgio Fabbro", "Michele Mancusi", "Yuki Mitsufuji"], "title": "ITO-Master: Inference-Time Optimization for Audio Effects Modeling of Music Mastering Processors", "categories": ["cs.SD", "eess.AS"], "comment": "ISMIR 2025", "summary": "Music mastering style transfer aims to model and apply the mastering\ncharacteristics of a reference track to a target track, simulating the\nprofessional mastering process. However, existing methods apply fixed\nprocessing based on a reference track, limiting users' ability to fine-tune the\nresults to match their artistic intent. In this paper, we introduce the\nITO-Master framework, a reference-based mastering style transfer system that\nintegrates Inference-Time Optimization (ITO) to enable finer user control over\nthe mastering process. By optimizing the reference embedding during inference,\nour approach allows users to refine the output dynamically, making micro-level\nadjustments to achieve more precise mastering results. We explore both\nblack-box and white-box methods for modeling mastering processors and\ndemonstrate that ITO improves mastering performance across different styles.\nThrough objective evaluation, subjective listening tests, and qualitative\nanalysis using text-based conditioning with CLAP embeddings, we validate that\nITO enhances mastering style similarity while offering increased adaptability.\nOur framework provides an effective and user-controllable solution for\nmastering style transfer, allowing users to refine their results beyond the\ninitial style transfer.", "AI": {"tldr": "The paper introduces ITO-Master, a framework for music mastering style transfer that uses Inference-Time Optimization (ITO) to allow users finer control over the mastering process, improving adaptability and precision.", "motivation": "Existing methods for mastering style transfer apply fixed processing, limiting user control over artistic intent. The paper aims to address this by enabling dynamic refinement of mastering results.", "method": "The ITO-Master framework integrates ITO to optimize reference embeddings during inference, allowing micro-level adjustments. It explores black-box and white-box methods for modeling mastering processors.", "result": "ITO improves mastering performance across styles, validated through objective evaluation, subjective tests, and CLAP embeddings. It enhances style similarity and adaptability.", "conclusion": "ITO-Master offers an effective, user-controllable solution for mastering style transfer, enabling refinement beyond initial style application."}}
{"id": "2506.16251", "pdf": "https://arxiv.org/pdf/2506.16251", "abs": "https://arxiv.org/abs/2506.16251", "authors": ["Aishwarya Pothula", "Bhavana Akkiraju", "Srihari Bandarupalli", "Charan D", "Santosh Kesiraju", "Anil Kumar Vuppala"], "title": "End-to-End Speech Translation for Low-Resource Languages Using Weakly Labeled Data", "categories": ["cs.CL", "eess.AS"], "comment": null, "summary": "The scarcity of high-quality annotated data presents a significant challenge\nin developing effective end-to-end speech-to-text translation (ST) systems,\nparticularly for low-resource languages. This paper explores the hypothesis\nthat weakly labeled data can be used to build ST models for low-resource\nlanguage pairs. We constructed speech-to-text translation datasets with the\nhelp of bitext mining using state-of-the-art sentence encoders. We mined the\nmultilingual Shrutilipi corpus to build Shrutilipi-anuvaad, a dataset\ncomprising ST data for language pairs Bengali-Hindi, Malayalam-Hindi,\nOdia-Hindi, and Telugu-Hindi. We created multiple versions of training data\nwith varying degrees of quality and quantity to investigate the effect of\nquality versus quantity of weakly labeled data on ST model performance. Results\ndemonstrate that ST systems can be built using weakly labeled data, with\nperformance comparable to massive multi-modal multilingual baselines such as\nSONAR and SeamlessM4T.", "AI": {"tldr": "The paper explores using weakly labeled data to build speech-to-text translation models for low-resource languages, achieving performance comparable to strong baselines.", "motivation": "Addressing the challenge of scarce high-quality annotated data for low-resource speech-to-text translation.", "method": "Constructed datasets using bitext mining from the Shrutilipi corpus, creating varied-quality training data for Bengali-Hindi, Malayalam-Hindi, Odia-Hindi, and Telugu-Hindi pairs.", "result": "ST systems built with weakly labeled data perform comparably to models like SONAR and SeamlessM4T.", "conclusion": "Weakly labeled data is viable for building effective ST systems for low-resource languages."}}
{"id": "2506.16102", "pdf": "https://arxiv.org/pdf/2506.16102", "abs": "https://arxiv.org/abs/2506.16102", "authors": ["Ziran Zhu", "Tongda Xu", "Minye Huang", "Dailan He", "Xingtong Ge", "Xinjie Zhang", "Ling Li", "Yan Wang"], "title": "Fast Training-free Perceptual Image Compression", "categories": ["eess.IV", "cs.CV"], "comment": null, "summary": "Training-free perceptual image codec adopt pre-trained unconditional\ngenerative model during decoding to avoid training new conditional generative\nmodel. However, they heavily rely on diffusion inversion or sample\ncommunication, which take 1 min to intractable amount of time to decode a\nsingle image. In this paper, we propose a training-free algorithm that improves\nthe perceptual quality of any existing codec with theoretical guarantee. We\nfurther propose different implementations for optimal perceptual quality when\ndecoding time budget is $\\approx 0.1$s, $0.1-10$s and $\\ge 10$s. Our approach:\n1). improves the decoding time of training-free codec from 1 min to $0.1-10$s\nwith comparable perceptual quality. 2). can be applied to non-differentiable\ncodec such as VTM. 3). can be used to improve previous perceptual codecs, such\nas MS-ILLM. 4). can easily achieve perception-distortion trade-off.\nEmpirically, we show that our approach successfully improves the perceptual\nquality of ELIC, VTM and MS-ILLM with fast decoding. Our approach achieves\ncomparable FID to previous training-free codec with significantly less decoding\ntime. And our approach still outperforms previous conditional generative model\nbased codecs such as HiFiC and MS-ILLM in terms of FID. The source code is\nprovided in the supplementary material.", "AI": {"tldr": "Proposes a training-free algorithm to improve perceptual quality of image codecs with fast decoding, outperforming existing methods in speed and quality.", "motivation": "Existing training-free perceptual image codecs are slow, relying on time-consuming methods like diffusion inversion. This work aims to enhance decoding speed and quality without additional training.", "method": "Introduces a training-free algorithm with implementations optimized for different decoding time budgets (\u22480.1s, 0.1-10s, \u226510s). It improves speed and quality, works with non-differentiable codecs, and enables perception-distortion trade-offs.", "result": "Reduces decoding time from 1 min to 0.1-10s with comparable perceptual quality. Outperforms HiFiC and MS-ILLM in FID and works with VTM, ELIC, and MS-ILLM.", "conclusion": "The approach significantly improves decoding speed and perceptual quality, offering a practical solution for existing codecs with theoretical guarantees."}}
{"id": "2506.15854", "pdf": "https://arxiv.org/pdf/2506.15854", "abs": "https://arxiv.org/abs/2506.15854", "authors": ["Abdolazim Rezaei", "Mehdi Sookhak", "Ahmad Patooghy"], "title": "Privacy-Preserving in Connected and Autonomous Vehicles Through Vision to Text Transformation", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "Connected and Autonomous Vehicles (CAVs) rely on a range of devices that\noften process privacy-sensitive data. Among these, roadside units play a\ncritical role particularly through the use of AI-equipped (AIE) cameras for\napplications such as violation detection. However, the privacy risks associated\nwith captured imagery remain a major concern, as such data can be misused for\nidentity theft, profiling, or unauthorized commercial purposes. While\ntraditional techniques such as face blurring and obfuscation have been applied\nto mitigate privacy risks, individual privacy remains at risk, as individuals\ncan still be tracked using other features such as their clothing. This paper\nintroduces a novel privacy-preserving framework that leverages feedback-based\nreinforcement learning (RL) and vision-language models (VLMs) to protect\nsensitive visual information captured by AIE cameras. The main idea is to\nconvert images into semantically equivalent textual descriptions, ensuring that\nscene-relevant information is retained while visual privacy is preserved. A\nhierarchical RL strategy is employed to iteratively refine the generated text,\nenhancing both semantic accuracy and privacy. Evaluation results demonstrate\nsignificant improvements in both privacy protection and textual quality, with\nthe Unique Word Count increasing by approximately 77\\% and Detail Density by\naround 50\\% compared to existing approaches.", "AI": {"tldr": "A novel framework using reinforcement learning and vision-language models converts AIE camera images into text to preserve privacy while retaining scene relevance.", "motivation": "Privacy risks from AIE cameras in CAVs, as traditional methods like face blurring fail to fully protect against tracking via other features.", "method": "Feedback-based reinforcement learning and vision-language models transform images into semantically equivalent text, refined iteratively for accuracy and privacy.", "result": "Significant improvements: 77% increase in Unique Word Count and 50% in Detail Density over existing methods.", "conclusion": "The framework effectively balances privacy protection and semantic retention, outperforming traditional techniques."}}
{"id": "2506.15692", "pdf": "https://arxiv.org/pdf/2506.15692", "abs": "https://arxiv.org/abs/2506.15692", "authors": ["Jaehyun Nam", "Jinsung Yoon", "Jiefeng Chen", "Jinwoo Shin", "Sercan \u00d6. Ar\u0131k", "Tomas Pfister"], "title": "MLE-STAR: Machine Learning Engineering Agent via Search and Targeted Refinement", "categories": ["cs.LG"], "comment": null, "summary": "Agents based on large language models (LLMs) for machine learning engineering\n(MLE) can automatically implement ML models via code generation. However,\nexisting approaches to build such agents often rely heavily on inherent LLM\nknowledge and employ coarse exploration strategies that modify the entire code\nstructure at once. This limits their ability to select effective task-specific\nmodels and perform deep exploration within specific components, such as\nexperimenting extensively with feature engineering options. To overcome these,\nwe propose MLE-STAR, a novel approach to build MLE agents. MLE-STAR first\nleverages external knowledge by using a search engine to retrieve effective\nmodels from the web, forming an initial solution, then iteratively refines it\nby exploring various strategies targeting specific ML components. This\nexploration is guided by ablation studies analyzing the impact of individual\ncode blocks. Furthermore, we introduce a novel ensembling method using an\neffective strategy suggested by MLE-STAR. Our experimental results show that\nMLE-STAR achieves medals in 44% of the Kaggle competitions on the MLE-bench,\nsignificantly outperforming the best alternative.", "AI": {"tldr": "MLE-STAR is a novel approach for building LLM-based MLE agents that leverages external knowledge and iterative refinement to outperform existing methods in Kaggle competitions.", "motivation": "Existing LLM-based MLE agents rely too much on inherent LLM knowledge and coarse exploration, limiting their ability to select task-specific models and deeply explore components like feature engineering.", "method": "MLE-STAR uses a search engine to retrieve effective models, forms an initial solution, and iteratively refines it by exploring specific ML components, guided by ablation studies. It also introduces a novel ensembling method.", "result": "MLE-STAR achieves medals in 44% of Kaggle competitions on MLE-bench, significantly outperforming alternatives.", "conclusion": "MLE-STAR demonstrates superior performance by combining external knowledge retrieval, targeted exploration, and novel ensembling."}}
{"id": "2506.15758", "pdf": "https://arxiv.org/pdf/2506.15758", "abs": "https://arxiv.org/abs/2506.15758", "authors": ["Marcel Wien\u00f6bst", "Sebastian Weichwald", "Leonard Henckel"], "title": "Linear-Time Primitives for Algorithm Development in Graphical Causal Inference", "categories": ["cs.AI", "cs.DS", "cs.LG", "stat.ME", "stat.ML"], "comment": null, "summary": "We introduce CIfly, a framework for efficient algorithmic primitives in\ngraphical causal inference that isolates reachability as a reusable core\noperation. It builds on the insight that many causal reasoning tasks can be\nreduced to reachability in purpose-built state-space graphs that can be\nconstructed on the fly during traversal. We formalize a rule table schema for\nspecifying such algorithms and prove they run in linear time. We establish\nCIfly as a more efficient alternative to the common primitives moralization and\nlatent projection, which we show are computationally equivalent to Boolean\nmatrix multiplication. Our open-source Rust implementation parses rule table\ntext files and runs the specified CIfly algorithms providing high-performance\nexecution accessible from Python and R. We demonstrate CIfly's utility by\nre-implementing a range of established causal inference tasks within the\nframework and by developing new algorithms for instrumental variables. These\ncontributions position CIfly as a flexible and scalable backbone for graphical\ncausal inference, guiding algorithm development and enabling easy and efficient\ndeployment.", "AI": {"tldr": "CIfly is a framework for efficient causal inference by reducing tasks to reachability in state-space graphs, offering linear-time performance and outperforming traditional methods like moralization and latent projection.", "motivation": "To provide a more efficient and scalable alternative to existing causal inference primitives, which are computationally expensive.", "method": "Uses reachability in state-space graphs constructed on-the-fly, formalized via rule tables, and implemented in Rust for high performance.", "result": "CIfly achieves linear-time performance, outperforms traditional methods, and supports Python/R integration.", "conclusion": "CIfly is a flexible, scalable backbone for causal inference, enabling efficient algorithm development and deployment."}}
{"id": "2506.16029", "pdf": "https://arxiv.org/pdf/2506.16029", "abs": "https://arxiv.org/abs/2506.16029", "authors": ["Zhenting Qi", "Fan Nie", "Alexandre Alahi", "James Zou", "Himabindu Lakkaraju", "Yilun Du", "Eric Xing", "Sham Kakade", "Hanlin Zhang"], "title": "EvoLM: In Search of Lost Language Model Training Dynamics", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "Modern language model (LM) training has been divided into multiple stages,\nmaking it difficult for downstream developers to evaluate the impact of design\nchoices made at each stage. We present EvoLM, a model suite that enables\nsystematic and transparent analysis of LMs' training dynamics across\npre-training, continued pre-training, supervised fine-tuning, and reinforcement\nlearning. By training over 100 LMs with 1B and 4B parameters from scratch, we\nrigorously evaluate both upstream (language modeling) and downstream\n(problem-solving) reasoning capabilities, including considerations of both\nin-domain and out-of-domain generalization. Key insights highlight the\ndiminishing returns from excessive pre-training and post-training, the\nimportance and practices of mitigating forgetting during domain-specific\ncontinued pre-training, the crucial role of continued pre-training in bridging\npre-training and post-training phases, and various intricate trade-offs when\nconfiguring supervised fine-tuning and reinforcement learning. To facilitate\nopen research and reproducibility, we release all pre-trained and post-trained\nmodels, training datasets for all stages, and our entire training and\nevaluation pipeline.", "AI": {"tldr": "EvoLM is a model suite enabling systematic analysis of LM training dynamics across stages, revealing insights like diminishing returns from excessive pre-training and the importance of mitigating forgetting.", "motivation": "To address the challenge of evaluating design choices in multi-stage LM training and provide transparency in training dynamics.", "method": "Train over 100 LMs (1B and 4B parameters) from scratch, evaluating upstream and downstream capabilities, including generalization.", "result": "Key findings include diminishing returns from excessive training, the role of continued pre-training, and trade-offs in fine-tuning and reinforcement learning.", "conclusion": "EvoLM offers insights into LM training dynamics and releases all models, datasets, and pipelines for open research."}}
{"id": "2506.16038", "pdf": "https://arxiv.org/pdf/2506.16038", "abs": "https://arxiv.org/abs/2506.16038", "authors": ["Masahiko Ueda", "Shoma Yagi", "Genki Ichinose"], "title": "Autocratic strategies in Cournot oligopoly game", "categories": ["physics.soc-ph", "cs.GT", "cs.MA", "cs.SY", "eess.SY"], "comment": "24 pages, 8 figures", "summary": "An oligopoly is a market in which the price of a goods is controlled by a few\nfirms. Cournot introduced the simplest game-theoretic model of oligopoly, where\nprofit-maximizing behavior of each firm results in market failure. Furthermore,\nwhen the Cournot oligopoly game is infinitely repeated, firms can tacitly\ncollude to monopolize the market. Such tacit collusion is realized by the same\nmechanism as direct reciprocity in the repeated prisoner's dilemma game, where\nmutual cooperation can be realized whereas defection is favorable for both\nprisoners in one-shot game. Recently, in the repeated prisoner's dilemma game,\na class of strategies called zero-determinant strategies attracts much\nattention in the context of direct reciprocity. Zero-determinant strategies are\nautocratic strategies which unilaterally control payoffs of players. There were\nmany attempts to find zero-determinant strategies in other games and to extend\nthem so as to apply them to broader situations. In this paper, first, we show\nthat zero-determinant strategies exist even in the repeated Cournot oligopoly\ngame. Especially, we prove that an averagely unbeatable zero-determinant\nstrategy exists, which is guaranteed to obtain the average payoff of the\nopponents. Second, we numerically show that the averagely unbeatable\nzero-determinant strategy can be used to promote collusion when it is used\nagainst an adaptively learning player, whereas it cannot promote collusion when\nit is used against two adaptively learning players. Our findings elucidate some\nnegative impact of zero-determinant strategies in oligopoly market.", "AI": {"tldr": "The paper explores zero-determinant strategies in repeated Cournot oligopoly games, showing their existence and impact on collusion.", "motivation": "To extend zero-determinant strategies from the prisoner's dilemma to oligopoly markets and analyze their effects on tacit collusion.", "method": "Theoretical proof of zero-determinant strategies' existence and numerical simulation of their impact against adaptive learners.", "result": "An averagely unbeatable zero-determinant strategy exists and can promote collusion against one adaptive learner but not two.", "conclusion": "Zero-determinant strategies can negatively influence oligopoly markets by enabling tacit collusion under certain conditions."}}
{"id": "2506.17055", "pdf": "https://arxiv.org/pdf/2506.17055", "abs": "https://arxiv.org/abs/2506.17055", "authors": ["Charilaos Papaioannou", "Emmanouil Benetos", "Alexandros Potamianos"], "title": "Universal Music Representations? Evaluating Foundation Models on World Music Corpora", "categories": ["cs.SD", "cs.IR", "cs.LG", "eess.AS"], "comment": "Accepted at ISMIR 2025", "summary": "Foundation models have revolutionized music information retrieval, but\nquestions remain about their ability to generalize across diverse musical\ntraditions. This paper presents a comprehensive evaluation of five\nstate-of-the-art audio foundation models across six musical corpora spanning\nWestern popular, Greek, Turkish, and Indian classical traditions. We employ\nthree complementary methodologies to investigate these models' cross-cultural\ncapabilities: probing to assess inherent representations, targeted supervised\nfine-tuning of 1-2 layers, and multi-label few-shot learning for low-resource\nscenarios. Our analysis shows varying cross-cultural generalization, with\nlarger models typically outperforming on non-Western music, though results\ndecline for culturally distant traditions. Notably, our approaches achieve\nstate-of-the-art performance on five out of six evaluated datasets,\ndemonstrating the effectiveness of foundation models for world music\nunderstanding. We also find that our targeted fine-tuning approach does not\nconsistently outperform probing across all settings, suggesting foundation\nmodels already encode substantial musical knowledge. Our evaluation framework\nand benchmarking results contribute to understanding how far current models are\nfrom achieving universal music representations while establishing metrics for\nfuture progress.", "AI": {"tldr": "The paper evaluates five audio foundation models across diverse musical traditions, revealing varying cross-cultural generalization and state-of-the-art performance in most cases.", "motivation": "To assess the generalization capabilities of foundation models across diverse musical traditions and address gaps in understanding their cross-cultural performance.", "method": "Three methodologies: probing inherent representations, targeted supervised fine-tuning of 1-2 layers, and multi-label few-shot learning for low-resource scenarios.", "result": "Larger models generally perform better on non-Western music, though performance declines for culturally distant traditions. State-of-the-art results achieved on five of six datasets.", "conclusion": "Foundation models encode substantial musical knowledge, but targeted fine-tuning doesn't always outperform probing. The framework aids in benchmarking future progress toward universal music representations."}}
{"id": "2506.16285", "pdf": "https://arxiv.org/pdf/2506.16285", "abs": "https://arxiv.org/abs/2506.16285", "authors": ["Hao-Chien Lu", "Jhen-Ke Lin", "Hong-Yun Lin", "Chung-Chun Wang", "Berlin Chen"], "title": "Advancing Automated Speaking Assessment Leveraging Multifaceted Relevance and Grammar Information", "categories": ["cs.CL", "cs.SD", "eess.AS"], "comment": "submitted to the ISCA SLaTE-2025 Workshop", "summary": "Current automated speaking assessment (ASA) systems for use in multi-aspect\nevaluations often fail to make full use of content relevance, overlooking image\nor exemplar cues, and employ superficial grammar analysis that lacks detailed\nerror types. This paper ameliorates these deficiencies by introducing two novel\nenhancements to construct a hybrid scoring model. First, a multifaceted\nrelevance module integrates question and the associated image content,\nexemplar, and spoken response of an L2 speaker for a comprehensive assessment\nof content relevance. Second, fine-grained grammar error features are derived\nusing advanced grammar error correction (GEC) and detailed annotation to\nidentify specific error categories. Experiments and ablation studies\ndemonstrate that these components significantly improve the evaluation of\ncontent relevance, language use, and overall ASA performance, highlighting the\nbenefits of using richer, more nuanced feature sets for holistic speaking\nassessment.", "AI": {"tldr": "The paper introduces a hybrid scoring model for automated speaking assessment (ASA) with two enhancements: a multifaceted relevance module and fine-grained grammar error features, improving content relevance and language use evaluation.", "motivation": "Current ASA systems lack comprehensive content relevance analysis and detailed grammar error identification, limiting their effectiveness in multi-aspect evaluations.", "method": "The proposed hybrid model includes a relevance module integrating question, image, exemplar, and spoken response, and fine-grained grammar error features derived from GEC and annotation.", "result": "Experiments show significant improvements in evaluating content relevance, language use, and overall ASA performance.", "conclusion": "Richer, nuanced feature sets enhance holistic speaking assessment, addressing prior deficiencies in ASA systems."}}
{"id": "2506.16116", "pdf": "https://arxiv.org/pdf/2506.16116", "abs": "https://arxiv.org/abs/2506.16116", "authors": ["Ignacio Hern\u00e1ndez Montilla", "Alfonso Medela", "Paola Pasquali", "Andy Aguilar", "Taig Mac Carthy", "Gerardo Fern\u00e1ndez", "Antonio Martorell", "Enrique Onieva"], "title": "Enhanced Dermatology Image Quality Assessment via Cross-Domain Training", "categories": ["eess.IV", "cs.CV"], "comment": "9 pages, 4 figures. This manuscript has been accepted to the 2025\n  12th International Conference on Bioinformatics Research and Applications\n  (ICBRA 2025). It will be published in International Conference Proceedings by\n  ACM, which will be archived in ACM Digital Library, indexed by Ei Compendex\n  and Scopus", "summary": "Teledermatology has become a widely accepted communication method in daily\nclinical practice, enabling remote care while showing strong agreement with\nin-person visits. Poor image quality remains an unsolved problem in\nteledermatology and is a major concern to practitioners, as bad-quality images\nreduce the usefulness of the remote consultation process. However, research on\nImage Quality Assessment (IQA) in dermatology is sparse, and does not leverage\nthe latest advances in non-dermatology IQA, such as using larger image\ndatabases with ratings from large groups of human observers. In this work, we\npropose cross-domain training of IQA models, combining dermatology and\nnon-dermatology IQA datasets. For this purpose, we created a novel dermatology\nIQA database, Legit.Health-DIQA-Artificial, using dermatology images from\nseveral sources and having them annotated by a group of human observers. We\ndemonstrate that cross-domain training yields optimal performance across\ndomains and overcomes one of the biggest limitations in dermatology IQA, which\nis the small scale of data, and leads to models trained on a larger pool of\nimage distortions, resulting in a better management of image quality in the\nteledermatology process.", "AI": {"tldr": "The paper proposes cross-domain training for Image Quality Assessment (IQA) in teledermatology, combining dermatology and non-dermatology datasets to improve image quality management.", "motivation": "Poor image quality in teledermatology reduces consultation effectiveness, but existing dermatology IQA research lacks large datasets and advanced methods.", "method": "Created a new dermatology IQA database (Legit.Health-DIQA-Artificial) and used cross-domain training with non-dermatology IQA datasets.", "result": "Cross-domain training improves performance by leveraging larger datasets and diverse image distortions, enhancing teledermatology image quality.", "conclusion": "Cross-domain IQA training addresses data limitations in dermatology, improving image quality management for remote consultations."}}
{"id": "2506.15871", "pdf": "https://arxiv.org/pdf/2506.15871", "abs": "https://arxiv.org/abs/2506.15871", "authors": ["Rim Assouel", "Declan Campbell", "Taylor Webb"], "title": "Visual symbolic mechanisms: Emergent symbol processing in vision language models", "categories": ["cs.CV"], "comment": null, "summary": "To accurately process a visual scene, observers must bind features together\nto represent individual objects. This capacity is necessary, for instance, to\ndistinguish an image containing a red square and a blue circle from an image\ncontaining a blue square and a red circle. Recent work has found that language\nmodels solve this 'binding problem' via a set of symbol-like,\ncontent-independent indices, but it is unclear whether similar mechanisms are\nemployed by vision language models (VLMs). This question is especially\nrelevant, given the persistent failures of VLMs on tasks that require binding.\nHere, we identify a set of emergent symbolic mechanisms that support binding in\nVLMs via a content-independent, spatial indexing scheme. Moreover, we find that\nbinding errors can be traced directly to failures in these mechanisms. Taken\ntogether, these results shed light on the mechanisms that support symbol-like\nprocessing in VLMs, and suggest possible avenues for addressing the persistent\nbinding failures exhibited by these models.", "AI": {"tldr": "The paper explores how vision language models (VLMs) solve the 'binding problem' using symbolic mechanisms and identifies failures in these mechanisms as the cause of binding errors.", "motivation": "Understanding how VLMs bind features to represent objects, given their persistent failures in such tasks.", "method": "Investigates emergent symbolic mechanisms in VLMs, focusing on a content-independent, spatial indexing scheme.", "result": "Identifies symbolic mechanisms supporting binding in VLMs and traces binding errors to failures in these mechanisms.", "conclusion": "The findings reveal symbol-like processing in VLMs and suggest ways to address their binding failures."}}
{"id": "2506.15693", "pdf": "https://arxiv.org/pdf/2506.15693", "abs": "https://arxiv.org/abs/2506.15693", "authors": ["Jiaxing Li", "Hanjiang Hu", "Yujie Yang", "Changliu Liu"], "title": "Verifiable Safety Q-Filters via Hamilton-Jacobi Reachability and Multiplicative Q-Networks", "categories": ["cs.LG"], "comment": "6 pages, 3 figures", "summary": "Recent learning-based safety filters have outperformed conventional methods,\nsuch as hand-crafted Control Barrier Functions (CBFs), by effectively adapting\nto complex constraints. However, these learning-based approaches lack formal\nsafety guarantees. In this work, we introduce a verifiable model-free safety\nfilter based on Hamilton-Jacobi reachability analysis. Our primary\ncontributions include: 1) extending verifiable self-consistency properties for\nQ value functions, 2) proposing a multiplicative Q-network structure to\nmitigate zero-sublevel-set shrinkage issues, and 3) developing a verification\npipeline capable of soundly verifying these self-consistency properties. Our\nproposed approach successfully synthesizes formally verified, model-free safety\ncertificates across four standard safe-control benchmarks.", "AI": {"tldr": "A verifiable model-free safety filter using Hamilton-Jacobi reachability is introduced, addressing the lack of formal guarantees in learning-based safety filters.", "motivation": "Learning-based safety filters outperform conventional methods but lack formal safety guarantees, prompting the need for verifiable solutions.", "method": "Extends verifiable self-consistency for Q value functions, introduces a multiplicative Q-network to prevent shrinkage, and develops a verification pipeline.", "result": "Successfully synthesizes formally verified, model-free safety certificates in four safe-control benchmarks.", "conclusion": "The proposed approach provides formally verified safety guarantees, advancing the reliability of learning-based safety filters."}}
{"id": "2506.15774", "pdf": "https://arxiv.org/pdf/2506.15774", "abs": "https://arxiv.org/abs/2506.15774", "authors": ["J. Schwardt", "J. C. Budich"], "title": "Advancing Stochastic 3-SAT Solvers by Dissipating Oversatisfied Constraints", "categories": ["cs.AI", "cond-mat.stat-mech", "cs.DS", "math.CO", "68Q25, 68W20, 90C27"], "comment": "5+1 pages, 6+2 figures", "summary": "We introduce and benchmark a stochastic local search heuristic for the\nNP-complete satisfiability problem 3-SAT that drastically outperforms existing\nsolvers in the notoriously difficult realm of critically hard instances. Our\nconstruction is based on the crucial observation that well established previous\napproaches such as WalkSAT are prone to get stuck in local minima that are\ndistinguished from true solutions by a larger number of oversatisfied\ncombinatorial constraints. To address this issue, the proposed algorithm,\ncoined DOCSAT, dissipates oversatisfied constraints (DOC), i.e. reduces their\nunfavorable abundance so as to render them critical. We analyze and benchmark\nour algorithm on a randomly generated sample of hard but satisfiable 3-SAT\ninstances with varying problem sizes up to N=15000. Quite remarkably, we find\nthat DOCSAT outperforms both WalkSAT and other well known algorithms including\nthe complete solver Kissat, even when comparing its ability to solve the\nhardest quintile of the sample to the average performance of its competitors.\nThe essence of DOCSAT may be seen as a way of harnessing statistical structure\nbeyond the primary cost function of a combinatorial problem to avoid or escape\nlocal minima traps in stochastic local search, which opens avenues for\ngeneralization to other optimization problems.", "AI": {"tldr": "DOCSAT, a new stochastic local search heuristic for 3-SAT, outperforms existing solvers like WalkSAT and Kissat by addressing oversatisfied constraints, especially in hard instances.", "motivation": "Existing solvers like WalkSAT get stuck in local minima due to oversatisfied constraints, limiting performance on hard 3-SAT instances.", "method": "DOCSAT dissipates oversatisfied constraints (DOC) to reduce their abundance and escape local minima.", "result": "DOCSAT outperforms WalkSAT and Kissat on hard 3-SAT instances up to N=15000, even in the hardest quintile.", "conclusion": "DOCSAT's approach of leveraging statistical structure beyond the primary cost function can generalize to other optimization problems."}}
{"id": "2506.16037", "pdf": "https://arxiv.org/pdf/2506.16037", "abs": "https://arxiv.org/abs/2506.16037", "authors": ["Xinyue Huang", "Ziqi Lin", "Fang Sun", "Wenchao Zhang", "Kejian Tong", "Yunbo Liu"], "title": "Enhancing Document-Level Question Answering via Multi-Hop Retrieval-Augmented Generation with LLaMA 3", "categories": ["cs.CL", "cs.LG"], "comment": null, "summary": "This paper presents a novel Retrieval-Augmented Generation (RAG) framework\ntailored for complex question answering tasks, addressing challenges in\nmulti-hop reasoning and contextual understanding across lengthy documents.\nBuilt upon LLaMA 3, the framework integrates a dense retrieval module with\nadvanced context fusion and multi-hop reasoning mechanisms, enabling more\naccurate and coherent response generation. A joint optimization strategy\ncombining retrieval likelihood and generation cross-entropy improves the\nmodel's robustness and adaptability. Experimental results show that the\nproposed system outperforms existing retrieval-augmented and generative\nbaselines, confirming its effectiveness in delivering precise, contextually\ngrounded answers.", "AI": {"tldr": "A novel RAG framework for complex QA tasks improves multi-hop reasoning and contextual understanding, outperforming existing baselines.", "motivation": "Address challenges in multi-hop reasoning and contextual understanding for complex QA tasks.", "method": "Integrates dense retrieval with context fusion and multi-hop reasoning, using LLaMA 3 and joint optimization of retrieval likelihood and generation cross-entropy.", "result": "Outperforms existing retrieval-augmented and generative baselines.", "conclusion": "The framework is effective for precise, contextually grounded answers in complex QA."}}
{"id": "2506.16120", "pdf": "https://arxiv.org/pdf/2506.16120", "abs": "https://arxiv.org/abs/2506.16120", "authors": ["Fivos Kalogiannis", "Emmanouil-Vasileios Vlatakis-Gkaragkounis", "Ian Gemp", "Georgios Piliouras"], "title": "Solving Zero-Sum Convex Markov Games", "categories": ["cs.GT", "cs.LG", "cs.MA", "math.OC"], "comment": "To appear in the Proceedings of the 2025 International Conference on\n  Machine Learning (ICML 2025)", "summary": "We contribute the first provable guarantees of global convergence to Nash\nequilibria (NE) in two-player zero-sum convex Markov games (cMGs) by using\nindependent policy gradient methods. Convex Markov games, recently defined by\nGemp et al. (2024), extend Markov decision processes to multi-agent settings\nwith preferences that are convex over occupancy measures, offering a broad\nframework for modeling generic strategic interactions. However, even the\nfundamental min-max case of cMGs presents significant challenges, including\ninherent nonconvexity, the absence of Bellman consistency, and the complexity\nof the infinite horizon.\n  We follow a two-step approach. First, leveraging properties of\nhidden-convex--hidden-concave functions, we show that a simple nonconvex\nregularization transforms the min-max optimization problem into a\nnonconvex-proximal Polyak-Lojasiewicz (NC-pPL) objective. Crucially, this\nregularization can stabilize the iterates of independent policy gradient\nmethods and ultimately lead them to converge to equilibria. Second, building on\nthis reduction, we address the general constrained min-max problems under\nNC-pPL and two-sided pPL conditions, providing the first global convergence\nguarantees for stochastic nested and alternating gradient descent-ascent\nmethods, which we believe may be of independent interest.", "AI": {"tldr": "The paper provides the first provable guarantees for global convergence to Nash equilibria in two-player zero-sum convex Markov games using independent policy gradient methods.", "motivation": "Addressing the challenges of nonconvexity, lack of Bellman consistency, and infinite horizon complexity in convex Markov games.", "method": "A two-step approach: transforming the min-max problem into a nonconvex-proximal Polyak-Lojasiewicz objective via regularization, then analyzing global convergence under NC-pPL and two-sided pPL conditions.", "result": "Demonstrates global convergence guarantees for stochastic nested and alternating gradient descent-ascent methods.", "conclusion": "The approach stabilizes policy gradient methods and ensures convergence to equilibria, offering a framework for strategic interactions in multi-agent settings."}}
{"id": "2506.16310", "pdf": "https://arxiv.org/pdf/2506.16310", "abs": "https://arxiv.org/abs/2506.16310", "authors": ["Pranav Pawar", "Akshansh Dwivedi", "Jenish Boricha", "Himanshu Gohil", "Aditya Dubey"], "title": "Optimizing Multilingual Text-To-Speech with Accents & Emotions", "categories": ["cs.LG", "cs.HC", "cs.SD", "eess.AS"], "comment": "12 pages, 8 figures", "summary": "State-of-the-art text-to-speech (TTS) systems realize high naturalness in\nmonolingual environments, synthesizing speech with correct multilingual accents\n(especially for Indic languages) and context-relevant emotions still poses\ndifficulty owing to cultural nuance discrepancies in current frameworks. This\npaper introduces a new TTS architecture integrating accent along with\npreserving transliteration with multi-scale emotion modelling, in particularly\ntuned for Hindi and Indian English accent. Our approach extends the Parler-TTS\nmodel by integrating A language-specific phoneme alignment hybrid\nencoder-decoder architecture, and culture-sensitive emotion embedding layers\ntrained on native speaker corpora, as well as incorporating a dynamic accent\ncode switching with residual vector quantization. Quantitative tests\ndemonstrate 23.7% improvement in accent accuracy (Word Error Rate reduction\nfrom 15.4% to 11.8%) and 85.3% emotion recognition accuracy from native\nlisteners, surpassing METTS and VECL-TTS baselines. The novelty of the system\nis that it can mix code in real time - generating statements such as \"Namaste,\nlet's talk about <Hindi phrase>\" with uninterrupted accent shifts while\npreserving emotional consistency. Subjective evaluation with 200 users reported\na mean opinion score (MOS) of 4.2/5 for cultural correctness, much better than\nexisting multilingual systems (p<0.01). This research makes cross-lingual\nsynthesis more feasible by showcasing scalable accent-emotion disentanglement,\nwith direct application in South Asian EdTech and accessibility software.", "AI": {"tldr": "A new TTS architecture improves multilingual accent accuracy and emotion synthesis for Hindi and Indian English, outperforming existing systems.", "motivation": "Current TTS systems struggle with multilingual accents and context-relevant emotions due to cultural nuances, especially for Indic languages.", "method": "Extends Parler-TTS with a hybrid encoder-decoder, culture-sensitive emotion layers, and dynamic accent code switching.", "result": "23.7% accent accuracy improvement, 85.3% emotion recognition, and 4.2/5 MOS for cultural correctness.", "conclusion": "The system advances cross-lingual synthesis with scalable accent-emotion disentanglement, useful for EdTech and accessibility."}}
{"id": "2506.16381", "pdf": "https://arxiv.org/pdf/2506.16381", "abs": "https://arxiv.org/abs/2506.16381", "authors": ["Kexin Huang", "Qian Tu", "Liwei Fan", "Chenchen Yang", "Dong Zhang", "Shimin Li", "Zhaoye Fei", "Qinyuan Cheng", "Xipeng Qiu"], "title": "InstructTTSEval: Benchmarking Complex Natural-Language Instruction Following in Text-to-Speech Systems", "categories": ["cs.CL", "cs.SD", "eess.AS"], "comment": "19 pages, 9 figures", "summary": "In modern speech synthesis, paralinguistic information--such as a speaker's\nvocal timbre, emotional state, and dynamic prosody--plays a critical role in\nconveying nuance beyond mere semantics. Traditional Text-to-Speech (TTS)\nsystems rely on fixed style labels or inserting a speech prompt to control\nthese cues, which severely limits flexibility. Recent attempts seek to employ\nnatural-language instructions to modulate paralinguistic features,\nsubstantially improving the generalization of instruction-driven TTS models.\nAlthough many TTS systems now support customized synthesis via textual\ndescription, their actual ability to interpret and execute complex instructions\nremains largely unexplored. In addition, there is still a shortage of\nhigh-quality benchmarks and automated evaluation metrics specifically designed\nfor instruction-based TTS, which hinders accurate assessment and iterative\noptimization of these models. To address these limitations, we introduce\nInstructTTSEval, a benchmark for measuring the capability of complex\nnatural-language style control. We introduce three tasks, namely\nAcoustic-Parameter Specification, Descriptive-Style Directive, and Role-Play,\nincluding English and Chinese subsets, each with 1k test cases (6k in total)\npaired with reference audio. We leverage Gemini as an automatic judge to assess\ntheir instruction-following abilities. Our evaluation of accessible\ninstruction-following TTS systems highlights substantial room for further\nimprovement. We anticipate that InstructTTSEval will drive progress toward more\npowerful, flexible, and accurate instruction-following TTS.", "AI": {"tldr": "The paper introduces InstructTTSEval, a benchmark for evaluating instruction-driven TTS systems' ability to handle complex natural-language style control, addressing gaps in current evaluation methods.", "motivation": "Traditional TTS systems lack flexibility in controlling paralinguistic features, and there's a shortage of high-quality benchmarks for evaluating instruction-based TTS models.", "method": "The authors propose InstructTTSEval, a benchmark with three tasks (Acoustic-Parameter Specification, Descriptive-Style Directive, Role-Play) across English and Chinese, using Gemini as an automatic judge.", "result": "Evaluation reveals significant room for improvement in current instruction-following TTS systems.", "conclusion": "InstructTTSEval aims to advance the development of more flexible and accurate instruction-driven TTS models."}}
{"id": "2506.16210", "pdf": "https://arxiv.org/pdf/2506.16210", "abs": "https://arxiv.org/abs/2506.16210", "authors": ["Zhenxuan Zhang", "Lipei Zhang", "Yanqi Cheng", "Zi Wang", "Fanwen Wang", "Haosen Zhang", "Yue Yang", "Yinzhe Wu", "Jiahao Huang", "Angelica I Aviles-Rivero", "Zhifan Gao", "Guang Yang", "Peter J. Lally"], "title": "From Coarse to Continuous: Progressive Refinement Implicit Neural Representation for Motion-Robust Anisotropic MRI Reconstruction", "categories": ["eess.IV", "cs.CV"], "comment": null, "summary": "In motion-robust magnetic resonance imaging (MRI), slice-to-volume\nreconstruction is critical for recovering anatomically consistent 3D brain\nvolumes from 2D slices, especially under accelerated acquisitions or patient\nmotion. However, this task remains challenging due to hierarchical structural\ndisruptions. It includes local detail loss from k-space undersampling, global\nstructural aliasing caused by motion, and volumetric anisotropy. Therefore, we\npropose a progressive refinement implicit neural representation (PR-INR)\nframework. Our PR-INR unifies motion correction, structural refinement, and\nvolumetric synthesis within a geometry-aware coordinate space. Specifically, a\nmotion-aware diffusion module is first employed to generate coarse volumetric\nreconstructions that suppress motion artifacts and preserve global anatomical\nstructures. Then, we introduce an implicit detail restoration module that\nperforms residual refinement by aligning spatial coordinates with visual\nfeatures. It corrects local structures and enhances boundary precision.\nFurther, a voxel continuous-aware representation module represents the image as\na continuous function over 3D coordinates. It enables accurate inter-slice\ncompletion and high-frequency detail recovery. We evaluate PR-INR on five\npublic MRI datasets under various motion conditions (3% and 5% displacement),\nundersampling rates (4x and 8x) and slice resolutions (scale = 5). Experimental\nresults demonstrate that PR-INR outperforms state-of-the-art methods in both\nquantitative reconstruction metrics and visual quality. It further shows\ngeneralization and robustness across diverse unseen domains.", "AI": {"tldr": "A progressive refinement implicit neural representation (PR-INR) framework is proposed for motion-robust MRI, unifying motion correction, structural refinement, and volumetric synthesis to address hierarchical disruptions in slice-to-volume reconstruction.", "motivation": "Slice-to-volume reconstruction in MRI is challenging due to local detail loss, global structural aliasing, and volumetric anisotropy caused by motion and undersampling.", "method": "PR-INR integrates a motion-aware diffusion module for coarse reconstruction, an implicit detail restoration module for local refinement, and a voxel continuous-aware representation module for inter-slice completion.", "result": "PR-INR outperforms state-of-the-art methods in reconstruction metrics and visual quality, demonstrating robustness across diverse conditions.", "conclusion": "The PR-INR framework effectively addresses motion and undersampling challenges in MRI, offering superior reconstruction and generalization."}}
{"id": "2506.15908", "pdf": "https://arxiv.org/pdf/2506.15908", "abs": "https://arxiv.org/abs/2506.15908", "authors": ["Elif Keles", "Merve Yazol", "Gorkem Durak", "Ziliang Hong", "Halil Ertugrul Aktas", "Zheyuan Zhang", "Linkai Peng", "Onkar Susladkar", "Necati Guzelyel", "Oznur Leman Boyunaga", "Cemal Yazici", "Mark Lowe", "Aliye Uc", "Ulas Bagci"], "title": "Pediatric Pancreas Segmentation from MRI Scans with Deep Learning", "categories": ["cs.CV", "cs.LG"], "comment": "Code and MRI data available for public", "summary": "Objective: Our study aimed to evaluate and validate PanSegNet, a deep\nlearning (DL) algorithm for pediatric pancreas segmentation on MRI in children\nwith acute pancreatitis (AP), chronic pancreatitis (CP), and healthy controls.\nMethods: With IRB approval, we retrospectively collected 84 MRI scans (1.5T/3T\nSiemens Aera/Verio) from children aged 2-19 years at Gazi University\n(2015-2024). The dataset includes healthy children as well as patients\ndiagnosed with AP or CP based on clinical criteria. Pediatric and general\nradiologists manually segmented the pancreas, then confirmed by a senior\npediatric radiologist. PanSegNet-generated segmentations were assessed using\nDice Similarity Coefficient (DSC) and 95th percentile Hausdorff distance\n(HD95). Cohen's kappa measured observer agreement. Results: Pancreas MRI T2W\nscans were obtained from 42 children with AP/CP (mean age: 11.73 +/- 3.9 years)\nand 42 healthy children (mean age: 11.19 +/- 4.88 years). PanSegNet achieved\nDSC scores of 88% (controls), 81% (AP), and 80% (CP), with HD95 values of 3.98\nmm (controls), 9.85 mm (AP), and 15.67 mm (CP). Inter-observer kappa was 0.86\n(controls), 0.82 (pancreatitis), and intra-observer agreement reached 0.88 and\n0.81. Strong agreement was observed between automated and manual volumes (R^2 =\n0.85 in controls, 0.77 in diseased), demonstrating clinical reliability.\nConclusion: PanSegNet represents the first validated deep learning solution for\npancreatic MRI segmentation, achieving expert-level performance across healthy\nand diseased states. This tool, algorithm, along with our annotated dataset,\nare freely available on GitHub and OSF, advancing accessible, radiation-free\npediatric pancreatic imaging and fostering collaborative research in this\nunderserved domain.", "AI": {"tldr": "PanSegNet, a DL algorithm for pediatric pancreas segmentation on MRI, was validated in children with AP, CP, and healthy controls, achieving expert-level performance.", "motivation": "To provide a reliable, radiation-free tool for pediatric pancreatic MRI segmentation, addressing a gap in this underserved domain.", "method": "Retrospective analysis of 84 MRI scans with manual segmentation by radiologists, evaluated using DSC, HD95, and Cohen's kappa.", "result": "DSC scores: 88% (controls), 81% (AP), 80% (CP). HD95: 3.98 mm (controls), 9.85 mm (AP), 15.67 mm (CP). Strong agreement between automated and manual volumes.", "conclusion": "PanSegNet is the first validated DL solution for pancreatic MRI segmentation, with expert-level performance, freely available for collaborative research."}}
{"id": "2506.15694", "pdf": "https://arxiv.org/pdf/2506.15694", "abs": "https://arxiv.org/abs/2506.15694", "authors": ["Iliyas Ibrahim Iliyas", "Souley Boukari", "Abdulsalam Yau Gital"], "title": "Development of a Multiprocessing Interface Genetic Algorithm for Optimising a Multilayer Perceptron for Disease Prediction", "categories": ["cs.LG"], "comment": null, "summary": "This study introduces a framework that integrates nonlinear feature\nextraction, classification, and efficient optimization. First, kernel principal\ncomponent analysis with a radial basis function kernel reduces dimensionality\nwhile preserving 95% of the variance. Second, a multilayer perceptron (MLP)\nlearns to predict disease status. Finally, a modified multiprocessing genetic\nalgorithm (MIGA) optimizes MLP hyperparameters in parallel over ten\ngenerations. We evaluated this approach on three datasets: the Wisconsin\nDiagnostic Breast Cancer dataset, the Parkinson's Telemonitoring dataset, and\nthe chronic kidney disease dataset. The MLP tuned by the MIGA achieved the best\naccuracy of 99.12% for breast cancer, 94.87% for Parkinson's disease, and 100%\nfor chronic kidney disease. These results outperform those of other methods,\nsuch as grid search, random search, and Bayesian optimization. Compared with a\nstandard genetic algorithm, kernel PCA revealed nonlinear relationships that\nimproved classification, and the MIGA's parallel fitness evaluations reduced\nthe tuning time by approximately 60%. The genetic algorithm incurs high\ncomputational cost from sequential fitness evaluations, but our multiprocessing\ninterface GA (MIGA) parallelizes this step, slashing the tuning time and\nsteering the MLP toward the best accuracy score of 99.12%, 94.87%, and 100% for\nbreast cancer, Parkinson's disease, and CKD, respectively.", "AI": {"tldr": "A framework combining kernel PCA, MLP, and MIGA for disease prediction achieves high accuracy (up to 100%) and reduces tuning time by 60%.", "motivation": "To improve disease prediction accuracy and reduce computational costs in hyperparameter optimization.", "method": "Uses kernel PCA for dimensionality reduction, MLP for classification, and MIGA for parallel hyperparameter optimization.", "result": "Achieved 99.12% (breast cancer), 94.87% (Parkinson's), and 100% (CKD) accuracy, outperforming other methods.", "conclusion": "The framework is effective for disease prediction, with MIGA significantly reducing tuning time and improving accuracy."}}
{"id": "2506.15787", "pdf": "https://arxiv.org/pdf/2506.15787", "abs": "https://arxiv.org/abs/2506.15787", "authors": ["Lukas Helff", "Ahmad Omar", "Felix Friedrich", "Wolfgang Stammer", "Antonia W\u00fcst", "Tim Woydt", "Rupert Mitchell", "Patrick Schramowski", "Kristian Kersting"], "title": "SLR: An Automated Synthesis Framework for Scalable Logical Reasoning", "categories": ["cs.AI", "cs.CL", "cs.LG"], "comment": null, "summary": "We introduce SLR, an end-to-end framework for systematic evaluation and\ntraining of Large Language Models (LLMs) via Scalable Logical Reasoning. Given\na user's task specification, SLR enables scalable, automated synthesis of\ninductive reasoning tasks with precisely controlled difficulty. For each task,\nSLR synthesizes (i) a latent ground-truth rule, (ii) an executable validation\nprogram used by a symbolic judge to deterministically verify model outputs, and\n(iii) an instruction prompt for the reasoning task. Using SLR, we create\nSLR-Bench, a benchmark comprising over 19k prompts spanning 20 curriculum\nlevels that progressively increase in relational, arithmetic, and recursive\ncomplexity. Large-scale evaluation reveals that contemporary LLMs readily\nproduce syntactically valid rules, yet often fail at correct logical inference.\nRecent reasoning LLMs do somewhat better, but incur substantial increases in\ntest-time compute, sometimes exceeding 15k completion tokens. Finally,\nlogic-tuning via SLR doubles Llama-3-8B accuracy on SLR-Bench, achieving parity\nwith Gemini-Flash-Thinking at a fraction of computational cost. SLR is fully\nautomated, requires no human annotation, ensures dataset novelty, and offers a\nscalable environment for probing and advancing LLMs' reasoning capabilities.", "AI": {"tldr": "SLR is a framework for scalable, automated evaluation and training of LLMs via logical reasoning, creating tasks with controlled difficulty and no human annotation.", "motivation": "To systematically evaluate and improve LLMs' logical reasoning capabilities without relying on human annotation or existing datasets.", "method": "SLR synthesizes tasks with ground-truth rules, validation programs, and prompts, creating the SLR-Bench benchmark with 19k prompts across 20 difficulty levels.", "result": "LLMs often fail at correct logical inference despite producing valid rules. Logic-tuning via SLR doubles Llama-3-8B accuracy, matching Gemini-Flash-Thinking at lower cost.", "conclusion": "SLR provides a scalable, automated way to probe and enhance LLMs' reasoning, ensuring novelty and efficiency."}}
{"id": "2506.16043", "pdf": "https://arxiv.org/pdf/2506.16043", "abs": "https://arxiv.org/abs/2506.16043", "authors": ["Fei Wang", "Xingchen Wan", "Ruoxi Sun", "Jiefeng Chen", "Sercan \u00d6. Ar\u0131k"], "title": "DynScaling: Efficient Verifier-free Inference Scaling via Dynamic and Integrated Sampling", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "Inference-time scaling has proven effective in boosting large language model\n(LLM) performance through increased test-time computation. Yet, its practical\napplication is often hindered by reliance on external verifiers or a lack of\noptimization for realistic computational constraints. We propose DynScaling,\nwhich addresses these limitations through two primary innovations: an\nintegrated parallel-sequential sampling strategy and a bandit-based dynamic\nbudget allocation framework. The integrated sampling strategy unifies parallel\nand sequential sampling by constructing synthetic sequential reasoning chains\nfrom initially independent parallel responses, promoting diverse and coherent\nreasoning trajectories. The dynamic budget allocation framework formulates the\nallocation of computational resources as a multi-armed bandit problem,\nadaptively distributing the inference budget across queries based on the\nuncertainty of previously sampled responses, thereby maximizing computational\nefficiency. By combining these components, DynScaling effectively improves LLM\nperformance under practical resource constraints without the need for external\nverifiers. Experimental results demonstrate that DynScaling consistently\nsurpasses existing verifier-free inference scaling baselines in both task\nperformance and computational cost.", "AI": {"tldr": "DynScaling improves LLM performance under resource constraints by integrating parallel-sequential sampling and dynamic budget allocation, outperforming existing methods.", "motivation": "Overcome limitations of inference-time scaling, such as reliance on external verifiers and lack of optimization for computational constraints.", "method": "Integrated parallel-sequential sampling and bandit-based dynamic budget allocation.", "result": "DynScaling surpasses verifier-free baselines in performance and computational efficiency.", "conclusion": "DynScaling is a practical and efficient solution for enhancing LLM performance without external verifiers."}}
{"id": "2506.16336", "pdf": "https://arxiv.org/pdf/2506.16336", "abs": "https://arxiv.org/abs/2506.16336", "authors": ["Yiou Huang"], "title": "Goal-conditioned Hierarchical Reinforcement Learning for Sample-efficient and Safe Autonomous Driving at Intersections", "categories": ["cs.RO", "cs.MA"], "comment": null, "summary": "Reinforcement learning (RL) exhibits remarkable potential in addressing\nautonomous driving tasks. However, it is difficult to train a sample-efficient\nand safe policy in complex scenarios. In this article, we propose a novel\nhierarchical reinforcement learning (HRL) framework with a goal-conditioned\ncollision prediction (GCCP) module. In the hierarchical structure, the GCCP\nmodule predicts collision risks according to different potential subgoals of\nthe ego vehicle. A high-level decision-maker choose the best safe subgoal. A\nlow-level motion-planner interacts with the environment according to the\nsubgoal. Compared to traditional RL methods, our algorithm is more\nsample-efficient, since its hierarchical structure allows reusing the policies\nof subgoals across similar tasks for various navigation scenarios. In\nadditional, the GCCP module's ability to predict both the ego vehicle's and\nsurrounding vehicles' future actions according to different subgoals, ensures\nthe safety of the ego vehicle throughout the decision-making process.\nExperimental results demonstrate that the proposed method converges to an\noptimal policy faster and achieves higher safety than traditional RL methods.", "AI": {"tldr": "A hierarchical RL framework with a goal-conditioned collision prediction module improves sample efficiency and safety in autonomous driving.", "motivation": "Training sample-efficient and safe RL policies in complex autonomous driving scenarios is challenging.", "method": "Proposes a hierarchical RL framework with a GCCP module for collision risk prediction and subgoal selection, alongside a high-level decision-maker and low-level motion-planner.", "result": "The method converges faster to optimal policies and ensures higher safety compared to traditional RL.", "conclusion": "The hierarchical approach with GCCP enhances efficiency and safety in autonomous driving tasks."}}
{"id": "2506.16558", "pdf": "https://arxiv.org/pdf/2506.16558", "abs": "https://arxiv.org/abs/2506.16558", "authors": ["Dana Serditova", "Kevin Tang", "Jochen Steffens"], "title": "Automatic Speech Recognition Biases in Newcastle English: an Error Analysis", "categories": ["cs.CL", "cs.CY", "cs.SD", "eess.AS"], "comment": "Submitted to Interspeech 2025", "summary": "Automatic Speech Recognition (ASR) systems struggle with regional dialects\ndue to biased training which favours mainstream varieties. While previous\nresearch has identified racial, age, and gender biases in ASR, regional bias\nremains underexamined. This study investigates ASR performance on Newcastle\nEnglish, a well-documented regional dialect known to be challenging for ASR. A\ntwo-stage analysis was conducted: first, a manual error analysis on a subsample\nidentified key phonological, lexical, and morphosyntactic errors behind ASR\nmisrecognitions; second, a case study focused on the systematic analysis of ASR\nrecognition of the regional pronouns ``yous'' and ``wor''. Results show that\nASR errors directly correlate with regional dialectal features, while social\nfactors play a lesser role in ASR mismatches. We advocate for greater dialectal\ndiversity in ASR training data and highlight the value of sociolinguistic\nanalysis in diagnosing and addressing regional biases.", "AI": {"tldr": "ASR systems perform poorly on regional dialects like Newcastle English due to biased training. This study identifies dialectal features as the main cause of errors, advocating for more diverse training data.", "motivation": "To address the underexamined issue of regional bias in ASR systems, focusing on Newcastle English, a challenging dialect.", "method": "A two-stage analysis: manual error analysis of phonological, lexical, and morphosyntactic errors, followed by a case study on regional pronouns.", "result": "ASR errors correlate with dialectal features; social factors have minimal impact.", "conclusion": "Greater dialectal diversity in training data and sociolinguistic analysis are needed to mitigate regional biases."}}
{"id": "2506.16574", "pdf": "https://arxiv.org/pdf/2506.16574", "abs": "https://arxiv.org/abs/2506.16574", "authors": ["Enes Yavuz Ugan", "Ngoc-Quan Pham", "Alexander Waibel"], "title": "Weight Factorization and Centralization for Continual Learning in Speech Recognition", "categories": ["cs.CL", "cs.SD", "eess.AS"], "comment": "Accepted to INTERSPEECH 2025", "summary": "Modern neural network based speech recognition models are required to\ncontinually absorb new data without re-training the whole system, especially in\ndownstream applications using foundation models, having no access to the\noriginal training data. Continually training the models in a rehearsal-free,\nmultilingual, and language agnostic condition, likely leads to catastrophic\nforgetting, when a seemingly insignificant disruption to the weights can\ndestructively harm the quality of the models. Inspired by the ability of human\nbrains to learn and consolidate knowledge through the waking-sleeping cycle, we\npropose a continual learning approach with two distinct phases: factorization\nand centralization, learning and merging knowledge accordingly. Our experiments\non a sequence of varied code-switching datasets showed that the centralization\nstage can effectively prevent catastrophic forgetting by accumulating the\nknowledge in multiple scattering low-rank adapters.", "AI": {"tldr": "A continual learning approach for neural speech recognition models prevents catastrophic forgetting using factorization and centralization phases, inspired by human brain learning cycles.", "motivation": "To enable neural networks to absorb new data without re-training, avoiding catastrophic forgetting in rehearsal-free, multilingual settings.", "method": "Proposes a two-phase approach: factorization for learning and centralization for merging knowledge, using low-rank adapters.", "result": "Effective prevention of catastrophic forgetting in experiments with varied code-switching datasets.", "conclusion": "The centralization phase successfully accumulates knowledge, maintaining model quality without re-training."}}
{"id": "2506.16213", "pdf": "https://arxiv.org/pdf/2506.16213", "abs": "https://arxiv.org/abs/2506.16213", "authors": ["Raghav Mehta", "Fabio De Sousa Ribeiro", "Tian Xia", "Melanie Roschewitz", "Ainkaran Santhirasekaram", "Dominic C. Marshall", "Ben Glocker"], "title": "CF-Seg: Counterfactuals meet Segmentation", "categories": ["eess.IV", "cs.AI", "cs.CV"], "comment": "Accepted at MICCAI 2025", "summary": "Segmenting anatomical structures in medical images plays an important role in\nthe quantitative assessment of various diseases. However, accurate segmentation\nbecomes significantly more challenging in the presence of disease. Disease\npatterns can alter the appearance of surrounding healthy tissues, introduce\nambiguous boundaries, or even obscure critical anatomical structures. As such,\nsegmentation models trained on real-world datasets may struggle to provide good\nanatomical segmentation, leading to potential misdiagnosis. In this paper, we\ngenerate counterfactual (CF) images to simulate how the same anatomy would\nappear in the absence of disease without altering the underlying structure. We\nthen use these CF images to segment structures of interest, without requiring\nany changes to the underlying segmentation model. Our experiments on two\nreal-world clinical chest X-ray datasets show that the use of counterfactual\nimages improves anatomical segmentation, thereby aiding downstream clinical\ndecision-making.", "AI": {"tldr": "Using counterfactual images to improve anatomical segmentation in medical images by simulating disease-free appearances.", "motivation": "Accurate segmentation is challenging due to disease-altered appearances and ambiguous boundaries, risking misdiagnosis.", "method": "Generate counterfactual images to simulate disease-free anatomy and use them for segmentation without modifying the model.", "result": "Experiments on chest X-ray datasets show improved anatomical segmentation.", "conclusion": "Counterfactual images enhance segmentation accuracy, supporting better clinical decisions."}}
{"id": "2506.15929", "pdf": "https://arxiv.org/pdf/2506.15929", "abs": "https://arxiv.org/abs/2506.15929", "authors": ["Liangyan Li", "Yimo Ning", "Kevin Le", "Wei Dong", "Yunzhe Li", "Jun Chen", "Xiaohong Liu"], "title": "Moir\u00e9XNet: Adaptive Multi-Scale Demoir\u00e9ing with Linear Attention Test-Time Training and Truncated Flow Matching Prior", "categories": ["cs.CV", "cs.AI", "eess.IV"], "comment": null, "summary": "This paper introduces a novel framework for image and video demoir\\'eing by\nintegrating Maximum A Posteriori (MAP) estimation with advanced deep learning\ntechniques. Demoir\\'eing addresses inherently nonlinear degradation processes,\nwhich pose significant challenges for existing methods.\n  Traditional supervised learning approaches either fail to remove moir\\'e\npatterns completely or produce overly smooth results. This stems from\nconstrained model capacity and scarce training data, which inadequately\nrepresent the clean image distribution and hinder accurate reconstruction of\nground-truth images. While generative models excel in image restoration for\nlinear degradations, they struggle with nonlinear cases such as demoir\\'eing\nand often introduce artifacts.\n  To address these limitations, we propose a hybrid MAP-based framework that\nintegrates two complementary components. The first is a supervised learning\nmodel enhanced with efficient linear attention Test-Time Training (TTT)\nmodules, which directly learn nonlinear mappings for RAW-to-sRGB demoir\\'eing.\nThe second is a Truncated Flow Matching Prior (TFMP) that further refines the\noutputs by aligning them with the clean image distribution, effectively\nrestoring high-frequency details and suppressing artifacts. These two\ncomponents combine the computational efficiency of linear attention with the\nrefinement abilities of generative models, resulting in improved restoration\nperformance.", "AI": {"tldr": "A hybrid MAP-based framework combining supervised learning with a Truncated Flow Matching Prior (TFMP) for improved image and video demoir\u00e9ing, addressing nonlinear degradation challenges.", "motivation": "Existing methods fail to fully remove moir\u00e9 patterns or produce overly smooth results due to limited model capacity and training data. Generative models struggle with nonlinear cases like demoir\u00e9ing.", "method": "Proposes a hybrid framework: 1) supervised learning with linear attention TTT modules for RAW-to-sRGB demoir\u00e9ing, and 2) TFMP to refine outputs by aligning with clean image distribution.", "result": "The framework combines computational efficiency with generative refinement, improving restoration performance by restoring high-frequency details and suppressing artifacts.", "conclusion": "The hybrid approach effectively addresses nonlinear demoir\u00e9ing challenges, outperforming traditional and generative methods."}}
{"id": "2506.15695", "pdf": "https://arxiv.org/pdf/2506.15695", "abs": "https://arxiv.org/abs/2506.15695", "authors": ["Xinxing Ren", "Qianbo Zang", "Zekun Guo"], "title": "SimuGen: Multi-modal Agentic Framework for Constructing Block Diagram-Based Simulation Models", "categories": ["cs.LG"], "comment": null, "summary": "Recent advances in large language models (LLMs) have shown impressive\nperformance in mathematical reasoning and code generation. However, LLMs still\nstruggle in the simulation domain, particularly in generating Simulink models,\nwhich are essential tools in engineering and scientific research. Our\npreliminary experiments indicate that LLM agents often fail to produce reliable\nand complete Simulink simulation code from text-only inputs, likely due to the\nlack of Simulink-specific data in their pretraining. To address this challenge,\nwe propose SimuGen, a multimodal agent-based framework that automatically\ngenerates accurate Simulink simulation code by leveraging both the visual\nSimulink diagram and domain knowledge. SimuGen coordinates several specialized\nagents, including an investigator, unit test reviewer, code generator,\nexecutor, debug locator, and report writer, supported by a domain-specific\nknowledge base. This collaborative and modular design enables interpretable,\nrobust, and reproducible Simulink simulation generation. Our source code is\npublicly available at https://github.com/renxinxing123/SimuGen_beta.", "AI": {"tldr": "SimuGen is a multimodal framework to generate accurate Simulink simulation code by combining visual diagrams and domain knowledge, addressing LLMs' limitations in this domain.", "motivation": "LLMs struggle with Simulink model generation due to lack of domain-specific pretraining data, necessitating a specialized solution.", "method": "SimuGen uses a collaborative agent-based framework with roles like investigator, code generator, and debug locator, supported by a knowledge base.", "result": "The framework produces interpretable, robust, and reproducible Simulink simulations.", "conclusion": "SimuGen effectively bridges the gap in LLM capabilities for Simulink code generation, offering a modular and domain-aware solution."}}
{"id": "2506.15880", "pdf": "https://arxiv.org/pdf/2506.15880", "abs": "https://arxiv.org/abs/2506.15880", "authors": ["Berk Yilmaz", "Junyu Hu", "Jinsong Liu"], "title": "Deep Reinforcement Learning Xiangqi Player with Monte Carlo Tree Search", "categories": ["cs.AI", "cs.LG", "68T05, 68T20"], "comment": "All authors contributed equally to this work.24 pages, 10 figures", "summary": "This paper presents a Deep Reinforcement Learning (DRL) system for Xiangqi\n(Chinese Chess) that integrates neural networks with Monte Carlo Tree Search\n(MCTS) to enable strategic self-play and self-improvement. Addressing the\nunderexplored complexity of Xiangqi, including its unique board layout, piece\nmovement constraints, and victory conditions, our approach combines\npolicy-value networks with MCTS to simulate move consequences and refine\ndecision-making. By overcoming challenges such as Xiangqi's high branching\nfactor and asymmetrical piece dynamics, our work advances AI capabilities in\nculturally significant strategy games while providing insights for adapting\nDRL-MCTS frameworks to domain-specific rule systems.", "AI": {"tldr": "A DRL system for Xiangqi combines neural networks with MCTS for strategic self-play, addressing its unique complexities like board layout and piece dynamics.", "motivation": "To explore Xiangqi's underexplored complexity and advance AI in culturally significant strategy games.", "method": "Integrates policy-value networks with MCTS to simulate moves and refine decisions, tackling challenges like high branching factor.", "result": "Advances AI capabilities in Xiangqi and provides insights for adapting DRL-MCTS to domain-specific rules.", "conclusion": "The system successfully enhances AI performance in Xiangqi, demonstrating adaptability of DRL-MCTS frameworks."}}
{"id": "2506.16052", "pdf": "https://arxiv.org/pdf/2506.16052", "abs": "https://arxiv.org/abs/2506.16052", "authors": ["Devesh Kumar"], "title": "A Hybrid DeBERTa and Gated Broad Learning System for Cyberbullying Detection in English Text", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "The proliferation of online communication platforms has created unprecedented\nopportunities for global connectivity while simultaneously enabling harmful\nbehaviors such as cyberbullying, which affects approximately 54.4\\% of\nteenagers according to recent research. This paper presents a hybrid\narchitecture that combines the contextual understanding capabilities of\ntransformer-based models with the pattern recognition strengths of broad\nlearning systems for effective cyberbullying detection. This approach\nintegrates a modified DeBERTa model augmented with Squeeze-and-Excitation\nblocks and sentiment analysis capabilities with a Gated Broad Learning System\n(GBLS) classifier, creating a synergistic framework that outperforms existing\napproaches across multiple benchmark datasets. The proposed ModifiedDeBERTa +\nGBLS model achieved good performance on four English datasets: 79.3\\% accuracy\non HateXplain, 95.41\\% accuracy on SOSNet, 91.37\\% accuracy on Mendeley-I, and\n94.67\\% accuracy on Mendeley-II. Beyond performance gains, the framework\nincorporates comprehensive explainability mechanisms including token-level\nattribution analysis, LIME-based local interpretations, and confidence\ncalibration, addressing critical transparency requirements in automated content\nmoderation. Ablation studies confirm the meaningful contribution of each\narchitectural component, while failure case analysis reveals specific\nchallenges in detecting implicit bias and sarcastic content, providing valuable\ninsights for future improvements in cyberbullying detection systems.", "AI": {"tldr": "A hybrid model combining DeBERTa and GBLS for cyberbullying detection achieves high accuracy and explainability.", "motivation": "Address the rising issue of cyberbullying by improving detection methods using advanced AI techniques.", "method": "Combines a modified DeBERTa model with sentiment analysis and a GBLS classifier for enhanced detection.", "result": "Achieves high accuracy (79.3%-95.41%) across four datasets and includes explainability features.", "conclusion": "The framework is effective and transparent, though challenges remain in detecting implicit bias and sarcasm."}}
{"id": "2506.16535", "pdf": "https://arxiv.org/pdf/2506.16535", "abs": "https://arxiv.org/abs/2506.16535", "authors": ["Tyler Landle", "Jordan Rapp", "Dean Blank", "Chandramouli Amarnath", "Abhijit Chatterjee", "Alex Daglis", "Umakishore Ramachandran"], "title": "eCAV: An Edge-Assisted Evaluation Platform for Connected Autonomous Vehicles", "categories": ["cs.RO", "cs.MA", "cs.NI", "cs.SY", "eess.SY"], "comment": null, "summary": "As autonomous vehicles edge closer to widespread adoption, enhancing road\nsafety through collision avoidance and minimization of collateral damage\nbecomes imperative. Vehicle-to-everything (V2X) technologies, which include\nvehicle-to-vehicle (V2V), vehicle-to-infrastructure (V2I), and vehicle-to-cloud\n(V2C), are being proposed as mechanisms to achieve this safety improvement.\n  Simulation-based testing is crucial for early-stage evaluation of Connected\nAutonomous Vehicle (CAV) control systems, offering a safer and more\ncost-effective alternative to real-world tests. However, simulating large 3D\nenvironments with many complex single- and multi-vehicle sensors and\ncontrollers is computationally intensive. There is currently no evaluation\nframework that can effectively evaluate realistic scenarios involving large\nnumbers of autonomous vehicles.\n  We propose eCAV -- an efficient, modular, and scalable evaluation platform to\nfacilitate both functional validation of algorithmic approaches to increasing\nroad safety, as well as performance prediction of algorithms of various V2X\ntechnologies, including a futuristic Vehicle-to-Edge control plane and\ncorrespondingly designed control algorithms. eCAV can model up to 256 vehicles\nrunning individual control algorithms without perception enabled, which is\n$8\\times$ more vehicles than what is possible with state-of-the-art\nalternatives. %faster than state-of-the-art alternatives that can simulate\n$8\\times$ fewer vehicles. With perception enabled, eCAV simulates up to 64\nvehicles with a step time under 800ms, which is $4\\times$ more and $1.5\\times$\nfaster than the state-of-the-art OpenCDA framework.", "AI": {"tldr": "eCAV is a scalable evaluation platform for testing V2X technologies in autonomous vehicles, outperforming current alternatives in vehicle capacity and speed.", "motivation": "Enhancing road safety through collision avoidance and minimizing collateral damage in autonomous vehicles using V2X technologies.", "method": "Proposes eCAV, a modular and scalable platform for simulating large-scale autonomous vehicle scenarios, including V2X technologies.", "result": "eCAV can simulate up to 256 vehicles without perception (8\u00d7 more than alternatives) and 64 vehicles with perception (4\u00d7 more and 1.5\u00d7 faster than OpenCDA).", "conclusion": "eCAV provides an efficient solution for evaluating V2X technologies and control algorithms in autonomous vehicles, addressing computational limitations of current frameworks."}}
{"id": "2506.16580", "pdf": "https://arxiv.org/pdf/2506.16580", "abs": "https://arxiv.org/abs/2506.16580", "authors": ["Tuan-Nam Nguyen", "Ngoc-Quan Pham", "Seymanur Akti", "Alexander Waibel"], "title": "Streaming Non-Autoregressive Model for Accent Conversion and Pronunciation Improvement", "categories": ["cs.CL", "cs.SD", "eess.AS"], "comment": "Accepted to INTERSPEECH 2025", "summary": "We propose a first streaming accent conversion (AC) model that transforms\nnon-native speech into a native-like accent while preserving speaker identity,\nprosody and improving pronunciation. Our approach enables stream processing by\nmodifying a previous AC architecture with an Emformer encoder and an optimized\ninference mechanism. Additionally, we integrate a native text-to-speech (TTS)\nmodel to generate ideal ground-truth data for efficient training. Our streaming\nAC model achieves comparable performance to the top AC models while maintaining\nstable latency, making it the first AC system capable of streaming.", "AI": {"tldr": "A streaming accent conversion model transforms non-native speech into native-like accents while preserving speaker identity and prosody, using an Emformer encoder and optimized inference for real-time processing.", "motivation": "To enable real-time accent conversion while maintaining speaker identity and prosody, addressing the lack of streaming-capable AC systems.", "method": "Modifies a previous AC architecture with an Emformer encoder and optimized inference, integrating a native TTS model for training data.", "result": "Achieves comparable performance to top AC models with stable latency, enabling the first streaming AC system.", "conclusion": "The proposed model successfully enables real-time accent conversion with preserved speaker identity and prosody, marking a milestone in streaming AC."}}
{"id": "2506.16738", "pdf": "https://arxiv.org/pdf/2506.16738", "abs": "https://arxiv.org/abs/2506.16738", "authors": ["Daejin Jo", "Jeeyoung Yun", "Byungseok Roh", "Sungwoong Kim"], "title": "LM-SPT: LM-Aligned Semantic Distillation for Speech Tokenization", "categories": ["cs.CL", "cs.AI", "cs.SD", "eess.AS"], "comment": null, "summary": "With the rapid progress of speech language models (SLMs), discrete speech\ntokens have emerged as a core interface between speech and text, enabling\nunified modeling across modalities. Recent speech tokenization approaches aim\nto isolate semantic information from low-level acoustics to better align with\nlanguage models. In particular, previous methods use SSL teachers such as\nHuBERT to extract semantic representations, which are then distilled into a\nsemantic quantizer to suppress acoustic redundancy as well as capture\ncontent-related latent structures. However, they still produce speech token\nsequences significantly longer than their textual counterparts, creating\nchallenges for efficient speech-language modeling. Reducing the frame rate is a\nnatural solution, but standard techniques, such as rigid average pooling across\nframes, can distort or dilute the semantic structure required for effective LM\nalignment. To address this, we propose LM-SPT, a speech tokenization method\nthat introduces a novel semantic distillation. Instead of directly matching\nteacher and student features via pooling, we reconstruct speech solely from\nsemantic tokens and minimize the discrepancy between the encoded\nrepresentations of the original and reconstructed waveforms, obtained from a\nfrozen automatic speech recognition (ASR) encoder. This indirect yet\ndata-driven supervision enables the tokenizer to learn discrete units that are\nmore semantically aligned with language models. LM-SPT further incorporates\narchitectural improvements to the encoder and decoder for speech tokenization,\nand supports multiple frame rates, including 25Hz, 12.5Hz, and 6.25Hz.\nExperimental results show that LM-SPT achieves superior reconstruction fidelity\ncompared to baselines, and that SLMs trained with LM-SPT tokens achieve\ncompetitive performances on speech-to-text and consistently outperform\nbaselines on text-to-speech tasks.", "AI": {"tldr": "LM-SPT introduces a novel semantic distillation method for speech tokenization, improving alignment with language models and supporting multiple frame rates, outperforming baselines in speech-to-text and text-to-speech tasks.", "motivation": "To address the challenge of speech token sequences being longer than textual ones, which complicates efficient speech-language modeling, by improving semantic alignment and reducing frame rate without distorting semantic structure.", "method": "Proposes LM-SPT, which reconstructs speech from semantic tokens and minimizes discrepancy between original and reconstructed waveforms using a frozen ASR encoder, alongside architectural improvements for tokenization.", "result": "LM-SPT achieves superior reconstruction fidelity and enables SLMs to perform competitively in speech-to-text and outperform baselines in text-to-speech tasks.", "conclusion": "LM-SPT effectively bridges the gap between speech and text modalities by enhancing semantic alignment and supporting flexible frame rates, demonstrating practical improvements in SLM performance."}}
{"id": "2506.16256", "pdf": "https://arxiv.org/pdf/2506.16256", "abs": "https://arxiv.org/abs/2506.16256", "authors": ["C\u00e9sar D\u00edaz-Parga", "Marta Nu\u00f1ez-Garcia", "Maria J. Carreira", "Gabriel Bernardino", "Nicol\u00e1s Vila-Blanco"], "title": "AGE-US: automated gestational age estimation based on fetal ultrasound images", "categories": ["eess.IV", "cs.CV"], "comment": "Accepted in Iberian Conference on Pattern Recognition and Image\n  Analysis (IbPRIA) 2025", "summary": "Being born small carries significant health risks, including increased\nneonatal mortality and a higher likelihood of future cardiac diseases. Accurate\nestimation of gestational age is critical for monitoring fetal growth, but\ntraditional methods, such as estimation based on the last menstrual period, are\nin some situations difficult to obtain. While ultrasound-based approaches offer\ngreater reliability, they rely on manual measurements that introduce\nvariability. This study presents an interpretable deep learning-based method\nfor automated gestational age calculation, leveraging a novel segmentation\narchitecture and distance maps to overcome dataset limitations and the scarcity\nof segmentation masks. Our approach achieves performance comparable to\nstate-of-the-art models while reducing complexity, making it particularly\nsuitable for resource-constrained settings and with limited annotated data.\nFurthermore, our results demonstrate that the use of distance maps is\nparticularly suitable for estimating femur endpoints.", "AI": {"tldr": "An interpretable deep learning method for automated gestational age calculation, using segmentation and distance maps, achieves state-of-the-art performance with reduced complexity.", "motivation": "Accurate gestational age estimation is crucial for fetal health, but traditional methods are unreliable or hard to obtain, and ultrasound-based approaches suffer from manual variability.", "method": "The study introduces a deep learning-based approach with a novel segmentation architecture and distance maps to address dataset limitations and lack of segmentation masks.", "result": "The method matches state-of-the-art performance while being simpler, suitable for resource-limited settings, and excels in femur endpoint estimation using distance maps.", "conclusion": "The proposed method offers a reliable, automated solution for gestational age estimation, especially in settings with limited resources or annotated data."}}
{"id": "2506.15937", "pdf": "https://arxiv.org/pdf/2506.15937", "abs": "https://arxiv.org/abs/2506.15937", "authors": ["Yosub Shin", "Igor Molybog"], "title": "Beyond Audio and Pose: A General-Purpose Framework for Video Synchronization", "categories": ["cs.CV", "cs.AI", "cs.MM"], "comment": null, "summary": "Video synchronization-aligning multiple video streams capturing the same\nevent from different angles-is crucial for applications such as reality TV show\nproduction, sports analysis, surveillance, and autonomous systems. Prior work\nhas heavily relied on audio cues or specific visual events, limiting\napplicability in diverse settings where such signals may be unreliable or\nabsent. Additionally, existing benchmarks for video synchronization lack\ngenerality and reproducibility, restricting progress in the field. In this\nwork, we introduce VideoSync, a video synchronization framework that operates\nindependently of specific feature extraction methods, such as human pose\nestimation, enabling broader applicability across different content types. We\nevaluate our system on newly composed datasets covering single-human,\nmulti-human, and non-human scenarios, providing both the methodology and code\nfor dataset creation to establish reproducible benchmarks. Our analysis reveals\nbiases in prior SOTA work, particularly in SeSyn-Net's preprocessing pipeline,\nleading to inflated performance claims. We correct these biases and propose a\nmore rigorous evaluation framework, demonstrating that VideoSync outperforms\nexisting approaches, including SeSyn-Net, under fair experimental conditions.\nAdditionally, we explore various synchronization offset prediction methods,\nidentifying a convolutional neural network (CNN)-based model as the most\neffective. Our findings advance video synchronization beyond domain-specific\nconstraints, making it more generalizable and robust for real-world\napplications.", "AI": {"tldr": "VideoSync is a framework for video synchronization that avoids reliance on audio or specific visual cues, outperforming prior methods like SeSyn-Net under fair conditions.", "motivation": "Prior methods depend on unreliable audio or visual cues, and benchmarks lack generality, hindering progress in video synchronization.", "method": "VideoSync is feature-agnostic, tested on diverse datasets (single-human, multi-human, non-human), with a CNN-based model for offset prediction.", "result": "VideoSync outperforms existing methods, corrects biases in prior work, and provides reproducible benchmarks.", "conclusion": "VideoSync advances video synchronization by improving generalizability and robustness for real-world applications."}}
{"id": "2506.15696", "pdf": "https://arxiv.org/pdf/2506.15696", "abs": "https://arxiv.org/abs/2506.15696", "authors": ["Haipeng Zhou", "Sicheng Yang", "Sihan Yang", "Jing Qin", "Lei Chen", "Lei Zhu"], "title": "CoC: Chain-of-Cancer based on Cross-Modal Autoregressive Traction for Survival Prediction", "categories": ["cs.LG"], "comment": null, "summary": "Survival prediction aims to evaluate the risk level of cancer patients.\nExisting methods primarily rely on pathology and genomics data, either\nindividually or in combination. From the perspective of cancer pathogenesis,\nepigenetic changes, such as methylation data, could also be crucial for this\ntask. Furthermore, no previous endeavors have utilized textual descriptions to\nguide the prediction. To this end, we are the first to explore the use of four\nmodalities, including three clinical modalities and language, for conducting\nsurvival prediction. In detail, we are motivated by the Chain-of-Thought (CoT)\nto propose the Chain-of-Cancer (CoC) framework, focusing on intra-learning and\ninter-learning. We encode the clinical data as the raw features, which remain\ndomain-specific knowledge for intra-learning. In terms of inter-learning, we\nuse language to prompt the raw features and introduce an Autoregressive Mutual\nTraction module for synergistic representation. This tailored framework\nfacilitates joint learning among multiple modalities. Our approach is evaluated\nacross five public cancer datasets, and extensive experiments validate the\neffectiveness of our methods and proposed designs, leading to producing \\sota\nresults. Codes will be released.", "AI": {"tldr": "The paper introduces a novel framework, Chain-of-Cancer (CoC), combining four modalities (three clinical and language) for cancer survival prediction, achieving state-of-the-art results.", "motivation": "Existing methods rely on pathology and genomics, ignoring epigenetic data and textual descriptions. The study aims to integrate these for better prediction.", "method": "Proposes CoC framework with intra-learning (domain-specific clinical data) and inter-learning (language prompting and Autoregressive Mutual Traction for synergy).", "result": "Evaluated on five cancer datasets, the method outperforms existing approaches, producing state-of-the-art results.", "conclusion": "The CoC framework effectively integrates multiple modalities for survival prediction, validated by extensive experiments."}}
{"id": "2506.15928", "pdf": "https://arxiv.org/pdf/2506.15928", "abs": "https://arxiv.org/abs/2506.15928", "authors": ["Myke C. Cohen", "Zhe Su", "Hsien-Te Kao", "Daniel Nguyen", "Spencer Lynch", "Maarten Sap", "Svitlana Volkova"], "title": "Exploring Big Five Personality and AI Capability Effects in LLM-Simulated Negotiation Dialogues", "categories": ["cs.AI", "cs.CL", "cs.HC"], "comment": "Under review for KDD 2025 Workshop on Evaluation and Trustworthiness\n  of Agentic and Generative AI Models", "summary": "This paper presents an evaluation framework for agentic AI systems in\nmission-critical negotiation contexts, addressing the need for AI agents that\ncan adapt to diverse human operators and stakeholders. Using Sotopia as a\nsimulation testbed, we present two experiments that systematically evaluated\nhow personality traits and AI agent characteristics influence LLM-simulated\nsocial negotiation outcomes--a capability essential for a variety of\napplications involving cross-team coordination and civil-military interactions.\nExperiment 1 employs causal discovery methods to measure how personality traits\nimpact price bargaining negotiations, through which we found that Agreeableness\nand Extraversion significantly affect believability, goal achievement, and\nknowledge acquisition outcomes. Sociocognitive lexical measures extracted from\nteam communications detected fine-grained differences in agents' empathic\ncommunication, moral foundations, and opinion patterns, providing actionable\ninsights for agentic AI systems that must operate reliably in high-stakes\noperational scenarios. Experiment 2 evaluates human-AI job negotiations by\nmanipulating both simulated human personality and AI system characteristics,\nspecifically transparency, competence, adaptability, demonstrating how AI agent\ntrustworthiness impact mission effectiveness. These findings establish a\nrepeatable evaluation methodology for experimenting with AI agent reliability\nacross diverse operator personalities and human-agent team dynamics, directly\nsupporting operational requirements for reliable AI systems. Our work advances\nthe evaluation of agentic AI workflows by moving beyond standard performance\nmetrics to incorporate social dynamics essential for mission success in complex\noperations.", "AI": {"tldr": "The paper introduces a framework to evaluate AI agents in mission-critical negotiations, focusing on how personality traits and AI characteristics affect outcomes. Experiments using Sotopia reveal key insights for reliable AI-human interactions.", "motivation": "Addresses the need for adaptable AI agents in high-stakes negotiations, ensuring reliability in diverse human-AI team dynamics.", "method": "Uses Sotopia for simulations; Experiment 1 analyzes personality traits' impact on bargaining, while Experiment 2 evaluates human-AI job negotiations by manipulating traits and AI characteristics.", "result": "Agreeableness and Extraversion significantly influence negotiation outcomes. AI transparency, competence, and adaptability affect trust and mission effectiveness.", "conclusion": "The framework provides actionable insights for designing reliable AI agents in complex, high-stakes scenarios, advancing beyond standard performance metrics."}}
{"id": "2506.16055", "pdf": "https://arxiv.org/pdf/2506.16055", "abs": "https://arxiv.org/abs/2506.16055", "authors": ["Andy Yang", "Micha\u00ebl Cadilhac", "David Chiang"], "title": "Knee-Deep in C-RASP: A Transformer Depth Hierarchy", "categories": ["cs.CL", "cs.FL"], "comment": "27 pages, 4 figures", "summary": "It has been observed that transformers with greater depth (that is, more\nlayers) have more capabilities, but can we establish formally which\ncapabilities are gained with greater depth? We answer this question with a\ntheoretical proof followed by an empirical study. First, we consider\ntransformers that round to fixed precision except inside attention. We show\nthat this subclass of transformers is expressively equivalent to the\nprogramming language C-RASP and this equivalence preserves depth. Second, we\nprove that deeper C-RASP programs are more expressive than shallower C-RASP\nprograms, implying that deeper transformers are more expressive than shallower\ntransformers (within the subclass mentioned above). These results are\nestablished by studying a form of temporal logic with counting operators, which\nwas shown equivalent to C-RASP in previous work. Finally, we provide empirical\nevidence that our theory predicts the depth required for transformers without\npositional encodings to length-generalize on a family of sequential dependency\ntasks.", "AI": {"tldr": "The paper explores the expressive capabilities of deeper transformers, proving their equivalence to C-RASP programs and showing deeper models are more expressive. Empirical evidence supports the theory.", "motivation": "To formally establish which capabilities are gained with greater depth in transformers, addressing the gap in understanding depth's role in expressiveness.", "method": "Theoretical proof and empirical study: (1) Equate transformers to C-RASP programs, preserving depth; (2) Prove deeper C-RASP programs are more expressive; (3) Validate with empirical tasks.", "result": "Deeper transformers are more expressive than shallower ones within the studied subclass. Empirical results align with theoretical predictions.", "conclusion": "Depth in transformers enhances expressiveness, as proven theoretically and supported empirically, particularly in sequential dependency tasks."}}
{"id": "2506.16650", "pdf": "https://arxiv.org/pdf/2506.16650", "abs": "https://arxiv.org/abs/2506.16650", "authors": ["Anvith Pabba", "Alex Mathai", "Anindya Chakraborty", "Baishakhi Ray"], "title": "SemAgent: A Semantics Aware Program Repair Agent", "categories": ["cs.SE", "cs.AI", "cs.MA"], "comment": null, "summary": "Large Language Models (LLMs) have shown impressive capabilities in downstream\nsoftware engineering tasks such as Automated Program Repair (APR). In\nparticular, there has been a lot of research on repository-level\nissue-resolution benchmarks such as SWE-Bench. Although there has been\nsignificant progress on this topic, we notice that in the process of solving\nsuch issues, existing agentic systems tend to hyper-localize on immediately\nsuspicious lines of code and fix them in isolation, without a deeper\nunderstanding of the issue semantics, code semantics, or execution semantics.\nConsequently, many existing systems generate patches that overfit to the user\nissue, even when a more general fix is preferable. To address this limitation,\nwe introduce SemAgent, a novel workflow-based procedure that leverages issue,\ncode, and execution semantics to generate patches that are complete -\nidentifying and fixing all lines relevant to the issue. We achieve this through\na novel pipeline that (a) leverages execution semantics to retrieve relevant\ncontext, (b) comprehends issue-semantics via generalized abstraction, (c)\nisolates code-semantics within the context of this abstraction, and (d)\nleverages this understanding in a two-stage architecture: a repair stage that\nproposes fine-grained fixes, followed by a reviewer stage that filters relevant\nfixes based on the inferred issue-semantics. Our evaluations show that our\nmethodology achieves a solve rate of 44.66% on the SWEBench-Lite benchmark\nbeating all other workflow-based approaches, and an absolute improvement of\n7.66% compared to our baseline, which lacks such deep semantic understanding.\nWe note that our approach performs particularly well on issues requiring\nmulti-line reasoning (and editing) and edge-case handling, suggesting that\nincorporating issue and code semantics into APR pipelines can lead to robust\nand semantically consistent repairs.", "AI": {"tldr": "SemAgent introduces a workflow-based approach for Automated Program Repair (APR) that leverages issue, code, and execution semantics to generate complete patches, outperforming existing methods.", "motivation": "Existing APR systems hyper-localize fixes without deeper semantic understanding, leading to overfitted patches. SemAgent aims to address this by incorporating broader semantic analysis.", "method": "SemAgent uses a pipeline with execution semantics for context retrieval, issue-semantics abstraction, code-semantics isolation, and a two-stage repair-reviewer architecture.", "result": "Achieves a 44.66% solve rate on SWEBench-Lite, with a 7.66% improvement over baselines, excelling in multi-line reasoning and edge-case handling.", "conclusion": "Incorporating semantic understanding into APR pipelines yields robust, semantically consistent repairs, especially for complex issues."}}
{"id": "2502.11478", "pdf": "https://arxiv.org/pdf/2502.11478", "abs": "https://arxiv.org/abs/2502.11478", "authors": ["Yunsik Kim", "Yonghun Song", "Yoonyoung Chung"], "title": "TAPS: Throat and Acoustic Paired Speech Dataset for Deep Learning-Based Speech Enhancement", "categories": ["cs.SD", "cs.LG", "eess.AS"], "comment": null, "summary": "In high-noise environments such as factories, subways, and busy streets,\ncapturing clear speech is challenging. Throat microphones can offer a solution\nbecause of their inherent noise-suppression capabilities; however, the passage\nof sound waves through skin and tissue attenuates high-frequency information,\nreducing speech clarity. Recent deep learning approaches have shown promise in\nenhancing throat microphone recordings, but further progress is constrained by\nthe lack of a standard dataset. Here, we introduce the Throat and Acoustic\nPaired Speech (TAPS) dataset, a collection of paired utterances recorded from\n60 native Korean speakers using throat and acoustic microphones. Furthermore,\nan optimal alignment approach was developed and applied to address the inherent\nsignal mismatch between the two microphones. We tested three baseline deep\nlearning models on the TAPS dataset and found mapping-based approaches to be\nsuperior for improving speech quality and restoring content. These findings\ndemonstrate the TAPS dataset's utility for speech enhancement tasks and support\nits potential as a standard resource for advancing research in throat\nmicrophone-based applications.", "AI": {"tldr": "The paper introduces the TAPS dataset for enhancing throat microphone recordings in noisy environments and evaluates deep learning models for speech improvement.", "motivation": "Clear speech capture in noisy settings is difficult; throat microphones help but lose high-frequency clarity. Lack of a standard dataset limits progress.", "method": "Developed the TAPS dataset with paired throat and acoustic recordings from 60 speakers, and an alignment method for signal mismatch. Tested three deep learning models.", "result": "Mapping-based models outperformed others in improving speech quality and content restoration.", "conclusion": "The TAPS dataset is valuable for speech enhancement and can serve as a standard for throat microphone research."}}
{"id": "2403.04433", "pdf": "https://arxiv.org/pdf/2403.04433", "abs": "https://arxiv.org/abs/2403.04433", "authors": ["Ond\u0159ej Mokr\u00fd", "Pavel Rajmic"], "title": "Tweaking autoregressive methods for inpainting of gaps in audio signals", "categories": ["eess.AS", "cs.SD"], "comment": "Accepted to EUSIPCO 2025", "summary": "A novel variant of the Janssen method for audio inpainting is presented and\ncompared to other popular audio inpainting methods based on autoregressive (AR)\nmodeling. Both conceptual differences and practical implications are discussed.\nThe experiments demonstrate the importance of the choice of the AR model\nestimator, window/context length, and model order. The results show the\nsuperiority of the proposed gap-wise Janssen approach using objective metrics,\nwhich is confirmed by a listening test.", "AI": {"tldr": "A new variant of the Janssen method for audio inpainting outperforms other AR-based methods, with key factors like AR model estimator, window length, and model order influencing results.", "motivation": "To improve audio inpainting by proposing a novel variant of the Janssen method and comparing it to existing AR-based methods.", "method": "The study introduces a gap-wise Janssen approach, evaluates it against other AR-based methods, and tests factors like AR model estimator, window length, and model order.", "result": "The proposed method shows superior performance in objective metrics and listening tests.", "conclusion": "The gap-wise Janssen method is effective for audio inpainting, with practical choices like AR model estimator and window length significantly impacting results."}}
{"id": "2506.16556", "pdf": "https://arxiv.org/pdf/2506.16556", "abs": "https://arxiv.org/abs/2506.16556", "authors": ["Salvatore Esposito", "Daniel Rebain", "Arno Onken", "Changjian Li", "Oisin Mac Aodha"], "title": "VesselSDF: Distance Field Priors for Vascular Network Reconstruction", "categories": ["eess.IV", "cs.CV"], "comment": null, "summary": "Accurate segmentation of vascular networks from sparse CT scan slices remains\na significant challenge in medical imaging, particularly due to the thin,\nbranching nature of vessels and the inherent sparsity between imaging planes.\nExisting deep learning approaches, based on binary voxel classification, often\nstruggle with structural continuity and geometric fidelity. To address this\nchallenge, we present VesselSDF, a novel framework that leverages signed\ndistance fields (SDFs) for robust vessel reconstruction. Our method\nreformulates vessel segmentation as a continuous SDF regression problem, where\neach point in the volume is represented by its signed distance to the nearest\nvessel surface. This continuous representation inherently captures the smooth,\ntubular geometry of blood vessels and their branching patterns. We obtain\naccurate vessel reconstructions while eliminating common SDF artifacts such as\nfloating segments, thanks to our adaptive Gaussian regularizer which ensures\nsmoothness in regions far from vessel surfaces while producing precise geometry\nnear the surface boundaries. Our experimental results demonstrate that\nVesselSDF significantly outperforms existing methods and preserves vessel\ngeometry and connectivity, enabling more reliable vascular analysis in clinical\nsettings.", "AI": {"tldr": "VesselSDF introduces a novel framework using signed distance fields (SDFs) for robust vessel segmentation from sparse CT scans, outperforming existing methods by preserving geometric fidelity and connectivity.", "motivation": "Accurate segmentation of vascular networks from sparse CT scans is challenging due to thin, branching vessels and sparsity between imaging planes. Existing deep learning methods struggle with structural continuity and geometric fidelity.", "method": "VesselSDF reformulates vessel segmentation as a continuous SDF regression problem, representing each point by its signed distance to the nearest vessel surface. An adaptive Gaussian regularizer ensures smoothness and precise geometry.", "result": "VesselSDF significantly outperforms existing methods, preserving vessel geometry and connectivity, and eliminating common SDF artifacts like floating segments.", "conclusion": "VesselSDF enables more reliable vascular analysis in clinical settings by providing accurate vessel reconstructions with improved geometric fidelity."}}
{"id": "2506.15940", "pdf": "https://arxiv.org/pdf/2506.15940", "abs": "https://arxiv.org/abs/2506.15940", "authors": ["Zhongchen Zhao", "Chaodong Xiao", "Hui Lin", "Qi Xie", "Lei Zhang", "Deyu Meng"], "title": "Polyline Path Masked Attention for Vision Transformer", "categories": ["cs.CV"], "comment": null, "summary": "Global dependency modeling and spatial position modeling are two core issues\nof the foundational architecture design in current deep learning frameworks.\nRecently, Vision Transformers (ViTs) have achieved remarkable success in\ncomputer vision, leveraging the powerful global dependency modeling capability\nof the self-attention mechanism. Furthermore, Mamba2 has demonstrated its\nsignificant potential in natural language processing tasks by explicitly\nmodeling the spatial adjacency prior through the structured mask. In this\npaper, we propose Polyline Path Masked Attention (PPMA) that integrates the\nself-attention mechanism of ViTs with an enhanced structured mask of Mamba2,\nharnessing the complementary strengths of both architectures. Specifically, we\nfirst ameliorate the traditional structured mask of Mamba2 by introducing a 2D\npolyline path scanning strategy and derive its corresponding structured mask,\npolyline path mask, which better preserves the adjacency relationships among\nimage tokens. Notably, we conduct a thorough theoretical analysis on the\nstructural characteristics of the proposed polyline path mask and design an\nefficient algorithm for the computation of the polyline path mask. Next, we\nembed the polyline path mask into the self-attention mechanism of ViTs,\nenabling explicit modeling of spatial adjacency prior. Extensive experiments on\nstandard benchmarks, including image classification, object detection, and\nsegmentation, demonstrate that our model outperforms previous state-of-the-art\napproaches based on both state-space models and Transformers. For example, our\nproposed PPMA-T/S/B models achieve 48.7%/51.1%/52.3% mIoU on the ADE20K\nsemantic segmentation task, surpassing RMT-T/S/B by 0.7%/1.3%/0.3%,\nrespectively. Code is available at https://github.com/zhongchenzhao/PPMA.", "AI": {"tldr": "The paper proposes Polyline Path Masked Attention (PPMA), integrating ViTs' self-attention with Mamba2's structured mask to enhance global dependency and spatial adjacency modeling in deep learning.", "motivation": "To combine the strengths of Vision Transformers (ViTs) and Mamba2 for improved performance in computer vision tasks by addressing global dependency and spatial adjacency modeling.", "method": "Introduces a 2D polyline path scanning strategy to enhance Mamba2's structured mask, then embeds this into ViTs' self-attention mechanism. Includes theoretical analysis and an efficient algorithm for mask computation.", "result": "PPMA outperforms state-of-the-art models in benchmarks like image classification, object detection, and segmentation, e.g., achieving 48.7%/51.1%/52.3% mIoU on ADE20K.", "conclusion": "PPMA successfully integrates ViTs and Mamba2, demonstrating superior performance in computer vision tasks."}}
{"id": "2506.15697", "pdf": "https://arxiv.org/pdf/2506.15697", "abs": "https://arxiv.org/abs/2506.15697", "authors": ["Yi Liu", "Hongji Zhang", "Yunhao Zhou", "Zhengyuan Shi", "Changran Xu", "Qiang Xu"], "title": "DeepRTL2: A Versatile Model for RTL-Related Tasks", "categories": ["cs.AR", "cs.CL", "cs.LG"], "comment": "ACL 2025 Findings", "summary": "The integration of large language models (LLMs) into electronic design\nautomation (EDA) has significantly advanced the field, offering transformative\nbenefits, particularly in register transfer level (RTL) code generation and\nunderstanding. While previous studies have demonstrated the efficacy of\nfine-tuning LLMs for these generation-based tasks, embedding-based tasks, which\nare equally critical to EDA workflows, have been largely overlooked. These\ntasks, including natural language code search, RTL code functionality\nequivalence checking, and performance prediction, are essential for\naccelerating and optimizing the hardware design process. To address this gap,\nwe present DeepRTL2, a family of versatile LLMs that unifies both generation-\nand embedding-based tasks related to RTL. By simultaneously tackling a broad\nrange of tasks, DeepRTL2 represents the first model to provide a comprehensive\nsolution to the diverse challenges in EDA. Through extensive experiments, we\nshow that DeepRTL2 achieves state-of-the-art performance across all evaluated\ntasks.", "AI": {"tldr": "DeepRTL2 unifies generation- and embedding-based tasks in EDA using LLMs, achieving state-of-the-art performance.", "motivation": "Previous work focused on generation tasks, neglecting embedding-based tasks critical for EDA workflows.", "method": "Developed DeepRTL2, a family of LLMs, to handle both generation and embedding tasks in RTL.", "result": "Achieved state-of-the-art performance across all evaluated tasks.", "conclusion": "DeepRTL2 provides a comprehensive solution for diverse EDA challenges."}}
{"id": "2506.16015", "pdf": "https://arxiv.org/pdf/2506.16015", "abs": "https://arxiv.org/abs/2506.16015", "authors": ["Craig S. Wright"], "title": "Bayesian Epistemology with Weighted Authority: A Formal Architecture for Truth-Promoting Autonomous Scientific Reasoning", "categories": ["cs.AI", "cs.CL", "cs.DB", "cs.LO", "math.LO", "68T27, 03B70, 68P20", "I.2.3; F.4.1; H.2.8"], "comment": "91 pages, 0 figures, includes mathematical appendix and formal\n  proofs. Designed as a foundational submission for a modular autonomous\n  epistemic reasoning system. Suitable for logic in computer science, AI\n  epistemology, and scientific informatics", "summary": "The exponential expansion of scientific literature has surpassed the\nepistemic processing capabilities of both human experts and current artificial\nintelligence systems. This paper introduces Bayesian Epistemology with Weighted\nAuthority (BEWA), a formally structured architecture that operationalises\nbelief as a dynamic, probabilistically coherent function over structured\nscientific claims. Each claim is contextualised, author-attributed, and\nevaluated through a system of replication scores, citation weighting, and\ntemporal decay. Belief updates are performed via evidence-conditioned Bayesian\ninference, contradiction processing, and epistemic decay mechanisms. The\narchitecture supports graph-based claim propagation, authorial credibility\nmodelling, cryptographic anchoring, and zero-knowledge audit verification. By\nformalising scientific reasoning into a computationally verifiable epistemic\nnetwork, BEWA advances the foundation for machine reasoning systems that\npromote truth utility, rational belief convergence, and audit-resilient\nintegrity across dynamic scientific domains.", "AI": {"tldr": "BEWA is a Bayesian-based architecture for structured scientific belief updates, integrating replication scores, citation weighting, and temporal decay to enhance machine reasoning and truth utility.", "motivation": "Address the challenge of processing vast scientific literature by formalizing belief updates and epistemic integrity.", "method": "Uses Bayesian inference, replication scores, citation weighting, temporal decay, and graph-based claim propagation.", "result": "Enables probabilistically coherent belief updates, author credibility modeling, and audit-resilient integrity.", "conclusion": "BEWA provides a foundation for machine reasoning systems that ensure rational belief convergence and truth utility in science."}}
{"id": "2506.16064", "pdf": "https://arxiv.org/pdf/2506.16064", "abs": "https://arxiv.org/abs/2506.16064", "authors": ["Duc Hieu Ho", "Chenglin Fan"], "title": "Self-Critique-Guided Curiosity Refinement: Enhancing Honesty and Helpfulness in Large Language Models via In-Context Learning", "categories": ["cs.CL"], "comment": null, "summary": "Large language models (LLMs) have demonstrated robust capabilities across\nvarious natural language tasks. However, producing outputs that are\nconsistently honest and helpful remains an open challenge. To overcome this\nchallenge, this paper tackles the problem through two complementary directions.\nIt conducts a comprehensive benchmark evaluation of ten widely used large\nlanguage models, including both proprietary and open-weight models from OpenAI,\nMeta, and Google. In parallel, it proposes a novel prompting strategy,\nself-critique-guided curiosity refinement prompting. The key idea behind this\nstrategy is enabling models to self-critique and refine their responses without\nadditional training. The proposed method extends the curiosity-driven prompting\nstrategy by incorporating two lightweight in-context steps including\nself-critique step and refinement step.\n  The experiment results on the HONESET dataset evaluated using the framework\n$\\mathrm{H}^2$ (honesty and helpfulness), which was executed with GPT-4o as a\njudge of honesty and helpfulness, show consistent improvements across all\nmodels. The approach reduces the number of poor-quality responses, increases\nhigh-quality responses, and achieves relative gains in $\\mathrm{H}^2$ scores\nranging from 1.4% to 4.3% compared to curiosity-driven prompting across\nevaluated models. These results highlight the effectiveness of structured\nself-refinement as a scalable and training-free strategy to improve the\ntrustworthiness of LLMs outputs.", "AI": {"tldr": "The paper addresses the challenge of improving honesty and helpfulness in LLM outputs by proposing a self-critique-guided prompting strategy and benchmarking ten models, showing consistent improvements.", "motivation": "Despite LLMs' capabilities, ensuring honest and helpful outputs remains a challenge. This paper aims to enhance trustworthiness without additional training.", "method": "A novel prompting strategy, self-critique-guided curiosity refinement, is introduced, involving self-critique and refinement steps. Ten LLMs are benchmarked.", "result": "Experiments on the HONESET dataset show improved H\u00b2 scores (1.4% to 4.3%), fewer poor-quality responses, and more high-quality outputs.", "conclusion": "Structured self-refinement is an effective, scalable, and training-free method to enhance LLM trustworthiness."}}
{"id": "2506.16710", "pdf": "https://arxiv.org/pdf/2506.16710", "abs": "https://arxiv.org/abs/2506.16710", "authors": ["Aditya Bhatt", "Mary Katherine Corra", "Franklin Merlo", "Prajit KrisshnaKumar", "Souma Chowdhury"], "title": "Experimental Setup and Software Pipeline to Evaluate Optimization based Autonomous Multi-Robot Search Algorithms", "categories": ["cs.RO", "cs.MA"], "comment": "to be published in IDETC 2025 conference proceedings", "summary": "Signal source localization has been a problem of interest in the multi-robot\nsystems domain given its applications in search \\& rescue and hazard\nlocalization in various industrial and outdoor settings. A variety of\nmulti-robot search algorithms exist that usually formulate and solve the\nassociated autonomous motion planning problem as a heuristic model-free or\nbelief model-based optimization process. Most of these algorithms however\nremains tested only in simulation, thereby losing the opportunity to generate\nknowledge about how such algorithms would compare/contrast in a real physical\nsetting in terms of search performance and real-time computing performance. To\naddress this gap, this paper presents a new lab-scale physical setup and\nassociated open-source software pipeline to evaluate and benchmark multi-robot\nsearch algorithms. The presented physical setup innovatively uses an acoustic\nsource (that is safe and inexpensive) and small ground robots (e-pucks)\noperating in a standard motion-capture environment. This setup can be easily\nrecreated and used by most robotics researchers. The acoustic source also\npresents interesting uncertainty in terms of its noise-to-signal ratio, which\nis useful to assess sim-to-real gaps. The overall software pipeline is designed\nto readily interface with any multi-robot search algorithm with minimal effort\nand is executable in parallel asynchronous form. This pipeline includes a\nframework for distributed implementation of multi-robot or swarm search\nalgorithms, integrated with a ROS (Robotics Operating System)-based software\nstack for motion capture supported localization. The utility of this novel\nsetup is demonstrated by using it to evaluate two state-of-the-art multi-robot\nsearch algorithms, based on swarm optimization and batch-Bayesian Optimization\n(called Bayes-Swarm), as well as a random walk baseline.", "AI": {"tldr": "The paper introduces a lab-scale physical setup and open-source software pipeline to benchmark multi-robot search algorithms, addressing the sim-to-real gap in signal source localization.", "motivation": "Existing multi-robot search algorithms are mostly tested in simulation, lacking real-world performance insights.", "method": "A physical setup using an acoustic source and e-puck robots in a motion-capture environment, paired with a ROS-based software pipeline for distributed algorithm evaluation.", "result": "The setup evaluates two state-of-the-art algorithms (swarm optimization and Bayes-Swarm) and a random walk baseline, demonstrating utility.", "conclusion": "The proposed setup is practical, reproducible, and useful for assessing sim-to-real gaps in multi-robot search algorithms."}}
{"id": "2506.07081", "pdf": "https://arxiv.org/pdf/2506.07081", "abs": "https://arxiv.org/abs/2506.07081", "authors": ["Sathvik Udupa", "Shinji Watanabe", "Petr Schwarz", "Jan Cernocky"], "title": "Streaming Endpointer for Spoken Dialogue using Neural Audio Codecs and Label-Delayed Training", "categories": ["cs.SD", "eess.AS"], "comment": null, "summary": "Accurate, low-latency endpointing is crucial for effective spoken dialogue\nsystems. While traditional endpointers often rely on spectrum-based audio\nfeatures, this work proposes real-time speech endpointing for multi-turn\ndialogues using streaming, low-bitrate Neural Audio Codec (NAC) features,\nbuilding upon recent advancements in neural audio codecs. To further reduce\ncutoff errors, we introduce a novel label delay training scheme. At a fixed\nmedian latency of 160 ms, our combined NAC and label delay approach achieves\nsignificant relative cutoff error reductions: 42.7% for a single-stream\nendpointer and 37.5% for a two-stream configuration, compared to baseline\nmethods. Finally, we demonstrate efficient integration with a codec-based\npretrained speech large language model, improving its median response time by\n1200 ms and reducing its cutoff error by 35%.", "AI": {"tldr": "The paper proposes a real-time speech endpointing method for multi-turn dialogues using Neural Audio Codec (NAC) features and a label delay training scheme, achieving significant error reductions and faster response times.", "motivation": "Traditional endpointers rely on spectrum-based audio features, which may not be optimal for real-time, multi-turn dialogues. The study aims to improve accuracy and reduce latency using NAC features.", "method": "The approach combines streaming, low-bitrate NAC features with a novel label delay training scheme to minimize cutoff errors.", "result": "At 160 ms median latency, the method reduces cutoff errors by 42.7% (single-stream) and 37.5% (two-stream) compared to baselines. Integration with a speech LLM improves response time by 1200 ms and reduces errors by 35%.", "conclusion": "The proposed NAC and label delay approach significantly enhances endpointing accuracy and efficiency, particularly for real-time dialogue systems."}}
{"id": "2409.06392", "pdf": "https://arxiv.org/pdf/2409.06392", "abs": "https://arxiv.org/abs/2409.06392", "authors": ["Ond\u0159ej Mokr\u00fd", "Peter Balu\u0161\u00edk", "Pavel Rajmic"], "title": "Janssen 2.0: Audio Inpainting in the Time-frequency Domain", "categories": ["eess.AS", "cs.SD"], "comment": "Accepted to EUSIPCO 2025", "summary": "The paper focuses on inpainting missing parts of an audio signal spectrogram,\ni.e., estimating the lacking time-frequency coefficients. The\nautoregression-based Janssen algorithm, a state-of-the-art for the time-domain\naudio inpainting, is adapted for the time-frequency setting. This novel method,\ntermed Janssen-TF, is compared with the deep-prior neural network approach\nusing both objective metrics and a subjective listening test, proving\nJanssen-TF to be superior in all the considered measures.", "AI": {"tldr": "The paper introduces Janssen-TF, an adapted autoregression-based method for audio spectrogram inpainting, outperforming deep-prior neural networks in objective and subjective tests.", "motivation": "To address the challenge of estimating missing time-frequency coefficients in audio spectrograms by adapting a proven time-domain method.", "method": "Adapts the Janssen algorithm (autoregression-based) for time-frequency inpainting (Janssen-TF) and compares it with deep-prior neural networks.", "result": "Janssen-TF outperforms deep-prior neural networks in both objective metrics and subjective listening tests.", "conclusion": "Janssen-TF is a superior method for audio spectrogram inpainting compared to deep-prior neural networks."}}
{"id": "2506.16572", "pdf": "https://arxiv.org/pdf/2506.16572", "abs": "https://arxiv.org/abs/2506.16572", "authors": ["Chanung Park", "Joo Chan Lee", "Jong Hwan Ko"], "title": "DiffO: Single-step Diffusion for Image Compression at Ultra-Low Bitrates", "categories": ["eess.IV", "cs.CV"], "comment": null, "summary": "Although image compression is fundamental to visual data processing and has\ninspired numerous standard and learned codecs, these methods still suffer\nsevere quality degradation at extremely low bits per pixel. While recent\ndiffusion based models provided enhanced generative performance at low\nbitrates, they still yields limited perceptual quality and prohibitive decoding\nlatency due to multiple denoising steps. In this paper, we propose the first\nsingle step diffusion model for image compression (DiffO) that delivers high\nperceptual quality and fast decoding at ultra low bitrates. DiffO achieves\nthese goals by coupling two key innovations: (i) VQ Residual training, which\nfactorizes a structural base code and a learned residual in latent space,\ncapturing both global geometry and high frequency details; and (ii) rate\nadaptive noise modulation, which tunes denoising strength on the fly to match\nthe desired bitrate. Extensive experiments show that DiffO surpasses state of\nthe art compression performance while improving decoding speed by about 50x\ncompared to prior diffusion-based methods, greatly improving the practicality\nof generative codecs. The code will be available at\nhttps://github.com/Freemasti/DiffO.", "AI": {"tldr": "DiffO is a single-step diffusion model for image compression, offering high perceptual quality and fast decoding at ultra-low bitrates.", "motivation": "Existing methods suffer from quality degradation at low bitrates and high latency due to multiple denoising steps.", "method": "DiffO uses VQ Residual training for global and detailed latent space factorization and rate-adaptive noise modulation for bitrate matching.", "result": "DiffO outperforms state-of-the-art methods, improving decoding speed by 50x.", "conclusion": "DiffO enhances the practicality of generative codecs for ultra-low bitrate image compression."}}
{"id": "2506.15971", "pdf": "https://arxiv.org/pdf/2506.15971", "abs": "https://arxiv.org/abs/2506.15971", "authors": ["Jiawen Yang", "Shuhao Chen", "Yucong Duan", "Ke Tang", "Yu Zhang"], "title": "Heterogeneous-Modal Unsupervised Domain Adaptation via Latent Space Bridging", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": null, "summary": "Unsupervised domain adaptation (UDA) methods effectively bridge domain gaps\nbut become struggled when the source and target domains belong to entirely\ndistinct modalities. To address this limitation, we propose a novel setting\ncalled Heterogeneous-Modal Unsupervised Domain Adaptation (HMUDA), which\nenables knowledge transfer between completely different modalities by\nleveraging a bridge domain containing unlabeled samples from both modalities.\nTo learn under the HMUDA setting, we propose Latent Space Bridging (LSB), a\nspecialized framework designed for the semantic segmentation task.\nSpecifically, LSB utilizes a dual-branch architecture, incorporating a feature\nconsistency loss to align representations across modalities and a domain\nalignment loss to reduce discrepancies between class centroids across domains.\nExtensive experiments conducted on six benchmark datasets demonstrate that LSB\nachieves state-of-the-art performance.", "AI": {"tldr": "Proposes HMUDA and LSB for domain adaptation between entirely distinct modalities, achieving state-of-the-art results.", "motivation": "Addresses the limitation of UDA when source and target domains are from entirely different modalities.", "method": "Introduces HMUDA and LSB, using a bridge domain, dual-branch architecture, feature consistency loss, and domain alignment loss.", "result": "LSB achieves state-of-the-art performance on six benchmark datasets.", "conclusion": "LSB effectively enables knowledge transfer between distinct modalities in UDA."}}
{"id": "2506.15698", "pdf": "https://arxiv.org/pdf/2506.15698", "abs": "https://arxiv.org/abs/2506.15698", "authors": ["Yunhak Oh", "Junseok Lee", "Yeongmin Kim", "Sangwoo Seo", "Namkyeong Lee", "Chanyoung Park"], "title": "Global Context-aware Representation Learning for Spatially Resolved Transcriptomics", "categories": ["cs.LG", "cs.CV"], "comment": "ICML 2025", "summary": "Spatially Resolved Transcriptomics (SRT) is a cutting-edge technique that\ncaptures the spatial context of cells within tissues, enabling the study of\ncomplex biological networks. Recent graph-based methods leverage both gene\nexpression and spatial information to identify relevant spatial domains.\nHowever, these approaches fall short in obtaining meaningful spot\nrepresentations, especially for spots near spatial domain boundaries, as they\nheavily emphasize adjacent spots that have minimal feature differences from an\nanchor node. To address this, we propose Spotscape, a novel framework that\nintroduces the Similarity Telescope module to capture global relationships\nbetween multiple spots. Additionally, we propose a similarity scaling strategy\nto regulate the distances between intra- and inter-slice spots, facilitating\neffective multi-slice integration. Extensive experiments demonstrate the\nsuperiority of Spotscape in various downstream tasks, including single-slice\nand multi-slice scenarios. Our code is available at the following link: https:\n//github.com/yunhak0/Spotscape.", "AI": {"tldr": "Spotscape is a new framework for Spatially Resolved Transcriptomics (SRT) that improves spatial domain identification by capturing global relationships and regulating spot distances, outperforming existing methods.", "motivation": "Existing graph-based methods for SRT struggle with meaningful spot representations, especially near domain boundaries, due to overemphasis on adjacent spots with minimal feature differences.", "method": "Spotscape introduces the Similarity Telescope module to capture global spot relationships and a similarity scaling strategy for intra- and inter-slice spot distance regulation.", "result": "Spotscape excels in single-slice and multi-slice downstream tasks, demonstrating superior performance.", "conclusion": "Spotscape addresses limitations of current SRT methods, offering enhanced spatial domain analysis and multi-slice integration."}}
{"id": "2506.16016", "pdf": "https://arxiv.org/pdf/2506.16016", "abs": "https://arxiv.org/abs/2506.16016", "authors": ["William Sharpless", "Dylan Hirsch", "Sander Tonkens", "Nikhil Shinde", "Sylvia Herbert"], "title": "Dual-Objective Reinforcement Learning with Novel Hamilton-Jacobi-Bellman Formulations", "categories": ["cs.AI", "cs.SY", "eess.SY"], "comment": null, "summary": "Hard constraints in reinforcement learning (RL), whether imposed via the\nreward function or the model architecture, often degrade policy performance.\nLagrangian methods offer a way to blend objectives with constraints, but often\nrequire intricate reward engineering and parameter tuning. In this work, we\nextend recent advances that connect Hamilton-Jacobi (HJ) equations with RL to\npropose two novel value functions for dual-objective satisfaction. Namely, we\naddress: (1) the Reach-Always-Avoid problem - of achieving distinct reward and\npenalty thresholds - and (2) the Reach-Reach problem - of achieving thresholds\nof two distinct rewards. In contrast with temporal logic approaches, which\ntypically involve representing an automaton, we derive explicit, tractable\nBellman forms in this context by decomposing our problem into reach, avoid, and\nreach-avoid problems, as to leverage these aforementioned recent advances. From\na mathematical perspective, the Reach-Always-Avoid and Reach-Reach problems are\ncomplementary and fundamentally different from standard sum-of-rewards problems\nand temporal logic problems, providing a new perspective on constrained\ndecision-making. We leverage our analysis to propose a variation of Proximal\nPolicy Optimization (DO-HJ-PPO), which solves these problems. Across a range of\ntasks for safe-arrival and multi-target achievement, we demonstrate that\nDO-HJ-PPO produces qualitatively distinct behaviors from previous approaches\nand out-competes a number of baselines in various metrics.", "AI": {"tldr": "The paper introduces novel value functions for dual-objective RL problems, leveraging Hamilton-Jacobi equations to address Reach-Always-Avoid and Reach-Reach problems, and proposes DO-HJ-PPO, outperforming baselines.", "motivation": "Hard constraints in RL degrade performance; Lagrangian methods require complex tuning. The work aims to simplify dual-objective satisfaction without intricate engineering.", "method": "Extends Hamilton-Jacobi RL advances to derive tractable Bellman forms for Reach-Always-Avoid and Reach-Reach problems, proposing DO-HJ-PPO for implementation.", "result": "DO-HJ-PPO produces distinct behaviors and outperforms baselines in safe-arrival and multi-target tasks.", "conclusion": "The approach offers a new perspective on constrained decision-making, solving dual-objective problems effectively with explicit, tractable forms."}}
{"id": "2506.16066", "pdf": "https://arxiv.org/pdf/2506.16066", "abs": "https://arxiv.org/abs/2506.16066", "authors": ["Devesh Kumar"], "title": "Cyberbullying Detection in Hinglish Text Using MURIL and Explainable AI", "categories": ["cs.CL"], "comment": null, "summary": "The growth of digital communication platforms has led to increased\ncyberbullying incidents worldwide, creating a need for automated detection\nsystems to protect users. The rise of code-mixed Hindi-English (Hinglish)\ncommunication on digital platforms poses challenges for existing cyberbullying\ndetection systems, which were designed primarily for monolingual text. This\npaper presents a framework for cyberbullying detection in Hinglish text using\nthe Multilingual Representations for Indian Languages (MURIL) architecture to\naddress limitations in current approaches. Evaluation across six benchmark\ndatasets -- Bohra \\textit{et al.}, BullyExplain, BullySentemo, Kumar \\textit{et\nal.}, HASOC 2021, and Mendeley Indo-HateSpeech -- shows that the MURIL-based\napproach outperforms existing multilingual models including RoBERTa and\nIndicBERT, with improvements of 1.36 to 13.07 percentage points and accuracies\nof 86.97\\% on Bohra, 84.62\\% on BullyExplain, 86.03\\% on BullySentemo, 75.41\\%\non Kumar datasets, 83.92\\% on HASOC 2021, and 94.63\\% on Mendeley dataset. The\nframework includes explainability features through attribution analysis and\ncross-linguistic pattern recognition. Ablation studies show that selective\nlayer freezing, appropriate classification head design, and specialized\npreprocessing for code-mixed content improve detection performance, while\nfailure analysis identifies challenges including context-dependent\ninterpretation, cultural understanding, and cross-linguistic sarcasm detection,\nproviding directions for future research in multilingual cyberbullying\ndetection.", "AI": {"tldr": "The paper introduces a MURIL-based framework for detecting cyberbullying in Hinglish text, outperforming existing models and incorporating explainability features.", "motivation": "The rise of code-mixed Hinglish communication on digital platforms highlights the limitations of monolingual cyberbullying detection systems, necessitating a specialized approach.", "method": "The framework uses the MURIL architecture, with selective layer freezing, tailored classification heads, and preprocessing for code-mixed text.", "result": "The MURIL-based approach outperforms RoBERTa and IndicBERT, achieving accuracies ranging from 75.41% to 94.63% across six datasets.", "conclusion": "The framework addresses key challenges in multilingual cyberbullying detection, with future research directions identified for context, culture, and sarcasm."}}
{"id": "2506.16748", "pdf": "https://arxiv.org/pdf/2506.16748", "abs": "https://arxiv.org/abs/2506.16748", "authors": ["Arjo Chakravarty", "Michael X. Grey", "M. A. Viraj J. Muthugala", "Mohan Rajesh Elara"], "title": "A Scalable Post-Processing Pipeline for Large-Scale Free-Space Multi-Agent Path Planning with PiBT", "categories": ["cs.RO", "cs.MA"], "comment": null, "summary": "Free-space multi-agent path planning remains challenging at large scales.\nMost existing methods either offer optimality guarantees but do not scale\nbeyond a few dozen agents, or rely on grid-world assumptions that do not\ngeneralize well to continuous space. In this work, we propose a hybrid,\nrule-based planning framework that combines Priority Inheritance with\nBacktracking (PiBT) with a novel safety-aware path smoothing method. Our\napproach extends PiBT to 8-connected grids and selectively applies\nstring-pulling based smoothing while preserving collision safety through local\ninteraction awareness and a fallback collision resolution step based on Safe\nInterval Path Planning (SIPP). This design allows us to reduce overall path\nlengths while maintaining real-time performance. We demonstrate that our method\ncan scale to over 500 agents in large free-space environments, outperforming\nexisting any-angle and optimal methods in terms of runtime, while producing\nnear-optimal trajectories in sparse domains. Our results suggest this framework\nis a promising building block for scalable, real-time multi-agent navigation in\nrobotics systems operating beyond grid constraints.", "AI": {"tldr": "A hybrid rule-based planning framework (PiBT with safety-aware path smoothing) scales to 500+ agents in free-space, balancing runtime and near-optimal paths.", "motivation": "Address scalability and optimality gaps in multi-agent path planning, avoiding grid-world limitations.", "method": "Combines Priority Inheritance with Backtracking (PiBT) on 8-connected grids and safety-aware path smoothing with Safe Interval Path Planning (SIPP) for collision resolution.", "result": "Scales to 500+ agents, outperforms existing methods in runtime, and produces near-optimal paths in sparse domains.", "conclusion": "The framework is promising for scalable, real-time multi-agent navigation in robotics beyond grid constraints."}}
{"id": "2506.14684", "pdf": "https://arxiv.org/pdf/2506.14684", "abs": "https://arxiv.org/abs/2506.14684", "authors": ["Aditya Bhattacharjee", "Ivan Meresman Higgs", "Mark Sandler", "Emmanouil Benetos"], "title": "Refining music sample identification with a self-supervised graph neural network", "categories": ["cs.SD", "cs.AI", "cs.IR", "H.5.5; I.2.6"], "comment": "Accepted at International Conference for Music Information Retrieval\n  (ISMIR) 2025", "summary": "Automatic sample identification (ASID), the detection and identification of\nportions of audio recordings that have been reused in new musical works, is an\nessential but challenging task in the field of audio query-based retrieval.\nWhile a related task, audio fingerprinting, has made significant progress in\naccurately retrieving musical content under \"real world\" (noisy, reverberant)\nconditions, ASID systems struggle to identify samples that have undergone\nmusical modifications. Thus, a system robust to common music production\ntransformations such as time-stretching, pitch-shifting, effects processing,\nand underlying or overlaying music is an important open challenge.\n  In this work, we propose a lightweight and scalable encoding architecture\nemploying a Graph Neural Network within a contrastive learning framework. Our\nmodel uses only 9% of the trainable parameters compared to the current\nstate-of-the-art system while achieving comparable performance, reaching a mean\naverage precision (mAP) of 44.2%.\n  To enhance retrieval quality, we introduce a two-stage approach consisting of\nan initial coarse similarity search for candidate selection, followed by a\ncross-attention classifier that rejects irrelevant matches and refines the\nranking of retrieved candidates - an essential capability absent in prior\nmodels. In addition, because queries in real-world applications are often short\nin duration, we benchmark our system for short queries using new fine-grained\nannotations for the Sample100 dataset, which we publish as part of this work.", "AI": {"tldr": "A lightweight Graph Neural Network model for ASID achieves comparable performance to state-of-the-art with fewer parameters, using a two-stage retrieval approach and benchmarking short queries.", "motivation": "ASID struggles with identifying samples modified by musical transformations, unlike audio fingerprinting, necessitating a robust solution.", "method": "Proposes a Graph Neural Network in a contrastive learning framework, with a two-stage retrieval system (coarse search + cross-attention classifier).", "result": "Achieves 44.2% mAP with only 9% of the parameters of the current best system.", "conclusion": "The model is scalable, efficient, and addresses key ASID challenges, with published annotations for short queries."}}
{"id": "2409.10819", "pdf": "https://arxiv.org/pdf/2409.10819", "abs": "https://arxiv.org/abs/2409.10819", "authors": ["Jiarui Hai", "Yong Xu", "Hao Zhang", "Chenxing Li", "Helin Wang", "Mounya Elhilali", "Dong Yu"], "title": "EzAudio: Enhancing Text-to-Audio Generation with Efficient Diffusion Transformer", "categories": ["eess.AS", "cs.SD"], "comment": "Accepted at Interspeech 2025", "summary": "We introduce EzAudio, a text-to-audio (T2A) generation framework designed to\nproduce high-quality, natural-sounding sound effects. Core designs include: (1)\nWe propose EzAudio-DiT, an optimized Diffusion Transformer (DiT) designed for\naudio latent representations, improving convergence speed, as well as parameter\nand memory efficiency. (2) We apply a classifier-free guidance (CFG) rescaling\ntechnique to mitigate fidelity loss at higher CFG scores and enhancing prompt\nadherence without compromising audio quality. (3) We propose a synthetic\ncaption generation strategy leveraging recent advances in audio understanding\nand LLMs to enhance T2A pretraining. We show that EzAudio, with its\ncomputationally efficient architecture and fast convergence, is a competitive\nopen-source model that excels in both objective and subjective evaluations by\ndelivering highly realistic listening experiences. Code, data, and pre-trained\nmodels are released at: https://haidog-yaqub.github.io/EzAudio-Page/.", "AI": {"tldr": "EzAudio is a T2A framework using optimized Diffusion Transformer (DiT) and CFG rescaling for high-quality sound effects, with synthetic captions for pretraining.", "motivation": "To create high-quality, natural-sounding sound effects efficiently with improved convergence and fidelity.", "method": "Uses EzAudio-DiT for audio latent representations, CFG rescaling for fidelity, and synthetic captions for pretraining.", "result": "Competitive open-source model with fast convergence, realistic audio, and strong evaluations.", "conclusion": "EzAudio is efficient, high-quality, and open-source, excelling in T2A generation."}}
{"id": "2506.16592", "pdf": "https://arxiv.org/pdf/2506.16592", "abs": "https://arxiv.org/abs/2506.16592", "authors": ["Muhammad Azeem Aslam", "Asim Naveed", "Nisar Ahmed"], "title": "Hybrid Attention Network for Accurate Breast Tumor Segmentation in Ultrasound Images", "categories": ["eess.IV", "cs.AI", "cs.CV"], "comment": null, "summary": "Breast ultrasound imaging is a valuable tool for early breast cancer\ndetection, but automated tumor segmentation is challenging due to inherent\nnoise, variations in scale of lesions, and fuzzy boundaries. To address these\nchallenges, we propose a novel hybrid attention-based network for lesion\nsegmentation. Our proposed architecture integrates a pre-trained DenseNet121 in\nthe encoder part for robust feature extraction with a multi-branch\nattention-enhanced decoder tailored for breast ultrasound images. The\nbottleneck incorporates Global Spatial Attention (GSA), Position Encoding (PE),\nand Scaled Dot-Product Attention (SDPA) to learn global context, spatial\nrelationships, and relative positional features. The Spatial Feature\nEnhancement Block (SFEB) is embedded at skip connections to refine and enhance\nspatial features, enabling the network to focus more effectively on tumor\nregions. A hybrid loss function combining Binary Cross-Entropy (BCE) and\nJaccard Index loss optimizes both pixel-level accuracy and region-level overlap\nmetrics, enhancing robustness to class imbalance and irregular tumor shapes.\nExperiments on public datasets demonstrate that our method outperforms existing\napproaches, highlighting its potential to assist radiologists in early and\naccurate breast cancer diagnosis.", "AI": {"tldr": "A hybrid attention-based network is proposed for breast ultrasound tumor segmentation, integrating DenseNet121, multi-branch attention, and a hybrid loss function, outperforming existing methods.", "motivation": "Automated tumor segmentation in breast ultrasound is challenging due to noise, scale variations, and fuzzy boundaries, necessitating a robust solution.", "method": "The network combines DenseNet121 for feature extraction with an attention-enhanced decoder, using GSA, PE, SDPA, and SFEB for spatial and positional feature refinement. A hybrid loss function (BCE + Jaccard) optimizes accuracy.", "result": "The method outperforms existing approaches on public datasets, showing promise for early breast cancer diagnosis.", "conclusion": "The proposed network effectively addresses segmentation challenges, offering potential to aid radiologists in accurate diagnosis."}}
{"id": "2506.15976", "pdf": "https://arxiv.org/pdf/2506.15976", "abs": "https://arxiv.org/abs/2506.15976", "authors": ["Jingwei Zhang", "Xi Han", "Hong Qin", "Mahdi S. Hosseini", "Dimitris Samaras"], "title": "LBMamba: Locally Bi-directional Mamba", "categories": ["cs.CV"], "comment": "Submitted to TMLR", "summary": "Mamba, a State Space Model (SSM) that accelerates training by recasting\nrecurrence as a parallel selective scan, has recently emerged as a\nlinearly-scaling, efficient alternative to self-attention. Because of its\nunidirectional nature, each state in Mamba only has information of its previous\nstates and is blind to states after. Current Mamba-based computer-vision\nmethods typically overcome this limitation by augmenting Mamba's global forward\nscan with a global backward scan, forming a bi-directional scan that restores a\nfull receptive field. However, this operation doubles the computational load,\neroding much of the efficiency advantage that originally Mamba have. To\neliminate this extra scans, we introduce LBMamba, a locally bi-directional SSM\nblock that embeds a lightweight locally backward scan inside the forward\nselective scan and executes it entirely in per-thread registers. Building on\nLBMamba, we present LBVim, a scalable vision backbone that alternates scan\ndirections every two layers to recover a global receptive field without extra\nbackward sweeps. We validate the versatility of our approach on both natural\nimages and whole slide images (WSIs). We show that our LBVim constantly offers\na superior performance-throughput trade-off. That is under the same throughput,\nLBVim achieves 0.8% to 1.6% higher top-1 accuracy on the ImageNet-1K\nclassification dataset, 0.6% to 2.7% higher mIoU on the ADE20K semantic\nsegmentation dataset, 0.9% higher APb and 1.1% higher APm on the COCO detection\ndataset. We also integrate LBMamba into the SOTA pathology multiple instance\nlearning (MIL) approach, MambaMIL, which uses single directional scan.\nExperiments on 3 public WSI classification datasets for show that our method\nachieves a relative improvement of up to 3.06% better AUC, 3.39% better F1,\n1.67% better accuracy.", "AI": {"tldr": "LBMamba introduces a locally bi-directional SSM block to avoid extra scans, improving efficiency and performance in vision tasks.", "motivation": "Overcome the computational inefficiency of bi-directional scans in Mamba-based vision methods while maintaining performance.", "method": "Embed a lightweight locally backward scan inside the forward selective scan, alternating scan directions every two layers in LBVim.", "result": "LBVim outperforms in accuracy, mIoU, APb, APm, and integrates well with MambaMIL for WSI classification.", "conclusion": "LBMamba offers a superior performance-throughput trade-off, validating its versatility across vision tasks."}}
{"id": "2506.15699", "pdf": "https://arxiv.org/pdf/2506.15699", "abs": "https://arxiv.org/abs/2506.15699", "authors": ["Shengyuan Hu", "Neil Kale", "Pratiksha Thaker", "Yiwei Fu", "Steven Wu", "Virginia Smith"], "title": "BLUR: A Benchmark for LLM Unlearning Robust to Forget-Retain Overlap", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Machine unlearning has the potential to improve the safety of large language\nmodels (LLMs) by removing sensitive or harmful information post hoc. A key\nchallenge in unlearning involves balancing between forget quality (effectively\nunlearning undesirable information) and retain quality (maintaining good\nperformance on other, general tasks). Unfortunately, as we show, current LLM\nunlearning benchmarks contain highly disparate forget and retain sets --\npainting a false picture of the effectiveness of LLM unlearning methods. This\ncan be particularly problematic because it opens the door for benign\nperturbations, such as relearning attacks, to easily reveal supposedly\nunlearned knowledge once models are deployed. To address this, we present\n$\\texttt{BLUR}$: a benchmark for LLM unlearning that provides more realistic\nscenarios of forget-retain overlap. $\\texttt{BLUR}$ significantly expands on\nexisting unlearning benchmarks by providing extended evaluation tasks, combined\nforget/retain queries, and relearning datasets of varying degrees of\ndifficulty. Despite the benign nature of the queries considered, we find that\nthe performance of existing methods drops significantly when evaluated on\n$\\texttt{BLUR}$, with simple approaches performing better on average than more\nrecent methods. These results highlight the importance of robust evaluation and\nsuggest several important directions of future study. Our benchmark is publicly\navailable at: https://huggingface.co/datasets/forgelab/BLUR", "AI": {"tldr": "The paper introduces $\texttt{BLUR}$, a benchmark for LLM unlearning, addressing flaws in current benchmarks by providing realistic forget-retain overlap scenarios. It shows existing methods perform poorly on $\texttt{BLUR}$, emphasizing the need for robust evaluation.", "motivation": "Current LLM unlearning benchmarks are flawed, giving a misleading picture of effectiveness. This can lead to vulnerabilities like relearning attacks, necessitating a more realistic benchmark.", "method": "The authors develop $\texttt{BLUR}$, a benchmark with extended evaluation tasks, combined forget/retain queries, and relearning datasets of varying difficulty.", "result": "Existing unlearning methods perform significantly worse on $\texttt{BLUR}$, with simpler approaches outperforming recent ones.", "conclusion": "The paper underscores the importance of robust evaluation in LLM unlearning and suggests future research directions. $\texttt{BLUR}$ is publicly available for use."}}
{"id": "2506.16042", "pdf": "https://arxiv.org/pdf/2506.16042", "abs": "https://arxiv.org/abs/2506.16042", "authors": ["Reyna Abhyankar", "Qi Qi", "Yiying Zhang"], "title": "OSWorld-Human: Benchmarking the Efficiency of Computer-Use Agents", "categories": ["cs.AI", "cs.LG", "cs.OS"], "comment": null, "summary": "Generative AI is being leveraged to solve a variety of computer-use tasks\ninvolving desktop applications. State-of-the-art systems have focused solely on\nimproving accuracy on leading benchmarks. However, these systems are\npractically unusable due to extremely high end-to-end latency (e.g., tens of\nminutes) for tasks that typically take humans just a few minutes to complete.\nTo understand the cause behind this and to guide future developments of\ncomputer agents, we conduct the first study on the temporal performance of\ncomputer-use agents on OSWorld, the flagship benchmark in computer-use AI. We\nfind that large model calls for planning and reflection account for the\nmajority of the overall latency, and as an agent uses more steps to complete a\ntask, each successive step can take 3x longer than steps at the beginning of a\ntask. We then construct OSWorld-Human, a manually annotated version of the\noriginal OSWorld dataset that contains a human-determined trajectory for each\ntask. We evaluate 16 agents on their efficiency using OSWorld-Human and found\nthat even the highest-scoring agents on OSWorld take 1.4-2.7x more steps than\nnecessary.", "AI": {"tldr": "Generative AI for desktop tasks has high latency due to excessive model calls for planning and reflection, making it impractical. A study on OSWorld reveals inefficiencies, with agents taking 1.4-2.7x more steps than humans.", "motivation": "Current generative AI systems for desktop tasks are impractical due to high latency, despite high benchmark accuracy. Understanding the causes can guide future improvements.", "method": "Conducted a study on OSWorld to analyze temporal performance, identifying model calls as the main latency source. Created OSWorld-Human, a human-annotated dataset, to evaluate agent efficiency.", "result": "Large model calls dominate latency, and agents take significantly more steps (1.4-2.7x) than humans to complete tasks.", "conclusion": "Future AI agents must optimize planning and reflection to reduce latency and improve efficiency for practical desktop task automation."}}
{"id": "2506.16123", "pdf": "https://arxiv.org/pdf/2506.16123", "abs": "https://arxiv.org/abs/2506.16123", "authors": ["Natapong Nitarach", "Warit Sirichotedumrong", "Panop Pitchayarthorn", "Pittawat Taveekitworachai", "Potsawee Manakul", "Kunat Pipatanakul"], "title": "FinCoT: Grounding Chain-of-Thought in Expert Financial Reasoning", "categories": ["cs.CL"], "comment": null, "summary": "This paper presents FinCoT, a structured chain-of-thought (CoT) prompting\napproach that incorporates insights from domain-specific expert financial\nreasoning to guide the reasoning traces of large language models. We\ninvestigate that there are three main prompting styles in FinNLP: (1) standard\nprompting--zero-shot prompting; (2) unstructured CoT--CoT prompting without an\nexplicit reasoning structure, such as the use of tags; and (3) structured CoT\nprompting--CoT prompting with explicit instructions or examples that define\nstructured reasoning steps. Previously, FinNLP has primarily focused on prompt\nengineering with either standard or unstructured CoT prompting. However,\nstructured CoT prompting has received limited attention in prior work.\nFurthermore, the design of reasoning structures in structured CoT prompting is\noften based on heuristics from non-domain experts. In this study, we\ninvestigate each prompting approach in FinNLP. We evaluate the three main\nprompting styles and FinCoT on CFA-style questions spanning ten financial\ndomains. We observe that FinCoT improves performance from 63.2% to 80.5% and\nQwen-2.5-7B-Instruct from 69.7% to 74.2%, while reducing generated tokens\neight-fold compared to structured CoT prompting. Our findings show that\ndomain-aligned structured prompts not only improve performance and reduce\ninference costs but also yield more interpretable and expert-aligned reasoning\ntraces.", "AI": {"tldr": "FinCoT introduces structured CoT prompting for financial reasoning, improving model performance and reducing token usage.", "motivation": "Prior FinNLP work lacks domain-specific structured CoT prompting, relying on heuristics from non-experts.", "method": "Evaluates three prompting styles (standard, unstructured CoT, structured CoT) and FinCoT on CFA-style questions.", "result": "FinCoT boosts performance (63.2% to 80.5%) and reduces tokens eight-fold compared to structured CoT.", "conclusion": "Domain-aligned structured prompts enhance performance, cost-efficiency, and interpretability."}}
{"id": "2506.16971", "pdf": "https://arxiv.org/pdf/2506.16971", "abs": "https://arxiv.org/abs/2506.16971", "authors": ["Oliver Sch\u00f6n", "Sofie Haesaert", "Sadegh Soudjani"], "title": "Formal Control for Uncertain Systems via Contract-Based Probabilistic Surrogates (Extended Version)", "categories": ["cs.SY", "cs.AI", "cs.MA", "eess.SY"], "comment": "26 pages, 5 figures, extended version of paper accepted for\n  publication at QEST 2025", "summary": "The requirement for identifying accurate system representations has not only\nbeen a challenge to fulfill, but it has compromised the scalability of formal\nmethods, as the resulting models are often too complex for effective decision\nmaking with formal correctness and performance guarantees. Focusing on\nprobabilistic simulation relations and surrogate models of stochastic systems,\nwe propose an approach that significantly enhances the scalability and\npractical applicability of such simulation relations by eliminating the need to\ncompute error bounds directly. As a result, we provide an abstraction-based\ntechnique that scales effectively to higher dimensions while addressing complex\nnonlinear agent-environment interactions with infinite-horizon temporal logic\nguarantees amidst uncertainty. Our approach trades scalability for conservatism\nfavorably, as demonstrated on a complex high-dimensional vehicle intersection\ncase study.", "AI": {"tldr": "Proposes a scalable abstraction-based technique for stochastic systems, eliminating direct error-bound computation, demonstrated on a high-dimensional vehicle intersection case.", "motivation": "Addresses the challenge of complex system representations compromising formal methods' scalability and decision-making effectiveness.", "method": "Uses probabilistic simulation relations and surrogate models to avoid computing error bounds directly, focusing on nonlinear agent-environment interactions.", "result": "Enhances scalability and applicability, trading conservatism for scalability, with infinite-horizon temporal logic guarantees.", "conclusion": "The approach effectively scales to higher dimensions, demonstrated in a complex case study."}}
{"id": "2410.20564", "pdf": "https://arxiv.org/pdf/2410.20564", "abs": "https://arxiv.org/abs/2410.20564", "authors": ["Sadia Nowrin", "Keith Vertanen"], "title": "Using Confidence Scores to Improve Eyes-free Detection of Speech Recognition Errors", "categories": ["cs.HC", "cs.SD", "eess.AS"], "comment": "To appear in PErvasive Technologies Related to Assistive Environments\n  (PETRA '25)", "summary": "Conversational systems rely heavily on speech recognition to interpret and\nrespond to user commands and queries. Despite progress on speech recognition\naccuracy, errors may still sometimes occur and can significantly affect the\nend-user utility of such systems. While visual feedback can help detect errors,\nit may not always be practical, especially for people who are blind or\nlow-vision. In this study, we investigate ways to improve error detection by\nmanipulating the audio output of the transcribed text based on the recognizer's\nconfidence level in its result. Our findings show that selectively slowing down\nthe audio when the recognizer exhibited uncertainty led to a 12% relative\nincrease in participants' ability to detect errors compared to uniformly\nslowing the audio. It also reduced the time it took participants to listen to\nthe recognition result and decide if there was an error by 11%.", "AI": {"tldr": "Improving error detection in speech recognition by adjusting audio speed based on recognizer confidence, leading to better accuracy and faster decisions.", "motivation": "Speech recognition errors reduce system utility, and visual feedback isn't always practical, especially for blind or low-vision users.", "method": "Manipulate audio output speed based on the recognizer's confidence level; selectively slow down when uncertainty is high.", "result": "12% relative increase in error detection and 11% reduction in decision time compared to uniform slowing.", "conclusion": "Adjusting audio speed based on confidence improves error detection efficiency, benefiting users, especially those with visual impairments."}}
{"id": "2502.09859", "pdf": "https://arxiv.org/pdf/2502.09859", "abs": "https://arxiv.org/abs/2502.09859", "authors": ["Naoyuki Kamo", "Naohiro Tawara", "Atsushi Ando", "Takatomo Kano", "Hiroshi Sato", "Rintaro Ikeshita", "Takafumi Moriya", "Shota Horiguchi", "Kohei Matsuura", "Atsunori Ogawa", "Alexis Plaquet", "Takanori Ashihara", "Tsubasa Ochiai", "Masato Mimura", "Marc Delcroix", "Tomohiro Nakatani", "Taichi Asami", "Shoko Araki"], "title": "Microphone Array Geometry Independent Multi-Talker Distant ASR: NTT System for the DASR Task of the CHiME-8 Challenge", "categories": ["eess.AS", "eess.SP"], "comment": "55 pages, 12 figures", "summary": "In this paper, we introduce a multi-talker distant automatic speech\nrecognition (DASR) system we designed for the DASR task 1 of the CHiME-8\nchallenge. Our system performs speaker counting, diarization, and ASR. It\nhandles various recording conditions, from diner parties to professional\nmeetings and from two to eight speakers. We perform diarization first, followed\nby speech enhancement, and then ASR as the challenge baseline. However, we\nintroduced several key refinements. First, we derived a powerful speaker\ndiarization relying on end-to-end speaker diarization with vector clustering\n(EEND-VC), multi-channel speaker counting using enhanced embeddings from\nEEND-VC, and target-speaker voice activity detection (TS-VAD). For speech\nenhancement, we introduced a novel microphone selection rule to better select\nthe most relevant microphones among the distributed microphones and\ninvestigated improvements to beamforming. Finally, for ASR, we developed\nseveral models exploiting Whisper and WavLM speech foundation models. We\npresent the results we submitted to the challenge and updated results we\nobtained afterward. Our strongest system achieves a 63% relative macro tcpWER\nimprovement over the baseline and outperforms the challenge best results on the\nNOTSOFAR-1 meeting evaluation data among geometry-independent systems.", "AI": {"tldr": "A multi-talker DASR system for CHiME-8 Task 1, featuring speaker counting, diarization, and ASR, with refinements like EEND-VC, TS-VAD, and improved beamforming, achieving a 63% tcpWER improvement.", "motivation": "To address the challenges of multi-talker distant speech recognition under varied conditions (e.g., diner parties, meetings) and improve upon the baseline system.", "method": "The system performs diarization (using EEND-VC and TS-VAD), speech enhancement (novel microphone selection and beamforming), and ASR (leveraging Whisper and WavLM models).", "result": "Achieves a 63% relative macro tcpWER improvement over the baseline and outperforms best results on NOTSOFAR-1 meeting data for geometry-independent systems.", "conclusion": "The refinements in diarization, speech enhancement, and ASR significantly improve performance, demonstrating the system's effectiveness for multi-talker DASR."}}
{"id": "2506.16631", "pdf": "https://arxiv.org/pdf/2506.16631", "abs": "https://arxiv.org/abs/2506.16631", "authors": ["Saghir Alfasly", "Ghazal Alabtah", "H. R. Tizhoosh"], "title": "Overfitting in Histopathology Model Training: The Need for Customized Architectures", "categories": ["eess.IV", "cs.CV"], "comment": null, "summary": "This study investigates the critical problem of overfitting in deep learning\nmodels applied to histopathology image analysis. We show that simply adopting\nand fine-tuning large-scale models designed for natural image analysis often\nleads to suboptimal performance and significant overfitting when applied to\nhistopathology tasks. Through extensive experiments with various model\narchitectures, including ResNet variants and Vision Transformers (ViT), we show\nthat increasing model capacity does not necessarily improve performance on\nhistopathology datasets. Our findings emphasize the need for customized\narchitectures specifically designed for histopathology image analysis,\nparticularly when working with limited datasets. Using Oesophageal\nAdenocarcinomas public dataset, we demonstrate that simpler, domain-specific\narchitectures can achieve comparable or better performance while minimizing\noverfitting.", "AI": {"tldr": "Overfitting in deep learning for histopathology image analysis is addressed by showing that large-scale natural image models underperform and overfit. Domain-specific architectures outperform them.", "motivation": "To highlight the limitations of using natural image models for histopathology tasks and the need for specialized solutions.", "method": "Experiments with ResNet variants and Vision Transformers (ViT) on histopathology datasets, comparing performance and overfitting.", "result": "Increasing model capacity doesn't improve performance; simpler, domain-specific architectures perform better and reduce overfitting.", "conclusion": "Customized architectures for histopathology are essential, especially with limited datasets, to avoid overfitting and improve results."}}
{"id": "2506.15977", "pdf": "https://arxiv.org/pdf/2506.15977", "abs": "https://arxiv.org/abs/2506.15977", "authors": ["Sungrae Hong", "Hyeongmin Park", "Youngsin Ko", "Sol Lee", "Bryan Wong", "Mun Yong Yi"], "title": "Towards Classifying Histopathological Microscope Images as Time Series Data", "categories": ["cs.CV"], "comment": "5 pages, 4 figures, Accepted by International Symposium on Biomedical\n  Imaging (ISBI) 2025", "summary": "As the frontline data for cancer diagnosis, microscopic pathology images are\nfundamental for providing patients with rapid and accurate treatment. However,\ndespite their practical value, the deep learning community has largely\noverlooked their usage. This paper proposes a novel approach to classifying\nmicroscopy images as time series data, addressing the unique challenges posed\nby their manual acquisition and weakly labeled nature. The proposed method fits\nimage sequences of varying lengths to a fixed-length target by leveraging\nDynamic Time-series Warping (DTW). Attention-based pooling is employed to\npredict the class of the case simultaneously. We demonstrate the effectiveness\nof our approach by comparing performance with various baselines and showcasing\nthe benefits of using various inference strategies in achieving stable and\nreliable results. Ablation studies further validate the contribution of each\ncomponent. Our approach contributes to medical image analysis by not only\nembracing microscopic images but also lifting them to a trustworthy level of\nperformance.", "AI": {"tldr": "A novel method classifies microscopy images as time series using Dynamic Time-series Warping (DTW) and attention-based pooling, achieving reliable performance in medical image analysis.", "motivation": "Microscopic pathology images are crucial for cancer diagnosis but underutilized in deep learning. This paper addresses their manual acquisition and weakly labeled challenges.", "method": "Proposes classifying microscopy images as time series, using DTW to fit varying-length sequences to fixed-length targets and attention-based pooling for class prediction.", "result": "Outperforms baselines, demonstrates stable results with various inference strategies, and validates contributions through ablation studies.", "conclusion": "The approach advances medical image analysis by effectively utilizing microscopy images and achieving trustworthy performance."}}
{"id": "2506.15700", "pdf": "https://arxiv.org/pdf/2506.15700", "abs": "https://arxiv.org/abs/2506.15700", "authors": ["Minjae Cho", "Hiroyasu Tsukamoto", "Huy Trong Tran"], "title": "Contraction Actor-Critic: Contraction Metric-Guided Reinforcement Learning for Robust Path Tracking", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Control contraction metrics (CCMs) provide a framework to co-synthesize a\ncontroller and a corresponding contraction metric -- a positive-definite\nRiemannian metric under which a closed-loop system is guaranteed to be\nincrementally exponentially stable. However, the synthesized controller only\nensures that all the trajectories of the system converge to one single\ntrajectory and, as such, does not impose any notion of optimality across an\nentire trajectory. Furthermore, constructing CCMs requires a known dynamics\nmodel and non-trivial effort in solving an infinite-dimensional convex\nfeasibility problem, which limits its scalability to complex systems featuring\nhigh dimensionality with uncertainty. To address these issues, we propose to\nintegrate CCMs into reinforcement learning (RL), where CCMs provide\ndynamics-informed feedback for learning control policies that minimize\ncumulative tracking error under unknown dynamics. We show that our algorithm,\ncalled contraction actor-critic (CAC), formally enhances the capability of CCMs\nto provide a set of contracting policies with the long-term optimality of RL in\na fully automated setting. Given a pre-trained dynamics model, CAC\nsimultaneously learns a contraction metric generator (CMG) -- which generates a\ncontraction metric -- and uses an actor-critic algorithm to learn an optimal\ntracking policy guided by that metric. We demonstrate the effectiveness of our\nalgorithm relative to established baselines through extensive empirical\nstudies, including simulated and real-world robot experiments, and provide a\ntheoretical rationale for incorporating contraction theory into RL.", "AI": {"tldr": "The paper integrates Control Contraction Metrics (CCMs) with reinforcement learning (RL) to enhance optimality and scalability in control policies, proposing the Contraction Actor-Critic (CAC) algorithm.", "motivation": "CCMs alone lack optimality guarantees and require known dynamics, limiting scalability. Integrating CCMs with RL addresses these issues by leveraging RL's long-term optimality and adaptability to unknown dynamics.", "method": "The CAC algorithm learns a contraction metric generator (CMG) and uses actor-critic RL to optimize tracking policies guided by the metric, combining CCMs' stability with RL's adaptability.", "result": "CAC outperforms baselines in simulated and real-world robot experiments, demonstrating improved control performance and scalability.", "conclusion": "Integrating CCMs with RL via CAC enhances control policy stability and optimality, offering a scalable solution for complex systems with uncertain dynamics."}}
{"id": "2506.16087", "pdf": "https://arxiv.org/pdf/2506.16087", "abs": "https://arxiv.org/abs/2506.16087", "authors": ["Tom Jeleniewski", "Hamied Nabizada", "Jonathan Reif", "Felix Gehlhoff", "Alexander Fay"], "title": "Consistency Verification in Ontology-Based Process Models with Parameter Interdependencies", "categories": ["cs.AI", "cs.DB"], "comment": "This paper is accepted at IEEE ETFA 2025 and will be published in the\n  conference proceedings", "summary": "The formalization of process knowledge using ontologies enables consistent\nmodeling of parameter interdependencies in manufacturing. These\ninterdependencies are typically represented as mathematical expressions that\ndefine relations between process parameters, supporting tasks such as\ncalculation, validation, and simulation. To support cross-context application\nand knowledge reuse, such expressions are often defined in a generic form and\napplied across multiple process contexts. This highlights the necessity of a\nconsistent and semantically coherent model to ensure the correctness of data\nretrieval and interpretation. Consequently, dedicated mechanisms are required\nto address key challenges such as selecting context-relevant data, ensuring\nunit compatibility between variables and data elements, and verifying the\ncompleteness of input data required for evaluating mathematical expressions.\nThis paper presents a set of verification mechanisms for a previously developed\nontology-based process model that integrates standardized process semantics,\ndata element definitions, and formal mathematical constructs. The approach\nincludes (i) SPARQL-based filtering to retrieve process-relevant data, (ii) a\nunit consistency check based on expected-unit annotations and semantic\nclassification, and (iii) a data completeness check to validate the\nevaluability of interdependencies. The applicability of the approach is\ndemonstrated with a use case from Resin Transfer Molding (RTM), supporting the\ndevelopment of machine-interpretable and verifiable engineering models.", "AI": {"tldr": "The paper presents verification mechanisms for an ontology-based process model to ensure correct data retrieval and interpretation in manufacturing, demonstrated with a Resin Transfer Molding (RTM) use case.", "motivation": "To address challenges like context-relevant data selection, unit compatibility, and input data completeness in modeling manufacturing process interdependencies.", "method": "Uses SPARQL-based filtering, unit consistency checks, and data completeness checks within an ontology-based process model.", "result": "Demonstrates applicability in RTM, supporting machine-interpretable and verifiable engineering models.", "conclusion": "The approach enhances consistency and correctness in modeling process interdependencies, facilitating knowledge reuse and cross-context application."}}
{"id": "2506.16151", "pdf": "https://arxiv.org/pdf/2506.16151", "abs": "https://arxiv.org/abs/2506.16151", "authors": ["Chenxi Wang", "Yixuan Zhang", "Lang Gao", "Zixiang Xu", "Zirui Song", "Yanbo Wang", "Xiuying Chen"], "title": "Under the Shadow of Babel: How Language Shapes Reasoning in LLMs", "categories": ["cs.CL", "cs.AI"], "comment": "15 pages, 10 figures", "summary": "Language is not only a tool for communication but also a medium for human\ncognition and reasoning. If, as linguistic relativity suggests, the structure\nof language shapes cognitive patterns, then large language models (LLMs)\ntrained on human language may also internalize the habitual logical structures\nembedded in different languages. To examine this hypothesis, we introduce\nBICAUSE, a structured bilingual dataset for causal reasoning, which includes\nsemantically aligned Chinese and English samples in both forward and reversed\ncausal forms. Our study reveals three key findings: (1) LLMs exhibit\ntypologically aligned attention patterns, focusing more on causes and\nsentence-initial connectives in Chinese, while showing a more balanced\ndistribution in English. (2) Models internalize language-specific preferences\nfor causal word order and often rigidly apply them to atypical inputs, leading\nto degraded performance, especially in Chinese. (3) When causal reasoning\nsucceeds, model representations converge toward semantically aligned\nabstractions across languages, indicating a shared understanding beyond surface\nform. Overall, these results suggest that LLMs not only mimic surface\nlinguistic forms but also internalize the reasoning biases shaped by language.\nRooted in cognitive linguistic theory, this phenomenon is for the first time\nempirically verified through structural analysis of model internals.", "AI": {"tldr": "LLMs internalize language-specific reasoning biases, as shown by attention patterns and performance on a bilingual causal reasoning dataset (BICAUSE).", "motivation": "To test if LLMs internalize habitual logical structures from language, inspired by linguistic relativity.", "method": "Used BICAUSE, a bilingual dataset with aligned Chinese and English causal samples, to analyze LLM attention and reasoning patterns.", "result": "LLMs show language-specific attention and reasoning biases, with degraded performance on atypical inputs, but converge on shared semantic abstractions when reasoning succeeds.", "conclusion": "LLMs mimic and internalize language-shaped reasoning biases, empirically verified through structural analysis."}}
{"id": "2406.11318", "pdf": "https://arxiv.org/pdf/2406.11318", "abs": "https://arxiv.org/abs/2406.11318", "authors": ["Kangwei Qi", "Qiong Wu", "Pingyi Fan", "Nan Cheng", "Qiang Fan", "Jiangzhou Wang"], "title": "Reconfigurable Intelligent Surface Assisted VEC Based on Multi-Agent Reinforcement Learning", "categories": ["cs.MA", "cs.DC", "cs.LG", "cs.NI", "eess.SP"], "comment": "This paper has been accepted by IEEE communications letters. The\n  source code has been released at:\n  https://github.com/qiongwu86/RIS-VEC-MARL.git", "summary": "Vehicular edge computing (VEC) is an emerging technology that enables\nvehicles to perform high-intensity tasks by executing tasks locally or\noffloading them to nearby edge devices. However, obstacles such as buildings\nmay degrade the communications and incur communication interruptions, and thus\nthe vehicle may not meet the requirement for task offloading. Reconfigurable\nintelligent surfaces (RIS) is introduced to support vehicle communication and\nprovide an alternative communication path. The system performance can be\nimproved by flexibly adjusting the phase-shift of the RIS. For RIS-assisted VEC\nsystem where tasks arrive randomly, we design a control scheme that considers\noffloading power, local power allocation and phase-shift optimization. To solve\nthis non-convex problem, we propose a new deep reinforcement learning (DRL)\nframework that employs modified multi-agent deep deterministic policy gradient\n(MADDPG) approach to optimize the power allocation for vehicle users (VUs) and\nblock coordinate descent (BCD) algorithm to optimize the phase-shift of the\nRIS. Simulation results show that our proposed scheme outperforms the\ncentralized deep deterministic policy gradient (DDPG) scheme and random scheme.", "AI": {"tldr": "The paper proposes a DRL framework for RIS-assisted VEC systems to optimize power allocation and phase-shift, outperforming existing schemes.", "motivation": "Obstacles degrade VEC communication; RIS provides an alternative path, but optimizing system performance is challenging due to random task arrivals.", "method": "A DRL framework combines MADDPG for power allocation and BCD for RIS phase-shift optimization.", "result": "Simulations show the proposed scheme outperforms DDPG and random schemes.", "conclusion": "The framework effectively improves RIS-assisted VEC system performance."}}
{"id": "2502.15849", "pdf": "https://arxiv.org/pdf/2502.15849", "abs": "https://arxiv.org/abs/2502.15849", "authors": ["Ilana Shapiro", "Ruanqianqian Huang", "Zachary Novack", "Cheng-i Wang", "Hao-Wen Dong", "Taylor Berg-Kirkpatrick", "Shlomo Dubnov", "Sorin Lerner"], "title": "Synthesizing Composite Hierarchical Structure from Symbolic Music Corpora", "categories": ["cs.AI", "cs.LO", "cs.SD", "G.1.6; I.2.4; J.5; G.2.2"], "comment": "In Proceedings of the 34th International Joint Conference on\n  Artificial Intelligence (IJCAI '25), Montreal, Canada, August 2025", "summary": "Western music is an innately hierarchical system of interacting levels of\nstructure, from fine-grained melody to high-level form. In order to analyze\nmusic compositions holistically and at multiple granularities, we propose a\nunified, hierarchical meta-representation of musical structure called the\nstructural temporal graph (STG). For a single piece, the STG is a data\nstructure that defines a hierarchy of progressively finer structural musical\nfeatures and the temporal relationships between them. We use the STG to enable\na novel approach for deriving a representative structural summary of a music\ncorpus, which we formalize as a nested NP-hard combinatorial optimization\nproblem extending the Generalized Median Graph problem. Our approach first\napplies simulated annealing to develop a measure of structural distance between\ntwo music pieces rooted in graph isomorphism. Our approach then combines the\nformal guarantees of SMT solvers with nested simulated annealing over\nstructural distances to produce a structurally sound, representative centroid\nSTG for an entire corpus of STGs from individual pieces. To evaluate our\napproach, we conduct experiments verifying that structural distance accurately\ndifferentiates between music pieces, and that derived centroids accurately\nstructurally characterize their corpora.", "AI": {"tldr": "The paper proposes a hierarchical meta-representation called the Structural Temporal Graph (STG) for analyzing music at multiple levels. It introduces a method to derive structural summaries of music corpora using combinatorial optimization and simulated annealing, validated by experiments.", "motivation": "Western music's hierarchical structure requires a unified representation for holistic analysis. The STG aims to capture multi-granularity features and temporal relationships in music.", "method": "The method involves creating STGs for individual pieces, measuring structural distance via simulated annealing, and using SMT solvers with nested simulated annealing to derive centroid STGs for corpora.", "result": "Experiments confirm that structural distance differentiates music pieces and that centroid STGs accurately represent their corpora.", "conclusion": "The STG and proposed method effectively analyze and summarize music structure, validated by empirical results."}}
{"id": "2506.09707", "pdf": "https://arxiv.org/pdf/2506.09707", "abs": "https://arxiv.org/abs/2506.09707", "authors": ["Suhas BN", "Andrew M. Sherrill", "Jyoti Alaparthi", "Dominik Mattioli", "Rosa I. Arriaga", "Chris W. Wiese", "Saeed Abdullah"], "title": "Fine-Tuning Large Audio-Language Models with LoRA for Precise Temporal Localization of Prolonged Exposure Therapy Elements", "categories": ["eess.AS", "cs.CL", "cs.HC", "68T07", "I.2.7; I.5.4; H.5.2"], "comment": "5 pages, 2 figures", "summary": "Prolonged Exposure (PE) therapy is an effective treatment for post-traumatic\nstress disorder (PTSD), but evaluating therapist fidelity remains\nlabor-intensive due to the need for manual review of session recordings. We\npresent a method for the automatic temporal localization of key PE fidelity\nelements -- identifying their start and stop times -- directly from session\naudio and transcripts. Our approach fine-tunes a large pre-trained\naudio-language model, Qwen2-Audio, using Low-Rank Adaptation (LoRA) to process\nfocused 30-second windows of audio-transcript input. Fidelity labels for three\ncore protocol phases -- therapist orientation (P1), imaginal exposure (P2), and\npost-imaginal processing (P3) -- are generated via LLM-based prompting and\nverified by trained raters. The model is trained to predict normalized boundary\noffsets using soft supervision guided by task-specific prompts. On a dataset of\n313 real PE sessions, our best configuration (LoRA rank 8, 30s windows)\nachieves a mean absolute error (MAE) of 5.3 seconds across tasks. We further\nanalyze the effects of window size and LoRA rank, highlighting the importance\nof context granularity and model adaptation. This work introduces a scalable\nframework for fidelity tracking in PE therapy, with potential to support\nclinician training, supervision, and quality assurance.", "AI": {"tldr": "A method for automatically localizing key PE therapy fidelity elements from session audio/transcripts using a fine-tuned audio-language model (Qwen2-Audio) with LoRA, achieving 5.3s MAE.", "motivation": "Manual review of PE therapy sessions for fidelity is labor-intensive; automation can improve scalability for clinician training and quality assurance.", "method": "Fine-tunes Qwen2-Audio with LoRA on 30s audio-transcript windows, using LLM-based prompting for fidelity labels (P1, P2, P3) and soft supervision for boundary prediction.", "result": "Best configuration (LoRA rank 8, 30s windows) achieves 5.3s MAE on 313 PE sessions. Analyzes window size and LoRA rank effects.", "conclusion": "Introduces a scalable framework for PE fidelity tracking, aiding clinician training and supervision."}}
{"id": "2506.16733", "pdf": "https://arxiv.org/pdf/2506.16733", "abs": "https://arxiv.org/abs/2506.16733", "authors": ["Fang Chen", "Weifeng Zhang", "Xingyu Ai", "BingXuan Li", "An Li", "Qiegen Liu"], "title": "A Prior-Guided Joint Diffusion Model in Projection Domain for PET Tracer Conversion", "categories": ["eess.IV", "cs.CV"], "comment": null, "summary": "Positron emission tomography (PET) is widely used to assess metabolic\nactivity, but its application is limited by the availability of radiotracers.\n18F-labeled fluorodeoxyglucose (18F-FDG) is the most commonly used tracer but\nshows limited effectiveness for certain tumors. In contrast,\n6-18F-fluoro-3,4-dihydroxy-L-phenylalanine (18F-DOPA) offers higher specificity\nfor neuroendocrine tumors and neurological disorders. However, its complex\nsynthesis and limitations in transportation and clinical use hinder widespread\nadoption. During PET imaging, the sinogram represents a form of raw data\nacquired by the scanner. Therefore, modeling in projection domain enables more\ndirect utilization of the original information, potentially reducing the\naccumulation of errors introduced during the image reconstruction process.\nInspired by these factors, this study proposes a prior-guided joint diffusion\nmodel (PJDM) for transforming 18F-FDG PET images into 18F-DOPA PET images in\nprojection domain. Specifically, a coarse estimation model and a prior\nrefinement model are trained independently. During inference, an initial\nsynthetic 18F-DOPA PET sinogram is generated using a higher-order hybrid\nsampler. This sinogram is then degraded and serves as an additional condition\nto guide the iterative refinement process using learned prior. Experimental\nresults demonstrated that PJDM effectively improved both sinogram quality and\nsynthetic outcomes. The code is available at: https://github.com/yqx7150/PJDM.", "AI": {"tldr": "A prior-guided joint diffusion model (PJDM) is proposed to transform 18F-FDG PET images into 18F-DOPA PET images in the projection domain, improving sinogram quality and synthetic outcomes.", "motivation": "The limitations of 18F-FDG for certain tumors and the challenges in synthesizing and using 18F-DOPA motivate the need for an alternative method to generate 18F-DOPA PET images.", "method": "The study introduces PJDM, combining a coarse estimation model and a prior refinement model, using a higher-order hybrid sampler and learned prior for iterative refinement.", "result": "PJDM effectively enhances sinogram quality and synthetic 18F-DOPA PET images.", "conclusion": "The proposed PJDM offers a promising solution for generating 18F-DOPA PET images, addressing limitations of current tracers and methods."}}
{"id": "2506.15980", "pdf": "https://arxiv.org/pdf/2506.15980", "abs": "https://arxiv.org/abs/2506.15980", "authors": ["Cong Wang", "Zexuan Deng", "Zhiwei Jiang", "Fei Shen", "Yafeng Yin", "Shiwei Gan", "Zifeng Cheng", "Shiping Ge", "Qing Gu"], "title": "Advanced Sign Language Video Generation with Compressed and Quantized Multi-Condition Tokenization", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Sign Language Video Generation (SLVG) seeks to generate identity-preserving\nsign language videos from spoken language texts. Existing methods primarily\nrely on the single coarse condition (\\eg, skeleton sequences) as the\nintermediary to bridge the translation model and the video generation model,\nwhich limits both the naturalness and expressiveness of the generated videos.\nTo overcome these limitations, we propose SignViP, a novel SLVG framework that\nincorporates multiple fine-grained conditions for improved generation fidelity.\nRather than directly translating error-prone high-dimensional conditions,\nSignViP adopts a discrete tokenization paradigm to integrate and represent\nfine-grained conditions (\\ie, fine-grained poses and 3D hands). SignViP\ncontains three core components. (1) Sign Video Diffusion Model is jointly\ntrained with a multi-condition encoder to learn continuous embeddings that\nencapsulate fine-grained motion and appearance. (2) Finite Scalar Quantization\n(FSQ) Autoencoder is further trained to compress and quantize these embeddings\ninto discrete tokens for compact representation of the conditions. (3)\nMulti-Condition Token Translator is trained to translate spoken language text\nto discrete multi-condition tokens. During inference, Multi-Condition Token\nTranslator first translates the spoken language text into discrete\nmulti-condition tokens. These tokens are then decoded to continuous embeddings\nby FSQ Autoencoder, which are subsequently injected into Sign Video Diffusion\nModel to guide video generation. Experimental results show that SignViP\nachieves state-of-the-art performance across metrics, including video quality,\ntemporal coherence, and semantic fidelity. The code is available at\nhttps://github.com/umnooob/signvip/.", "AI": {"tldr": "SignViP is a novel SLVG framework using multiple fine-grained conditions (poses, 3D hands) via discrete tokenization, outperforming existing methods in video quality and semantic fidelity.", "motivation": "Existing SLVG methods rely on coarse conditions (e.g., skeletons), limiting video naturalness and expressiveness.", "method": "SignViP integrates fine-grained conditions through a diffusion model, FSQ Autoencoder, and token translator for text-to-video generation.", "result": "SignViP achieves state-of-the-art performance in video quality, coherence, and semantic fidelity.", "conclusion": "SignViP advances SLVG by leveraging fine-grained conditions and discrete tokenization for superior video generation."}}
{"id": "2506.15701", "pdf": "https://arxiv.org/pdf/2506.15701", "abs": "https://arxiv.org/abs/2506.15701", "authors": ["Haolin Pan", "Hongyu Lin", "Haoran Luo", "Yang Liu", "Kaichun Yao", "Libo Zhang", "Mingjie Xing", "Yanjun Wu"], "title": "Compiler-R1: Towards Agentic Compiler Auto-tuning with Reinforcement Learning", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Compiler auto-tuning optimizes pass sequences to improve performance metrics\nsuch as Intermediate Representation (IR) instruction count. Although recent\nadvances leveraging Large Language Models (LLMs) have shown promise in\nautomating compiler tuning, two significant challenges still remain: the\nabsence of high-quality reasoning datasets for agents training, and limited\neffective interactions with the compilation environment. In this work, we\nintroduce Compiler-R1, the first reinforcement learning (RL)-driven framework\nspecifically augmenting LLM capabilities for compiler auto-tuning. Compiler-R1\nfeatures a curated, high-quality reasoning dataset and a novel two-stage\nend-to-end RL training pipeline, enabling efficient environment exploration and\nlearning through an outcome-based reward. Extensive experiments across seven\ndatasets demonstrate Compiler-R1 achieving an average 8.46% IR instruction\ncount reduction compared to opt -Oz, showcasing the strong potential of\nRL-trained LLMs for compiler optimization. Our code and datasets are publicly\navailable at https://github.com/Panhaolin2001/Compiler-R1.", "AI": {"tldr": "Compiler-R1 is an RL-driven framework enhancing LLMs for compiler auto-tuning, featuring a high-quality dataset and two-stage RL training, achieving 8.46% IR instruction reduction.", "motivation": "Addressing the lack of high-quality reasoning datasets and limited interactions in compiler tuning using LLMs.", "method": "Introduces Compiler-R1 with a curated dataset and two-stage RL training pipeline for efficient exploration and learning.", "result": "Achieves an average 8.46% reduction in IR instruction count compared to opt -Oz across seven datasets.", "conclusion": "Demonstrates the potential of RL-trained LLMs for compiler optimization, with publicly available code and datasets."}}
{"id": "2506.16144", "pdf": "https://arxiv.org/pdf/2506.16144", "abs": "https://arxiv.org/abs/2506.16144", "authors": ["Ana Kostovska", "Carola Doerr", "Sa\u0161o D\u017eeroski", "Pan\u010de Panov", "Tome Eftimov"], "title": "Geometric Learning in Black-Box Optimization: A GNN Framework for Algorithm Performance Prediction", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "Automated algorithm performance prediction in numerical blackbox optimization\noften relies on problem characterizations, such as exploratory landscape\nanalysis features. These features are typically used as inputs to machine\nlearning models and are represented in a tabular format. However, such\napproaches often overlook algorithm configurations, a key factor influencing\nperformance. The relationships between algorithm operators, parameters, problem\ncharacteristics, and performance outcomes form a complex structure best\nrepresented as a graph. This work explores the use of heterogeneous graph data\nstructures and graph neural networks to predict the performance of optimization\nalgorithms by capturing the complex dependencies between problems, algorithm\nconfigurations, and performance outcomes. We focus on two modular frameworks,\nmodCMA-ES and modDE, which decompose two widely used derivative-free\noptimization algorithms: the covariance matrix adaptation evolution strategy\n(CMA-ES) and differential evolution (DE). We evaluate 324 modCMA-ES and 576\nmodDE variants on 24 BBOB problems across six runtime budgets and two problem\ndimensions. Achieving up to 36.6% improvement in MSE over traditional\ntabular-based methods, this work highlights the potential of geometric learning\nin black-box optimization.", "AI": {"tldr": "The paper proposes using graph neural networks and heterogeneous graph structures to predict optimization algorithm performance, outperforming traditional tabular methods by up to 36.6% in MSE.", "motivation": "Existing methods for algorithm performance prediction overlook algorithm configurations, which are crucial for performance. The paper addresses this gap by modeling complex dependencies between problems, configurations, and outcomes as a graph.", "method": "The study uses heterogeneous graph data structures and graph neural networks to capture dependencies. It evaluates modular frameworks (modCMA-ES and modDE) on BBOB problems across various runtime budgets and dimensions.", "result": "The approach achieves up to 36.6% improvement in mean squared error (MSE) over traditional tabular-based methods.", "conclusion": "The work demonstrates the potential of geometric learning in black-box optimization, offering a more accurate performance prediction method."}}
{"id": "2506.16172", "pdf": "https://arxiv.org/pdf/2506.16172", "abs": "https://arxiv.org/abs/2506.16172", "authors": ["Guanhua Chen", "Yutong Yao", "Lidia S. Chao", "Xuebo Liu", "Derek F. Wong"], "title": "SGIC: A Self-Guided Iterative Calibration Framework for RAG", "categories": ["cs.CL"], "comment": null, "summary": "Recent research in retrieval-augmented generation (RAG) has concentrated on\nretrieving useful information from candidate documents. However, numerous\nmethodologies frequently neglect the calibration capabilities of large language\nmodels (LLMs), which capitalize on their robust in-context reasoning prowess.\nThis work illustrates that providing LLMs with specific cues substantially\nimproves their calibration efficacy, especially in multi-round calibrations. We\npresent a new SGIC: Self-Guided Iterative Calibration Framework that employs\nuncertainty scores as a tool. Initially, this framework calculates uncertainty\nscores to determine both the relevance of each document to the query and the\nconfidence level in the responses produced by the LLMs. Subsequently, it\nreevaluates these scores iteratively, amalgamating them with prior responses to\nrefine calibration. Furthermore, we introduce an innovative approach for\nconstructing an iterative self-calibration training set, which optimizes LLMs\nto efficiently harness uncertainty scores for capturing critical information\nand enhancing response accuracy. Our proposed framework significantly improves\nperformance on both closed-source and open-weight LLMs.", "AI": {"tldr": "The paper introduces SGIC, a Self-Guided Iterative Calibration Framework, to improve LLM calibration by using uncertainty scores for document relevance and response confidence, enhancing multi-round calibration and response accuracy.", "motivation": "Existing RAG methods often overlook LLMs' calibration capabilities, despite their strong in-context reasoning. This work addresses this gap by leveraging specific cues to improve calibration.", "method": "The SGIC framework uses uncertainty scores to assess document relevance and LLM response confidence, iteratively refining calibration. It also introduces a method to create a self-calibration training set for optimizing LLMs.", "result": "The framework significantly boosts performance on both closed-source and open-weight LLMs.", "conclusion": "SGIC effectively enhances LLM calibration and response accuracy by integrating uncertainty scores and iterative refinement."}}
{"id": "2502.14321", "pdf": "https://arxiv.org/pdf/2502.14321", "abs": "https://arxiv.org/abs/2502.14321", "authors": ["Bingyu Yan", "Zhibo Zhou", "Litian Zhang", "Lian Zhang", "Ziyi Zhou", "Dezhuang Miao", "Zhoujun Li", "Chaozhuo Li", "Xiaoming Zhang"], "title": "Beyond Self-Talk: A Communication-Centric Survey of LLM-Based Multi-Agent Systems", "categories": ["cs.MA", "cs.CL"], "comment": null, "summary": "Large language model-based multi-agent systems have recently gained\nsignificant attention due to their potential for complex, collaborative, and\nintelligent problem-solving capabilities. Existing surveys typically categorize\nLLM-based multi-agent systems (LLM-MAS) according to their application domains\nor architectures, overlooking the central role of communication in coordinating\nagent behaviors and interactions. To address this gap, this paper presents a\ncomprehensive survey of LLM-MAS from a communication-centric perspective.\nSpecifically, we propose a structured framework that integrates system-level\ncommunication (architecture, goals, and protocols) with system internal\ncommunication (strategies, paradigms, objects, and content), enabling a\ndetailed exploration of how agents interact, negotiate, and achieve collective\nintelligence. Through an extensive analysis of recent literature, we identify\nkey components in multiple dimensions and summarize their strengths and\nlimitations. In addition, we highlight current challenges, including\ncommunication efficiency, security vulnerabilities, inadequate benchmarking,\nand scalability issues, and outline promising future research directions. This\nreview aims to help researchers and practitioners gain a clear understanding of\nthe communication mechanisms in LLM-MAS, thereby facilitating the design and\ndeployment of robust, scalable, and secure multi-agent systems.", "AI": {"tldr": "This paper surveys LLM-based multi-agent systems (LLM-MAS) from a communication-centric perspective, proposing a framework to analyze agent interactions and highlighting challenges like efficiency and scalability.", "motivation": "Existing surveys overlook communication's role in LLM-MAS coordination, prompting this comprehensive review to bridge the gap.", "method": "Proposes a structured framework integrating system-level and internal communication, analyzing literature to identify key components and challenges.", "result": "Identifies strengths, limitations, and challenges (e.g., efficiency, security) in LLM-MAS communication, offering future research directions.", "conclusion": "Aims to clarify communication mechanisms in LLM-MAS to improve system design, scalability, and security."}}
{"id": "2506.11160", "pdf": "https://arxiv.org/pdf/2506.11160", "abs": "https://arxiv.org/abs/2506.11160", "authors": ["Yu Pan", "Yuguang Yang", "Yanni Hu", "Jianhao Ye", "Xiang Zhang", "Hongbin Zhou", "Lei Ma", "Jianjun Zhao"], "title": "S2ST-Omni: An Efficient and Scalable Multilingual Speech-to-Speech Translation Framework via Seamless Speech-Text Alignment and Streaming Speech Generation", "categories": ["eess.AS", "cs.SD"], "comment": "Working in progress", "summary": "Multilingual speech-to-speech translation (S2ST) aims to directly convert\nspoken utterances from multiple source languages into fluent and intelligible\nspeech in a target language. Despite recent progress, several critical\nchallenges persist: 1) achieving high-quality S2ST remains a significant\nobstacle; 2) most existing S2ST methods rely heavily on large-scale parallel\nspeech corpora, which are difficult and resource-intensive to obtain. To tackle\nthese challenges, we introduce S2ST-Omni, a novel, efficient, and scalable\nframework tailored for multilingual speech-to-speech translation. Specifically,\nwe decompose S2ST into speech-to-text translation (S2TT) and text-to-speech\nsynthesis (TTS). To enable high-quality S2TT while mitigating reliance on\nlarge-scale parallel speech corpora, we leverage powerful pretrained models:\nWhisper for robust audio understanding and Qwen 3.0 for advanced text\ncomprehension. A lightweight speech adapter is introduced to bridge the\nmodality gap between speech and text representations, facilitating effective\nutilization of pretrained multimodal knowledge. To ensure both translation\naccuracy and real-time responsiveness, we adopt a streaming speech generation\nmodel in the TTS stage, which generates the target speech in an autoregressive\nmanner. Extensive experiments conducted on the CVSS benchmark demonstrate that\nS2ST-Omni consistently surpasses several state-of-the-art S2ST baselines in\ntranslation quality, highlighting its effectiveness and superiority.", "AI": {"tldr": "S2ST-Omni is a novel framework for multilingual speech-to-speech translation, decomposing the task into speech-to-text translation and text-to-speech synthesis, leveraging pretrained models to reduce reliance on large parallel corpora.", "motivation": "Addressing challenges in high-quality multilingual speech-to-speech translation and reducing dependency on large-scale parallel speech corpora.", "method": "Decomposes S2ST into S2TT and TTS, uses pretrained models (Whisper, Qwen 3.0), and introduces a speech adapter to bridge speech-text gaps. Streaming TTS ensures real-time responsiveness.", "result": "Outperforms state-of-the-art baselines on the CVSS benchmark in translation quality.", "conclusion": "S2ST-Omni is effective and superior for multilingual S2ST, offering scalability and efficiency."}}
{"id": "2506.13053", "pdf": "https://arxiv.org/pdf/2506.13053", "abs": "https://arxiv.org/abs/2506.13053", "authors": ["Han Zhu", "Wei Kang", "Zengwei Yao", "Liyong Guo", "Fangjun Kuang", "Zhaoqing Li", "Weiji Zhuang", "Long Lin", "Daniel Povey"], "title": "ZipVoice: Fast and High-Quality Zero-Shot Text-to-Speech with Flow Matching", "categories": ["eess.AS", "cs.SD"], "comment": null, "summary": "Existing large-scale zero-shot text-to-speech (TTS) models deliver high\nspeech quality but suffer from slow inference speeds due to massive parameters.\nTo address this issue, this paper introduces ZipVoice, a high-quality\nflow-matching-based zero-shot TTS model with a compact model size and fast\ninference speed. Key designs include: 1) a Zipformer-based flow-matching\ndecoder to maintain adequate modeling capabilities under constrained size; 2)\nAverage upsampling-based initial speech-text alignment and Zipformer-based text\nencoder to improve speech intelligibility; 3) A flow distillation method to\nreduce sampling steps and eliminate the inference overhead associated with\nclassifier-free guidance. Experiments on 100k hours multilingual datasets show\nthat ZipVoice matches state-of-the-art models in speech quality, while being 3\ntimes smaller and up to 30 times faster than a DiT-based flow-matching\nbaseline. Codes, model checkpoints and demo samples are publicly available.", "AI": {"tldr": "ZipVoice is a compact, fast zero-shot TTS model using flow-matching, achieving high speech quality while being smaller and faster than existing models.", "motivation": "Existing zero-shot TTS models are slow due to large parameters, prompting the need for a more efficient solution.", "method": "ZipVoice employs a Zipformer-based flow-matching decoder, average upsampling for alignment, and flow distillation to reduce steps.", "result": "ZipVoice matches state-of-the-art quality, is 3x smaller, and up to 30x faster than baseline models.", "conclusion": "ZipVoice offers a high-quality, efficient alternative to large-scale zero-shot TTS models."}}
{"id": "2506.16803", "pdf": "https://arxiv.org/pdf/2506.16803", "abs": "https://arxiv.org/abs/2506.16803", "authors": ["Ning Chu", "Siya Zheng", "Shanqing Zhang", "Li Li", "Caifang Cai", "Ali Mohammad-Djafari", "Feng Zhao", "Yuanbo Song"], "title": "Temperature calibration of surface emissivities with an improved thermal image enhancement network", "categories": ["eess.IV", "cs.CV"], "comment": null, "summary": "Infrared thermography faces persistent challenges in temperature accuracy due\nto material emissivity variations, where existing methods often neglect the\njoint optimization of radiometric calibration and image degradation. This study\nintroduces a physically guided neural framework that unifies temperature\ncorrection and image enhancement through a symmetric skip-CNN architecture and\nan emissivity-aware attention module. The pre-processing stage segments the\nROIs of the image and and initially corrected the firing rate. A novel\ndual-constrained loss function strengthens the statistical consistency between\nthe target and reference regions through mean-variance alignment and histogram\nmatching based on Kullback-Leibler dispersion. The method works by dynamically\nfusing thermal radiation features and spatial context, and the model suppresses\nemissivity artifacts while recovering structural details. After validating the\nindustrial blower system under different conditions, the improved network\nrealizes the dynamic fusion of thermal radiation characteristics and spatial\nbackground, with accurate calibration results in various industrial conditions.", "AI": {"tldr": "A neural framework combines temperature correction and image enhancement for infrared thermography, addressing emissivity variations and improving accuracy.", "motivation": "Existing methods lack joint optimization of radiometric calibration and image degradation, leading to temperature inaccuracies.", "method": "Uses a symmetric skip-CNN and emissivity-aware attention module, with ROI segmentation, dual-constrained loss, and dynamic feature fusion.", "result": "Achieves accurate calibration and detail recovery in industrial conditions, validated on a blower system.", "conclusion": "The framework effectively unifies temperature correction and image enhancement, improving infrared thermography accuracy."}}
{"id": "2506.15988", "pdf": "https://arxiv.org/pdf/2506.15988", "abs": "https://arxiv.org/abs/2506.15988", "authors": ["Connor Malone", "Owen Claxton", "Iman Shames", "Michael Milford"], "title": "Adversarial Attacks and Detection in Visual Place Recognition for Safer Robot Navigation", "categories": ["cs.CV", "cs.RO"], "comment": null, "summary": "Stand-alone Visual Place Recognition (VPR) systems have little defence\nagainst a well-designed adversarial attack, which can lead to disastrous\nconsequences when deployed for robot navigation. This paper extensively\nanalyzes the effect of four adversarial attacks common in other perception\ntasks and four novel VPR-specific attacks on VPR localization performance. We\nthen propose how to close the loop between VPR, an Adversarial Attack Detector\n(AAD), and active navigation decisions by demonstrating the performance benefit\nof simulated AADs in a novel experiment paradigm -- which we detail for the\nrobotics community to use as a system framework. In the proposed experiment\nparadigm, we see the addition of AADs across a range of detection accuracies\ncan improve performance over baseline; demonstrating a significant improvement\n-- such as a ~50% reduction in the mean along-track localization error -- can\nbe achieved with True Positive and False Positive detection rates of only 75%\nand up to 25% respectively. We examine a variety of metrics including:\nAlong-Track Error, Percentage of Time Attacked, Percentage of Time in an\n`Unsafe' State, and Longest Continuous Time Under Attack. Expanding further on\nthese results, we provide the first investigation into the efficacy of the Fast\nGradient Sign Method (FGSM) adversarial attack for VPR. The analysis in this\nwork highlights the need for AADs in real-world systems for trustworthy\nnavigation, and informs quantitative requirements for system design.", "AI": {"tldr": "The paper analyzes adversarial attacks on Visual Place Recognition (VPR) systems, proposes an Adversarial Attack Detector (AAD) framework, and demonstrates its effectiveness in improving navigation performance.", "motivation": "VPR systems are vulnerable to adversarial attacks, which can compromise robot navigation. The paper aims to address this by integrating AADs into the system.", "method": "The study evaluates four common and four novel VPR-specific adversarial attacks, introduces an AAD framework, and tests it in a novel experiment paradigm.", "result": "Adding AADs improves performance, e.g., reducing mean along-track error by ~50% with 75% True Positive and up to 25% False Positive rates.", "conclusion": "AADs are essential for trustworthy navigation, and the paper provides quantitative design requirements for real-world systems."}}
{"id": "2506.15702", "pdf": "https://arxiv.org/pdf/2506.15702", "abs": "https://arxiv.org/abs/2506.15702", "authors": ["Peter Belcak", "Greg Heinrich", "Jan Kautz", "Pavlo Molchanov"], "title": "Minifinetuning: Low-Data Generation Domain Adaptation through Corrective Self-Distillation", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Finetuning language models for a new domain inevitably leads to the\ndeterioration of their general performance. This becomes more pronounced the\nmore limited the finetuning data resource.\n  We introduce minifinetuning (MFT), a method for language model domain\nadaptation that considerably reduces the effects of overfitting-induced\ndegeneralization in low-data settings and which does so in the absence of any\npre-training data for replay. MFT demonstrates 2-10x more favourable\nspecialization-to-degeneralization ratios than standard finetuning across a\nwide range of models and domains and exhibits an intrinsic robustness to\noverfitting when data in the new domain is scarce and down to as little as 500\nsamples.\n  Employing corrective self-distillation that is individualized on the sample\nlevel, MFT outperforms parameter-efficient finetuning methods, demonstrates\nreplay-like degeneralization mitigation properties, and is composable with\neither for a combined effect.", "AI": {"tldr": "Minifinetuning (MFT) reduces overfitting-induced performance loss in low-data domain adaptation without pre-training data, outperforming standard finetuning and parameter-efficient methods.", "motivation": "Addressing the deterioration of general performance in language models when finetuned for new domains, especially with limited data.", "method": "MFT uses corrective self-distillation at the sample level to mitigate overfitting and degeneralization, requiring as little as 500 samples.", "result": "MFT shows 2-10x better specialization-to-degeneralization ratios than standard finetuning and is robust to overfitting in low-data settings.", "conclusion": "MFT effectively balances domain adaptation and general performance, offering a scalable solution for low-resource scenarios."}}
{"id": "2506.16163", "pdf": "https://arxiv.org/pdf/2506.16163", "abs": "https://arxiv.org/abs/2506.16163", "authors": ["Hao Li", "Gengrui Zhang", "Petter Holme", "Shuyue Hu", "Zhen Wang"], "title": "Large Language Models are Near-Optimal Decision-Makers with a Non-Human Learning Behavior", "categories": ["cs.AI"], "comment": null, "summary": "Human decision-making belongs to the foundation of our society and\ncivilization, but we are on the verge of a future where much of it will be\ndelegated to artificial intelligence. The arrival of Large Language Models\n(LLMs) has transformed the nature and scope of AI-supported decision-making;\nhowever, the process by which they learn to make decisions, compared to humans,\nremains poorly understood. In this study, we examined the decision-making\nbehavior of five leading LLMs across three core dimensions of real-world\ndecision-making: uncertainty, risk, and set-shifting. Using three\nwell-established experimental psychology tasks designed to probe these\ndimensions, we benchmarked LLMs against 360 newly recruited human participants.\nAcross all tasks, LLMs often outperformed humans, approaching near-optimal\nperformance. Moreover, the processes underlying their decisions diverged\nfundamentally from those of humans. On the one hand, our finding demonstrates\nthe ability of LLMs to manage uncertainty, calibrate risk, and adapt to\nchanges. On the other hand, this disparity highlights the risks of relying on\nthem as substitutes for human judgment, calling for further inquiry.", "AI": {"tldr": "LLMs outperform humans in decision-making tasks involving uncertainty, risk, and adaptability, but their decision processes differ fundamentally from humans, raising concerns about their use as substitutes for human judgment.", "motivation": "To understand how LLMs learn and execute decision-making compared to humans, especially in dimensions like uncertainty, risk, and set-shifting.", "method": "Benchmarked five leading LLMs against 360 humans using three experimental psychology tasks.", "result": "LLMs often outperformed humans, achieving near-optimal performance, but their decision-making processes were fundamentally different.", "conclusion": "While LLMs excel in decision-making, their divergence from human processes calls for caution and further research before relying on them as substitutes for human judgment."}}
{"id": "2506.16187", "pdf": "https://arxiv.org/pdf/2506.16187", "abs": "https://arxiv.org/abs/2506.16187", "authors": ["Masashi Takeshita", "Rafal Rzepka"], "title": "JETHICS: Japanese Ethics Understanding Evaluation Dataset", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "In this work, we propose JETHICS, a Japanese dataset for evaluating ethics\nunderstanding of AI models. JETHICS contains 78K examples and is built by\nfollowing the construction methods of the existing English ETHICS dataset. It\nincludes four categories based normative theories and concepts from ethics and\npolitical philosophy; and one representing commonsense morality. Our evaluation\nexperiments on non-proprietary large language models (LLMs) and on GPT-4o\nreveal that even GPT-4o achieves only an average score of about 0.7, while the\nbest-performing Japanese LLM attains around 0.5, indicating a relatively large\nroom for improvement in current LLMs.", "AI": {"tldr": "JETHICS is a Japanese dataset for evaluating AI ethics understanding, containing 78K examples. Evaluations show GPT-4o scores 0.7, while the best Japanese LLM scores 0.5, indicating room for improvement.", "motivation": "To assess the ethics understanding of AI models in Japanese, filling a gap in non-English datasets.", "method": "Follows the construction of the English ETHICS dataset, includes four normative theory categories and commonsense morality.", "result": "GPT-4o scores 0.7, best Japanese LLM scores 0.5, showing significant improvement potential.", "conclusion": "Current LLMs, including GPT-4o, have notable gaps in Japanese ethics understanding, highlighting the need for further development."}}
{"id": "2504.03353", "pdf": "https://arxiv.org/pdf/2504.03353", "abs": "https://arxiv.org/abs/2504.03353", "authors": ["Kentaro Nomura", "Tatsuya Aoki", "Tadahiro Taniguchi", "Takato Horii"], "title": "Decentralized Collective World Model for Emergent Communication and Coordination", "categories": ["cs.MA", "cs.AI"], "comment": "Accepted at IEEE ICDL 2025", "summary": "We propose a fully decentralized multi-agent world model that enables both\nsymbol emergence for communication and coordinated behavior through temporal\nextension of collective predictive coding. Unlike previous research that\nfocuses on either communication or coordination separately, our approach\nachieves both simultaneously. Our method integrates world models with\ncommunication channels, enabling agents to predict environmental dynamics,\nestimate states from partial observations, and share critical information\nthrough bidirectional message exchange with contrastive learning for message\nalignment. Using a two-agent trajectory drawing task, we demonstrate that our\ncommunication-based approach outperforms non-communicative models when agents\nhave divergent perceptual capabilities, achieving the second-best coordination\nafter centralized models. Importantly, our decentralized approach with\nconstraints preventing direct access to other agents' internal states\nfacilitates the emergence of more meaningful symbol systems that accurately\nreflect environmental states. These findings demonstrate the effectiveness of\ndecentralized communication for supporting coordination while developing shared\nrepresentations of the environment.", "AI": {"tldr": "A decentralized multi-agent model integrates communication and coordination via predictive coding, outperforming non-communicative models in tasks with divergent perceptual capabilities.", "motivation": "To simultaneously achieve symbol emergence for communication and coordinated behavior, addressing the gap in prior research that treated these separately.", "method": "Integrates world models with communication channels, using bidirectional message exchange and contrastive learning for alignment. Tested on a two-agent trajectory drawing task.", "result": "Outperforms non-communicative models, achieving near-centralized coordination levels and facilitating meaningful symbol systems.", "conclusion": "Decentralized communication effectively supports coordination and shared environmental representations."}}
{"id": "2506.16934", "pdf": "https://arxiv.org/pdf/2506.16934", "abs": "https://arxiv.org/abs/2506.16934", "authors": ["Bin Huang", "Feihong Xu", "Xinchong Shi", "Shan Huang", "Binxuan Li", "Fei Li", "Qiegen Liu"], "title": "PET Tracer Separation Using Conditional Diffusion Transformer with Multi-latent Space Learning", "categories": ["eess.IV", "cs.CV"], "comment": null, "summary": "In clinical practice, single-radiotracer positron emission tomography (PET)\nis commonly used for imaging. Although multi-tracer PET imaging can provide\nsupplementary information of radiotracers that are sensitive to physiological\nfunction changes, enabling a more comprehensive characterization of\nphysiological and pathological states, the gamma-photon pairs generated by\npositron annihilation reactions of different tracers in PET imaging have the\nsame energy, making it difficult to distinguish the tracer signals. In this\nstudy, a multi-latent space guided texture conditional diffusion transformer\nmodel (MS-CDT) is proposed for PET tracer separation. To the best of our\nknowledge, this is the first attempt to use texture condition and multi-latent\nspace for tracer separation in PET imaging. The proposed model integrates\ndiffusion and transformer architectures into a unified optimization framework,\nwith the novel addition of texture masks as conditional inputs to enhance image\ndetails. By leveraging multi-latent space prior derived from different tracers,\nthe model captures multi-level feature representations, aiming to balance\ncomputational efficiency and detail preservation. The texture masks, serving as\nconditional guidance, help the model focus on salient structural patterns,\nthereby improving the extraction and utilization of fine-grained image\ntextures. When combined with the diffusion transformer backbone, this\nconditioning mechanism contributes to more accurate and robust tracer\nseparation. To evaluate its effectiveness, the proposed MS-CDT is compared with\nseveral advanced methods on two types of 3D PET datasets: brain and chest\nscans. Experimental results indicate that MS-CDT achieved competitive\nperformance in terms of image quality and preservation of clinically relevant\ninformation. Code is available at: https://github.com/yqx7150/MS-CDT.", "AI": {"tldr": "A novel model (MS-CDT) for PET tracer separation using texture conditions and multi-latent space, outperforming existing methods in image quality and clinical relevance.", "motivation": "Multi-tracer PET imaging provides comprehensive physiological insights but faces challenges in distinguishing tracer signals due to identical gamma-photon energies.", "method": "Proposes MS-CDT, integrating diffusion and transformer architectures with texture masks and multi-latent space for enhanced tracer separation.", "result": "MS-CDT achieves competitive performance in image quality and clinical relevance on brain and chest PET datasets.", "conclusion": "MS-CDT is effective for PET tracer separation, balancing computational efficiency and detail preservation."}}
{"id": "2506.16006", "pdf": "https://arxiv.org/pdf/2506.16006", "abs": "https://arxiv.org/abs/2506.16006", "authors": ["Weiwei Duan", "Michael P. Gerlek", "Steven N. Minton", "Craig A. Knoblock", "Fandel Lin", "Theresa Chen", "Leeje Jang", "Sofia Kirsanova", "Zekun Li", "Yijun Lin", "Yao-Yi Chiang"], "title": "DIGMAPPER: A Modular System for Automated Geologic Map Digitization", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Historical geologic maps contain rich geospatial information, such as rock\nunits, faults, folds, and bedding planes, that is critical for assessing\nmineral resources essential to renewable energy, electric vehicles, and\nnational security. However, digitizing maps remains a labor-intensive and\ntime-consuming task. We present DIGMAPPER, a modular, scalable system developed\nin collaboration with the United States Geological Survey (USGS) to automate\nthe digitization of geologic maps. DIGMAPPER features a fully dockerized,\nworkflow-orchestrated architecture that integrates state-of-the-art deep\nlearning models for map layout analysis, feature extraction, and\ngeoreferencing. To overcome challenges such as limited training data and\ncomplex visual content, our system employs innovative techniques, including\nin-context learning with large language models, synthetic data generation, and\ntransformer-based models. Evaluations on over 100 annotated maps from the\nDARPA-USGS dataset demonstrate high accuracy across polygon, line, and point\nfeature extraction, and reliable georeferencing performance. Deployed at USGS,\nDIGMAPPER significantly accelerates the creation of analysis-ready geospatial\ndatasets, supporting national-scale critical mineral assessments and broader\ngeoscientific applications.", "AI": {"tldr": "DIGMAPPER is a scalable, automated system for digitizing geologic maps, using deep learning and innovative techniques to overcome data limitations, achieving high accuracy and efficiency.", "motivation": "Historical geologic maps are vital for renewable energy and national security but digitizing them is labor-intensive.", "method": "DIGMAPPER integrates deep learning models for layout analysis, feature extraction, and georeferencing, using in-context learning, synthetic data, and transformers.", "result": "Evaluations on 100+ maps show high accuracy in feature extraction and georeferencing, with successful USGS deployment.", "conclusion": "DIGMAPPER accelerates geospatial dataset creation, aiding critical mineral assessments and geoscientific applications."}}
{"id": "2506.15703", "pdf": "https://arxiv.org/pdf/2506.15703", "abs": "https://arxiv.org/abs/2506.15703", "authors": ["Guoqing Chao", "Zhenghao Zhang", "Lei Meng", "Jie Wen", "Dianhui Chu"], "title": "Federated Incomplete Multi-view Clustering with Globally Fused Graph Guidance", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Federated multi-view clustering has been proposed to mine the valuable\ninformation within multi-view data distributed across different devices and has\nachieved impressive results while preserving the privacy. Despite great\nprogress, most federated multi-view clustering methods only used global\npseudo-labels to guide the downstream clustering process and failed to exploit\nthe global information when extracting features. In addition, missing data\nproblem in federated multi-view clustering task is less explored. To address\nthese problems, we propose a novel Federated Incomplete Multi-view Clustering\nmethod with globally Fused Graph guidance (FIMCFG). Specifically, we designed a\ndual-head graph convolutional encoder at each client to extract two kinds of\nunderlying features containing global and view-specific information.\nSubsequently, under the guidance of the fused graph, the two underlying\nfeatures are fused into high-level features, based on which clustering is\nconducted under the supervision of pseudo-labeling. Finally, the high-level\nfeatures are uploaded to the server to refine the graph fusion and\npseudo-labeling computation. Extensive experimental results demonstrate the\neffectiveness and superiority of FIMCFG. Our code is publicly available at\nhttps://github.com/PaddiHunter/FIMCFG.", "AI": {"tldr": "FIMCFG is a federated incomplete multi-view clustering method that uses globally fused graph guidance to improve feature extraction and clustering, addressing missing data issues.", "motivation": "Existing federated multi-view clustering methods lack global feature exploitation and overlook missing data problems.", "method": "Dual-head graph convolutional encoder extracts global and view-specific features, fused under a global graph for clustering with pseudo-labeling.", "result": "FIMCFG outperforms existing methods, demonstrating effectiveness and superiority.", "conclusion": "FIMCFG successfully addresses missing data and global feature integration in federated multi-view clustering."}}
{"id": "2506.16294", "pdf": "https://arxiv.org/pdf/2506.16294", "abs": "https://arxiv.org/abs/2506.16294", "authors": ["Linde Vanbesien", "Bart Bogaerts", "Marc Denecker"], "title": "Approximation Fixpoint Theory with Refined Approximation Spaces", "categories": ["cs.AI", "cs.LO"], "comment": "Submitted to KR 2024", "summary": "Approximation Fixpoint Theory (AFT) is a powerful theory covering various\nsemantics of non-monotonic reasoning formalisms in knowledge representation\nsuch as Logic Programming and Answer Set Programming. Many semantics of such\nnon-monotonic formalisms can be characterized as suitable fixpoints of a\nnon-monotonic operator on a suitable lattice. Instead of working on the\noriginal lattice, AFT operates on intervals in such lattice to approximate or\nconstruct the fixpoints of interest. While AFT has been applied successfully\nacross a broad range of non-monotonic reasoning formalisms, it is confronted by\nits limitations in other, relatively simple, examples. In this paper, we\novercome those limitations by extending consistent AFT to deal with\napproximations that are more refined than intervals. Therefore, we introduce a\nmore general notion of approximation spaces, showcase the improved\nexpressiveness and investigate relations between different approximation\nspaces.", "AI": {"tldr": "The paper extends consistent Approximation Fixpoint Theory (AFT) by introducing more refined approximation spaces to overcome its limitations in certain non-monotonic reasoning formalisms.", "motivation": "AFT has limitations in handling some simple examples despite its broad applicability in non-monotonic reasoning. The paper aims to address these limitations by refining approximation spaces.", "method": "The authors generalize approximation spaces beyond intervals, introducing a more flexible framework for approximating fixpoints in non-monotonic operators.", "result": "The extended AFT framework demonstrates improved expressiveness and explores relationships between different approximation spaces.", "conclusion": "The refined approximation spaces enhance AFT's applicability, overcoming previous limitations and broadening its utility in non-monotonic reasoning."}}
{"id": "2506.16190", "pdf": "https://arxiv.org/pdf/2506.16190", "abs": "https://arxiv.org/abs/2506.16190", "authors": ["Luna Wang", "Andrew Caines", "Alice Hutchings"], "title": "Web(er) of Hate: A Survey on How Hate Speech Is Typed", "categories": ["cs.CL"], "comment": null, "summary": "The curation of hate speech datasets involves complex design decisions that\nbalance competing priorities. This paper critically examines these\nmethodological choices in a diverse range of datasets, highlighting common\nthemes and practices, and their implications for dataset reliability. Drawing\non Max Weber's notion of ideal types, we argue for a reflexive approach in\ndataset creation, urging researchers to acknowledge their own value judgments\nduring dataset construction, fostering transparency and methodological rigour.", "AI": {"tldr": "The paper critiques hate speech dataset curation, advocating for reflexive methods and transparency.", "motivation": "To examine methodological choices in hate speech datasets and their impact on reliability.", "method": "Analyzes diverse datasets using Max Weber's ideal types, promoting reflexive approaches.", "result": "Highlights common themes and practices, emphasizing the need for transparency.", "conclusion": "Researchers should acknowledge value judgments in dataset creation for methodological rigor."}}
{"id": "2409.17655", "pdf": "https://arxiv.org/pdf/2409.17655", "abs": "https://arxiv.org/abs/2409.17655", "authors": ["Nan Sun", "Bo Mao", "Yongchang Li", "Di Guo", "Huaping Liu"], "title": "AssistantX: An LLM-Powered Proactive Assistant in Collaborative Human-Populated Environment", "categories": ["cs.RO", "cs.AI", "cs.MA"], "comment": "8 pages, 10 figures, 6 tables", "summary": "Current service robots suffer from limited natural language communication\nabilities, heavy reliance on predefined commands, ongoing human intervention,\nand, most notably, a lack of proactive collaboration awareness in\nhuman-populated environments. This results in narrow applicability and low\nutility. In this paper, we introduce AssistantX, an LLM-powered proactive\nassistant designed for autonomous operation in realworld scenarios with high\naccuracy. AssistantX employs a multi-agent framework consisting of 4\nspecialized LLM agents, each dedicated to perception, planning,\ndecision-making, and reflective review, facilitating advanced inference\ncapabilities and comprehensive collaboration awareness, much like a human\nassistant by your side. We built a dataset of 210 real-world tasks to validate\nAssistantX, which includes instruction content and status information on\nwhether relevant personnel are available. Extensive experiments were conducted\nin both text-based simulations and a real office environment over the course of\na month and a half. Our experiments demonstrate the effectiveness of the\nproposed framework, showing that AssistantX can reactively respond to user\ninstructions, actively adjust strategies to adapt to contingencies, and\nproactively seek assistance from humans to ensure successful task completion.\nMore details and videos can be found at\nhttps://assistantx-agent.github.io/AssistantX/.", "AI": {"tldr": "AssistantX is an LLM-powered proactive assistant using a multi-agent framework for autonomous operation in real-world scenarios, validated by extensive experiments.", "motivation": "Current service robots lack natural language communication, proactive collaboration, and autonomy, limiting their utility.", "method": "AssistantX employs 4 specialized LLM agents for perception, planning, decision-making, and reflective review, tested with 210 real-world tasks.", "result": "Experiments show AssistantX can reactively respond, adapt to contingencies, and proactively seek human help for task completion.", "conclusion": "AssistantX demonstrates effectiveness in real-world scenarios, enhancing robot autonomy and collaboration awareness."}}
{"id": "2506.17133", "pdf": "https://arxiv.org/pdf/2506.17133", "abs": "https://arxiv.org/abs/2506.17133", "authors": ["Josu\u00e9 Mart\u00ednez-Mart\u00ednez", "Olivia Brown", "Mostafa Karami", "Sheida Nabavi"], "title": "Robust Training with Data Augmentation for Medical Imaging Classification", "categories": ["eess.IV", "cs.AI", "cs.CV", "cs.LG"], "comment": null, "summary": "Deep neural networks are increasingly being used to detect and diagnose\nmedical conditions using medical imaging. Despite their utility, these models\nare highly vulnerable to adversarial attacks and distribution shifts, which can\naffect diagnostic reliability and undermine trust among healthcare\nprofessionals. In this study, we propose a robust training algorithm with data\naugmentation (RTDA) to mitigate these vulnerabilities in medical image\nclassification. We benchmark classifier robustness against adversarial\nperturbations and natural variations of RTDA and six competing baseline\ntechniques, including adversarial training and data augmentation approaches in\nisolation and combination, using experimental data sets with three different\nimaging technologies (mammograms, X-rays, and ultrasound). We demonstrate that\nRTDA achieves superior robustness against adversarial attacks and improved\ngeneralization performance in the presence of distribution shift in each image\nclassification task while maintaining high clean accuracy.", "AI": {"tldr": "Proposes RTDA, a robust training algorithm with data augmentation, to improve medical image classifier resilience against adversarial attacks and distribution shifts.", "motivation": "Deep neural networks in medical imaging are vulnerable to adversarial attacks and distribution shifts, undermining diagnostic reliability and trust.", "method": "Introduces RTDA, benchmarking it against six baseline techniques (including adversarial training and data augmentation) across three imaging technologies.", "result": "RTDA shows superior robustness against adversarial attacks and better generalization with distribution shifts while maintaining high clean accuracy.", "conclusion": "RTDA effectively enhances the reliability of medical image classifiers by addressing adversarial and distribution shift vulnerabilities."}}
{"id": "2506.16017", "pdf": "https://arxiv.org/pdf/2506.16017", "abs": "https://arxiv.org/abs/2506.16017", "authors": ["Liangjing Shao", "Linxin Bai", "Chenkang Du", "Xinrong Chen"], "title": "EndoMUST: Monocular Depth Estimation for Robotic Endoscopy via End-to-end Multi-step Self-supervised Training", "categories": ["cs.CV", "cs.RO"], "comment": "Accepted by IROS 2025", "summary": "Monocular depth estimation and ego-motion estimation are significant tasks\nfor scene perception and navigation in stable, accurate and efficient\nrobot-assisted endoscopy. To tackle lighting variations and sparse textures in\nendoscopic scenes, multiple techniques including optical flow, appearance flow\nand intrinsic image decomposition have been introduced into the existing\nmethods. However, the effective training strategy for multiple modules are\nstill critical to deal with both illumination issues and information\ninterference for self-supervised depth estimation in endoscopy. Therefore, a\nnovel framework with multistep efficient finetuning is proposed in this work.\nIn each epoch of end-to-end training, the process is divided into three steps,\nincluding optical flow registration, multiscale image decomposition and\nmultiple transformation alignments. At each step, only the related networks are\ntrained without interference of irrelevant information. Based on\nparameter-efficient finetuning on the foundation model, the proposed method\nachieves state-of-the-art performance on self-supervised depth estimation on\nSCARED dataset and zero-shot depth estimation on Hamlyn dataset, with\n4\\%$\\sim$10\\% lower error. The evaluation code of this work has been published\non https://github.com/BaymaxShao/EndoMUST.", "AI": {"tldr": "A novel framework with multistep efficient finetuning improves self-supervised depth estimation in endoscopy, achieving state-of-the-art performance with lower error rates.", "motivation": "Addressing lighting variations and sparse textures in endoscopic scenes for better depth and ego-motion estimation.", "method": "Three-step training process: optical flow registration, multiscale image decomposition, and multiple transformation alignments, with parameter-efficient finetuning.", "result": "Achieves 4-10% lower error on SCARED and Hamlyn datasets.", "conclusion": "The proposed method outperforms existing techniques, offering a robust solution for endoscopic depth estimation."}}
{"id": "2506.15704", "pdf": "https://arxiv.org/pdf/2506.15704", "abs": "https://arxiv.org/abs/2506.15704", "authors": ["Feiyu Yao", "Qian Wang"], "title": "Learn from the Past: Fast Sparse Indexing for Large Language Model Decoding", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": null, "summary": "As large language models (LLMs) continue to support increasingly longer\ncontexts, the memory demand for key-value (KV) caches during decoding grows\nrapidly, becoming a critical bottleneck in both GPU memory capacity and PCIe\nbandwidth. Sparse attention mechanisms alleviate this issue by computing\nattention weights only for selected key-value pairs. However, their indexing\ncomputation typically requires traversing all key vectors, resulting in\nsignificant computational and data transfer overhead. To reduce the cost of\nindex retrieval, existing methods often treat each decoding step as an\nindependent process, failing to exploit the temporal correlations embedded in\nhistorical decoding information. To this end, we propose LFPS(Learn From the\nPast for Sparse Indexing), an acceleration method that dynamically constructs\nsparse indexing candidates based on historical attention patterns. LFPS\ncaptures two prevalent trends in decoder attention -vertical patterns\n(attending to fixed positions) and slash patterns (attending to relative\npositions) -and incorporates a positional expansion strategy to effectively\npredict the Top-k indices for the current step. We validate LFPS on challenging\nlong-context benchmarks such as LongBench-RULER, using Llama-3.1-8B-Instruct as\nthe base model. Experimental results show that LFPS achieves up to 22.8$\\times$\nspeedup over full attention and 9.6$\\times$ speedup over exact Top-k retrieval\non an RTX 4090 GPU and a single CPU core of a Xeon Gold 6430, respectively,\nwhile preserving generation accuracy. These results demonstrate that LFPS\noffers a practical and efficient solution for decoding optimization in\nlong-context LLM inference.", "AI": {"tldr": "LFPS accelerates sparse indexing in LLMs by leveraging historical attention patterns, achieving significant speedups while maintaining accuracy.", "motivation": "The growing memory demand for KV caches in LLMs with long contexts creates bottlenecks in GPU memory and bandwidth. Existing sparse attention methods inefficiently retrieve indices due to independent step processing.", "method": "LFPS dynamically constructs sparse indexing candidates using historical attention patterns (vertical and slash) and a positional expansion strategy to predict Top-k indices.", "result": "LFPS achieves up to 22.8\u00d7 speedup over full attention and 9.6\u00d7 over exact Top-k retrieval on benchmarks, preserving accuracy.", "conclusion": "LFPS provides an efficient and practical solution for optimizing long-context LLM decoding."}}
{"id": "2506.16335", "pdf": "https://arxiv.org/pdf/2506.16335", "abs": "https://arxiv.org/abs/2506.16335", "authors": ["Albert Sadowski", "Jaros\u0142aw A. Chudziak"], "title": "Explainable Rule Application via Structured Prompting: A Neural-Symbolic Approach", "categories": ["cs.AI", "cs.CL"], "comment": "Accepted for publication at the 29th International Conference on\n  Knowledge-Based and Intelligent Information \\& Engineering Systems (KES 2025)", "summary": "Large Language Models (LLMs) excel in complex reasoning tasks but struggle\nwith consistent rule application, exception handling, and explainability,\nparticularly in domains like legal analysis that require both natural language\nunderstanding and precise logical inference. This paper introduces a structured\nprompting framework that decomposes reasoning into three verifiable steps:\nentity identification, property extraction, and symbolic rule application. By\nintegrating neural and symbolic approaches, our method leverages LLMs'\ninterpretive flexibility while ensuring logical consistency through formal\nverification. The framework externalizes task definitions, enabling domain\nexperts to refine logical structures without altering the architecture.\nEvaluated on the LegalBench hearsay determination task, our approach\nsignificantly outperformed baselines, with OpenAI o-family models showing\nsubstantial improvements - o1 achieving an F1 score of 0.929 and o3-mini\nreaching 0.867 using structured decomposition with complementary predicates,\ncompared to their few-shot baselines of 0.714 and 0.74 respectively. This\nhybrid neural-symbolic system offers a promising pathway for transparent and\nconsistent rule-based reasoning, suggesting potential for explainable AI\napplications in structured legal reasoning tasks.", "AI": {"tldr": "A structured prompting framework combines neural and symbolic methods to improve LLMs' rule-based reasoning, achieving high performance in legal tasks.", "motivation": "LLMs struggle with consistent rule application and explainability in domains like legal analysis, requiring a hybrid approach for better performance.", "method": "Decomposes reasoning into entity identification, property extraction, and symbolic rule application, integrating neural flexibility with formal verification.", "result": "Outperformed baselines on LegalBench, with F1 scores of 0.929 (o1) and 0.867 (o3-mini) vs. few-shot baselines of 0.714 and 0.74.", "conclusion": "The hybrid system enhances transparent, consistent reasoning, showing promise for explainable AI in legal tasks."}}
{"id": "2506.16247", "pdf": "https://arxiv.org/pdf/2506.16247", "abs": "https://arxiv.org/abs/2506.16247", "authors": ["Anindita Bhattacharya", "Tohida Rehman", "Debarshi Kumar Sanyal", "Samiran Chattopadhyay"], "title": "Comparative Analysis of Abstractive Summarization Models for Clinical Radiology Reports", "categories": ["cs.CL"], "comment": "14 pages, 2 figures, 6 tables", "summary": "The findings section of a radiology report is often detailed and lengthy,\nwhereas the impression section is comparatively more compact and captures key\ndiagnostic conclusions. This research explores the use of advanced abstractive\nsummarization models to generate the concise impression from the findings\nsection of a radiology report. We have used the publicly available MIMIC-CXR\ndataset. A comparative analysis is conducted on leading pre-trained and\nopen-source large language models, including T5-base, BART-base,\nPEGASUS-x-base, ChatGPT-4, LLaMA-3-8B, and a custom Pointer Generator Network\nwith a coverage mechanism. To ensure a thorough assessment, multiple evaluation\nmetrics are employed, including ROUGE-1, ROUGE-2, ROUGE-L, METEOR, and\nBERTScore. By analyzing the performance of these models, this study identifies\ntheir respective strengths and limitations in the summarization of medical\ntext. The findings of this paper provide helpful information for medical\nprofessionals who need automated summarization solutions in the healthcare\nsector.", "AI": {"tldr": "This research evaluates advanced abstractive summarization models to generate concise radiology report impressions from detailed findings, using the MIMIC-CXR dataset and comparing multiple models and metrics.", "motivation": "To automate the summarization of lengthy radiology findings into concise impressions, aiding medical professionals.", "method": "Comparative analysis of pre-trained models (T5-base, BART-base, PEGASUS-x-base, ChatGPT-4, LLaMA-3-8B) and a custom Pointer Generator Network with coverage, evaluated using ROUGE, METEOR, and BERTScore.", "result": "Identifies strengths and limitations of each model in medical text summarization.", "conclusion": "Provides valuable insights for healthcare professionals seeking automated summarization solutions."}}
{"id": "2503.23804", "pdf": "https://arxiv.org/pdf/2503.23804", "abs": "https://arxiv.org/abs/2503.23804", "authors": ["Shiyi Yang", "Zhibo Hu", "Xinshu Li", "Chen Wang", "Tong Yu", "Xiwei Xu", "Liming Zhu", "Lina Yao"], "title": "DrunkAgent: Stealthy Memory Corruption in LLM-Powered Recommender Agents", "categories": ["cs.CR", "cs.CL", "cs.IR", "cs.MA"], "comment": null, "summary": "Large language model (LLM)-powered agents are increasingly used in\nrecommender systems (RSs) to achieve personalized behavior modeling, where the\nmemory mechanism plays a pivotal role in enabling the agents to autonomously\nexplore, learn and self-evolve from real-world interactions. However, this very\nmechanism, serving as a contextual repository, inherently exposes an attack\nsurface for potential adversarial manipulations. Despite its central role, the\nrobustness of agentic RSs in the face of such threats remains largely\nunderexplored. Previous works suffer from semantic mismatches or rely on static\nembeddings or pre-defined prompts, all of which hinder their applicability to\nsystems with dynamic memory states. This challenge is exacerbated by the\nblack-box nature of commercial RSs.\n  To tackle the above problems, in this paper, we present the first systematic\ninvestigation of memory-based vulnerabilities in LLM-powered recommender\nagents, revealing their security limitations and guiding efforts to strengthen\nsystem resilience and trustworthiness. Specifically, we propose a novel\nblack-box attack framework named DrunkAgent. DrunkAgent crafts semantically\nmeaningful adversarial textual triggers for target item promotions and\nintroduces a series of strategies to maximize the trigger effect by corrupting\nthe memory updates during the interactions. The triggers and strategies are\noptimized on a surrogate model, enabling DrunkAgent transferable and stealthy.\nExtensive experiments on real-world datasets across diverse agentic RSs,\nincluding collaborative filtering, retrieval augmentation and sequential\nrecommendations, demonstrate the generalizability, transferability and\nstealthiness of DrunkAgent.", "AI": {"tldr": "The paper investigates vulnerabilities in LLM-powered recommender agents, proposing a black-box attack framework, DrunkAgent, to exploit memory-based weaknesses and enhance system resilience.", "motivation": "The memory mechanism in LLM-powered recommender agents, while enabling autonomous learning, introduces vulnerabilities to adversarial attacks, which are underexplored.", "method": "The authors propose DrunkAgent, a framework crafting adversarial textual triggers and strategies to corrupt memory updates, optimized on a surrogate model.", "result": "Experiments show DrunkAgent's effectiveness across diverse recommender systems, highlighting its generalizability, transferability, and stealthiness.", "conclusion": "The study underscores the need for robust defenses in LLM-powered recommender agents against memory-based adversarial attacks."}}
{"id": "2506.17140", "pdf": "https://arxiv.org/pdf/2506.17140", "abs": "https://arxiv.org/abs/2506.17140", "authors": ["David Jacob Drexlin", "Jonas Dippel", "Julius Hense", "Niklas Preni\u00dfl", "Gr\u00e9goire Montavon", "Frederick Klauschen", "Klaus-Robert M\u00fcller"], "title": "MeDi: Metadata-Guided Diffusion Models for Mitigating Biases in Tumor Classification", "categories": ["eess.IV", "cs.AI", "cs.CV"], "comment": null, "summary": "Deep learning models have made significant advances in histological\nprediction tasks in recent years. However, for adaptation in clinical practice,\ntheir lack of robustness to varying conditions such as staining, scanner,\nhospital, and demographics is still a limiting factor: if trained on\noverrepresented subpopulations, models regularly struggle with less frequent\npatterns, leading to shortcut learning and biased predictions. Large-scale\nfoundation models have not fully eliminated this issue. Therefore, we propose a\nnovel approach explicitly modeling such metadata into a Metadata-guided\ngenerative Diffusion model framework (MeDi). MeDi allows for a targeted\naugmentation of underrepresented subpopulations with synthetic data, which\nbalances limited training data and mitigates biases in downstream models. We\nexperimentally show that MeDi generates high-quality histopathology images for\nunseen subpopulations in TCGA, boosts the overall fidelity of the generated\nimages, and enables improvements in performance for downstream classifiers on\ndatasets with subpopulation shifts. Our work is a proof-of-concept towards\nbetter mitigating data biases with generative models.", "AI": {"tldr": "MeDi, a Metadata-guided generative Diffusion model, addresses biases in deep learning for histopathology by augmenting underrepresented subpopulations with synthetic data, improving downstream model performance.", "motivation": "Deep learning models in histopathology lack robustness to varying conditions (e.g., staining, demographics), leading to biased predictions due to shortcut learning. Foundation models haven't fully resolved this.", "method": "Proposes MeDi, a framework that models metadata to generate synthetic data for underrepresented subpopulations, balancing training data and mitigating biases.", "result": "MeDi generates high-quality histopathology images for unseen subpopulations, improves image fidelity, and enhances downstream classifier performance on datasets with subpopulation shifts.", "conclusion": "MeDi demonstrates potential for mitigating data biases in histopathology using generative models, serving as a proof-of-concept."}}
{"id": "2506.16054", "pdf": "https://arxiv.org/pdf/2506.16054", "abs": "https://arxiv.org/abs/2506.16054", "authors": ["Tianchen Zhao", "Ke Hong", "Xinhao Yang", "Xuefeng Xiao", "Huixia Li", "Feng Ling", "Ruiqi Xie", "Siqi Chen", "Hongyu Zhu", "Yichong Zhang", "Yu Wang"], "title": "PAROAttention: Pattern-Aware ReOrdering for Efficient Sparse and Quantized Attention in Visual Generation Models", "categories": ["cs.CV", "cs.GR"], "comment": "project page: https://a-suozhang.xyz/paroattn.github.io", "summary": "In visual generation, the quadratic complexity of attention mechanisms\nresults in high memory and computational costs, especially for longer token\nsequences required in high-resolution image or multi-frame video generation. To\naddress this, prior research has explored techniques such as sparsification and\nquantization. However, these techniques face significant challenges under low\ndensity and reduced bitwidths. Through systematic analysis, we identify that\nthe core difficulty stems from the dispersed and irregular characteristics of\nvisual attention patterns. Therefore, instead of introducing specialized\nsparsification and quantization design to accommodate such patterns, we propose\nan alternative strategy: *reorganizing* the attention pattern to alleviate the\nchallenges. Inspired by the local aggregation nature of visual feature\nextraction, we design a novel **Pattern-Aware token ReOrdering (PARO)**\ntechnique, which unifies the diverse attention patterns into a\nhardware-friendly block-wise pattern. This unification substantially simplifies\nand enhances both sparsification and quantization. We evaluate the\nperformance-efficiency trade-offs of various design choices and finalize a\nmethodology tailored for the unified pattern. Our approach, **PAROAttention**,\nachieves video and image generation with lossless metrics, and nearly identical\nresults from full-precision (FP) baselines, while operating at notably lower\ndensity (~20%-30%) and bitwidth (**INT8/INT4**), achieving a **1.9x** to\n**2.7x** end-to-end latency speedup.", "AI": {"tldr": "PAROAttention reorganizes visual attention patterns into block-wise structures to simplify sparsification and quantization, achieving efficient high-resolution image/video generation with minimal quality loss.", "motivation": "Quadratic complexity of attention mechanisms in visual generation leads to high costs; existing sparsification/quantization techniques struggle with low density and reduced bitwidths due to irregular attention patterns.", "method": "Proposes PARO, a technique to reorganize attention patterns into hardware-friendly block-wise structures, enhancing sparsification and quantization.", "result": "PAROAttention achieves lossless metrics and near-FP baseline results at lower density (~20%-30%) and bitwidth (INT8/INT4), with 1.9x-2.7x speedup.", "conclusion": "Reorganizing attention patterns (PARO) is an effective alternative to specialized sparsification/quantization, enabling efficient visual generation without compromising quality."}}
{"id": "2506.15705", "pdf": "https://arxiv.org/pdf/2506.15705", "abs": "https://arxiv.org/abs/2506.15705", "authors": ["Jittarin Jetwiriyanon", "Teo Susnjak", "Surangika Ranathunga"], "title": "Generalisation Bounds of Zero-Shot Economic Forecasting using Time Series Foundation Models", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "This study investigates zero-shot forecasting capabilities of Time Series\nFoundation Models (TSFMs) for macroeconomic indicators. We apply TSFMs to\nforecasting economic indicators under univariate conditions, bypassing the need\nfor train bespoke econometric models using and extensive training datasets. Our\nexperiments were conducted on a case study dataset, without additional\ncustomisation. We rigorously back-tested three state-of-the-art TSFMs (Chronos,\nTimeGPT and Moirai) under data-scarce conditions and structural breaks. Our\nresults demonstrate that appropriately engineered TSFMs can internalise rich\neconomic dynamics, accommodate regime shifts, and deliver well-behaved\nuncertainty estimates out of the box, while matching state-of-the-art\nmultivariate models on this domain. Our findings suggest that, without any\nfine-tuning, TSFMs can match or exceed classical models during stable economic\nconditions. However, they are vulnerable to degradation in performances during\nperiods of rapid shocks. The findings offer guidance to practitioners on when\nzero-shot deployments are viable for macroeconomic monitoring and strategic\nplanning.", "AI": {"tldr": "TSFMs show strong zero-shot forecasting for macroeconomic indicators, matching classical models in stable conditions but struggling during rapid shocks.", "motivation": "To explore the zero-shot forecasting capabilities of TSFMs for macroeconomic indicators without extensive training data.", "method": "Applied three TSFMs (Chronos, TimeGPT, Moirai) to univariate forecasting of economic indicators, tested under data-scarce conditions and structural breaks.", "result": "TSFMs internalize economic dynamics, handle regime shifts, and provide uncertainty estimates, matching multivariate models in stable conditions but degrading during shocks.", "conclusion": "TSFMs are viable for zero-shot macroeconomic forecasting in stable conditions but require caution during rapid shocks."}}
{"id": "2506.16402", "pdf": "https://arxiv.org/pdf/2506.16402", "abs": "https://arxiv.org/abs/2506.16402", "authors": ["Xiaoya Lu", "Zeren Chen", "Xuhao Hu", "Yijin Zhou", "Weichen Zhang", "Dongrui Liu", "Lu Sheng", "Jing Shao"], "title": "IS-Bench: Evaluating Interactive Safety of VLM-Driven Embodied Agents in Daily Household Tasks", "categories": ["cs.AI", "cs.CL", "cs.CV", "cs.LG", "cs.RO"], "comment": null, "summary": "Flawed planning from VLM-driven embodied agents poses significant safety\nhazards, hindering their deployment in real-world household tasks. However,\nexisting static, non-interactive evaluation paradigms fail to adequately assess\nrisks within these interactive environments, since they cannot simulate dynamic\nrisks that emerge from an agent's actions and rely on unreliable post-hoc\nevaluations that ignore unsafe intermediate steps. To bridge this critical gap,\nwe propose evaluating an agent's interactive safety: its ability to perceive\nemergent risks and execute mitigation steps in the correct procedural order. We\nthus present IS-Bench, the first multi-modal benchmark designed for interactive\nsafety, featuring 161 challenging scenarios with 388 unique safety risks\ninstantiated in a high-fidelity simulator. Crucially, it facilitates a novel\nprocess-oriented evaluation that verifies whether risk mitigation actions are\nperformed before/after specific risk-prone steps. Extensive experiments on\nleading VLMs, including the GPT-4o and Gemini-2.5 series, reveal that current\nagents lack interactive safety awareness, and that while safety-aware\nChain-of-Thought can improve performance, it often compromises task completion.\nBy highlighting these critical limitations, IS-Bench provides a foundation for\ndeveloping safer and more reliable embodied AI systems.", "AI": {"tldr": "IS-Bench is a new benchmark for evaluating interactive safety in VLM-driven embodied agents, addressing dynamic risks and mitigation steps in real-world tasks.", "motivation": "Current evaluation methods fail to assess dynamic risks in interactive environments, posing safety hazards for embodied agents.", "method": "Proposes IS-Bench, a multi-modal benchmark with 161 scenarios and 388 safety risks, enabling process-oriented evaluation of risk mitigation.", "result": "Experiments show current VLMs lack interactive safety awareness; safety-aware Chain-of-Thought helps but may hinder task completion.", "conclusion": "IS-Bench lays groundwork for safer embodied AI by exposing critical safety limitations in current agents."}}
{"id": "2506.16322", "pdf": "https://arxiv.org/pdf/2506.16322", "abs": "https://arxiv.org/abs/2506.16322", "authors": ["Aleksandra Krasnod\u0119bska", "Karolina Seweryn", "Szymon \u0141ukasik", "Wojciech Kusa"], "title": "PL-Guard: Benchmarking Language Model Safety for Polish", "categories": ["cs.CL", "I.2.7"], "comment": "Accepted to the 10th Workshop on Slavic Natural Language Processing", "summary": "Despite increasing efforts to ensure the safety of large language models\n(LLMs), most existing safety assessments and moderation tools remain heavily\nbiased toward English and other high-resource languages, leaving majority of\nglobal languages underexamined. To address this gap, we introduce a manually\nannotated benchmark dataset for language model safety classification in Polish.\nWe also create adversarially perturbed variants of these samples designed to\nchallenge model robustness. We conduct a series of experiments to evaluate\nLLM-based and classifier-based models of varying sizes and architectures.\nSpecifically, we fine-tune three models: Llama-Guard-3-8B, a HerBERT-based\nclassifier (a Polish BERT derivative), and PLLuM, a Polish-adapted Llama-8B\nmodel. We train these models using different combinations of annotated data and\nevaluate their performance, comparing it against publicly available guard\nmodels. Results demonstrate that the HerBERT-based classifier achieves the\nhighest overall performance, particularly under adversarial conditions.", "AI": {"tldr": "A benchmark dataset for LLM safety in Polish is introduced, with adversarial samples. Three models are evaluated, with the HerBERT-based classifier performing best.", "motivation": "Existing safety assessments for LLMs are biased toward high-resource languages, leaving others like Polish underexamined.", "method": "A manually annotated benchmark dataset for Polish is created, along with adversarial variants. Three models (Llama-Guard-3-8B, HerBERT-based classifier, PLLuM) are fine-tuned and evaluated.", "result": "The HerBERT-based classifier achieves the highest performance, especially under adversarial conditions.", "conclusion": "The study highlights the need for multilingual safety assessments and demonstrates the effectiveness of a Polish-specific classifier."}}
{"id": "2504.12345", "pdf": "https://arxiv.org/pdf/2504.12345", "abs": "https://arxiv.org/abs/2504.12345", "authors": ["Yutong Xia", "Ao Qu", "Yunhan Zheng", "Yihong Tang", "Dingyi Zhuang", "Yuxuan Liang", "Shenhao Wang", "Cathy Wu", "Lijun Sun", "Roger Zimmermann", "Jinhua Zhao"], "title": "Reimagining Urban Science: Scaling Causal Inference with Large Language Models", "categories": ["cs.CL", "cs.CY", "cs.MA"], "comment": null, "summary": "Urban causal research is essential for understanding the complex, dynamic\nprocesses that shape cities and for informing evidence-based policies. However,\ncurrent practices are often constrained by inefficient and biased hypothesis\nformulation, challenges in integrating multimodal data, and fragile\nexperimental methodologies. Imagine a system that automatically estimates the\ncausal impact of congestion pricing on commute times by income group or\nmeasures how new green spaces affect asthma rates across neighborhoods using\nsatellite imagery and health reports, and then generates comprehensive,\npolicy-ready outputs, including causal estimates, subgroup analyses, and\nactionable recommendations. In this Perspective, we propose UrbanCIA, an\nLLM-driven conceptual framework composed of four distinct modular agents\nresponsible for hypothesis generation, data engineering, experiment design and\nexecution, and results interpretation with policy insights. We begin by\nexamining the current landscape of urban causal research through a structured\ntaxonomy of research topics, data sources, and methodological approaches,\nrevealing systemic limitations across the workflow. Next, we introduce the\ndesign principles and technological roadmap for the four modules in the\nproposed framework. We also propose evaluation criteria to assess the rigor and\ntransparency of these AI-augmented processes. Finally, we reflect on the\nbroader implications for human-AI collaboration, equity, and accountability. We\ncall for a new research agenda that embraces LLM-driven tools as catalysts for\nmore scalable, reproducible, and inclusive urban research.", "AI": {"tldr": "UrbanCIA is an LLM-driven framework for urban causal research, addressing inefficiencies in hypothesis formulation, data integration, and methodology. It proposes modular agents for hypothesis generation, data engineering, experiment design, and policy insights.", "motivation": "Current urban causal research faces challenges like biased hypothesis formulation, data integration issues, and fragile methodologies, limiting its effectiveness for policy-making.", "method": "UrbanCIA uses four modular agents: hypothesis generation, data engineering, experiment design/execution, and results interpretation. It leverages LLMs for scalable, reproducible research.", "result": "The framework aims to improve rigor, transparency, and inclusivity in urban research, enabling better policy insights and actionable recommendations.", "conclusion": "UrbanCIA advocates for LLM-driven tools to enhance urban research scalability, reproducibility, and equity, calling for a new research agenda."}}
{"id": "2506.17165", "pdf": "https://arxiv.org/pdf/2506.17165", "abs": "https://arxiv.org/abs/2506.17165", "authors": ["Mahin Montasir Afif", "Abdullah Al Noman", "K. M. Tahsin Kabir", "Md. Mortuza Ahmmed", "Md. Mostafizur Rahman", "Mufti Mahmud", "Md. Ashraful Babu"], "title": "Proportional Sensitivity in Generative Adversarial Network (GAN)-Augmented Brain Tumor Classification Using Convolutional Neural Network", "categories": ["eess.IV", "cs.AI", "cs.CV"], "comment": "This papaer has been submitted to The 18th International Conference\n  on Brain Informatics (BI'25), Italy", "summary": "Generative Adversarial Networks (GAN) have shown potential in expanding\nlimited medical imaging datasets. This study explores how different ratios of\nGAN-generated and real brain tumor MRI images impact the performance of a CNN\nin classifying healthy vs. tumorous scans. A DCGAN was used to create synthetic\nimages which were mixed with real ones at various ratios to train a custom CNN.\nThe CNN was then evaluated on a separate real-world test set. Our results\nindicate that the model maintains high sensitivity and precision in tumor\nclassification, even when trained predominantly on synthetic data. When only a\nsmall portion of GAN data was added, such as 900 real images and 100 GAN\nimages, the model achieved excellent performance, with test accuracy reaching\n95.2%, and precision, recall, and F1-score all exceeding 95%. However, as the\nproportion of GAN images increased further, performance gradually declined.\nThis study suggests that while GANs are useful for augmenting limited datasets\nespecially when real data is scarce, too much synthetic data can introduce\nartifacts that affect the model's ability to generalize to real world cases.", "AI": {"tldr": "GAN-generated MRI images can augment limited medical datasets, but excessive synthetic data may reduce CNN performance.", "motivation": "To explore the impact of varying ratios of GAN-generated and real brain tumor MRI images on CNN classification performance.", "method": "Used DCGAN to create synthetic images, mixed them with real images at different ratios, and trained a custom CNN for classification.", "result": "High performance (95.2% accuracy) with small GAN additions, but performance declined as synthetic data proportion increased.", "conclusion": "GANs are useful for data augmentation, but excessive synthetic data can harm model generalization."}}
{"id": "2506.16058", "pdf": "https://arxiv.org/pdf/2506.16058", "abs": "https://arxiv.org/abs/2506.16058", "authors": ["Yong Liu", "SongLi Wu", "Sule Bai", "Jiahao Wang", "Yitong Wang", "Yansong Tang"], "title": "Stepping Out of Similar Semantic Space for Open-Vocabulary Segmentation", "categories": ["cs.CV"], "comment": null, "summary": "Open-vocabulary segmentation aims to achieve segmentation of arbitrary\ncategories given unlimited text inputs as guidance. To achieve this, recent\nworks have focused on developing various technical routes to exploit the\npotential of large-scale pre-trained vision-language models and have made\nsignificant progress on existing benchmarks. However, we find that existing\ntest sets are limited in measuring the models' comprehension of\n``open-vocabulary\" concepts, as their semantic space closely resembles the\ntraining space, even with many overlapping categories. To this end, we present\na new benchmark named OpenBench that differs significantly from the training\nsemantics. It is designed to better assess the model's ability to understand\nand segment a wide range of real-world concepts. When testing existing methods\non OpenBench, we find that their performance diverges from the conclusions\ndrawn on existing test sets. In addition, we propose a method named OVSNet to\nimprove the segmentation performance for diverse and open scenarios. Through\nelaborate fusion of heterogeneous features and cost-free expansion of the\ntraining space, OVSNet achieves state-of-the-art results on both existing\ndatasets and our proposed OpenBench. Corresponding analysis demonstrate the\nsoundness and effectiveness of our proposed benchmark and method.", "AI": {"tldr": "The paper introduces OpenBench, a new benchmark for open-vocabulary segmentation, and proposes OVSNet, a method that outperforms existing approaches on both traditional and new benchmarks.", "motivation": "Existing benchmarks for open-vocabulary segmentation fail to measure true comprehension of diverse concepts due to semantic overlap with training data.", "method": "The authors propose OVSNet, which fuses heterogeneous features and expands the training space cost-free to improve segmentation.", "result": "OVSNet achieves state-of-the-art results on existing datasets and the new OpenBench benchmark.", "conclusion": "The paper demonstrates the effectiveness of OpenBench and OVSNet in advancing open-vocabulary segmentation."}}
{"id": "2506.15706", "pdf": "https://arxiv.org/pdf/2506.15706", "abs": "https://arxiv.org/abs/2506.15706", "authors": ["Yunze Lin"], "title": "MDPO: Multi-Granularity Direct Preference Optimization for Mathematical Reasoning", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Mathematical reasoning presents a significant challenge for Large Language\nModels (LLMs) as it requires ensuring the correctness of each reasoning step.\nResearchers have been strengthening the mathematical reasoning abilities of\nLLMs through supervised fine-tuning, but due to the inability to suppress\nincorrect outputs, illusions can easily arise. Recently, Direct Preference\nOptimization (DPO) has been widely adopted for aligning human intent by using\npreference data to prevent LLMs from generating incorrect outputs. However, it\nhas shown limited benefits in long-chain mathematical reasoning, mainly because\nDPO struggles to effectively capture the differences between accepted and\nrejected answers from preferences in long-chain data. The inconsistency between\nDPO training and LLMs' generation metrics also affects the effectiveness of\nsuppressing incorrect outputs. We propose the Multi-Granularity Direct\nPreference Optimization (MDPO) method, optimizing the mathematical reasoning of\nLLMs at three granularities: Solution2Solution, Inference2Inference, and\nStep2Step. Solution2Solution focuses on the correctness of entire long-chain\nreasoning; Inference2Inference concentrates on logical reasoning between steps;\nStep2Step corrects computational errors in steps, enhancing the computational\ncapabilities of LLMs. Additionally, we unify the training objectives of the\nthree granularities to align with the generation metrics. We conducted\nexperiments on the open-source models Qwen2 and Llama3, achieving improvements\nof 1.7% and 0.9% on the GSM8K dataset, and 2.3% and 1.2% on the MATH dataset,\noutperforming DPO and other DPO variant methods. Furthermore, we also provide a\npipeline for constructing MDPO training data that is simple and does not\nrequire manual annotation costs.", "AI": {"tldr": "The paper introduces Multi-Granularity Direct Preference Optimization (MDPO) to improve LLMs' mathematical reasoning by addressing DPO's limitations in long-chain reasoning, achieving better performance on GSM8K and MATH datasets.", "motivation": "Existing methods like DPO fail to effectively suppress incorrect outputs in long-chain mathematical reasoning due to their inability to capture granular differences in preferences.", "method": "Proposes MDPO, optimizing LLMs at three granularities (Solution2Solution, Inference2Inference, Step2Step) and unifying training objectives with generation metrics.", "result": "MDPO improves Qwen2 and Llama3 by 1.7%/0.9% on GSM8K and 2.3%/1.2% on MATH, outperforming DPO and variants.", "conclusion": "MDPO enhances mathematical reasoning in LLMs by addressing DPO's shortcomings and offers a cost-effective data construction pipeline."}}
{"id": "2506.16429", "pdf": "https://arxiv.org/pdf/2506.16429", "abs": "https://arxiv.org/abs/2506.16429", "authors": ["Sami Abboud", "Eleanor Hanna", "Olivier Jeunen", "Vineesha Raheja", "Schaun Wheeler"], "title": "Agentic Personalisation of Cross-Channel Marketing Experiences", "categories": ["cs.AI", "cs.IR", "cs.LG"], "comment": null, "summary": "Consumer applications provide ample opportunities to surface and communicate\nvarious forms of content to users. From promotional campaigns for new features\nor subscriptions, to evergreen nudges for engagement, or personalised\nrecommendations; across e-mails, push notifications, and in-app surfaces. The\nconventional approach to orchestration for communication relies heavily on\nlabour-intensive manual marketer work, and inhibits effective personalisation\nof content, timing, frequency, and copy-writing. We formulate this task under a\nsequential decision-making framework, where we aim to optimise a modular\ndecision-making policy that maximises incremental engagement for any funnel\nevent. Our approach leverages a Difference-in-Differences design for Individual\nTreatment Effect estimation, and Thompson sampling to balance the\nexplore-exploit trade-off. We present results from a multi-service application,\nwhere our methodology has resulted in significant increases to a variety of\ngoal events across several product features, and is currently deployed across\n150 million users.", "AI": {"tldr": "The paper introduces an automated approach to optimize consumer communication, replacing manual marketer work with a sequential decision-making framework for personalized engagement.", "motivation": "Manual orchestration of consumer communication is labor-intensive and limits personalization. The paper aims to automate and optimize this process.", "method": "Uses a Difference-in-Differences design for Individual Treatment Effect estimation and Thompson sampling to balance exploration and exploitation.", "result": "Significant increases in engagement across multiple product features, deployed for 150 million users.", "conclusion": "The proposed framework effectively automates and personalizes consumer communication, improving engagement at scale."}}
{"id": "2506.16337", "pdf": "https://arxiv.org/pdf/2506.16337", "abs": "https://arxiv.org/abs/2506.16337", "authors": ["Agnese Daffara", "Sourabh Dattawad", "Sebastian Pad\u00f3", "Tanise Ceron"], "title": "Generalizability of Media Frames: Corpus creation and analysis across countries", "categories": ["cs.CL"], "comment": "8 pages + References (3 pages) and Appendix (4 pages). This paper was\n  submitted to StarSem 2025 and is currently under review", "summary": "Frames capture aspects of an issue that are emphasized in a debate by\ninterlocutors and can help us understand how political language conveys\ndifferent perspectives and ultimately shapes people's opinions. The Media Frame\nCorpus (MFC) is the most commonly used framework with categories and detailed\nguidelines for operationalizing frames. It is, however, focused on a few\nsalient U.S. news issues, making it unclear how well these frames can capture\nnews issues in other cultural contexts. To explore this, we introduce\nFrameNews-PT, a dataset of Brazilian Portuguese news articles covering\npolitical and economic news and annotate it within the MFC framework. Through\nseveral annotation rounds, we evaluate the extent to which MFC frames\ngeneralize to the Brazilian debate issues. We further evaluate how fine-tuned\nand zero-shot models perform on out-of-domain data. Results show that the 15\nMFC frames remain broadly applicable with minor revisions of the guidelines.\nHowever, some MFC frames are rarely used, and novel news issues are analyzed\nusing general 'fall-back' frames. We conclude that cross-cultural frame use\nrequires careful consideration.", "AI": {"tldr": "The paper evaluates the applicability of the Media Frame Corpus (MFC) to Brazilian Portuguese news, finding it broadly applicable but requiring minor adjustments.", "motivation": "To assess if MFC frames generalize to non-U.S. cultural contexts, specifically Brazilian news.", "method": "Introduce FrameNews-PT, annotate Brazilian news using MFC, and evaluate frame generalization and model performance.", "result": "MFC frames are broadly applicable but need minor guideline revisions; some frames are rarely used.", "conclusion": "Cross-cultural frame use requires careful consideration due to variations in frame applicability."}}
{"id": "2505.12010", "pdf": "https://arxiv.org/pdf/2505.12010", "abs": "https://arxiv.org/abs/2505.12010", "authors": ["Drashthi Doshi", "Aditya Vema Reddy Kesari", "Swaprava Nath", "Avishek Ghosh", "Suhas S Kowshik"], "title": "Incentivize Contribution and Learn Parameters Too: Federated Learning with Strategic Data Owners", "categories": ["cs.GT", "cs.LG", "cs.MA"], "comment": "19 pages, 12 figures, under review", "summary": "Classical federated learning (FL) assumes that the clients have a limited\namount of noisy data with which they voluntarily participate and contribute\ntowards learning a global, more accurate model in a principled manner. The\nlearning happens in a distributed fashion without sharing the data with the\ncenter. However, these methods do not consider the incentive of an agent for\nparticipating and contributing to the process, given that data collection and\nrunning a distributed algorithm is costly for the clients. The question of\nrationality of contribution has been asked recently in the literature and some\nresults exist that consider this problem. This paper addresses the question of\nsimultaneous parameter learning and incentivizing contribution, which\ndistinguishes it from the extant literature. Our first mechanism incentivizes\neach client to contribute to the FL process at a Nash equilibrium and\nsimultaneously learn the model parameters. However, this equilibrium outcome\ncan be away from the optimal, where clients contribute with their full data and\nthe algorithm learns the optimal parameters. We propose a second mechanism with\nmonetary transfers that is budget balanced and enables the full data\ncontribution along with optimal parameter learning. Large scale experiments\nwith real (federated) datasets (CIFAR-10, FeMNIST, and Twitter) show that these\nalgorithms converge quite fast in practice, yield good welfare guarantees, and\nbetter model performance for all agents.", "AI": {"tldr": "The paper introduces mechanisms to incentivize client participation in federated learning (FL) while simultaneously learning model parameters, addressing gaps in existing literature.", "motivation": "Current FL methods overlook client incentives for participation, despite the costs of data collection and distributed learning. This paper aims to bridge this gap.", "method": "Two mechanisms are proposed: one ensures Nash equilibrium for client contribution, and another uses monetary transfers to achieve optimal data contribution and parameter learning.", "result": "Experiments on real datasets (CIFAR-10, FeMNIST, Twitter) show fast convergence, good welfare guarantees, and improved model performance for all agents.", "conclusion": "The proposed mechanisms effectively balance incentives and learning, enhancing FL outcomes."}}
{"id": "2506.15821", "pdf": "https://arxiv.org/pdf/2506.15821", "abs": "https://arxiv.org/abs/2506.15821", "authors": ["Pham Khai Nguyen Do", "Bao Nguyen Tran", "Nam Nguyen", "Duc Dung Nguyen"], "title": "VEIGAR: View-consistent Explicit Inpainting and Geometry Alignment for 3D object Removal", "categories": ["cs.GR", "cs.AI", "cs.CV", "eess.IV"], "comment": null, "summary": "Recent advances in Novel View Synthesis (NVS) and 3D generation have\nsignificantly improved editing tasks, with a primary emphasis on maintaining\ncross-view consistency throughout the generative process. Contemporary methods\ntypically address this challenge using a dual-strategy framework: performing\nconsistent 2D inpainting across all views guided by embedded priors either\nexplicitly in pixel space or implicitly in latent space; and conducting 3D\nreconstruction with additional consistency guidance. Previous strategies, in\nparticular, often require an initial 3D reconstruction phase to establish\ngeometric structure, introducing considerable computational overhead. Even with\nthe added cost, the resulting reconstruction quality often remains suboptimal.\nIn this paper, we present VEIGAR, a computationally efficient framework that\noutperforms existing methods without relying on an initial reconstruction\nphase. VEIGAR leverages a lightweight foundation model to reliably align priors\nexplicitly in the pixel space. In addition, we introduce a novel supervision\nstrategy based on scale-invariant depth loss, which removes the need for\ntraditional scale-and-shift operations in monocular depth regularization.\nThrough extensive experimentation, VEIGAR establishes a new state-of-the-art\nbenchmark in reconstruction quality and cross-view consistency, while achieving\na threefold reduction in training time compared to the fastest existing method,\nhighlighting its superior balance of efficiency and effectiveness.", "AI": {"tldr": "VEIGAR is a novel framework for efficient Novel View Synthesis and 3D generation, eliminating the need for initial 3D reconstruction and improving consistency and speed.", "motivation": "Addressing the computational overhead and suboptimal quality of existing methods that rely on initial 3D reconstruction.", "method": "Uses a lightweight foundation model for pixel-space alignment and introduces scale-invariant depth loss for supervision.", "result": "Achieves state-of-the-art reconstruction quality and cross-view consistency with a threefold reduction in training time.", "conclusion": "VEIGAR offers a superior balance of efficiency and effectiveness in NVS and 3D generation tasks."}}
{"id": "2506.16061", "pdf": "https://arxiv.org/pdf/2506.16061", "abs": "https://arxiv.org/abs/2506.16061", "authors": ["Yucheng Jin", "Jinyan Chen", "Ziyue He", "Baojun Han", "Furan An"], "title": "STAR-Pose: Efficient Low-Resolution Video Human Pose Estimation via Spatial-Temporal Adaptive Super-Resolution", "categories": ["cs.CV"], "comment": "14pages 3figures, alredy submiss to PRCV 2025", "summary": "Human pose estimation in low-resolution videos presents a fundamental\nchallenge in computer vision. Conventional methods either assume high-quality\ninputs or employ computationally expensive cascaded processing, which limits\ntheir deployment in resource-constrained environments. We propose STAR-Pose, a\nspatial-temporal adaptive super-resolution framework specifically designed for\nvideo-based human pose estimation. Our method features a novel spatial-temporal\nTransformer with LeakyReLU-modified linear attention, which efficiently\ncaptures long-range temporal dependencies. Moreover, it is complemented by an\nadaptive fusion module that integrates parallel CNN branch for local texture\nenhancement. We also design a pose-aware compound loss to achieve task-oriented\nsuper-resolution. This loss guides the network to reconstruct structural\nfeatures that are most beneficial for keypoint localization, rather than\noptimizing purely for visual quality. Extensive experiments on several\nmainstream video HPE datasets demonstrate that STAR-Pose outperforms existing\napproaches. It achieves up to 5.2% mAP improvement under extremely\nlow-resolution (64x48) conditions while delivering 2.8x to 4.4x faster\ninference than cascaded approaches.", "AI": {"tldr": "STAR-Pose is a spatial-temporal adaptive super-resolution framework for low-resolution video-based human pose estimation, outperforming existing methods in accuracy and speed.", "motivation": "Human pose estimation in low-resolution videos is challenging due to conventional methods requiring high-quality inputs or being computationally expensive.", "method": "STAR-Pose uses a spatial-temporal Transformer with LeakyReLU-modified linear attention for long-range dependencies and an adaptive fusion module with a CNN branch for local texture enhancement. A pose-aware compound loss optimizes for keypoint localization.", "result": "STAR-Pose achieves up to 5.2% mAP improvement in low-resolution (64x48) conditions and is 2.8x to 4.4x faster than cascaded approaches.", "conclusion": "STAR-Pose effectively addresses the challenge of low-resolution video pose estimation with improved accuracy and efficiency."}}
{"id": "2506.15707", "pdf": "https://arxiv.org/pdf/2506.15707", "abs": "https://arxiv.org/abs/2506.15707", "authors": ["Xinglin Wang", "Yiwei Li", "Shaoxiong Feng", "Peiwen Yuan", "Yueqi Zhang", "Jiayi Shi", "Chuyi Tan", "Boyuan Pan", "Yao Hu", "Kan Li"], "title": "Every Rollout Counts: Optimal Resource Allocation for Efficient Test-Time Scaling", "categories": ["cs.LG", "cs.AI"], "comment": "preprint", "summary": "Test-Time Scaling (TTS) improves the performance of Large Language Models\n(LLMs) by using additional inference-time computation to explore multiple\nreasoning paths through search. Yet how to allocate a fixed rollout budget most\neffectively during search remains underexplored, often resulting in inefficient\nuse of compute at test time. To bridge this gap, we formulate test-time search\nas a resource allocation problem and derive the optimal allocation strategy\nthat maximizes the probability of obtaining a correct solution under a fixed\nrollout budget. Within this formulation, we reveal a core limitation of\nexisting search methods: solution-level allocation tends to favor reasoning\ndirections with more candidates, leading to theoretically suboptimal and\ninefficient use of compute. To address this, we propose Direction-Oriented\nResource Allocation (DORA), a provably optimal method that mitigates this bias\nby decoupling direction quality from candidate count and allocating resources\nat the direction level. To demonstrate DORA's effectiveness, we conduct\nextensive experiments on challenging mathematical reasoning benchmarks\nincluding MATH500, AIME2024, and AIME2025. The empirical results show that DORA\nconsistently outperforms strong baselines with comparable computational cost,\nachieving state-of-the-art accuracy. We hope our findings contribute to a\nbroader understanding of optimal TTS for LLMs.", "AI": {"tldr": "DORA optimizes test-time search in LLMs by allocating resources at the direction level, outperforming existing methods.", "motivation": "Existing search methods inefficiently allocate compute due to favoring reasoning directions with more candidates.", "method": "Formulates test-time search as a resource allocation problem and introduces DORA, a direction-level allocation strategy.", "result": "DORA achieves state-of-the-art accuracy on MATH500, AIME2024, and AIME2025 benchmarks.", "conclusion": "DORA provides a provably optimal solution for efficient test-time scaling in LLMs."}}
{"id": "2506.16499", "pdf": "https://arxiv.org/pdf/2506.16499", "abs": "https://arxiv.org/abs/2506.16499", "authors": ["Zexi Liu", "Yuzhu Cai", "Xinyu Zhu", "Yujie Zheng", "Runkun Chen", "Ying Wen", "Yanfeng Wang", "Weinan E", "Siheng Chen"], "title": "ML-Master: Towards AI-for-AI via Integration of Exploration and Reasoning", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "As AI capabilities advance toward and potentially beyond human-level\nperformance, a natural transition emerges where AI-driven development becomes\nmore efficient than human-centric approaches. A promising pathway toward this\ntransition lies in AI-for-AI (AI4AI), which leverages AI techniques to automate\nand optimize the design, training, and deployment of AI systems themselves.\nWhile LLM-based agents have shown the potential to realize AI4AI, they are\noften unable to fully leverage the experience accumulated by agents during the\nexploration of solutions in the reasoning process, leading to inefficiencies\nand suboptimal performance. To address this limitation, we propose ML-Master, a\nnovel AI4AI agent that seamlessly integrates exploration and reasoning by\nemploying a selectively scoped memory mechanism. This approach allows ML-Master\nto efficiently combine diverse insights from parallel solution trajectories\nwith analytical reasoning, guiding further exploration without overwhelming the\nagent with excessive context. We evaluate ML-Master on the MLE-Bench, where it\nachieves a 29.3% average medal rate, significantly surpassing existing methods,\nparticularly in medium-complexity tasks, while accomplishing this superior\nperformance within a strict 12-hour time constraint-half the 24-hour limit used\nby previous baselines. These results demonstrate ML-Master's potential as a\npowerful tool for advancing AI4AI.", "AI": {"tldr": "ML-Master, an AI4AI agent, integrates exploration and reasoning with a memory mechanism, outperforming existing methods by 29.3% in efficiency and speed.", "motivation": "AI-driven development (AI4AI) is more efficient than human-centric approaches, but current LLM-based agents struggle to leverage accumulated experience, leading to inefficiencies.", "method": "ML-Master employs a selectively scoped memory mechanism to combine insights from parallel solution trajectories with analytical reasoning.", "result": "ML-Master achieves a 29.3% average medal rate on MLE-Bench, surpassing baselines, especially in medium-complexity tasks, within half the time.", "conclusion": "ML-Master shows promise as a powerful tool for advancing AI4AI by improving efficiency and performance."}}
{"id": "2506.16343", "pdf": "https://arxiv.org/pdf/2506.16343", "abs": "https://arxiv.org/abs/2506.16343", "authors": ["Cedric M\u00f6ller", "Ricardo Usbeck"], "title": "Analyzing the Influence of Knowledge Graph Information on Relation Extraction", "categories": ["cs.CL", "cs.AI", "cs.IR"], "comment": null, "summary": "We examine the impact of incorporating knowledge graph information on the\nperformance of relation extraction models across a range of datasets. Our\nhypothesis is that the positions of entities within a knowledge graph provide\nimportant insights for relation extraction tasks. We conduct experiments on\nmultiple datasets, each varying in the number of relations, training examples,\nand underlying knowledge graphs. Our results demonstrate that integrating\nknowledge graph information significantly enhances performance, especially when\ndealing with an imbalance in the number of training examples for each relation.\nWe evaluate the contribution of knowledge graph-based features by combining\nestablished relation extraction methods with graph-aware Neural Bellman-Ford\nnetworks. These features are tested in both supervised and zero-shot settings,\ndemonstrating consistent performance improvements across various datasets.", "AI": {"tldr": "Incorporating knowledge graph information improves relation extraction model performance, especially in imbalanced datasets, using graph-aware features.", "motivation": "To test if entity positions in knowledge graphs enhance relation extraction tasks.", "method": "Combined established relation extraction methods with graph-aware Neural Bellman-Ford networks, tested in supervised and zero-shot settings.", "result": "Significant performance improvements, particularly with imbalanced training examples.", "conclusion": "Knowledge graph integration boosts relation extraction effectiveness across diverse datasets."}}
{"id": "2506.11140", "pdf": "https://arxiv.org/pdf/2506.11140", "abs": "https://arxiv.org/abs/2506.11140", "authors": ["Jin Kim", "Muhammad Wahi-Anwa", "Sangyun Park", "Shawn Shin", "John M. Hoffman", "Matthew S. Brown"], "title": "Autonomous Computer Vision Development with Agentic AI", "categories": ["cs.CV", "cs.AI", "cs.MA"], "comment": "The paper is 13 pages long and contains 4 figures", "summary": "Agentic Artificial Intelligence (AI) systems leveraging Large Language Models\n(LLMs) exhibit significant potential for complex reasoning, planning, and tool\nutilization. We demonstrate that a specialized computer vision system can be\nbuilt autonomously from a natural language prompt using Agentic AI methods.\nThis involved extending SimpleMind (SM), an open-source Cognitive AI\nenvironment with configurable tools for medical image analysis, with an\nLLM-based agent, implemented using OpenManus, to automate the planning (tool\nconfiguration) for a particular computer vision task. We provide a\nproof-of-concept demonstration that an agentic system can interpret a computer\nvision task prompt, plan a corresponding SimpleMind workflow by decomposing the\ntask and configuring appropriate tools. From the user input prompt, \"provide sm\n(SimpleMind) config for lungs, heart, and ribs segmentation for cxr (chest\nx-ray)\"), the agent LLM was able to generate the plan (tool configuration file\nin YAML format), and execute SM-Learn (training) and SM-Think (inference)\nscripts autonomously. The computer vision agent automatically configured,\ntrained, and tested itself on 50 chest x-ray images, achieving mean dice scores\nof 0.96, 0.82, 0.83, for lungs, heart, and ribs, respectively. This work shows\nthe potential for autonomous planning and tool configuration that has\ntraditionally been performed by a data scientist in the development of computer\nvision applications.", "AI": {"tldr": "Agentic AI using LLMs autonomously builds a computer vision system from a natural language prompt, achieving high accuracy in medical image segmentation.", "motivation": "To demonstrate the potential of Agentic AI in automating complex tasks like computer vision system configuration, traditionally requiring human expertise.", "method": "Extending SimpleMind with an LLM-based agent to interpret prompts, plan workflows, and configure tools for medical image analysis.", "result": "The system autonomously configured, trained, and tested on 50 chest x-rays, achieving mean dice scores of 0.96 (lungs), 0.82 (heart), and 0.83 (ribs).", "conclusion": "Agentic AI can autonomously perform planning and tool configuration, reducing reliance on data scientists in computer vision development."}}
{"id": "2506.15843", "pdf": "https://arxiv.org/pdf/2506.15843", "abs": "https://arxiv.org/abs/2506.15843", "authors": ["Ninghe Liu", "Yu Xi Huang", "Simon Mahler", "Changhuei Yang"], "title": "Optimized cerebral blood flow measurement in speckle contrast optical spectroscopy via refinement of noise calibration", "categories": ["eess.SP", "eess.IV"], "comment": "5 pages, 3 figures", "summary": "Speckle contrast optical spectroscopy (SCOS) offers a non-invasive and\ncost-effective method for monitoring cerebral blood flow (CBF). However,\nextracting accurate CBF from SCOS necessitates precise noise pre-calibration.\nErrors from this can degrade CBF measurement fidelity, particularly when the\noverall signal level is low. Such errors primarily stem from residual speckle\ncontrast associated with camera and shot noise, whose fluctuations exhibit a\ntemporal structure that mimics cerebral blood volume (CBV) waveforms. We\npropose an optimization-based framework that performs an adaptive refinement of\nnoise calibration, mitigating the CBV-mimicking artifacts by reducing the\nCBF-CBV waveform correlation. Validated on 10 human subjects, our approach\neffectively lowered the signal threshold for reliable CBF signal from 97 to 26\nelectrons per pixel for a 1920x1200 pixels SCOS system. This improvement\nenables more accurate and robust CBF measurements in SCOS, especially at large\nsource-detector (SD) distances for deeper tissue interrogation.", "AI": {"tldr": "An optimization-based framework improves noise calibration in SCOS, reducing CBV-mimicking artifacts and enabling more accurate CBF measurements at lower signal levels.", "motivation": "Accurate CBF measurement in SCOS is hindered by noise calibration errors, which mimic CBV waveforms and degrade fidelity, especially at low signal levels.", "method": "Proposes an adaptive refinement of noise calibration using an optimization-based framework to reduce CBF-CBV waveform correlation.", "result": "Validated on 10 subjects, the method lowered the reliable CBF signal threshold from 97 to 26 electrons per pixel, improving accuracy, especially at large SD distances.", "conclusion": "The framework enhances SCOS performance for deeper tissue interrogation by mitigating noise-related artifacts and improving CBF measurement robustness."}}
{"id": "2506.16073", "pdf": "https://arxiv.org/pdf/2506.16073", "abs": "https://arxiv.org/abs/2506.16073", "authors": ["Byung Hoon Lee", "Wooseok Shin", "Sung Won Han"], "title": "TD3Net: A Temporal Densely Connected Multi-Dilated Convolutional Network for Lipreading", "categories": ["cs.CV", "I.4.8; I.5.4; I.2.10"], "comment": "15 pages, 6 figures", "summary": "The word-level lipreading approach typically employs a two-stage framework\nwith separate frontend and backend architectures to model dynamic lip\nmovements. Each component has been extensively studied, and in the backend\narchitecture, temporal convolutional networks (TCNs) have been widely adopted\nin state-of-the-art methods. Recently, dense skip connections have been\nintroduced in TCNs to mitigate the limited density of the receptive field,\nthereby improving the modeling of complex temporal representations. However,\ntheir performance remains constrained owing to potential information loss\nregarding the continuous nature of lip movements, caused by blind spots in the\nreceptive field. To address this limitation, we propose TD3Net, a temporal\ndensely connected multi-dilated convolutional network that combines dense skip\nconnections and multi-dilated temporal convolutions as the backend\narchitecture. TD3Net covers a wide and dense receptive field without blind\nspots by applying different dilation factors to skip-connected features.\nExperimental results on a word-level lipreading task using two large publicly\navailable datasets, Lip Reading in the Wild (LRW) and LRW-1000, indicate that\nthe proposed method achieves performance comparable to state-of-the-art\nmethods. It achieved higher accuracy with fewer parameters and lower\nfloating-point operations compared to existing TCN-based backend architectures.\nMoreover, visualization results suggest that our approach effectively utilizes\ndiverse temporal features while preserving temporal continuity, presenting\nnotable advantages in lipreading systems. The code is available at our GitHub\nrepository:\nhttps://github.com/Leebh-kor/TD3Net-A-Temporal-Densely-Connected-Multi-dilated-Convolutional-Network-for-Lipreading", "AI": {"tldr": "TD3Net improves lipreading by combining dense skip connections and multi-dilated convolutions, achieving high accuracy with fewer parameters and FLOPs.", "motivation": "Existing TCN-based lipreading methods suffer from blind spots in the receptive field, leading to information loss about continuous lip movements.", "method": "Proposes TD3Net, a backend architecture with dense skip connections and multi-dilated temporal convolutions to eliminate blind spots.", "result": "Achieves comparable performance to state-of-the-art methods on LRW and LRW-1000 datasets with fewer parameters and lower FLOPs.", "conclusion": "TD3Net effectively models temporal continuity and diverse features, offering advantages for lipreading systems."}}
{"id": "2506.15708", "pdf": "https://arxiv.org/pdf/2506.15708", "abs": "https://arxiv.org/abs/2506.15708", "authors": ["Falih Gozi Febrinanto", "Adonia Simango", "Chengpei Xu", "Jingjing Zhou", "Jiangang Ma", "Sonika Tyagi", "Feng Xia"], "title": "Refined Causal Graph Structure Learning via Curvature for Brain Disease Classification", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Graph neural networks (GNNs) have been developed to model the relationship\nbetween regions of interest (ROIs) in brains and have shown significant\nimprovement in detecting brain diseases. However, most of these frameworks do\nnot consider the intrinsic relationship of causality factor between brain ROIs,\nwhich is arguably more essential to observe cause and effect interaction\nbetween signals rather than typical correlation values. We propose a novel\nframework called CGB (Causal Graphs for Brains) for brain disease\nclassification/detection, which models refined brain networks based on the\ncausal discovery method, transfer entropy, and geometric curvature strategy.\nCGB unveils causal relationships between ROIs that bring vital information to\nenhance brain disease classification performance. Furthermore, CGB also\nperforms a graph rewiring through a geometric curvature strategy to refine the\ngenerated causal graph to become more expressive and reduce potential\ninformation bottlenecks when GNNs model it. Our extensive experiments show that\nCGB outperforms state-of-the-art methods in classification tasks on brain\ndisease datasets, as measured by average F1 scores.", "AI": {"tldr": "CGB, a novel GNN framework, improves brain disease classification by modeling causal relationships between brain ROIs using transfer entropy and geometric curvature, outperforming existing methods.", "motivation": "Existing GNNs for brain disease detection often overlook causal relationships between ROIs, which are crucial for understanding signal interactions.", "method": "CGB combines causal discovery (transfer entropy) and geometric curvature to refine brain networks, enhancing GNN performance.", "result": "CGB achieves superior classification performance (higher F1 scores) compared to state-of-the-art methods.", "conclusion": "CGB's focus on causality and graph refinement significantly advances brain disease detection using GNNs."}}
{"id": "2506.16575", "pdf": "https://arxiv.org/pdf/2506.16575", "abs": "https://arxiv.org/abs/2506.16575", "authors": ["Mustafa Akben", "Aaron Satko"], "title": "Advancing Harmful Content Detection in Organizational Research: Integrating Large Language Models with Elo Rating System", "categories": ["cs.AI", "cs.CL"], "comment": "Submitted for HICSS 2025 (Hawaii International Conference on System\n  Sciences); under review", "summary": "Large language models (LLMs) offer promising opportunities for organizational\nresearch. However, their built-in moderation systems can create problems when\nresearchers try to analyze harmful content, often refusing to follow certain\ninstructions or producing overly cautious responses that undermine validity of\nthe results. This is particularly problematic when analyzing organizational\nconflicts such as microaggressions or hate speech. This paper introduces an Elo\nrating-based method that significantly improves LLM performance for harmful\ncontent analysis In two datasets, one focused on microaggression detection and\nthe other on hate speech, we find that our method outperforms traditional LLM\nprompting techniques and conventional machine learning models on key measures\nsuch as accuracy, precision, and F1 scores. Advantages include better\nreliability when analyzing harmful content, fewer false positives, and greater\nscalability for large-scale datasets. This approach supports organizational\napplications, including detecting workplace harassment, assessing toxic\ncommunication, and fostering safer and more inclusive work environments.", "AI": {"tldr": "The paper introduces an Elo rating-based method to improve LLM performance for analyzing harmful content, outperforming traditional techniques in accuracy and reliability.", "motivation": "LLMs' built-in moderation systems hinder analysis of harmful content like microaggressions and hate speech, affecting research validity.", "method": "An Elo rating-based method is proposed to enhance LLM performance for harmful content analysis.", "result": "The method outperforms traditional LLM prompting and ML models in accuracy, precision, and F1 scores on microaggression and hate speech datasets.", "conclusion": "The approach enhances reliability, reduces false positives, and supports applications like workplace harassment detection and fostering inclusive environments."}}
{"id": "2506.16348", "pdf": "https://arxiv.org/pdf/2506.16348", "abs": "https://arxiv.org/abs/2506.16348", "authors": ["Cedric M\u00f6ller", "Ricardo Usbeck"], "title": "DISCIE -- Discriminative Closed Information Extraction", "categories": ["cs.CL"], "comment": null, "summary": "This paper introduces a novel method for closed information extraction. The\nmethod employs a discriminative approach that incorporates type and\nentity-specific information to improve relation extraction accuracy,\nparticularly benefiting long-tail relations. Notably, this method demonstrates\nsuperior performance compared to state-of-the-art end-to-end generative models.\nThis is especially evident for the problem of large-scale closed information\nextraction where we are confronted with millions of entities and hundreds of\nrelations. Furthermore, we emphasize the efficiency aspect by leveraging\nsmaller models. In particular, the integration of type-information proves\ninstrumental in achieving performance levels on par with or surpassing those of\na larger generative model. This advancement holds promise for more accurate and\nefficient information extraction techniques.", "AI": {"tldr": "A discriminative method for closed information extraction improves accuracy, especially for long-tail relations, outperforming generative models and emphasizing efficiency with smaller models.", "motivation": "To enhance relation extraction accuracy, particularly for long-tail relations, and address the challenge of large-scale closed information extraction with millions of entities and hundreds of relations.", "method": "Employs a discriminative approach incorporating type and entity-specific information, leveraging smaller models for efficiency.", "result": "Superior performance compared to state-of-the-art generative models, achieving comparable or better results with smaller models.", "conclusion": "The method promises more accurate and efficient information extraction, especially for large-scale applications."}}
{"id": "2506.15948", "pdf": "https://arxiv.org/pdf/2506.15948", "abs": "https://arxiv.org/abs/2506.15948", "authors": ["Connor Ding", "Abhiram Rao Gorle", "Jiwon Jeong", "Naomi Sagan", "Tsachy Weissman"], "title": "Information-computation trade-offs in non-linear transforms", "categories": ["cs.IT", "eess.IV", "math.IT"], "comment": "Authors listed in alphabetical order of last name", "summary": "In this work, we explore the interplay between information and computation in\nnon-linear transform-based compression for broad classes of modern\ninformation-processing tasks. We first investigate two emerging nonlinear data\ntransformation frameworks for image compression: Implicit Neural\nRepresentations (INRs) and 2D Gaussian Splatting (GS). We analyze their\nrepresentational properties, behavior under lossy compression, and convergence\ndynamics. Our results highlight key trade-offs between INR's compact,\nresolution-flexible neural field representations and GS's highly\nparallelizable, spatially interpretable fitting, providing insights for future\nhybrid and compression-aware frameworks. Next, we introduce the textual\ntransform that enables efficient compression at ultra-low bitrate regimes and\nsimultaneously enhances human perceptual satisfaction. When combined with the\nconcept of denoising via lossy compression, the textual transform becomes a\npowerful tool for denoising tasks. Finally, we present a Lempel-Ziv (LZ78)\n\"transform\", a universal method that, when applied to any member of a broad\ncompressor family, produces new compressors that retain the asymptotic\nuniversality guarantees of the LZ78 algorithm. Collectively, these three\ntransforms illuminate the fundamental trade-offs between coding efficiency and\ncomputational cost. We discuss how these insights extend beyond compression to\ntasks such as classification, denoising, and generative AI, suggesting new\npathways for using non-linear transformations to balance resource constraints\nand performance.", "AI": {"tldr": "The paper explores non-linear transform-based compression, analyzing Implicit Neural Representations (INRs) and 2D Gaussian Splatting (GS), introduces a textual transform for ultra-low bitrate compression, and presents a Lempel-Ziv (LZ78) transform. It highlights trade-offs between coding efficiency and computational cost, extending insights to tasks like classification and generative AI.", "motivation": "To understand the interplay between information and computation in non-linear transform-based compression and its applications in modern information-processing tasks.", "method": "Analyzes INRs and GS for image compression, introduces a textual transform for ultra-low bitrate regimes, and presents a LZ78 transform. Evaluates representational properties, compression behavior, and convergence dynamics.", "result": "Key trade-offs between INR's compact neural fields and GS's parallelizable fitting are identified. The textual transform enhances perceptual satisfaction and aids denoising. The LZ78 transform retains universality guarantees.", "conclusion": "The findings reveal fundamental trade-offs in compression and suggest new pathways for balancing resource constraints and performance in tasks like classification, denoising, and generative AI."}}
{"id": "2506.16082", "pdf": "https://arxiv.org/pdf/2506.16082", "abs": "https://arxiv.org/abs/2506.16082", "authors": ["Yizhe Li", "Sanping Zhou", "Zheng Qin", "Le Wang"], "title": "PR-DETR: Injecting Position and Relation Prior for Dense Video Captioning", "categories": ["cs.CV"], "comment": null, "summary": "Dense video captioning is a challenging task that aims to localize and\ncaption multiple events in an untrimmed video. Recent studies mainly follow the\ntransformer-based architecture to jointly perform the two sub-tasks, i.e.,\nevent localization and caption generation, in an end-to-end manner. Based on\nthe general philosophy of detection transformer, these methods implicitly learn\nthe event locations and event semantics, which requires a large amount of\ntraining data and limits the model's performance in practice. In this paper, we\npropose a novel dense video captioning framework, named PR-DETR, which injects\nthe explicit position and relation prior into the detection transformer to\nimprove the localization accuracy and caption quality, simultaneously. On the\none hand, we first generate a set of position-anchored queries to provide the\nscene-specific position and semantic information about potential events as\nposition prior, which serves as the initial event search regions to eliminate\nthe implausible event proposals. On the other hand, we further design an event\nrelation encoder to explicitly calculate the relationship between event\nboundaries as relation prior to guide the event interaction to improve the\nsemantic coherence of the captions. Extensive ablation studies are conducted to\nverify the effectiveness of the position and relation prior. Experimental\nresults also show the competitive performance of our method on ActivityNet\nCaptions and YouCook2 datasets.", "AI": {"tldr": "PR-DETR improves dense video captioning by injecting explicit position and relation priors into a detection transformer, enhancing localization and caption quality.", "motivation": "Current transformer-based methods for dense video captioning implicitly learn event locations and semantics, requiring large datasets and limiting performance.", "method": "PR-DETR introduces position-anchored queries for scene-specific position prior and an event relation encoder for boundary relationship prior.", "result": "The method shows competitive performance on ActivityNet Captions and YouCook2 datasets.", "conclusion": "Explicit position and relation priors significantly improve dense video captioning accuracy and coherence."}}
{"id": "2506.15709", "pdf": "https://arxiv.org/pdf/2506.15709", "abs": "https://arxiv.org/abs/2506.15709", "authors": ["Pedro C. Vieira", "Miguel E. P. Silva", "Pedro Manuel Pinto Ribeiro"], "title": "Studying and Improving Graph Neural Network-based Motif Estimation", "categories": ["cs.LG", "cs.AI"], "comment": "This manuscript represents a revised version from the paper on\n  https://openreview.net/forum?id=PZVVOeu6xx. Still a work in progress.\n  Comments are welcome! 23 pages (12 main text + references), 9 figures, 5\n  tables", "summary": "Graph Neural Networks (GNNs) are a predominant method for graph\nrepresentation learning. However, beyond subgraph frequency estimation, their\napplication to network motif significance-profile (SP) prediction remains\nunder-explored, with no established benchmarks in the literature. We propose to\naddress this problem, framing SP estimation as a task independent of subgraph\nfrequency estimation. Our approach shifts from frequency counting to direct SP\nestimation and modulates the problem as multitarget regression. The\nreformulation is optimised for interpretability, stability and scalability on\nlarge graphs. We validate our method using a large synthetic dataset and\nfurther test it on real-world graphs. Our experiments reveal that 1-WL limited\nmodels struggle to make precise estimations of SPs. However, they can\ngeneralise to approximate the graph generation processes of networks by\ncomparing their predicted SP with the ones originating from synthetic\ngenerators. This first study on GNN-based motif estimation also hints at how\nusing direct SP estimation can help go past the theoretical limitations that\nmotif estimation faces when performed through subgraph counting.", "AI": {"tldr": "The paper proposes a method for direct motif significance-profile (SP) estimation using GNNs, shifting from traditional subgraph frequency counting to multitarget regression, improving interpretability and scalability.", "motivation": "The application of GNNs to network motif SP prediction is under-explored, lacking benchmarks. The study aims to address this gap by reformulating SP estimation as an independent task.", "method": "The approach reframes SP estimation as multitarget regression, optimizing for interpretability, stability, and scalability on large graphs. It is validated on synthetic and real-world datasets.", "result": "Experiments show 1-WL limited models struggle with precise SP estimation but can generalize to approximate graph generation processes by comparing predicted SPs with synthetic ones.", "conclusion": "Direct SP estimation with GNNs can overcome theoretical limitations of subgraph counting, offering a promising direction for motif estimation."}}
{"id": "2506.16596", "pdf": "https://arxiv.org/pdf/2506.16596", "abs": "https://arxiv.org/abs/2506.16596", "authors": ["Vinay K Chaudhri", "Chaitan Baru", "Brandon Bennett", "Mehul Bhatt", "Darion Cassel", "Anthony G Cohn", "Rina Dechter", "Esra Erdem", "Dave Ferrucci", "Ken Forbus", "Gregory Gelfond", "Michael Genesereth", "Andrew S. Gordon", "Benjamin Grosof", "Gopal Gupta", "Jim Hendler", "Sharat Israni", "Tyler R. Josephson", "Patrick Kyllonen", "Yuliya Lierler", "Vladimir Lifschitz", "Clifton McFate", "Hande K. McGinty", "Leora Morgenstern", "Alessandro Oltramari", "Praveen Paritosh", "Dan Roth", "Blake Shepard", "Cogan Shimzu", "Denny Vrande\u010di\u0107", "Mark Whiting", "Michael Witbrock"], "title": "A Community-driven vision for a new Knowledge Resource for AI", "categories": ["cs.AI"], "comment": "17 pages", "summary": "The long-standing goal of creating a comprehensive, multi-purpose knowledge\nresource, reminiscent of the 1984 Cyc project, still persists in AI. Despite\nthe success of knowledge resources like WordNet, ConceptNet, Wolfram|Alpha and\nother commercial knowledge graphs, verifiable, general-purpose widely available\nsources of knowledge remain a critical deficiency in AI infrastructure. Large\nlanguage models struggle due to knowledge gaps; robotic planning lacks\nnecessary world knowledge; and the detection of factually false information\nrelies heavily on human expertise. What kind of knowledge resource is most\nneeded in AI today? How can modern technology shape its development and\nevaluation? A recent AAAI workshop gathered over 50 researchers to explore\nthese questions. This paper synthesizes our findings and outlines a\ncommunity-driven vision for a new knowledge infrastructure. In addition to\nleveraging contemporary advances in knowledge representation and reasoning, one\npromising idea is to build an open engineering framework to exploit knowledge\nmodules effectively within the context of practical applications. Such a\nframework should include sets of conventions and social structures that are\nadopted by contributors.", "AI": {"tldr": "The paper discusses the need for a comprehensive, multi-purpose knowledge resource in AI, addressing gaps in current systems like large language models and robotic planning. It proposes a community-driven vision for a new knowledge infrastructure, leveraging modern technology and open engineering frameworks.", "motivation": "The motivation is to address the critical deficiency in AI infrastructure caused by the lack of verifiable, general-purpose knowledge resources, which impacts areas like language models, robotic planning, and misinformation detection.", "method": "The paper synthesizes findings from a AAAI workshop with over 50 researchers, proposing a community-driven approach to develop a new knowledge infrastructure. It suggests leveraging modern knowledge representation and reasoning techniques, along with an open engineering framework for practical applications.", "result": "The result is a proposed vision for a new knowledge infrastructure, including conventions and social structures for contributors, to address current AI knowledge gaps.", "conclusion": "The conclusion emphasizes the importance of a collaborative, open framework to build a comprehensive knowledge resource, addressing AI's current limitations and enabling future advancements."}}
{"id": "2506.16370", "pdf": "https://arxiv.org/pdf/2506.16370", "abs": "https://arxiv.org/abs/2506.16370", "authors": ["Iwan Williams"], "title": "Can structural correspondences ground real world representational content in Large Language Models?", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Large Language Models (LLMs) such as GPT-4 produce compelling responses to a\nwide range of prompts. But their representational capacities are uncertain.\nMany LLMs have no direct contact with extra-linguistic reality: their inputs,\noutputs and training data consist solely of text, raising the questions (1) can\nLLMs represent anything and (2) if so, what? In this paper, I explore what it\nwould take to answer these questions according to a structural-correspondence\nbased account of representation, and make an initial survey of this evidence. I\nargue that the mere existence of structural correspondences between LLMs and\nworldly entities is insufficient to ground representation of those entities.\nHowever, if these structural correspondences play an appropriate role - they\nare exploited in a way that explains successful task performance - then they\ncould ground real world contents. This requires overcoming a challenge: the\ntext-boundedness of LLMs appears, on the face of it, to prevent them engaging\nin the right sorts of tasks.", "AI": {"tldr": "The paper examines whether LLMs like GPT-4 can represent real-world entities, concluding that structural correspondences alone are insufficient unless they explain task success.", "motivation": "To address uncertainties about LLMs' representational capacities, especially given their text-only inputs and outputs.", "method": "Uses a structural-correspondence based account to evaluate LLMs' representation of worldly entities.", "result": "Structural correspondences alone don't ground representation; they must explain task performance to do so.", "conclusion": "LLMs could represent real-world contents if structural correspondences are exploited for task success, despite text-boundedness challenges."}}
{"id": "2506.16265", "pdf": "https://arxiv.org/pdf/2506.16265", "abs": "https://arxiv.org/abs/2506.16265", "authors": ["Zhaoyi Wang", "Jemil Avers Butt", "Shengyu Huang", "Tomislav Medic", "Andreas Wieser"], "title": "Dense 3D Displacement Estimation for Landslide Monitoring via Fusion of TLS Point Clouds and Embedded RGB Images", "categories": ["cs.CV", "cs.RO", "eess.IV", "physics.geo-ph"], "comment": "20 pages, 16 figures. Preprint under peer review. Example data and\n  code available at [GitHub](https://github.com/zhaoyiww/fusion4landslide)", "summary": "Landslide monitoring is essential for understanding geohazards and mitigating\nassociated risks. However, existing point cloud-based methods typically rely on\neither geometric or radiometric information and often yield sparse or non-3D\ndisplacement estimates. In this paper, we propose a hierarchical\npartition-based coarse-to-fine approach that fuses 3D point clouds and\nco-registered RGB images to estimate dense 3D displacement vector fields. We\nconstruct patch-level matches using both 3D geometry and 2D image features.\nThese matches are refined via geometric consistency checks, followed by rigid\ntransformation estimation per match. Experimental results on two real-world\nlandslide datasets demonstrate that our method produces 3D displacement\nestimates with high spatial coverage (79% and 97%) and high accuracy.\nDeviations in displacement magnitude with respect to external measurements\n(total station or GNSS observations) are 0.15 m and 0.25 m on the two datasets,\nrespectively, and only 0.07 m and 0.20 m compared to manually derived\nreferences. These values are below the average scan resolutions (0.08 m and\n0.30 m). Our method outperforms the state-of-the-art method F2S3 in spatial\ncoverage while maintaining comparable accuracy. Our approach offers a practical\nand adaptable solution for TLS-based landslide monitoring and is extensible to\nother types of point clouds and monitoring tasks. Our example data and source\ncode are publicly available at https://github.com/zhaoyiww/fusion4landslide.", "AI": {"tldr": "A hierarchical coarse-to-fine approach fuses 3D point clouds and RGB images for dense 3D landslide displacement estimation, outperforming existing methods in coverage and accuracy.", "motivation": "Existing methods for landslide monitoring rely on sparse or non-3D displacement estimates, lacking comprehensive spatial coverage.", "method": "A hierarchical partition-based approach combines 3D geometry and 2D image features, refining matches via geometric consistency and rigid transformations.", "result": "Achieves high spatial coverage (79% and 97%) and accuracy (deviations of 0.07m-0.25m), outperforming F2S3 in coverage.", "conclusion": "The method provides a practical, adaptable solution for TLS-based landslide monitoring, extensible to other point clouds and tasks."}}
{"id": "2506.16112", "pdf": "https://arxiv.org/pdf/2506.16112", "abs": "https://arxiv.org/abs/2506.16112", "authors": ["Yuan Zhang", "Chun-Kai Fan", "Tao Huang", "Ming Lu", "Sicheng Yu", "Junwen Pan", "Kuan Cheng", "Qi She", "Shanghang Zhang"], "title": "AutoV: Learning to Retrieve Visual Prompt for Large Vision-Language Models", "categories": ["cs.CV"], "comment": "19 pages", "summary": "Inspired by text prompts in large language models (LLMs), visual prompts have\nbeen explored to enhance the reasoning capabilities of large vision-language\nmodels (LVLMs). Current methods design heuristic visual prompts, such as\noverlaying a text-query-guided attention heatmap on the original input image.\nHowever, designing effective prompts manually is challenging and\ntime-consuming, and it often fails to explore the benefits of different visual\nprompts, leading to sub-optimal performance. To this end, we propose\n\\textbf{AutoV} that learns to automatically select the optimal visual prompt\nfrom various candidates based on given textual queries and the input image. To\ntrain AutoV, we developed an automatic data collection and labeling pipeline\nthat evaluates various visual prompts with a pre-trained LVLM. We input a set\nof visual prompts into the LVLM and rank them according to the prediction\nlosses generated by the model. Using the ranking as a supervision signal, we\ntrain AutoV to automatically choose the optimal visual prompt from various\nvisual prompts for LVLMs. Experimental results indicate that AutoV enhances the\nperformance of various LVLMs across multiple popular image understanding tasks.\nFor instance, LLaVA-OV with AutoV achieves $\\textbf{1.7}\\%$ accuracy gain on\nLLaVA$^{\\text{Wild}}$, and AutoV boosts Qwen2.5-VL by $\\textbf{1.9}\\%$ on MMMU,\nhighlighting its potential as an optimal visual prompting method for LVLMs.", "AI": {"tldr": "AutoV automates visual prompt selection for LVLMs, improving performance across tasks.", "motivation": "Manual visual prompt design is challenging and sub-optimal; automation is needed.", "method": "AutoV learns to select optimal visual prompts using a ranking-based training pipeline.", "result": "AutoV boosts LVLM performance (e.g., 1.7% gain for LLaVA-OV, 1.9% for Qwen2.5-VL).", "conclusion": "AutoV is an effective automated visual prompting method for LVLMs."}}
{"id": "2506.15710", "pdf": "https://arxiv.org/pdf/2506.15710", "abs": "https://arxiv.org/abs/2506.15710", "authors": ["Siru Ouyang", "Xinyu Zhu", "Zilin Xiao", "Minhao Jiang", "Yu Meng", "Jiawei Han"], "title": "RAST: Reasoning Activation in LLMs via Small-model Transfer", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Reinforcement learning (RL) has become a powerful approach for improving the\nreasoning capabilities of large language models (LLMs), as evidenced by recent\nsuccesses such as OpenAI's o1 and Deepseek-R1. However, applying RL at scale\nremains intimidatingly resource-intensive, requiring multiple model copies and\nextensive GPU workloads. On the other hand, while being powerful, recent\nstudies suggest that RL does not fundamentally endow models with new knowledge;\nrather, it primarily reshapes the model's output distribution to activate\nreasoning capabilities latent in the base model. Building on this insight, we\nhypothesize that the changes in output probabilities induced by RL are largely\nmodel-size invariant, opening the door to a more efficient paradigm: training a\nsmall model with RL and transferring its induced probability shifts to larger\nbase models. To verify our hypothesis, we conduct a token-level analysis of\ndecoding trajectories and find high alignment in RL-induced output\ndistributions across model scales, validating our hypothesis. Motivated by\nthis, we propose RAST, a simple yet effective method that transfers reasoning\nbehaviors by injecting RL-induced probability adjustments from a small\nRL-trained model into larger models. Experiments across multiple mathematical\nreasoning benchmarks show that RAST substantially and consistently enhances the\nreasoning capabilities of base models while requiring significantly lower GPU\nmemory than direct RL training, sometimes even yielding better performance than\nthe RL-trained counterparts. Our findings offer new insights into the nature of\nRL-driven reasoning and practical strategies for scaling its benefits without\nincurring its full computational cost. The project page of RAST is available at\nhttps://ozyyshr.github.io/RAST/.", "AI": {"tldr": "The paper introduces RAST, a method to transfer RL-induced probability adjustments from small to large models, enhancing reasoning capabilities efficiently.", "motivation": "Applying RL to large language models is resource-intensive, and RL doesn't add new knowledge but reshapes output distributions. The hypothesis is that these shifts are model-size invariant.", "method": "Proposes RAST, which transfers RL-induced probability adjustments from a small RL-trained model to larger models.", "result": "RAST improves reasoning in base models with lower GPU memory usage, sometimes outperforming direct RL training.", "conclusion": "RAST offers a scalable, efficient way to leverage RL benefits without high computational costs, providing insights into RL-driven reasoning."}}
{"id": "2506.16617", "pdf": "https://arxiv.org/pdf/2506.16617", "abs": "https://arxiv.org/abs/2506.16617", "authors": ["Soobin Chae", "Suhwan Lee", "Hanna Hauptmann", "Hajo A. Reijers", "Xixi Lu"], "title": "The Role of Explanation Styles and Perceived Accuracy on Decision Making in Predictive Process Monitoring", "categories": ["cs.AI", "cs.HC"], "comment": "Accepted at CAiSE'25", "summary": "Predictive Process Monitoring (PPM) often uses deep learning models to\npredict the future behavior of ongoing processes, such as predicting process\noutcomes. While these models achieve high accuracy, their lack of\ninterpretability undermines user trust and adoption. Explainable AI (XAI) aims\nto address this challenge by providing the reasoning behind the predictions.\nHowever, current evaluations of XAI in PPM focus primarily on functional\nmetrics (such as fidelity), overlooking user-centered aspects such as their\neffect on task performance and decision-making. This study investigates the\neffects of explanation styles (feature importance, rule-based, and\ncounterfactual) and perceived AI accuracy (low or high) on decision-making in\nPPM. We conducted a decision-making experiment, where users were presented with\nthe AI predictions, perceived accuracy levels, and explanations of different\nstyles. Users' decisions were measured both before and after receiving\nexplanations, allowing the assessment of objective metrics (Task Performance\nand Agreement) and subjective metrics (Decision Confidence). Our findings show\nthat perceived accuracy and explanation style have a significant effect.", "AI": {"tldr": "The study explores how explanation styles and perceived AI accuracy affect decision-making in Predictive Process Monitoring (PPM), finding both factors significantly influence user decisions.", "motivation": "Deep learning models in PPM lack interpretability, reducing user trust. Explainable AI (XAI) addresses this, but current evaluations overlook user-centered impacts.", "method": "A decision-making experiment tested users with AI predictions, perceived accuracy levels, and different explanation styles (feature importance, rule-based, counterfactual).", "result": "Perceived accuracy and explanation style significantly impact decision-making, affecting task performance, agreement, and decision confidence.", "conclusion": "The study highlights the importance of user-centered XAI evaluations in PPM, showing that explanation styles and perceived accuracy shape decision-making outcomes."}}
{"id": "2506.16383", "pdf": "https://arxiv.org/pdf/2506.16383", "abs": "https://arxiv.org/abs/2506.16383", "authors": ["Hao Li", "Viktor Schlegel", "Yizheng Sun", "Riza Batista-Navarro", "Goran Nenadic"], "title": "Large Language Models in Argument Mining: A Survey", "categories": ["cs.CL"], "comment": "Work draft", "summary": "Argument Mining (AM), a critical subfield of Natural Language Processing\n(NLP), focuses on extracting argumentative structures from text. The advent of\nLarge Language Models (LLMs) has profoundly transformed AM, enabling advanced\nin-context learning, prompt-based generation, and robust cross-domain\nadaptability. This survey systematically synthesizes recent advancements in\nLLM-driven AM. We provide a concise review of foundational theories and\nannotation frameworks, alongside a meticulously curated catalog of datasets. A\nkey contribution is our comprehensive taxonomy of AM subtasks, elucidating how\ncontemporary LLM techniques -- such as prompting, chain-of-thought reasoning,\nand retrieval augmentation -- have reconfigured their execution. We further\ndetail current LLM architectures and methodologies, critically assess\nevaluation practices, and delineate pivotal challenges including long-context\nreasoning, interpretability, and annotation bottlenecks. Conclusively, we\nhighlight emerging trends and propose a forward-looking research agenda for\nLLM-based computational argumentation, aiming to strategically guide\nresearchers in this rapidly evolving domain.", "AI": {"tldr": "A survey on how Large Language Models (LLMs) are transforming Argument Mining (AM) in NLP, covering theories, datasets, methodologies, challenges, and future directions.", "motivation": "To synthesize recent advancements in LLM-driven AM and provide a roadmap for researchers in this evolving field.", "method": "Systematic review of foundational theories, datasets, and LLM techniques (e.g., prompting, chain-of-thought reasoning).", "result": "Comprehensive taxonomy of AM subtasks, evaluation practices, and identified challenges like long-context reasoning and interpretability.", "conclusion": "Proposes a research agenda for LLM-based computational argumentation to guide future work."}}
{"id": "2506.16307", "pdf": "https://arxiv.org/pdf/2506.16307", "abs": "https://arxiv.org/abs/2506.16307", "authors": ["Xu Zhao", "Chen Zhao", "Xiantao Hu", "Hongliang Zhang", "Ying Tai", "Jian Yang"], "title": "Learning Multi-scale Spatial-frequency Features for Image Denoising", "categories": ["cs.CV", "cs.AI", "eess.IV"], "comment": null, "summary": "Recent advancements in multi-scale architectures have demonstrated\nexceptional performance in image denoising tasks. However, existing\narchitectures mainly depends on a fixed single-input single-output Unet\narchitecture, ignoring the multi-scale representations of pixel level. In\naddition, previous methods treat the frequency domain uniformly, ignoring the\ndifferent characteristics of high-frequency and low-frequency noise. In this\npaper, we propose a novel multi-scale adaptive dual-domain network (MADNet) for\nimage denoising. We use image pyramid inputs to restore noise-free results from\nlow-resolution images. In order to realize the interaction of high-frequency\nand low-frequency information, we design an adaptive spatial-frequency learning\nunit (ASFU), where a learnable mask is used to separate the information into\nhigh-frequency and low-frequency components. In the skip connections, we design\na global feature fusion block to enhance the features at different scales.\nExtensive experiments on both synthetic and real noisy image datasets verify\nthe effectiveness of MADNet compared with current state-of-the-art denoising\napproaches.", "AI": {"tldr": "A novel multi-scale adaptive dual-domain network (MADNet) is proposed for image denoising, addressing limitations of fixed single-input single-output Unet architectures and uniform frequency domain treatment.", "motivation": "Existing architectures lack multi-scale pixel-level representations and uniform frequency domain treatment, ignoring high/low-frequency noise differences.", "method": "MADNet uses image pyramid inputs and an adaptive spatial-frequency learning unit (ASFU) with a learnable mask for frequency separation, along with a global feature fusion block in skip connections.", "result": "Extensive experiments show MADNet outperforms state-of-the-art denoising methods on synthetic and real noisy datasets.", "conclusion": "MADNet effectively addresses multi-scale and frequency domain challenges in image denoising, demonstrating superior performance."}}
{"id": "2506.16119", "pdf": "https://arxiv.org/pdf/2506.16119", "abs": "https://arxiv.org/abs/2506.16119", "authors": ["Chengyu Bai", "Yuming Li", "Zhongyu Zhao", "Jintao Chen", "Peidong Jia", "Qi She", "Ming Lu", "Shanghang Zhang"], "title": "FastInit: Fast Noise Initialization for Temporally Consistent Video Generation", "categories": ["cs.CV"], "comment": null, "summary": "Video generation has made significant strides with the development of\ndiffusion models; however, achieving high temporal consistency remains a\nchallenging task. Recently, FreeInit identified a training-inference gap and\nintroduced a method to iteratively refine the initial noise during inference.\nHowever, iterative refinement significantly increases the computational cost\nassociated with video generation. In this paper, we introduce FastInit, a fast\nnoise initialization method that eliminates the need for iterative refinement.\nFastInit learns a Video Noise Prediction Network (VNPNet) that takes random\nnoise and a text prompt as input, generating refined noise in a single forward\npass. Therefore, FastInit greatly enhances the efficiency of video generation\nwhile achieving high temporal consistency across frames. To train the VNPNet,\nwe create a large-scale dataset consisting of pairs of text prompts, random\nnoise, and refined noise. Extensive experiments with various text-to-video\nmodels show that our method consistently improves the quality and temporal\nconsistency of the generated videos. FastInit not only provides a substantial\nimprovement in video generation but also offers a practical solution that can\nbe applied directly during inference. The code and dataset will be released.", "AI": {"tldr": "FastInit introduces a fast noise initialization method for video generation, eliminating iterative refinement and improving efficiency and temporal consistency.", "motivation": "Addressing the computational cost and temporal inconsistency in video generation caused by iterative refinement methods like FreeInit.", "method": "FastInit uses a Video Noise Prediction Network (VNPNet) to generate refined noise in a single forward pass, trained on a large-scale dataset of text prompts, random noise, and refined noise pairs.", "result": "FastInit enhances video generation efficiency and quality, achieving high temporal consistency across frames in various text-to-video models.", "conclusion": "FastInit offers a practical, efficient solution for video generation, with plans to release the code and dataset."}}
{"id": "2506.15711", "pdf": "https://arxiv.org/pdf/2506.15711", "abs": "https://arxiv.org/abs/2506.15711", "authors": ["Le Jiang", "Liyan Ma", "Guang Yang"], "title": "Shadow defense against gradient inversion attack in federated learning", "categories": ["cs.LG", "cs.AI", "cs.CR", "cs.CV"], "comment": null, "summary": "Federated learning (FL) has emerged as a transformative framework for\nprivacy-preserving distributed training, allowing clients to collaboratively\ntrain a global model without sharing their local data. This is especially\ncrucial in sensitive fields like healthcare, where protecting patient data is\nparamount. However, privacy leakage remains a critical challenge, as the\ncommunication of model updates can be exploited by potential adversaries.\nGradient inversion attacks (GIAs), for instance, allow adversaries to\napproximate the gradients used for training and reconstruct training images,\nthus stealing patient privacy. Existing defense mechanisms obscure gradients,\nyet lack a nuanced understanding of which gradients or types of image\ninformation are most vulnerable to such attacks. These indiscriminate\ncalibrated perturbations result in either excessive privacy protection\ndegrading model accuracy, or insufficient one failing to safeguard sensitive\ninformation. Therefore, we introduce a framework that addresses these\nchallenges by leveraging a shadow model with interpretability for identifying\nsensitive areas. This enables a more targeted and sample-specific noise\ninjection. Specially, our defensive strategy achieves discrepancies of 3.73 in\nPSNR and 0.2 in SSIM compared to the circumstance without defense on the\nChestXRay dataset, and 2.78 in PSNR and 0.166 in the EyePACS dataset. Moreover,\nit minimizes adverse effects on model performance, with less than 1\\% F1\nreduction compared to SOTA methods. Our extensive experiments, conducted across\ndiverse types of medical images, validate the generalization of the proposed\nframework. The stable defense improvements for FedAvg are consistently over\n1.5\\% times in LPIPS and SSIM. It also offers a universal defense against\nvarious GIA types, especially for these sensitive areas in images.", "AI": {"tldr": "A framework for targeted noise injection in federated learning to defend against gradient inversion attacks, balancing privacy and model accuracy.", "motivation": "Privacy leakage in federated learning, especially in healthcare, due to gradient inversion attacks, necessitates a nuanced defense mechanism.", "method": "Uses a shadow model with interpretability to identify sensitive areas for sample-specific noise injection.", "result": "Achieves significant privacy protection (3.73 PSNR, 0.2 SSIM on ChestXRay; 2.78 PSNR, 0.166 SSIM on EyePACS) with minimal model performance impact (<1% F1 reduction).", "conclusion": "The framework effectively defends against gradient inversion attacks while preserving model accuracy, validated across diverse medical datasets."}}
{"id": "2506.16696", "pdf": "https://arxiv.org/pdf/2506.16696", "abs": "https://arxiv.org/abs/2506.16696", "authors": ["Kenjiro Ide", "Taiga Someya", "Kohei Kawaguchi", "Keisuke Fujii"], "title": "Interpretable Low-Dimensional Modeling of Spatiotemporal Agent States for Decision Making in Football Tactics", "categories": ["cs.AI"], "comment": "5 pages, 3 figures, presented in iCSports 2024 Abstract Track", "summary": "Understanding football tactics is crucial for managers and analysts. Previous\nresearch has proposed models based on spatial and kinematic equations, but\nthese are computationally expensive. Also, Reinforcement learning approaches\nuse player positions and velocities but lack interpretability and require large\ndatasets. Rule-based models align with expert knowledge but have not fully\nconsidered all players' states. This study explores whether low-dimensional,\nrule-based models using spatiotemporal data can effectively capture football\ntactics. Our approach defines interpretable state variables for both the\nball-holder and potential pass receivers, based on criteria that explore\noptions like passing. Through discussions with a manager, we identified key\nvariables representing the game state. We then used StatsBomb event data and\nSkillCorner tracking data from the 2023$/$24 LaLiga season to train an XGBoost\nmodel to predict pass success. The analysis revealed that the distance between\nthe player and the ball, as well as the player's space score, were key factors\nin determining successful passes. Our interpretable low-dimensional modeling\nfacilitates tactical analysis through the use of intuitive variables and\nprovides practical value as a tool to support decision-making in football.", "AI": {"tldr": "The paper explores low-dimensional, rule-based models for football tactics, using interpretable state variables to predict pass success, validated with real-world data.", "motivation": "Existing models for football tactics are either computationally expensive, lack interpretability, or ignore some player states. This study aims to address these gaps.", "method": "The study uses spatiotemporal data to define interpretable state variables for players and trains an XGBoost model with StatsBomb and SkillCorner data to predict pass success.", "result": "Key factors like distance to the ball and space score were identified as significant for pass success. The model is interpretable and practical for tactical analysis.", "conclusion": "The proposed low-dimensional, rule-based model effectively captures football tactics, offering interpretability and practical decision-making support."}}
{"id": "2506.16388", "pdf": "https://arxiv.org/pdf/2506.16388", "abs": "https://arxiv.org/abs/2506.16388", "authors": ["Sani Abdullahi Sani", "Salim Abubakar", "Falalu Ibrahim Lawan", "Abdulhamid Abubakar", "Maryam Bala"], "title": "HausaNLP at SemEval-2025 Task 11: Advancing Hausa Text-based Emotion Detection", "categories": ["cs.CL"], "comment": null, "summary": "This paper presents our approach to multi-label emotion detection in Hausa, a\nlow-resource African language, as part of SemEval Track A. We fine-tuned\nAfriBERTa, a transformer-based model pre-trained on African languages, to\nclassify Hausa text into six emotions: anger, disgust, fear, joy, sadness, and\nsurprise. Our methodology involved data preprocessing, tokenization, and model\nfine-tuning using the Hugging Face Trainer API. The system achieved a\nvalidation accuracy of 74.00%, with an F1-score of 73.50%, demonstrating the\neffectiveness of transformer-based models for emotion detection in low-resource\nlanguages.", "AI": {"tldr": "Fine-tuning AfriBERTa for multi-label emotion detection in Hausa achieved 74% accuracy and 73.5% F1-score.", "motivation": "Addressing emotion detection in Hausa, a low-resource African language, using transformer models.", "method": "Fine-tuned AfriBERTa with data preprocessing, tokenization, and Hugging Face Trainer API.", "result": "74.00% validation accuracy and 73.50% F1-score.", "conclusion": "Transformer models are effective for emotion detection in low-resource languages like Hausa."}}
{"id": "2506.16418", "pdf": "https://arxiv.org/pdf/2506.16418", "abs": "https://arxiv.org/abs/2506.16418", "authors": ["Berk Yilmaz", "Daniel Fidel Harvey", "Prajit Dhuri"], "title": "Efficient Transformations in Deep Learning Convolutional Neural Networks", "categories": ["cs.CV", "cs.AI", "eess.IV", "eess.SP", "68T07, 68T10, 94A08, 42C10"], "comment": "All authors contributed equally to this work. 17 pages, 36\n  references, 10 figures, 1 appendix", "summary": "This study investigates the integration of signal processing transformations\n-- Fast Fourier Transform (FFT), Walsh-Hadamard Transform (WHT), and Discrete\nCosine Transform (DCT) -- within the ResNet50 convolutional neural network\n(CNN) model for image classification. The primary objective is to assess the\ntrade-offs between computational efficiency, energy consumption, and\nclassification accuracy during training and inference. Using the CIFAR-100\ndataset (100 classes, 60,000 images), experiments demonstrated that\nincorporating WHT significantly reduced energy consumption while improving\naccuracy. Specifically, a baseline ResNet50 model achieved a testing accuracy\nof 66%, consuming an average of 25,606 kJ per model. In contrast, a modified\nResNet50 incorporating WHT in the early convolutional layers achieved 74%\naccuracy, and an enhanced version with WHT applied to both early and late\nlayers achieved 79% accuracy, with an average energy consumption of only 39 kJ\nper model. These results demonstrate the potential of WHT as a highly efficient\nand effective approach for energy-constrained CNN applications.", "AI": {"tldr": "Integration of WHT in ResNet50 improves accuracy (79%) and reduces energy consumption (39 kJ) compared to baseline (66%, 25,606 kJ).", "motivation": "To assess trade-offs between computational efficiency, energy consumption, and classification accuracy in CNNs using signal processing transforms.", "method": "Modified ResNet50 with WHT applied to early and/or late layers, tested on CIFAR-100 dataset.", "result": "WHT integration boosted accuracy (74-79%) and drastically cut energy use (39 kJ vs. 25,606 kJ).", "conclusion": "WHT is efficient and effective for energy-constrained CNNs."}}
{"id": "2506.16129", "pdf": "https://arxiv.org/pdf/2506.16129", "abs": "https://arxiv.org/abs/2506.16129", "authors": ["Stefano Colamonaco", "David Debot", "Giuseppe Marra"], "title": "Neurosymbolic Object-Centric Learning with Distant Supervision", "categories": ["cs.CV"], "comment": null, "summary": "Relational learning enables models to generalize across structured domains by\nreasoning over objects and their interactions. While recent advances in\nneurosymbolic reasoning and object-centric learning bring us closer to this\ngoal, existing systems rely either on object-level supervision or on a\npredefined decomposition of the input into objects. In this work, we propose a\nneurosymbolic formulation for learning object-centric representations directly\nfrom raw unstructured perceptual data and using only distant supervision. We\ninstantiate this approach in DeepObjectLog, a neurosymbolic model that\nintegrates a perceptual module, which extracts relevant object representations,\nwith a symbolic reasoning layer based on probabilistic logic programming. By\nenabling sound probabilistic logical inference, the symbolic component\nintroduces a novel learning signal that further guides the discovery of\nmeaningful objects in the input. We evaluate our model across a diverse range\nof generalization settings, including unseen object compositions, unseen tasks,\nand unseen number of objects. Experimental results show that our method\noutperforms neural and neurosymbolic baselines across the tested settings.", "AI": {"tldr": "DeepObjectLog learns object-centric representations from raw data using distant supervision, combining perceptual and symbolic reasoning for better generalization.", "motivation": "Existing systems require object-level supervision or predefined decompositions, limiting flexibility. The goal is to learn object-centric representations directly from unstructured data.", "method": "DeepObjectLog integrates a perceptual module for object extraction with a symbolic reasoning layer using probabilistic logic programming.", "result": "Outperforms neural and neurosymbolic baselines in generalization tasks like unseen compositions, tasks, and object counts.", "conclusion": "The neurosymbolic approach effectively learns object-centric representations and generalizes well without explicit supervision."}}
{"id": "2506.15712", "pdf": "https://arxiv.org/pdf/2506.15712", "abs": "https://arxiv.org/abs/2506.15712", "authors": ["Songqi Zhou", "Ruixue Liu", "Yixing Wang", "Jia Lu", "Benben Jiang"], "title": "BatteryBERT for Realistic Battery Fault Detection Using Point-Masked Signal Modeling", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Accurate fault detection in lithium-ion batteries is essential for the safe\nand reliable operation of electric vehicles and energy storage systems.\nHowever, existing methods often struggle to capture complex temporal\ndependencies and cannot fully leverage abundant unlabeled data. Although large\nlanguage models (LLMs) exhibit strong representation capabilities, their\narchitectures are not directly suited to the numerical time-series data common\nin industrial settings. To address these challenges, we propose a novel\nframework that adapts BERT-style pretraining for battery fault detection by\nextending the standard BERT architecture with a customized time-series-to-token\nrepresentation module and a point-level Masked Signal Modeling (point-MSM)\npretraining task tailored to battery applications. This approach enables\nself-supervised learning on sequential current, voltage, and other\ncharge-discharge cycle data, yielding distributionally robust, context-aware\ntemporal embeddings. We then concatenate these embeddings with battery metadata\nand feed them into a downstream classifier for accurate fault classification.\nExperimental results on a large-scale real-world dataset show that models\ninitialized with our pretrained parameters significantly improve both\nrepresentation quality and classification accuracy, achieving an AUROC of 0.945\nand substantially outperforming existing approaches. These findings validate\nthe effectiveness of BERT-style pretraining for time-series fault detection.", "AI": {"tldr": "A novel BERT-style pretraining framework for battery fault detection improves accuracy by leveraging time-series data and self-supervised learning.", "motivation": "Existing methods fail to capture complex temporal dependencies and underutilize unlabeled data in battery fault detection.", "method": "Extends BERT architecture with a time-series-to-token module and point-MSM pretraining task for self-supervised learning on battery data.", "result": "Achieves AUROC of 0.945, outperforming existing methods in fault classification.", "conclusion": "BERT-style pretraining is effective for time-series fault detection in batteries."}}
{"id": "2506.16731", "pdf": "https://arxiv.org/pdf/2506.16731", "abs": "https://arxiv.org/abs/2506.16731", "authors": ["Jinlong Pang", "Jiaheng Wei", "Yifan Hua", "Chen Qian", "Yang Liu"], "title": "Incentivizing High-quality Participation From Federated Learning Agents", "categories": ["cs.AI", "cs.DC", "cs.LG"], "comment": null, "summary": "Federated learning (FL) provides a promising paradigm for facilitating\ncollaboration between multiple clients that jointly learn a global model\nwithout directly sharing their local data. However, existing research suffers\nfrom two caveats: 1) From the perspective of agents, voluntary and unselfish\nparticipation is often assumed. But self-interested agents may opt out of the\nsystem or provide low-quality contributions without proper incentives; 2) From\nthe mechanism designer's perspective, the aggregated models can be\nunsatisfactory as the existing game-theoretical federated learning approach for\ndata collection ignores the potential heterogeneous effort caused by\ncontributed data. To alleviate above challenges, we propose an incentive-aware\nframework for agent participation that considers data heterogeneity to\naccelerate the convergence process. Specifically, we first introduce the notion\nof Wasserstein distance to explicitly illustrate the heterogeneous effort and\nreformulate the existing upper bound of convergence. To induce truthful\nreporting from agents, we analyze and measure the generalization error gap of\nany two agents by leveraging the peer prediction mechanism to develop score\nfunctions. We further present a two-stage Stackelberg game model that\nformalizes the process and examines the existence of equilibrium. Extensive\nexperiments on real-world datasets demonstrate the effectiveness of our\nproposed mechanism.", "AI": {"tldr": "The paper proposes an incentive-aware framework for federated learning (FL) to address challenges of voluntary participation and data heterogeneity, using Wasserstein distance and a two-stage Stackelberg game model.", "motivation": "Existing FL research assumes voluntary participation and ignores data heterogeneity, leading to potential opt-outs or low-quality contributions. The paper aims to incentivize truthful participation and improve model quality.", "method": "The framework uses Wasserstein distance to measure data heterogeneity and reformulates convergence bounds. It employs peer prediction for truthful reporting and a Stackelberg game to model interactions and ensure equilibrium.", "result": "Experiments on real-world datasets show the framework's effectiveness in accelerating convergence and improving model quality.", "conclusion": "The proposed incentive-aware framework successfully addresses participation and data heterogeneity challenges in FL, enhancing collaboration and model performance."}}
{"id": "2506.16389", "pdf": "https://arxiv.org/pdf/2506.16389", "abs": "https://arxiv.org/abs/2506.16389", "authors": ["Chenyi Zhou", "Zhengyan Shi", "Yuan Yao", "Lei Liang", "Huajun Chen", "Qiang Zhang"], "title": "RiOT: Efficient Prompt Refinement with Residual Optimization Tree", "categories": ["cs.CL"], "comment": null, "summary": "Recent advancements in large language models (LLMs) have highlighted their\npotential across a variety of tasks, but their performance still heavily relies\non the design of effective prompts. Existing methods for automatic prompt\noptimization face two challenges: lack of diversity, limiting the exploration\nof valuable and innovative directions and semantic drift, where optimizations\nfor one task can degrade performance in others. To address these issues, we\npropose Residual Optimization Tree (RiOT), a novel framework for automatic\nprompt optimization. RiOT iteratively refines prompts through text gradients,\ngenerating multiple semantically diverse candidates at each step, and selects\nthe best prompt using perplexity. Additionally, RiOT incorporates the text\nresidual connection to mitigate semantic drift by selectively retaining\nbeneficial content across optimization iterations. A tree structure efficiently\nmanages the optimization process, ensuring scalability and flexibility.\nExtensive experiments across five benchmarks, covering commonsense,\nmathematical, logical, temporal, and semantic reasoning, demonstrate that RiOT\noutperforms both previous prompt optimization methods and manual prompting.", "AI": {"tldr": "RiOT is a novel framework for automatic prompt optimization in LLMs, addressing diversity and semantic drift issues by using text gradients, residual connections, and a tree structure. It outperforms existing methods and manual prompting.", "motivation": "Current prompt optimization methods lack diversity and suffer from semantic drift, limiting LLM performance.", "method": "RiOT iteratively refines prompts using text gradients, generates diverse candidates, selects the best via perplexity, and uses residual connections to mitigate semantic drift. A tree structure ensures scalability.", "result": "RiOT outperforms previous prompt optimization methods and manual prompting across five benchmarks.", "conclusion": "RiOT effectively addresses diversity and semantic drift, enhancing LLM performance through scalable and flexible prompt optimization."}}
{"id": "2506.16601", "pdf": "https://arxiv.org/pdf/2506.16601", "abs": "https://arxiv.org/abs/2506.16601", "authors": ["Muhammad Azeem Aslam", "Muhammad Hamza", "Nisar Ahmed", "Gulshan Saleem", "Zhu Shuangtong", "Hu Hongfei", "Xu Wei", "Saba Aslam", "Wang Jun"], "title": "MetaQAP -- A Meta-Learning Approach for Quality-Aware Pretraining in Image Quality Assessment", "categories": ["cs.CV", "eess.IV"], "comment": null, "summary": "Image Quality Assessment (IQA) is a critical task in a wide range of\napplications but remains challenging due to the subjective nature of human\nperception and the complexity of real-world image distortions. This study\nproposes MetaQAP, a novel no-reference IQA model designed to address these\nchallenges by leveraging quality-aware pre-training and meta-learning. The\nmodel performs three key contributions: pre-training Convolutional Neural\nNetworks (CNNs) on a quality-aware dataset, implementing a quality-aware loss\nfunction to optimize predictions, and integrating a meta-learner to form an\nensemble model that effectively combines predictions from multiple base models.\nExperimental evaluations were conducted on three benchmark datasets: LiveCD,\nKonIQ-10K, and BIQ2021. The proposed MetaQAP model achieved exceptional\nperformance with Pearson Linear Correlation Coefficient (PLCC) and Spearman\nRank Order Correlation Coefficient (SROCC) scores of 0.9885/0.9812 on LiveCD,\n0.9702/0.9658 on KonIQ-10K, and 0.884/0.8765 on BIQ2021, outperforming existing\nIQA methods. Cross-dataset evaluations further demonstrated the\ngeneralizability of the model, with PLCC and SROCC scores ranging from 0.6721\nto 0.8023 and 0.6515 to 0.7805, respectively, across diverse datasets. The\nablation study confirmed the significance of each model component, revealing\nsubstantial performance degradation when critical elements such as the\nmeta-learner or quality-aware loss function were omitted. MetaQAP not only\naddresses the complexities of authentic distortions but also establishes a\nrobust and generalizable framework for practical IQA applications. By advancing\nthe state-of-the-art in no-reference IQA, this research provides valuable\ninsights and methodologies for future improvements and extensions in the field.", "AI": {"tldr": "MetaQAP is a no-reference IQA model using quality-aware pre-training and meta-learning, outperforming existing methods on benchmark datasets.", "motivation": "Addressing the challenges of subjective human perception and complex real-world image distortions in IQA.", "method": "Pre-training CNNs on a quality-aware dataset, using a quality-aware loss function, and integrating a meta-learner for ensemble predictions.", "result": "Achieved high PLCC and SROCC scores (e.g., 0.9885/0.9812 on LiveCD) and demonstrated generalizability in cross-dataset evaluations.", "conclusion": "MetaQAP provides a robust, generalizable framework for IQA, advancing the field with valuable insights for future improvements."}}
{"id": "2506.16141", "pdf": "https://arxiv.org/pdf/2506.16141", "abs": "https://arxiv.org/abs/2506.16141", "authors": ["Yi Chen", "Yuying Ge", "Rui Wang", "Yixiao Ge", "Junhao Cheng", "Ying Shan", "Xihui Liu"], "title": "GRPO-CARE: Consistency-Aware Reinforcement Learning for Multimodal Reasoning", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.LG"], "comment": "Code released at: https://github.com/TencentARC/GRPO-CARE", "summary": "Recent reinforcement learning approaches, such as outcome-supervised GRPO,\nhave advanced Chain-of-Thought reasoning in large language models (LLMs), yet\ntheir adaptation to multimodal LLMs (MLLMs) is unexplored. To address the lack\nof rigorous evaluation for MLLM post-training methods, we introduce\nSEED-Bench-R1, a benchmark with complex real-world videos requiring balanced\nperception and reasoning. It offers a large training set and evaluates\ngeneralization across three escalating challenges: in-distribution,\ncross-environment, and cross-environment-task scenarios. Using SEED-Bench-R1,\nwe find that standard GRPO, while improving answer accuracy, often reduces\nlogical coherence between reasoning steps and answers, with only a 57.9%\nconsistency rate. This stems from reward signals focusing solely on final\nanswers, encouraging shortcuts, and strict KL penalties limiting exploration.To\naddress this, we propose GRPO-CARE, a consistency-aware RL framework optimizing\nboth answer correctness and reasoning coherence without explicit supervision.\nGRPO-CARE introduces a two-tiered reward: (1) a base reward for answer\ncorrectness, and (2) an adaptive consistency bonus, computed by comparing the\nmodel's reasoning-to-answer likelihood (via a slowly-evolving reference model)\nagainst group peers.This dual mechanism amplifies rewards for reasoning paths\nthat are both correct and logically consistent. Replacing KL penalties with\nthis adaptive bonus, GRPO-CARE outperforms standard GRPO on SEED-Bench-R1,\nachieving a 6.7% performance gain on the hardest evaluation level and a 24.5%\nimprovement in consistency. It also shows strong transferability, improving\nmodel performance across diverse video understanding benchmarks. Our work\ncontributes a systematically designed benchmark and a generalizable\npost-training framework, advancing the development of more interpretable and\nrobust MLLMs.", "AI": {"tldr": "The paper introduces SEED-Bench-R1 for evaluating multimodal LLMs (MLLMs) and proposes GRPO-CARE, a consistency-aware RL framework, to improve answer correctness and reasoning coherence.", "motivation": "Existing reinforcement learning methods like GRPO lack rigorous evaluation for MLLMs and often sacrifice logical coherence for answer accuracy.", "method": "GRPO-CARE uses a two-tiered reward system: a base reward for answer correctness and an adaptive consistency bonus for logical coherence, replacing KL penalties.", "result": "GRPO-CARE outperforms standard GRPO, achieving a 6.7% performance gain on the hardest evaluation level and a 24.5% improvement in consistency.", "conclusion": "The work provides a benchmark and framework to enhance interpretability and robustness in MLLMs."}}
{"id": "2506.15713", "pdf": "https://arxiv.org/pdf/2506.15713", "abs": "https://arxiv.org/abs/2506.15713", "authors": ["Michael T. M. B. Morris-Thomas", "Marius Martens"], "title": "An application of machine learning to the motion response prediction of floating assets", "categories": ["cs.LG", "physics.data-an", "physics.flu-dyn"], "comment": "17 pages, 6 figures", "summary": "The real-time prediction of floating offshore asset behavior under stochastic\nmetocean conditions remains a significant challenge in offshore engineering.\nWhile traditional empirical and frequency-domain methods work well in benign\nconditions, they struggle with both extreme sea states and nonlinear responses.\nThis study presents a supervised machine learning approach using multivariate\nregression to predict the nonlinear motion response of a turret-moored vessel\nin 400 m water depth. We developed a machine learning workflow combining a\ngradient-boosted ensemble method with a custom passive weathervaning solver,\ntrained on approximately $10^6$ samples spanning 100 features. The model\nachieved mean prediction errors of less than 5% for critical mooring parameters\nand vessel heading accuracy to within 2.5 degrees across diverse metocean\nconditions, significantly outperforming traditional frequency-domain methods.\nThe framework has been successfully deployed on an operational facility,\ndemonstrating its efficacy for real-time vessel monitoring and operational\ndecision-making in offshore environments.", "AI": {"tldr": "A machine learning model predicts floating offshore asset behavior with high accuracy, outperforming traditional methods.", "motivation": "Traditional methods fail in extreme conditions and nonlinear responses, necessitating a better solution.", "method": "Supervised machine learning with multivariate regression, combining gradient-boosted ensemble and a custom solver, trained on 1M samples.", "result": "Achieved <5% error for mooring parameters and <2.5\u00b0 heading accuracy, outperforming frequency-domain methods.", "conclusion": "The framework is effective for real-time monitoring and decision-making in offshore operations."}}
{"id": "2506.16764", "pdf": "https://arxiv.org/pdf/2506.16764", "abs": "https://arxiv.org/abs/2506.16764", "authors": ["Yanchen Zhu", "Honghui Zou", "Chufan Liu", "Yuyu Luo", "Yuankai Wu", "Yuxuan Liang"], "title": "Reinforcement learning for hybrid charging stations planning and operation considering fixed and mobile chargers", "categories": ["cs.AI"], "comment": "11pages", "summary": "The success of vehicle electrification, which brings significant societal and\nenvironmental benefits, is contingent upon the availability of efficient and\nadaptable charging infrastructure. Traditional fixed-location charging stations\noften face issues like underutilization or congestion due to the dynamic nature\nof charging demand. Mobile chargers have emerged as a flexible solution,\ncapable of relocating to align with these demand fluctuations. This paper\naddresses the optimal planning and operation of hybrid charging\ninfrastructures, integrating both fixed and mobile chargers within urban road\nnetworks. We introduce the Hybrid Charging Station Planning and Operation\n(HCSPO) problem, which simultaneously optimizes the location and configuration\nof fixed charging stations and schedules mobile chargers for dynamic\noperations. Our approach incorporates a charging demand prediction model\ngrounded in Model Predictive Control (MPC) to enhance decision-making. To solve\nthe HCSPO problem, we propose a deep reinforcement learning method, augmented\nwith heuristic scheduling techniques, to effectively bridge the planning of\nfixed chargers with the real-time operation of mobile chargers. Extensive case\nstudies using real-world urban scenarios demonstrate that our method\nsignificantly improves the availability of charging infrastructure and reduces\nuser inconvenience compared to existing solutions and baselines.", "AI": {"tldr": "The paper proposes a hybrid charging infrastructure (fixed and mobile chargers) optimized via deep reinforcement learning and MPC-based demand prediction, improving availability and reducing user inconvenience.", "motivation": "Dynamic charging demand causes underutilization or congestion in fixed charging stations; mobile chargers offer flexibility but require optimal integration with fixed infrastructure.", "method": "Introduces the HCSPO problem, combining fixed charger planning and mobile charger scheduling using deep reinforcement learning and heuristic techniques.", "result": "Case studies show improved charging availability and reduced user inconvenience compared to baselines.", "conclusion": "Hybrid infrastructure with optimized planning and operation is effective for dynamic urban charging demands."}}
{"id": "2506.16393", "pdf": "https://arxiv.org/pdf/2506.16393", "abs": "https://arxiv.org/abs/2506.16393", "authors": ["Yao Lu", "Zhaiyuan Ji", "Jiawei Du", "Yu Shanqing", "Qi Xuan", "Tianyi Zhou"], "title": "From LLM-anation to LLM-orchestrator: Coordinating Small Models for Data Labeling", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Although the annotation paradigm based on Large Language Models (LLMs) has\nmade significant breakthroughs in recent years, its actual deployment still has\ntwo core bottlenecks: first, the cost of calling commercial APIs in large-scale\nannotation is very expensive; second, in scenarios that require fine-grained\nsemantic understanding, such as sentiment classification and toxicity\nclassification, the annotation accuracy of LLMs is even lower than that of\nSmall Language Models (SLMs) dedicated to this field. To address these\nproblems, we propose a new paradigm of multi-model cooperative annotation and\ndesign a fully automatic annotation framework AutoAnnotator based on this.\nSpecifically, AutoAnnotator consists of two layers. The upper-level\nmeta-controller layer uses the generation and reasoning capabilities of LLMs to\nselect SLMs for annotation, automatically generate annotation code and verify\ndifficult samples; the lower-level task-specialist layer consists of multiple\nSLMs that perform annotation through multi-model voting. In addition, we use\nthe difficult samples obtained by the secondary review of the meta-controller\nlayer as the reinforcement learning set and fine-tune the SLMs in stages\nthrough a continual learning strategy, thereby improving the generalization of\nSLMs. Extensive experiments show that AutoAnnotator outperforms existing\nopen-source/API LLMs in zero-shot, one-shot, CoT, and majority voting settings.\nNotably, AutoAnnotator reduces the annotation cost by 74.15% compared to\ndirectly annotating with GPT-3.5-turbo, while still improving the accuracy by\n6.21%. Project page: https://github.com/Zhaiyuan-Ji/AutoAnnotator.", "AI": {"tldr": "AutoAnnotator is a multi-model cooperative annotation framework that reduces costs and improves accuracy by combining LLMs and SLMs.", "motivation": "Address the high cost and low accuracy of LLMs in fine-grained semantic tasks by leveraging SLMs and a cooperative annotation approach.", "method": "A two-layer framework: meta-controller (LLMs for selection, code generation, and verification) and task-specialist (SLMs for voting). Uses continual learning to fine-tune SLMs.", "result": "Outperforms LLMs in zero-shot, one-shot, CoT, and majority voting settings, reducing cost by 74.15% and improving accuracy by 6.21%.", "conclusion": "AutoAnnotator offers a cost-effective and accurate alternative to LLM-based annotation, especially for fine-grained tasks."}}
{"id": "2506.16735", "pdf": "https://arxiv.org/pdf/2506.16735", "abs": "https://arxiv.org/abs/2506.16735", "authors": ["Yunshan Li", "Wenwu Gong", "Qianqian Wang", "Chao Wang", "Lili Yang"], "title": "3DeepRep: 3D Deep Low-rank Tensor Representation for Hyperspectral Image Inpainting", "categories": ["cs.CV", "eess.IV"], "comment": null, "summary": "Recent approaches based on transform-based tensor nuclear norm (TNN) have\ndemonstrated notable effectiveness in hyperspectral image (HSI) inpainting by\nleveraging low-rank structures in latent representations. Recent developments\nincorporate deep transforms to improve low-rank tensor representation; however,\nexisting approaches typically restrict the transform to the spectral mode,\nneglecting low-rank properties along other tensor modes. In this paper, we\npropose a novel 3-directional deep low-rank tensor representation (3DeepRep)\nmodel, which performs deep nonlinear transforms along all three modes of the\nHSI tensor. To enforce low-rankness, the model minimizes the nuclear norms of\nmode-i frontal slices in the corresponding latent space for each direction\n(i=1,2,3), forming a 3-directional TNN regularization. The outputs from the\nthree directional branches are subsequently fused via a learnable aggregation\nmodule to produce the final result. An efficient gradient-based optimization\nalgorithm is developed to solve the model in a self-supervised manner.\nExtensive experiments on real-world HSI datasets demonstrate that the proposed\nmethod achieves superior inpainting performance compared to existing\nstate-of-the-art techniques, both qualitatively and quantitatively.", "AI": {"tldr": "The paper introduces 3DeepRep, a novel 3-directional deep low-rank tensor representation model for HSI inpainting, outperforming existing methods.", "motivation": "Existing approaches focus on spectral mode transforms, neglecting low-rank properties in other tensor modes. The paper aims to address this gap.", "method": "3DeepRep performs deep nonlinear transforms along all three HSI tensor modes, using 3-directional TNN regularization and a learnable aggregation module.", "result": "The method achieves superior inpainting performance on real-world HSI datasets, both qualitatively and quantitatively.", "conclusion": "3DeepRep effectively leverages multi-directional low-rank structures, offering a significant improvement over state-of-the-art techniques."}}
{"id": "2506.16157", "pdf": "https://arxiv.org/pdf/2506.16157", "abs": "https://arxiv.org/abs/2506.16157", "authors": ["Xingbai Chen", "Tingchao Fu", "Renyang Liu", "Wei Zhou", "Chao Yi"], "title": "MBA: Multimodal Bidirectional Attack for Referring Expression Segmentation Models", "categories": ["cs.CV"], "comment": "17 pages, 5pages", "summary": "Referring Expression Segmentation (RES) enables precise object segmentation\nin images based on natural language descriptions, offering high flexibility and\nbroad applicability in real-world vision tasks. Despite its impressive\nperformance, the robustness of RES models against adversarial examples remains\nlargely unexplored. While prior adversarial attack methods have explored\nadversarial robustness on conventional segmentation models, they perform poorly\nwhen directly applied to RES, failing to expose vulnerabilities in its\nmultimodal structure. Moreover, in practical open-world scenarios, users\ntypically issue multiple, diverse referring expressions to interact with the\nsame image, highlighting the need for adversarial examples that generalize\nacross varied textual inputs. To address these multimodal challenges, we\npropose a novel adversarial attack strategy termed \\textbf{Multimodal\nBidirectional Attack}, tailored for RES models. Our method introduces learnable\nproxy textual embedding perturbation and jointly performs visual-aligned\noptimization on the image modality and textual-adversarial optimization on the\ntextual modality during attack generation. This dual optimization framework\nencourages adversarial images to actively adapt to more challenging text\nembedding during optimization, thereby enhancing their cross-text\ntransferability, which refers to the ability of adversarial examples to remain\neffective under a variety of unseen or semantically diverse textual inputs.\nExtensive experiments conducted on multiple RES models and benchmark datasets\ndemonstrate the superior effectiveness of our method compared to existing\nmethods.", "AI": {"tldr": "The paper proposes a novel adversarial attack strategy, Multimodal Bidirectional Attack, for Referring Expression Segmentation (RES) models to address their robustness against adversarial examples and improve cross-text transferability.", "motivation": "RES models lack exploration of adversarial robustness, and existing attack methods fail for RES due to its multimodal structure. Practical scenarios involve diverse referring expressions, necessitating adversarial examples that generalize across varied textual inputs.", "method": "The method introduces learnable proxy textual embedding perturbation and jointly optimizes visual and textual modalities during attack generation, enhancing cross-text transferability.", "result": "Extensive experiments show the proposed method outperforms existing methods in effectiveness across multiple RES models and datasets.", "conclusion": "The Multimodal Bidirectional Attack successfully addresses RES robustness challenges and improves adversarial example transferability across diverse textual inputs."}}
{"id": "2506.15714", "pdf": "https://arxiv.org/pdf/2506.15714", "abs": "https://arxiv.org/abs/2506.15714", "authors": ["Andrew Kiruluta"], "title": "Adaptive Two Sided Laplace Transforms: A Learnable, Interpretable, and Scalable Replacement for Self-Attention", "categories": ["cs.LG", "cs.CL"], "comment": null, "summary": "We propose an innovative, learnable two-sided short-time Laplace transform\n(STLT) mechanism to supplant the traditional self attention in\ntransformer-based LLMs. Our STLT introduces trainable parameters for each\nLaplace node, enabling end-to-end learning of decay rates , oscillatory\nfrequencies, and window bandwidth T. This flexibility allows the model to\ndynamically adapt token relevance half lives and frequency responses during\ntraining. By selecting S learnable nodes and leveraging fast recursive\nconvolution, we achieve an effective complexity of in time and memory. We\nfurther incorporate an efficient FFT-based computation of the relevance matrix\nand an adaptive node allocation mechanism to dynamically adjust the number of\nactive Laplace nodes. Empirical results on language modeling (WikiText\\-103,\nProject Gutenberg), machine translation (WMT'14 En\\-De), and long document\nquestion answering (NarrativeQA) demonstrate that our learnable STLT achieves\nperplexities and scores on par with or better than existing efficient\ntransformers while naturally extending to context lengths exceeding 100k tokens\nor more limited only by available hardware. Ablation studies confirm the\nimportance of learnable parameters and adaptive node allocation. The proposed\napproach combines interpretability, through explicit decay and frequency\nparameters, with scalability and robustness, offering a pathway towards\nultra-long-sequence language modeling without the computational bottleneck of\nself-attention.", "AI": {"tldr": "Proposes a learnable two-sided short-time Laplace transform (STLT) to replace self-attention in transformers, enabling dynamic adaptation of token relevance and frequency responses with scalable complexity.", "motivation": "To address the computational bottleneck of self-attention in transformers while maintaining or improving performance, especially for ultra-long sequences.", "method": "Introduces trainable parameters for Laplace nodes, fast recursive convolution, FFT-based relevance matrix computation, and adaptive node allocation.", "result": "Achieves comparable or better perplexities and scores on tasks like language modeling, translation, and QA, extending to 100k+ token contexts.", "conclusion": "The STLT combines interpretability, scalability, and robustness, offering a viable alternative to self-attention for long-sequence modeling."}}
{"id": "2506.16898", "pdf": "https://arxiv.org/pdf/2506.16898", "abs": "https://arxiv.org/abs/2506.16898", "authors": ["Ciro Beneduce", "Massimiliano Luca", "Bruno Lepri"], "title": "AI's Blind Spots: Geographic Knowledge and Diversity Deficit in Generated Urban Scenario", "categories": ["cs.AI", "cs.CV", "cs.CY"], "comment": null, "summary": "Image generation models are revolutionizing many domains, and urban analysis\nand design is no exception. While such models are widely adopted, there is a\nlimited literature exploring their geographic knowledge, along with the biases\nthey embed. In this work, we generated 150 synthetic images for each state in\nthe USA and related capitals using FLUX 1 and Stable Diffusion 3.5, two\nstate-of-the-art models for image generation. We embed each image using DINO-v2\nViT-S/14 and the Fr\\'echet Inception Distances to measure the similarity\nbetween the generated images. We found that while these models have implicitly\nlearned aspects of USA geography, if we prompt the models to generate an image\nfor \"United States\" instead of specific cities or states, the models exhibit a\nstrong representative bias toward metropolis-like areas, excluding rural states\nand smaller cities. {\\color{black} In addition, we found that models\nsystematically exhibit some entity-disambiguation issues with European-sounding\nnames like Frankfort or Devon.", "AI": {"tldr": "The paper explores geographic biases in image generation models (FLUX 1 and Stable Diffusion 3.5) when generating USA-related images, revealing a bias toward metropolis-like areas and issues with European-sounding names.", "motivation": "To investigate the geographic knowledge and biases embedded in state-of-the-art image generation models when applied to urban analysis and design.", "method": "Generated 150 synthetic images per USA state and capital using FLUX 1 and Stable Diffusion 3.5, analyzed similarity using DINO-v2 ViT-S/14 and Fr\u00e9chet Inception Distances.", "result": "Models show implicit geographic learning but exhibit strong bias toward metropolis-like areas and disambiguation issues with European-sounding names.", "conclusion": "Image generation models have geographic biases and limitations, highlighting the need for addressing representational fairness in such applications."}}
{"id": "2506.16395", "pdf": "https://arxiv.org/pdf/2506.16395", "abs": "https://arxiv.org/abs/2506.16395", "authors": ["Zhexu Wang", "Yiping Liu", "Yejie Wang", "Wenyang He", "Bofei Gao", "Muxi Diao", "Yanxu Chen", "Kelin Fu", "Flood Sung", "Zhilin Yang", "Tianyu Liu", "Weiran Xu"], "title": "OJBench: A Competition Level Code Benchmark For Large Language Models", "categories": ["cs.CL"], "comment": "9 pages, 5 figures", "summary": "Recent advancements in large language models (LLMs) have demonstrated\nsignificant progress in math and code reasoning capabilities. However, existing\ncode benchmark are limited in their ability to evaluate the full spectrum of\nthese capabilities, particularly at the competitive level. To bridge this gap,\nwe introduce OJBench, a novel and challenging benchmark designed to assess the\ncompetitive-level code reasoning abilities of LLMs. OJBench comprises 232\nprogramming competition problems from NOI and ICPC, providing a more rigorous\ntest of models' reasoning skills. We conducted a comprehensive evaluation using\nOJBench on 37 models, including both closed-source and open-source models,\nreasoning-oriented and non-reasoning-oriented models. Our results indicate that\neven state-of-the-art reasoning-oriented models, such as o4-mini and\nGemini-2.5-pro-exp, struggle with highly challenging competition-level\nproblems. This highlights the significant challenges that models face in\ncompetitive-level code reasoning.", "AI": {"tldr": "OJBench is a new benchmark for evaluating competitive-level code reasoning in LLMs, revealing limitations even in top models.", "motivation": "Existing benchmarks fall short in assessing competitive-level code reasoning in LLMs.", "method": "OJBench includes 232 programming competition problems from NOI and ICPC, tested on 37 models.", "result": "State-of-the-art models struggle with highly challenging competition-level problems.", "conclusion": "Competitive-level code reasoning remains a significant challenge for LLMs."}}
{"id": "2506.16961", "pdf": "https://arxiv.org/pdf/2506.16961", "abs": "https://arxiv.org/abs/2506.16961", "authors": ["Haina Qin", "Wenyang Luo", "Libin Wang", "Dandan Zheng", "Jingdong Chen", "Ming Yang", "Bing Li", "Weiming Hu"], "title": "Reversing Flow for Image Restoration", "categories": ["cs.CV", "eess.IV", "68U10", "I.4.4"], "comment": "CVPR2025 Final Version; Corresponding Author: Bing Li", "summary": "Image restoration aims to recover high-quality (HQ) images from degraded\nlow-quality (LQ) ones by reversing the effects of degradation. Existing\ngenerative models for image restoration, including diffusion and score-based\nmodels, often treat the degradation process as a stochastic transformation,\nwhich introduces inefficiency and complexity. In this work, we propose ResFlow,\na novel image restoration framework that models the degradation process as a\ndeterministic path using continuous normalizing flows. ResFlow augments the\ndegradation process with an auxiliary process that disambiguates the\nuncertainty in HQ prediction to enable reversible modeling of the degradation\nprocess. ResFlow adopts entropy-preserving flow paths and learns the augmented\ndegradation flow by matching the velocity field. ResFlow significantly improves\nthe performance and speed of image restoration, completing the task in fewer\nthan four sampling steps. Extensive experiments demonstrate that ResFlow\nachieves state-of-the-art results across various image restoration benchmarks,\noffering a practical and efficient solution for real-world applications.", "AI": {"tldr": "ResFlow is a novel image restoration framework using deterministic continuous normalizing flows, improving efficiency and performance over stochastic methods.", "motivation": "Existing generative models for image restoration treat degradation as stochastic, leading to inefficiency and complexity.", "method": "ResFlow models degradation as a deterministic path with entropy-preserving flow paths and learns by matching the velocity field.", "result": "ResFlow achieves state-of-the-art results, completing restoration in fewer than four steps.", "conclusion": "ResFlow offers a practical, efficient solution for image restoration, outperforming existing methods."}}
{"id": "2506.16159", "pdf": "https://arxiv.org/pdf/2506.16159", "abs": "https://arxiv.org/abs/2506.16159", "authors": ["Taisei Omine", "Naoyuki Kawabata", "Fuminori Homma"], "title": "Co-Speech Gesture and Facial Expression Generation for Non-Photorealistic 3D Characters", "categories": ["cs.CV", "I.2.10"], "comment": "Accepted to SIGGRAPH 2025 Poster", "summary": "With the advancement of conversational AI, research on bodily expressions,\nincluding gestures and facial expressions, has also progressed. However, many\nexisting studies focus on photorealistic avatars, making them unsuitable for\nnon-photorealistic characters, such as those found in anime. This study\nproposes methods for expressing emotions, including exaggerated expressions\nunique to non-photorealistic characters, by utilizing expression data extracted\nfrom comics and dialogue-specific semantic gestures. A user study demonstrated\nsignificant improvements across multiple aspects when compared to existing\nresearch.", "AI": {"tldr": "Proposes methods for expressing emotions in non-photorealistic characters using comic data and semantic gestures, showing improvements over existing research.", "motivation": "Existing studies focus on photorealistic avatars, neglecting non-photorealistic characters like anime.", "method": "Utilizes expression data from comics and dialogue-specific semantic gestures.", "result": "User study showed significant improvements in multiple aspects.", "conclusion": "The proposed methods effectively enhance emotional expression for non-photorealistic characters."}}
{"id": "2506.15715", "pdf": "https://arxiv.org/pdf/2506.15715", "abs": "https://arxiv.org/abs/2506.15715", "authors": ["Hanyu Pei", "Jing-Xiao Liao", "Qibin Zhao", "Ting Gao", "Shijun Zhang", "Xiaoge Zhang", "Feng-Lei Fan"], "title": "NeuronSeek: On Stability and Expressivity of Task-driven Neurons", "categories": ["cs.LG", "cs.AI"], "comment": "14 pages, 10 figures", "summary": "Drawing inspiration from our human brain that designs different neurons for\ndifferent tasks, recent advances in deep learning have explored modifying a\nnetwork's neurons to develop so-called task-driven neurons. Prototyping\ntask-driven neurons (referred to as NeuronSeek) employs symbolic regression\n(SR) to discover the optimal neuron formulation and construct a network from\nthese optimized neurons. Along this direction, this work replaces symbolic\nregression with tensor decomposition (TD) to discover optimal neuronal\nformulations, offering enhanced stability and faster convergence. Furthermore,\nwe establish theoretical guarantees that modifying the aggregation functions\nwith common activation functions can empower a network with a fixed number of\nparameters to approximate any continuous function with an arbitrarily small\nerror, providing a rigorous mathematical foundation for the NeuronSeek\nframework. Extensive empirical evaluations demonstrate that our NeuronSeek-TD\nframework not only achieves superior stability, but also is competitive\nrelative to the state-of-the-art models across diverse benchmarks. The code is\navailable at https://github.com/HanyuPei22/NeuronSeek.", "AI": {"tldr": "NeuronSeek-TD replaces symbolic regression with tensor decomposition to optimize neuron formulations, improving stability and convergence while maintaining competitive performance.", "motivation": "Inspired by the human brain's task-specific neurons, the paper aims to develop task-driven neurons for deep learning networks.", "method": "Uses tensor decomposition (TD) instead of symbolic regression (SR) to discover optimal neuron formulations and modifies aggregation functions with common activations.", "result": "Achieves superior stability, faster convergence, and competitive performance against state-of-the-art models.", "conclusion": "NeuronSeek-TD provides a mathematically grounded framework for task-driven neurons, validated by empirical results."}}
{"id": "2506.16924", "pdf": "https://arxiv.org/pdf/2506.16924", "abs": "https://arxiv.org/abs/2506.16924", "authors": ["Tomoya Kashimata", "Yohei Hamakawa", "Masaya Yamasaki", "Kosuke Tatsumura"], "title": "Real-Time Black-Box Optimization for Dynamic Discrete Environments Using Embedded Ising Machines", "categories": ["cs.AI", "cs.ET", "I.2.8"], "comment": "18 pages, 6figures", "summary": "Many real-time systems require the optimization of discrete variables.\nBlack-box optimization (BBO) algorithms and multi-armed bandit (MAB) algorithms\nperform optimization by repeatedly taking actions and observing the\ncorresponding instant rewards without any prior knowledge. Recently, a BBO\nmethod using an Ising machine has been proposed to find the best action that is\nrepresented by a combination of discrete values and maximizes the instant\nreward in static environments. In contrast, dynamic environments, where\nreal-time systems operate, necessitate MAB algorithms that maximize the average\nreward over multiple trials. However, due to the enormous number of actions\nresulting from the combinatorial nature of discrete optimization, conventional\nMAB algorithms cannot effectively optimize dynamic, discrete environments.\nHere, we show a heuristic MAB method for dynamic, discrete environments by\nextending the BBO method, in which an Ising machine effectively explores the\nactions while considering interactions between variables and changes in dynamic\nenvironments. We demonstrate the dynamic adaptability of the proposed method in\na wireless communication system with moving users.", "AI": {"tldr": "A heuristic MAB method for dynamic, discrete environments is proposed by extending a BBO approach using an Ising machine, addressing limitations of conventional MAB algorithms in combinatorial optimization.", "motivation": "Real-time systems in dynamic environments require optimization of discrete variables, but conventional MAB algorithms fail due to the combinatorial explosion of actions.", "method": "Extends a BBO method using an Ising machine to explore actions while accounting for variable interactions and environmental changes.", "result": "Demonstrated dynamic adaptability in a wireless communication system with moving users.", "conclusion": "The proposed method effectively optimizes dynamic, discrete environments where traditional MAB algorithms fall short."}}
{"id": "2506.16399", "pdf": "https://arxiv.org/pdf/2506.16399", "abs": "https://arxiv.org/abs/2506.16399", "authors": ["Shushanta Pudasaini", "Aman Shakya", "Siddhartha Shrestha", "Sahil Bhatta", "Sunil Thapa", "Sushmita Palikhe"], "title": "NepaliGPT: A Generative Language Model for the Nepali Language", "categories": ["cs.CL", "cs.AI"], "comment": "11 pages, 9 figures", "summary": "After the release of ChatGPT, Large Language Models (LLMs) have gained huge\npopularity in recent days and thousands of variants of LLMs have been released.\nHowever, there is no generative language model for the Nepali language, due to\nwhich other downstream tasks, including fine-tuning, have not been explored\nyet. To fill this research gap in the Nepali NLP space, this research proposes\n\\textit{NepaliGPT}, a generative large language model tailored specifically for\nthe Nepali language. This research introduces an advanced corpus for the Nepali\nlanguage collected from several sources, called the Devanagari Corpus.\nLikewise, the research introduces the first NepaliGPT benchmark dataset\ncomprised of 4,296 question-answer pairs in the Nepali language. The proposed\nLLM NepaliGPT achieves the following metrics in text generation: Perplexity of\n26.32245, ROUGE-1 score of 0.2604, causal coherence of 81.25\\%, and causal\nconsistency of 85.41\\%.", "AI": {"tldr": "The paper introduces NepaliGPT, the first generative large language model for the Nepali language, along with a new corpus and benchmark dataset, achieving strong performance metrics.", "motivation": "The lack of a generative language model for Nepali hinders downstream tasks, prompting the development of NepaliGPT to fill this gap.", "method": "The research collects the Devanagari Corpus and creates a benchmark dataset (4,296 QA pairs), then trains NepaliGPT.", "result": "NepaliGPT achieves a perplexity of 26.32245, ROUGE-1 score of 0.2604, causal coherence of 81.25%, and causal consistency of 85.41%.", "conclusion": "NepaliGPT successfully addresses the gap in Nepali NLP, demonstrating strong generative capabilities."}}
{"id": "2506.17027", "pdf": "https://arxiv.org/pdf/2506.17027", "abs": "https://arxiv.org/abs/2506.17027", "authors": ["Yiyang Tie", "Hong Zhu", "Yunyun Luo", "Jing Shi"], "title": "Unsupervised Image Super-Resolution Reconstruction Based on Real-World Degradation Patterns", "categories": ["cs.CV", "eess.IV"], "comment": null, "summary": "The training of real-world super-resolution reconstruction models heavily\nrelies on datasets that reflect real-world degradation patterns. Extracting and\nmodeling degradation patterns for super-resolution reconstruction using only\nreal-world low-resolution (LR) images remains a challenging task. When\nsynthesizing datasets to simulate real-world degradation, relying solely on\ndegradation extraction methods fails to capture both blur and diverse noise\ncharacteristics across varying LR distributions, as well as more implicit\ndegradations such as color gamut shifts. Conversely, domain translation alone\ncannot accurately approximate real-world blur characteristics due to the\nsignificant degradation domain gap between synthetic and real data. To address\nthese challenges, we propose a novel TripleGAN framework comprising two\nstrategically designed components: The FirstGAN primarily focuses on narrowing\nthe domain gap in blur characteristics, while the SecondGAN performs\ndomain-specific translation to approximate target-domain blur properties and\nlearn additional degradation patterns. The ThirdGAN is trained on pseudo-real\ndata generated by the FirstGAN and SecondGAN to reconstruct real-world LR\nimages. Extensive experiments on the RealSR and DRealSR datasets demonstrate\nthat our method exhibits clear advantages in quantitative metrics while\nmaintaining sharp reconstructions without over-smoothing artifacts. The\nproposed framework effectively learns real-world degradation patterns from LR\nobservations and synthesizes aligned datasets with corresponding degradation\ncharacteristics, thereby enabling the trained network to achieve superior\nperformance in reconstructing high-quality SR images from real-world LR inputs.", "AI": {"tldr": "The paper proposes a TripleGAN framework to address challenges in modeling real-world degradation patterns for super-resolution (SR) tasks, outperforming existing methods in quantitative metrics and visual quality.", "motivation": "Existing methods struggle to capture diverse real-world degradation patterns (e.g., blur, noise, color shifts) from low-resolution (LR) images, limiting SR model performance.", "method": "The TripleGAN framework includes three GANs: FirstGAN narrows the blur domain gap, SecondGAN translates domain-specific blur and learns additional degradations, and ThirdGAN reconstructs LR images from pseudo-real data.", "result": "Experiments on RealSR and DRealSR datasets show superior quantitative performance and sharp reconstructions without over-smoothing.", "conclusion": "The framework effectively learns and synthesizes real-world degradation patterns, enabling high-quality SR reconstruction from real-world LR inputs."}}
{"id": "2506.16160", "pdf": "https://arxiv.org/pdf/2506.16160", "abs": "https://arxiv.org/abs/2506.16160", "authors": ["Jiyao Wang", "Xiao Yang", "Hao Lu", "Dengbo He", "Kaishun Wu"], "title": "Align the GAP: Prior-based Unified Multi-Task Remote Physiological Measurement Framework For Domain Generalization and Personalization", "categories": ["cs.CV"], "comment": null, "summary": "Multi-source synsemantic domain generalization (MSSDG) for multi-task remote\nphysiological measurement seeks to enhance the generalizability of these\nmetrics and attracts increasing attention. However, challenges like partial\nlabeling and environmental noise may disrupt task-specific accuracy. Meanwhile,\ngiven that real-time adaptation is necessary for personalized products, the\ntest-time personalized adaptation (TTPA) after MSSDG is also worth exploring,\nwhile the gap between previous generalization and personalization methods is\nsignificant and hard to fuse. Thus, we proposed a unified framework for\nMSSD\\textbf{G} and TTP\\textbf{A} employing \\textbf{P}riors (\\textbf{GAP}) in\nbiometrics and remote photoplethysmography (rPPG). We first disentangled\ninformation from face videos into invariant semantics, individual bias, and\nnoise. Then, multiple modules incorporating priors and our observations were\napplied in different stages and for different facial information. Then, based\non the different principles of achieving generalization and personalization,\nour framework could simultaneously address MSSDG and TTPA under multi-task\nremote physiological estimation with minimal adjustments. We expanded the MSSDG\nbenchmark to the TTPA protocol on six publicly available datasets and\nintroduced a new real-world driving dataset with complete labeling. Extensive\nexperiments that validated our approach, and the codes along with the new\ndataset will be released.", "AI": {"tldr": "A unified framework (GAP) combines multi-source synsemantic domain generalization (MSSDG) and test-time personalized adaptation (TTPA) for remote physiological measurement, addressing challenges like partial labeling and noise.", "motivation": "Enhancing generalizability and personalization in remote physiological measurement, overcoming issues like partial labeling, environmental noise, and the gap between generalization and personalization methods.", "method": "Disentangles face video data into invariant semantics, individual bias, and noise, using priors and observations in multiple modules for MSSDG and TTPA.", "result": "Validated on six datasets and a new real-world driving dataset, showing effectiveness in simultaneous MSSDG and TTPA with minimal adjustments.", "conclusion": "The GAP framework successfully bridges MSSDG and TTPA, offering a practical solution for multi-task remote physiological estimation."}}
{"id": "2506.15716", "pdf": "https://arxiv.org/pdf/2506.15716", "abs": "https://arxiv.org/abs/2506.15716", "authors": ["Angelos Assos", "Carmel Baharav", "Bailey Flanigan", "Ariel Procaccia"], "title": "Alternates, Assemble! Selecting Optimal Alternates for Citizens' Assemblies", "categories": ["cs.LG", "cs.AI", "cs.GT"], "comment": null, "summary": "An increasingly influential form of deliberative democracy centers on\ncitizens' assemblies, where randomly selected people discuss policy questions.\nThe legitimacy of these panels hinges on their representation of the broader\npopulation, but panelists often drop out, leading to an unbalanced composition.\nAlthough participant attrition is mitigated in practice by alternates, their\nselection is not taken into account by existing methods. To address this gap,\nwe introduce an optimization framework for alternate selection. Our algorithmic\napproach, which leverages learning-theoretic machinery, estimates dropout\nprobabilities using historical data and selects alternates to minimize expected\nmisrepresentation. We establish theoretical guarantees for our approach,\nincluding worst-case bounds on sample complexity (with implications for\ncomputational efficiency) and on loss when panelists' probabilities of dropping\nout are mis-estimated. Empirical evaluation using real-world data demonstrates\nthat, compared to the status quo, our method significantly improves\nrepresentation while requiring fewer alternates.", "AI": {"tldr": "The paper introduces an optimization framework for selecting alternates in citizens' assemblies to improve representation by minimizing expected misrepresentation, using historical data and learning-theoretic methods.", "motivation": "Citizens' assemblies rely on random selection for legitimacy, but dropout rates can skew representation. Existing methods ignore alternate selection, creating a gap this work addresses.", "method": "The authors propose an algorithmic approach using learning-theoretic tools to estimate dropout probabilities and optimize alternate selection. Theoretical guarantees and empirical validation are provided.", "result": "The method improves representation and reduces the number of alternates needed, as shown in real-world data.", "conclusion": "The framework offers a practical solution to enhance the legitimacy of citizens' assemblies by addressing dropout-related misrepresentation."}}
{"id": "2506.16931", "pdf": "https://arxiv.org/pdf/2506.16931", "abs": "https://arxiv.org/abs/2506.16931", "authors": ["Jiaqi Chen", "Mingfeng Fan", "Xuefeng Zhang", "Jingsong Liang", "Yuhong Cao", "Guohua Wu", "Guillaume Adrien Sartoretti"], "title": "Multimodal Fused Learning for Solving the Generalized Traveling Salesman Problem in Robotic Task Planning", "categories": ["cs.AI", "cs.RO"], "comment": "14 pages, 6 figures, under review", "summary": "Effective and efficient task planning is essential for mobile robots,\nespecially in applications like warehouse retrieval and environmental\nmonitoring. These tasks often involve selecting one location from each of\nseveral target clusters, forming a Generalized Traveling Salesman Problem\n(GTSP) that remains challenging to solve both accurately and efficiently. To\naddress this, we propose a Multimodal Fused Learning (MMFL) framework that\nleverages both graph and image-based representations to capture complementary\naspects of the problem, and learns a policy capable of generating high-quality\ntask planning schemes in real time. Specifically, we first introduce a\ncoordinate-based image builder that transforms GTSP instances into spatially\ninformative representations. We then design an adaptive resolution scaling\nstrategy to enhance adaptability across different problem scales, and develop a\nmultimodal fusion module with dedicated bottlenecks that enables effective\nintegration of geometric and spatial features. Extensive experiments show that\nour MMFL approach significantly outperforms state-of-the-art methods across\nvarious GTSP instances while maintaining the computational efficiency required\nfor real-time robotic applications. Physical robot tests further validate its\npractical effectiveness in real-world scenarios.", "AI": {"tldr": "Proposes a Multimodal Fused Learning (MMFL) framework for solving the Generalized Traveling Salesman Problem (GTSP) in robotic task planning, combining graph and image-based representations for real-time efficiency.", "motivation": "Addressing the challenge of accurate and efficient task planning for mobile robots in applications like warehouse retrieval and environmental monitoring, where GTSP is a key problem.", "method": "Introduces a coordinate-based image builder, adaptive resolution scaling, and a multimodal fusion module to integrate geometric and spatial features.", "result": "MMFL outperforms state-of-the-art methods in GTSP instances and maintains computational efficiency for real-time applications, validated by physical robot tests.", "conclusion": "The MMFL framework effectively solves GTSP in robotic task planning, demonstrating practical utility in real-world scenarios."}}
{"id": "2506.16411", "pdf": "https://arxiv.org/pdf/2506.16411", "abs": "https://arxiv.org/abs/2506.16411", "authors": ["Zhen Xu", "Shang Zhu", "Jue Wang", "Junlin Wang", "Ben Athiwaratkun", "Chi Wang", "James Zou", "Ce Zhang"], "title": "When Does Divide and Conquer Work for Long Context LLM? A Noise Decomposition Framework", "categories": ["cs.CL", "cs.LG"], "comment": "under review", "summary": "We investigate the challenge of applying Large Language Models (LLMs) to long\ntexts. We propose a theoretical framework that distinguishes the failure modes\nof long context tasks into three categories: cross-chunk dependence (task\nnoise), confusion that grows with context size (model noise), and the imperfect\nintegration of partial results (aggregator noise). Under this view, we analyze\nwhen it is effective to use multi-agent chunking, i.e., dividing a length\nsequence into smaller chunks and aggregating the processed results of each\nchunk. Our experiments on tasks such as retrieval, question answering, and\nsummarization confirm both the theoretical analysis and the conditions that\nfavor multi-agent chunking. By exploring superlinear model noise growth with\ninput length, we also explain why, for large inputs, a weaker model configured\nwith chunk-based processing can surpass a more advanced model like GPT4o\napplied in a single shot. Overall, we present a principled understanding\nframework and our results highlight a direct pathway to handling long contexts\nin LLMs with carefully managed chunking and aggregator strategies.", "AI": {"tldr": "The paper explores challenges of applying LLMs to long texts, proposing a framework to categorize failure modes and validating multi-agent chunking as an effective solution.", "motivation": "Addressing the difficulty of using LLMs for long-context tasks by identifying and mitigating failure modes.", "method": "Proposes a theoretical framework categorizing failure modes and tests multi-agent chunking on tasks like retrieval, QA, and summarization.", "result": "Experiments confirm the framework's validity and show chunk-based processing can outperform advanced models like GPT4o for large inputs.", "conclusion": "A principled framework and chunking strategy offer a viable solution for handling long contexts in LLMs."}}
{"id": "2403.02566", "pdf": "https://arxiv.org/pdf/2403.02566", "abs": "https://arxiv.org/abs/2403.02566", "authors": ["Runmin Jiang", "Zhaoxin Fan", "Junhao Wu", "Lenghan Zhu", "Xin Huang", "Tianyang Wang", "Heng Huang", "Min Xu"], "title": "Enhancing Weakly Supervised 3D Medical Image Segmentation through Probabilistic-aware Learning", "categories": ["eess.IV", "cs.CV"], "comment": null, "summary": "3D medical image segmentation is a challenging task with crucial implications\nfor disease diagnosis and treatment planning. Recent advances in deep learning\nhave significantly enhanced fully supervised medical image segmentation.\nHowever, this approach heavily relies on labor-intensive and time-consuming\nfully annotated ground-truth labels, particularly for 3D volumes. To overcome\nthis limitation, we propose a novel probabilistic-aware weakly supervised\nlearning pipeline, specifically designed for 3D medical imaging. Our pipeline\nintegrates three innovative components: a Probability-based Pseudo Label\nGeneration technique for synthesizing dense segmentation masks from sparse\nannotations, a Probabilistic Multi-head Self-Attention network for robust\nfeature extraction within our Probabilistic Transformer Network, and a\nProbability-informed Segmentation Loss Function to enhance training with\nannotation confidence. Demonstrating significant advances, our approach not\nonly rivals the performance of fully supervised methods but also surpasses\nexisting weakly supervised methods in CT and MRI datasets, achieving up to\n18.1% improvement in Dice scores for certain organs. The code is available at\nhttps://github.com/runminjiang/PW4MedSeg.", "AI": {"tldr": "A novel weakly supervised learning pipeline for 3D medical image segmentation reduces reliance on fully annotated data, achieving competitive performance with fully supervised methods.", "motivation": "Fully supervised 3D medical image segmentation requires labor-intensive annotations. The paper aims to address this by proposing a weakly supervised approach.", "method": "The pipeline includes Probability-based Pseudo Label Generation, a Probabilistic Multi-head Self-Attention network, and a Probability-informed Segmentation Loss Function.", "result": "The method outperforms existing weakly supervised methods, achieving up to 18.1% improvement in Dice scores for certain organs.", "conclusion": "The proposed pipeline is effective for 3D medical image segmentation, reducing annotation burden while maintaining high performance."}}
{"id": "2506.16186", "pdf": "https://arxiv.org/pdf/2506.16186", "abs": "https://arxiv.org/abs/2506.16186", "authors": ["Zhenghao Xi", "Xiang Liu", "Yaqi Liu", "Yitong Cai", "Yangyu Zheng"], "title": "Integrating Generative Adversarial Networks and Convolutional Neural Networks for Enhanced Traffic Accidents Detection and Analysis", "categories": ["cs.CV"], "comment": null, "summary": "Accident detection using Closed Circuit Television (CCTV) footage is one of\nthe most imperative features for enhancing transport safety and efficient\ntraffic control. To this end, this research addresses the issues of supervised\nmonitoring and data deficiency in accident detection systems by adapting\nexcellent deep learning technologies. The motivation arises from rising\nstatistics in the number of car accidents worldwide; this calls for innovation\nand the establishment of a smart, efficient and automated way of identifying\naccidents and calling for help to save lives. Addressing the problem of the\nscarcity of data, the presented framework joins Generative Adversarial Networks\n(GANs) for synthesizing data and Convolutional Neural Networks (CNN) for model\ntraining. Video frames for accidents and non-accidents are collected from\nYouTube videos, and we perform resizing, image enhancement and image\nnormalisation pixel range adjustments. Three models are used: CNN, Fine-tuned\nConvolutional Neural Network (FTCNN) and Vision Transformer (VIT) worked best\nfor detecting accidents from CCTV, obtaining an accuracy rate of 94% and 95%,\nwhile the CNN model obtained 88%. Such results show that the proposed framework\nsuits traffic safety applications due to its high real-time accident detection\ncapabilities and broad-scale applicability. This work lays the foundation for\nintelligent surveillance systems in the future for real-time traffic\nmonitoring, smart city framework, and integration of intelligent surveillance\nsystems into emergency management systems.", "AI": {"tldr": "The paper proposes a deep learning framework using GANs and CNNs for accident detection in CCTV footage, achieving high accuracy (up to 95%) with models like FTCNN and VIT.", "motivation": "The rising global car accident rates necessitate automated, efficient accident detection systems to enhance transport safety and emergency response.", "method": "The framework combines GANs for data synthesis and CNNs (including FTCNN and VIT) for training. Data preprocessing includes resizing, enhancement, and normalization of video frames from YouTube.", "result": "FTCNN and VIT achieved 94% and 95% accuracy, respectively, outperforming the baseline CNN (88%).", "conclusion": "The framework is effective for real-time accident detection, paving the way for future intelligent surveillance and smart city applications."}}
{"id": "2506.15717", "pdf": "https://arxiv.org/pdf/2506.15717", "abs": "https://arxiv.org/abs/2506.15717", "authors": ["Zhengze Zhang", "Shiqi Wang", "Yiqun Shen", "Simin Guo", "Dahua Lin", "Xiaoliang Wang", "Nguyen Cam-Tu", "Fei Tan"], "title": "daDPO: Distribution-Aware DPO for Distilling Conversational Abilities", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": null, "summary": "Large language models (LLMs) have demonstrated exceptional performance across\nvarious applications, but their conversational abilities decline sharply as\nmodel size decreases, presenting a barrier to their deployment in\nresource-constrained environments. Knowledge distillation with Direct\nPreference Optimization (dDPO) has emerged as a promising approach to enhancing\nthe conversational abilities of smaller models using a larger teacher model.\nHowever, current methods primarily focus on 'black-box' KD, which only uses the\nteacher's responses, overlooking the output distribution offered by the\nteacher. This paper addresses this gap by introducing daDPO (Distribution-Aware\nDPO), a unified method for preference optimization and distribution-based\ndistillation. We provide rigorous theoretical analysis and empirical\nvalidation, showing that daDPO outperforms existing methods in restoring\nperformance for pruned models and enhancing smaller LLM models. Notably, in\nin-domain evaluation, our method enables a 20% pruned Vicuna1.5-7B to achieve\nnear-teacher performance (-7.3% preference rate compared to that of dDPO's\n-31%), and allows Qwen2.5-1.5B to occasionally outperform its 7B teacher model\n(14.0% win rate).", "AI": {"tldr": "daDPO (Distribution-Aware DPO) improves smaller LLMs' conversational abilities by leveraging teacher models' output distributions, outperforming existing methods.", "motivation": "Smaller LLMs lose conversational ability as size decreases, limiting deployment in resource-constrained settings. Current methods ignore teacher models' output distributions.", "method": "Introduces daDPO, combining preference optimization and distribution-based distillation, validated theoretically and empirically.", "result": "daDPO restores pruned model performance and enhances smaller LLMs, e.g., 20% pruned Vicuna1.5-7B nears teacher performance, Qwen2.5-1.5B sometimes beats its 7B teacher.", "conclusion": "daDPO effectively bridges the performance gap between smaller and larger LLMs by utilizing teacher models' output distributions."}}
{"id": "2506.16995", "pdf": "https://arxiv.org/pdf/2506.16995", "abs": "https://arxiv.org/abs/2506.16995", "authors": ["Lingfeng Li", "Yunlong Lu", "Yongyi Wang", "Wenxin Li"], "title": "Elevating Styled Mahjong Agents with Learning from Demonstration", "categories": ["cs.AI"], "comment": null, "summary": "A wide variety of bots in games enriches the gameplay experience and enhances\nreplayability. Recent advancements in game artificial intelligence have\npredominantly focused on improving the proficiency of bots. Nevertheless,\ndeveloping highly competent bots with a wide range of distinct play styles\nremains a relatively under-explored area. We select the Mahjong game\nenvironment as a case study. The high degree of randomness inherent in the\nMahjong game and the prevalence of out-of-distribution states lead to\nsuboptimal performance of existing offline learning and\nLearning-from-Demonstration (LfD) algorithms. In this paper, we leverage the\ngameplay histories of existing Mahjong agents and put forward a novel LfD\nalgorithm that necessitates only minimal modifications to the Proximal Policy\nOptimization algorithm. The comprehensive empirical results illustrate that our\nproposed method not only significantly enhances the proficiency of the agents\nbut also effectively preserves their unique play styles.", "AI": {"tldr": "The paper introduces a novel Learning-from-Demonstration (LfD) algorithm for Mahjong bots, enhancing proficiency and preserving play styles with minimal changes to Proximal Policy Optimization.", "motivation": "Existing methods for developing competent bots with diverse play styles are under-explored, and Mahjong's randomness challenges offline learning and LfD algorithms.", "method": "The authors propose a modified LfD algorithm using gameplay histories of Mahjong agents, requiring minimal adjustments to Proximal Policy Optimization.", "result": "Empirical results show the method significantly improves bot proficiency while maintaining distinct play styles.", "conclusion": "The novel LfD algorithm effectively addresses the limitations of existing methods in Mahjong, balancing performance and style diversity."}}
{"id": "2506.16444", "pdf": "https://arxiv.org/pdf/2506.16444", "abs": "https://arxiv.org/abs/2506.16444", "authors": ["Kangqi Chen", "Andreas Kosmas Kakolyris", "Rakesh Nadig", "Manos Frouzakis", "Nika Mansouri Ghiasi", "Yu Liang", "Haiyu Mao", "Jisung Park", "Mohammad Sadrosadati", "Onur Mutlu"], "title": "REIS: A High-Performance and Energy-Efficient Retrieval System with In-Storage Processing", "categories": ["cs.CL", "cs.AR", "cs.DB", "H.3.3; I.2.7"], "comment": "Extended version of our publication at the 52nd International\n  Symposium on Computer Architecture (ISCA-52), 2025", "summary": "Large Language Models (LLMs) face an inherent challenge: their knowledge is\nconfined to the data that they have been trained on. To overcome this issue,\nRetrieval-Augmented Generation (RAG) complements the static training-derived\nknowledge of LLMs with an external knowledge repository. RAG consists of three\nstages: indexing, retrieval, and generation. The retrieval stage of RAG becomes\na significant bottleneck in inference pipelines. In this stage, a user query is\nmapped to an embedding vector and an Approximate Nearest Neighbor Search (ANNS)\nalgorithm searches for similar vectors in the database to identify relevant\nitems. Due to the large database sizes, ANNS incurs significant data movement\noverheads between the host and the storage system. To alleviate these\noverheads, prior works propose In-Storage Processing (ISP) techniques that\naccelerate ANNS by performing computations inside storage. However, existing\nworks that leverage ISP for ANNS (i) employ algorithms that are not tailored to\nISP systems, (ii) do not accelerate data retrieval operations for data selected\nby ANNS, and (iii) introduce significant hardware modifications, limiting\nperformance and hindering their adoption. We propose REIS, the first ISP system\ntailored for RAG that addresses these limitations with three key mechanisms.\nFirst, REIS employs a database layout that links database embedding vectors to\ntheir associated documents, enabling efficient retrieval. Second, it enables\nefficient ANNS by introducing an ISP-tailored data placement technique that\ndistributes embeddings across the planes of the storage system and employs a\nlightweight Flash Translation Layer. Third, REIS leverages an ANNS engine that\nuses the existing computational resources inside the storage system. Compared\nto a server-grade system, REIS improves the performance (energy efficiency) of\nretrieval by an average of 13x (55x).", "AI": {"tldr": "REIS is an In-Storage Processing (ISP) system designed to optimize Retrieval-Augmented Generation (RAG) by addressing bottlenecks in retrieval, improving performance and energy efficiency.", "motivation": "Large Language Models (LLMs) lack dynamic knowledge updates, and RAG's retrieval stage is inefficient due to data movement overheads in Approximate Nearest Neighbor Search (ANNS).", "method": "REIS introduces three mechanisms: a linked database layout, ISP-tailored data placement, and leveraging existing storage computational resources for ANNS.", "result": "REIS improves retrieval performance by 13x and energy efficiency by 55x compared to server-grade systems.", "conclusion": "REIS effectively addresses RAG's retrieval bottleneck with minimal hardware modifications, enhancing efficiency and adoption potential."}}
{"id": "2404.11511", "pdf": "https://arxiv.org/pdf/2404.11511", "abs": "https://arxiv.org/abs/2404.11511", "authors": ["Manasi Muglikar", "Siddharth Somasundaram", "Akshat Dave", "Edoardo Charbon", "Ramesh Raskar", "Davide Scaramuzza"], "title": "Event Cameras Meet SPADs for High-Speed, Low-Bandwidth Imaging", "categories": ["eess.IV", "cs.CV"], "comment": "IEEE Transactions on Pattern Analysis and Machine Intelligence, 2025", "summary": "Traditional cameras face a trade-off between low-light performance and\nhigh-speed imaging: longer exposure times to capture sufficient light results\nin motion blur, whereas shorter exposures result in Poisson-corrupted noisy\nimages. While burst photography techniques help mitigate this tradeoff,\nconventional cameras are fundamentally limited in their sensor noise\ncharacteristics. Event cameras and single-photon avalanche diode (SPAD) sensors\nhave emerged as promising alternatives to conventional cameras due to their\ndesirable properties. SPADs are capable of single-photon sensitivity with\nmicrosecond temporal resolution, and event cameras can measure brightness\nchanges up to 1 MHz with low bandwidth requirements. We show that these\nproperties are complementary, and can help achieve low-light, high-speed image\nreconstruction with low bandwidth requirements. We introduce a sensor fusion\nframework to combine SPADs with event cameras to improves the reconstruction of\nhigh-speed, low-light scenes while reducing the high bandwidth cost associated\nwith using every SPAD frame. Our evaluation, on both synthetic and real sensor\ndata, demonstrates significant enhancements ( > 5 dB PSNR) in reconstructing\nlow-light scenes at high temporal resolution (100 kHz) compared to conventional\ncameras. Event-SPAD fusion shows great promise for real-world applications,\nsuch as robotics or medical imaging.", "AI": {"tldr": "The paper introduces a sensor fusion framework combining SPADs and event cameras to achieve high-speed, low-light imaging with reduced bandwidth.", "motivation": "Overcome the trade-off in traditional cameras between low-light performance and high-speed imaging, which leads to motion blur or noisy images.", "method": "Proposes a fusion framework integrating SPADs (for single-photon sensitivity and microsecond resolution) and event cameras (for high-speed brightness changes with low bandwidth).", "result": "Demonstrates significant improvements (>5 dB PSNR) in reconstructing low-light scenes at high temporal resolution (100 kHz) compared to conventional cameras.", "conclusion": "Event-SPAD fusion shows promise for applications like robotics and medical imaging, offering better performance in challenging conditions."}}
{"id": "2506.16209", "pdf": "https://arxiv.org/pdf/2506.16209", "abs": "https://arxiv.org/abs/2506.16209", "authors": ["Annajoyce Mariani", "Kira Maag", "Hanno Gottschalk"], "title": "VideoGAN-based Trajectory Proposal for Automated Vehicles", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "Being able to generate realistic trajectory options is at the core of\nincreasing the degree of automation of road vehicles. While model-driven,\nrule-based, and classical learning-based methods are widely used to tackle\nthese tasks at present, they can struggle to effectively capture the complex,\nmultimodal distributions of future trajectories. In this paper we investigate\nwhether a generative adversarial network (GAN) trained on videos of bird's-eye\nview (BEV) traffic scenarios can generate statistically accurate trajectories\nthat correctly capture spatial relationships between the agents. To this end,\nwe propose a pipeline that uses low-resolution BEV occupancy grid videos as\ntraining data for a video generative model. From the generated videos of\ntraffic scenarios we extract abstract trajectory data using single-frame object\ndetection and frame-to-frame object matching. We particularly choose a GAN\narchitecture for the fast training and inference times with respect to\ndiffusion models. We obtain our best results within 100 GPU hours of training,\nwith inference times under 20\\,ms. We demonstrate the physical realism of the\nproposed trajectories in terms of distribution alignment of spatial and dynamic\nparameters with respect to the ground truth videos from the Waymo Open Motion\nDataset.", "AI": {"tldr": "A GAN-based approach generates realistic traffic trajectories from BEV videos, achieving fast training and inference while aligning with real-world data.", "motivation": "Existing methods struggle with complex, multimodal trajectory distributions, prompting the use of GANs for better accuracy and efficiency.", "method": "Uses low-resolution BEV occupancy grid videos to train a GAN, extracts trajectories via object detection and matching, and compares to diffusion models.", "result": "Achieves realistic trajectories with 100 GPU hours training and <20ms inference, aligning with Waymo dataset metrics.", "conclusion": "GANs are effective for generating accurate, efficient traffic trajectories, outperforming traditional methods."}}
{"id": "2506.15718", "pdf": "https://arxiv.org/pdf/2506.15718", "abs": "https://arxiv.org/abs/2506.15718", "authors": ["Yu Guo", "Hongji Fang", "Tianyu Fang", "Zhe Cui"], "title": "BuildingBRep-11K: Precise Multi-Storey B-Rep Building Solids with Rich Layout Metadata", "categories": ["cs.LG"], "comment": null, "summary": "With the rise of artificial intelligence, the automatic generation of\nbuilding-scale 3-D objects has become an active research topic, yet training\nsuch models still demands large, clean and richly annotated datasets. We\nintroduce BuildingBRep-11K, a collection of 11 978 multi-storey (2-10 floors)\nbuildings (about 10 GB) produced by a shape-grammar-driven pipeline that\nencodes established building-design principles. Every sample consists of a\ngeometrically exact B-rep solid-covering floors, walls, slabs and rule-based\nopenings-together with a fast-loading .npy metadata file that records detailed\nper-floor parameters. The generator incorporates constraints on spatial scale,\ndaylight optimisation and interior layout, and the resulting objects pass\nmulti-stage filters that remove Boolean failures, undersized rooms and extreme\naspect ratios, ensuring compliance with architectural standards. To verify the\ndataset's learnability we trained two lightweight PointNet baselines. (i)\nMulti-attribute regression. A single encoder predicts storey count, total\nrooms, per-storey vector and mean room area from a 4 000-point cloud. On 100\nunseen buildings it attains 0.37-storey MAE (87 \\% within $\\pm1$), 5.7-room\nMAE, and 3.2 m$^2$ MAE on mean area. (ii) Defect detection. With the same\nbackbone we classify GOOD versus DEFECT; on a balanced 100-model set the\nnetwork reaches 54 \\% accuracy, recalling 82 \\% of true defects at 53 \\%\nprecision (41 TP, 9 FN, 37 FP, 13 TN). These pilots show that BuildingBRep-11K\nis learnable yet non-trivial for both geometric regression and topological\nquality assessment", "AI": {"tldr": "BuildingBRep-11K is a dataset of 11,978 multi-storey buildings with detailed annotations, designed for training AI models in 3D object generation. It includes metadata and passes architectural standards. Two PointNet baselines demonstrate its learnability for regression and defect detection.", "motivation": "The lack of large, clean, and richly annotated datasets for training AI models in building-scale 3D object generation motivates the creation of BuildingBRep-11K.", "method": "A shape-grammar-driven pipeline generates the dataset, incorporating design principles and multi-stage filters for quality. Two PointNet models are trained for multi-attribute regression and defect detection.", "result": "The regression model achieves 0.37-storey MAE, 5.7-room MAE, and 3.2 m\u00b2 MAE on mean area. The defect detection model reaches 54% accuracy, with 82% recall for true defects.", "conclusion": "BuildingBRep-11K is learnable but challenging for geometric regression and topological quality assessment, proving its utility for AI research in 3D building generation."}}
{"id": "2506.17018", "pdf": "https://arxiv.org/pdf/2506.17018", "abs": "https://arxiv.org/abs/2506.17018", "authors": ["Davide Frizzo", "Francesco Borsatti", "Gian Antonio Susto"], "title": "A Quantile Regression Approach for Remaining Useful Life Estimation with State Space Models", "categories": ["cs.AI", "cs.LG"], "comment": "Submitted to IFAC Joint Conference on Computers, Cognition, and\n  Communication (J3C) 2025", "summary": "Predictive Maintenance (PdM) is pivotal in Industry 4.0 and 5.0, proactively\nenhancing efficiency through accurate equipment Remaining Useful Life (RUL)\nprediction, thus optimizing maintenance scheduling and reducing unexpected\nfailures and premature interventions. This paper introduces a novel RUL\nestimation approach leveraging State Space Models (SSM) for efficient long-term\nsequence modeling. To handle model uncertainty, Simoultaneous Quantile\nRegression (SQR) is integrated into the SSM, enabling multiple quantile\nestimations. The proposed method is benchmarked against traditional sequence\nmodelling techniques (LSTM, Transformer, Informer) using the C-MAPSS dataset.\nResults demonstrate superior accuracy and computational efficiency of SSM\nmodels, underscoring their potential for high-stakes industrial applications.", "AI": {"tldr": "A novel RUL estimation method using State Space Models (SSM) with Simultaneous Quantile Regression (SQR) outperforms traditional techniques in accuracy and efficiency.", "motivation": "To enhance Predictive Maintenance (PdM) in Industry 4.0/5.0 by improving RUL prediction for better maintenance scheduling and reduced failures.", "method": "Integrates SQR into SSM for long-term sequence modeling and uncertainty handling, benchmarked against LSTM, Transformer, and Informer on the C-MAPSS dataset.", "result": "SSM models show superior accuracy and computational efficiency compared to traditional methods.", "conclusion": "The proposed SSM-based approach is highly effective for industrial RUL estimation, offering reliability and efficiency."}}
{"id": "2506.16445", "pdf": "https://arxiv.org/pdf/2506.16445", "abs": "https://arxiv.org/abs/2506.16445", "authors": ["Haotian Xia", "Hao Peng", "Yunjia Qi", "Xiaozhi Wang", "Bin Xu", "Lei Hou", "Juanzi Li"], "title": "StoryWriter: A Multi-Agent Framework for Long Story Generation", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Long story generation remains a challenge for existing large language models\n(LLMs), primarily due to two main factors: (1) discourse coherence, which\nrequires plot consistency, logical coherence, and completeness in the long-form\ngeneration, and (2) narrative complexity, which requires an interwoven and\nengaging narrative. To address these challenges, we propose StoryWriter, a\nmulti-agent story generation framework, which consists of three main modules:\n(1) outline agent, which generates event-based outlines containing rich event\nplots, character, and event-event relationships. (2) planning agent, which\nfurther details events and plans which events should be written in each chapter\nto maintain an interwoven and engaging story. (3) writing agent, which\ndynamically compresses the story history based on the current event to generate\nand reflect new plots, ensuring the coherence of the generated story. We\nconduct both human and automated evaluation, and StoryWriter significantly\noutperforms existing story generation baselines in both story quality and\nlength. Furthermore, we use StoryWriter to generate a dataset, which contains\nabout $6,000$ high-quality long stories, with an average length of $8,000$\nwords. We train the model Llama3.1-8B and GLM4-9B using supervised fine-tuning\non LongStory and develop StoryWriter_GLM and StoryWriter_GLM, which\ndemonstrates advanced performance in long story generation.", "AI": {"tldr": "StoryWriter is a multi-agent framework for long story generation, addressing coherence and complexity through outline, planning, and writing agents. It outperforms baselines and generates a high-quality dataset.", "motivation": "Existing LLMs struggle with long story generation due to issues in discourse coherence and narrative complexity.", "method": "Proposes StoryWriter with three modules: outline agent (event-based outlines), planning agent (detailed event planning), and writing agent (dynamic story generation).", "result": "Outperforms baselines in quality and length, generates a dataset of 6,000 long stories (~8,000 words each), and fine-tunes models (Llama3.1-8B, GLM4-9B) for advanced performance.", "conclusion": "StoryWriter effectively addresses long story generation challenges, demonstrating superior performance and scalability."}}
{"id": "2410.14769", "pdf": "https://arxiv.org/pdf/2410.14769", "abs": "https://arxiv.org/abs/2410.14769", "authors": ["Guohui Cai", "Ying Cai", "Zeyu Zhang", "Yuanzhouhan Cao", "Lin Wu", "Daji Ergu", "Zhinbin Liao", "Yang Zhao"], "title": "Medical Artificial Intelligence for Early Detection of Lung Cancer: A Survey", "categories": ["eess.IV", "cs.CV"], "comment": "Accepted to Engineering Applications of Artificial Intelligence", "summary": "Lung cancer remains one of the leading causes of morbidity and mortality\nworldwide, making early diagnosis critical for improving therapeutic outcomes\nand patient prognosis. Computer-aided diagnosis systems, which analyze computed\ntomography images, have proven effective in detecting and classifying pulmonary\nnodules, significantly enhancing the detection rate of early-stage lung cancer.\nAlthough traditional machine learning algorithms have been valuable, they\nexhibit limitations in handling complex sample data. The recent emergence of\ndeep learning has revolutionized medical image analysis, driving substantial\nadvancements in this field. This review focuses on recent progress in deep\nlearning for pulmonary nodule detection, segmentation, and classification.\nTraditional machine learning methods, such as support vector machines and\nk-nearest neighbors, have shown limitations, paving the way for advanced\napproaches like Convolutional Neural Networks, Recurrent Neural Networks, and\nGenerative Adversarial Networks. The integration of ensemble models and novel\ntechniques is also discussed, emphasizing the latest developments in lung\ncancer diagnosis. Deep learning algorithms, combined with various analytical\ntechniques, have markedly improved the accuracy and efficiency of pulmonary\nnodule analysis, surpassing traditional methods, particularly in nodule\nclassification. Although challenges remain, continuous technological\nadvancements are expected to further strengthen the role of deep learning in\nmedical diagnostics, especially for early lung cancer detection and diagnosis.\nA comprehensive list of lung cancer detection models reviewed in this work is\navailable at https://github.com/CaiGuoHui123/Awesome-Lung-Cancer-Detection.", "AI": {"tldr": "The paper reviews deep learning advancements in pulmonary nodule detection, segmentation, and classification, highlighting its superiority over traditional machine learning methods for early lung cancer diagnosis.", "motivation": "Early diagnosis of lung cancer is crucial for better outcomes, and traditional machine learning methods have limitations in handling complex data.", "method": "Focuses on deep learning techniques like CNNs, RNNs, and GANs, as well as ensemble models, for analyzing CT images.", "result": "Deep learning significantly improves accuracy and efficiency in nodule analysis, especially in classification.", "conclusion": "Despite challenges, deep learning is expected to play a stronger role in medical diagnostics, particularly for early lung cancer detection."}}
{"id": "2506.16218", "pdf": "https://arxiv.org/pdf/2506.16218", "abs": "https://arxiv.org/abs/2506.16218", "authors": ["Xinting Liao", "Weiming Liu", "Jiaming Qian", "Pengyang Zhou", "Jiahe Xu", "Wenjie Wang", "Chaochao Chen", "Xiaolin Zheng", "Tat-Seng Chua"], "title": "FOCoOp: Enhancing Out-of-Distribution Robustness in Federated Prompt Learning for Vision-Language Models", "categories": ["cs.CV"], "comment": "Accepted by ICML25", "summary": "Federated prompt learning (FPL) for vision-language models is a powerful\napproach to collaboratively adapt models across distributed clients while\npreserving data privacy. However, existing FPL approaches suffer from a\ntrade-off between performance and robustness, particularly in\nout-of-distribution (OOD) shifts, limiting their reliability in real-world\nscenarios. The inherent in-distribution (ID) data heterogeneity among different\nclients makes it more challenging to maintain this trade-off. To fill this gap,\nwe introduce a Federated OOD-aware Context Optimization (FOCoOp) framework,\nwhich captures diverse distributions among clients using ID global prompts,\nlocal prompts, and OOD prompts. Specifically, FOCoOp leverages three sets of\nprompts to create both class-level and distribution-level separations, which\nadapt to OOD shifts through bi-level distributionally robust optimization.\nAdditionally, FOCoOp improves the discrimination consistency among clients,\ni.e., calibrating global prompts, seemingly OOD prompts, and OOD prompts by\nsemi-unbalanced optimal transport. The extensive experiments on real-world\ndatasets demonstrate that FOCoOp effectively captures decentralized\nheterogeneous distributions and enhances robustness of different OOD shifts.\nThe project is available at GitHub.", "AI": {"tldr": "FOCoOp is a federated OOD-aware framework that improves robustness in vision-language models by using ID global, local, and OOD prompts, addressing performance-robustness trade-offs in federated prompt learning.", "motivation": "Existing federated prompt learning approaches struggle with balancing performance and robustness, especially under OOD shifts, due to data heterogeneity among clients.", "method": "FOCoOp employs ID global, local, and OOD prompts for class- and distribution-level separations, using bi-level robust optimization and semi-unbalanced optimal transport for calibration.", "result": "Experiments show FOCoOp effectively captures heterogeneous distributions and enhances robustness against OOD shifts.", "conclusion": "FOCoOp successfully addresses the trade-off in federated prompt learning, improving reliability in real-world scenarios."}}
{"id": "2506.15719", "pdf": "https://arxiv.org/pdf/2506.15719", "abs": "https://arxiv.org/abs/2506.15719", "authors": ["Manal Rahal", "Bestoun S. Ahmed", "Roger Renstrom", "Robert Stener", "Albrecht Wurtz"], "title": "Data-Driven Heat Pump Management: Combining Machine Learning with Anomaly Detection for Residential Hot Water Systems", "categories": ["cs.LG"], "comment": "33 pages accepted in Neural Networks and Applications", "summary": "Heat pumps (HPs) have emerged as a cost-effective and clean technology for\nsustainable energy systems, but their efficiency in producing hot water remains\nrestricted by conventional threshold-based control methods. Although machine\nlearning (ML) has been successfully implemented for various HP applications,\noptimization of household hot water demand forecasting remains understudied.\nThis paper addresses this problem by introducing a novel approach that combines\npredictive ML with anomaly detection to create adaptive hot water production\nstrategies based on household-specific consumption patterns. Our key\ncontributions include: (1) a composite approach combining ML and isolation\nforest (iForest) to forecast household demand for hot water and steer\nresponsive HP operations; (2) multi-step feature selection with advanced\ntime-series analysis to capture complex usage patterns; (3) application and\ntuning of three ML models: Light Gradient Boosting Machine (LightGBM), Long\nShort-Term Memory (LSTM), and Bi-directional LSTM with the self-attention\nmechanism on data from different types of real HP installations; and (4)\nexperimental validation on six real household installations. Our experiments\nshow that the best-performing model LightGBM achieves superior performance,\nwith RMSE improvements of up to 9.37\\% compared to LSTM variants with $R^2$\nvalues between 0.748-0.983. For anomaly detection, our iForest implementation\nachieved an F1-score of 0.87 with a false alarm rate of only 5.2\\%,\ndemonstrating strong generalization capabilities across different household\ntypes and consumption patterns, making it suitable for real-world HP\ndeployments.", "AI": {"tldr": "The paper introduces a machine learning (ML) approach combining predictive ML and anomaly detection to optimize heat pump (HP) efficiency for household hot water production. Key contributions include demand forecasting, feature selection, ML model tuning, and experimental validation, with LightGBM outperforming other models.", "motivation": "Heat pumps are cost-effective and clean but limited by conventional control methods. ML optimization for household hot water demand forecasting is understudied.", "method": "Combines predictive ML (LightGBM, LSTM, Bi-LSTM) with isolation forest (iForest) for demand forecasting and anomaly detection. Uses multi-step feature selection and time-series analysis.", "result": "LightGBM achieved the best performance (RMSE improvements up to 9.37%, R\u00b2 0.748-0.983). iForest achieved an F1-score of 0.87 with a 5.2% false alarm rate.", "conclusion": "The approach demonstrates strong generalization and suitability for real-world HP deployments, improving efficiency and adaptability."}}
{"id": "2506.17085", "pdf": "https://arxiv.org/pdf/2506.17085", "abs": "https://arxiv.org/abs/2506.17085", "authors": ["Fabian Neuhaus"], "title": "Dispositions and Roles of Generically Dependent Entities", "categories": ["cs.AI"], "comment": null, "summary": "BFO 2020 does not support functions, dispositions, and roles of generically\ndependent continuants (like software or datasets). In this paper, we argue that\nthis is a severe limitation, which prevents, for example, the adequate\nrepresentation of the functions of computer models or the various roles of\ndatasets during the execution of these models. We discuss the aspects of BFO\n2020 that prevent the representation of realizable entities of generically\ndependent continuants. Two approaches to address the issue are presented: (a)\nthe use of defined classes and (b) a proposal of changes that allow BFO to\nsupport functions, dispositions, and roles of generically dependent\ncontinuants.", "AI": {"tldr": "The paper critiques BFO 2020 for lacking support for functions, dispositions, and roles of generically dependent continuants (e.g., software, datasets) and proposes two solutions.", "motivation": "BFO 2020's inability to represent these aspects limits its utility, especially for modeling functions of computer models or roles of datasets during execution.", "method": "The paper analyzes BFO 2020's limitations and presents two approaches: using defined classes and proposing changes to BFO.", "result": "The analysis highlights the issue and offers potential solutions to enhance BFO's capability.", "conclusion": "Addressing these limitations would improve BFO's applicability for representing generically dependent continuants."}}
{"id": "2506.16476", "pdf": "https://arxiv.org/pdf/2506.16476", "abs": "https://arxiv.org/abs/2506.16476", "authors": ["Saad Almohaimeed", "Saleh Almohaimeed", "Damla Turgut", "Ladislau B\u00f6l\u00f6ni"], "title": "Towards Generalizable Generic Harmful Speech Datasets for Implicit Hate Speech Detection", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "Implicit hate speech has recently emerged as a critical challenge for social\nmedia platforms. While much of the research has traditionally focused on\nharmful speech in general, the need for generalizable techniques to detect\nveiled and subtle forms of hate has become increasingly pressing. Based on\nlexicon analysis, we hypothesize that implicit hate speech is already present\nin publicly available harmful speech datasets but may not have been explicitly\nrecognized or labeled by annotators. Additionally, crowdsourced datasets are\nprone to mislabeling due to the complexity of the task and often influenced by\nannotators' subjective interpretations. In this paper, we propose an approach\nto address the detection of implicit hate speech and enhance generalizability\nacross diverse datasets by leveraging existing harmful speech datasets. Our\nmethod comprises three key components: influential sample identification,\nreannotation, and augmentation using Llama-3 70B and GPT-4o. Experimental\nresults demonstrate the effectiveness of our approach in improving implicit\nhate detection, achieving a +12.9-point F1 score improvement compared to the\nbaseline.", "AI": {"tldr": "The paper addresses the challenge of detecting implicit hate speech in social media by leveraging existing harmful speech datasets. It proposes a method involving influential sample identification, reannotation, and augmentation using advanced models, achieving a significant F1 score improvement.", "motivation": "Implicit hate speech is a growing issue on social media, often overlooked in traditional harmful speech datasets due to its subtle nature and annotator subjectivity. The paper aims to improve detection by utilizing existing datasets more effectively.", "method": "The approach includes three steps: identifying influential samples, reannotating them, and augmenting the dataset using Llama-3 70B and GPT-4o to enhance generalizability.", "result": "The method improves implicit hate speech detection, achieving a +12.9-point F1 score increase over the baseline.", "conclusion": "The proposed approach effectively addresses the detection of implicit hate speech, demonstrating significant performance improvements and potential for broader application."}}
{"id": "2502.05142", "pdf": "https://arxiv.org/pdf/2502.05142", "abs": "https://arxiv.org/abs/2502.05142", "authors": ["Zefan Yang", "Xuanang Xu", "Jiajin Zhang", "Ge Wang", "Mannudeep K. Kalra", "Pingkun Yan"], "title": "Chest X-ray Foundation Model with Global and Local Representations Integration", "categories": ["eess.IV", "cs.CV"], "comment": "Accepted by IEEE Transactions on Medical Imaging (TMI)", "summary": "Chest X-ray (CXR) is the most frequently ordered imaging test, supporting\ndiverse clinical tasks from thoracic disease detection to postoperative\nmonitoring. However, task-specific classification models are limited in scope,\nrequire costly labeled data, and lack generalizability to out-of-distribution\ndatasets. To address these challenges, we introduce CheXFound, a\nself-supervised vision foundation model that learns robust CXR representations\nand generalizes effectively across a wide range of downstream tasks. We\npretrain CheXFound on a curated CXR-1M dataset, comprising over one million\nunique CXRs from publicly available sources. We propose a Global and Local\nRepresentations Integration (GLoRI) module for downstream adaptations, by\nincorporating disease-specific local features with global image features for\nenhanced performance in multilabel classification. Our experimental results\nshow that CheXFound outperforms state-of-the-art models in classifying 40\ndisease findings across different prevalence levels on the CXR-LT 24 dataset\nand exhibits superior label efficiency on downstream tasks with limited\ntraining data. Additionally, CheXFound achieved significant improvements on new\ntasks with out-of-distribution datasets, including opportunistic cardiovascular\ndisease risk estimation and mortality prediction. These results highlight\nCheXFound's strong generalization capabilities, enabling diverse adaptations\nwith improved label efficiency. The project source code is publicly available\nat https://github.com/RPIDIAL/CheXFound.", "AI": {"tldr": "CheXFound is a self-supervised vision foundation model for chest X-rays, improving generalization and label efficiency across diverse tasks.", "motivation": "Task-specific CXR models are limited in scope, require costly labeled data, and lack generalizability. CheXFound addresses these challenges.", "method": "Pretrained on CXR-1M dataset, CheXFound uses a GLoRI module to integrate global and local features for multilabel classification.", "result": "Outperforms state-of-the-art models on CXR-LT 24 dataset, excels in label efficiency, and generalizes well to out-of-distribution tasks.", "conclusion": "CheXFound demonstrates strong generalization and efficiency, enabling diverse clinical applications with limited labeled data."}}
{"id": "2506.16262", "pdf": "https://arxiv.org/pdf/2506.16262", "abs": "https://arxiv.org/abs/2506.16262", "authors": ["Weeyoung Kwon", "Jeahun Sung", "Minkyu Jeon", "Chanho Eom", "Jihyong Oh"], "title": "R3eVision: A Survey on Robust Rendering, Restoration, and Enhancement for 3D Low-Level Vision", "categories": ["cs.CV"], "comment": "Please visit our project page at\n  https://github.com/CMLab-Korea/Awesome-3D-Low-Level-Vision", "summary": "Neural rendering methods such as Neural Radiance Fields (NeRF) and 3D\nGaussian Splatting (3DGS) have achieved significant progress in photorealistic\n3D scene reconstruction and novel view synthesis. However, most existing models\nassume clean and high-resolution (HR) multi-view inputs, which limits their\nrobustness under real-world degradations such as noise, blur, low-resolution\n(LR), and weather-induced artifacts. To address these limitations, the emerging\nfield of 3D Low-Level Vision (3D LLV) extends classical 2D Low-Level Vision\ntasks including super-resolution (SR), deblurring, weather degradation removal,\nrestoration, and enhancement into the 3D spatial domain. This survey, referred\nto as R\\textsuperscript{3}eVision, provides a comprehensive overview of robust\nrendering, restoration, and enhancement for 3D LLV by formalizing the\ndegradation-aware rendering problem and identifying key challenges related to\nspatio-temporal consistency and ill-posed optimization. Recent methods that\nintegrate LLV into neural rendering frameworks are categorized to illustrate\nhow they enable high-fidelity 3D reconstruction under adverse conditions.\nApplication domains such as autonomous driving, AR/VR, and robotics are also\ndiscussed, where reliable 3D perception from degraded inputs is critical. By\nreviewing representative methods, datasets, and evaluation protocols, this work\npositions 3D LLV as a fundamental direction for robust 3D content generation\nand scene-level reconstruction in real-world environments.", "AI": {"tldr": "A survey on 3D Low-Level Vision (3D LLV) addressing robust rendering, restoration, and enhancement for degraded inputs in neural rendering methods like NeRF and 3DGS.", "motivation": "Existing neural rendering models assume clean, high-resolution inputs, limiting robustness under real-world degradations like noise, blur, and weather artifacts.", "method": "Formalizes degradation-aware rendering, identifies challenges (spatio-temporal consistency, ill-posed optimization), and categorizes recent methods integrating LLV into neural rendering.", "result": "Highlights advancements enabling high-fidelity 3D reconstruction under adverse conditions, with applications in autonomous driving, AR/VR, and robotics.", "conclusion": "Positions 3D LLV as a key direction for robust 3D content generation and scene reconstruction in real-world environments."}}
{"id": "2506.15720", "pdf": "https://arxiv.org/pdf/2506.15720", "abs": "https://arxiv.org/abs/2506.15720", "authors": ["Juntae Lee", "Munawar Hayat", "Sungrack Yun"], "title": "Tripartite Weight-Space Ensemble for Few-Shot Class-Incremental Learning", "categories": ["cs.LG", "cs.CV"], "comment": "Accepted at CVPR 2025", "summary": "Few-shot class incremental learning (FSCIL) enables the continual learning of\nnew concepts with only a few training examples. In FSCIL, the model undergoes\nsubstantial updates, making it prone to forgetting previous concepts and\noverfitting to the limited new examples. Most recent trend is typically to\ndisentangle the learning of the representation from the classification head of\nthe model. A well-generalized feature extractor on the base classes (many\nexamples and many classes) is learned, and then fixed during incremental\nlearning. Arguing that the fixed feature extractor restricts the model's\nadaptability to new classes, we introduce a novel FSCIL method to effectively\naddress catastrophic forgetting and overfitting issues. Our method enables to\nseamlessly update the entire model with a few examples. We mainly propose a\ntripartite weight-space ensemble (Tri-WE). Tri-WE interpolates the base,\nimmediately previous, and current models in weight-space, especially for the\nclassification heads of the models. Then, it collaboratively maintains\nknowledge from the base and previous models. In addition, we recognize the\nchallenges of distilling generalized representations from the previous model\nfrom scarce data. Hence, we suggest a regularization loss term using amplified\ndata knowledge distillation. Simply intermixing the few-shot data, we can\nproduce richer data enabling the distillation of critical knowledge from the\nprevious model. Consequently, we attain state-of-the-art results on the\nminiImageNet, CUB200, and CIFAR100 datasets.", "AI": {"tldr": "A novel FSCIL method, Tri-WE, addresses catastrophic forgetting and overfitting by interpolating base, previous, and current models in weight-space and using amplified data distillation.", "motivation": "Fixed feature extractors in FSCIL limit adaptability to new classes, causing forgetting and overfitting.", "method": "Tripartite weight-space ensemble (Tri-WE) interpolates models in weight-space, and amplified data distillation regularizes representation learning.", "result": "Achieves state-of-the-art performance on miniImageNet, CUB200, and CIFAR100.", "conclusion": "Tri-WE effectively updates models with few examples while mitigating forgetting and overfitting."}}
{"id": "2506.17104", "pdf": "https://arxiv.org/pdf/2506.17104", "abs": "https://arxiv.org/abs/2506.17104", "authors": ["Chuxue Cao", "Mengze Li", "Juntao Dai", "Jinluan Yang", "Zijian Zhao", "Shengyu Zhang", "Weijie Shi", "Chengzhong Liu", "Sirui Han", "Yike Guo"], "title": "Towards Advanced Mathematical Reasoning for LLMs via First-Order Logic Theorem Proving", "categories": ["cs.AI", "cs.CL", "cs.LO"], "comment": null, "summary": "Large language models (LLMs) have shown promising first-order logic (FOL)\nreasoning capabilities with applications in various areas. However, their\neffectiveness in complex mathematical reasoning involving multi-step FOL\ndeductions is still under-researched. While LLMs perform competitively on\nestablished mathematical reasoning benchmarks, they struggle with multi-step\nFOL tasks, as demonstrated by Deepseek-Prover-V2-7B's low accuracy (4.2%) on\nour proposed theorem proving dataset. This issue arises from the limited\nexploration of diverse proof strategies and the potential for early reasoning\nmistakes to undermine entire proofs. To address these issues, we propose DREAM,\na self-adaptive solution that enhances the Diversity and REAsonability of LLMs'\ngeneration strategies. DREAM incorporates an Axiom-Driven Strategy\nDiversification mechanism to promote varied strategic outcomes and a\nSub-Proposition Error Feedback to help LLMs reflect on and correct their\nproofs. Our contributions include pioneering advancements in LLMs' mathematical\nreasoning through FOL theorem proving, introducing a novel inference stage\nsolution that improves performance by 0.6% to 6.4%, and providing a curated\ndataset of 447 mathematical theorems in Lean 4 format for evaluation.", "AI": {"tldr": "DREAM enhances LLMs' multi-step FOL reasoning by diversifying strategies and correcting errors, improving performance by 0.6%-6.4%.", "motivation": "LLMs struggle with multi-step FOL reasoning due to limited proof diversity and early errors, as shown by low accuracy (4.2%) on theorem proving tasks.", "method": "DREAM introduces Axiom-Driven Strategy Diversification and Sub-Proposition Error Feedback to improve reasoning diversity and correctness.", "result": "DREAM improves LLM performance by 0.6% to 6.4% on theorem proving, with a dataset of 447 Lean 4 theorems for evaluation.", "conclusion": "DREAM advances LLMs' mathematical reasoning by addressing diversity and error correction, offering a scalable solution for complex FOL tasks."}}
{"id": "2506.16502", "pdf": "https://arxiv.org/pdf/2506.16502", "abs": "https://arxiv.org/abs/2506.16502", "authors": ["Soumya Suvra Ghosal", "Vaibhav Singh", "Akash Ghosh", "Soumyabrata Pal", "Subhadip Baidya", "Sriparna Saha", "Dinesh Manocha"], "title": "Relic: Enhancing Reward Model Generalization for Low-Resource Indic Languages with Few-Shot Examples", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Reward models are essential for aligning large language models (LLMs) with\nhuman preferences. However, most open-source multilingual reward models are\nprimarily trained on preference datasets in high-resource languages, resulting\nin unreliable reward signals for low-resource Indic languages. Collecting\nlarge-scale, high-quality preference data for these languages is prohibitively\nexpensive, making preference-based training approaches impractical. To address\nthis challenge, we propose RELIC, a novel in-context learning framework for\nreward modeling in low-resource Indic languages. RELIC trains a retriever with\na pairwise ranking objective to select in-context examples from auxiliary\nhigh-resource languages that most effectively highlight the distinction between\npreferred and less-preferred responses. Extensive experiments on three\npreference datasets- PKU-SafeRLHF, WebGPT, and HH-RLHF-using state-of-the-art\nopen-source reward models demonstrate that RELIC significantly improves reward\nmodel accuracy for low-resource Indic languages, consistently outperforming\nexisting example selection methods. For example, on Bodo-a low-resource Indic\nlanguage-using a LLaMA-3.2-3B reward model, RELIC achieves a 12.81% and 10.13%\nimprovement in accuracy over zero-shot prompting and state-of-the-art example\nselection method, respectively.", "AI": {"tldr": "RELIC is a novel in-context learning framework for reward modeling in low-resource Indic languages, improving accuracy by selecting effective examples from high-resource languages.", "motivation": "Existing multilingual reward models are unreliable for low-resource Indic languages due to lack of preference data, making traditional training impractical.", "method": "RELIC uses a retriever trained with a pairwise ranking objective to select in-context examples from high-resource languages that highlight distinctions between responses.", "result": "RELIC improves reward model accuracy for low-resource Indic languages, outperforming zero-shot and state-of-the-art methods by up to 12.81%.", "conclusion": "RELIC effectively addresses the challenge of reward modeling in low-resource languages by leveraging in-context learning."}}
{"id": "2503.16010", "pdf": "https://arxiv.org/pdf/2503.16010", "abs": "https://arxiv.org/abs/2503.16010", "authors": ["Claudio Fantasia", "Luca Calatroni", "Xavier Descombes", "Rim Rekik"], "title": "Patch-based learning of adaptive Total Variation parameter maps for blind image denoising", "categories": ["eess.IV", "cs.LG", "cs.NA", "math.NA"], "comment": null, "summary": "We consider a patch-based learning approach defined in terms of neural\nnetworks to estimate spatially adaptive regularisation parameter maps for image\ndenoising with weighted Total Variation (TV) and test it to situations when the\nnoise distribution is unknown. As an example, we consider situations where\nnoise could be either Gaussian or Poisson and perform preliminary model\nselection by a standard binary classification network. Then, we define a\npatch-based approach where at each image pixel an optimal weighting between TV\nregularisation and the corresponding data fidelity is learned in a supervised\nway using reference natural image patches upon optimisation of SSIM and in a\nsliding window fashion. Extensive numerical results are reported for both noise\nmodels, showing significant improvement w.r.t. results obtained by means of\noptimal scalar regularisation.", "AI": {"tldr": "A patch-based neural network approach learns adaptive regularization for image denoising with weighted TV, outperforming scalar regularization for unknown noise distributions.", "motivation": "To address image denoising when noise distribution (Gaussian or Poisson) is unknown, requiring adaptive regularization.", "method": "Uses a binary classification network for noise model selection, then learns patch-based optimal TV weights supervisedly via SSIM optimization.", "result": "Significant improvement over scalar regularization for both Gaussian and Poisson noise models.", "conclusion": "The adaptive patch-based approach effectively handles unknown noise distributions, enhancing denoising performance."}}
{"id": "2506.16297", "pdf": "https://arxiv.org/pdf/2506.16297", "abs": "https://arxiv.org/abs/2506.16297", "authors": ["Heng Zhang", "Zikang Wan", "Danilo Vasconcellos Vargas"], "title": "SycnMapV2: Robust and Adaptive Unsupervised Segmentation", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": null, "summary": "Human vision excels at segmenting visual cues without the need for explicit\ntraining, and it remains remarkably robust even as noise severity increases. In\ncontrast, existing AI algorithms struggle to maintain accuracy under similar\nconditions. Here, we present SyncMapV2, the first to solve unsupervised\nsegmentation with state-of-the-art robustness. SyncMapV2 exhibits a minimal\ndrop in mIoU, only 0.01%, under digital corruption, compared to a 23.8% drop\nobserved in SOTA methods.This superior performance extends across various types\nof corruption: noise (7.3% vs. 37.7%), weather (7.5% vs. 33.8%), and blur (7.0%\nvs. 29.5%). Notably, SyncMapV2 accomplishes this without any robust training,\nsupervision, or loss functions. It is based on a learning paradigm that uses\nself-organizing dynamical equations combined with concepts from random\nnetworks. Moreover,unlike conventional methods that require re-initialization\nfor each new input, SyncMapV2 adapts online, mimicking the continuous\nadaptability of human vision. Thus, we go beyond the accurate and robust\nresults, and present the first algorithm that can do all the above online,\nadapting to input rather than re-initializing. In adaptability tests, SyncMapV2\ndemonstrates near-zero performance degradation, which motivates and fosters a\nnew generation of robust and adaptive intelligence in the near future.", "AI": {"tldr": "SyncMapV2 is a novel unsupervised segmentation algorithm with exceptional robustness, outperforming SOTA methods under various corruptions without requiring robust training or supervision.", "motivation": "Human vision's robustness and adaptability inspire the need for AI algorithms that can segment visual cues accurately under noise without explicit training.", "method": "SyncMapV2 uses self-organizing dynamical equations and random network concepts, enabling online adaptation without re-initialization for each input.", "result": "SyncMapV2 shows minimal performance drop (0.01% mIoU) under digital corruption, significantly outperforming SOTA methods in noise, weather, and blur scenarios.", "conclusion": "SyncMapV2 represents a breakthrough in robust, adaptive AI, paving the way for future intelligent systems that mimic human vision's continuous adaptability."}}
{"id": "2506.15721", "pdf": "https://arxiv.org/pdf/2506.15721", "abs": "https://arxiv.org/abs/2506.15721", "authors": ["Junqi Gao", "Zhichang Guo", "Dazhi Zhang", "Dong Li", "Runze Liu", "Pengfei Li", "Kai Tian", "Biqing Qi"], "title": "Bohdi: Heterogeneous LLM Fusion with Automatic Data Exploration", "categories": ["cs.LG"], "comment": null, "summary": "Heterogeneous Large Language Model (LLM) fusion integrates the strengths of\nmultiple source LLMs with different architectures into a target LLM with low\ncomputational overhead. While promising, existing methods suffer from two major\nlimitations: 1) reliance on real data from limited domain for knowledge fusion,\npreventing the target LLM from fully acquiring knowledge across diverse\ndomains, and 2) fixed data allocation proportions across domains, failing to\ndynamically adjust according to the target LLM's varying capabilities across\ndomains, leading to a capability imbalance. To overcome these limitations, we\npropose Bohdi, a synthetic-data-only heterogeneous LLM fusion framework.\nThrough the organization of knowledge domains into a hierarchical tree\nstructure, Bohdi enables automatic domain exploration and multi-domain data\ngeneration through multi-model collaboration, thereby comprehensively\nextracting knowledge from source LLMs. By formalizing domain expansion and data\nsampling proportion allocation on the knowledge tree as a Hierarchical\nMulti-Armed Bandit problem, Bohdi leverages the designed DynaBranches mechanism\nto adaptively adjust sampling proportions based on the target LLM's performance\nfeedback across domains. Integrated with our proposed Introspection-Rebirth\n(IR) mechanism, DynaBranches dynamically tracks capability shifts during target\nLLM's updates via Sliding Window Binomial Likelihood Ratio Testing (SWBLRT),\nfurther enhancing its online adaptation capability. Comparative experimental\nresults on a comprehensive suite of benchmarks demonstrate that Bohdi\nsignificantly outperforms existing baselines on multiple target LLMs, exhibits\nhigher data efficiency, and virtually eliminates the imbalance in the target\nLLM's capabilities. Our code is available at\nhttps://github.com/gjq100/Bohdi.git.", "AI": {"tldr": "Bohdi is a synthetic-data-only framework for heterogeneous LLM fusion, addressing limitations of existing methods by enabling dynamic domain exploration and adaptive data sampling.", "motivation": "Existing methods for LLM fusion rely on limited real data and fixed domain allocations, leading to incomplete knowledge acquisition and capability imbalance.", "method": "Bohdi organizes knowledge domains hierarchically, uses multi-model collaboration for data generation, and adapts sampling via DynaBranches and IR mechanisms.", "result": "Bohdi outperforms baselines, shows higher data efficiency, and balances capabilities across domains.", "conclusion": "Bohdi effectively addresses fusion challenges, offering a scalable and adaptive solution for heterogeneous LLM integration."}}
{"id": "2506.17111", "pdf": "https://arxiv.org/pdf/2506.17111", "abs": "https://arxiv.org/abs/2506.17111", "authors": ["Lina Berrayana", "Sean Rooney", "Luis Garc\u00e9s-Erice", "Ioana Giurgiu"], "title": "Are Bias Evaluation Methods Biased ?", "categories": ["cs.AI", "cs.CL"], "comment": "Accepted to ACL 2025 Workshop GEM", "summary": "The creation of benchmarks to evaluate the safety of Large Language Models is\none of the key activities within the trusted AI community. These benchmarks\nallow models to be compared for different aspects of safety such as toxicity,\nbias, harmful behavior etc. Independent benchmarks adopt different approaches\nwith distinct data sets and evaluation methods. We investigate how robust such\nbenchmarks are by using different approaches to rank a set of representative\nmodels for bias and compare how similar are the overall rankings. We show that\ndifferent but widely used bias evaluations methods result in disparate model\nrankings. We conclude with recommendations for the community in the usage of\nsuch benchmarks.", "AI": {"tldr": "The paper examines the robustness of benchmarks for evaluating bias in Large Language Models (LLMs), showing that different evaluation methods yield inconsistent model rankings.", "motivation": "To assess the reliability of independent benchmarks used for evaluating LLM safety, particularly bias, given their varied approaches and datasets.", "method": "Investigates robustness by comparing rankings of representative models for bias using different evaluation methods.", "result": "Different widely used bias evaluation methods produce disparate model rankings.", "conclusion": "Recommends cautious usage of such benchmarks due to their inconsistent results."}}
{"id": "2506.16584", "pdf": "https://arxiv.org/pdf/2506.16584", "abs": "https://arxiv.org/abs/2506.16584", "authors": ["Nadav Kunievsky", "James A. Evans"], "title": "Measuring (a Sufficient) World Model in LLMs: A Variance Decomposition Framework", "categories": ["cs.CL", "cs.AI", "cs.LG", "68T50, 68T05", "I.2.7; I.2.6; I.5.1"], "comment": null, "summary": "Understanding whether large language models (LLMs) possess a world model-a\nstructured understanding of the world that supports generalization beyond\nsurface-level patterns-is central to assessing their reliability, especially in\nhigh-stakes applications. We propose a formal framework for evaluating whether\nan LLM exhibits a sufficiently robust world model, defined as producing\nconsistent outputs across semantically equivalent prompts while distinguishing\nbetween prompts that express different intents. We introduce a new evaluation\napproach to measure this that decomposes model response variability into three\ncomponents: variability due to user purpose, user articulation, and model\ninstability. An LLM with a strong world model should attribute most of the\nvariability in its responses to changes in foundational purpose rather than\nsuperficial changes in articulation. This approach allows us to quantify how\nmuch of a model's behavior is semantically grounded rather than driven by model\ninstability or alternative wording. We apply this framework to evaluate LLMs\nacross diverse domains. Our results show how larger models attribute a greater\nshare of output variability to changes in user purpose, indicating a more\nrobust world model. This improvement is not uniform, however: larger models do\nnot consistently outperform smaller ones across all domains, and their\nadvantage in robustness is often modest. These findings highlight the\nimportance of moving beyond accuracy-based benchmarks toward semantic\ndiagnostics that more directly assess the structure and stability of a model's\ninternal understanding of the world.", "AI": {"tldr": "The paper proposes a framework to evaluate if LLMs have a robust world model by analyzing response variability across semantically equivalent prompts. Larger models show more robustness but not uniformly across domains.", "motivation": "Assessing LLM reliability in high-stakes applications requires understanding if they possess a structured world model for generalization beyond surface patterns.", "method": "Introduces an evaluation approach decomposing response variability into user purpose, articulation, and model instability to measure semantic grounding.", "result": "Larger models attribute more variability to user purpose, indicating a stronger world model, though improvements are modest and not uniform across domains.", "conclusion": "Semantic diagnostics are crucial for assessing LLM world models, moving beyond accuracy benchmarks to evaluate internal understanding stability."}}
{"id": "2505.16028", "pdf": "https://arxiv.org/pdf/2505.16028", "abs": "https://arxiv.org/abs/2505.16028", "authors": ["Shuvashis Sarker", "Shamim Rahim Refat", "Faika Fairuj Preotee", "Tanvir Rouf Shawon", "Raihan Tanvir"], "title": "Comprehensive Lung Disease Detection Using Deep Learning Models and Hybrid Chest X-ray Data with Explainable AI", "categories": ["eess.IV", "cs.CV"], "comment": "Accepted for publication in 2024 27th International Conference on\n  Computer and Information Technology (ICCIT)", "summary": "Advanced diagnostic instruments are crucial for the accurate detection and\ntreatment of lung diseases, which affect millions of individuals globally. This\nstudy examines the effectiveness of deep learning and transfer learning models\nusing a hybrid dataset, created by merging four individual datasets from\nBangladesh and global sources. The hybrid dataset significantly enhances model\naccuracy and generalizability, particularly in detecting COVID-19, pneumonia,\nlung opacity, and normal lung conditions from chest X-ray images. A range of\nmodels, including CNN, VGG16, VGG19, InceptionV3, Xception, ResNet50V2,\nInceptionResNetV2, MobileNetV2, and DenseNet121, were applied to both\nindividual and hybrid datasets. The results showed superior performance on the\nhybrid dataset, with VGG16, Xception, ResNet50V2, and DenseNet121 each\nachieving an accuracy of 99%. This consistent performance across the hybrid\ndataset highlights the robustness of these models in handling diverse data\nwhile maintaining high accuracy. To understand the models implicit behavior,\nexplainable AI techniques were employed to illuminate their black-box nature.\nSpecifically, LIME was used to enhance the interpretability of model\npredictions, especially in cases of misclassification, contributing to the\ndevelopment of reliable and interpretable AI-driven solutions for medical\nimaging.", "AI": {"tldr": "Deep learning and transfer learning models, tested on a hybrid lung X-ray dataset, achieved 99% accuracy in detecting lung conditions, with explainable AI techniques like LIME enhancing interpretability.", "motivation": "To improve the accuracy and generalizability of lung disease detection using AI, addressing the global impact of lung diseases.", "method": "Applied CNN, VGG16, VGG19, InceptionV3, Xception, ResNet50V2, InceptionResNetV2, MobileNetV2, and DenseNet121 to individual and hybrid datasets, using explainable AI (LIME) for interpretability.", "result": "Hybrid dataset improved model accuracy, with VGG16, Xception, ResNet50V2, and DenseNet121 achieving 99% accuracy.", "conclusion": "Hybrid datasets and explainable AI techniques enhance the reliability and interpretability of AI-driven medical imaging solutions."}}
{"id": "2506.16318", "pdf": "https://arxiv.org/pdf/2506.16318", "abs": "https://arxiv.org/abs/2506.16318", "authors": ["Carmelo Scribano", "Elena Govi", "Paolo bertellini", "Simone Parisi", "Giorgia Franchini", "Marko Bertogna"], "title": "Segment Anything for Satellite Imagery: A Strong Baseline and a Regional Dataset for Automatic Field Delineation", "categories": ["cs.CV", "cs.AI"], "comment": "Acceptet at ICIAP 2025", "summary": "Accurate mapping of agricultural field boundaries is essential for the\nefficient operation of agriculture. Automatic extraction from high-resolution\nsatellite imagery, supported by computer vision techniques, can avoid costly\nground surveys. In this paper, we present a pipeline for field delineation\nbased on the Segment Anything Model (SAM), introducing a fine-tuning strategy\nto adapt SAM to this task. In addition to using published datasets, we describe\na method for acquiring a complementary regional dataset that covers areas\nbeyond current sources. Extensive experiments assess segmentation accuracy and\nevaluate the generalization capabilities. Our approach provides a robust\nbaseline for automated field delineation. The new regional dataset, known as\nERAS, is now publicly available.", "AI": {"tldr": "A pipeline for agricultural field boundary mapping using a fine-tuned Segment Anything Model (SAM) and a new regional dataset (ERAS).", "motivation": "Accurate field boundary mapping is crucial for efficient agriculture, and automated methods can reduce reliance on costly ground surveys.", "method": "Fine-tuning SAM for field delineation and creating a complementary regional dataset (ERAS) to extend coverage.", "result": "The approach offers robust automated field delineation, with the ERAS dataset now publicly available.", "conclusion": "The method provides a strong baseline for automated field boundary mapping, supported by the new ERAS dataset."}}
{"id": "2506.15722", "pdf": "https://arxiv.org/pdf/2506.15722", "abs": "https://arxiv.org/abs/2506.15722", "authors": ["Wangzhi Zhan", "Jianpeng Chen", "Dongqi Fu", "Dawei Zhou"], "title": "UniMate: A Unified Model for Mechanical Metamaterial Generation, Property Prediction, and Condition Confirmation", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Metamaterials are artificial materials that are designed to meet unseen\nproperties in nature, such as ultra-stiffness and negative materials indices.\nIn mechanical metamaterial design, three key modalities are typically involved,\ni.e., 3D topology, density condition, and mechanical property. Real-world\ncomplex application scenarios place the demanding requirements on machine\nlearning models to consider all three modalities together. However, a\ncomprehensive literature review indicates that most existing works only\nconsider two modalities, e.g., predicting mechanical properties given the 3D\ntopology or generating 3D topology given the required properties. Therefore,\nthere is still a significant gap for the state-of-the-art machine learning\nmodels capturing the whole. Hence, we propose a unified model named UNIMATE,\nwhich consists of a modality alignment module and a synergetic diffusion\ngeneration module. Experiments indicate that UNIMATE outperforms the other\nbaseline models in topology generation task, property prediction task, and\ncondition confirmation task by up to 80.2%, 5.1%, and 50.2%, respectively. We\nopensource our proposed UNIMATE model and corresponding results at\nhttps://github.com/wzhan24/UniMate.", "AI": {"tldr": "UNIMATE is a unified model for mechanical metamaterial design, addressing all three key modalities (3D topology, density condition, mechanical property) and outperforming baselines in tasks like topology generation and property prediction.", "motivation": "Existing machine learning models for mechanical metamaterials often only consider two of the three key modalities, leaving a gap for comprehensive solutions.", "method": "UNIMATE combines a modality alignment module and a synergetic diffusion generation module to integrate all three modalities.", "result": "UNIMATE outperforms baselines by up to 80.2% in topology generation, 5.1% in property prediction, and 50.2% in condition confirmation.", "conclusion": "UNIMATE bridges the gap in metamaterial design by unifying all three modalities, with open-sourced results for further research."}}
{"id": "2506.17114", "pdf": "https://arxiv.org/pdf/2506.17114", "abs": "https://arxiv.org/abs/2506.17114", "authors": ["Dadi Guo", "Jiayu Liu", "Zhiyuan Fan", "Zhitao He", "Haoran Li", "Yumeng Wang", "Yi R.", "Fung"], "title": "Mathematical Proof as a Litmus Test: Revealing Failure Modes of Advanced Large Reasoning Models", "categories": ["cs.AI"], "comment": null, "summary": "Large reasoning models (e.g., R1, o3) have demonstrated remarkable\nmathematical problem-solving abilities. However, the high reported accuracy of\nthese advanced models on popular datasets, reliance on purely numerical\nevaluation and potential benchmark leakage, often masks their true reasoning\nshortcomings. To address this, we propose leveraging the inherent rigor and\nmethodological complexity of mathematical proofs as a diagnostic tool to expose\nthese hidden failures. Specifically, we introduce the RFMDataset (Reveal\nFailure Modes), a collection of 200 diverse mathematical proof problems, and\nthoroughly evaluate advanced models' performance on it. Our in-depth analysis\nof their failures uncovers 10 fine-grained error types, which shows fundamental\nlimitations in current large reasoning models: 1) large reasoning models\ngrapple profoundly with mathematical proofs, with some generating entirely\ncorrect proofs for less than 20% of problems and failing even on basic ones; 2)\nmodels exhibit a diverse spectrum of reasoning failures, prominently\ndemonstrating the lack of guarantees for the correctness and rigor of\nsingle-step reasoning; and 3) models show hallucination and incompleteness\nduring the reasoning process. Our findings reveal that models' self-reflection\nis insufficient to resolve the current logical dilemmas, necessitating\nformalized and fine-grained logical training.", "AI": {"tldr": "The paper introduces the RFMDataset to evaluate large reasoning models' performance on mathematical proofs, revealing significant shortcomings like low correctness rates, diverse reasoning failures, and hallucinations.", "motivation": "To expose hidden reasoning failures in large models, which are often masked by high accuracy on numerical evaluations and potential benchmark leakage.", "method": "The authors create the RFMDataset with 200 diverse proof problems and analyze model performance, identifying 10 fine-grained error types.", "result": "Models struggle with proofs (some <20% correct), exhibit diverse reasoning failures, and lack guarantees for correctness or rigor in single-step reasoning.", "conclusion": "Current models' self-reflection is insufficient; formalized, fine-grained logical training is needed to address these limitations."}}
{"id": "2506.16594", "pdf": "https://arxiv.org/pdf/2506.16594", "abs": "https://arxiv.org/abs/2506.16594", "authors": ["Hanshu Rao", "Weisi Liu", "Haohan Wang", "I-Chan Huang", "Zhe He", "Xiaolei Huang"], "title": "A Scoping Review of Synthetic Data Generation for Biomedical Research and Applications", "categories": ["cs.CL"], "comment": null, "summary": "Synthetic data generation--mitigating data scarcity, privacy concerns, and\ndata quality challenges in biomedical fields--has been facilitated by rapid\nadvances of large language models (LLMs). This scoping review follows\nPRISMA-ScR guidelines and synthesizes 59 studies, published between 2020 and\n2025 and collected from PubMed, ACM, Web of Science, and Google Scholar. The\nreview systematically examines biomedical research and application trends in\nsynthetic data generation, emphasizing clinical applications, methodologies,\nand evaluations. Our analysis identifies data modalities of unstructured texts\n(78.0%), tabular data (13.6%), and multimodal sources (8.4%); generation\nmethods of prompting (72.9%), fine-tuning (22.0%) LLMs and specialized model\n(5.1%); and heterogeneous evaluations of intrinsic metrics (27.1%),\nhuman-in-the-loop assessments (55.9%), and LLM-based evaluations (13.6%). The\nanalysis addresses current limitations in what, where, and how health\nprofessionals can leverage synthetic data generation for biomedical domains.\nOur review also highlights challenges in adaption across clinical domains,\nresource and model accessibility, and evaluation standardizations.", "AI": {"tldr": "A scoping review of 59 studies (2020-2025) on synthetic data generation in biomedical fields, focusing on LLMs, methodologies, evaluations, and challenges.", "motivation": "Address data scarcity, privacy, and quality issues in biomedical research using synthetic data generated by LLMs.", "method": "Followed PRISMA-ScR guidelines to review studies from PubMed, ACM, Web of Science, and Google Scholar, analyzing trends in clinical applications, methods, and evaluations.", "result": "Identified data modalities (texts, tabular, multimodal), generation methods (prompting, fine-tuning, specialized models), and evaluation metrics (intrinsic, human-in-the-loop, LLM-based). Highlighted limitations and challenges in adoption.", "conclusion": "Synthetic data generation via LLMs shows promise but faces challenges in clinical adaptation, accessibility, and standardization."}}
{"id": "2506.13995", "pdf": "https://arxiv.org/pdf/2506.13995", "abs": "https://arxiv.org/abs/2506.13995", "authors": ["Menghua Xia", "Reimund Bayerlein", "Yanis Chemli", "Xiaofeng Liu", "Jinsong Ouyang", "Georges El Fakhri", "Ramsey D. Badawi", "Quanzheng Li", "Chi Liu"], "title": "DREAM: On hallucinations in AI-generated content for nuclear medicine imaging", "categories": ["eess.IV"], "comment": "12 pages, 7 figures", "summary": "Artificial intelligence-generated content (AIGC) has shown remarkable\nperformance in nuclear medicine imaging (NMI), offering cost-effective software\nsolutions for tasks such as image enhancement, motion correction, and\nattenuation correction. However, these advancements come with the risk of\nhallucinations, generating realistic yet factually incorrect content.\nHallucinations can misrepresent anatomical and functional information,\ncompromising diagnostic accuracy and clinical trust. This paper presents a\ncomprehensive perspective of hallucination-related challenges in AIGC for NMI,\nintroducing the DREAM report, which covers recommendations for definition,\nrepresentative examples, detection and evaluation metrics, underlying causes,\nand mitigation strategies. This position statement paper aims to initiate a\ncommon understanding for discussions and future research toward enhancing AIGC\napplications in NMI, thereby supporting their safe and effective deployment in\nclinical practice.", "AI": {"tldr": "The paper discusses the risks of hallucinations in AI-generated content (AIGC) for nuclear medicine imaging (NMI) and introduces the DREAM report to address these challenges.", "motivation": "To highlight the potential dangers of AI hallucinations in NMI, which can compromise diagnostic accuracy and clinical trust, and to propose solutions.", "method": "Introduces the DREAM report, providing recommendations for defining, detecting, evaluating, and mitigating hallucinations in AIGC for NMI.", "result": "A framework (DREAM report) is proposed to address hallucination-related challenges, aiming to improve AIGC reliability in NMI.", "conclusion": "The paper calls for a unified approach to tackle hallucinations in AIGC for NMI, ensuring safer and more effective clinical applications."}}
{"id": "2506.16319", "pdf": "https://arxiv.org/pdf/2506.16319", "abs": "https://arxiv.org/abs/2506.16319", "authors": ["Arpit Jadon", "Haoran Wang", "Phillip Thomas", "Michael Stanley", "S. Nathaniel Cibik", "Rachel Laurat", "Omar Maher", "Lukas Hoyer", "Ozan Unal", "Dengxin Dai"], "title": "RealDriveSim: A Realistic Multi-Modal Multi-Task Synthetic Dataset for Autonomous Driving", "categories": ["cs.CV"], "comment": "Accepted at the IEEE Intelligent Vehicles Symposium (IV) 2025", "summary": "As perception models continue to develop, the need for large-scale datasets\nincreases. However, data annotation remains far too expensive to effectively\nscale and meet the demand. Synthetic datasets provide a solution to boost model\nperformance with substantially reduced costs. However, current synthetic\ndatasets remain limited in their scope, realism, and are designed for specific\ntasks and applications. In this work, we present RealDriveSim, a realistic\nmulti-modal synthetic dataset for autonomous driving that not only supports\npopular 2D computer vision applications but also their LiDAR counterparts,\nproviding fine-grained annotations for up to 64 classes. We extensively\nevaluate our dataset for a wide range of applications and domains,\ndemonstrating state-of-the-art results compared to existing synthetic\nbenchmarks. The dataset is publicly available at\nhttps://realdrivesim.github.io/.", "AI": {"tldr": "RealDriveSim is a realistic multi-modal synthetic dataset for autonomous driving, supporting 2D and LiDAR applications with fine-grained annotations for 64 classes, outperforming existing benchmarks.", "motivation": "The high cost and limited scope of current synthetic datasets hinder scalable perception model development.", "method": "Developed RealDriveSim, a multi-modal synthetic dataset with fine-grained annotations for 64 classes, supporting 2D and LiDAR applications.", "result": "Demonstrated state-of-the-art performance across various applications and domains compared to existing synthetic benchmarks.", "conclusion": "RealDriveSim addresses scalability and realism gaps in synthetic datasets, offering a cost-effective solution for autonomous driving research."}}
{"id": "2506.15724", "pdf": "https://arxiv.org/pdf/2506.15724", "abs": "https://arxiv.org/abs/2506.15724", "authors": ["Kunxi Li", "Zhonghua Jiang", "Zhouzhou Shen", "Zhaode Wang", "Chengfei Lv", "Shengyu Zhang", "Fan Wu", "Fei Wu"], "title": "MadaKV: Adaptive Modality-Perception KV Cache Eviction for Efficient Multimodal Long-Context Inference", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": null, "summary": "This paper introduces MadaKV, a modality-adaptive key-value (KV) cache\neviction strategy designed to enhance the efficiency of multimodal large\nlanguage models (MLLMs) in long-context inference. In multimodal scenarios,\nattention heads exhibit varying preferences for different modalities, resulting\nin significant disparities in modality importance across attention heads.\nTraditional KV cache eviction methods, which are tailored for unimodal\nsettings, fail to capture modality-specific information, thereby yielding\nsuboptimal performance. MadaKV addresses these challenges through two key\ncomponents: modality preference adaptation and hierarchical compression\ncompensation. By dynamically sensing modality information within attention\nheads and adaptively retaining critical tokens, MadaKV achieves substantial\nreductions in KV cache memory footprint and model inference decoding latency\n(1.3 to 1.5 times improvement) while maintaining high accuracy across various\nmultimodal long-context tasks. Extensive experiments on representative MLLMs\nand the MileBench benchmark demonstrate the effectiveness of MadaKV compared to\nexisting KV cache eviction methods.", "AI": {"tldr": "MadaKV is a modality-adaptive KV cache eviction strategy for MLLMs, improving efficiency in long-context inference by addressing modality disparities and reducing memory/latency.", "motivation": "Traditional KV cache eviction methods are unimodal and fail to handle modality-specific information, leading to suboptimal performance in multimodal scenarios.", "method": "MadaKV uses modality preference adaptation and hierarchical compression compensation to dynamically retain critical tokens.", "result": "Achieves 1.3-1.5x improvement in memory footprint and decoding latency while maintaining accuracy.", "conclusion": "MadaKV outperforms existing methods, demonstrating effectiveness in multimodal long-context tasks."}}
{"id": "2506.17124", "pdf": "https://arxiv.org/pdf/2506.17124", "abs": "https://arxiv.org/abs/2506.17124", "authors": ["Josiah P. Hanna", "Nicholas E. Corrado"], "title": "When Can Model-Free Reinforcement Learning be Enough for Thinking?", "categories": ["cs.AI"], "comment": "15 pages, 3 figures", "summary": "Recent work on large language models has demonstrated the use of model-free\nreinforcement learning (RL) to train reasoning-like capabilities. The emergence\nof \"thinking\" through model-free RL is interesting as thinking actions neither\nproduce reward nor change the external world state to one where the agent is\nmore likely to get reward. This paper seeks to build a domain-independent\nunderstanding of when model-free RL will lead to \"thinking\" as a strategy for\nreward maximization. To build this understanding, we first introduce a\ntheoretical model which we call a \\textit{thought Markov decision process}\n(MDP). Thought MDPs minimally extend the classical MDP model to include an\nabstract notion of thought state and thought action. Using the thought MDP\nmodel, we prove the importance of policy initialization in determining whether\nor not thinking emerges and show formally that thought actions are equivalent\nto the agent choosing to perform a step of policy improvement before continuing\nto act. We then show that open-source LLMs satisfy the conditions that our\ntheory predicts are necessary for model-free RL to produce thinking-like\nbehavior. Finally, we hypothesize sufficient conditions that would enable\nthinking to be learned outside of language generation and introduce a toy\ndomain where a combination of multi-task pre-training and designated thought\nactions enable more data-efficient RL compared to non-thinking agents.", "AI": {"tldr": "The paper explores how model-free RL can lead to \"thinking\" behaviors in agents, introduces a theoretical \"thought MDP\" model, and validates findings with LLMs.", "motivation": "To understand when and why model-free RL results in \"thinking\" strategies for reward maximization, despite such actions not directly affecting rewards or world states.", "method": "Introduces a \"thought MDP\" model to abstractly represent thought states and actions, analyzes policy initialization's role, and tests conditions with LLMs.", "result": "Proves thought actions equate to policy improvement steps, shows LLMs meet necessary conditions for thinking-like behavior, and hypothesizes broader applicability.", "conclusion": "Model-free RL can produce thinking-like behavior under specific conditions, with potential applications beyond language generation."}}
{"id": "2506.16622", "pdf": "https://arxiv.org/pdf/2506.16622", "abs": "https://arxiv.org/abs/2506.16622", "authors": ["Jiaxin Pei", "Dustin Wright", "Isabelle Augenstin", "David Jurgens"], "title": "Modeling Public Perceptions of Science in Media", "categories": ["cs.CL", "cs.AI", "cs.CY", "cs.HC"], "comment": null, "summary": "Effectively engaging the public with science is vital for fostering trust and\nunderstanding in our scientific community. Yet, with an ever-growing volume of\ninformation, science communicators struggle to anticipate how audiences will\nperceive and interact with scientific news. In this paper, we introduce a\ncomputational framework that models public perception across twelve dimensions,\nsuch as newsworthiness, importance, and surprisingness. Using this framework,\nwe create a large-scale science news perception dataset with 10,489 annotations\nfrom 2,101 participants from diverse US and UK populations, providing valuable\ninsights into public responses to scientific information across domains. We\nfurther develop NLP models that predict public perception scores with a strong\nperformance. Leveraging the dataset and model, we examine public perception of\nscience from two perspectives: (1) Perception as an outcome: What factors\naffect the public perception of scientific information? (2) Perception as a\npredictor: Can we use the estimated perceptions to predict public engagement\nwith science? We find that individuals' frequency of science news consumption\nis the driver of perception, whereas demographic factors exert minimal\ninfluence. More importantly, through a large-scale analysis and carefully\ndesigned natural experiment on Reddit, we demonstrate that the estimated public\nperception of scientific information has direct connections with the final\nengagement pattern. Posts with more positive perception scores receive\nsignificantly more comments and upvotes, which is consistent across different\nscientific information and for the same science, but are framed differently.\nOverall, this research underscores the importance of nuanced perception\nmodeling in science communication, offering new pathways to predict public\ninterest and engagement with scientific content.", "AI": {"tldr": "The paper introduces a computational framework to model public perception of science news, using a large dataset and NLP models to analyze and predict engagement.", "motivation": "To address the challenge of anticipating how audiences perceive scientific news and improve science communication.", "method": "Developed a computational framework and NLP models to analyze public perception, using a dataset of 10,489 annotations from 2,101 participants.", "result": "Frequency of science news consumption drives perception, and estimated perception scores predict public engagement (e.g., comments, upvotes).", "conclusion": "Nuanced perception modeling is crucial for predicting public interest and engagement with scientific content."}}
{"id": "2506.15258", "pdf": "https://arxiv.org/pdf/2506.15258", "abs": "https://arxiv.org/abs/2506.15258", "authors": ["Jonghun Kim", "Gyeongdeok Jo", "Sinyoung Ra", "Hyunjin Park"], "title": "Privacy-Preserving Chest X-ray Classification in Latent Space with Homomorphically Encrypted Neural Inference", "categories": ["eess.IV", "cs.CV"], "comment": "11 pages, 5 figures", "summary": "Medical imaging data contain sensitive patient information requiring strong\nprivacy protection. Many analytical setups require data to be sent to a server\nfor inference purposes. Homomorphic encryption (HE) provides a solution by\nallowing computations to be performed on encrypted data without revealing the\noriginal information. However, HE inference is computationally expensive,\nparticularly for large images (e.g., chest X-rays). In this study, we propose\nan HE inference framework for medical images that uses VQGAN to compress images\ninto latent representations, thereby significantly reducing the computational\nburden while preserving image quality. We approximate the activation functions\nwith lower-degree polynomials to balance the accuracy and efficiency in\ncompliance with HE requirements. We observed that a downsampling factor of\neight for compression achieved an optimal balance between performance and\ncomputational cost. We further adapted the squeeze and excitation module, which\nis known to improve traditional CNNs, to enhance the HE framework. Our method\nwas tested on two chest X-ray datasets for multi-label classification tasks\nusing vanilla CNN backbones. Although HE inference remains relatively slow and\nintroduces minor performance differences compared with unencrypted inference,\nour approach shows strong potential for practical use in medical images", "AI": {"tldr": "Proposed an HE inference framework for medical images using VQGAN for compression and polynomial approximations for activation functions, balancing accuracy and efficiency.", "motivation": "Medical imaging data require privacy protection, but HE inference is computationally expensive for large images.", "method": "Uses VQGAN to compress images into latent representations, approximates activation functions with low-degree polynomials, and adapts squeeze and excitation modules.", "result": "Achieved optimal balance with an 8x downsampling factor; minor performance differences compared to unencrypted inference.", "conclusion": "The framework shows strong potential for practical use in medical imaging despite slower HE inference."}}
{"id": "2506.16330", "pdf": "https://arxiv.org/pdf/2506.16330", "abs": "https://arxiv.org/abs/2506.16330", "authors": ["Ji Zhang", "Jingkuan Song", "Lianli Gao", "Nicu Sebe", "Heng Tao Shen"], "title": "Reliable Few-shot Learning under Dual Noises", "categories": ["cs.CV", "cs.AI"], "comment": "17 pages, 6 figures,", "summary": "Recent advances in model pre-training give rise to task adaptation-based\nfew-shot learning (FSL), where the goal is to adapt a pre-trained task-agnostic\nmodel for capturing task-specific knowledge with a few-labeled support samples\nof the target task.Nevertheless, existing approaches may still fail in the open\nworld due to the inevitable in-distribution (ID) and out-of-distribution (OOD)\nnoise from both support and query samples of the target task. With limited\nsupport samples available, i) the adverse effect of the dual noises can be\nseverely amplified during task adaptation, and ii) the adapted model can\nproduce unreliable predictions on query samples in the presence of the dual\nnoises. In this work, we propose DEnoised Task Adaptation (DETA++) for reliable\nFSL. DETA++ uses a Contrastive Relevance Aggregation (CoRA) module to calculate\nimage and region weights for support samples, based on which a clean prototype\nloss and a noise entropy maximization loss are proposed to achieve noise-robust\ntask adaptation. Additionally,DETA++ employs a memory bank to store and refine\nclean regions for each inner-task class, based on which a Local Nearest\nCentroid Classifier (LocalNCC) is devised to yield noise-robust predictions on\nquery samples. Moreover, DETA++ utilizes an Intra-class Region Swapping\n(IntraSwap) strategy to rectify ID class prototypes during task adaptation,\nenhancing the model's robustness to the dual noises. Extensive experiments\ndemonstrate the effectiveness and flexibility of DETA++.", "AI": {"tldr": "DETA++ is a noise-robust few-shot learning method using contrastive relevance aggregation and memory bank techniques to handle ID/OOD noise in task adaptation.", "motivation": "Existing few-shot learning methods struggle with noise in support and query samples, leading to unreliable predictions. DETA++ aims to address this by improving task adaptation robustness.", "method": "DETA++ employs CoRA for support sample weighting, clean prototype and noise entropy losses, a memory bank for clean region storage, LocalNCC for query predictions, and IntraSwap for prototype rectification.", "result": "Extensive experiments show DETA++ effectively handles dual noises, improving reliability in few-shot learning.", "conclusion": "DETA++ provides a robust solution for noise-affected few-shot learning, enhancing task adaptation and prediction reliability."}}
{"id": "2506.15725", "pdf": "https://arxiv.org/pdf/2506.15725", "abs": "https://arxiv.org/abs/2506.15725", "authors": ["Matteo Ninniri", "Marco Podda", "Davide Bacciu"], "title": "Graph Diffusion that can Insert and Delete", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Generative models of graphs based on discrete Denoising Diffusion\nProbabilistic Models (DDPMs) offer a principled approach to molecular\ngeneration by systematically removing structural noise through iterative atom\nand bond adjustments. However, existing formulations are fundamentally limited\nby their inability to adapt the graph size (that is, the number of atoms)\nduring the diffusion process, severely restricting their effectiveness in\nconditional generation scenarios such as property-driven molecular design,\nwhere the targeted property often correlates with the molecular size. In this\npaper, we reformulate the noising and denoising processes to support monotonic\ninsertion and deletion of nodes. The resulting model, which we call GrIDDD,\ndynamically grows or shrinks the chemical graph during generation. GrIDDD\nmatches or exceeds the performance of existing graph diffusion models on\nmolecular property targeting despite being trained on a more difficult problem.\nFurthermore, when applied to molecular optimization, GrIDDD exhibits\ncompetitive performance compared to specialized optimization models. This work\npaves the way for size-adaptive molecular generation with graph diffusion.", "AI": {"tldr": "GrIDDD introduces a size-adaptive graph diffusion model for molecular generation, overcoming limitations of fixed graph sizes in existing methods.", "motivation": "Existing graph diffusion models cannot adapt graph size during generation, limiting their use in property-driven molecular design.", "method": "Reformulates noising and denoising processes to allow monotonic node insertion/deletion, creating the GrIDDD model.", "result": "GrIDDD matches/exceeds existing models in property targeting and shows competitive performance in molecular optimization.", "conclusion": "GrIDDD enables size-adaptive molecular generation, advancing graph diffusion applications."}}
{"id": "2506.17130", "pdf": "https://arxiv.org/pdf/2506.17130", "abs": "https://arxiv.org/abs/2506.17130", "authors": ["Botao Zhu", "Xianbin Wang", "Lei Zhang", "Xuemin", "Shen"], "title": "Chain-of-Trust: A Progressive Trust Evaluation Framework Enabled by Generative AI", "categories": ["cs.AI"], "comment": null, "summary": "In collaborative systems with complex tasks relying on distributed resources,\ntrust evaluation of potential collaborators has emerged as an effective\nmechanism for task completion. However, due to the network dynamics and varying\ninformation gathering latencies, it is extremely challenging to observe and\ncollect all trust attributes of a collaborating device concurrently for a\ncomprehensive trust assessment. In this paper, a novel progressive trust\nevaluation framework, namely chain-of-trust, is proposed to make better use of\nmisaligned device attribute data. This framework, designed for effective task\ncompletion, divides the trust evaluation process into multiple chained stages\nbased on task decomposition. At each stage, based on the task completion\nprocess, the framework only gathers the latest device attribute data relevant\nto that stage, leading to reduced trust evaluation complexity and overhead. By\nleveraging advanced in-context learning, few-shot learning, and reasoning\ncapabilities, generative AI is then employed to analyze and interpret the\ncollected data to produce correct evaluation results quickly. Only devices\ndeemed trustworthy at this stage proceed to the next round of trust evaluation.\nThe framework ultimately determines devices that remain trustworthy across all\nstages. Experimental results demonstrate that the proposed framework achieves\nhigh accuracy in trust evaluation.", "AI": {"tldr": "A progressive trust evaluation framework, chain-of-trust, is proposed to handle misaligned device attribute data in collaborative systems, improving accuracy and reducing overhead.", "motivation": "Addressing the challenge of comprehensive trust assessment due to network dynamics and varying data latencies in collaborative systems.", "method": "Divides trust evaluation into chained stages, gathering relevant data per stage, and uses generative AI for analysis.", "result": "Achieves high accuracy in trust evaluation with reduced complexity.", "conclusion": "The chain-of-trust framework effectively improves trust assessment in dynamic collaborative environments."}}
{"id": "2506.16628", "pdf": "https://arxiv.org/pdf/2506.16628", "abs": "https://arxiv.org/abs/2506.16628", "authors": ["Jianlin Shi", "Brian T. Bucher"], "title": "Initial Investigation of LLM-Assisted Development of Rule-Based Clinical NLP System", "categories": ["cs.CL", "cs.LG"], "comment": null, "summary": "Despite advances in machine learning (ML) and large language models (LLMs),\nrule-based natural language processing (NLP) systems remain active in clinical\nsettings due to their interpretability and operational efficiency. However,\ntheir manual development and maintenance are labor-intensive, particularly in\ntasks with large linguistic variability. To overcome these limitations, we\nproposed a novel approach employing LLMs solely during the rule-based systems\ndevelopment phase. We conducted the initial experiments focusing on the first\ntwo steps of developing a rule-based NLP pipeline: find relevant snippets from\nthe clinical note; extract informative keywords from the snippets for the\nrule-based named entity recognition (NER) component. Our experiments\ndemonstrated exceptional recall in identifying clinically relevant text\nsnippets (Deepseek: 0.98, Qwen: 0.99) and 1.0 in extracting key terms for NER.\nThis study sheds light on a promising new direction for NLP development,\nenabling semi-automated or automated development of rule-based systems with\nsignificantly faster, more cost-effective, and transparent execution compared\nwith deep learning model-based solutions.", "AI": {"tldr": "The paper proposes using LLMs to automate the development of rule-based NLP systems, achieving high recall in clinical text snippet identification and perfect key term extraction.", "motivation": "Rule-based NLP systems are preferred in clinical settings for interpretability and efficiency, but manual development is labor-intensive.", "method": "Employ LLMs during the development phase to automate snippet identification and keyword extraction for rule-based NER.", "result": "High recall in snippet identification (Deepseek: 0.98, Qwen: 0.99) and perfect key term extraction (1.0).", "conclusion": "LLMs enable faster, cost-effective, and transparent development of rule-based NLP systems compared to deep learning."}}
{"id": "2406.06967", "pdf": "https://arxiv.org/pdf/2406.06967", "abs": "https://arxiv.org/abs/2406.06967", "authors": ["Kailas Dayanandan", "Nikhil Kumar", "Anand Sinha", "Brejesh Lall"], "title": "Dual Thinking and Logical Processing -- Are Multi-modal Large Language Models Closing the Gap with Human Vision ?", "categories": ["cs.CV", "cs.AI", "eess.IV"], "comment": null, "summary": "The dual thinking framework considers fast, intuitive, and slower logical\nprocessing. The perception of dual thinking in vision requires images where\ninferences from intuitive and logical processing differ, and the latter is\nunder-explored in current studies. We introduce a novel adversarial dataset to\nprovide evidence for the dual thinking framework in human vision, which also\nfacilitates the study of the qualitative behavior of deep learning models. Our\npsychophysical studies show the presence of multiple inferences in rapid\nsuccession, and analysis of errors shows that the early stopping of visual\nprocessing can result in missing relevant information. MLLMs (Multi-modal Large\nLanguage Models) and VLMs (Vision Language Models) have made significant\nprogress in correcting errors in intuitive processing in human vision and\nshowed enhanced performance on images requiring logical processing. However,\ntheir improvements in logical processing have not kept pace with their\nadvancements in intuitive processing. In contrast, segmentation models exhibit\nerrors similar to those seen in intuitive human processing and lack\nunderstanding of sub-structures, as indicated by errors related to\nsub-components in identified instances. As AI (Artificial Intelligence)-based\nsystems find increasing applications in safety-critical domains like autonomous\ndriving, the integration of logical processing capabilities becomes essential.\nThis not only enhances performance but also addresses the limitations of\nscaling-based approaches while ensuring robustness and reliability in\nreal-world environments.", "AI": {"tldr": "The paper explores dual thinking in vision, introduces an adversarial dataset, and evaluates AI models' performance in intuitive vs. logical processing.", "motivation": "To study dual thinking in human vision and assess AI models' capabilities in intuitive and logical processing, especially for safety-critical applications.", "method": "Introduces a novel adversarial dataset, conducts psychophysical studies, and analyzes errors in MLLMs, VLMs, and segmentation models.", "result": "Shows early stopping in visual processing can miss information; MLLMs/VLMs improve intuitive but lag in logical processing; segmentation models mimic human intuitive errors.", "conclusion": "Enhancing logical processing in AI is crucial for safety-critical applications, ensuring robustness and reliability beyond scaling-based approaches."}}
{"id": "2506.16331", "pdf": "https://arxiv.org/pdf/2506.16331", "abs": "https://arxiv.org/abs/2506.16331", "authors": ["Viktoria Pundy", "Marco Peer", "Florian Kleber"], "title": "Transparency Techniques for Neural Networks trained on Writer Identification and Writer Verification", "categories": ["cs.CV"], "comment": null, "summary": "Neural Networks are the state of the art for many tasks in the computer\nvision domain, including Writer Identification (WI) and Writer Verification\n(WV). The transparency of these \"black box\" systems is important for\nimprovements of performance and reliability. For this work, two transparency\ntechniques are applied to neural networks trained on WI and WV for the first\ntime in this domain. The first technique provides pixel-level saliency maps,\nwhile the point-specific saliency maps of the second technique provide\ninformation on similarities between two images. The transparency techniques are\nevaluated using deletion and insertion score metrics. The goal is to support\nforensic experts with information on similarities in handwritten text and to\nexplore the characteristics selected by a neural network for the identification\nprocess. For the qualitative evaluation, the highlights of the maps are\ncompared to the areas forensic experts consider during the identification\nprocess. The evaluation results show that the pixel-wise saliency maps\noutperform the point-specific saliency maps and are suitable for the support of\nforensic experts.", "AI": {"tldr": "The paper applies two transparency techniques to neural networks for Writer Identification and Verification, evaluating their effectiveness for forensic analysis.", "motivation": "To improve the transparency of neural networks in Writer Identification and Verification, aiding forensic experts by revealing the networks' decision-making processes.", "method": "Two techniques are used: pixel-level saliency maps and point-specific saliency maps, evaluated with deletion and insertion score metrics.", "result": "Pixel-wise saliency maps outperform point-specific maps and align well with forensic experts' focus areas.", "conclusion": "Pixel-wise saliency maps are effective for supporting forensic experts in analyzing handwritten text similarities."}}
{"id": "2506.15792", "pdf": "https://arxiv.org/pdf/2506.15792", "abs": "https://arxiv.org/abs/2506.15792", "authors": ["Jackson Burns", "Akshat Zalte", "William Green"], "title": "Descriptor-based Foundation Models for Molecular Property Prediction", "categories": ["cs.LG", "physics.chem-ph"], "comment": null, "summary": "Fast and accurate prediction of molecular properties with machine learning is\npivotal to scientific advancements across myriad domains. Foundation models in\nparticular have proven especially effective, enabling accurate training on\nsmall, real-world datasets. This study introduces CheMeleon, a novel molecular\nfoundation model pre-trained on deterministic molecular descriptors from the\nMordred package, leveraging a Directed Message-Passing Neural Network to\npredict these descriptors in a noise-free setting. Unlike conventional\napproaches relying on noisy experimental data or biased quantum mechanical\nsimulations, CheMeleon uses low-noise molecular descriptors to learn rich\nmolecular representations. Evaluated on 58 benchmark datasets from Polaris and\nMoleculeACE, CheMeleon achieves a win rate of 79% on Polaris tasks,\noutperforming baselines like Random Forest (46%), fastprop (39%), and Chemprop\n(36%), and a 97% win rate on MoleculeACE assays, surpassing Random Forest (63%)\nand other foundation models. However, it struggles to distinguish activity\ncliffs like many of the tested models. The t-SNE projection of CheMeleon's\nlearned representations demonstrates effective separation of chemical series,\nhighlighting its ability to capture structural nuances. These results\nunderscore the potential of descriptor-based pre-training for scalable and\neffective molecular property prediction, opening avenues for further\nexploration of descriptor sets and unlabeled datasets.", "AI": {"tldr": "CheMeleon, a molecular foundation model, outperforms baselines in predicting molecular properties using noise-free descriptors, achieving high win rates on benchmark datasets.", "motivation": "To improve molecular property prediction accuracy by leveraging deterministic molecular descriptors and avoiding noisy or biased data sources.", "method": "CheMeleon pre-trains on Mordred package descriptors using a Directed Message-Passing Neural Network, focusing on noise-free learning.", "result": "Achieves 79% win rate on Polaris tasks and 97% on MoleculeACE assays, outperforming Random Forest and other models, though struggles with activity cliffs.", "conclusion": "Descriptor-based pre-training shows promise for scalable molecular property prediction, with potential for further exploration of descriptor sets and unlabeled data."}}
{"id": "2506.17163", "pdf": "https://arxiv.org/pdf/2506.17163", "abs": "https://arxiv.org/abs/2506.17163", "authors": ["Abinitha Gourabathina", "Yuexing Hao", "Walter Gerych", "Marzyeh Ghassemi"], "title": "The MedPerturb Dataset: What Non-Content Perturbations Reveal About Human and Clinical LLM Decision Making", "categories": ["cs.AI"], "comment": null, "summary": "Clinical robustness is critical to the safe deployment of medical Large\nLanguage Models (LLMs), but key questions remain about how LLMs and humans may\ndiffer in response to the real-world variability typified by clinical settings.\nTo address this, we introduce MedPerturb, a dataset designed to systematically\nevaluate medical LLMs under controlled perturbations of clinical input.\nMedPerturb consists of clinical vignettes spanning a range of pathologies, each\ntransformed along three axes: (1) gender modifications (e.g., gender-swapping\nor gender-removal); (2) style variation (e.g., uncertain phrasing or colloquial\ntone); and (3) format changes (e.g., LLM-generated multi-turn conversations or\nsummaries). With MedPerturb, we release a dataset of 800 clinical contexts\ngrounded in realistic input variability, outputs from four LLMs, and three\nhuman expert reads per clinical context. We use MedPerturb in two case studies\nto reveal how shifts in gender identity cues, language style, or format reflect\ndiverging treatment selections between humans and LLMs. We find that LLMs are\nmore sensitive to gender and style perturbations while human annotators are\nmore sensitive to LLM-generated format perturbations such as clinical\nsummaries. Our results highlight the need for evaluation frameworks that go\nbeyond static benchmarks to assess the similarity between human clinician and\nLLM decisions under the variability characteristic of clinical settings.", "AI": {"tldr": "MedPerturb dataset evaluates medical LLMs under controlled perturbations, revealing differences in sensitivity to gender, style, and format changes between LLMs and humans.", "motivation": "To assess how LLMs and humans differ in handling real-world clinical variability, ensuring clinical robustness for safe deployment.", "method": "Introduce MedPerturb, a dataset of 800 clinical vignettes perturbed along gender, style, and format axes, comparing outputs of four LLMs and human experts.", "result": "LLMs are more sensitive to gender and style changes, while humans are more sensitive to format changes like summaries.", "conclusion": "Evaluation frameworks must account for clinical variability to align LLM decisions with human clinicians."}}
{"id": "2506.16640", "pdf": "https://arxiv.org/pdf/2506.16640", "abs": "https://arxiv.org/abs/2506.16640", "authors": ["Pavlo Vasylenko", "Marcos Treviso", "Andr\u00e9 F. T. Martins"], "title": "Long-Context Generalization with Sparse Attention", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Transformer-based architectures traditionally employ softmax to compute\nattention weights, which produces dense distributions over all tokens in a\nsequence. While effective in many settings, this density has been shown to be\ndetrimental for tasks that demand precise focus on fixed-size patterns: as\nsequence length increases, non-informative tokens accumulate attention\nprobability mass, leading to dispersion and representational collapse. We show\nin this paper that sparse attention mechanisms using $\\alpha$-entmax can avoid\nthese issues, due to their ability to assign exact zeros to irrelevant tokens.\nFurthermore, we introduce Adaptive-Scalable Entmax (ASEntmax), which endows\n$\\alpha$-entmax with a learnable temperature parameter, allowing the attention\ndistribution to interpolate between sparse (pattern-focused) and dense\n(softmax-like) regimes. Finally, we show that the ability to locate and\ngeneralize fixed-size patterns can be further improved through a careful design\nof position encodings, which impacts both dense and sparse attention methods.\nBy integrating ASEntmax into standard transformer layers alongside proper\npositional encodings, we show that our models greatly outperform softmax,\nscalable softmax, and fixed-temperature $\\alpha$-entmax baselines on\nlong-context generalization.", "AI": {"tldr": "The paper proposes using sparse attention mechanisms with ASEntmax to improve focus on fixed-size patterns in transformers, outperforming traditional softmax methods.", "motivation": "Traditional softmax attention disperses focus as sequence length grows, harming tasks requiring precise attention on fixed patterns.", "method": "Introduces ASEntmax, a sparse attention mechanism with learnable temperature, and optimizes position encodings.", "result": "ASEntmax with proper position encodings outperforms softmax and other baselines in long-context generalization.", "conclusion": "Sparse attention and adaptive mechanisms like ASEntmax enhance transformer performance for tasks needing precise focus."}}
{"id": "2501.08924", "pdf": "https://arxiv.org/pdf/2501.08924", "abs": "https://arxiv.org/abs/2501.08924", "authors": ["Benoit Brummer", "Christophe De Vleeschouwer"], "title": "Learning Joint Denoising, Demosaicing, and Compression from the Raw Natural Image Noise Dataset", "categories": ["cs.CV", "eess.IV", "68U10", "I.4.2; I.4.3; I.4.4; I.4.9; I.2.10; H.4.3"], "comment": null, "summary": "This paper introduces the Raw Natural Image Noise Dataset (RawNIND), a\ndiverse collection of paired raw images designed to support the development of\ndenoising models that generalize across sensors, image development workflows,\nand styles. Two denoising methods are proposed: one operates directly on raw\nBayer data, leveraging computational efficiency, while the other processes\nlinear RGB images for improved generalization to different sensors, with both\npreserving flexibility for subsequent development. Both methods outperform\ntraditional approaches which rely on developed images. Additionally, the\nintegration of denoising and compression at the raw data level significantly\nenhances rate-distortion performance and computational efficiency. These\nfindings suggest a paradigm shift toward raw data workflows for efficient and\nflexible image processing.", "AI": {"tldr": "RawNIND dataset introduced for denoising model development. Two denoising methods outperform traditional approaches, with raw data workflows enhancing efficiency and flexibility.", "motivation": "To support denoising model development that generalizes across sensors, workflows, and styles.", "method": "Two denoising methods: one on raw Bayer data for efficiency, another on linear RGB for sensor generalization.", "result": "Both methods outperform traditional approaches; raw data integration improves rate-distortion and efficiency.", "conclusion": "Suggests a shift toward raw data workflows for efficient and flexible image processing."}}
{"id": "2506.16353", "pdf": "https://arxiv.org/pdf/2506.16353", "abs": "https://arxiv.org/abs/2506.16353", "authors": ["Chao He", "Hongxi Wei"], "title": "MambaHash: Visual State Space Deep Hashing Model for Large-Scale Image Retrieval", "categories": ["cs.CV"], "comment": "Accepted by ICMR2025. arXiv admin note: text overlap with\n  arXiv:2405.07524", "summary": "Deep image hashing aims to enable effective large-scale image retrieval by\nmapping the input images into simple binary hash codes through deep neural\nnetworks. More recently, Vision Mamba with linear time complexity has attracted\nextensive attention from researchers by achieving outstanding performance on\nvarious computer tasks. Nevertheless, the suitability of Mamba for large-scale\nimage retrieval tasks still needs to be explored. Towards this end, we propose\na visual state space hashing model, called MambaHash. Concretely, we propose a\nbackbone network with stage-wise architecture, in which grouped Mamba operation\nis introduced to model local and global information by utilizing Mamba to\nperform multi-directional scanning along different groups of the channel.\nSubsequently, the proposed channel interaction attention module is used to\nenhance information communication across channels. Finally, we meticulously\ndesign an adaptive feature enhancement module to increase feature diversity and\nenhance the visual representation capability of the model. We have conducted\ncomprehensive experiments on three widely used datasets: CIFAR-10, NUS-WIDE and\nIMAGENET. The experimental results demonstrate that compared with the\nstate-of-the-art deep hashing methods, our proposed MambaHash has well\nefficiency and superior performance to effectively accomplish large-scale image\nretrieval tasks. Source code is available\nhttps://github.com/shuaichaochao/MambaHash.git", "AI": {"tldr": "MambaHash, a visual state space hashing model, leverages Vision Mamba for efficient large-scale image retrieval, outperforming state-of-the-art methods.", "motivation": "To explore the suitability of Vision Mamba for large-scale image retrieval tasks, given its linear time complexity and strong performance in computer vision.", "method": "Proposes a backbone network with grouped Mamba operations for local/global modeling, channel interaction attention for cross-channel communication, and adaptive feature enhancement for diversity.", "result": "Outperforms state-of-the-art deep hashing methods on CIFAR-10, NUS-WIDE, and IMAGENET datasets, demonstrating efficiency and superior performance.", "conclusion": "MambaHash effectively addresses large-scale image retrieval with Vision Mamba, offering a promising solution with open-source availability."}}
{"id": "2506.15809", "pdf": "https://arxiv.org/pdf/2506.15809", "abs": "https://arxiv.org/abs/2506.15809", "authors": ["Deyi Li", "Zijun Yao", "Muxuan Liang", "Mei Liu"], "title": "DeepJ: Graph Convolutional Transformers with Differentiable Pooling for Patient Trajectory Modeling", "categories": ["cs.LG"], "comment": null, "summary": "In recent years, graph learning has gained significant interest for modeling\ncomplex interactions among medical events in structured Electronic Health\nRecord (EHR) data. However, existing graph-based approaches often work in a\nstatic manner, either restricting interactions within individual encounters or\ncollapsing all historical encounters into a single snapshot. As a result, when\nit is necessary to identify meaningful groups of medical events spanning\nlongitudinal encounters, existing methods are inadequate in modeling\ninteractions cross encounters while accounting for temporal dependencies. To\naddress this limitation, we introduce Deep Patient Journey (DeepJ), a novel\ngraph convolutional transformer model with differentiable graph pooling to\neffectively capture intra-encounter and inter-encounter medical event\ninteractions. DeepJ can identify groups of temporally and functionally related\nmedical events, offering valuable insights into key event clusters pertinent to\npatient outcome prediction. DeepJ significantly outperformed five\nstate-of-the-art baseline models while enhancing interpretability,\ndemonstrating its potential for improved patient risk stratification.", "AI": {"tldr": "DeepJ, a graph convolutional transformer model, improves modeling of medical event interactions in EHR data by capturing intra- and inter-encounter dynamics, outperforming existing methods.", "motivation": "Existing graph-based approaches fail to model cross-encounter interactions and temporal dependencies in EHR data, limiting their effectiveness for patient outcome prediction.", "method": "DeepJ combines graph convolutional networks with transformers and differentiable graph pooling to capture intra- and inter-encounter medical event interactions.", "result": "DeepJ outperforms five state-of-the-art baseline models and enhances interpretability by identifying key event clusters for patient risk stratification.", "conclusion": "DeepJ addresses limitations of static graph methods, offering improved modeling of longitudinal EHR data for better patient outcome insights."}}
{"id": "2506.15655", "pdf": "https://arxiv.org/pdf/2506.15655", "abs": "https://arxiv.org/abs/2506.15655", "authors": ["Yilin Zhang", "Xinran Zhao", "Zora Zhiruo Wang", "Chenyang Yang", "Jiayi Wei", "Tongshuang Wu"], "title": "cAST: Enhancing Code Retrieval-Augmented Generation with Structural Chunking via Abstract Syntax Tree", "categories": ["cs.SE", "cs.AI", "cs.CL", "cs.IR"], "comment": null, "summary": "Retrieval-Augmented Generation (RAG) has become essential for large-scale\ncode generation, grounding predictions in external code corpora to improve\nactuality. However, a critical yet underexplored aspect of RAG pipelines is\nchunking -- the process of dividing documents into retrievable units. Existing\nline-based chunking heuristics often break semantic structures, splitting\nfunctions or merging unrelated code, which can degrade generation quality. We\npropose chunking via Abstract Syntax Trees (\\ourwork), a structure-aware method\nthat recursively breaks large AST nodes into smaller chunks and merges sibling\nnodes while respecting size limits. This approach generates self-contained,\nsemantically coherent units across programming languages and tasks, improving\nperformance on diverse code generation tasks, e.g., boosting Recall@5 by 4.3\npoints on RepoEval retrieval and Pass@1 by 2.67 points on SWE-bench generation.\nOur work highlights the importance of structure-aware chunking for scaling\nretrieval-enhanced code intelligence.", "AI": {"tldr": "Proposes AST-based chunking for RAG pipelines to improve code generation quality by preserving semantic coherence.", "motivation": "Existing line-based chunking heuristics break semantic structures in code, degrading generation quality.", "method": "Uses Abstract Syntax Trees (ASTs) to recursively break and merge nodes into coherent chunks while respecting size limits.", "result": "Improves Recall@5 by 4.3 points on RepoEval and Pass@1 by 2.67 points on SWE-bench.", "conclusion": "Structure-aware chunking is crucial for enhancing retrieval-augmented code generation."}}
{"id": "2506.16655", "pdf": "https://arxiv.org/pdf/2506.16655", "abs": "https://arxiv.org/abs/2506.16655", "authors": ["Co Tran", "Salman Paracha", "Adil Hafeez", "Shuguang Chen"], "title": "Arch-Router: Aligning LLM Routing with Human Preferences", "categories": ["cs.CL"], "comment": null, "summary": "With the rapid proliferation of large language models (LLMs) -- each\noptimized for different strengths, style, or latency/cost profile -- routing\nhas become an essential technique to operationalize the use of different\nmodels. However, existing LLM routing approaches are limited in two key ways:\nthey evaluate performance using benchmarks that often fail to capture human\npreferences driven by subjective evaluation criteria, and they typically select\nfrom a limited pool of models. In this work, we propose a preference-aligned\nrouting framework that guides model selection by matching queries to\nuser-defined domains (e.g., travel) or action types (e.g., image editing) --\noffering a practical mechanism to encode preferences in routing decisions.\nSpecifically, we introduce \\textbf{Arch-Router}, a compact 1.5B model that\nlearns to map queries to domain-action preferences for model routing decisions.\nOur approach also supports seamlessly adding new models for routing without\nrequiring retraining or architectural modifications. Experiments on\nconversational datasets demonstrate that our approach achieves state-of-the-art\n(SOTA) results in matching queries with human preferences, outperforming top\nproprietary models. Our approach captures subjective evaluation criteria and\nmakes routing decisions more transparent and flexible. Our model is available\nat: \\texttt{https://huggingface.co/katanemo/Arch-Router-1.5B}.", "AI": {"tldr": "The paper introduces Arch-Router, a 1.5B model for preference-aligned routing of LLMs, addressing limitations of current routing methods by capturing human preferences and enabling flexible model selection.", "motivation": "Existing LLM routing approaches lack alignment with human preferences and flexibility in model selection, limiting their practical utility.", "method": "Proposes Arch-Router, a compact model that maps queries to user-defined domains or action types for routing decisions, supporting new models without retraining.", "result": "Achieves SOTA in matching queries with human preferences on conversational datasets, outperforming proprietary models.", "conclusion": "Arch-Router enhances routing transparency, flexibility, and preference alignment, with the model publicly available."}}
{"id": "2503.11290", "pdf": "https://arxiv.org/pdf/2503.11290", "abs": "https://arxiv.org/abs/2503.11290", "authors": ["Qi Mao", "Haobo Hu", "Yujie He", "Difei Gao", "Haokun Chen", "Libiao Jin"], "title": "EmoAgent: A Multi-Agent Framework for Diverse Affective Image Manipulation", "categories": ["cs.CV", "eess.IV"], "comment": null, "summary": "Affective Image Manipulation (AIM) aims to alter visual elements within an\nimage to evoke specific emotional responses from viewers. However, existing AIM\napproaches rely on rigid \\emph{one-to-one} mappings between emotions and visual\ncues, making them ill-suited for the inherently subjective and diverse ways in\nwhich humans perceive and express emotion.To address this, we introduce a novel\ntask setting termed \\emph{Diverse AIM (D-AIM)}, aiming to generate multiple\nvisually distinct yet emotionally consistent image edits from a single source\nimage and target emotion. We propose \\emph{EmoAgent}, the first multi-agent\nframework tailored specifically for D-AIM. EmoAgent explicitly decomposes the\nmanipulation process into three specialized phases executed by collaborative\nagents: a Planning Agent that generates diverse emotional editing strategies,\nan Editing Agent that precisely executes these strategies, and a Critic Agent\nthat iteratively refines the results to ensure emotional accuracy. This\ncollaborative design empowers EmoAgent to model \\emph{one-to-many}\nemotion-to-visual mappings, enabling semantically diverse and emotionally\nfaithful edits.Extensive quantitative and qualitative evaluations demonstrate\nthat EmoAgent substantially outperforms state-of-the-art approaches in both\nemotional fidelity and semantic diversity, effectively generating multiple\ndistinct visual edits that convey the same target emotion.", "AI": {"tldr": "The paper introduces Diverse AIM (D-AIM) and EmoAgent, a multi-agent framework for generating diverse yet emotionally consistent image edits, outperforming existing methods.", "motivation": "Existing AIM methods use rigid one-to-one emotion-to-visual mappings, failing to capture subjective and diverse human emotional perception.", "method": "EmoAgent decomposes the process into three collaborative agents: Planning (diverse strategies), Editing (execution), and Critic (refinement).", "result": "EmoAgent outperforms state-of-the-art methods in emotional fidelity and semantic diversity, generating multiple distinct edits for the same emotion.", "conclusion": "EmoAgent successfully models one-to-many emotion-to-visual mappings, enabling diverse and emotionally accurate image manipulations."}}
{"id": "2506.16369", "pdf": "https://arxiv.org/pdf/2506.16369", "abs": "https://arxiv.org/abs/2506.16369", "authors": ["Pallabi Dutta", "Anubhab Maity", "Sushmita Mitra"], "title": "Prompt-based Dynamic Token Pruning to Guide Transformer Attention in Efficient Segmentation", "categories": ["cs.CV"], "comment": null, "summary": "The high computational demands of Vision Transformers (ViTs), in processing a\nhuge number of tokens, often constrain their practical application in analyzing\nmedical images. This research proposes an adaptive prompt-guided pruning method\nto selectively reduce the processing of irrelevant tokens in the segmentation\npipeline. The prompt-based spatial prior helps to rank the tokens according to\ntheir relevance. Tokens with low-relevance scores are down-weighted, ensuring\nthat only the relevant ones are propagated for processing across subsequent\nstages. This data-driven pruning strategy facilitates end-to-end training,\nmaintains gradient flow, and improves segmentation accuracy by focusing\ncomputational resources on essential regions. The proposed framework is\nintegrated with several state-of-the-art models to facilitate the elimination\nof irrelevant tokens; thereby, enhancing computational efficiency while\npreserving segmentation accuracy. The experimental results show a reduction of\n$\\sim$ 35-55\\% tokens; thus reducing the computational costs relative to the\nbaselines. Cost-effective medical image processing, using our framework,\nfacilitates real-time diagnosis by expanding its applicability in\nresource-constrained environments.", "AI": {"tldr": "The paper proposes an adaptive prompt-guided pruning method for Vision Transformers (ViTs) to reduce computational costs in medical image segmentation by focusing on relevant tokens.", "motivation": "ViTs' high computational demands limit their practical use in medical image analysis. The goal is to improve efficiency by pruning irrelevant tokens.", "method": "An adaptive prompt-guided pruning method ranks tokens by relevance, down-weights low-relevance ones, and propagates only relevant tokens. This integrates with state-of-the-art models for end-to-end training.", "result": "The method reduces tokens by 35-55%, lowering computational costs while maintaining segmentation accuracy.", "conclusion": "The framework enables cost-effective, real-time medical image processing, making ViTs more viable in resource-constrained settings."}}
{"id": "2506.15817", "pdf": "https://arxiv.org/pdf/2506.15817", "abs": "https://arxiv.org/abs/2506.15817", "authors": ["Jason Tandiary"], "title": "Optimizing Bidding Strategies in First-Price Auctions in Binary Feedback Setting with Predictions", "categories": ["cs.LG"], "comment": null, "summary": "This paper studies Vickrey first-price auctions under binary feedback.\nLeveraging the enhanced performance of machine learning algorithms, the new\nalgorithm uses past information to improve the regret bounds of the BROAD-OMD\nalgorithm. Motivated by the growing relevance of first-price auctions and the\npredictive capabilities of machine learning models, this paper proposes a new\nalgorithm within the BROAD-OMD framework (Hu et al., 2025) that leverages\npredictions of the highest competing bid. This paper's main contribution is an\nalgorithm that achieves zero regret under accurate predictions. Additionally, a\nbounded regret bound of O(T^(3/4) * Vt^(1/4)) is established under certain\nnormality conditions.", "AI": {"tldr": "The paper introduces a new algorithm for Vickrey first-price auctions with binary feedback, improving regret bounds using machine learning predictions.", "motivation": "The study is driven by the increasing importance of first-price auctions and the potential of machine learning to enhance performance.", "method": "The proposed algorithm, within the BROAD-OMD framework, uses predictions of the highest competing bid to optimize performance.", "result": "The algorithm achieves zero regret with accurate predictions and a bounded regret of O(T^(3/4) * Vt^(1/4)) under normality conditions.", "conclusion": "The paper demonstrates the effectiveness of leveraging machine learning predictions to improve auction performance, achieving strong regret bounds."}}
{"id": "2506.16678", "pdf": "https://arxiv.org/pdf/2506.16678", "abs": "https://arxiv.org/abs/2506.16678", "authors": ["Ananth Agarwal", "Jasper Jian", "Christopher D. Manning", "Shikhar Murty"], "title": "Mechanisms vs. Outcomes: Probing for Syntax Fails to Explain Performance on Targeted Syntactic Evaluations", "categories": ["cs.CL"], "comment": null, "summary": "Large Language Models (LLMs) exhibit a robust mastery of syntax when\nprocessing and generating text. While this suggests internalized understanding\nof hierarchical syntax and dependency relations, the precise mechanism by which\nthey represent syntactic structure is an open area within interpretability\nresearch. Probing provides one way to identify the mechanism of syntax being\nlinearly encoded in activations, however, no comprehensive study has yet\nestablished whether a model's probing accuracy reliably predicts its downstream\nsyntactic performance. Adopting a \"mechanisms vs. outcomes\" framework, we\nevaluate 32 open-weight transformer models and find that syntactic features\nextracted via probing fail to predict outcomes of targeted syntax evaluations\nacross English linguistic phenomena. Our results highlight a substantial\ndisconnect between latent syntactic representations found via probing and\nobservable syntactic behaviors in downstream tasks.", "AI": {"tldr": "Probing syntactic features in LLMs doesn't reliably predict downstream syntactic performance.", "motivation": "To understand if probing accuracy in LLMs correlates with their actual syntactic performance in tasks.", "method": "Evaluated 32 transformer models using probing and targeted syntax evaluations.", "result": "Syntactic features from probing don't predict downstream syntactic behaviors.", "conclusion": "Latent syntactic representations from probing are disconnected from observable syntactic performance."}}
{"id": "2504.14947", "pdf": "https://arxiv.org/pdf/2504.14947", "abs": "https://arxiv.org/abs/2504.14947", "authors": ["Xiaojun Yuan", "Haoming Ma", "Yinuo Huang", "Zhoufan Hua", "Yong Zuo", "Zhi Ding"], "title": "AGI-Driven Generative Semantic Communications: Principles and Practices", "categories": ["cs.AI", "eess.IV", "eess.SP"], "comment": null, "summary": "Semantic communications leverage artificial intelligence (AI) technologies to\nextract semantic information for efficient data delivery, thereby significantly\nreducing communication cost. With the evolution towards artificial general\nintelligence (AGI), the increasing demands for AGI services pose new challenges\nto semantic communications. In this context, an AGI application is typically\ndefined on a general-sense task, covering a broad, even unforeseen, set of\nobjectives, as well as driven by the need for a human-friendly interface in\nforms (e.g., videos, images, or text) easily understood by human users.In\nresponse, we introduce an AGI-driven communication paradigm for supporting AGI\napplications, called generative semantic communication (GSC). We first describe\nthe basic concept of GSC and its difference from existing semantic\ncommunications, and then introduce a general framework of GSC based on advanced\nAI technologies including foundation models and generative models. Two case\nstudies are presented to verify the advantages of GSC. Finally, open challenges\nand new research directions are discussed to stimulate this line of research\nand pave the way for practical applications.", "AI": {"tldr": "The paper introduces Generative Semantic Communication (GSC), an AGI-driven paradigm for efficient data delivery, leveraging AI to reduce communication costs and support human-friendly interfaces.", "motivation": "The increasing demands for AGI services and the need for efficient, human-understandable communication drive the development of GSC.", "method": "Proposes a GSC framework using advanced AI technologies like foundation and generative models, with case studies to validate its advantages.", "result": "GSC demonstrates potential for efficient semantic communication, supported by case studies.", "conclusion": "GSC presents a promising direction for AGI-driven communication, though open challenges remain for practical implementation."}}
{"id": "2506.16371", "pdf": "https://arxiv.org/pdf/2506.16371", "abs": "https://arxiv.org/abs/2506.16371", "authors": ["Yunhao Hou", "Bochao Zou", "Min Zhang", "Ran Chen", "Shangdong Yang", "Yanmei Zhang", "Junbao Zhuo", "Siheng Chen", "Jiansheng Chen", "Huimin Ma"], "title": "AGC-Drive: A Large-Scale Dataset for Real-World Aerial-Ground Collaboration in Driving Scenarios", "categories": ["cs.CV"], "comment": null, "summary": "By sharing information across multiple agents, collaborative perception helps\nautonomous vehicles mitigate occlusions and improve overall perception\naccuracy. While most previous work focus on vehicle-to-vehicle and\nvehicle-to-infrastructure collaboration, with limited attention to aerial\nperspectives provided by UAVs, which uniquely offer dynamic, top-down views to\nalleviate occlusions and monitor large-scale interactive environments. A major\nreason for this is the lack of high-quality datasets for aerial-ground\ncollaborative scenarios. To bridge this gap, we present AGC-Drive, the first\nlarge-scale real-world dataset for Aerial-Ground Cooperative 3D perception. The\ndata collection platform consists of two vehicles, each equipped with five\ncameras and one LiDAR sensor, and one UAV carrying a forward-facing camera and\na LiDAR sensor, enabling comprehensive multi-view and multi-agent perception.\nConsisting of approximately 120K LiDAR frames and 440K images, the dataset\ncovers 14 diverse real-world driving scenarios, including urban roundabouts,\nhighway tunnels, and on/off ramps. Notably, 19.5% of the data comprises dynamic\ninteraction events, including vehicle cut-ins, cut-outs, and frequent lane\nchanges. AGC-Drive contains 400 scenes, each with approximately 100 frames and\nfully annotated 3D bounding boxes covering 13 object categories. We provide\nbenchmarks for two 3D perception tasks: vehicle-to-vehicle collaborative\nperception and vehicle-to-UAV collaborative perception. Additionally, we\nrelease an open-source toolkit, including spatiotemporal alignment verification\ntools, multi-agent visualization systems, and collaborative annotation\nutilities. The dataset and code are available at\nhttps://github.com/PercepX/AGC-Drive.", "AI": {"tldr": "AGC-Drive is the first large-scale real-world dataset for aerial-ground cooperative 3D perception, addressing the lack of data for UAV-involved collaborative scenarios.", "motivation": "Previous work lacks focus on aerial perspectives (UAVs) in collaborative perception, and there's a scarcity of high-quality datasets for such scenarios.", "method": "The dataset includes two vehicles and one UAV equipped with cameras and LiDAR, capturing 120K LiDAR frames and 440K images across 14 diverse driving scenarios.", "result": "AGC-Drive provides benchmarks for vehicle-to-vehicle and vehicle-to-UAV collaborative perception, with fully annotated 3D bounding boxes for 13 object categories.", "conclusion": "The dataset and toolkit aim to advance research in aerial-ground collaborative perception, offering tools for alignment, visualization, and annotation."}}
{"id": "2506.15823", "pdf": "https://arxiv.org/pdf/2506.15823", "abs": "https://arxiv.org/abs/2506.15823", "authors": ["Chiara Razzetta", "Shahryar Noei", "Federico Barbarossa", "Edoardo Spairani", "Monica Roascio", "Elisa Barbi", "Giulia Ciacci", "Sara Sommariva", "Sabrina Guastavino", "Michele Piana", "Matteo Lenge", "Gabriele Arnulfo", "Giovanni Magenes", "Elvira Maranesi", "Giulio Amabili", "Anna Maria Massone", "Federico Benvenuto", "Giuseppe Jurman", "Diego Sona", "Cristina Campi"], "title": "AI-based modular warning machine for risk identification in proximity healthcare", "categories": ["cs.LG", "68T01, 68T05"], "comment": null, "summary": "\"DHEAL-COM - Digital Health Solutions in Community Medicine\" is a research\nand technology project funded by the Italian Department of Health for the\ndevelopment of digital solutions of interest in proximity healthcare. The\nactivity within the DHEAL-COM framework allows scientists to gather a notable\namount of multi-modal data whose interpretation can be performed by means of\nmachine learning algorithms. The present study illustrates a general automated\npipeline made of numerous unsupervised and supervised methods that can ingest\nsuch data, provide predictive results, and facilitate model interpretations via\nfeature identification.", "AI": {"tldr": "DHEAL-COM develops digital health solutions for proximity healthcare, using machine learning to analyze multi-modal data and provide predictive insights.", "motivation": "To address the need for digital solutions in community medicine by leveraging data and machine learning for predictive healthcare.", "method": "An automated pipeline combining unsupervised and supervised machine learning methods to process multi-modal data, predict outcomes, and identify key features.", "result": "The pipeline successfully ingests data, provides predictive results, and aids in model interpretation through feature identification.", "conclusion": "DHEAL-COM's approach demonstrates the potential of machine learning in enhancing digital health solutions for community medicine."}}
{"id": "2506.16692", "pdf": "https://arxiv.org/pdf/2506.16692", "abs": "https://arxiv.org/abs/2506.16692", "authors": ["Hyunsoo Yun", "Eun Hak Lee"], "title": "LegiGPT: Party Politics and Transport Policy with Large Language Model", "categories": ["cs.CL"], "comment": null, "summary": "Given the significant influence of lawmakers' political ideologies on\nlegislative decision-making, understanding their impact on policymaking is\ncritically important. We introduce a novel framework, LegiGPT, which integrates\na large language model (LLM) with explainable artificial intelligence (XAI) to\nanalyze transportation-related legislative proposals. LegiGPT employs a\nmulti-stage filtering and classification pipeline using zero-shot prompting\nwith GPT-4. Using legislative data from South Korea's 21st National Assembly,\nwe identify key factors - including sponsor characteristics, political\naffiliations, and geographic variables - that significantly influence\ntransportation policymaking. The LLM was used to classify\ntransportation-related bill proposals through a stepwise filtering process\nbased on keywords, phrases, and contextual relevance. XAI techniques were then\napplied to examine relationships between party affiliation and associated\nattributes. The results reveal that the number and proportion of conservative\nand progressive sponsors, along with district size and electoral population,\nare critical determinants shaping legislative outcomes. These findings suggest\nthat both parties contributed to bipartisan legislation through different forms\nof engagement, such as initiating or supporting proposals. This integrated\napproach provides a valuable tool for understanding legislative dynamics and\nguiding future policy development, with broader implications for infrastructure\nplanning and governance.", "AI": {"tldr": "LegiGPT, a framework combining LLM and XAI, analyzes transportation-related legislative proposals in South Korea, revealing key factors like political affiliations and sponsor characteristics influencing policymaking.", "motivation": "Understanding the impact of lawmakers' political ideologies on legislative decision-making, particularly in transportation policy.", "method": "LegiGPT uses GPT-4 for zero-shot classification of bills and XAI to analyze relationships between party affiliation and attributes.", "result": "Conservative and progressive sponsors, district size, and electoral population significantly shape legislative outcomes, with bipartisan contributions.", "conclusion": "LegiGPT offers insights into legislative dynamics, aiding future policy development and governance."}}
{"id": "2506.16385", "pdf": "https://arxiv.org/pdf/2506.16385", "abs": "https://arxiv.org/abs/2506.16385", "authors": ["Santosh Patapati", "Trisanth Srinivasan", "Amith Adiraju"], "title": "CLIP-MG: Guiding Semantic Attention with Skeletal Pose Features and RGB Data for Micro-Gesture Recognition on the iMiGUE Dataset", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": null, "summary": "Micro-gesture recognition is a challenging task in affective computing due to\nthe subtle, involuntary nature of the gestures and their low movement\namplitude. In this paper, we introduce a Pose-Guided Semantics-Aware CLIP-based\narchitecture, or CLIP for Micro-Gesture recognition (CLIP-MG), a modified CLIP\nmodel tailored for micro-gesture classification on the iMiGUE dataset. CLIP-MG\nintegrates human pose (skeleton) information into the CLIP-based recognition\npipeline through pose-guided semantic query generation and a gated multi-modal\nfusion mechanism. The proposed model achieves a Top-1 accuracy of 61.82%. These\nresults demonstrate both the potential of our approach and the remaining\ndifficulty in fully adapting vision-language models like CLIP for micro-gesture\nrecognition.", "AI": {"tldr": "A modified CLIP model, CLIP-MG, is introduced for micro-gesture recognition, integrating pose-guided semantics and multi-modal fusion, achieving 61.82% Top-1 accuracy.", "motivation": "Micro-gestures are subtle and involuntary, making recognition challenging in affective computing.", "method": "CLIP-MG uses pose-guided semantic query generation and gated multi-modal fusion to adapt CLIP for micro-gesture classification.", "result": "The model achieves a Top-1 accuracy of 61.82% on the iMiGUE dataset.", "conclusion": "The approach shows promise but highlights challenges in adapting vision-language models for micro-gesture recognition."}}
{"id": "2506.15825", "pdf": "https://arxiv.org/pdf/2506.15825", "abs": "https://arxiv.org/abs/2506.15825", "authors": ["Luiz Pereira", "M. Hadi Amini"], "title": "Heterogeneous Federated Reinforcement Learning Using Wasserstein Barycenters", "categories": ["cs.LG"], "comment": null, "summary": "In this paper, we first propose a novel algorithm for model fusion that\nleverages Wasserstein barycenters in training a global Deep Neural Network\n(DNN) in a distributed architecture. To this end, we divide the dataset into\nequal parts that are fed to \"agents\" who have identical deep neural networks\nand train only over the dataset fed to them (known as the local dataset). After\nsome training iterations, we perform an aggregation step where we combine the\nweight parameters of all neural networks using Wasserstein barycenters. These\nsteps form the proposed algorithm referred to as FedWB. Moreover, we leverage\nthe processes created in the first part of the paper to develop an algorithm to\ntackle Heterogeneous Federated Reinforcement Learning (HFRL). Our test\nexperiment is the CartPole toy problem, where we vary the lengths of the poles\nto create heterogeneous environments. We train a deep Q-Network (DQN) in each\nenvironment to learn to control each cart, while occasionally performing a\nglobal aggregation step to generalize the local models; the end outcome is a\nglobal DQN that functions across all environments.", "AI": {"tldr": "Proposes FedWB, a model fusion algorithm using Wasserstein barycenters for DNNs in distributed settings, and extends it to HFRL with DQNs in heterogeneous environments.", "motivation": "To address the challenge of training global models in distributed architectures and heterogeneous federated reinforcement learning scenarios.", "method": "Uses Wasserstein barycenters for aggregating DNN weights in FedWB and applies it to HFRL with DQNs in varying CartPole environments.", "result": "Developed FedWB for DNN fusion and a global DQN for HFRL, tested on CartPole with heterogeneous pole lengths.", "conclusion": "FedWB and the HFRL approach effectively generalize local models into global ones, validated by CartPole experiments."}}
{"id": "2506.15737", "pdf": "https://arxiv.org/pdf/2506.15737", "abs": "https://arxiv.org/abs/2506.15737", "authors": ["Gautam Siddharth Kashyap", "Md Tabrez Nafis", "Samar Wazir"], "title": "A Study of Hybrid and Evolutionary Metaheuristics for Single Hidden Layer Feedforward Neural Network Architecture", "categories": ["cs.NE", "cs.AI"], "comment": null, "summary": "Training Artificial Neural Networks (ANNs) with Stochastic Gradient Descent\n(SGD) frequently encounters difficulties, including substantial computing\nexpense and the risk of converging to local optima, attributable to its\ndependence on partial weight gradients. Therefore, this work investigates\nParticle Swarm Optimization (PSO) and Genetic Algorithms (GAs) - two\npopulation-based Metaheuristic Optimizers (MHOs) - as alternatives to SGD to\nmitigate these constraints. A hybrid PSO-SGD strategy is developed to improve\nlocal search efficiency. The findings indicate that the hybrid PSO-SGD\ntechnique decreases the median training MSE by 90 to 95 percent relative to\nconventional GA and PSO across various network sizes (e.g., from around 0.02 to\napproximately 0.001 in the Sphere function). RMHC attains substantial\nenhancements, reducing MSE by roughly 85 to 90 percent compared to GA.\nSimultaneously, RS consistently exhibits errors exceeding 0.3, signifying\nsubpar performance. These findings underscore that hybrid and evolutionary\nprocedures significantly improve training efficiency and accuracy compared to\nconventional optimization methods and imply that the Building Block Hypothesis\n(BBH) may still be valid, indicating that advantageous weight structures are\nretained during evolutionary search.", "AI": {"tldr": "The paper explores PSO and GAs as alternatives to SGD for training ANNs, proposing a hybrid PSO-SGD method that reduces training MSE by 90-95% compared to traditional methods.", "motivation": "SGD's limitations (high computational cost, local optima convergence) motivate the search for better optimization methods like PSO and GAs.", "method": "A hybrid PSO-SGD strategy is developed to enhance local search efficiency, tested against GA, PSO, RMHC, and RS.", "result": "The hybrid PSO-SGD reduces median training MSE by 90-95%, outperforming GA and PSO. RMHC also improves MSE by 85-90%, while RS performs poorly.", "conclusion": "Hybrid and evolutionary methods significantly enhance ANN training efficiency and accuracy, supporting the validity of the Building Block Hypothesis."}}
{"id": "2506.16712", "pdf": "https://arxiv.org/pdf/2506.16712", "abs": "https://arxiv.org/abs/2506.16712", "authors": ["Bin Chen", "Xinzge Gao", "Chuanrui Hu", "Penghang Yu", "Hua Zhang", "Bing-Kun Bao"], "title": "ReasonGRM: Enhancing Generative Reward Models through Large Reasoning Models", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Generative Reward Models (GRMs) provide greater flexibility than scalar\nreward models in capturing human preferences, but their effectiveness is\nlimited by poor reasoning capabilities. This often results in incomplete or\noverly speculative reasoning paths, leading to hallucinations or missing key\ninformation in complex tasks. We address this challenge with ReasonGRM, a\nthree-stage generative reward modeling framework. In the first stage, Zero-RL\nis used to generate concise, outcome-directed reasoning paths that reduce the\nlikelihood of critical omissions. In the second stage, we introduce a novel\nevaluation metric, $R^\\star$, which scores reasoning paths based on their\ngeneration likelihood. This favors paths that reach correct answers with\nminimal exploration, helping to reduce hallucination-prone data during\ntraining. In the final stage, the model is further refined through\nreinforcement learning on challenging examples to enhance its preference\ndiscrimination capabilities. Experiments on three public benchmarks show that\nReasonGRM achieves competitive or state-of-the-art performance, outperforming\nprevious best GRMs by 1.8\\% on average and surpassing proprietary models such\nas GPT-4o by up to 5.6\\%. These results demonstrate the effectiveness of\nreasoning-aware training and highlight the importance of high-quality rationale\nselection for reliable preference modeling.", "AI": {"tldr": "ReasonGRM is a three-stage framework improving generative reward models by enhancing reasoning paths, reducing hallucinations, and outperforming existing models.", "motivation": "Current generative reward models (GRMs) lack strong reasoning, leading to incomplete or speculative reasoning paths and hallucinations.", "method": "Three-stage framework: 1) Zero-RL for concise reasoning paths, 2) Novel metric $R^\\star$ to score paths, 3) Reinforcement learning refinement.", "result": "Outperforms previous GRMs by 1.8% and proprietary models like GPT-4o by up to 5.6%.", "conclusion": "ReasonGRM demonstrates the value of reasoning-aware training and high-quality rationale selection for reliable preference modeling."}}
{"id": "2506.16398", "pdf": "https://arxiv.org/pdf/2506.16398", "abs": "https://arxiv.org/abs/2506.16398", "authors": ["Peixiang Huang", "Yanyan Huang", "Weiqin Zhao", "Junjun He", "Lequan Yu"], "title": "HyperPath: Knowledge-Guided Hyperbolic Semantic Hierarchy Modeling for WSI Analysis", "categories": ["cs.CV"], "comment": null, "summary": "Pathology is essential for cancer diagnosis, with multiple instance learning\n(MIL) widely used for whole slide image (WSI) analysis. WSIs exhibit a natural\nhierarchy -- patches, regions, and slides -- with distinct semantic\nassociations. While some methods attempt to leverage this hierarchy for\nimproved representation, they predominantly rely on Euclidean embeddings, which\nstruggle to fully capture semantic hierarchies. To address this limitation, we\npropose HyperPath, a novel method that integrates knowledge from textual\ndescriptions to guide the modeling of semantic hierarchies of WSIs in\nhyperbolic space, thereby enhancing WSI classification. Our approach adapts\nboth visual and textual features extracted by pathology vision-language\nfoundation models to the hyperbolic space. We design an Angular Modality\nAlignment Loss to ensure robust cross-modal alignment, while a Semantic\nHierarchy Consistency Loss further refines feature hierarchies through\nentailment and contradiction relationships and thus enhance semantic coherence.\nThe classification is performed with geodesic distance, which measures the\nsimilarity between entities in the hyperbolic semantic hierarchy. This\neliminates the need for linear classifiers and enables a geometry-aware\napproach to WSI analysis. Extensive experiments show that our method achieves\nsuperior performance across tasks compared to existing methods, highlighting\nthe potential of hyperbolic embeddings for WSI analysis.", "AI": {"tldr": "HyperPath leverages hyperbolic space and textual descriptions to model semantic hierarchies in WSIs, improving classification via geometry-aware methods.", "motivation": "Existing methods for WSI analysis rely on Euclidean embeddings, which inadequately capture semantic hierarchies. HyperPath addresses this by integrating textual knowledge and hyperbolic space.", "method": "HyperPath adapts visual and textual features to hyperbolic space, using Angular Modality Alignment Loss and Semantic Hierarchy Consistency Loss for cross-modal alignment and hierarchy refinement. Classification uses geodesic distance.", "result": "HyperPath outperforms existing methods in WSI classification tasks, demonstrating the effectiveness of hyperbolic embeddings.", "conclusion": "Hyperbolic embeddings, guided by textual knowledge, enhance WSI analysis by better modeling semantic hierarchies, offering superior performance."}}
{"id": "2506.15840", "pdf": "https://arxiv.org/pdf/2506.15840", "abs": "https://arxiv.org/abs/2506.15840", "authors": ["Kevin Yin", "Julia Gersey", "Pei Zhang"], "title": "In-field Calibration of Low-Cost Sensors through XGBoost $\\&$ Aggregate Sensor Data", "categories": ["cs.LG"], "comment": "6 pages including citations", "summary": "Effective large-scale air quality monitoring necessitates distributed sensing\ndue to the pervasive and harmful nature of particulate matter (PM),\nparticularly in urban environments. However, precision comes at a cost: highly\naccurate sensors are expensive, limiting the spatial deployments and thus their\ncoverage. As a result, low-cost sensors have become popular, though they are\nprone to drift caused by environmental sensitivity and manufacturing\nvariability. This paper presents a model for in-field sensor calibration using\nXGBoost ensemble learning to consolidate data from neighboring sensors. This\napproach reduces dependence on the presumed accuracy of individual sensors and\nimproves generalization across different locations.", "AI": {"tldr": "A model using XGBoost for in-field calibration of low-cost air quality sensors improves accuracy by leveraging neighboring sensor data.", "motivation": "High-cost sensors limit large-scale air quality monitoring, while low-cost sensors suffer from drift due to environmental and manufacturing issues.", "method": "Proposes an XGBoost ensemble learning model to calibrate low-cost sensors using data from neighboring sensors.", "result": "Reduces reliance on individual sensor accuracy and enhances generalization across locations.", "conclusion": "The approach enables more effective large-scale air quality monitoring with improved sensor reliability."}}
{"id": "2506.15786", "pdf": "https://arxiv.org/pdf/2506.15786", "abs": "https://arxiv.org/abs/2506.15786", "authors": ["Peter Yichen Chen", "Minghao Guo", "Hanspeter Pfister", "Ming Lin", "William Freeman", "Qixing Huang", "Han-Wei Shen", "Wojciech Matusik"], "title": "Graphics4Science: Computer Graphics for Scientific Impacts", "categories": ["cs.GR", "cs.AI", "cs.LG", "physics.comp-ph", "physics.optics"], "comment": null, "summary": "Computer graphics, often associated with films, games, and visual effects,\nhas long been a powerful tool for addressing scientific challenges--from its\norigins in 3D visualization for medical imaging to its role in modern\ncomputational modeling and simulation. This course explores the deep and\nevolving relationship between computer graphics and science, highlighting past\nachievements, ongoing contributions, and open questions that remain. We show\nhow core methods, such as geometric reasoning and physical modeling, provide\ninductive biases that help address challenges in both fields, especially in\ndata-scarce settings. To that end, we aim to reframe graphics as a modeling\nlanguage for science by bridging vocabulary gaps between the two communities.\nDesigned for both newcomers and experts, Graphics4Science invites the graphics\ncommunity to engage with science, tackle high-impact problems where graphics\nexpertise can make a difference, and contribute to the future of scientific\ndiscovery. Additional details are available on the course website:\nhttps://graphics4science.github.io", "AI": {"tldr": "The paper explores the intersection of computer graphics and science, emphasizing its role in scientific modeling and simulation, and aims to bridge gaps between the two fields.", "motivation": "To highlight the evolving relationship between computer graphics and science, showcasing its potential as a modeling language for scientific challenges.", "method": "Core methods like geometric reasoning and physical modeling are used to address data-scarce problems, fostering collaboration between graphics and science communities.", "result": "Graphics is reframed as a tool for scientific discovery, with ongoing contributions and open questions identified.", "conclusion": "The course invites the graphics community to engage with science, tackle high-impact problems, and contribute to future scientific advancements."}}
{"id": "2506.16724", "pdf": "https://arxiv.org/pdf/2506.16724", "abs": "https://arxiv.org/abs/2506.16724", "authors": ["Xinyi Liu", "Weiguang Wang", "Hangfeng He"], "title": "The Role of Model Confidence on Bias Effects in Measured Uncertainties", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "With the growing adoption of Large Language Models (LLMs) for open-ended\ntasks, accurately assessing epistemic uncertainty, which reflects a model's\nlack of knowledge, has become crucial to ensuring reliable outcomes. However,\nquantifying epistemic uncertainty in such tasks is challenging due to the\npresence of aleatoric uncertainty, which arises from multiple valid answers.\nWhile bias can introduce noise into epistemic uncertainty estimation, it may\nalso reduce noise from aleatoric uncertainty. To investigate this trade-off, we\nconduct experiments on Visual Question Answering (VQA) tasks and find that\nmitigating prompt-introduced bias improves uncertainty quantification in\nGPT-4o. Building on prior work showing that LLMs tend to copy input information\nwhen model confidence is low, we further analyze how these prompt biases affect\nmeasured epistemic and aleatoric uncertainty across varying bias-free\nconfidence levels with GPT-4o and Qwen2-VL. We find that all considered biases\ninduce greater changes in both uncertainties when bias-free model confidence is\nlower. Moreover, lower bias-free model confidence leads to greater\nunderestimation of epistemic uncertainty (i.e. overconfidence) due to bias,\nwhereas it has no significant effect on the direction of changes in aleatoric\nuncertainty estimation. These distinct effects deepen our understanding of bias\nmitigation for uncertainty quantification and potentially inform the\ndevelopment of more advanced techniques.", "AI": {"tldr": "The paper investigates how bias affects epistemic and aleatoric uncertainty in LLMs, finding that mitigating prompt-introduced bias improves uncertainty quantification, especially when model confidence is low.", "motivation": "Accurately assessing epistemic uncertainty in LLMs is crucial for reliable outcomes, but it's complicated by aleatoric uncertainty and bias.", "method": "Experiments on Visual Question Answering tasks with GPT-4o and Qwen2-VL, analyzing the impact of bias on uncertainty quantification.", "result": "Bias induces greater changes in uncertainties when model confidence is low, leading to underestimation of epistemic uncertainty (overconfidence).", "conclusion": "Bias mitigation improves uncertainty quantification, and understanding its effects can inform advanced techniques for LLMs."}}
{"id": "2506.16407", "pdf": "https://arxiv.org/pdf/2506.16407", "abs": "https://arxiv.org/abs/2506.16407", "authors": ["Dong Nguyen Tien", "Dung D. Le"], "title": "Robustness Evaluation of OCR-based Visual Document Understanding under Multi-Modal Adversarial Attacks", "categories": ["cs.CV", "cs.AI"], "comment": "8 pages, 1 figure, under review at EMNLP 2025", "summary": "Visual Document Understanding (VDU) systems have achieved strong performance\nin information extraction by integrating textual, layout, and visual signals.\nHowever, their robustness under realistic adversarial perturbations remains\ninsufficiently explored. We introduce the first unified framework for\ngenerating and evaluating multi-modal adversarial attacks on OCR-based VDU\nmodels. Our method covers six gradient-based layout attack scenarios,\nincorporating manipulations of OCR bounding boxes, pixels, and texts across\nboth word and line granularities, with constraints on layout perturbation\nbudget (e.g., IoU >= 0.6) to preserve plausibility.\n  Experimental results across four datasets (FUNSD, CORD, SROIE, DocVQA) and\nsix model families demonstrate that line-level attacks and compound\nperturbations (BBox + Pixel + Text) yield the most severe performance\ndegradation. Projected Gradient Descent (PGD)-based BBox perturbations\noutperform random-shift baselines in all investigated models. Ablation studies\nfurther validate the impact of layout budget, text modification, and\nadversarial transferability.", "AI": {"tldr": "The paper introduces a unified framework for generating and evaluating multi-modal adversarial attacks on OCR-based VDU models, highlighting the effectiveness of line-level and compound perturbations.", "motivation": "To explore the robustness of Visual Document Understanding (VDU) systems under realistic adversarial perturbations, which remains understudied.", "method": "A framework covering six gradient-based layout attack scenarios, manipulating OCR bounding boxes, pixels, and texts at word and line granularities with layout perturbation constraints.", "result": "Line-level attacks and compound perturbations cause the most severe performance degradation; PGD-based BBox perturbations outperform random-shift baselines.", "conclusion": "The study validates the impact of layout budget, text modification, and adversarial transferability, emphasizing the vulnerability of VDU models to carefully crafted attacks."}}
{"id": "2506.15850", "pdf": "https://arxiv.org/pdf/2506.15850", "abs": "https://arxiv.org/abs/2506.15850", "authors": ["Pedro Mendes", "Paolo Romano", "David Garlan"], "title": "Uncertainty Estimation by Human Perception versus Neural Models", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Modern neural networks (NNs) often achieve high predictive accuracy but\nremain poorly calibrated, producing overconfident predictions even when wrong.\nThis miscalibration poses serious challenges in applications where reliable\nuncertainty estimates are critical. In this work, we investigate how human\nperceptual uncertainty compares to uncertainty estimated by NNs. Using three\nvision benchmarks annotated with both human disagreement and crowdsourced\nconfidence, we assess the correlation between model-predicted uncertainty and\nhuman-perceived uncertainty. Our results show that current methods only weakly\nalign with human intuition, with correlations varying significantly across\ntasks and uncertainty metrics. Notably, we find that incorporating\nhuman-derived soft labels into the training process can improve calibration\nwithout compromising accuracy. These findings reveal a persistent gap between\nmodel and human uncertainty and highlight the potential of leveraging human\ninsights to guide the development of more trustworthy AI systems.", "AI": {"tldr": "Neural networks often mispredict confidence. This paper compares human and NN uncertainty, finding weak alignment. Using human-derived labels improves calibration.", "motivation": "NNs are poorly calibrated, leading to overconfident predictions. Reliable uncertainty is critical for trustworthy AI.", "method": "Compare human and NN uncertainty on vision benchmarks with human disagreement and confidence annotations.", "result": "Current methods weakly align with human uncertainty. Human-derived labels improve calibration without losing accuracy.", "conclusion": "A gap exists between human and model uncertainty. Human insights can enhance AI trustworthiness."}}
{"id": "2506.15791", "pdf": "https://arxiv.org/pdf/2506.15791", "abs": "https://arxiv.org/abs/2506.15791", "authors": ["Albert Dorador"], "title": "TRUST: Transparent, Robust and Ultra-Sparse Trees", "categories": ["stat.ME", "cs.AI", "cs.LG", "stat.ML"], "comment": null, "summary": "Piecewise-constant regression trees remain popular for their\ninterpretability, yet often lag behind black-box models like Random Forest in\npredictive accuracy. In this work, we introduce TRUST (Transparent, Robust, and\nUltra-Sparse Trees), a novel regression tree model that combines the accuracy\nof Random Forests with the interpretability of shallow decision trees and\nsparse linear models. TRUST further enhances transparency by leveraging Large\nLanguage Models to generate tailored, user-friendly explanations. Extensive\nvalidation on synthetic and real-world benchmark datasets demonstrates that\nTRUST consistently outperforms other interpretable models -- including CART,\nLasso, and Node Harvest -- in predictive accuracy, while matching the accuracy\nof Random Forest and offering substantial gains in both accuracy and\ninterpretability over M5', a well-established model that is conceptually\nrelated.", "AI": {"tldr": "TRUST is a novel regression tree model combining Random Forest accuracy with interpretability, using LLMs for explanations, outperforming other interpretable models.", "motivation": "To bridge the gap between interpretability and predictive accuracy in regression trees, addressing the limitations of existing models like CART and Lasso.", "method": "Introduces TRUST, leveraging Large Language Models for explanations and combining Random Forest-like accuracy with sparse linear model interpretability.", "result": "TRUST outperforms interpretable models (CART, Lasso, Node Harvest) in accuracy, matches Random Forest, and surpasses M5' in accuracy and interpretability.", "conclusion": "TRUST successfully balances accuracy and interpretability, offering a transparent and robust alternative to black-box models."}}
{"id": "2506.16755", "pdf": "https://arxiv.org/pdf/2506.16755", "abs": "https://arxiv.org/abs/2506.16755", "authors": ["Lance Ying", "Ryan Truong", "Katherine M. Collins", "Cedegao E. Zhang", "Megan Wei", "Tyler Brooke-Wilson", "Tan Zhi-Xuan", "Lionel Wong", "Joshua B. Tenenbaum"], "title": "Language-Informed Synthesis of Rational Agent Models for Grounded Theory-of-Mind Reasoning On-The-Fly", "categories": ["cs.CL", "cs.AI"], "comment": "5 figures, 19 pages", "summary": "Drawing real world social inferences usually requires taking into account\ninformation from multiple modalities. Language is a particularly powerful\nsource of information in social settings, especially in novel situations where\nlanguage can provide both abstract information about the environment dynamics\nand concrete specifics about an agent that cannot be easily visually observed.\nIn this paper, we propose Language-Informed Rational Agent Synthesis (LIRAS), a\nframework for drawing context-specific social inferences that integrate\nlinguistic and visual inputs. LIRAS frames multimodal social reasoning as a\nprocess of constructing structured but situation-specific agent and environment\nrepresentations - leveraging multimodal language models to parse language and\nvisual inputs into unified symbolic representations, over which a Bayesian\ninverse planning engine can be run to produce granular probabilistic judgments.\nOn a range of existing and new social reasoning tasks derived from cognitive\nscience experiments, we find that our model (instantiated with a comparatively\nlightweight VLM) outperforms ablations and state-of-the-art models in capturing\nhuman judgments across all domains.", "AI": {"tldr": "LIRAS integrates linguistic and visual inputs for social reasoning, outperforming state-of-the-art models.", "motivation": "Language provides critical social insights, especially in novel situations where visual cues are insufficient.", "method": "LIRAS combines multimodal language models with Bayesian inverse planning to create unified symbolic representations.", "result": "The model outperforms ablations and state-of-the-art models in capturing human judgments.", "conclusion": "LIRAS effectively integrates language and vision for context-specific social inferences."}}
{"id": "2506.16421", "pdf": "https://arxiv.org/pdf/2506.16421", "abs": "https://arxiv.org/abs/2506.16421", "authors": ["Jan Skvrna", "Lukas Neumann"], "title": "Structured Semantic 3D Reconstruction (S23DR) Challenge 2025 -- Winning solution", "categories": ["cs.CV"], "comment": null, "summary": "This paper presents the winning solution for the S23DR Challenge 2025, which\ninvolves predicting a house's 3D roof wireframe from a sparse point cloud and\nsemantic segmentations. Our method operates directly in 3D, first identifying\nvertex candidates from the COLMAP point cloud using Gestalt segmentations. We\nthen employ two PointNet-like models: one to refine and classify these\ncandidates by analyzing local cubic patches, and a second to predict edges by\nprocessing the cylindrical regions connecting vertex pairs. This two-stage, 3D\ndeep learning approach achieved a winning Hybrid Structure Score (HSS) of 0.43\non the private leaderboard.", "AI": {"tldr": "Winning solution for S23DR Challenge 2025: a 3D deep learning method to predict house roof wireframes from sparse point clouds and semantic segmentations, achieving top HSS score.", "motivation": "The challenge involves predicting 3D roof wireframes from sparse data, requiring robust 3D analysis and deep learning techniques.", "method": "Two-stage 3D deep learning: (1) identify vertex candidates from COLMAP point cloud using Gestalt segmentations, (2) refine vertices and predict edges using two PointNet-like models.", "result": "Achieved a winning Hybrid Structure Score (HSS) of 0.43 on the private leaderboard.", "conclusion": "The two-stage 3D deep learning approach effectively predicts roof wireframes, demonstrating success in the challenge."}}
{"id": "2506.15864", "pdf": "https://arxiv.org/pdf/2506.15864", "abs": "https://arxiv.org/abs/2506.15864", "authors": ["Xixi Hu", "Runlong Liao", "Keyang Xu", "Bo Liu", "Yeqing Li", "Eugene Ie", "Hongliang Fei", "Qiang Liu"], "title": "Improving Rectified Flow with Boundary Conditions", "categories": ["cs.LG"], "comment": "14 pages", "summary": "Rectified Flow offers a simple and effective approach to high-quality\ngenerative modeling by learning a velocity field. However, we identify a\nlimitation in directly modeling the velocity with an unconstrained neural\nnetwork: the learned velocity often fails to satisfy certain boundary\nconditions, leading to inaccurate velocity field estimations that deviate from\nthe desired ODE. This issue is particularly critical during stochastic sampling\nat inference, as the score function's errors are amplified near the boundary.\nTo mitigate this, we propose a Boundary-enforced Rectified Flow Model (Boundary\nRF Model), in which we enforce boundary conditions with a minimal code\nmodification. Boundary RF Model improves performance over vanilla RF model,\ndemonstrating 8.01% improvement in FID score on ImageNet using ODE sampling and\n8.98% improvement using SDE sampling.", "AI": {"tldr": "Boundary-enforced Rectified Flow Model (Boundary RF Model) improves generative modeling by enforcing boundary conditions, outperforming vanilla RF with better FID scores.", "motivation": "The vanilla Rectified Flow model's unconstrained neural network for velocity field learning fails to meet boundary conditions, causing inaccuracies, especially during stochastic sampling.", "method": "Proposes Boundary RF Model, enforcing boundary conditions with minimal code changes to rectify velocity field estimation.", "result": "Achieves 8.01% FID improvement on ImageNet with ODE sampling and 8.98% with SDE sampling.", "conclusion": "Boundary RF Model effectively addresses boundary condition issues, enhancing generative modeling performance."}}
{"id": "2506.15793", "pdf": "https://arxiv.org/pdf/2506.15793", "abs": "https://arxiv.org/abs/2506.15793", "authors": ["Ruipeng Liu", "Qinru Qiu", "Simon Khan", "Garrett E. Katz"], "title": "Linearithmic Clean-up for Vector-Symbolic Key-Value Memory with Kroneker Rotation Products", "categories": ["cs.DS", "cs.AI"], "comment": "10 pages, 10 figures, conference paper", "summary": "A computational bottleneck in current Vector-Symbolic Architectures (VSAs) is\nthe ``clean-up'' step, which decodes the noisy vectors retrieved from the\narchitecture. Clean-up typically compares noisy vectors against a ``codebook''\nof prototype vectors, incurring computational complexity that is quadratic or\nsimilar. We present a new codebook representation that supports efficient\nclean-up, based on Kroneker products of rotation-like matrices. The resulting\nclean-up time complexity is linearithmic, i.e. $\\mathcal{O}(N\\,\\text{log}\\,N)$,\nwhere $N$ is the vector dimension and also the number of vectors in the\ncodebook. Clean-up space complexity is $\\mathcal{O}(N)$. Furthermore, the\ncodebook is not stored explicitly in computer memory: It can be represented in\n$\\mathcal{O}(\\text{log}\\,N)$ space, and individual vectors in the codebook can\nbe materialized in $\\mathcal{O}(N)$ time and space. At the same time,\nasymptotic memory capacity remains comparable to standard approaches. Computer\nexperiments confirm these results, demonstrating several orders of magnitude\nmore scalability than baseline VSA techniques.", "AI": {"tldr": "A new codebook representation for VSAs reduces clean-up complexity to linearithmic time and linear space, while maintaining memory capacity.", "motivation": "Current VSA clean-up steps are computationally expensive due to quadratic complexity.", "method": "Uses Kroneker products of rotation-like matrices for efficient clean-up.", "result": "Achieves linearithmic time and linear space complexity, with codebook stored implicitly.", "conclusion": "The method significantly improves scalability over baseline VSA techniques."}}
{"id": "2506.16756", "pdf": "https://arxiv.org/pdf/2506.16756", "abs": "https://arxiv.org/abs/2506.16756", "authors": ["Zhuang Chen", "Yaru Cao", "Guanqun Bi", "Jincenzi Wu", "Jinfeng Zhou", "Xiyao Xiao", "Si Chen", "Hongning Wang", "Minlie Huang"], "title": "SocialSim: Towards Socialized Simulation of Emotional Support Conversation", "categories": ["cs.CL"], "comment": "AAAI 2025 Paper #32116 (Without Publication Edits)", "summary": "Emotional support conversation (ESC) helps reduce people's psychological\nstress and provide emotional value through interactive dialogues. Due to the\nhigh cost of crowdsourcing a large ESC corpus, recent attempts use large\nlanguage models for dialogue augmentation. However, existing approaches largely\noverlook the social dynamics inherent in ESC, leading to less effective\nsimulations. In this paper, we introduce SocialSim, a novel framework that\nsimulates ESC by integrating key aspects of social interactions: social\ndisclosure and social awareness. On the seeker side, we facilitate social\ndisclosure by constructing a comprehensive persona bank that captures diverse\nand authentic help-seeking scenarios. On the supporter side, we enhance social\nawareness by eliciting cognitive reasoning to generate logical and supportive\nresponses. Building upon SocialSim, we construct SSConv, a large-scale\nsynthetic ESC corpus of which quality can even surpass crowdsourced ESC data.\nWe further train a chatbot on SSConv and demonstrate its state-of-the-art\nperformance in both automatic and human evaluations. We believe SocialSim\noffers a scalable way to synthesize ESC, making emotional care more accessible\nand practical.", "AI": {"tldr": "SocialSim is a framework for simulating emotional support conversations by integrating social disclosure and awareness, outperforming crowdsourced data in quality.", "motivation": "High costs of crowdsourcing ESC data and the oversight of social dynamics in existing methods necessitate a scalable, effective simulation approach.", "method": "SocialSim uses a persona bank for social disclosure and cognitive reasoning for social awareness, creating the SSConv corpus.", "result": "SSConv surpasses crowdsourced ESC data in quality, and a chatbot trained on it achieves state-of-the-art performance.", "conclusion": "SocialSim provides a scalable, high-quality solution for synthesizing ESC, enhancing accessibility to emotional care."}}
{"id": "2506.16450", "pdf": "https://arxiv.org/pdf/2506.16450", "abs": "https://arxiv.org/abs/2506.16450", "authors": ["Giuseppe Lando", "Rosario Forte", "Giovanni Maria Farinella", "Antonino Furnari"], "title": "How Far Can Off-the-Shelf Multimodal Large Language Models Go in Online Episodic Memory Question Answering?", "categories": ["cs.CV"], "comment": null, "summary": "We investigate whether off-the-shelf Multimodal Large Language Models (MLLMs)\ncan tackle Online Episodic-Memory Video Question Answering (OEM-VQA) without\nadditional training. Our pipeline converts a streaming egocentric video into a\nlightweight textual memory, only a few kilobytes per minute, via an MLLM\ndescriptor module, and answers multiple-choice questions by querying this\nmemory with an LLM reasoner module. On the QAEgo4D-Closed benchmark, our best\nconfiguration attains 56.0% accuracy with 3.6 kB per minute storage, matching\nthe performance of dedicated state-of-the-art systems while being 10**4/10**5\ntimes more memory-efficient. Extensive ablations provides insights into the\nrole of each component and design choice, and highlight directions of\nimprovement for future research.", "AI": {"tldr": "Off-the-shelf MLLMs achieve competitive performance in OEM-VQA without training, using lightweight textual memory (3.6 kB/min) and matching SOTA systems in accuracy.", "motivation": "To explore if MLLMs can handle OEM-VQA without additional training, focusing on memory efficiency and performance.", "method": "Convert streaming video to lightweight textual memory via MLLM descriptor, answer questions using LLM reasoner.", "result": "56.0% accuracy on QAEgo4D-Closed, 3.6 kB/min storage, matching SOTA with 10^4/10^5 better memory efficiency.", "conclusion": "MLLMs can effectively tackle OEM-VQA, offering insights for future improvements in memory and performance."}}
{"id": "2506.15872", "pdf": "https://arxiv.org/pdf/2506.15872", "abs": "https://arxiv.org/abs/2506.15872", "authors": ["Sara Kangaslahti", "Elan Rosenfeld", "Naomi Saphra"], "title": "Hidden Breakthroughs in Language Model Training", "categories": ["cs.LG"], "comment": "17 pages, 10 figures", "summary": "Loss curves are smooth during most of model training, so visible\ndiscontinuities stand out as possible conceptual breakthroughs. Studying these\nbreakthroughs enables a deeper understanding of learning dynamics, but only\nwhen they are properly identified. This paper argues that similar breakthroughs\noccur frequently throughout training but they are obscured by a loss metric\nthat collapses all variation into a single scalar. To find these hidden\ntransitions, we introduce POLCA, a method for decomposing changes in loss along\narbitrary bases of the low-rank training subspace. We use our method to\nidentify clusters of samples that share similar changes in loss during\ntraining, disaggregating the overall loss into that of smaller groups of\nconceptually similar data. We validate our method on synthetic arithmetic and\nnatural language tasks, showing that POLCA recovers clusters that represent\ninterpretable breakthroughs in the model's capabilities. We demonstrate the\npromise of these hidden phase transitions as a tool for unsupervised\ninterpretability.", "AI": {"tldr": "POLCA identifies hidden training breakthroughs by decomposing loss changes along low-rank subspaces, revealing interpretable clusters of data.", "motivation": "Visible discontinuities in loss curves may indicate breakthroughs, but many are obscured by scalar loss metrics. This paper aims to uncover hidden transitions for deeper learning insights.", "method": "Introduces POLCA, a method to decompose loss changes along low-rank training subspaces, identifying clusters of samples with similar loss dynamics.", "result": "Validated on synthetic and natural language tasks, POLCA successfully recovers interpretable clusters representing model capability breakthroughs.", "conclusion": "POLCA offers a promising tool for unsupervised interpretability by revealing hidden phase transitions in training."}}
{"id": "2506.15803", "pdf": "https://arxiv.org/pdf/2506.15803", "abs": "https://arxiv.org/abs/2506.15803", "authors": ["Bohan Yang", "Gang Liu", "Rirao Dao", "Yujia Qian", "Ke Shi", "Anke Tang", "Yong Luo", "Jingnan Liu"], "title": "Unsupervised deep learning model for fast energy layer pre-selection of delivery-efficient proton arc therapy plan optimization of nasopharyngeal carcinoma", "categories": ["physics.med-ph", "cs.AI"], "comment": null, "summary": "Objective. Proton arc therapy (PAT) is an emerging and promising modality in\nradiotherapy, offering several advantages over conventional intensitymodulated\nproton therapy (IMPT). However, identifying the optimal energy layer (EL)\nsequence remains computationally intensive due to the large number of possible\nenergy layer transitions. This study proposes an unsupervised deep learning\nframework for fast and effective EL pre-selection, aiming to minimize energy\nlayer switch time while preserving high plan quality. Approach. We introduce a\nnovel data representation method, spot-count representation, which encodes the\nnumber of proton spots intersecting the target and organs at risk (OARs) in a\nmatrix structured by sorted gantry angles and energy layers. This\nrepresentation is the input of a UNet-based architecture, SPArcdl, which is\ntrained to optimize a tri-objective function: maximizing target coverage,\nminimizing OAR exposure, and reducing energy switching time. The model is\nevaluated on 54 nasopharyngeal cancer cases, and its performance is benchmarked\nagainst plans generated by SPArcparticle swarm. Main results. SPArcdl produces\nEL pre-selection that significantly improves both plan quality and delivery\nefficiency. Compared to SPArc particle swarm, it enhances the conformity index\nby 0.16 (p < 0.01), reduces the homogeneity index by 0.71 (p < 0.01), shortens\nthe energy switching time by 38.4% (p < 0.01), and lowers the mean dose to\nbrainstem by 0.21 (p < 0.01). The results unintentionally reveal employing\nunchanged ELS is more time-wise efficient than descended ELS. SPArcdl's\ninference time is within 1 second. Significance. SPArcdl is a fast and\neffective tool for generating high-quality PAT plans by strategically\npre-selecting energy layers to reduce delivery time while maintaining excellent\ndosimetric performance.", "AI": {"tldr": "Proposes SPArcdl, an unsupervised deep learning framework for fast energy layer pre-selection in proton arc therapy, improving plan quality and delivery efficiency.", "motivation": "Optimizing energy layer sequences in proton arc therapy is computationally intensive; SPArcdl aims to simplify this while maintaining high plan quality.", "method": "Uses spot-count representation and a UNet-based architecture (SPArcdl) to optimize target coverage, OAR exposure, and energy switching time.", "result": "SPArcdl outperforms SPArc particle swarm, improving conformity, homogeneity, and reducing switching time and brainstem dose.", "conclusion": "SPArcdl is a fast, effective tool for high-quality proton arc therapy plans with reduced delivery time."}}
{"id": "2506.16760", "pdf": "https://arxiv.org/pdf/2506.16760", "abs": "https://arxiv.org/abs/2506.16760", "authors": ["Lei Jiang", "Zixun Zhang", "Zizhou Wang", "Xiaobing Sun", "Zhen Li", "Liangli Zhen", "Xiaohua Xu"], "title": "Cross-Modal Obfuscation for Jailbreak Attacks on Large Vision-Language Models", "categories": ["cs.CL", "cs.CV"], "comment": "15 pages, 9 figures", "summary": "Large Vision-Language Models (LVLMs) demonstrate exceptional performance\nacross multimodal tasks, yet remain vulnerable to jailbreak attacks that bypass\nbuilt-in safety mechanisms to elicit restricted content generation. Existing\nblack-box jailbreak methods primarily rely on adversarial textual prompts or\nimage perturbations, yet these approaches are highly detectable by standard\ncontent filtering systems and exhibit low query and computational efficiency.\nIn this work, we present Cross-modal Adversarial Multimodal Obfuscation (CAMO),\na novel black-box jailbreak attack framework that decomposes malicious prompts\ninto semantically benign visual and textual fragments. By leveraging LVLMs'\ncross-modal reasoning abilities, CAMO covertly reconstructs harmful\ninstructions through multi-step reasoning, evading conventional detection\nmechanisms. Our approach supports adjustable reasoning complexity and requires\nsignificantly fewer queries than prior attacks, enabling both stealth and\nefficiency. Comprehensive evaluations conducted on leading LVLMs validate\nCAMO's effectiveness, showcasing robust performance and strong cross-model\ntransferability. These results underscore significant vulnerabilities in\ncurrent built-in safety mechanisms, emphasizing an urgent need for advanced,\nalignment-aware security and safety solutions in vision-language systems.", "AI": {"tldr": "CAMO introduces a stealthy, efficient black-box jailbreak attack for LVLMs by decomposing malicious prompts into benign visual and textual fragments, evading detection.", "motivation": "Existing jailbreak methods are detectable and inefficient; CAMO aims to exploit LVLMs' cross-modal reasoning for covert attacks.", "method": "CAMO decomposes harmful prompts into benign fragments, leveraging LVLMs' cross-modal reasoning to reconstruct malicious instructions.", "result": "CAMO outperforms prior attacks in stealth and efficiency, demonstrating robust performance and cross-model transferability.", "conclusion": "CAMO highlights vulnerabilities in LVLMs' safety mechanisms, calling for advanced security solutions."}}
{"id": "2506.16497", "pdf": "https://arxiv.org/pdf/2506.16497", "abs": "https://arxiv.org/abs/2506.16497", "authors": ["Riccardo Ziglio", "Cecilia Pasquini", "Silvio Ranise"], "title": "Spotting tell-tale visual artifacts in face swapping videos: strengths and pitfalls of CNN detectors", "categories": ["cs.CV", "cs.AI", "cs.CR"], "comment": "8 pages, 4 figures, workshop paper", "summary": "Face swapping manipulations in video streams represents an increasing threat\nin remote video communications, due to advances\n  in automated and real-time tools. Recent literature proposes to characterize\nand exploit visual artifacts introduced in video frames\n  by swapping algorithms when dealing with challenging physical scenes, such as\nface occlusions. This paper investigates the\n  effectiveness of this approach by benchmarking CNN-based data-driven models\non two data corpora (including a newly collected\n  one) and analyzing generalization capabilities with respect to different\nacquisition sources and swapping algorithms. The results\n  confirm excellent performance of general-purpose CNN architectures when\noperating within the same data source, but a significant\n  difficulty in robustly characterizing occlusion-based visual cues across\ndatasets. This highlights the need for specialized detection\n  strategies to deal with such artifacts.", "AI": {"tldr": "The paper evaluates CNN-based models for detecting face-swapping in videos, focusing on occlusion artifacts. While models perform well within the same dataset, they struggle with generalization across sources.", "motivation": "Face swapping in videos is a growing threat due to advanced real-time tools, necessitating robust detection methods, especially for occlusion artifacts.", "method": "Benchmarking CNN-based models on two datasets (one newly collected) to analyze generalization across sources and swapping algorithms.", "result": "CNNs excel within the same dataset but fail to generalize occlusion-based cues across different sources.", "conclusion": "Specialized detection strategies are needed to handle occlusion artifacts robustly in face-swapping detection."}}
{"id": "2506.15879", "pdf": "https://arxiv.org/pdf/2506.15879", "abs": "https://arxiv.org/abs/2506.15879", "authors": ["Abdel Rahman Alsheyab", "Mohammad Alkhasawneh", "Nidal Shahin"], "title": "Job Market Cheat Codes: Prototyping Salary Prediction and Job Grouping with Synthetic Job Listings", "categories": ["cs.LG"], "comment": "8 pages, 5 figures, synthetic data only, experimental work", "summary": "This paper presents a machine learning methodology prototype using a large\nsynthetic dataset of job listings to identify trends, predict salaries, and\ngroup similar job roles. Employing techniques such as regression,\nclassification, clustering, and natural language processing (NLP) for\ntext-based feature extraction and representation, this study aims to uncover\nthe key features influencing job market dynamics and provide valuable insights\nfor job seekers, employers, and researchers. Exploratory data analysis was\nconducted to understand the dataset's characteristics. Subsequently, regression\nmodels were developed to predict salaries, classification models to predict job\ntitles, and clustering techniques were applied to group similar jobs. The\nanalyses revealed significant factors influencing salary and job roles, and\nidentified distinct job clusters based on the provided data. While the results\nare based on synthetic data and not intended for real-world deployment, the\nmethodology demonstrates a transferable framework for job market analysis.", "AI": {"tldr": "A machine learning prototype analyzes synthetic job data to predict salaries, classify roles, and cluster jobs using regression, classification, clustering, and NLP.", "motivation": "To uncover job market trends and provide insights for job seekers, employers, and researchers.", "method": "Uses regression for salary prediction, classification for job titles, clustering for grouping jobs, and NLP for text feature extraction.", "result": "Identified key salary and role influencers and distinct job clusters, though based on synthetic data.", "conclusion": "The methodology offers a transferable framework for job market analysis, despite synthetic data limitations."}}
{"id": "2506.15828", "pdf": "https://arxiv.org/pdf/2506.15828", "abs": "https://arxiv.org/abs/2506.15828", "authors": ["Emanuele Musumeci", "Michele Brienza", "Francesco Argenziano", "Vincenzo Suriani", "Daniele Nardi", "Domenico D. Bloisi"], "title": "Context Matters! Relaxing Goals with LLMs for Feasible 3D Scene Planning", "categories": ["cs.RO", "cs.AI"], "comment": null, "summary": "Classical planning in AI and Robotics addresses complex tasks by shifting\nfrom imperative to declarative approaches (e.g., PDDL). However, these methods\noften fail in real scenarios due to limited robot perception and the need to\nground perceptions to planning predicates. This often results in heavily\nhard-coded behaviors that struggle to adapt, even with scenarios where goals\ncan be achieved through relaxed planning. Meanwhile, Large Language Models\n(LLMs) lead to planning systems that leverage commonsense reasoning but often\nat the cost of generating unfeasible and/or unsafe plans. To address these\nlimitations, we present an approach integrating classical planning with LLMs,\nleveraging their ability to extract commonsense knowledge and ground actions.\nWe propose a hierarchical formulation that enables robots to make unfeasible\ntasks tractable by defining functionally equivalent goals through gradual\nrelaxation. This mechanism supports partial achievement of the intended\nobjective, suited to the agent's specific context. Our method demonstrates its\nability to adapt and execute tasks effectively within environments modeled\nusing 3D Scene Graphs through comprehensive qualitative and quantitative\nevaluations. We also show how this method succeeds in complex scenarios where\nother benchmark methods are more likely to fail. Code, dataset, and additional\nmaterial are released to the community.", "AI": {"tldr": "The paper integrates classical planning with LLMs to address limitations in robot perception and grounding, proposing a hierarchical method for adaptable task execution.", "motivation": "Classical planning and LLMs each have limitations in robotics\u2014hard-coded behaviors and unfeasible plans, respectively. The goal is to combine their strengths for robust planning.", "method": "A hierarchical approach combines classical planning with LLMs, using gradual goal relaxation to make tasks tractable and adaptable to the robot's context.", "result": "The method effectively adapts and executes tasks in 3D Scene Graph environments, outperforming benchmarks in complex scenarios.", "conclusion": "The integration of classical planning and LLMs offers a viable solution for adaptable and feasible robotic task execution, supported by released resources."}}
{"id": "2506.16777", "pdf": "https://arxiv.org/pdf/2506.16777", "abs": "https://arxiv.org/abs/2506.16777", "authors": ["Heloisa Oss Boll", "Antonio Oss Boll", "Leticia Puttlitz Boll", "Ameen Abu Hanna", "Iacer Calixto"], "title": "DistillNote: LLM-based clinical note summaries improve heart failure diagnosis", "categories": ["cs.CL"], "comment": null, "summary": "Large language models (LLMs) offer unprecedented opportunities to generate\nconcise summaries of patient information and alleviate the burden of clinical\ndocumentation that overwhelms healthcare providers. We present Distillnote, a\nframework for LLM-based clinical note summarization, and generate over 64,000\nadmission note summaries through three techniques: (1) One-step, direct\nsummarization, and a divide-and-conquer approach involving (2) Structured\nsummarization focused on independent clinical insights, and (3) Distilled\nsummarization that further condenses the Structured summaries. We test how\nuseful are the summaries by using them to predict heart failure compared to a\nmodel trained on the original notes. Distilled summaries achieve 79% text\ncompression and up to 18.2% improvement in AUPRC compared to an LLM trained on\nthe full notes. We also evaluate the quality of the generated summaries in an\nLLM-as-judge evaluation as well as through blinded pairwise comparisons with\nclinicians. Evaluations indicate that one-step summaries are favoured by\nclinicians according to relevance and clinical actionability, while distilled\nsummaries offer optimal efficiency (avg. 6.9x compression-to-performance ratio)\nand significantly reduce hallucinations. We release our summaries on PhysioNet\nto encourage future research.", "AI": {"tldr": "Distillnote, an LLM-based framework, generates clinical note summaries using three techniques, achieving high compression and improved predictive performance for heart failure, with clinician preference for one-step summaries and efficiency for distilled summaries.", "motivation": "To alleviate the burden of clinical documentation by generating concise summaries of patient information using LLMs.", "method": "Three summarization techniques: (1) One-step direct summarization, (2) Structured summarization, and (3) Distilled summarization. Evaluated using predictive performance (AUPRC), LLM-as-judge, and clinician comparisons.", "result": "Distilled summaries achieve 79% text compression and 18.2% AUPRC improvement. One-step summaries are preferred for relevance, while distilled summaries excel in efficiency and reduce hallucinations.", "conclusion": "Distillnote effectively balances summary quality and efficiency, with potential to enhance clinical documentation and decision-making."}}
{"id": "2506.16504", "pdf": "https://arxiv.org/pdf/2506.16504", "abs": "https://arxiv.org/abs/2506.16504", "authors": ["Zeqiang Lai", "Yunfei Zhao", "Haolin Liu", "Zibo Zhao", "Qingxiang Lin", "Huiwen Shi", "Xianghui Yang", "Mingxin Yang", "Shuhui Yang", "Yifei Feng", "Sheng Zhang", "Xin Huang", "Di Luo", "Fan Yang", "Fang Yang", "Lifu Wang", "Sicong Liu", "Yixuan Tang", "Yulin Cai", "Zebin He", "Tian Liu", "Yuhong Liu", "Jie Jiang", "Linus", "Jingwei Huang", "Chunchao Guo"], "title": "Hunyuan3D 2.5: Towards High-Fidelity 3D Assets Generation with Ultimate Details", "categories": ["cs.CV", "cs.AI"], "comment": "Technical report", "summary": "In this report, we present Hunyuan3D 2.5, a robust suite of 3D diffusion\nmodels aimed at generating high-fidelity and detailed textured 3D assets.\nHunyuan3D 2.5 follows two-stages pipeline of its previous version Hunyuan3D\n2.0, while demonstrating substantial advancements in both shape and texture\ngeneration. In terms of shape generation, we introduce a new shape foundation\nmodel -- LATTICE, which is trained with scaled high-quality datasets,\nmodel-size, and compute. Our largest model reaches 10B parameters and generates\nsharp and detailed 3D shape with precise image-3D following while keeping mesh\nsurface clean and smooth, significantly closing the gap between generated and\nhandcrafted 3D shapes. In terms of texture generation, it is upgraded with\nphyiscal-based rendering (PBR) via a novel multi-view architecture extended\nfrom Hunyuan3D 2.0 Paint model. Our extensive evaluation shows that Hunyuan3D\n2.5 significantly outperforms previous methods in both shape and end-to-end\ntexture generation.", "AI": {"tldr": "Hunyuan3D 2.5 is an advanced 3D diffusion model suite improving shape and texture generation, featuring a 10B-parameter shape model (LATTICE) and PBR-based texture upgrades.", "motivation": "To bridge the gap between generated and handcrafted 3D assets by enhancing fidelity and detail in shape and texture.", "method": "Two-stage pipeline with a new shape foundation model (LATTICE) and PBR-based texture generation via a multi-view architecture.", "result": "Outperforms previous methods in shape and texture generation, producing clean, smooth, and detailed 3D assets.", "conclusion": "Hunyuan3D 2.5 sets a new benchmark for high-fidelity 3D asset generation."}}
{"id": "2506.15881", "pdf": "https://arxiv.org/pdf/2506.15881", "abs": "https://arxiv.org/abs/2506.15881", "authors": ["Alexey Yermakov", "David Zoro", "Mars Liyao Gao", "J. Nathan Kutz"], "title": "T-SHRED: Symbolic Regression for Regularization and Model Discovery with Transformer Shallow Recurrent Decoders", "categories": ["cs.LG"], "comment": "16 pages, 5 figures, submitted to Transactions of the Royal Society\n  (Symbolic Regression in the Physical Sciences)", "summary": "SHallow REcurrent Decoders (SHRED) are effective for system identification\nand forecasting from sparse sensor measurements. Such models are light-weight\nand computationally efficient, allowing them to be trained on consumer laptops.\nSHRED-based models rely on Recurrent Neural Networks (RNNs) and a simple\nMulti-Layer Perceptron (MLP) for the temporal encoding and spatial decoding\nrespectively. Despite the relatively simple structure of SHRED, they are able\nto predict chaotic dynamical systems on different physical, spatial, and\ntemporal scales directly from a sparse set of sensor measurements. In this\nwork, we improve SHRED by leveraging transformers (T-SHRED) for the temporal\nencoding which improves performance on next-step state prediction on large\ndatasets. We also introduce a sparse identification of nonlinear dynamics\n(SINDy) attention mechanism into T-SHRED to perform symbolic regression\ndirectly on the latent space as part of the model regularization architecture.\nSymbolic regression improves model interpretability by learning and\nregularizing the dynamics of the latent space during training. We analyze the\nperformance of T-SHRED on three different dynamical systems ranging from\nlow-data to high-data regimes. We observe that SINDy attention T-SHRED\naccurately predicts future frames based on an interpretable symbolic model\nacross all tested datasets.", "AI": {"tldr": "SHRED models, using RNNs and MLPs, are lightweight and effective for chaotic system prediction. The improved T-SHRED with transformers and SINDy attention enhances performance and interpretability.", "motivation": "To improve SHRED models by incorporating transformers for better temporal encoding and adding SINDy attention for symbolic regression, enhancing both performance and interpretability.", "method": "Leverage transformers (T-SHRED) for temporal encoding and introduce SINDy attention for symbolic regression in the latent space.", "result": "T-SHRED with SINDy attention accurately predicts future states and provides interpretable symbolic models across various datasets.", "conclusion": "The enhanced T-SHRED model outperforms SHRED, offering better prediction accuracy and interpretability through symbolic regression."}}
{"id": "2506.15847", "pdf": "https://arxiv.org/pdf/2506.15847", "abs": "https://arxiv.org/abs/2506.15847", "authors": ["Arpit Bahety", "Arnav Balaji", "Ben Abbatematteo", "Roberto Mart\u00edn-Mart\u00edn"], "title": "SafeMimic: Towards Safe and Autonomous Human-to-Robot Imitation for Mobile Manipulation", "categories": ["cs.RO", "cs.AI"], "comment": null, "summary": "For robots to become efficient helpers in the home, they must learn to\nperform new mobile manipulation tasks simply by watching humans perform them.\nLearning from a single video demonstration from a human is challenging as the\nrobot needs to first extract from the demo what needs to be done and how,\ntranslate the strategy from a third to a first-person perspective, and then\nadapt it to be successful with its own morphology. Furthermore, to mitigate the\ndependency on costly human monitoring, this learning process should be\nperformed in a safe and autonomous manner. We present SafeMimic, a framework to\nlearn new mobile manipulation skills safely and autonomously from a single\nthird-person human video. Given an initial human video demonstration of a\nmulti-step mobile manipulation task, SafeMimic first parses the video into\nsegments, inferring both the semantic changes caused and the motions the human\nexecuted to achieve them and translating them to an egocentric reference. Then,\nit adapts the behavior to the robot's own morphology by sampling candidate\nactions around the human ones, and verifying them for safety before execution\nin a receding horizon fashion using an ensemble of safety Q-functions trained\nin simulation. When safe forward progression is not possible, SafeMimic\nbacktracks to previous states and attempts a different sequence of actions,\nadapting both the trajectory and the grasping modes when required for its\nmorphology. As a result, SafeMimic yields a strategy that succeeds in the\ndemonstrated behavior and learns task-specific actions that reduce exploration\nin future attempts. Our experiments show that our method allows robots to\nsafely and efficiently learn multi-step mobile manipulation behaviors from a\nsingle human demonstration, from different users, and in different\nenvironments, with improvements over state-of-the-art baselines across seven\ntasks", "AI": {"tldr": "SafeMimic enables robots to learn mobile manipulation tasks safely and autonomously from a single human video demonstration, adapting actions to the robot's morphology and ensuring safety.", "motivation": "Robots need to learn tasks from human demonstrations efficiently and autonomously, reducing dependency on human monitoring while ensuring safety.", "method": "SafeMimic parses human videos into segments, translates actions to the robot's perspective, samples candidate actions, verifies safety, and adapts trajectories as needed.", "result": "The framework successfully learns multi-step tasks from single demonstrations, improving over baselines in seven tasks.", "conclusion": "SafeMimic provides a robust, safe, and efficient method for robots to learn complex tasks from human videos."}}
{"id": "2506.16792", "pdf": "https://arxiv.org/pdf/2506.16792", "abs": "https://arxiv.org/abs/2506.16792", "authors": ["Muyang Zheng", "Yuanzhi Yao", "Changting Lin", "Rui Wang", "Meng Han"], "title": "MIST: Jailbreaking Black-box Large Language Models via Iterative Semantic Tuning", "categories": ["cs.CL", "cs.AI"], "comment": "12 pages, 3 figures", "summary": "Despite efforts to align large language models (LLMs) with societal and moral\nvalues, these models remain susceptible to jailbreak attacks--methods designed\nto elicit harmful responses. Jailbreaking black-box LLMs is considered\nchallenging due to the discrete nature of token inputs, restricted access to\nthe target LLM, and limited query budget. To address the issues above, we\npropose an effective method for jailbreaking black-box large language Models\nvia Iterative Semantic Tuning, named MIST. MIST enables attackers to\niteratively refine prompts that preserve the original semantic intent while\ninducing harmful content. Specifically, to balance semantic similarity with\ncomputational efficiency, MIST incorporates two key strategies: sequential\nsynonym search, and its advanced version--order-determining optimization.\nExtensive experiments across two open-source models and four closed-source\nmodels demonstrate that MIST achieves competitive attack success rates and\nattack transferability compared with other state-of-the-art white-box and\nblack-box jailbreak methods. Additionally, we conduct experiments on\ncomputational efficiency to validate the practical viability of MIST.", "AI": {"tldr": "The paper introduces MIST, an iterative semantic tuning method for jailbreaking black-box LLMs, achieving high success rates and efficiency.", "motivation": "Despite alignment efforts, LLMs remain vulnerable to jailbreak attacks due to discrete inputs, restricted access, and limited queries.", "method": "MIST uses sequential synonym search and order-determining optimization to refine prompts for harmful content while preserving intent.", "result": "MIST outperforms state-of-the-art methods in attack success and transferability across multiple models.", "conclusion": "MIST is a practical and efficient solution for jailbreaking black-box LLMs."}}
{"id": "2506.16531", "pdf": "https://arxiv.org/pdf/2506.16531", "abs": "https://arxiv.org/abs/2506.16531", "authors": ["Mei Qi Tang", "Sean Sedwards", "Chengjie Huang", "Krzysztof Czarnecki"], "title": "How Hard Is Snow? A Paired Domain Adaptation Dataset for Clear and Snowy Weather: CADC+", "categories": ["cs.CV"], "comment": "IEEE IV 2025", "summary": "The impact of snowfall on 3D object detection performance remains\nunderexplored. Conducting such an evaluation requires a dataset with sufficient\nlabelled data from both weather conditions, ideally captured in the same\ndriving environment. Current driving datasets with LiDAR point clouds either do\nnot provide enough labelled data in both snowy and clear weather conditions, or\nrely on de-snowing methods to generate synthetic clear weather. Synthetic data\noften lacks realism and introduces an additional domain shift that confounds\naccurate evaluations. To address these challenges, we present CADC+, the first\npaired weather domain adaptation dataset for autonomous driving in winter\nconditions. CADC+ extends the Canadian Adverse Driving Conditions dataset\n(CADC) using clear weather data that was recorded on the same roads and in the\nsame period as CADC. To create CADC+, we pair each CADC sequence with a clear\nweather sequence that matches the snowy sequence as closely as possible. CADC+\nthus minimizes the domain shift resulting from factors unrelated to the\npresence of snow. We also present some preliminary results using CADC+ to\nevaluate the effect of snow on 3D object detection performance. We observe that\nsnow introduces a combination of aleatoric and epistemic uncertainties, acting\nas both noise and a distinct data domain.", "AI": {"tldr": "CADC+ is a paired weather domain adaptation dataset for autonomous driving in winter, addressing the lack of realistic snowy and clear weather data for 3D object detection evaluation.", "motivation": "The impact of snowfall on 3D object detection is underexplored due to insufficient labeled data in both snowy and clear conditions, and synthetic data lacks realism.", "method": "CADC+ extends the CADC dataset by pairing snowy sequences with clear weather sequences recorded on the same roads and period, minimizing domain shift.", "result": "Preliminary results show snow introduces aleatoric and epistemic uncertainties, acting as both noise and a distinct data domain.", "conclusion": "CADC+ provides a realistic dataset for evaluating snow's impact on 3D object detection, revealing its dual role as noise and a unique domain."}}
{"id": "2506.15882", "pdf": "https://arxiv.org/pdf/2506.15882", "abs": "https://arxiv.org/abs/2506.15882", "authors": ["Sheng Liu", "Tianlang Chen", "Pan Lu", "Haotian Ye", "Yizheng Chen", "Lei Xing", "James Zou"], "title": "Fractional Reasoning via Latent Steering Vectors Improves Inference Time Compute", "categories": ["cs.LG", "cs.AI", "cs.CL", "eess.SP"], "comment": "18 pages, 5 figures, Project website:\n  https://shengliu66.github.io/fractreason/", "summary": "Test-time compute has emerged as a powerful paradigm for improving the\nperformance of large language models (LLMs), where generating multiple outputs\nor refining individual chains can significantly boost answer accuracy. However,\nexisting methods like Best-of-N, majority voting, and self-reflection typically\napply reasoning in a uniform way across inputs, overlooking the fact that\ndifferent problems may require different levels of reasoning depth. In this\nwork, we propose Fractional Reasoning, a training-free and model-agnostic\nframework that enables continuous control over reasoning intensity at inference\ntime, going beyond the limitations of fixed instructional prompts. Our method\noperates by extracting the latent steering vector associated with deeper\nreasoning and reapplying it with a tunable scaling factor, allowing the model\nto tailor its reasoning process to the complexity of each input. This supports\ntwo key modes of test-time scaling: (1) improving output quality in\nbreadth-based strategies (e.g., Best-of-N, majority voting), and (2) enhancing\nthe correctness of individual reasoning chains in depth-based strategies (e.g.,\nself-reflection). Experiments on GSM8K, MATH500, and GPQA demonstrate that\nFractional Reasoning consistently improves performance across diverse reasoning\ntasks and models.", "AI": {"tldr": "Fractional Reasoning is a training-free, model-agnostic framework for dynamically adjusting reasoning intensity at inference time, improving performance in diverse tasks.", "motivation": "Existing methods apply uniform reasoning across inputs, ignoring varying problem complexities. Fractional Reasoning addresses this by enabling tailored reasoning depth.", "method": "Extracts a latent steering vector for deeper reasoning and scales it dynamically, supporting breadth- and depth-based strategies.", "result": "Experiments on GSM8K, MATH500, and GPQA show consistent performance improvements across tasks and models.", "conclusion": "Fractional Reasoning offers flexible, input-adaptive reasoning, outperforming fixed methods in accuracy and correctness."}}
{"id": "2506.15862", "pdf": "https://arxiv.org/pdf/2506.15862", "abs": "https://arxiv.org/abs/2506.15862", "authors": ["Jushaan Singh Kalra", "Xinran Zhao", "To Eun Kim", "Fengyu Cai", "Fernando Diaz", "Tongshuang Wu"], "title": "MoR: Better Handling Diverse Queries with a Mixture of Sparse, Dense, and Human Retrievers", "categories": ["cs.IR", "cs.AI", "cs.CL"], "comment": "19 pages, 3 figures", "summary": "Retrieval-augmented Generation (RAG) is powerful, but its effectiveness\nhinges on which retrievers we use and how. Different retrievers offer distinct,\noften complementary signals: BM25 captures lexical matches; dense retrievers,\nsemantic similarity. Yet in practice, we typically fix a single retriever based\non heuristics, which fails to generalize across diverse information needs. Can\nwe dynamically select and integrate multiple retrievers for each individual\nquery, without the need for manual selection? In our work, we validate this\nintuition with quantitative analysis and introduce mixture of retrievers: a\nzero-shot, weighted combination of heterogeneous retrievers. Extensive\nexperiments show that such mixtures are effective and efficient: Despite\ntotaling just 0.8B parameters, this mixture outperforms every individual\nretriever and even larger 7B models by +10.8% and +3.9% on average,\nrespectively. Further analysis also shows that this mixture framework can help\nincorporate specialized non-oracle human information sources as retrievers to\nachieve good collaboration, with a 58.9% relative performance improvement over\nsimulated humans alone.", "AI": {"tldr": "The paper introduces a zero-shot, weighted combination of heterogeneous retrievers (mixture of retrievers) to dynamically select and integrate multiple retrievers per query, outperforming individual retrievers and larger models.", "motivation": "Current RAG systems rely on a single retriever, limiting generalization across diverse queries. The paper explores dynamic integration of complementary retrievers.", "method": "Proposes a mixture of retrievers framework, combining signals from BM25 (lexical matches) and dense retrievers (semantic similarity) without manual selection.", "result": "The mixture outperforms individual retrievers (+10.8%) and larger 7B models (+3.9%), and improves collaboration with human sources by 58.9%.", "conclusion": "Dynamic integration of retrievers is effective and efficient, enhancing RAG performance across diverse information needs."}}
{"id": "2506.16912", "pdf": "https://arxiv.org/pdf/2506.16912", "abs": "https://arxiv.org/abs/2506.16912", "authors": ["Daniel Christoph", "Max Ploner", "Patrick Haller", "Alan Akbik"], "title": "From Data to Knowledge: Evaluating How Efficiently Language Models Learn Facts", "categories": ["cs.CL", "cs.LG"], "comment": "Accepted to the First Workshop on Large Language Model Memorization\n  (L2M2), co-located with ACL 2025 in Vienna", "summary": "Sample efficiency is a crucial property of language models with practical\nimplications for training efficiency. In real-world text, information follows a\nlong-tailed distribution. Yet, we expect models to learn and recall frequent\nand infrequent facts. Sample-efficient models are better equipped to handle\nthis challenge of learning and retaining rare information without requiring\nexcessive exposure. This study analyzes multiple models of varying\narchitectures and sizes, all trained on the same pre-training data. By\nannotating relational facts with their frequencies in the training corpus, we\nexamine how model performance varies with fact frequency. Our findings show\nthat most models perform similarly on high-frequency facts but differ notably\non low-frequency facts. This analysis provides new insights into the\nrelationship between model architecture, size, and factual learning efficiency.", "AI": {"tldr": "The study explores how language models of different architectures and sizes perform on high- and low-frequency facts, revealing notable differences in handling rare information.", "motivation": "Sample efficiency is critical for training language models, especially given the long-tailed distribution of information in real-world text. The study aims to understand how models learn and recall rare facts.", "method": "Multiple models of varying architectures and sizes were trained on the same data. Relational facts were annotated by frequency, and model performance was analyzed across fact frequencies.", "result": "Most models perform similarly on high-frequency facts but differ significantly on low-frequency facts.", "conclusion": "The analysis offers insights into how model architecture and size impact factual learning efficiency, particularly for rare information."}}
{"id": "2506.16563", "pdf": "https://arxiv.org/pdf/2506.16563", "abs": "https://arxiv.org/abs/2506.16563", "authors": ["Keyhan Najafian", "Farhad Maleki", "Lingling Jin", "Ian Stavness"], "title": "From Semantic To Instance: A Semi-Self-Supervised Learning Approach", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": null, "summary": "Instance segmentation is essential for applications such as automated\nmonitoring of plant health, growth, and yield. However, extensive effort is\nrequired to create large-scale datasets with pixel-level annotations of each\nobject instance for developing instance segmentation models that restrict the\nuse of deep learning in these areas. This challenge is more significant in\nimages with densely packed, self-occluded objects, which are common in\nagriculture. To address this challenge, we propose a semi-self-supervised\nlearning approach that requires minimal manual annotation to develop a\nhigh-performing instance segmentation model. We design GLMask, an image-mask\nrepresentation for the model to focus on shape, texture, and pattern while\nminimizing its dependence on color features. We develop a pipeline to generate\nsemantic segmentation and then transform it into instance-level segmentation.\nThe proposed approach substantially outperforms the conventional instance\nsegmentation models, establishing a state-of-the-art wheat head instance\nsegmentation model with mAP@50 of 98.5%. Additionally, we assessed the proposed\nmethodology on the general-purpose Microsoft COCO dataset, achieving a\nsignificant performance improvement of over 12.6% mAP@50. This highlights that\nthe utility of our proposed approach extends beyond precision agriculture and\napplies to other domains, specifically those with similar data characteristics.", "AI": {"tldr": "A semi-self-supervised learning approach, GLMask, is proposed for instance segmentation with minimal manual annotation, achieving high performance in agriculture and general datasets.", "motivation": "The need for large-scale pixel-level annotations in instance segmentation is labor-intensive, especially in agriculture with dense, occluded objects.", "method": "GLMask focuses on shape, texture, and pattern while reducing color dependence. A pipeline converts semantic to instance segmentation.", "result": "Achieves 98.5% mAP@50 for wheat head segmentation and 12.6% improvement on COCO dataset.", "conclusion": "The approach is effective for precision agriculture and other domains with similar data challenges."}}
{"id": "2506.15893", "pdf": "https://arxiv.org/pdf/2506.15893", "abs": "https://arxiv.org/abs/2506.15893", "authors": ["Farnam Mansouri", "Hans U. Simon", "Adish Singla", "Yuxin Chen", "Sandra Zilles"], "title": "Formal Models of Active Learning from Contrastive Examples", "categories": ["cs.LG"], "comment": null, "summary": "Machine learning can greatly benefit from providing learning algorithms with\npairs of contrastive training examples -- typically pairs of instances that\ndiffer only slightly, yet have different class labels. Intuitively, the\ndifference in the instances helps explain the difference in the class labels.\nThis paper proposes a theoretical framework in which the effect of various\ntypes of contrastive examples on active learners is studied formally. The focus\nis on the sample complexity of learning concept classes and how it is\ninfluenced by the choice of contrastive examples. We illustrate our results\nwith geometric concept classes and classes of Boolean functions. Interestingly,\nwe reveal a connection between learning from contrastive examples and the\nclassical model of self-directed learning.", "AI": {"tldr": "The paper explores how contrastive examples (slightly differing instances with different labels) improve machine learning, focusing on their impact on active learners' sample complexity.", "motivation": "To understand how contrastive examples enhance learning by explaining label differences and their effect on sample complexity.", "method": "Proposes a theoretical framework to study contrastive examples' impact on active learners, using geometric and Boolean function classes.", "result": "Reveals a connection between learning from contrastive examples and self-directed learning.", "conclusion": "Contrastive examples significantly influence learning efficiency, bridging gaps with classical self-directed learning models."}}
{"id": "2506.15896", "pdf": "https://arxiv.org/pdf/2506.15896", "abs": "https://arxiv.org/abs/2506.15896", "authors": ["Yu Zhang", "Gaoshan Bi", "Simon Jeffery", "Max Davis", "Yang Li", "Qing Xue", "Po Yang"], "title": "KG-FGNN: Knowledge-guided GNN Foundation Model for Fertilisation-oriented Soil GHG Flux Prediction", "categories": ["cs.LG", "cs.AI"], "comment": "8 pages, 4 figures", "summary": "Precision soil greenhouse gas (GHG) flux prediction is essential in\nagricultural systems for assessing environmental impacts, developing emission\nmitigation strategies and promoting sustainable agriculture. Due to the lack of\nadvanced sensor and network technologies on majority of farms, there are\nchallenges in obtaining comprehensive and diverse agricultural data. As a\nresult, the scarcity of agricultural data seriously obstructs the application\nof machine learning approaches in precision soil GHG flux prediction. This\nresearch proposes a knowledge-guided graph neural network framework that\naddresses the above challenges by integrating knowledge embedded in an\nagricultural process-based model and graph neural network techniques.\nSpecifically, we utilise the agricultural process-based model to simulate and\ngenerate multi-dimensional agricultural datasets for 47 countries that cover a\nwide range of agricultural variables. To extract key agricultural features and\nintegrate correlations among agricultural features in the prediction process,\nwe propose a machine learning framework that integrates the autoencoder and\nmulti-target multi-graph based graph neural networks, which utilises the\nautoencoder to selectively extract significant agricultural features from the\nagricultural process-based model simulation data and the graph neural network\nto integrate correlations among agricultural features for accurately predict\nfertilisation-oriented soil GHG fluxes. Comprehensive experiments were\nconducted with both the agricultural simulation dataset and real-world\nagricultural dataset to evaluate the proposed approach in comparison with\nwell-known baseline and state-of-the-art regression methods. The results\ndemonstrate that our proposed approach provides superior accuracy and stability\nin fertilisation-oriented soil GHG prediction.", "AI": {"tldr": "A knowledge-guided graph neural network framework is proposed for precision soil GHG flux prediction, addressing data scarcity by integrating agricultural process-based models and graph neural networks.", "motivation": "Precision GHG flux prediction is crucial for sustainable agriculture, but data scarcity limits machine learning applications.", "method": "The framework combines an agricultural process-based model for data simulation with autoencoder and multi-target multi-graph neural networks to extract features and integrate correlations.", "result": "The approach outperforms baseline and state-of-the-art methods in accuracy and stability for GHG prediction.", "conclusion": "The proposed framework effectively addresses data scarcity and enhances GHG flux prediction, supporting sustainable agriculture."}}
{"id": "2506.16982", "pdf": "https://arxiv.org/pdf/2506.16982", "abs": "https://arxiv.org/abs/2506.16982", "authors": ["Antonin Berthon", "Mihaela van der Schaar"], "title": "Language Bottleneck Models: A Framework for Interpretable Knowledge Tracing and Beyond", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "Accurately assessing student knowledge is critical for effective education,\nyet traditional Knowledge Tracing (KT) methods rely on opaque latent\nembeddings, limiting interpretability. Even LLM-based approaches generate\ndirect predictions or summaries that may hallucinate without any accuracy\nguarantees. We recast KT as an inverse problem: learning the minimum\nnatural-language summary that makes past answers explainable and future answers\npredictable. Our Language Bottleneck Model (LBM) consists of an encoder LLM\nthat writes an interpretable knowledge summary and a frozen decoder LLM that\nmust reconstruct and predict student responses using only that summary text. By\nconstraining all predictive information to pass through a short\nnatural-language bottleneck, LBMs ensure that the summary contains accurate\ninformation while remaining human-interpretable. Experiments on synthetic\narithmetic benchmarks and the large-scale Eedi dataset show that LBMs rival the\naccuracy of state-of-the-art KT and direct LLM methods while requiring\norders-of-magnitude fewer student trajectories. We demonstrate that training\nthe encoder with group-relative policy optimization, using downstream decoding\naccuracy as a reward signal, effectively improves summary quality.", "AI": {"tldr": "The paper introduces a Language Bottleneck Model (LBM) for Knowledge Tracing (KT), using interpretable natural-language summaries to improve accuracy and transparency.", "motivation": "Traditional KT methods lack interpretability, and LLM-based approaches may produce unreliable predictions. The goal is to create a method that ensures accuracy and human-understandable summaries.", "method": "LBM uses an encoder LLM to generate interpretable summaries and a frozen decoder LLM to predict student responses. Training involves group-relative policy optimization to improve summary quality.", "result": "LBMs match state-of-the-art KT and LLM methods in accuracy while requiring fewer student trajectories.", "conclusion": "LBMs offer a transparent and accurate alternative for KT, balancing interpretability and predictive performance."}}
{"id": "2506.16578", "pdf": "https://arxiv.org/pdf/2506.16578", "abs": "https://arxiv.org/abs/2506.16578", "authors": ["Tongan Cai", "Haomiao Ni", "Wenchao Ma", "Yuan Xue", "Qian Ma", "Rachel Leicht", "Kelvin Wong", "John Volpi", "Stephen T. C. Wong", "James Z. Wang", "Sharon X. Huang"], "title": "SafeTriage: Facial Video De-identification for Privacy-Preserving Stroke Triage", "categories": ["cs.CV"], "comment": "IPMI 2025", "summary": "Effective stroke triage in emergency settings often relies on clinicians'\nability to identify subtle abnormalities in facial muscle coordination. While\nrecent AI models have shown promise in detecting such patterns from patient\nfacial videos, their reliance on real patient data raises significant ethical\nand privacy challenges -- especially when training robust and generalizable\nmodels across institutions. To address these concerns, we propose SafeTriage, a\nnovel method designed to de-identify patient facial videos while preserving\nessential motion cues crucial for stroke diagnosis. SafeTriage leverages a\npretrained video motion transfer (VMT) model to map the motion characteristics\nof real patient faces onto synthetic identities. This approach retains\ndiagnostically relevant facial dynamics without revealing the patients'\nidentities. To mitigate the distribution shift between normal population\npre-training videos and patient population test videos, we introduce a\nconditional generative model for visual prompt tuning, which adapts the input\nspace of the VMT model to ensure accurate motion transfer without needing to\nfine-tune the VMT model backbone. Comprehensive evaluation, including\nquantitative metrics and clinical expert assessments, demonstrates that\nSafeTriage-produced synthetic videos effectively preserve stroke-relevant\nfacial patterns, enabling reliable AI-based triage. Our evaluations also show\nthat SafeTriage provides robust privacy protection while maintaining diagnostic\naccuracy, offering a secure and ethically sound foundation for data sharing and\nAI-driven clinical analysis in neurological disorders.", "AI": {"tldr": "SafeTriage de-identifies patient facial videos for stroke diagnosis while preserving motion cues, using a pretrained VMT model and conditional generative model for adaptation.", "motivation": "Address ethical and privacy challenges in AI-based stroke triage by de-identifying patient data without losing diagnostic relevance.", "method": "Leverages a pretrained VMT model to transfer motion from real faces to synthetic identities, with a conditional generative model to adapt input space.", "result": "Synthetic videos retain stroke-relevant facial patterns, ensuring reliable AI triage and robust privacy protection.", "conclusion": "SafeTriage offers a secure, ethical solution for data sharing and AI-driven clinical analysis in neurological disorders."}}
{"id": "2506.15898", "pdf": "https://arxiv.org/pdf/2506.15898", "abs": "https://arxiv.org/abs/2506.15898", "authors": ["Xiao Zhang", "Xingyu Zhao", "Hong Xia", "Yuan Cao", "Guiyuan Jiang", "Junyu Dong", "Yanwei Yu"], "title": "TrajDiff: Diffusion Bridge Network with Semantic Alignment for Trajectory Similarity Computation", "categories": ["cs.LG"], "comment": null, "summary": "With the proliferation of location-tracking technologies, massive volumes of\ntrajectory data are continuously being collected. As a fundamental task in\ntrajectory data mining, trajectory similarity computation plays a critical role\nin a wide range of real-world applications. However, existing learning-based\nmethods face three challenges: First, they ignore the semantic gap between GPS\nand grid features in trajectories, making it difficult to obtain meaningful\ntrajectory embeddings. Second, the noise inherent in the trajectories, as well\nas the noise introduced during grid discretization, obscures the true motion\npatterns of the trajectories. Third, existing methods focus solely on\npoint-wise and pair-wise losses, without utilizing the global ranking\ninformation obtained by sorting all trajectories according to their similarity\nto a given trajectory. To address the aforementioned challenges, we propose a\nnovel trajectory similarity computation framework, named TrajDiff.\nSpecifically, the semantic alignment module relies on cross-attention and an\nattention score mask mechanism with adaptive fusion, effectively eliminating\nsemantic discrepancies between data at two scales and generating a unified\nrepresentation. Additionally, the DDBM-based Noise-robust Pre-Training\nintroduces the transfer patterns between any two trajectories into the model\ntraining process, enhancing the model's noise robustness. Finally, the overall\nranking-aware regularization shifts the model's focus from a local to a global\nperspective, enabling it to capture the holistic ordering information among\ntrajectories. Extensive experiments on three publicly available datasets show\nthat TrajDiff consistently outperforms state-of-the-art baselines. In\nparticular, it achieves an average HR@1 gain of 33.38% across all three\nevaluation metrics and datasets.", "AI": {"tldr": "TrajDiff is a new framework for trajectory similarity computation that addresses semantic gaps, noise, and global ranking issues, outperforming existing methods with a 33.38% average HR@1 gain.", "motivation": "Existing methods for trajectory similarity computation struggle with semantic gaps between GPS and grid features, noise in data, and lack of global ranking awareness.", "method": "TrajDiff uses semantic alignment with cross-attention, noise-robust pre-training with DDBM, and ranking-aware regularization to improve trajectory embeddings.", "result": "TrajDiff outperforms state-of-the-art baselines, achieving a 33.38% average HR@1 gain across three datasets.", "conclusion": "TrajDiff effectively addresses key challenges in trajectory similarity computation, demonstrating significant performance improvements."}}
{"id": "2506.15923", "pdf": "https://arxiv.org/pdf/2506.15923", "abs": "https://arxiv.org/abs/2506.15923", "authors": ["Liangyan Li", "Yangyi Liu", "Yimo Ning", "Stefano Rini", "Jun Chen"], "title": "PNCS:Power-Norm Cosine Similarity for Diverse Client Selection in Federated Learning", "categories": ["cs.LG", "cs.AI", "cs.DC"], "comment": null, "summary": "Federated Learning (FL) has emerged as a powerful paradigm for leveraging\ndiverse datasets from multiple sources while preserving data privacy by\navoiding centralized storage. However, many existing approaches fail to account\nfor the intricate gradient correlations between remote clients, a limitation\nthat becomes especially problematic in data heterogeneity scenarios. In this\nwork, we propose a novel FL framework utilizing Power-Norm Cosine Similarity\n(PNCS) to improve client selection for model aggregation. By capturing\nhigher-order gradient moments, PNCS addresses non-IID data challenges,\nenhancing convergence speed and accuracy. Additionally, we introduce a simple\nalgorithm ensuring diverse client selection through a selection history queue.\nExperiments with a VGG16 model across varied data partitions demonstrate\nconsistent improvements over state-of-the-art methods.", "AI": {"tldr": "A novel FL framework using Power-Norm Cosine Similarity (PNCS) improves client selection for model aggregation, addressing non-IID data challenges and enhancing convergence speed and accuracy.", "motivation": "Existing FL approaches often overlook gradient correlations between clients, especially in data heterogeneity scenarios, limiting performance.", "method": "Proposes PNCS to capture higher-order gradient moments and introduces a selection history queue for diverse client selection.", "result": "Experiments with a VGG16 model show consistent improvements in convergence speed and accuracy over state-of-the-art methods.", "conclusion": "The PNCS-based FL framework effectively addresses non-IID data challenges, improving model performance in federated learning."}}
{"id": "2506.16990", "pdf": "https://arxiv.org/pdf/2506.16990", "abs": "https://arxiv.org/abs/2506.16990", "authors": ["Sahil Kale", "Vijaykant Nadadur"], "title": "TeXpert: A Multi-Level Benchmark for Evaluating LaTeX Code Generation by LLMs", "categories": ["cs.CL", "cs.AI"], "comment": "Accepted to the SDProc Workshop @ ACL 2025", "summary": "LaTeX's precision and flexibility in typesetting have made it the gold\nstandard for the preparation of scientific documentation. Large Language Models\n(LLMs) present a promising opportunity for researchers to produce\npublication-ready material using LaTeX with natural language instructions, yet\ncurrent benchmarks completely lack evaluation of this ability. By introducing\nTeXpert, our benchmark dataset with natural language prompts for generating\nLaTeX code focused on components of scientific documents across multiple\ndifficulty levels, we conduct an in-depth analysis of LLM performance in this\nregard and identify frequent error types. Our evaluation across open and\nclosed-source LLMs highlights multiple key findings: LLMs excelling on standard\nbenchmarks perform poorly in LaTeX generation with a significant accuracy\ndrop-off as the complexity of tasks increases; open-source models like DeepSeek\nv3 and DeepSeek Coder strongly rival closed-source counterparts in LaTeX tasks;\nand formatting and package errors are unexpectedly prevalent, suggesting a lack\nof diverse LaTeX examples in the training datasets of most LLMs. Our dataset,\ncode, and model evaluations are available at\nhttps://github.com/knowledge-verse-ai/TeXpert.", "AI": {"tldr": "The paper introduces TeXpert, a benchmark dataset for evaluating LLMs' ability to generate LaTeX code from natural language prompts, revealing performance gaps and common errors.", "motivation": "Current benchmarks lack evaluation of LLMs' ability to generate LaTeX code for scientific documents, despite its importance for researchers.", "method": "The authors create TeXpert, a dataset with natural language prompts for LaTeX generation across difficulty levels, and evaluate open and closed-source LLMs.", "result": "LLMs perform poorly in LaTeX generation, with accuracy dropping as task complexity increases. Open-source models rival closed-source ones, and formatting/package errors are common.", "conclusion": "The study highlights the need for more diverse LaTeX training data in LLMs and provides a benchmark for future improvements."}}
{"id": "2506.16589", "pdf": "https://arxiv.org/pdf/2506.16589", "abs": "https://arxiv.org/abs/2506.16589", "authors": ["Tal Zeevi", "El\u00e9onore V. Lieffrig", "Lawrence H. Staib", "John A. Onofrey"], "title": "Spatially-Aware Evaluation of Segmentation Uncertainty", "categories": ["cs.CV", "cs.AI", "cs.PF", "stat.ML"], "comment": "Presented at the 4th Workshop on Uncertainty Quantification for\n  Computer Vision (CVPR 2025), June 11, 2025. This version is not included in\n  the official proceedings", "summary": "Uncertainty maps highlight unreliable regions in segmentation predictions.\nHowever, most uncertainty evaluation metrics treat voxels independently,\nignoring spatial context and anatomical structure. As a result, they may assign\nidentical scores to qualitatively distinct patterns (e.g., scattered vs.\nboundary-aligned uncertainty). We propose three spatially aware metrics that\nincorporate structural and boundary information and conduct a thorough\nvalidation on medical imaging data from the prostate zonal segmentation\nchallenge within the Medical Segmentation Decathlon. Our results demonstrate\nimproved alignment with clinically important factors and better discrimination\nbetween meaningful and spurious uncertainty patterns.", "AI": {"tldr": "Proposed three spatially aware metrics for uncertainty evaluation in segmentation, improving alignment with clinical factors and distinguishing meaningful uncertainty patterns.", "motivation": "Current uncertainty metrics ignore spatial context and anatomical structure, leading to identical scores for distinct patterns (e.g., scattered vs. boundary-aligned uncertainty).", "method": "Developed three spatially aware metrics incorporating structural and boundary information, validated on prostate zonal segmentation data from the Medical Segmentation Decathlon.", "result": "Improved alignment with clinically important factors and better discrimination between meaningful and spurious uncertainty patterns.", "conclusion": "Spatially aware metrics enhance uncertainty evaluation by considering spatial context and anatomical structure."}}
{"id": "2506.15901", "pdf": "https://arxiv.org/pdf/2506.15901", "abs": "https://arxiv.org/abs/2506.15901", "authors": ["Li Sun", "Shuheng Chen", "Yong Si", "Junyi Fan", "Maryam Pishgar", "Elham Pishgar", "Kamiar Alaei", "Greg Placencia"], "title": "Clinically Interpretable Mortality Prediction for ICU Patients with Diabetes and Atrial Fibrillation: A Machine Learning Approach", "categories": ["cs.LG"], "comment": null, "summary": "Background: Patients with both diabetes mellitus (DM) and atrial fibrillation\n(AF) face elevated mortality in intensive care units (ICUs), yet models\ntargeting this high-risk group remain limited.\n  Objective: To develop an interpretable machine learning (ML) model predicting\n28-day mortality in ICU patients with concurrent DM and AF using early-phase\nclinical data.\n  Methods: A retrospective cohort of 1,535 adult ICU patients with DM and AF\nwas extracted from the MIMIC-IV database. Data preprocessing involved\nmedian/mode imputation, z-score normalization, and early temporal feature\nengineering. A two-step feature selection pipeline-univariate filtering (ANOVA\nF-test) and Random Forest-based multivariate ranking-yielded 19 interpretable\nfeatures. Seven ML models were trained with stratified 5-fold cross-validation\nand SMOTE oversampling. Interpretability was assessed via ablation and\nAccumulated Local Effects (ALE) analysis.\n  Results: Logistic regression achieved the best performance (AUROC: 0.825; 95%\nCI: 0.779-0.867), surpassing more complex models. Key predictors included RAS,\nage, bilirubin, and extubation. ALE plots showed intuitive, non-linear effects\nsuch as age-related risk acceleration and bilirubin thresholds.\n  Conclusion: This interpretable ML model offers accurate risk prediction and\nclinical insights for early ICU triage in patients with DM and AF.", "AI": {"tldr": "An interpretable ML model predicts 28-day mortality in ICU patients with DM and AF using early-phase clinical data, outperforming complex models with key predictors like RAS, age, bilirubin, and extubation.", "motivation": "Limited models exist for predicting mortality in high-risk ICU patients with both DM and AF, necessitating an interpretable ML solution.", "method": "Retrospective cohort study using MIMIC-IV data, preprocessing, feature selection, and training of seven ML models with cross-validation and SMOTE oversampling.", "result": "Logistic regression performed best (AUROC: 0.825), with key predictors identified. ALE plots revealed non-linear effects like age-related risk.", "conclusion": "The model provides accurate, interpretable risk prediction for early ICU triage in DM and AF patients."}}
{"id": "2506.15961", "pdf": "https://arxiv.org/pdf/2506.15961", "abs": "https://arxiv.org/abs/2506.15961", "authors": ["Yunchi Lu", "Youshan Miao", "Cheng Tan", "Peng Huang", "Yi Zhu", "Xian Zhang", "Fan Yang"], "title": "TrainVerify: Equivalence-Based Verification for Distributed LLM Training", "categories": ["cs.DC", "cs.AI", "cs.LG"], "comment": null, "summary": "Training large language models (LLMs) at scale requires parallel execution\nacross thousands of devices, incurring enormous computational costs. Yet, these\ncostly distributed trainings are rarely verified, leaving them prone to silent\nerrors and potentially wasting millions of GPU hours. We introduce TrainVerify,\na system for verifiable distributed training of LLMs. Given a deep learning\nmodel's logical specification as the ground truth, TrainVerify formally\nverifies that a distributed parallel execution plan is mathematically\nequivalent to it. Direct verification is notoriously difficult due to the sheer\nscale of LLMs which often involves billions of variables and highly intricate\ncomputation graphs. Therefore, TrainVerify introduces shape-reduction\ntechniques and a stage-wise parallel verification algorithm that significantly\nreduces complexity while preserving formal correctness. TrainVerify scales to\nfrontier LLMs, including the successful verification of the Llama3 (405B) and\nDeepSeek-V3 (671B) training plans.", "AI": {"tldr": "TrainVerify is a system for verifiable distributed training of LLMs, ensuring correctness and avoiding costly errors in large-scale training.", "motivation": "Distributed training of LLMs is costly and prone to silent errors, leading to wasted resources.", "method": "TrainVerify uses logical specifications and formal verification, employing shape-reduction techniques and a stage-wise parallel verification algorithm.", "result": "It successfully verifies training plans for large models like Llama3 (405B) and DeepSeek-V3 (671B).", "conclusion": "TrainVerify provides a scalable solution for ensuring correctness in distributed LLM training."}}
{"id": "2506.17001", "pdf": "https://arxiv.org/pdf/2506.17001", "abs": "https://arxiv.org/abs/2506.17001", "authors": ["Mikhail Menschikov", "Dmitry Evseev", "Ruslan Kostoev", "Ilya Perepechkin", "Ilnaz Salimov", "Victoria Dochkina", "Petr Anokhin", "Evgeny Burnaev", "Nikita Semenov"], "title": "PersonalAI: Towards digital twins in the graph form", "categories": ["cs.CL", "cs.IR"], "comment": null, "summary": "The challenge of personalizing language models, specifically the ability to\naccount for a user's history during interactions, is of significant interest.\nDespite recent advancements in large language models (LLMs) and Retrieval\nAugmented Generation that have enhanced the factual base of LLMs, the task of\nretaining extensive personal information and using it to generate personalized\nresponses remains pertinent. To address this, we propose utilizing external\nmemory in the form of knowledge graphs, which are constructed and updated by\nthe LLM itself. We have expanded upon ideas of AriGraph architecture and for\nthe first time introduced a combined graph featuring both standard edges and\ntwo types of hyperedges. Experiments conducted on the TriviaQA, HotpotQA and\nDiaASQ benchmarks indicates that this approach aids in making the process of\ngraph construction and knowledge extraction unified and robust. Furthermore, we\naugmented the DiaASQ benchmark by incorporating parameters such as time into\ndialogues and introducing contradictory statements made by the same speaker at\ndifferent times. Despite these modifications, the performance of the\nquestion-answering system remained robust, demonstrating the proposed\narchitecture's ability to maintain and utilize temporal dependencies.", "AI": {"tldr": "The paper proposes using knowledge graphs with standard edges and hyperedges for personalized language models, showing robustness in benchmarks like TriviaQA and DiaASQ.", "motivation": "Addressing the challenge of personalizing language models by retaining and utilizing extensive personal information for tailored responses.", "method": "Utilizing external memory via knowledge graphs, including standard edges and two hyperedge types, based on AriGraph architecture.", "result": "Improved robustness in graph construction and knowledge extraction, with maintained performance on modified benchmarks like DiaASQ.", "conclusion": "The proposed architecture effectively handles temporal dependencies and contradictory statements, enhancing personalized language model performance."}}
{"id": "2506.16647", "pdf": "https://arxiv.org/pdf/2506.16647", "abs": "https://arxiv.org/abs/2506.16647", "authors": ["Ajesh Thangaraj Nadar", "Gabriel Nixon Raj", "Soham Chandane", "Sushant Bhat"], "title": "Leveraging CNN and IoT for Effective E-Waste Management", "categories": ["cs.CV", "68T05 (Primary), 68T01 (Secondary)", "I.2.10; C.3; J.2"], "comment": "6 pages, 4 figures, published in 2023 7th International Conference on\n  I-SMAC IoT in Social Mobile Analytics and Cloud. Conference held in Kirtipur\n  Nepal from 11 to 13 October 2023", "summary": "The increasing proliferation of electronic devices in the modern era has led\nto a significant surge in electronic waste (e-waste). Improper disposal and\ninsufficient recycling of e-waste pose serious environmental and health risks.\nThis paper proposes an IoT-enabled system combined with a lightweight CNN-based\nclassification pipeline to enhance the identification, categorization, and\nrouting of e-waste materials. By integrating a camera system and a digital\nweighing scale, the framework automates the classification of electronic items\nbased on visual and weight-based attributes. The system demonstrates how\nreal-time detection of e-waste components such as circuit boards, sensors, and\nwires can facilitate smart recycling workflows and improve overall waste\nprocessing efficiency.", "AI": {"tldr": "An IoT and CNN-based system for automated e-waste classification to improve recycling efficiency.", "motivation": "Addressing the environmental and health risks of improper e-waste disposal by enhancing identification and recycling processes.", "method": "Combines IoT with a lightweight CNN for real-time classification using visual and weight-based attributes from cameras and digital scales.", "result": "Demonstrates effective detection of e-waste components like circuit boards and wires, enabling smarter recycling workflows.", "conclusion": "The proposed system enhances e-waste processing efficiency and supports better recycling practices."}}
{"id": "2506.15903", "pdf": "https://arxiv.org/pdf/2506.15903", "abs": "https://arxiv.org/abs/2506.15903", "authors": ["Josef Kucha\u0159", "Marek Kadl\u010d\u00edk", "Michal Spiegel", "Michal \u0160tef\u00e1nik"], "title": "VectorEdits: A Dataset and Benchmark for Instruction-Based Editing of Vector Graphics", "categories": ["cs.LG"], "comment": null, "summary": "We introduce a large-scale dataset for instruction-guided vector image\nediting, consisting of over 270,000 pairs of SVG images paired with natural\nlanguage edit instructions. Our dataset enables training and evaluation of\nmodels that modify vector graphics based on textual commands. We describe the\ndata collection process, including image pairing via CLIP similarity and\ninstruction generation with vision-language models. Initial experiments with\nstate-of-the-art large language models reveal that current methods struggle to\nproduce accurate and valid edits, underscoring the challenge of this task. To\nfoster research in natural language-driven vector graphic generation and\nediting, we make our resources created within this work publicly available.", "AI": {"tldr": "A large-scale dataset for instruction-guided vector image editing is introduced, with 270,000 SVG-text pairs, to train models for text-based vector graphic modifications.", "motivation": "To advance research in natural language-driven vector graphic editing by providing a comprehensive dataset and highlighting the challenges in current methods.", "method": "Data collection involved pairing SVG images via CLIP similarity and generating edit instructions using vision-language models. Initial experiments tested state-of-the-art large language models.", "result": "Current methods struggle to produce accurate and valid edits, indicating the difficulty of the task.", "conclusion": "The dataset and resources are made publicly available to encourage further research in this area."}}
{"id": "2506.16000", "pdf": "https://arxiv.org/pdf/2506.16000", "abs": "https://arxiv.org/abs/2506.16000", "authors": ["Hemanth Kannamarlapudi", "Sowmya Chintalapudi"], "title": "Quantum Artificial Intelligence for Secure Autonomous Vehicle Navigation: An Architectural Proposal", "categories": ["cs.ET", "cs.AI", "cs.RO", "quant-ph", "I.2.9; I.2.6; K.4.4"], "comment": "5 pages, 2 figures, 17 references. Architectural proposal for quantum\n  AI integration in autonomous vehicle navigation systems for secured\n  navigation", "summary": "Navigation is a very crucial aspect of autonomous vehicle ecosystem which\nheavily relies on collecting and processing large amounts of data in various\nstates and taking a confident and safe decision to define the next vehicle\nmaneuver. In this paper, we propose a novel architecture based on Quantum\nArtificial Intelligence by enabling quantum and AI at various levels of\nnavigation decision making and communication process in Autonomous vehicles :\nQuantum Neural Networks for multimodal sensor fusion, Nav-Q for Quantum\nreinforcement learning for navigation policy optimization and finally\npost-quantum cryptographic protocols for secure communication. Quantum neural\nnetworks uses quantum amplitude encoding to fuse data from various sensors like\nLiDAR, radar, camera, GPS and weather etc., This approach gives a unified\nquantum state representation between heterogeneous sensor modalities. Nav-Q\nmodule processes the fused quantum states through variational quantum circuits\nto learn optimal navigation policies under swift dynamic and complex\nconditions. Finally, post quantum cryptographic protocols are used to secure\ncommunication channels for both within vehicle communication and V2X (Vehicle\nto Everything) communications and thus secures the autonomous vehicle\ncommunication from both classical and quantum security threats. Thus, the\nproposed framework addresses fundamental challenges in autonomous vehicles\nnavigation by providing quantum performance and future proof security. Index\nTerms Quantum Computing, Autonomous Vehicles, Sensor Fusion", "AI": {"tldr": "The paper proposes a quantum AI-based architecture for autonomous vehicle navigation, integrating quantum neural networks for sensor fusion, quantum reinforcement learning for policy optimization, and post-quantum cryptography for secure communication.", "motivation": "To address the challenges of autonomous vehicle navigation, such as handling large, heterogeneous data and ensuring secure communication, by leveraging quantum computing and AI.", "method": "Uses Quantum Neural Networks for multimodal sensor fusion, Nav-Q for quantum reinforcement learning, and post-quantum cryptographic protocols for secure communication.", "result": "The framework provides unified quantum state representation for sensor data, optimal navigation policies, and secure communication, addressing both classical and quantum threats.", "conclusion": "The proposed quantum AI architecture enhances autonomous vehicle navigation with improved performance and future-proof security."}}
{"id": "2506.17006", "pdf": "https://arxiv.org/pdf/2506.17006", "abs": "https://arxiv.org/abs/2506.17006", "authors": ["Danielle R. Thomas", "Conrad Borchers", "Shambhavi Bhushan", "Erin Gatz", "Shivang Gupta", "Kenneth R. Koedinger"], "title": "LLM-Generated Feedback Supports Learning If Learners Choose to Use It", "categories": ["cs.CL", "cs.CY"], "comment": "Full research paper accepted at EC-TEL '25", "summary": "Large language models (LLMs) are increasingly used to generate feedback, yet\ntheir impact on learning remains underexplored, especially compared to existing\nfeedback methods. This study investigates how on-demand LLM-generated\nexplanatory feedback influences learning in seven scenario-based tutor training\nlessons. Analyzing over 2,600 lesson completions from 885 tutor learners, we\ncompare posttest performance among learners across three groups: learners who\nreceived feedback generated by gpt-3.5-turbo, those who declined it, and those\nwithout access. All groups received non-LLM corrective feedback. To address\npotential selection bias-where higher-performing learners may be more inclined\nto use LLM feedback-we applied propensity scoring. Learners with a higher\npredicted likelihood of engaging with LLM feedback scored significantly higher\nat posttest than those with lower propensity. After adjusting for this effect,\ntwo out of seven lessons showed statistically significant learning benefits\nfrom LLM feedback with standardized effect sizes of 0.28 and 0.33. These\nmoderate effects suggest that the effectiveness of LLM feedback depends on the\nlearners' tendency to seek support. Importantly, LLM feedback did not\nsignificantly increase completion time, and learners overwhelmingly rated it as\nhelpful. These findings highlight LLM feedback's potential as a low-cost and\nscalable way to improve learning on open-ended tasks, particularly in existing\nsystems already providing feedback without LLMs. This work contributes open\ndatasets, LLM prompts, and rubrics to support reproducibility.", "AI": {"tldr": "LLM-generated feedback shows moderate learning benefits in tutor training, with effectiveness depending on learners' tendency to seek support. It's scalable and well-received.", "motivation": "To explore the impact of LLM-generated feedback on learning compared to traditional methods, especially in tutor training.", "method": "Analyzed 2,600 lesson completions from 885 learners across three groups (LLM feedback, declined feedback, no access) using propensity scoring to address selection bias.", "result": "Two out of seven lessons showed significant learning benefits (effect sizes 0.28, 0.33). LLM feedback was rated helpful and didn't increase completion time.", "conclusion": "LLM feedback is a scalable, low-cost tool for improving learning in open-ended tasks, particularly in systems already providing feedback."}}
{"id": "2506.16663", "pdf": "https://arxiv.org/pdf/2506.16663", "abs": "https://arxiv.org/abs/2506.16663", "authors": ["Michael Gyimadu", "Gregory Bell"], "title": "A Comparative Analysis of Principal Component Analysis (PCA) and Singular Value Decomposition (SVD) as Dimensionality Reduction Techniques", "categories": ["cs.CV", "cs.NA", "math.NA"], "comment": null, "summary": "High-dimensional image data often require dimensionality reduction before\nfurther analysis. This paper provides a purely analytical comparison of two\nlinear techniques-Principal Component Analysis (PCA) and Singular Value\nDecomposition (SVD). After the derivation of each algorithm from first\nprinciples, we assess their interpretability, numerical stability, and\nsuitability for differing matrix shapes. building on classical and recent\nnumerical literature, We synthesize rule-of-thumb guidelines for choosing one\nout of the two algorithms without empirical benchmarking, building on classical\nand recent numerical literature. Limitations and directions for future\nexperimental work are outlined at the end.", "AI": {"tldr": "The paper compares PCA and SVD for dimensionality reduction, focusing on interpretability, stability, and suitability for matrix shapes, providing guidelines for choosing between them.", "motivation": "To analytically compare PCA and SVD for high-dimensional image data reduction without empirical benchmarking.", "method": "Derivation of PCA and SVD from first principles, assessing interpretability, numerical stability, and matrix shape suitability.", "result": "Synthesized guidelines for choosing PCA or SVD based on theoretical analysis.", "conclusion": "Limitations and future experimental work are outlined, emphasizing the need for empirical validation."}}
{"id": "2506.15907", "pdf": "https://arxiv.org/pdf/2506.15907", "abs": "https://arxiv.org/abs/2506.15907", "authors": ["Hang Yang", "Yusheng Hu", "Yong Liu", "Cong", "Hao"], "title": "Pieceformer: Similarity-Driven Knowledge Transfer via Scalable Graph Transformer in VLSI", "categories": ["cs.LG", "cs.SY", "eess.SY"], "comment": "7 pages, 4 figures, 1 table, submitted", "summary": "Accurate graph similarity is critical for knowledge transfer in VLSI design,\nenabling the reuse of prior solutions to reduce engineering effort and\nturnaround time. We propose Pieceformer, a scalable, self-supervised similarity\nassessment framework, equipped with a hybrid message-passing and graph\ntransformer encoder. To address transformer scalability, we incorporate a\nlinear transformer backbone and introduce a partitioned training pipeline for\nefficient memory and parallelism management. Evaluations on synthetic and\nreal-world CircuitNet datasets show that Pieceformer reduces mean absolute\nerror (MAE) by 24.9% over the baseline and is the only method to correctly\ncluster all real-world design groups. We further demonstrate the practical\nusage of our model through a case study on a partitioning task, achieving up to\n89% runtime reduction. These results validate the framework's effectiveness for\nscalable, unbiased design reuse in modern VLSI systems.", "AI": {"tldr": "Pieceformer is a scalable, self-supervised framework for graph similarity in VLSI design, reducing MAE by 24.9% and enabling efficient design reuse.", "motivation": "Accurate graph similarity is needed to reduce engineering effort and turnaround time in VLSI design by reusing prior solutions.", "method": "Proposes Pieceformer, a hybrid message-passing and graph transformer encoder with a linear transformer backbone and partitioned training for scalability.", "result": "Reduces MAE by 24.9%, correctly clusters all real-world design groups, and achieves up to 89% runtime reduction in a partitioning task.", "conclusion": "Pieceformer is effective for scalable, unbiased design reuse in modern VLSI systems."}}
{"id": "2506.16001", "pdf": "https://arxiv.org/pdf/2506.16001", "abs": "https://arxiv.org/abs/2506.16001", "authors": ["Qianru Zhang", "Honggang Wen", "Ming Li", "Dong Huang", "Siu-Ming Yiu", "Christian S. Jensen", "Pietro Li\u00f2"], "title": "AutoHFormer: Efficient Hierarchical Autoregressive Transformer for Time Series Prediction", "categories": ["cs.LG", "cs.AI"], "comment": "14 pages", "summary": "Time series forecasting requires architectures that simultaneously achieve\nthree competing objectives: (1) strict temporal causality for reliable\npredictions, (2) sub-quadratic complexity for practical scalability, and (3)\nmulti-scale pattern recognition for accurate long-horizon forecasting. We\nintroduce AutoHFormer, a hierarchical autoregressive transformer that addresses\nthese challenges through three key innovations: 1) Hierarchical Temporal\nModeling: Our architecture decomposes predictions into segment-level blocks\nprocessed in parallel, followed by intra-segment sequential refinement. This\ndual-scale approach maintains temporal coherence while enabling efficient\ncomputation. 2) Dynamic Windowed Attention: The attention mechanism employs\nlearnable causal windows with exponential decay, reducing complexity while\npreserving precise temporal relationships. This design avoids both the\nanti-causal violations of standard transformers and the sequential bottlenecks\nof RNN hybrids. 3) Adaptive Temporal Encoding: a novel position encoding system\nis adopted to capture time patterns at multiple scales. It combines fixed\noscillating patterns for short-term variations with learnable decay rates for\nlong-term trends. Comprehensive experiments demonstrate that AutoHFormer 10.76X\nfaster training and 6.06X memory reduction compared to PatchTST on PEMS08,\nwhile maintaining consistent accuracy across 96-720 step horizons in most of\ncases. These breakthroughs establish new benchmarks for efficient and precise\ntime series modeling. Implementations of our method and all baselines in\nhierarchical autoregressive mechanism are available at\nhttps://github.com/lizzyhku/Autotime.", "AI": {"tldr": "AutoHFormer is a hierarchical autoregressive transformer for time series forecasting, addressing temporal causality, scalability, and multi-scale pattern recognition with innovations like hierarchical modeling, dynamic windowed attention, and adaptive temporal encoding.", "motivation": "To achieve strict temporal causality, sub-quadratic complexity, and multi-scale pattern recognition in time series forecasting.", "method": "Uses hierarchical temporal modeling, dynamic windowed attention, and adaptive temporal encoding.", "result": "10.76X faster training, 6.06X memory reduction vs. PatchTST, with consistent accuracy across long horizons.", "conclusion": "AutoHFormer sets new benchmarks for efficient and precise time series modeling."}}
{"id": "2506.17019", "pdf": "https://arxiv.org/pdf/2506.17019", "abs": "https://arxiv.org/abs/2506.17019", "authors": ["Giuseppe Attanasio", "Sonal Sannigrahi", "Ben Peters", "Andr\u00e9 F. T. Martins"], "title": "Instituto de Telecomunica\u00e7\u00f5es at IWSLT 2025: Aligning Small-Scale Speech and Language Models for Speech-to-Text Learning", "categories": ["cs.CL", "cs.AI"], "comment": "7 pages, 1 figure, IWSLT 2025", "summary": "This paper presents the IT-IST submission to the IWSLT 2025 Shared Task on\nInstruction Following Speech Processing. We submit results for the Short Track,\ni.e., speech recognition, translation, and spoken question answering. Our model\nis a unified speech-to-text model that integrates a pre-trained continuous\nspeech encoder and text decoder through a first phase of modality alignment and\na second phase of instruction fine-tuning. Crucially, we focus on using\nsmall-scale language model backbones (< 2B) and restrict to high-quality, CC-BY\ndata along with synthetic data generation to supplement existing resources.", "AI": {"tldr": "The paper describes IT-IST's submission to IWSLT 2025, focusing on a unified speech-to-text model for speech recognition, translation, and question answering, using small-scale LMs and high-quality data.", "motivation": "To address the challenges of instruction-following speech processing with efficient, small-scale models while leveraging high-quality and synthetic data.", "method": "A unified speech-to-text model combining a pre-trained speech encoder and text decoder, trained in two phases: modality alignment and instruction fine-tuning.", "result": "Submission results for the Short Track (speech recognition, translation, and spoken question answering) at IWSLT 2025.", "conclusion": "The approach demonstrates the feasibility of using small-scale models and curated data for effective speech processing tasks."}}
{"id": "2506.16673", "pdf": "https://arxiv.org/pdf/2506.16673", "abs": "https://arxiv.org/abs/2506.16673", "authors": ["Ruiming Chen", "Junming Yang", "Shiyu Xia", "Xu Yang", "Jing Wang", "Xin Geng"], "title": "Extracting Multimodal Learngene in CLIP: Unveiling the Multimodal Generalizable Knowledge", "categories": ["cs.CV"], "comment": null, "summary": "CLIP (Contrastive Language-Image Pre-training) has attracted widespread\nattention for its multimodal generalizable knowledge, which is significant for\ndownstream tasks. However, the computational overhead of a large number of\nparameters and large-scale pre-training poses challenges of pre-training a\ndifferent scale of CLIP. Learngene extracts the generalizable components termed\nas learngene from an ancestry model and initializes diverse descendant models\nwith it. Previous Learngene paradigms fail to handle the generalizable\nknowledge in multimodal scenarios. In this paper, we put forward the idea of\nutilizing a multimodal block to extract the multimodal generalizable knowledge,\nwhich inspires us to propose MM-LG (Multimodal Learngene), a novel framework\ndesigned to extract and leverage generalizable components from CLIP.\nSpecifically, we first establish multimodal and unimodal blocks to extract the\nmultimodal and unimodal generalizable knowledge in a weighted-sum manner.\nSubsequently, we employ these components to numerically initialize descendant\nmodels of varying scales and modalities. Extensive experiments demonstrate\nMM-LG's effectiveness, which achieves performance gains over existing learngene\napproaches (e.g.,+3.1% on Oxford-IIIT PET and +4.13% on Flickr30k) and\ncomparable or superior results to the pre-training and fine-tuning paradigm\n(e.g.,+1.9% on Oxford-IIIT PET and +3.65% on Flickr30k). Notably, MM-LG\nrequires only around 25% of the parameter storage while reducing around 2.8\ntimes pre-training costs for diverse model scales compared to the pre-training\nand fine-tuning paradigm, making it particularly suitable for efficient\ndeployment across diverse downstream tasks.", "AI": {"tldr": "MM-LG extracts multimodal generalizable knowledge from CLIP, reducing computational costs and improving performance over existing methods.", "motivation": "Address the challenge of pre-training CLIP at different scales and modalities by leveraging generalizable components efficiently.", "method": "Uses multimodal and unimodal blocks to extract knowledge, initializes descendant models with these components, and evaluates performance.", "result": "Achieves performance gains (e.g., +3.1% on Oxford-IIIT PET) and reduces pre-training costs by ~2.8x with 25% parameter storage.", "conclusion": "MM-LG is efficient and effective for diverse downstream tasks, outperforming existing approaches and reducing resource demands."}}
{"id": "2506.15926", "pdf": "https://arxiv.org/pdf/2506.15926", "abs": "https://arxiv.org/abs/2506.15926", "authors": ["Soumya Basu"], "title": "Competing Bandits in Matching Markets via Super Stability", "categories": ["cs.LG", "cs.IT", "math.IT"], "comment": null, "summary": "We study bandit learning in matching markets with two-sided reward\nuncertainty, extending prior research primarily focused on single-sided\nuncertainty. Leveraging the concept of `super-stability' from Irving (1994), we\ndemonstrate the advantage of the Extended Gale-Shapley (GS) algorithm over the\nstandard GS algorithm in achieving true stable matchings under incomplete\ninformation. By employing the Extended GS algorithm, our centralized algorithm\nattains a logarithmic pessimal stable regret dependent on an instance-dependent\nadmissible gap parameter. This algorithm is further adapted to a decentralized\nsetting with a constant regret increase. Finally, we establish a novel\ncentralized instance-dependent lower bound for binary stable regret,\nelucidating the roles of the admissible gap and super-stable matching in\ncharacterizing the complexity of stable matching with bandit feedback.", "AI": {"tldr": "The paper extends bandit learning to two-sided reward uncertainty in matching markets, showing the Extended Gale-Shapley algorithm outperforms the standard GS algorithm in achieving stable matchings under incomplete information. It achieves logarithmic pessimal stable regret and adapts to decentralized settings with minimal regret increase.", "motivation": "Prior research focused on single-sided uncertainty in matching markets. This work addresses the gap by studying two-sided reward uncertainty, aiming to improve stable matching under incomplete information.", "method": "The paper leverages the concept of 'super-stability' and employs the Extended Gale-Shapley algorithm. It develops a centralized algorithm with logarithmic pessimal stable regret and adapts it to decentralized settings.", "result": "The centralized algorithm achieves logarithmic pessimal stable regret dependent on an admissible gap parameter. The decentralized adaptation incurs only a constant regret increase. A novel centralized instance-dependent lower bound for binary stable regret is established.", "conclusion": "The study highlights the advantage of the Extended GS algorithm in stable matching under incomplete information, providing theoretical insights into the complexity of stable matching with bandit feedback."}}
{"id": "2506.16014", "pdf": "https://arxiv.org/pdf/2506.16014", "abs": "https://arxiv.org/abs/2506.16014", "authors": ["Jina Kim", "Youjin Jang", "Jeongjin Han"], "title": "VRAIL: Vectorized Reward-based Attribution for Interpretable Learning", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "We propose VRAIL (Vectorized Reward-based Attribution for Interpretable\nLearning), a bi-level framework for value-based reinforcement learning (RL)\nthat learns interpretable weight representations from state features. VRAIL\nconsists of two stages: a deep learning (DL) stage that fits an estimated value\nfunction using state features, and an RL stage that uses this to shape learning\nvia potential-based reward transformations. The estimator is modeled in either\nlinear or quadratic form, allowing attribution of importance to individual\nfeatures and their interactions. Empirical results on the Taxi-v3 environment\ndemonstrate that VRAIL improves training stability and convergence compared to\nstandard DQN, without requiring environment modifications. Further analysis\nshows that VRAIL uncovers semantically meaningful subgoals, such as passenger\npossession, highlighting its ability to produce human-interpretable behavior.\nOur findings suggest that VRAIL serves as a general, model-agnostic framework\nfor reward shaping that enhances both learning and interpretability.", "AI": {"tldr": "VRAIL is a bi-level RL framework combining deep learning and reward shaping for interpretable feature attribution, improving stability and interpretability in RL tasks like Taxi-v3.", "motivation": "To enhance interpretability and stability in value-based RL by learning meaningful weight representations from state features.", "method": "Two-stage approach: DL for value function estimation (linear/quadratic) and RL for reward shaping via potential-based transformations.", "result": "Improves training stability and convergence in Taxi-v3, identifies meaningful subgoals (e.g., passenger possession), and works without environment changes.", "conclusion": "VRAIL is a model-agnostic framework that boosts both learning performance and interpretability in RL."}}
{"id": "2506.17046", "pdf": "https://arxiv.org/pdf/2506.17046", "abs": "https://arxiv.org/abs/2506.17046", "authors": ["Xiaolong Wang", "Zhaolu Kang", "Wangyuxuan Zhai", "Xinyue Lou", "Yunghwei Lai", "Ziyue Wang", "Yawen Wang", "Kaiyu Huang", "Yile Wang", "Peng Li", "Yang Liu"], "title": "MUCAR: Benchmarking Multilingual Cross-Modal Ambiguity Resolution for Multimodal Large Language Models", "categories": ["cs.CL", "cs.LG"], "comment": null, "summary": "Multimodal Large Language Models (MLLMs) have demonstrated significant\nadvances across numerous vision-language tasks. Due to their strong image-text\nalignment capability, MLLMs can effectively understand image-text pairs with\nclear meanings. However, effectively resolving the inherent ambiguities in\nnatural language and visual contexts remains challenging. Existing multimodal\nbenchmarks typically overlook linguistic and visual ambiguities, relying mainly\non unimodal context for disambiguation and thus failing to exploit the mutual\nclarification potential between modalities. To bridge this gap, we introduce\nMUCAR, a novel and challenging benchmark designed explicitly for evaluating\nmultimodal ambiguity resolution across multilingual and cross-modal scenarios.\nMUCAR includes: (1) a multilingual dataset where ambiguous textual expressions\nare uniquely resolved by corresponding visual contexts, and (2) a\ndual-ambiguity dataset that systematically pairs ambiguous images with\nambiguous textual contexts, with each combination carefully constructed to\nyield a single, clear interpretation through mutual disambiguation. Extensive\nevaluations involving 19 state-of-the-art multimodal models--encompassing both\nopen-source and proprietary architectures--reveal substantial gaps compared to\nhuman-level performance, highlighting the need for future research into more\nsophisticated cross-modal ambiguity comprehension methods, further pushing the\nboundaries of multimodal reasoning.", "AI": {"tldr": "MUCAR is a new benchmark for evaluating multimodal ambiguity resolution, addressing gaps in existing benchmarks by focusing on multilingual and cross-modal scenarios.", "motivation": "Existing benchmarks overlook linguistic and visual ambiguities, failing to leverage mutual clarification between modalities.", "method": "MUCAR includes a multilingual dataset and a dual-ambiguity dataset to test multimodal ambiguity resolution.", "result": "Evaluations of 19 state-of-the-art models show significant performance gaps compared to humans.", "conclusion": "Future research is needed to improve cross-modal ambiguity comprehension and advance multimodal reasoning."}}
{"id": "2506.16679", "pdf": "https://arxiv.org/pdf/2506.16679", "abs": "https://arxiv.org/abs/2506.16679", "authors": ["Manuel Brack", "Sudeep Katakol", "Felix Friedrich", "Patrick Schramowski", "Hareesh Ravi", "Kristian Kersting", "Ajinkya Kale"], "title": "How to Train your Text-to-Image Model: Evaluating Design Choices for Synthetic Training Captions", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": null, "summary": "Training data is at the core of any successful text-to-image models. The\nquality and descriptiveness of image text are crucial to a model's performance.\nGiven the noisiness and inconsistency in web-scraped datasets, recent works\nshifted towards synthetic training captions. While this setup is generally\nbelieved to produce more capable models, current literature does not provide\nany insights into its design choices. This study closes this gap by\nsystematically investigating how different synthetic captioning strategies\nimpact the downstream performance of text-to-image models. Our experiments\ndemonstrate that dense, high-quality captions enhance text alignment but may\nintroduce trade-offs in output aesthetics and diversity. Conversely, captions\nof randomized lengths yield balanced improvements across aesthetics and\nalignment without compromising sample diversity. We also demonstrate that\nvarying caption distributions introduce significant shifts in the output bias\nof a trained model. Our findings underscore the importance of caption design in\nachieving optimal model performance and provide practical insights for more\neffective training data strategies in text-to-image generation.", "AI": {"tldr": "The study explores how synthetic captioning strategies affect text-to-image models, finding that dense captions improve alignment but may reduce aesthetics and diversity, while randomized-length captions balance these aspects.", "motivation": "To address the lack of understanding about synthetic captioning design choices and their impact on text-to-image model performance.", "method": "Systematic investigation of different synthetic captioning strategies and their effects on model performance.", "result": "Dense captions enhance alignment but may harm aesthetics and diversity; randomized-length captions balance these trade-offs. Caption distributions also influence output bias.", "conclusion": "Caption design is critical for optimal model performance, and the study offers practical insights for better training data strategies."}}
{"id": "2506.15933", "pdf": "https://arxiv.org/pdf/2506.15933", "abs": "https://arxiv.org/abs/2506.15933", "authors": ["Esther Rodriguez", "Monica Welfert", "Samuel McDowell", "Nathan Stromberg", "Julian Antolin Camarena", "Lalitha Sankar"], "title": "CORAL: Disentangling Latent Representations in Long-Tailed Diffusion", "categories": ["cs.LG"], "comment": null, "summary": "Diffusion models have achieved impressive performance in generating\nhigh-quality and diverse synthetic data. However, their success typically\nassumes a class-balanced training distribution. In real-world settings,\nmulti-class data often follow a long-tailed distribution, where standard\ndiffusion models struggle -- producing low-diversity and lower-quality samples\nfor tail classes. While this degradation is well-documented, its underlying\ncause remains poorly understood. In this work, we investigate the behavior of\ndiffusion models trained on long-tailed datasets and identify a key issue: the\nlatent representations (from the bottleneck layer of the U-Net) for tail class\nsubspaces exhibit significant overlap with those of head classes, leading to\nfeature borrowing and poor generation quality. Importantly, we show that this\nis not merely due to limited data per class, but that the relative class\nimbalance significantly contributes to this phenomenon. To address this, we\npropose COntrastive Regularization for Aligning Latents (CORAL), a contrastive\nlatent alignment framework that leverages supervised contrastive losses to\nencourage well-separated latent class representations. Experiments demonstrate\nthat CORAL significantly improves both the diversity and visual quality of\nsamples generated for tail classes relative to state-of-the-art methods.", "AI": {"tldr": "Diffusion models struggle with long-tailed data distributions, producing poor-quality tail-class samples due to overlapping latent representations. CORAL, a contrastive regularization method, improves tail-class generation quality.", "motivation": "Real-world multi-class data often follows long-tailed distributions, where standard diffusion models fail to generate diverse and high-quality samples for tail classes. The underlying cause of this degradation is unclear.", "method": "The study investigates diffusion models on long-tailed datasets, identifying overlapping latent representations as the key issue. CORAL is proposed, using contrastive losses to separate latent class representations.", "result": "CORAL significantly enhances the diversity and visual quality of tail-class samples compared to state-of-the-art methods.", "conclusion": "The relative class imbalance, not just limited data, causes poor tail-class generation. CORAL effectively addresses this by aligning latent representations."}}
{"id": "2506.16035", "pdf": "https://arxiv.org/pdf/2506.16035", "abs": "https://arxiv.org/abs/2506.16035", "authors": ["Vishesh Tripathi", "Tanmay Odapally", "Indraneel Das", "Uday Allu", "Biddwan Ahmed"], "title": "Vision-Guided Chunking Is All You Need: Enhancing RAG with Multimodal Document Understanding", "categories": ["cs.LG", "cs.AI", "cs.IR"], "comment": "11 pages, 1 Figure, 1 Table", "summary": "Retrieval-Augmented Generation (RAG) systems have revolutionized information\nretrieval and question answering, but traditional text-based chunking methods\nstruggle with complex document structures, multi-page tables, embedded figures,\nand contextual dependencies across page boundaries. We present a novel\nmultimodal document chunking approach that leverages Large Multimodal Models\n(LMMs) to process PDF documents in batches while maintaining semantic coherence\nand structural integrity. Our method processes documents in configurable page\nbatches with cross-batch context preservation, enabling accurate handling of\ntables spanning multiple pages, embedded visual elements, and procedural\ncontent. We evaluate our approach on a curated dataset of PDF documents with\nmanually crafted queries, demonstrating improvements in chunk quality and\ndownstream RAG performance. Our vision-guided approach achieves better accuracy\ncompared to traditional vanilla RAG systems, with qualitative analysis showing\nsuperior preservation of document structure and semantic coherence.", "AI": {"tldr": "A novel multimodal document chunking method using Large Multimodal Models (LMMs) improves RAG systems by handling complex document structures, multi-page tables, and embedded figures better than traditional text-based chunking.", "motivation": "Traditional text-based chunking struggles with complex document structures, multi-page tables, and embedded figures, limiting RAG system performance.", "method": "Uses LMMs to process PDF documents in configurable page batches with cross-batch context preservation, maintaining semantic coherence and structural integrity.", "result": "Improves chunk quality and downstream RAG performance, achieving better accuracy and superior preservation of document structure and semantic coherence.", "conclusion": "The multimodal approach outperforms traditional RAG systems in handling complex documents."}}
{"id": "2506.17077", "pdf": "https://arxiv.org/pdf/2506.17077", "abs": "https://arxiv.org/abs/2506.17077", "authors": ["Dominik Mach\u00e1\u010dek", "Peter Pol\u00e1k"], "title": "Simultaneous Translation with Offline Speech and LLM Models in CUNI Submission to IWSLT 2025", "categories": ["cs.CL"], "comment": "IWSLT 2025", "summary": "This paper describes Charles University submission to the Simultaneous Speech\nTranslation Task of the IWSLT 2025. We cover all four language pairs with a\ndirect or cascade approach. The backbone of our systems is the offline Whisper\nspeech model, which we use for both translation and transcription in\nsimultaneous mode with the state-of-the-art simultaneous policy AlignAtt. We\nfurther improve the performance by prompting to inject in-domain terminology,\nand we accommodate context. Our cascaded systems further use EuroLLM for\nunbounded simultaneous translation. Compared to the Organizers' baseline, our\nsystems improve by 2 BLEU points on Czech to English and 13-22 BLEU points on\nEnglish to German, Chinese and Japanese on the development sets. Additionally,\nwe also propose a new enhanced measure of speech recognition latency.", "AI": {"tldr": "Charles University's IWSLT 2025 submission uses Whisper and AlignAtt for simultaneous speech translation, improving BLEU scores significantly.", "motivation": "To enhance simultaneous speech translation performance across multiple language pairs using advanced models and policies.", "method": "Utilizes Whisper for translation/transcription with AlignAtt policy, in-domain prompting, and EuroLLM for cascaded systems.", "result": "Improves BLEU scores by 2 (Czech-English) and 13-22 (English-German/Chinese/Japanese). Also proposes a new latency measure.", "conclusion": "The approach effectively boosts translation quality and introduces a novel latency metric."}}
{"id": "2506.16690", "pdf": "https://arxiv.org/pdf/2506.16690", "abs": "https://arxiv.org/abs/2506.16690", "authors": ["Yun Xing", "Yue Cao", "Nhat Chung", "Jie Zhang", "Ivor Tsang", "Ming-Ming Cheng", "Yang Liu", "Lei Ma", "Qing Guo"], "title": "DepthVanish: Optimizing Adversarial Interval Structures for Stereo-Depth-Invisible Patches", "categories": ["cs.CV"], "comment": null, "summary": "Stereo Depth estimation is a critical task in autonomous driving and\nrobotics, where inaccuracies (such as misidentifying nearby objects as distant)\ncan lead to dangerous situations. Adversarial attacks against stereo depth\nestimation can help reveal vulnerabilities before deployment. Previous work has\nshown that repeating optimized textures can effectively mislead stereo depth\nestimation in digital settings. However, our research reveals that these\nnaively repeated texture structures perform poorly in physical-world\nimplementations, i.e., when deployed as patches, limiting their practical\nutility for testing stereo depth estimation systems. In this work, for the\nfirst time, we discover that introducing regular intervals between repeated\ntextures, creating a striped structure, significantly enhances the patch attack\neffectiveness. Through extensive experimentation, we analyze how variations of\nthis novel structure influence the performance. Based on these insights, we\ndevelop a novel stereo depth attack that jointly optimizes both the striped\nstructure and texture elements. Our generated adversarial patches can be\ninserted into any scenes and successfully attack state-of-the-art stereo depth\nestimation methods, i.e., RAFT-Stereo and STTR. Most critically, our patch can\nalso attack commercial RGB-D cameras (Intel RealSense) in real-world\nconditions, demonstrating their practical relevance for security assessment of\nstereo systems.", "AI": {"tldr": "Introducing striped structures in adversarial patches improves physical-world attack effectiveness on stereo depth estimation systems.", "motivation": "To address the poor performance of naively repeated textures in physical-world adversarial attacks on stereo depth estimation, revealing vulnerabilities before deployment.", "method": "Developed a novel attack by optimizing striped structures and textures, tested on RAFT-Stereo, STTR, and Intel RealSense.", "result": "The striped structure significantly enhances attack effectiveness, successfully misleading state-of-the-art systems and commercial cameras.", "conclusion": "The proposed adversarial patches are practical for real-world security assessments of stereo depth estimation systems."}}
{"id": "2506.15943", "pdf": "https://arxiv.org/pdf/2506.15943", "abs": "https://arxiv.org/abs/2506.15943", "authors": ["Bruce Huang", "Ruida Zhou", "Lin F. Yang", "Suhas Diggavi"], "title": "On the optimal regret of collaborative personalized linear bandits", "categories": ["cs.LG"], "comment": "30 pages, 4 figures", "summary": "Stochastic linear bandits are a fundamental model for sequential decision\nmaking, where an agent selects a vector-valued action and receives a noisy\nreward with expected value given by an unknown linear function. Although well\nstudied in the single-agent setting, many real-world scenarios involve multiple\nagents solving heterogeneous bandit problems, each with a different unknown\nparameter. Applying single agent algorithms independently ignores cross-agent\nsimilarity and learning opportunities. This paper investigates the optimal\nregret achievable in collaborative personalized linear bandits. We provide an\ninformation-theoretic lower bound that characterizes how the number of agents,\nthe interaction rounds, and the degree of heterogeneity jointly affect regret.\nWe then propose a new two-stage collaborative algorithm that achieves the\noptimal regret. Our analysis models heterogeneity via a hierarchical Bayesian\nframework and introduces a novel information-theoretic technique for bounding\nregret. Our results offer a complete characterization of when and how\ncollaboration helps with a optimal regret bound $\\tilde{O}(d\\sqrt{mn})$,\n$\\tilde{O}(dm^{1-\\gamma}\\sqrt{n})$, $\\tilde{O}(dm\\sqrt{n})$ for the number of\nrounds $n$ in the range of $(0, \\frac{d}{m \\sigma^2})$, $[\\frac{d}{m^{2\\gamma}\n\\sigma^2}, \\frac{d}{\\sigma^2}]$ and $(\\frac{d}{\\sigma^2}, \\infty)$\nrespectively, where $\\sigma$ measures the level of heterogeneity, $m$ is the\nnumber of agents, and $\\gamma\\in[0, 1/2]$ is an absolute constant. In contrast,\nagents without collaboration achieve a regret bound $O(dm\\sqrt{n})$ at best.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2506.16056", "pdf": "https://arxiv.org/pdf/2506.16056", "abs": "https://arxiv.org/abs/2506.16056", "authors": ["Puchun Liu", "C. L. Philip Chen", "Yubin He", "Tong Zhang"], "title": "CRIA: A Cross-View Interaction and Instance-Adapted Pre-training Framework for Generalizable EEG Representations", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "The difficulty of extracting deep features from EEG data and effectively\nintegrating information from multiple views presents significant challenges for\ndeveloping a generalizable pretraining framework for EEG representation\nlearning. However, most existing pre-training methods rely solely on the\ncontextual semantics of a single view, failing to capture the complex and\nsynergistic interactions among different perspectives, limiting the\nexpressiveness and generalization of learned representations. To address these\nissues, this paper proposes CRIA, an adaptive framework that utilizes\nvariable-length and variable-channel coding to achieve a unified representation\nof EEG data across different datasets. In this work, we define cross-view\ninformation as the integrated representation that emerges from the interaction\namong temporal, spectral, and spatial views of EEG signals. The model employs a\ncross-attention mechanism to fuse temporal, spectral, and spatial features\neffectively, and combines an attention matrix masking strategy based on the\ninformation bottleneck principle with a novel viewpoint masking pre-training\nscheme. Experimental results on the Temple University EEG corpus and the\nCHB-MIT dataset show that CRIA outperforms existing methods with the same\npre-training conditions, achieving a balanced accuracy of 57.02% for\nmulti-class event classification and 80.03% for anomaly detection, highlighting\nits strong generalization ability.", "AI": {"tldr": "CRIA is a novel EEG pretraining framework that integrates temporal, spectral, and spatial views using cross-attention and masking strategies, outperforming existing methods in generalization.", "motivation": "Existing EEG pretraining methods lack the ability to capture multi-view interactions, limiting representation expressiveness and generalization.", "method": "CRIA uses variable-length/channel coding, cross-attention for feature fusion, and a masking strategy based on the information bottleneck principle.", "result": "Achieves 57.02% balanced accuracy for multi-class event classification and 80.03% for anomaly detection, surpassing existing methods.", "conclusion": "CRIA demonstrates strong generalization by effectively integrating multi-view EEG data, offering a robust pretraining framework."}}
{"id": "2506.17080", "pdf": "https://arxiv.org/pdf/2506.17080", "abs": "https://arxiv.org/abs/2506.17080", "authors": ["Ricardo Rei", "Nuno M. Guerreiro", "Jos\u00e9 Pombal", "Jo\u00e3o Alves", "Pedro Teixeirinha", "Amin Farajian", "Andr\u00e9 F. T. Martins"], "title": "Tower+: Bridging Generality and Translation Specialization in Multilingual LLMs", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Fine-tuning pretrained LLMs has been shown to be an effective strategy for\nreaching state-of-the-art performance on specific tasks like machine\ntranslation. However, this process of adaptation often implies sacrificing\ngeneral-purpose capabilities, such as conversational reasoning and\ninstruction-following, hampering the utility of the system in real-world\napplications that require a mixture of skills. In this paper, we introduce\nTower+, a suite of models designed to deliver strong performance across both\ntranslation and multilingual general-purpose text capabilities. We achieve a\nPareto frontier between translation specialization and multilingual\ngeneral-purpose capabilities by introducing a novel training recipe that builds\non Tower (Alves et al., 2024), comprising continued pretraining, supervised\nfine-tuning, preference optimization, and reinforcement learning with\nverifiable rewards. At each stage of training, we carefully generate and curate\ndata to strengthen performance on translation as well as general-purpose tasks\ninvolving code generation, mathematics problem solving, and general\ninstruction-following. We develop models at multiple scales: 2B, 9B, and 72B.\nOur smaller models often outperform larger general-purpose open-weight and\nproprietary LLMs (e.g., Llama 3.3 70B, GPT-4o). Our largest model delivers\nbest-in-class translation performance for high-resource languages and top\nresults in multilingual Arena Hard evaluations and in IF-MT, a benchmark we\nintroduce for evaluating both translation and instruction-following. Our\nfindings highlight that it is possible to rival frontier models in general\ncapabilities, while optimizing for specific business domains, such as\ntranslation and localization.", "AI": {"tldr": "Tower+ is a suite of models balancing translation specialization and multilingual general-purpose capabilities, outperforming larger models in specific tasks while maintaining broad utility.", "motivation": "Fine-tuning LLMs for specific tasks like translation often sacrifices general-purpose capabilities, limiting real-world application. Tower+ aims to address this trade-off.", "method": "A novel training recipe includes continued pretraining, supervised fine-tuning, preference optimization, and reinforcement learning with verifiable rewards, using carefully curated data.", "result": "Tower+ models (2B, 9B, 72B) outperform larger general-purpose and proprietary LLMs in translation and general tasks, with the 72B model achieving best-in-class translation and top multilingual results.", "conclusion": "Tower+ demonstrates that optimizing for specific domains (e.g., translation) while rivaling frontier models in general capabilities is achievable."}}
{"id": "2506.16691", "pdf": "https://arxiv.org/pdf/2506.16691", "abs": "https://arxiv.org/abs/2506.16691", "authors": ["Tongtian Yue", "Longteng Guo", "Yepeng Tang", "Zijia Zhao", "Xinxin Zhu", "Hua Huang", "Jing Liu"], "title": "LaVi: Efficient Large Vision-Language Models via Internal Feature Modulation", "categories": ["cs.CV"], "comment": null, "summary": "Despite the impressive advancements of Large Vision-Language Models (LVLMs),\nexisting approaches suffer from a fundamental bottleneck: inefficient\nvisual-language integration. Current methods either disrupt the model's\ninherent structure or introduce severe long-context computational burden,\nseverely limiting scalability and efficiency. In this paper, we rethink\nmultimodal integration and present LaVi, a novel LVLM that enables seamless and\nefficient vision-language fusion through internal feature modulation within the\nLarge Language Models (LLMs). Unlike dominant LVLMs that rely on visual token\nconcatenation, LaVi bypasses long-context expansion by introducing a\nlightweight and adaptive transformation, which incorporates visual context by\ninjecting token-wise vision-conditioned deltas into the affine parameters of\nlayer normalization. This mechanism directly modulates linguistic hidden states\nbased on visual input, ensuring precise vision-language alignment while\npreserving the LLM's linguistic priors and drastically reducing computational\ncosts. Extensive evaluations across 15 image and video benchmarks demonstrate\nthat LaVi not only achieves state-of-the-art multimodal performance but also\ndramatically enhances efficiency. Compared to LLaVA-OV-7B, LaVi reduces FLOPs\nby 94.0%, improves inference speed by 3.1 times, and cuts memory usage in half\n- establishing LaVi as a scalable and practical solution for real-time\nmultimodal reasoning. The code and models will be released soon.", "AI": {"tldr": "LaVi introduces a lightweight, adaptive transformation for efficient vision-language fusion in LVLMs, reducing computational costs while maintaining performance.", "motivation": "Current LVLMs suffer from inefficient visual-language integration, disrupting model structure or increasing computational burden.", "method": "LaVi uses internal feature modulation within LLMs, injecting vision-conditioned deltas into layer normalization parameters to align vision and language without long-context expansion.", "result": "LaVi achieves state-of-the-art performance on 15 benchmarks, reducing FLOPs by 94%, improving speed by 3.1x, and halving memory usage compared to LLaVA-OV-7B.", "conclusion": "LaVi offers a scalable, efficient solution for real-time multimodal reasoning, with code and models to be released."}}
{"id": "2506.15954", "pdf": "https://arxiv.org/pdf/2506.15954", "abs": "https://arxiv.org/abs/2506.15954", "authors": ["Vinicius Yuiti Fukase", "Heitor Gama", "Barbara Bueno", "Lucas Libanio", "Anna Helena Reali Costa", "Artur Jordao"], "title": "One Period to Rule Them All: Identifying Critical Learning Periods in Deep Networks", "categories": ["cs.LG"], "comment": null, "summary": "Critical Learning Periods comprehend an important phenomenon involving deep\nlearning, where early epochs play a decisive role in the success of many\ntraining recipes, such as data augmentation. Existing works confirm the\nexistence of this phenomenon and provide useful insights. However, the\nliterature lacks efforts to precisely identify when critical periods occur. In\nthis work, we fill this gap by introducing a systematic approach for\nidentifying critical periods during the training of deep neural networks,\nfocusing on eliminating computationally intensive regularization techniques and\neffectively applying mechanisms for reducing computational costs, such as data\npruning. Our method leverages generalization prediction mechanisms to pinpoint\ncritical phases where training recipes yield maximum benefits to the predictive\nability of models. By halting resource-intensive recipes beyond these periods,\nwe significantly accelerate the learning phase and achieve reductions in\ntraining time, energy consumption, and CO$_2$ emissions. Experiments on\nstandard architectures and benchmarks confirm the effectiveness of our method.\nSpecifically, we achieve significant milestones by reducing the training time\nof popular architectures by up to 59.67%, leading to a 59.47% decrease in\nCO$_2$ emissions and a 60% reduction in financial costs, without compromising\nperformance. Our work enhances understanding of training dynamics and paves the\nway for more sustainable and efficient deep learning practices, particularly in\nresource-constrained environments. In the era of the race for foundation\nmodels, we believe our method emerges as a valuable framework. The repository\nis available at https://github.com/baunilhamarga/critical-periods", "AI": {"tldr": "The paper introduces a method to identify critical learning periods in deep neural network training, reducing computational costs and emissions without performance loss.", "motivation": "Existing works confirm critical learning periods but lack precise identification. This work fills the gap by systematically identifying these periods to optimize training efficiency.", "method": "The approach uses generalization prediction mechanisms to pinpoint critical phases, halting resource-intensive techniques beyond these periods.", "result": "The method reduces training time by up to 59.67%, CO$_2$ emissions by 59.47%, and costs by 60%, with no performance compromise.", "conclusion": "The work advances understanding of training dynamics and promotes sustainable deep learning, especially in resource-constrained settings."}}
{"id": "2506.16078", "pdf": "https://arxiv.org/pdf/2506.16078", "abs": "https://arxiv.org/abs/2506.16078", "authors": ["Tianle Gu", "Kexin Huang", "Zongqi Wang", "Yixu Wang", "Jie Li", "Yuanqi Yao", "Yang Yao", "Yujiu Yang", "Yan Teng", "Yingchun Wang"], "title": "Probing the Robustness of Large Language Models Safety to Latent Perturbations", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.CR"], "comment": null, "summary": "Safety alignment is a key requirement for building reliable Artificial\nGeneral Intelligence. Despite significant advances in safety alignment, we\nobserve that minor latent shifts can still trigger unsafe responses in aligned\nmodels. We argue that this stems from the shallow nature of existing alignment\nmethods, which focus on surface-level refusal behaviors without sufficiently\naltering internal representations. Consequently, small shifts in hidden\nactivations can re-trigger harmful behaviors embedded in the latent space. To\nexplore the robustness of safety alignment to latent perturbations, we\nintroduce a probing method that measures the Negative Log-Likelihood of the\noriginal response generated by the model. This probe quantifies local\nsensitivity in the latent space, serving as a diagnostic tool for identifying\nvulnerable directions. Based on this signal, we construct effective jailbreak\ntrajectories, giving rise to the Activation Steering Attack (ASA). More\nimportantly, these insights offer a principled foundation for improving\nalignment robustness. To this end, we introduce Layer-wise Adversarial Patch\nTraining~(LAPT), a fine-tuning strategy that inject controlled perturbations\ninto hidden representations during training. Experimental results highlight\nthat LAPT strengthen alignment robustness without compromising general\ncapabilities. Our findings reveal fundamental flaws in current alignment\nparadigms and call for representation-level training strategies that move\nbeyond surface-level behavior supervision. Codes and results are available at\nhttps://github.com/Carol-gutianle/LatentSafety.", "AI": {"tldr": "The paper identifies flaws in current safety alignment methods for AI, showing minor latent shifts can trigger unsafe responses. It introduces a probing method (ASA) and a training strategy (LAPT) to improve robustness.", "motivation": "Existing safety alignment methods are shallow, focusing on surface-level behaviors, making models vulnerable to latent shifts that re-trigger harmful behaviors.", "method": "Proposed a probing method (ASA) to measure latent sensitivity and introduced LAPT, a fine-tuning strategy using controlled perturbations in hidden representations.", "result": "LAPT improved alignment robustness without degrading general capabilities, revealing vulnerabilities in current methods.", "conclusion": "Current alignment paradigms are flawed; representation-level training (like LAPT) is needed for robust safety alignment."}}
{"id": "2506.17088", "pdf": "https://arxiv.org/pdf/2506.17088", "abs": "https://arxiv.org/abs/2506.17088", "authors": ["Jiahao Cheng", "Tiancheng Su", "Jia Yuan", "Guoxiu He", "Jiawei Liu", "Xinqi Tao", "Jingwen Xie", "Huaxia Li"], "title": "Chain-of-Thought Prompting Obscures Hallucination Cues in Large Language Models: An Empirical Evaluation", "categories": ["cs.CL"], "comment": null, "summary": "Large Language Models (LLMs) often exhibit \\textit{hallucinations},\ngenerating factually incorrect or semantically irrelevant content in response\nto prompts. Chain-of-Thought (CoT) prompting can mitigate hallucinations by\nencouraging step-by-step reasoning, but its impact on hallucination detection\nremains underexplored. To bridge this gap, we conduct a systematic empirical\nevaluation. We begin with a pilot experiment, revealing that CoT reasoning\nsignificantly affects the LLM's internal states and token probability\ndistributions. Building on this, we evaluate the impact of various CoT\nprompting methods on mainstream hallucination detection methods across both\ninstruction-tuned and reasoning-oriented LLMs. Specifically, we examine three\nkey dimensions: changes in hallucination score distributions, variations in\ndetection accuracy, and shifts in detection confidence. Our findings show that\nwhile CoT prompting helps reduce hallucination frequency, it also tends to\nobscure critical signals used for detection, impairing the effectiveness of\nvarious detection methods. Our study highlights an overlooked trade-off in the\nuse of reasoning. Code is publicly available at:\nhttps://anonymous.4open.science/r/cot-hallu-detect.", "AI": {"tldr": "CoT prompting reduces LLM hallucinations but weakens detection methods by obscuring key signals.", "motivation": "To explore the underexplored impact of CoT prompting on hallucination detection in LLMs.", "method": "Systematic empirical evaluation, including pilot experiments and analysis of CoT's effects on hallucination detection across LLMs.", "result": "CoT reduces hallucinations but impairs detection accuracy by masking critical signals.", "conclusion": "CoT introduces a trade-off between reducing hallucinations and maintaining detection effectiveness."}}
{"id": "2506.16701", "pdf": "https://arxiv.org/pdf/2506.16701", "abs": "https://arxiv.org/abs/2506.16701", "authors": ["Xiaodan Hu", "Chuhang Zou", "Suchen Wang", "Jaechul Kim", "Narendra Ahuja"], "title": "Language-driven Description Generation and Common Sense Reasoning for Video Action Recognition", "categories": ["cs.CV"], "comment": null, "summary": "Recent video action recognition methods have shown excellent performance by\nadapting large-scale pre-trained language-image models to the video domain.\nHowever, language models contain rich common sense priors - the scene contexts\nthat humans use to constitute an understanding of objects, human-object\ninteractions, and activities - that have not been fully exploited. In this\npaper, we introduce a framework incorporating language-driven common sense\npriors to identify cluttered video action sequences from monocular views that\nare often heavily occluded. We propose: (1) A video context summary component\nthat generates candidate objects, activities, and the interactions between\nobjects and activities; (2) A description generation module that describes the\ncurrent scene given the context and infers subsequent activities, through\nauxiliary prompts and common sense reasoning; (3) A multi-modal activity\nrecognition head that combines visual and textual cues to recognize video\nactions. We demonstrate the effectiveness of our approach on the challenging\nAction Genome and Charades datasets.", "AI": {"tldr": "A framework leveraging language-driven common sense priors improves video action recognition in cluttered, occluded scenes by combining visual and textual cues.", "motivation": "Existing methods underutilize rich common sense priors in language models for understanding cluttered video scenes.", "method": "Proposes a framework with three components: video context summary, description generation, and multi-modal activity recognition.", "result": "Demonstrated effectiveness on Action Genome and Charades datasets.", "conclusion": "Incorporating language-driven common sense priors enhances video action recognition in challenging scenarios."}}
{"id": "2506.15963", "pdf": "https://arxiv.org/pdf/2506.15963", "abs": "https://arxiv.org/abs/2506.15963", "authors": ["Jingyi Cui", "Qi Zhang", "Yifei Wang", "Yisen Wang"], "title": "On the Theoretical Understanding of Identifiable Sparse Autoencoders and Beyond", "categories": ["cs.LG"], "comment": null, "summary": "Sparse autoencoders (SAEs) have emerged as a powerful tool for interpreting\nfeatures learned by large language models (LLMs). It aims to recover complex\nsuperposed polysemantic features into interpretable monosemantic ones through\nfeature reconstruction via sparsely activated neural networks. Despite the wide\napplications of SAEs, it remains unclear under what conditions an SAE can fully\nrecover the ground truth monosemantic features from the superposed polysemantic\nones. In this paper, through theoretical analysis, we for the first time\npropose the necessary and sufficient conditions for identifiable SAEs (SAEs\nthat learn unique and ground truth monosemantic features), including 1) extreme\nsparsity of the ground truth feature, 2) sparse activation of SAEs, and 3)\nenough hidden dimensions of SAEs. Moreover, when the identifiable conditions\nare not fully met, we propose a reweighting strategy to improve the\nidentifiability. Specifically, following the theoretically suggested weight\nselection principle, we prove that the gap between the loss functions of SAE\nreconstruction and monosemantic feature reconstruction can be narrowed, so that\nthe reweighted SAEs have better reconstruction of the ground truth monosemantic\nfeatures than the uniformly weighted ones. In experiments, we validate our\ntheoretical findings and show that our weighted SAE significantly improves\nfeature monosemanticity and interpretability.", "AI": {"tldr": "The paper identifies conditions for sparse autoencoders (SAEs) to recover monosemantic features from polysemantic ones and proposes a reweighting strategy to enhance identifiability when conditions aren't fully met.", "motivation": "To clarify under what conditions SAEs can uniquely and accurately recover ground truth monosemantic features from superposed polysemantic ones.", "method": "Theoretical analysis to derive necessary and sufficient conditions for identifiable SAEs, followed by a reweighting strategy to narrow the loss function gap.", "result": "Validated theoretical conditions and showed that weighted SAEs improve monosemanticity and interpretability.", "conclusion": "The study provides theoretical and practical insights into improving SAEs for feature recovery, enhancing interpretability in large language models."}}
{"id": "2506.16096", "pdf": "https://arxiv.org/pdf/2506.16096", "abs": "https://arxiv.org/abs/2506.16096", "authors": ["Qianqian Liao", "Wuque Cai", "Hongze Sun", "Dongze Liu", "Duo Chen", "Dezhong Yao", "Daqing Guo"], "title": "A Brain-to-Population Graph Learning Framework for Diagnosing Brain Disorders", "categories": ["cs.LG", "cs.AI"], "comment": "16 pages, 7 figures, 13 tables; this paper has been submitted for\n  possible publication", "summary": "Recent developed graph-based methods for diagnosing brain disorders using\nfunctional connectivity highly rely on predefined brain atlases, but overlook\nthe rich information embedded within atlases and the confounding effects of\nsite and phenotype variability. To address these challenges, we propose a\ntwo-stage Brain-to-Population Graph Learning (B2P-GL) framework that integrates\nthe semantic similarity of brain regions and condition-based population graph\nmodeling. In the first stage, termed brain representation learning, we leverage\nbrain atlas knowledge from GPT-4 to enrich the graph representation and refine\nthe brain graph through an adaptive node reassignment graph attention network.\nIn the second stage, termed population disorder diagnosis, phenotypic data is\nincorporated into population graph construction and feature fusion to mitigate\nconfounding effects and enhance diagnosis performance. Experiments on the ABIDE\nI, ADHD-200, and Rest-meta-MDD datasets show that B2P-GL outperforms\nstate-of-the-art methods in prediction accuracy while enhancing\ninterpretability. Overall, our proposed framework offers a reliable and\npersonalized approach to brain disorder diagnosis, advancing clinical\napplicability.", "AI": {"tldr": "A two-stage framework (B2P-GL) improves brain disorder diagnosis by integrating brain region similarity and population graph modeling, outperforming existing methods.", "motivation": "Existing graph-based methods rely on predefined brain atlases but ignore embedded information and confounding effects of site/phenotype variability.", "method": "B2P-GL uses GPT-4 for brain representation learning and phenotypic data for population graph modeling to refine diagnosis.", "result": "B2P-GL achieves higher prediction accuracy on ABIDE I, ADHD-200, and Rest-meta-MDD datasets compared to state-of-the-art methods.", "conclusion": "The framework provides a reliable, personalized approach for brain disorder diagnosis, enhancing clinical applicability."}}
{"id": "2506.17090", "pdf": "https://arxiv.org/pdf/2506.17090", "abs": "https://arxiv.org/abs/2506.17090", "authors": ["Murtaza Nazir", "Matthew Finlayson", "John X. Morris", "Xiang Ren", "Swabha Swayamdipta"], "title": "Better Language Model Inversion by Compactly Representing Next-Token Distributions", "categories": ["cs.CL"], "comment": null, "summary": "Language model inversion seeks to recover hidden prompts using only language\nmodel outputs. This capability has implications for security and accountability\nin language model deployments, such as leaking private information from an\nAPI-protected language model's system message. We propose a new method --\nprompt inversion from logprob sequences (PILS) -- that recovers hidden prompts\nby gleaning clues from the model's next-token probabilities over the course of\nmultiple generation steps. Our method is enabled by a key insight: The\nvector-valued outputs of a language model occupy a low-dimensional subspace.\nThis enables us to losslessly compress the full next-token probability\ndistribution over multiple generation steps using a linear map, allowing more\noutput information to be used for inversion. Our approach yields massive gains\nover previous state-of-the-art methods for recovering hidden prompts, achieving\n2--3.5 times higher exact recovery rates across test sets, in one case\nincreasing the recovery rate from 17% to 60%. Our method also exhibits\nsurprisingly good generalization behavior; for instance, an inverter trained on\n16 generations steps gets 5--27 points higher prompt recovery when we increase\nthe number of steps to 32 at test time. Furthermore, we demonstrate strong\nperformance of our method on the more challenging task of recovering hidden\nsystem messages. We also analyze the role of verbatim repetition in prompt\nrecovery and propose a new method for cross-family model transfer for\nlogit-based inverters. Our findings show that next-token probabilities are a\nconsiderably more vulnerable attack surface for inversion attacks than\npreviously known.", "AI": {"tldr": "The paper introduces PILS, a method for recovering hidden prompts from language model outputs using next-token probabilities, achieving significant improvements over prior methods.", "motivation": "The work addresses security and accountability concerns in language model deployments, particularly the risk of leaking private information through hidden prompts.", "method": "PILS leverages low-dimensional subspace properties of language model outputs to compress next-token probabilities, enabling more effective inversion.", "result": "PILS achieves 2--3.5 times higher exact recovery rates than previous methods, with strong generalization and performance on hidden system messages.", "conclusion": "Next-token probabilities are a highly vulnerable attack surface, and PILS demonstrates their potential for inversion attacks."}}
{"id": "2506.16728", "pdf": "https://arxiv.org/pdf/2506.16728", "abs": "https://arxiv.org/abs/2506.16728", "authors": ["Yunhan Ren", "Feng Luo", "Siyu Huang"], "title": "Few-Shot Generalized Category Discovery With Retrieval-Guided Decision Boundary Enhancement", "categories": ["cs.CV"], "comment": "Accepted by ICMR 2025", "summary": "While existing Generalized Category Discovery (GCD) models have achieved\nsignificant success, their performance with limited labeled samples and a small\nnumber of known categories remains largely unexplored. In this work, we\nintroduce the task of Few-shot Generalized Category Discovery (FSGCD), aiming\nto achieve competitive performance in GCD tasks under conditions of known\ninformation scarcity. To tackle this challenge, we propose a decision boundary\nenhancement framework with affinity-based retrieval. Our framework is designed\nto learn the decision boundaries of known categories and transfer these\nboundaries to unknown categories. First, we use a decision boundary\npre-training module to mitigate the overfitting of pre-trained information on\nknown category boundaries and improve the learning of these decision boundaries\nusing labeled samples. Second, we implement a two-stage retrieval-guided\ndecision boundary optimization strategy. Specifically, this strategy further\nenhances the severely limited known boundaries by using affinity-retrieved\npseudo-labeled samples. Then, these refined boundaries are applied to unknown\nclusters via guidance from affinity-based feature retrieval. Experimental\nresults demonstrate that our proposed method outperforms existing methods on\nsix public GCD benchmarks under the FSGCD setting. The codes are available at:\nhttps://github.com/Ryh1218/FSGCD", "AI": {"tldr": "The paper introduces Few-shot Generalized Category Discovery (FSGCD) to address GCD tasks with limited labeled samples and few known categories. A decision boundary enhancement framework with affinity-based retrieval is proposed, outperforming existing methods on six benchmarks.", "motivation": "Existing GCD models lack exploration of performance with limited labeled samples and few known categories. FSGCD aims to address this gap.", "method": "A decision boundary enhancement framework is introduced, featuring pre-training to mitigate overfitting and a two-stage retrieval-guided optimization strategy using affinity-based retrieval.", "result": "The proposed method outperforms existing methods on six public GCD benchmarks under FSGCD settings.", "conclusion": "The framework effectively addresses the challenge of limited labeled data in GCD tasks, demonstrating superior performance."}}
{"id": "2506.15969", "pdf": "https://arxiv.org/pdf/2506.15969", "abs": "https://arxiv.org/abs/2506.15969", "authors": ["Haoyue Zhang", "Hualei Zhang", "Xiaosong Ma", "Jie Zhang", "Song Guo"], "title": "LazyEviction: Lagged KV Eviction with Attention Pattern Observation for Efficient Long Reasoning", "categories": ["cs.LG", "cs.CL"], "comment": null, "summary": "Large Language Models (LLMs) exhibit enhanced reasoning capabilities by\nemploying Chain-of-Thought (CoT). However, the extended reasoning sequences\nintroduce significant GPU memory overhead due to increased key-value (KV) cache\nsize, particularly in tasks requiring long reasoning sequences, such as\nmathematics and programming. Existing KV cache compression methods mitigate\nmemory bottlenecks but struggle in long reasoning tasks. In this paper, we\nanalyze attention patterns in reasoning tasks and reveal a Token Importance\nRecurrence phenomenon: a large proportion of tokens receive renewed attention\nafter multiple decoding steps, which is failed to capture by existing works and\nmay lead to unpredictable eviction on such periodically critical tokens. To\naddress this, we propose LazyEviction, a lagged KV eviction framework designed\nto maintain reasoning performance while reducing KV memory. LazyEviction is an\nObservation Window-based Lagged Eviction Mechanism retaining latent recurring\ntokens by performing lagged evictions across decoding steps, which contains two\nkey components: (1) Recurrence Interval Tracking for capturing temporal\nvariations in token importance, and (2) an Maximum Recurrence Interval-Centric\nEviction Policy that prioritizes eviction based on tokens' recurrence patterns.\nExtensive experiments demonstrate that LazyEviction reduces KV cache size by\n50% while maintaining comparable accuracy on mathematics reasoning datasets,\noutperforming state-of-the-art methods. Our findings highlight the importance\nof preserving recurring tokens, which are critical for maintaining knowledge\ncontinuity in multi-step reasoning tasks.", "AI": {"tldr": "LazyEviction reduces KV cache size by 50% while maintaining accuracy in long reasoning tasks by preserving recurring tokens.", "motivation": "Existing KV cache compression methods struggle with long reasoning tasks, missing the Token Importance Recurrence phenomenon.", "method": "Proposes LazyEviction, a lagged KV eviction framework with Recurrence Interval Tracking and an eviction policy based on recurrence patterns.", "result": "LazyEviction outperforms state-of-the-art methods, reducing KV cache size by 50% without compromising accuracy.", "conclusion": "Preserving recurring tokens is crucial for knowledge continuity in multi-step reasoning tasks."}}
{"id": "2506.16114", "pdf": "https://arxiv.org/pdf/2506.16114", "abs": "https://arxiv.org/abs/2506.16114", "authors": ["Yejing Wang", "Shengyu Zhou", "Jinyu Lu", "Qidong Liu", "Xinhang Li", "Wenlin Zhang", "Feng Li", "Pengjie Wang", "Jian Xu", "Bo Zheng", "Xiangyu Zhao"], "title": "GFlowGR: Fine-tuning Generative Recommendation Frameworks with Generative Flow Networks", "categories": ["cs.IR", "cs.AI"], "comment": null, "summary": "Generative recommendations (GR), which usually include item tokenizers and\ngenerative Large Language Models (LLMs), have demonstrated remarkable success\nacross a wide range of scenarios. The majority of existing research efforts\nprimarily concentrate on developing powerful item tokenizers or advancing LLM\ndecoding strategies to attain superior performance. However, the critical\nfine-tuning step in GR frameworks, which is essential for adapting LLMs to\nrecommendation data, remains largely unexplored. Current approaches\npredominantly rely on either the next-token prediction loss of supervised\nfine-tuning (SFT) or recommendationspecific direct preference optimization\n(DPO) strategies. Both methods ignore the exploration of possible positive\nunobserved samples, which is commonly referred to as the exposure bias problem.\nTo mitigate this problem, this paper treats the GR as a multi-step generation\ntask and constructs a GFlowNets-based fine-tuning framework (GFlowGR). The\nproposed framework integrates collaborative knowledge from traditional\nrecommender systems to create an adaptive trajectory sampler and a\ncomprehensive reward model. Leveraging the diverse generation property of\nGFlowNets, along with sampling and heuristic weighting techniques, GFlowGR\nemerges as a promising approach to mitigate the exposure bias problem.\nExtensive empirical results on two real-world datasets and with two different\nGR backbones highlight the effectiveness and robustness of GFlowGR.", "AI": {"tldr": "The paper introduces GFlowGR, a GFlowNets-based fine-tuning framework for generative recommendations, addressing exposure bias by leveraging collaborative knowledge and diverse generation properties.", "motivation": "Existing generative recommendation frameworks overlook fine-tuning adaptation, relying on methods that ignore unobserved positive samples (exposure bias).", "method": "Proposes GFlowGR, integrating collaborative knowledge for adaptive trajectory sampling and reward modeling, using GFlowNets for diverse generation.", "result": "GFlowGR effectively mitigates exposure bias, demonstrated by robust performance on real-world datasets with different GR backbones.", "conclusion": "GFlowGR is a promising solution for exposure bias in generative recommendations, enhancing performance and adaptability."}}
{"id": "2506.17121", "pdf": "https://arxiv.org/pdf/2506.17121", "abs": "https://arxiv.org/abs/2506.17121", "authors": ["Adithya Bhaskar", "Alexander Wettig", "Tianyu Gao", "Yihe Dong", "Danqi Chen"], "title": "Cache Me If You Can: How Many KVs Do You Need for Effective Long-Context LMs?", "categories": ["cs.CL"], "comment": "We release our code publicly at\n  https://github.com/princeton-pli/PruLong", "summary": "Language models handle increasingly long contexts for tasks such as book\nsummarization, but this leads to growing memory costs for the key-value (KV)\ncache. Many prior works have proposed ways of discarding KVs from memory, but\ntheir approaches are tailored to favorable settings, obscuring caveats like\nhigh peak memory and performance degradation, and a fair comparison between\nmethods is difficult. In this paper, we propose the *KV footprint* as a unified\nmetric, which accounts for both the amount of KV entries stored and their\nlifespan in memory. We evaluate methods based on the smallest footprint they\nattain while preserving performance in both long-context understanding and\ngeneration, with context lengths of up to 128K tokens. This metric reveals the\nhigh peak memory of prior KV eviction methods. One class of methods --\n*post-fill eviction* -- has a high footprint due to being incompatible with\neviction during pre-filling. We adapt these methods to be able to evict KVs\nduring pre-filling, achieving substantially lower KV footprints. We then turn\nto *recency eviction* methods, wherein we propose PruLong, an end-to-end\noptimization method for learning which attention heads need to retain the full\nKV cache and which do not. PruLong saves memory while preserving long-context\nperformance, achieving 12% smaller KV footprint than prior methods while\nretaining performance in challenging recall tasks. Our paper clarifies the\ncomplex tangle of long-context inference methods and paves the way for future\ndevelopment to minimize the KV footprint.", "AI": {"tldr": "The paper introduces the *KV footprint* metric to evaluate memory efficiency in language models, highlights flaws in prior KV eviction methods, and proposes improved techniques like *post-fill eviction* adaptation and *PruLong* for better performance and lower memory usage.", "motivation": "Addressing the growing memory costs of KV caches in long-context language models, and the lack of a fair comparison between existing KV eviction methods.", "method": "Proposes *KV footprint* as a unified metric, adapts *post-fill eviction* methods for pre-filling, and introduces *PruLong* for optimized KV cache management.", "result": "Reveals high peak memory in prior methods; adapted *post-fill eviction* and *PruLong* achieve lower KV footprints (12% improvement) while maintaining performance.", "conclusion": "The paper provides clarity on long-context inference methods and advances techniques to minimize KV footprint, paving the way for future improvements."}}
{"id": "2506.16730", "pdf": "https://arxiv.org/pdf/2506.16730", "abs": "https://arxiv.org/abs/2506.16730", "authors": ["Mingrui Zhu", "Xiru Chen", "Xin Wei", "Nannan Wang", "Xinbo Gao"], "title": "TeSG: Textual Semantic Guidance for Infrared and Visible Image Fusion", "categories": ["cs.CV"], "comment": "11 pages, 6 figures", "summary": "Infrared and visible image fusion (IVF) aims to combine complementary\ninformation from both image modalities, producing more informative and\ncomprehensive outputs. Recently, text-guided IVF has shown great potential due\nto its flexibility and versatility. However, the effective integration and\nutilization of textual semantic information remains insufficiently studied. To\ntackle these challenges, we introduce textual semantics at two levels: the mask\nsemantic level and the text semantic level, both derived from textual\ndescriptions extracted by large Vision-Language Models (VLMs). Building on\nthis, we propose Textual Semantic Guidance for infrared and visible image\nfusion, termed TeSG, which guides the image synthesis process in a way that is\noptimized for downstream tasks such as detection and segmentation.\nSpecifically, TeSG consists of three core components: a Semantic Information\nGenerator (SIG), a Mask-Guided Cross-Attention (MGCA) module, and a Text-Driven\nAttentional Fusion (TDAF) module. The SIG generates mask and text semantics\nbased on textual descriptions. The MGCA module performs initial attention-based\nfusion of visual features from both infrared and visible images, guided by mask\nsemantics. Finally, the TDAF module refines the fusion process with gated\nattention driven by text semantics. Extensive experiments demonstrate the\ncompetitiveness of our approach, particularly in terms of performance on\ndownstream tasks, compared to existing state-of-the-art methods.", "AI": {"tldr": "The paper introduces TeSG, a method for text-guided infrared and visible image fusion (IVF), leveraging textual semantics from Vision-Language Models to enhance fusion for downstream tasks.", "motivation": "Existing text-guided IVF lacks effective integration of textual semantic information, limiting its utility for tasks like detection and segmentation.", "method": "TeSG uses a Semantic Information Generator (SIG) to derive mask and text semantics, followed by Mask-Guided Cross-Attention (MGCA) and Text-Driven Attentional Fusion (TDAF) modules for guided fusion.", "result": "TeSG outperforms state-of-the-art methods, especially in downstream task performance.", "conclusion": "TeSG effectively integrates textual semantics into IVF, improving fusion quality and downstream task applicability."}}
{"id": "2506.16009", "pdf": "https://arxiv.org/pdf/2506.16009", "abs": "https://arxiv.org/abs/2506.16009", "authors": ["Hamdi Altaheri", "Fakhri Karray", "Md. Milon Islam", "S M Taslim Uddin Raju", "Amir-Hossein Karimi"], "title": "Bridging Brain with Foundation Models through Self-Supervised Learning", "categories": ["cs.LG"], "comment": null, "summary": "Foundation models (FMs), powered by self-supervised learning (SSL), have\nredefined the capabilities of artificial intelligence, demonstrating\nexceptional performance in domains like natural language processing and\ncomputer vision. These advances present a transformative opportunity for brain\nsignal analysis. Unlike traditional supervised learning, which is limited by\nthe scarcity of labeled neural data, SSL offers a promising solution by\nenabling models to learn meaningful representations from unlabeled data. This\nis particularly valuable in addressing the unique challenges of brain signals,\nincluding high noise levels, inter-subject variability, and low signal-to-noise\nratios. This survey systematically reviews the emerging field of bridging brain\nsignals with foundation models through the innovative application of SSL. It\nexplores key SSL techniques, the development of brain-specific foundation\nmodels, their adaptation to downstream tasks, and the integration of brain\nsignals with other modalities in multimodal SSL frameworks. The review also\ncovers commonly used evaluation metrics and benchmark datasets that support\ncomparative analysis. Finally, it highlights key challenges and outlines future\nresearch directions. This work aims to provide researchers with a structured\nunderstanding of this rapidly evolving field and a roadmap for developing\ngeneralizable brain foundation models powered by self-supervision.", "AI": {"tldr": "A survey on using foundation models (FMs) and self-supervised learning (SSL) for brain signal analysis, addressing challenges like noise and variability, and exploring techniques, adaptations, and future directions.", "motivation": "Traditional supervised learning is limited by scarce labeled neural data, while SSL can learn from unlabeled data, making it promising for brain signal analysis.", "method": "Systematic review of SSL techniques, brain-specific FMs, downstream task adaptation, multimodal SSL frameworks, and evaluation metrics.", "result": "Identifies key challenges and opportunities in applying SSL to brain signals, providing a roadmap for future research.", "conclusion": "The survey offers a structured understanding and future directions for developing generalizable brain FMs using SSL."}}
{"id": "2506.16150", "pdf": "https://arxiv.org/pdf/2506.16150", "abs": "https://arxiv.org/abs/2506.16150", "authors": ["Xinyi Wu", "Geng Hong", "Pei Chen", "Yueyue Chen", "Xudong Pan", "Min Yang"], "title": "PRISON: Unmasking the Criminal Potential of Large Language Models", "categories": ["cs.CR", "cs.AI", "cs.CL"], "comment": null, "summary": "As large language models (LLMs) advance, concerns about their misconduct in\ncomplex social contexts intensify. Existing research overlooked the systematic\nunderstanding and assessment of their criminal capability in realistic\ninteractions. We propose a unified framework PRISON, to quantify LLMs' criminal\npotential across five dimensions: False Statements, Frame-Up, Psychological\nManipulation, Emotional Disguise, and Moral Disengagement. Using structured\ncrime scenarios adapted from classic films, we evaluate both criminal potential\nand anti-crime ability of LLMs via role-play. Results show that\nstate-of-the-art LLMs frequently exhibit emergent criminal tendencies, such as\nproposing misleading statements or evasion tactics, even without explicit\ninstructions. Moreover, when placed in a detective role, models recognize\ndeceptive behavior with only 41% accuracy on average, revealing a striking\nmismatch between conducting and detecting criminal behavior. These findings\nunderscore the urgent need for adversarial robustness, behavioral alignment,\nand safety mechanisms before broader LLM deployment.", "AI": {"tldr": "PRISON framework assesses LLMs' criminal potential in five dimensions, revealing emergent criminal tendencies and poor detection accuracy, highlighting safety concerns.", "motivation": "Addressing the overlooked systematic understanding of LLMs' criminal capabilities in realistic social interactions.", "method": "Proposes PRISON framework, using structured crime scenarios from films to evaluate criminal potential and anti-crime ability via role-play.", "result": "LLMs show emergent criminal tendencies (e.g., misleading statements) and only 41% accuracy in detecting deceptive behavior.", "conclusion": "Urgent need for adversarial robustness, behavioral alignment, and safety mechanisms in LLM deployment."}}
{"id": "2506.17180", "pdf": "https://arxiv.org/pdf/2506.17180", "abs": "https://arxiv.org/abs/2506.17180", "authors": ["Naiming Liu", "Richard Baraniuk", "Shashank Sonkar"], "title": "CLEAR-3K: Assessing Causal Explanatory Capabilities in Language Models", "categories": ["cs.CL"], "comment": null, "summary": "We introduce CLEAR-3K, a dataset of 3,000 assertion-reasoning questions\ndesigned to evaluate whether language models can determine if one statement\ncausally explains another. Each question present an assertion-reason pair and\nchallenge language models to distinguish between semantic relatedness and\ngenuine causal explanatory relationships. Through comprehensive evaluation of\n21 state-of-the-art language models (ranging from 0.5B to 72B parameters), we\nidentify two fundamental findings. First, language models frequently confuse\nsemantic similarity with causality, relying on lexical and semantic overlap\ninstead of inferring actual causal explanatory relationships. Second, as\nparameter size increases, models tend to shift from being overly skeptical\nabout causal relationships to being excessively permissive in accepting them.\nDespite this shift, performance measured by the Matthews Correlation\nCoefficient plateaus at just 0.55, even for the best-performing models.Hence,\nCLEAR-3K provides a crucial benchmark for developing and evaluating genuine\ncausal reasoning in language models, which is an essential capability for\napplications that require accurate assessment of causal relationships.", "AI": {"tldr": "CLEAR-3K is a dataset for testing causal reasoning in language models, revealing their tendency to confuse semantic similarity with causality and showing limited performance even in larger models.", "motivation": "To evaluate whether language models can distinguish genuine causal relationships from mere semantic relatedness.", "method": "A dataset of 3,000 assertion-reasoning questions (CLEAR-3K) was used to test 21 state-of-the-art language models of varying sizes.", "result": "Models often confuse semantic similarity with causality, and performance plateaus at a Matthews Correlation Coefficient of 0.55, even for the largest models.", "conclusion": "CLEAR-3K serves as a benchmark for improving causal reasoning in language models, a critical capability for applications requiring accurate causal assessment."}}
{"id": "2506.16737", "pdf": "https://arxiv.org/pdf/2506.16737", "abs": "https://arxiv.org/abs/2506.16737", "authors": ["Liu Zongzhen", "Luo Hui", "Wang Zhixing", "Wei Yuxing", "Zuo Haorui", "Zhang Jianlin"], "title": "Cross-modal Offset-guided Dynamic Alignment and Fusion for Weakly Aligned UAV Object Detection", "categories": ["cs.CV"], "comment": null, "summary": "Unmanned aerial vehicle (UAV) object detection plays a vital role in\napplications such as environmental monitoring and urban security. To improve\nrobustness, recent studies have explored multimodal detection by fusing visible\n(RGB) and infrared (IR) imagery. However, due to UAV platform motion and\nasynchronous imaging, spatial misalignment frequently occurs between\nmodalities, leading to weak alignment. This introduces two major challenges:\nsemantic inconsistency at corresponding spatial locations and modality conflict\nduring feature fusion. Existing methods often address these issues in\nisolation, limiting their effectiveness. In this paper, we propose Cross-modal\nOffset-guided Dynamic Alignment and Fusion (CoDAF), a unified framework that\njointly tackles both challenges in weakly aligned UAV-based object detection.\nCoDAF comprises two novel modules: the Offset-guided Semantic Alignment (OSA),\nwhich estimates attention-based spatial offsets and uses deformable convolution\nguided by a shared semantic space to align features more precisely; and the\nDynamic Attention-guided Fusion Module (DAFM), which adaptively balances\nmodality contributions through gating and refines fused features via\nspatial-channel dual attention. By integrating alignment and fusion in a\nunified design, CoDAF enables robust UAV object detection. Experiments on\nstandard benchmarks validate the effectiveness of our approach, with CoDAF\nachieving a mAP of 78.6% on the DroneVehicle dataset.", "AI": {"tldr": "CoDAF is a unified framework for weakly aligned UAV object detection, addressing semantic inconsistency and modality conflict through offset-guided alignment and dynamic fusion.", "motivation": "Improving robustness in UAV object detection by tackling spatial misalignment and modality conflict in multimodal (RGB-IR) imagery.", "method": "Proposes CoDAF with two modules: OSA for semantic alignment using deformable convolution and DAFM for adaptive fusion via gating and dual attention.", "result": "Achieves 78.6% mAP on the DroneVehicle dataset, outperforming existing methods.", "conclusion": "CoDAF effectively integrates alignment and fusion, enhancing UAV object detection performance."}}
{"id": "2506.16032", "pdf": "https://arxiv.org/pdf/2506.16032", "abs": "https://arxiv.org/abs/2506.16032", "authors": ["Zhen Qin", "Michael B. Wakin", "Zhihui Zhu"], "title": "A Scalable Factorization Approach for High-Order Structured Tensor Recovery", "categories": ["cs.LG", "eess.SP", "math.OC"], "comment": null, "summary": "Tensor decompositions, which represent an $N$-order tensor using\napproximately $N$ factors of much smaller dimensions, can significantly reduce\nthe number of parameters. This is particularly beneficial for high-order\ntensors, as the number of entries in a tensor grows exponentially with the\norder. Consequently, they are widely used in signal recovery and data analysis\nacross domains such as signal processing, machine learning, and quantum\nphysics. A computationally and memory-efficient approach to these problems is\nto optimize directly over the factors using local search algorithms such as\ngradient descent, a strategy known as the factorization approach in matrix and\ntensor optimization. However, the resulting optimization problems are highly\nnonconvex due to the multiplicative interactions between factors, posing\nsignificant challenges for convergence analysis and recovery guarantees.\n  In this paper, we present a unified framework for the factorization approach\nto solving various tensor decomposition problems. Specifically, by leveraging\nthe canonical form of tensor decompositions--where most factors are constrained\nto be orthonormal to mitigate scaling ambiguity--we apply Riemannian gradient\ndescent (RGD) to optimize these orthonormal factors on the Stiefel manifold.\nUnder a mild condition on the loss function, we establish a Riemannian\nregularity condition for the factorized objective and prove that RGD converges\nto the ground-truth tensor at a linear rate when properly initialized. Notably,\nboth the initialization requirement and the convergence rate scale polynomially\nrather than exponentially with $N$, improving upon existing results for Tucker\nand tensor-train format tensors.", "AI": {"tldr": "A unified framework for tensor decomposition using Riemannian gradient descent (RGD) on the Stiefel manifold, achieving linear convergence to ground-truth with polynomial scaling in tensor order.", "motivation": "Tensor decompositions reduce parameters for high-order tensors but face nonconvex optimization challenges. This work aims to provide a scalable and efficient solution.", "method": "Leverages canonical tensor decomposition forms with orthonormal factors, applying RGD on the Stiefel manifold under mild loss function conditions.", "result": "Proves RGD converges linearly to ground-truth tensors with polynomial scaling in tensor order, improving upon Tucker and tensor-train formats.", "conclusion": "The framework offers efficient, scalable tensor decomposition with strong theoretical guarantees, advancing applications in signal processing, machine learning, and quantum physics."}}
{"id": "2506.16168", "pdf": "https://arxiv.org/pdf/2506.16168", "abs": "https://arxiv.org/abs/2506.16168", "authors": ["Thomas Barbera", "Jacopo Burger", "Alessandro D'Amelio", "Simone Zini", "Simone Bianco", "Raffaella Lanzarotti", "Paolo Napoletano", "Giuseppe Boccignone", "Jose Luis Contreras-Vidal"], "title": "On using AI for EEG-based BCI applications: problems, current challenges and future trends", "categories": ["cs.HC", "cs.AI"], "comment": null, "summary": "Imagine unlocking the power of the mind to communicate, create, and even\ninteract with the world around us. Recent breakthroughs in Artificial\nIntelligence (AI), especially in how machines \"see\" and \"understand\" language,\nare now fueling exciting progress in decoding brain signals from scalp\nelectroencephalography (EEG). Prima facie, this opens the door to revolutionary\nbrain-computer interfaces (BCIs) designed for real life, moving beyond\ntraditional uses to envision Brain-to-Speech, Brain-to-Image, and even a\nBrain-to-Internet of Things (BCIoT).\n  However, the journey is not as straightforward as it was for Computer Vision\n(CV) and Natural Language Processing (NLP). Applying AI to real-world EEG-based\nBCIs, particularly in building powerful foundational models, presents unique\nand intricate hurdles that could affect their reliability.\n  Here, we unfold a guided exploration of this dynamic and rapidly evolving\nresearch area. Rather than barely outlining a map of current endeavors and\nresults, the goal is to provide a principled navigation of this hot and\ncutting-edge research landscape. We consider the basic paradigms that emerge\nfrom a causal perspective and the attendant challenges presented to AI-based\nmodels. Looking ahead, we then discuss promising research avenues that could\novercome today's technological, methodological, and ethical limitations. Our\naim is to lay out a clear roadmap for creating truly practical and effective\nEEG-based BCI solutions that can thrive in everyday environments.", "AI": {"tldr": "The paper explores AI-driven EEG-based BCIs, highlighting challenges and future directions for practical applications.", "motivation": "To advance brain-computer interfaces (BCIs) by leveraging AI for real-world EEG signal decoding, moving beyond traditional uses.", "method": "A guided exploration of current research, focusing on causal paradigms and AI-based model challenges.", "result": "Identifies hurdles in reliability and outlines promising research avenues to overcome technological and ethical limitations.", "conclusion": "Proposes a roadmap for developing practical EEG-based BCI solutions for everyday use."}}
{"id": "2506.17188", "pdf": "https://arxiv.org/pdf/2506.17188", "abs": "https://arxiv.org/abs/2506.17188", "authors": ["Yuchen Li", "Hengyi Cai", "Rui Kong", "Xinran Chen", "Jiamin Chen", "Jun Yang", "Haojie Zhang", "Jiayi Li", "Jiayi Wu", "Yiqun Chen", "Changle Qu", "Keyi Kong", "Wenwen Ye", "Lixin Su", "Xinyu Ma", "Long Xia", "Daiting Shi", "Jiashu Zhao", "Haoyi Xiong", "Shuaiqiang Wang", "Dawei Yin"], "title": "Towards AI Search Paradigm", "categories": ["cs.CL", "cs.AI", "cs.IR"], "comment": null, "summary": "In this paper, we introduce the AI Search Paradigm, a comprehensive blueprint\nfor next-generation search systems capable of emulating human information\nprocessing and decision-making. The paradigm employs a modular architecture of\nfour LLM-powered agents (Master, Planner, Executor and Writer) that dynamically\nadapt to the full spectrum of information needs, from simple factual queries to\ncomplex multi-stage reasoning tasks. These agents collaborate dynamically\nthrough coordinated workflows to evaluate query complexity, decompose problems\ninto executable plans, and orchestrate tool usage, task execution, and content\nsynthesis. We systematically present key methodologies for realizing this\nparadigm, including task planning and tool integration, execution strategies,\naligned and robust retrieval-augmented generation, and efficient LLM inference,\nspanning both algorithmic techniques and infrastructure-level optimizations. By\nproviding an in-depth guide to these foundational components, this work aims to\ninform the development of trustworthy, adaptive, and scalable AI search\nsystems.", "AI": {"tldr": "The paper introduces the AI Search Paradigm, a modular system using four LLM-powered agents to handle diverse information needs through dynamic collaboration and workflows.", "motivation": "To create next-generation search systems that emulate human information processing and decision-making, addressing a wide range of query complexities.", "method": "Employs a modular architecture with four LLM-powered agents (Master, Planner, Executor, Writer) for task planning, tool integration, execution strategies, and content synthesis.", "result": "A comprehensive blueprint for adaptive, scalable, and trustworthy AI search systems, with methodologies for robust retrieval-augmented generation and efficient LLM inference.", "conclusion": "The work provides foundational guidance for developing advanced AI search systems capable of dynamic adaptation and scalability."}}
{"id": "2506.16742", "pdf": "https://arxiv.org/pdf/2506.16742", "abs": "https://arxiv.org/abs/2506.16742", "authors": ["Md Nahiduzzaman", "Ruwan Tennakoon", "Steven Korevaar", "Zongyuan Ge", "Alireza Bab-Hadiashar"], "title": "Uncertainty-Aware Variational Information Pursuit for Interpretable Medical Image Analysis", "categories": ["cs.CV"], "comment": null, "summary": "In medical imaging, AI decision-support systems must balance accuracy and\ninterpretability to build user trust and support effective clinical\ndecision-making. Recently, Variational Information Pursuit (V-IP) and its\nvariants have emerged as interpretable-by-design modeling techniques, aiming to\nexplain AI decisions in terms of human-understandable, clinically relevant\nconcepts. However, existing V-IP methods overlook instance-level uncertainties\nin query-answer generation, which can arise from model limitations (epistemic\nuncertainty) or variability in expert responses (aleatoric uncertainty).\n  This paper introduces Uncertainty-Aware V-IP (UAV-IP), a novel framework that\nintegrates uncertainty quantification into the V-IP process. We evaluate UAV-IP\nacross four medical imaging datasets, PH2, Derm7pt, BrEaST, and SkinCon,\ndemonstrating an average AUC improvement of approximately 3.2% while generating\n20% more concise explanations compared to baseline V-IP, without sacrificing\ninformativeness. These findings highlight the importance of uncertainty-aware\nreasoning in interpretable by design models for robust and reliable medical\ndecision-making.", "AI": {"tldr": "UAV-IP improves V-IP by integrating uncertainty quantification, boosting AUC by 3.2% and generating 20% more concise explanations without losing informativeness.", "motivation": "Existing V-IP methods ignore instance-level uncertainties, which can undermine trust and reliability in AI-driven medical decision-making.", "method": "Introduces Uncertainty-Aware V-IP (UAV-IP), a framework that quantifies epistemic and aleatoric uncertainties in query-answer generation.", "result": "Tested on four datasets (PH2, Derm7pt, BrEaST, SkinCon), UAV-IP achieves a 3.2% higher AUC and 20% more concise explanations than baseline V-IP.", "conclusion": "Uncertainty-aware reasoning enhances interpretable AI models, making them more robust and reliable for medical applications."}}
{"id": "2506.16051", "pdf": "https://arxiv.org/pdf/2506.16051", "abs": "https://arxiv.org/abs/2506.16051", "authors": ["Zhiwei Li", "Carl Kesselman", "Tran Huy Nguyen", "Benjamin Yixing Xu", "Kyle Bolo", "Kimberley Yu"], "title": "From Data to Decision: Data-Centric Infrastructure for Reproducible ML in Collaborative eScience", "categories": ["cs.LG", "cs.DB", "cs.DL", "cs.HC"], "comment": null, "summary": "Reproducibility remains a central challenge in machine learning (ML),\nespecially in collaborative eScience projects where teams iterate over data,\nfeatures, and models. Current ML workflows are often dynamic yet fragmented,\nrelying on informal data sharing, ad hoc scripts, and loosely connected tools.\nThis fragmentation impedes transparency, reproducibility, and the adaptability\nof experiments over time. This paper introduces a data-centric framework for\nlifecycle-aware reproducibility, centered around six structured artifacts:\nDataset, Feature, Workflow, Execution, Asset, and Controlled Vocabulary. These\nartifacts formalize the relationships between data, code, and decisions,\nenabling ML experiments to be versioned, interpretable, and traceable over\ntime. The approach is demonstrated through a clinical ML use case of glaucoma\ndetection, illustrating how the system supports iterative exploration, improves\nreproducibility, and preserves the provenance of collaborative decisions across\nthe ML lifecycle.", "AI": {"tldr": "A framework for lifecycle-aware reproducibility in ML, using six structured artifacts to improve transparency and traceability in collaborative projects.", "motivation": "Addressing the challenge of reproducibility in ML, especially in dynamic, collaborative eScience projects with fragmented workflows.", "method": "Introduces a data-centric framework with six artifacts (Dataset, Feature, Workflow, Execution, Asset, Controlled Vocabulary) to formalize relationships between data, code, and decisions.", "result": "Demonstrated in a clinical ML use case (glaucoma detection), showing improved reproducibility, iterative exploration, and provenance tracking.", "conclusion": "The framework enhances reproducibility and adaptability in ML workflows by formalizing and versioning artifacts."}}
{"id": "2506.16170", "pdf": "https://arxiv.org/pdf/2506.16170", "abs": "https://arxiv.org/abs/2506.16170", "authors": ["Simardeep Singh"], "title": "From Teacher to Student: Tracking Memorization Through Model Distillation", "categories": ["cs.LG", "cs.AI"], "comment": "5 pages, in-proceedings L2M2 @ ACL 2025", "summary": "Large language models (LLMs) are known to memorize parts of their training\ndata, raising important concerns around privacy and security. While previous\nresearch has focused on studying memorization in pre-trained models, much less\nis known about how knowledge distillation (KD) affects memorization.In this\nstudy, we explore how different KD methods influence the memorization of\nfine-tuned task data when a large teacher model is distilled into smaller\nstudent variants.This study demonstrates that distilling a larger teacher\nmodel, fine-tuned on a dataset, into a smaller variant not only lowers\ncomputational costs and model size but also significantly reduces the\nmemorization risks compared to standard fine-tuning approaches.", "AI": {"tldr": "This study examines how knowledge distillation (KD) from a large teacher model to smaller student variants affects memorization of fine-tuned task data, showing KD reduces memorization risks compared to standard fine-tuning.", "motivation": "Address privacy and security concerns by understanding how KD impacts memorization in LLMs, as previous research focused on pre-trained models.", "method": "Investigate different KD methods when distilling a large teacher model (fine-tuned on a dataset) into smaller student variants.", "result": "KD not only lowers computational costs and model size but also significantly reduces memorization risks.", "conclusion": "KD is a promising approach to mitigate memorization risks while maintaining efficiency in LLMs."}}
{"id": "2506.17209", "pdf": "https://arxiv.org/pdf/2506.17209", "abs": "https://arxiv.org/abs/2506.17209", "authors": ["Kathleen C. Fraser", "Hillary Dawkins", "Isar Nejadgholi", "Svetlana Kiritchenko"], "title": "Fine-Tuning Lowers Safety and Disrupts Evaluation Consistency", "categories": ["cs.CL"], "comment": "to appear at LLMSEC 2025", "summary": "Fine-tuning a general-purpose large language model (LLM) for a specific\ndomain or task has become a routine procedure for ordinary users. However,\nfine-tuning is known to remove the safety alignment features of the model, even\nwhen the fine-tuning data does not contain any harmful content. We consider\nthis to be a critical failure mode of LLMs due to the widespread uptake of\nfine-tuning, combined with the benign nature of the \"attack\". Most\nwell-intentioned developers are likely unaware that they are deploying an LLM\nwith reduced safety. On the other hand, this known vulnerability can be easily\nexploited by malicious actors intending to bypass safety guardrails. To make\nany meaningful progress in mitigating this issue, we first need reliable and\nreproducible safety evaluations. In this work, we investigate how robust a\nsafety benchmark is to trivial variations in the experimental procedure, and\nthe stochastic nature of LLMs. Our initial experiments expose surprising\nvariance in the results of the safety evaluation, even when seemingly\ninconsequential changes are made to the fine-tuning setup. Our observations\nhave serious implications for how researchers in this field should report\nresults to enable meaningful comparisons in the future.", "AI": {"tldr": "Fine-tuning LLMs can unintentionally remove safety features, posing risks. Safety benchmarks show high variance, raising concerns about evaluation reliability.", "motivation": "To address the critical failure mode where fine-tuning LLMs removes safety alignment, even with benign data, and the need for reliable safety evaluations.", "method": "Investigate the robustness of safety benchmarks by testing trivial variations in fine-tuning setups and evaluating the stochastic nature of LLMs.", "result": "High variance in safety evaluation results due to minor changes in fine-tuning, highlighting unreliability.", "conclusion": "Researchers must improve reporting methods for meaningful comparisons and address safety evaluation inconsistencies."}}
{"id": "2506.16743", "pdf": "https://arxiv.org/pdf/2506.16743", "abs": "https://arxiv.org/abs/2506.16743", "authors": ["Weinan Guan", "Wei Wang", "Bo Peng", "Ziwen He", "Jing Dong", "Haonan Cheng"], "title": "Noise-Informed Diffusion-Generated Image Detection with Anomaly Attention", "categories": ["cs.CV"], "comment": "Accepted by TIFS 2025. Our code is availabel at\n  https://github.com/WeinanGuan/NASA-Swin", "summary": "With the rapid development of image generation technologies, especially the\nadvancement of Diffusion Models, the quality of synthesized images has\nsignificantly improved, raising concerns among researchers about information\nsecurity. To mitigate the malicious abuse of diffusion models,\ndiffusion-generated image detection has proven to be an effective\ncountermeasure.However, a key challenge for forgery detection is generalising\nto diffusion models not seen during training. In this paper, we address this\nproblem by focusing on image noise. We observe that images from different\ndiffusion models share similar noise patterns, distinct from genuine images.\nBuilding upon this insight, we introduce a novel Noise-Aware Self-Attention\n(NASA) module that focuses on noise regions to capture anomalous patterns. To\nimplement a SOTA detection model, we incorporate NASA into Swin Transformer,\nforming an novel detection architecture NASA-Swin. Additionally, we employ a\ncross-modality fusion embedding to combine RGB and noise images, along with a\nchannel mask strategy to enhance feature learning from both modalities.\nExtensive experiments demonstrate the effectiveness of our approach in\nenhancing detection capabilities for diffusion-generated images. When\nencountering unseen generation methods, our approach achieves the\nstate-of-the-art performance.Our code is available at\nhttps://github.com/WeinanGuan/NASA-Swin.", "AI": {"tldr": "The paper introduces a Noise-Aware Self-Attention (NASA) module to detect diffusion-generated images by focusing on shared noise patterns, achieving state-of-the-art performance even for unseen models.", "motivation": "The rapid advancement of diffusion models raises security concerns, necessitating robust detection methods that generalize to unseen models.", "method": "Proposes NASA-Swin, integrating NASA into Swin Transformer, using cross-modality fusion (RGB and noise images) and a channel mask strategy.", "result": "Demonstrates superior detection performance, especially for unseen diffusion models.", "conclusion": "The NASA-Swin approach effectively addresses generalization challenges in diffusion-generated image detection."}}
{"id": "2506.16065", "pdf": "https://arxiv.org/pdf/2506.16065", "abs": "https://arxiv.org/abs/2506.16065", "authors": ["Geonho Hwang", "Wonyeol Lee", "Yeachan Park", "Sejun Park", "Feras Saad"], "title": "Floating-Point Neural Networks Are Provably Robust Universal Approximators", "categories": ["cs.LG", "cs.LO", "cs.PL"], "comment": "70 pages, 4 figures. Appearing in CAV 2025", "summary": "The classical universal approximation (UA) theorem for neural networks\nestablishes mild conditions under which a feedforward neural network can\napproximate a continuous function $f$ with arbitrary accuracy. A recent result\nshows that neural networks also enjoy a more general interval universal\napproximation (IUA) theorem, in the sense that the abstract interpretation\nsemantics of the network using the interval domain can approximate the direct\nimage map of $f$ (i.e., the result of applying $f$ to a set of inputs) with\narbitrary accuracy. These theorems, however, rest on the unrealistic assumption\nthat the neural network computes over infinitely precise real numbers, whereas\ntheir software implementations in practice compute over finite-precision\nfloating-point numbers. An open question is whether the IUA theorem still holds\nin the floating-point setting.\n  This paper introduces the first IUA theorem for floating-point neural\nnetworks that proves their remarkable ability to perfectly capture the direct\nimage map of any rounded target function $f$, showing no limits exist on their\nexpressiveness. Our IUA theorem in the floating-point setting exhibits material\ndifferences from the real-valued setting, which reflects the fundamental\ndistinctions between these two computational models. This theorem also implies\nsurprising corollaries, which include (i) the existence of provably robust\nfloating-point neural networks; and (ii) the computational completeness of the\nclass of straight-line programs that use only floating-point additions and\nmultiplications for the class of all floating-point programs that halt.", "AI": {"tldr": "The paper introduces the first interval universal approximation (IUA) theorem for floating-point neural networks, proving their ability to perfectly capture the direct image map of any rounded target function, with surprising corollaries like provably robust networks and computational completeness.", "motivation": "The motivation is to address the gap between theoretical UA/IUA theorems (assuming infinite precision) and practical implementations (using finite-precision floating-point numbers), exploring whether IUA holds in the floating-point setting.", "method": "The paper introduces a novel IUA theorem specifically for floating-point neural networks, analyzing their expressiveness and differences from the real-valued setting.", "result": "The result shows that floating-point neural networks can perfectly approximate the direct image map of any rounded target function, with additional corollaries like provable robustness and computational completeness.", "conclusion": "The conclusion highlights the material differences between real-valued and floating-point settings and the surprising implications of the IUA theorem for floating-point neural networks."}}
{"id": "2506.16189", "pdf": "https://arxiv.org/pdf/2506.16189", "abs": "https://arxiv.org/abs/2506.16189", "authors": ["Putri A. van der Linden", "Alexander Timans", "Erik J. Bekkers"], "title": "CP$^2$: Leveraging Geometry for Conformal Prediction via Canonicalization", "categories": ["stat.ML", "cs.AI", "cs.LG"], "comment": "17 pages, 7 figures, 9 tables (including appendix); published at UAI\n  2025", "summary": "We study the problem of conformal prediction (CP) under geometric data\nshifts, where data samples are susceptible to transformations such as rotations\nor flips. While CP endows prediction models with post-hoc uncertainty\nquantification and formal coverage guarantees, their practicality breaks under\ndistribution shifts that deteriorate model performance. To address this issue,\nwe propose integrating geometric information--such as geometric pose--into the\nconformal procedure to reinstate its guarantees and ensure robustness under\ngeometric shifts. In particular, we explore recent advancements on pose\ncanonicalization as a suitable information extractor for this purpose.\nEvaluating the combined approach across discrete and continuous shifts and\nagainst equivariant and augmentation-based baselines, we find that integrating\ngeometric information with CP yields a principled way to address geometric\nshifts while maintaining broad applicability to black-box predictors.", "AI": {"tldr": "Integrating geometric information into conformal prediction (CP) improves robustness under geometric data shifts like rotations or flips.", "motivation": "CP's practicality breaks under geometric distribution shifts, so the paper aims to restore its guarantees by incorporating geometric data.", "method": "Proposes integrating geometric pose information into CP, using pose canonicalization as an extractor, and evaluates against baselines.", "result": "The combined approach effectively addresses geometric shifts while maintaining broad applicability to black-box predictors.", "conclusion": "Geometric information integration with CP provides a principled solution for robustness under geometric shifts."}}
{"id": "2506.16773", "pdf": "https://arxiv.org/pdf/2506.16773", "abs": "https://arxiv.org/abs/2506.16773", "authors": ["Shuchen Sun", "Ligen Shi", "Chang Liu", "Lina Wu", "Jun Qiu"], "title": "Infrared and Visible Image Fusion Based on Implicit Neural Representations", "categories": ["cs.CV"], "comment": null, "summary": "Infrared and visible light image fusion aims to combine the strengths of both\nmodalities to generate images that are rich in information and fulfill visual\nor computational requirements. This paper proposes an image fusion method based\non Implicit Neural Representations (INR), referred to as INRFuse. This method\nparameterizes a continuous function through a neural network to implicitly\nrepresent the multimodal information of the image, breaking through the\ntraditional reliance on discrete pixels or explicit features. The normalized\nspatial coordinates of the infrared and visible light images serve as inputs,\nand multi-layer perceptrons is utilized to adaptively fuse the features of both\nmodalities, resulting in the output of the fused image. By designing multiple\nloss functions, the method jointly optimizes the similarity between the fused\nimage and the original images, effectively preserving the thermal radiation\ninformation of the infrared image while maintaining the texture details of the\nvisible light image. Furthermore, the resolution-independent characteristic of\nINR allows for the direct fusion of images with varying resolutions and\nachieves super-resolution reconstruction through high-density coordinate\nqueries. Experimental results indicate that INRFuse outperforms existing\nmethods in both subjective visual quality and objective evaluation metrics,\nproducing fused images with clear structures, natural details, and rich\ninformation without the necessity for a training dataset.", "AI": {"tldr": "The paper introduces INRFuse, an image fusion method using Implicit Neural Representations (INR) to combine infrared and visible light images, achieving superior results without needing a training dataset.", "motivation": "To create fused images that retain thermal radiation from infrared and texture details from visible light, overcoming limitations of traditional pixel-based methods.", "method": "Uses INR to parameterize a continuous function via neural networks, fusing features adaptively with multi-layer perceptrons and optimizing through multiple loss functions.", "result": "INRFuse outperforms existing methods in visual quality and metrics, producing clear, natural, and information-rich fused images.", "conclusion": "INRFuse is effective for multimodal image fusion, offering resolution independence and super-resolution capabilities without training data."}}
{"id": "2506.16072", "pdf": "https://arxiv.org/pdf/2506.16072", "abs": "https://arxiv.org/abs/2506.16072", "authors": ["Kexuan Wang", "An Liu"], "title": "A Lightweight RL-Driven Deep Unfolding Network for Robust WMMSE Precoding in Massive MU-MIMO-OFDM Systems", "categories": ["cs.LG"], "comment": null, "summary": "Weighted Minimum Mean Square Error (WMMSE) precoding is widely recognized for\nits near-optimal weighted sum rate performance. However, its practical\ndeployment in massive multi-user (MU) multiple-input multiple-output (MIMO)\northogonal frequency-division multiplexing (OFDM) systems is hindered by the\nassumption of perfect channel state information (CSI) and high computational\ncomplexity. To address these issues, we first develop a wideband stochastic\nWMMSE (SWMMSE) algorithm that iteratively maximizes the ergodic weighted\nsum-rate (EWSR) under imperfect CSI. Building on this, we propose a lightweight\nreinforcement learning (RL)-driven deep unfolding (DU) network (RLDDU-Net),\nwhere each SWMMSE iteration is mapped to a network layer. Specifically, its DU\nmodule integrates approximation techniques and leverages beam-domain sparsity\nas well as frequency-domain subcarrier correlation, significantly accelerating\nconvergence and reducing computational overhead. Furthermore, the RL module\nadaptively adjusts the network depth and generates compensation matrices to\nmitigate approximation errors. Simulation results under imperfect CSI\ndemonstrate that RLDDU-Net outperforms existing baselines in EWSR performance\nwhile offering superior computational and convergence efficiency.", "AI": {"tldr": "The paper proposes a lightweight RL-driven deep unfolding network (RLDDU-Net) to improve the WMMSE precoding algorithm for massive MU-MIMO OFDM systems under imperfect CSI, achieving better performance and efficiency.", "motivation": "Practical deployment of WMMSE precoding in massive MU-MIMO OFDM systems is limited by perfect CSI assumptions and high computational complexity.", "method": "Develops a wideband stochastic WMMSE (SWMMSE) algorithm and integrates it into RLDDU-Net, which uses deep unfolding and RL to optimize performance.", "result": "RLDDU-Net outperforms baselines in ergodic weighted sum-rate (EWSR) performance under imperfect CSI, with improved computational and convergence efficiency.", "conclusion": "The proposed RLDDU-Net effectively addresses the limitations of WMMSE precoding, offering a practical solution for massive MU-MIMO OFDM systems."}}
{"id": "2506.16243", "pdf": "https://arxiv.org/pdf/2506.16243", "abs": "https://arxiv.org/abs/2506.16243", "authors": ["Abdulvahap Mutlu", "\u015eeng\u00fcl Do\u011fan", "T\u00fcrker Tuncer"], "title": "Synthetic ALS-EEG Data Augmentation for ALS Diagnosis Using Conditional WGAN with Weight Clipping", "categories": ["cs.LG", "cs.AI"], "comment": "The code is available on GitHub:\n  https://github.com/abdulvahapmutlu/als-synthetic-data-augmentation-wgan", "summary": "Amyotrophic Lateral Sclerosis (ALS) is a rare neurodegenerative disease, and\nhigh-quality EEG data from ALS patients are scarce. This data scarcity, coupled\nwith severe class imbalance between ALS and healthy control recordings, poses a\nchallenge for training reliable machine learning classifiers. In this work, we\naddress these issues by generating synthetic EEG signals for ALS patients using\na Conditional Wasserstein Generative Adversarial Network (CWGAN). We train\nCWGAN on a private EEG dataset (ALS vs. non-ALS) to learn the distribution of\nALS EEG signals and produce realistic synthetic samples. We preprocess and\nnormalize EEG recordings, and train a CWGAN model to generate synthetic ALS\nsignals. The CWGAN architecture and training routine are detailed, with key\nhyperparameters chosen for stable training. Qualitative evaluation of generated\nsignals shows that they closely mimic real ALS EEG patterns. The CWGAN training\nconverged with generator and discriminator loss curves stabilizing, indicating\nsuccessful learning. The synthetic EEG signals appear realistic and have\npotential use as augmented data for training classifiers, helping to mitigate\nclass imbalance and improve ALS detection accuracy. We discuss how this\napproach can facilitate data sharing and enhance diagnostic models.", "AI": {"tldr": "A CWGAN is used to generate synthetic ALS EEG signals to address data scarcity and class imbalance, improving classifier training.", "motivation": "Data scarcity and class imbalance in ALS EEG recordings hinder reliable machine learning classifier training.", "method": "A CWGAN is trained on a private EEG dataset to generate synthetic ALS signals, with detailed preprocessing and hyperparameter tuning.", "result": "Generated signals mimic real ALS EEG patterns, and the CWGAN training converged successfully.", "conclusion": "Synthetic EEG signals can augment training data, mitigate class imbalance, and enhance ALS detection accuracy."}}
{"id": "2506.15975", "pdf": "https://arxiv.org/pdf/2506.15975", "abs": "https://arxiv.org/abs/2506.15975", "authors": ["Zihao Fu", "Chris Russell"], "title": "Multi-use LLM Watermarking and the False Detection Problem", "categories": ["cs.CR", "cs.CL"], "comment": null, "summary": "Digital watermarking is a promising solution for mitigating some of the risks\narising from the misuse of automatically generated text. These approaches\neither embed non-specific watermarks to allow for the detection of any text\ngenerated by a particular sampler, or embed specific keys that allow the\nidentification of the LLM user. However, simultaneously using the same\nembedding for both detection and user identification leads to a false detection\nproblem, whereby, as user capacity grows, unwatermarked text is increasingly\nlikely to be falsely detected as watermarked. Through theoretical analysis, we\nidentify the underlying causes of this phenomenon. Building on these insights,\nwe propose Dual Watermarking which jointly encodes detection and identification\nwatermarks into generated text, significantly reducing false positives while\nmaintaining high detection accuracy. Our experimental results validate our\ntheoretical findings and demonstrate the effectiveness of our approach.", "AI": {"tldr": "Dual Watermarking reduces false positives in detecting watermarked text by separately encoding detection and identification watermarks.", "motivation": "Address the false detection problem in digital watermarking when the same embedding is used for both detection and user identification.", "method": "Propose Dual Watermarking, which jointly encodes detection and identification watermarks.", "result": "Theoretical analysis and experiments show reduced false positives while maintaining high detection accuracy.", "conclusion": "Dual Watermarking effectively mitigates false detection issues in digital watermarking."}}
{"id": "2506.16776", "pdf": "https://arxiv.org/pdf/2506.16776", "abs": "https://arxiv.org/abs/2506.16776", "authors": ["Beomseok Ko", "Hyeryung Jang"], "title": "PQCAD-DM: Progressive Quantization and Calibration-Assisted Distillation for Extremely Efficient Diffusion Model", "categories": ["cs.CV", "cs.AI"], "comment": "10 pages, 6 figures", "summary": "Diffusion models excel in image generation but are computational and\nresource-intensive due to their reliance on iterative Markov chain processes,\nleading to error accumulation and limiting the effectiveness of naive\ncompression techniques. In this paper, we propose PQCAD-DM, a novel hybrid\ncompression framework combining Progressive Quantization (PQ) and\nCalibration-Assisted Distillation (CAD) to address these challenges. PQ employs\na two-stage quantization with adaptive bit-width transitions guided by a\nmomentum-based mechanism, reducing excessive weight perturbations in\nlow-precision. CAD leverages full-precision calibration datasets during\ndistillation, enabling the student to match full-precision performance even\nwith a quantized teacher. As a result, PQCAD-DM achieves a balance between\ncomputational efficiency and generative quality, halving inference time while\nmaintaining competitive performance. Extensive experiments validate PQCAD-DM's\nsuperior generative capabilities and efficiency across diverse datasets,\noutperforming fixed-bit quantization methods.", "AI": {"tldr": "PQCAD-DM combines Progressive Quantization and Calibration-Assisted Distillation to compress diffusion models efficiently without sacrificing generative quality.", "motivation": "Diffusion models are computationally intensive and suffer from error accumulation, making naive compression ineffective.", "method": "PQCAD-DM uses two-stage quantization (PQ) and calibration-assisted distillation (CAD) to reduce computational load while maintaining performance.", "result": "PQCAD-DM halves inference time while matching full-precision performance, outperforming fixed-bit quantization methods.", "conclusion": "PQCAD-DM offers a balanced solution for efficient and high-quality diffusion model compression."}}
{"id": "2506.16074", "pdf": "https://arxiv.org/pdf/2506.16074", "abs": "https://arxiv.org/abs/2506.16074", "authors": ["Kexuan Wang", "An Liu"], "title": "Joint User Priority and Power Scheduling for QoS-Aware WMMSE Precoding: A Constrained-Actor Attentive-Critic Approach", "categories": ["cs.LG"], "comment": null, "summary": "6G wireless networks are expected to support diverse quality-of-service (QoS)\ndemands while maintaining high energy efficiency. Weighted Minimum Mean Square\nError (WMMSE) precoding with fixed user priorities and transmit power is widely\nrecognized for enhancing overall system performance but lacks flexibility to\nadapt to user-specific QoS requirements and time-varying channel conditions. To\naddress this, we propose a novel constrained reinforcement learning (CRL)\nalgorithm, Constrained-Actor Attentive-Critic (CAAC), which uses a policy\nnetwork to dynamically allocate user priorities and power for WMMSE precoding.\nSpecifically, CAAC integrates a Constrained Stochastic Successive Convex\nApproximation (CSSCA) method to optimize the policy, enabling more effective\nhandling of energy efficiency goals and satisfaction of stochastic non-convex\nQoS constraints compared to traditional and existing CRL methods. Moreover,\nCAAC employs lightweight attention-enhanced Q-networks to evaluate policy\nupdates without prior environment model knowledge. The network architecture not\nonly enhances representational capacity but also boosts learning efficiency.\nSimulation results show that CAAC outperforms baselines in both energy\nefficiency and QoS satisfaction.", "AI": {"tldr": "A novel CRL algorithm, CAAC, dynamically optimizes WMMSE precoding for 6G networks, improving energy efficiency and QoS adaptability.", "motivation": "Traditional WMMSE precoding lacks flexibility for user-specific QoS and dynamic channel conditions.", "method": "Proposes CAAC, integrating CSSCA for policy optimization and attention-enhanced Q-networks for efficient learning.", "result": "CAAC outperforms baselines in energy efficiency and QoS satisfaction.", "conclusion": "CAAC offers a flexible and efficient solution for 6G networks."}}
{"id": "2506.16255", "pdf": "https://arxiv.org/pdf/2506.16255", "abs": "https://arxiv.org/abs/2506.16255", "authors": ["Xingzhong Fan", "Hongming Tang", "Yue Zeng", "M. B. N. Kouwenhoven", "Guangquan Zeng"], "title": "Category-based Galaxy Image Generation via Diffusion Models", "categories": ["astro-ph.IM", "cs.AI"], "comment": "18 pages, 6 figures. Submitted to AAS Astronomical Journal (AJ) and\n  is under revision. See another indenpdent work for furthur reference -- Can\n  AI Dream of Unseen Galaxies? Conditional Diffusion Model for Galaxy\n  Morphology Augmentation (Ma, Sun et al.). Comments are welcome", "summary": "Conventional galaxy generation methods rely on semi-analytical models and\nhydrodynamic simulations, which are highly dependent on physical assumptions\nand parameter tuning. In contrast, data-driven generative models do not have\nexplicit physical parameters pre-determined, and instead learn them efficiently\nfrom observational data, making them alternative solutions to galaxy\ngeneration. Among these, diffusion models outperform Variational Autoencoders\n(VAEs) and Generative Adversarial Networks (GANs) in quality and diversity.\nLeveraging physical prior knowledge to these models can further enhance their\ncapabilities. In this work, we present GalCatDiff, the first framework in\nastronomy to leverage both galaxy image features and astrophysical properties\nin the network design of diffusion models. GalCatDiff incorporates an enhanced\nU-Net and a novel block entitled Astro-RAB (Residual Attention Block), which\ndynamically combines attention mechanisms with convolution operations to ensure\nglobal consistency and local feature fidelity. Moreover, GalCatDiff uses\ncategory embeddings for class-specific galaxy generation, avoiding the high\ncomputational costs of training separate models for each category. Our\nexperimental results demonstrate that GalCatDiff significantly outperforms\nexisting methods in terms of the consistency of sample color and size\ndistributions, and the generated galaxies are both visually realistic and\nphysically consistent. This framework will enhance the reliability of galaxy\nsimulations and can potentially serve as a data augmentor to support future\ngalaxy classification algorithm development.", "AI": {"tldr": "GalCatDiff, a diffusion model framework, outperforms traditional galaxy generation methods by combining image features and astrophysical properties, ensuring realistic and physically consistent results.", "motivation": "Traditional galaxy generation methods depend heavily on physical assumptions and tuning, while data-driven models like GalCatDiff learn from observational data, offering a more efficient alternative.", "method": "GalCatDiff uses an enhanced U-Net and Astro-RAB block to combine attention mechanisms with convolutions, along with category embeddings for class-specific generation.", "result": "GalCatDiff surpasses existing methods in sample consistency and realism, producing galaxies that are visually and physically accurate.", "conclusion": "GalCatDiff enhances galaxy simulation reliability and can support future galaxy classification algorithm development as a data augmentor."}}
{"id": "2506.16412", "pdf": "https://arxiv.org/pdf/2506.16412", "abs": "https://arxiv.org/abs/2506.16412", "authors": ["Paulina DeVito", "Akhil Vallala", "Sean Mcmahon", "Yaroslav Hinda", "Benjamin Thaw", "Hanqi Zhuang", "Hari Kalva"], "title": "Unpacking Generative AI in Education: Computational Modeling of Teacher and Student Perspectives in Social Media Discourse", "categories": ["cs.SI", "cs.CL", "cs.CY"], "comment": "This work has been submitted to IEEE Transactions on Computational\n  Social Systems for possible publication", "summary": "Generative AI (GAI) technologies are quickly reshaping the educational\nlandscape. As adoption accelerates, understanding how students and educators\nperceive these tools is essential. This study presents one of the most\ncomprehensive analyses to date of stakeholder discourse dynamics on GAI in\neducation using social media data. Our dataset includes 1,199 Reddit posts and\n13,959 corresponding top-level comments. We apply sentiment analysis, topic\nmodeling, and author classification. To support this, we propose and validate a\nmodular framework that leverages prompt-based large language models (LLMs) for\nanalysis of online social discourse, and we evaluate this framework against\nclassical natural language processing (NLP) models. Our GPT-4o pipeline\nconsistently outperforms prior approaches across all tasks. For example, it\nachieved 90.6% accuracy in sentiment analysis against gold-standard human\nannotations. Topic extraction uncovered 12 latent topics in the public\ndiscourse with varying sentiment and author distributions. Teachers and\nstudents convey optimism about GAI's potential for personalized learning and\nproductivity in higher education. However, key differences emerged: students\noften voice distress over false accusations of cheating by AI detectors, while\nteachers generally express concern about job security, academic integrity, and\ninstitutional pressures to adopt GAI tools. These contrasting perspectives\nhighlight the tension between innovation and oversight in GAI-enabled learning\nenvironments. Our findings suggest a need for clearer institutional policies,\nmore transparent GAI integration practices, and support mechanisms for both\neducators and students. More broadly, this study demonstrates the potential of\nLLM-based frameworks for modeling stakeholder discourse within online\ncommunities.", "AI": {"tldr": "The study analyzes stakeholder perceptions of Generative AI (GAI) in education using social media data, proposing a modular LLM-based framework that outperforms classical NLP methods. Key findings include contrasting student and teacher concerns, highlighting the need for clearer policies and support.", "motivation": "To understand how students and educators perceive GAI tools in education, given their rapid adoption and transformative potential.", "method": "Analyzed 1,199 Reddit posts and 13,959 comments using sentiment analysis, topic modeling, and author classification. A modular LLM-based framework (GPT-4o) was validated against classical NLP models.", "result": "The LLM framework achieved 90.6% accuracy in sentiment analysis. Topic modeling revealed 12 latent topics with varying sentiments. Students expressed distress over cheating accusations, while teachers worried about job security and academic integrity.", "conclusion": "The study underscores the need for better policies and support in GAI-enabled education. It also demonstrates the effectiveness of LLM-based frameworks for analyzing online discourse."}}
{"id": "2506.16796", "pdf": "https://arxiv.org/pdf/2506.16796", "abs": "https://arxiv.org/abs/2506.16796", "authors": ["Junbo Qiao", "Miaomiao Cai", "Wei Li", "Yutong Liu", "Xudong Huang", "Gaoqi He", "Jiao Xie", "Jie Hu", "Xinghao Chen", "Shaohui Lin"], "title": "RealSR-R1: Reinforcement Learning for Real-World Image Super-Resolution with Vision-Language Chain-of-Thought", "categories": ["cs.CV"], "comment": null, "summary": "Real-World Image Super-Resolution is one of the most challenging task in\nimage restoration. However, existing methods struggle with an accurate\nunderstanding of degraded image content, leading to reconstructed results that\nare both low-fidelity and unnatural. We present RealSR-R1 in this work, which\nempowers the RealSR models with understanding and reasoning capabilities.\nInspired by the success of Chain of Thought (CoT) in large language models\n(LLMs), we simulate the human process of handling degraded images and propose\nthe VLCoT framework, which integrates vision and language reasoning. The\nframework aims to precisely restore image details by progressively generating\nmore comprehensive text and higher-resolution images. To overcome the challenge\nof traditional supervised learning CoT failing to generalize to real-world\nscenarios, we introduce, for the first time, Group Relative Policy Optimization\n(GRPO) into the Real-World Image Super-Resolution task. We propose VLCoT-GRPO\nas a solution, which designs four reward functions: (1) Format reward, used to\nstandardize the CoT process; (2) Degradation reward, to incentivize accurate\ndegradation estimation; (3) Understanding reward, to ensure the accuracy of the\ngenerated content; and (4) Generation reward, where we propose using a visual\nexpert model to evaluate the quality of generated images, encouraging the model\nto generate more realistic images. Extensive experiments demonstrate that our\nproposed RealSR-R1 can generate realistic details and accurately understand\nimage content, particularly in semantically rich scenes or images with severe\ndegradation.", "AI": {"tldr": "RealSR-R1 introduces VLCoT-GRPO, a framework combining vision-language reasoning and Group Relative Policy Optimization (GRPO) for realistic image super-resolution, outperforming traditional methods.", "motivation": "Existing methods fail to accurately understand degraded images, leading to low-fidelity results. RealSR-R1 aims to improve this by integrating reasoning capabilities.", "method": "Proposes VLCoT framework (inspired by Chain of Thought in LLMs) and GRPO with four reward functions: Format, Degradation, Understanding, and Generation rewards.", "result": "RealSR-R1 generates realistic details and accurately understands image content, especially in complex or severely degraded scenes.", "conclusion": "The VLCoT-GRPO framework effectively enhances Real-World Image Super-Resolution by combining reasoning and optimization, achieving superior results."}}
{"id": "2506.16110", "pdf": "https://arxiv.org/pdf/2506.16110", "abs": "https://arxiv.org/abs/2506.16110", "authors": ["Langzhang Liang", "Fanchen Bu", "Zixing Song", "Zenglin Xu", "Shirui Pan", "Kijung Shin"], "title": "Mitigating Over-Squashing in Graph Neural Networks by Spectrum-Preserving Sparsification", "categories": ["cs.LG"], "comment": "Published as a conference paper at ICML 2025", "summary": "The message-passing paradigm of Graph Neural Networks often struggles with\nexchanging information across distant nodes typically due to structural\nbottlenecks in certain graph regions, a limitation known as\n\\textit{over-squashing}. To reduce such bottlenecks, \\textit{graph rewiring},\nwhich modifies graph topology, has been widely used. However, existing graph\nrewiring techniques often overlook the need to preserve critical properties of\nthe original graph, e.g., \\textit{spectral properties}. Moreover, many\napproaches rely on increasing edge count to improve connectivity, which\nintroduces significant computational overhead and exacerbates the risk of\nover-smoothing. In this paper, we propose a novel graph rewiring method that\nleverages \\textit{spectrum-preserving} graph \\textit{sparsification}, for\nmitigating over-squashing. Our method generates graphs with enhanced\nconnectivity while maintaining sparsity and largely preserving the original\ngraph spectrum, effectively balancing structural bottleneck reduction and graph\nproperty preservation. Experimental results validate the effectiveness of our\napproach, demonstrating its superiority over strong baseline methods in\nclassification accuracy and retention of the Laplacian spectrum.", "AI": {"tldr": "A novel graph rewiring method using spectrum-preserving sparsification to mitigate over-squashing in GNNs, balancing connectivity and property preservation.", "motivation": "Addressing over-squashing in GNNs caused by structural bottlenecks, while preserving critical graph properties like spectral features.", "method": "Proposes spectrum-preserving graph sparsification to rewire graphs, enhancing connectivity without increasing edge count or losing spectral properties.", "result": "Improved classification accuracy and better retention of the Laplacian spectrum compared to baselines.", "conclusion": "The method effectively reduces over-squashing while preserving graph properties, outperforming existing techniques."}}
{"id": "2506.16263", "pdf": "https://arxiv.org/pdf/2506.16263", "abs": "https://arxiv.org/abs/2506.16263", "authors": ["Xiting He", "Mingwu Su", "Xinqi Jiang", "Long Bai", "Jiewen Lai", "Hongliang Ren"], "title": "CapsDT: Diffusion-Transformer for Capsule Robot Manipulation", "categories": ["cs.RO", "cs.AI"], "comment": "IROS 2025", "summary": "Vision-Language-Action (VLA) models have emerged as a prominent research\narea, showcasing significant potential across a variety of applications.\nHowever, their performance in endoscopy robotics, particularly endoscopy\ncapsule robots that perform actions within the digestive system, remains\nunexplored. The integration of VLA models into endoscopy robots allows more\nintuitive and efficient interactions between human operators and medical\ndevices, improving both diagnostic accuracy and treatment outcomes. In this\nwork, we design CapsDT, a Diffusion Transformer model for capsule robot\nmanipulation in the stomach. By processing interleaved visual inputs, and\ntextual instructions, CapsDT can infer corresponding robotic control signals to\nfacilitate endoscopy tasks. In addition, we developed a capsule endoscopy robot\nsystem, a capsule robot controlled by a robotic arm-held magnet, addressing\ndifferent levels of four endoscopy tasks and creating corresponding capsule\nrobot datasets within the stomach simulator. Comprehensive evaluations on\nvarious robotic tasks indicate that CapsDT can serve as a robust\nvision-language generalist, achieving state-of-the-art performance in various\nlevels of endoscopy tasks while achieving a 26.25% success rate in real-world\nsimulation manipulation.", "AI": {"tldr": "CapsDT, a Diffusion Transformer model, integrates Vision-Language-Action (VLA) for endoscopy capsule robots, improving diagnostic accuracy and treatment outcomes with a 26.25% success rate in real-world simulations.", "motivation": "To explore the untapped potential of VLA models in endoscopy robotics, specifically for capsule robots in the digestive system, enhancing human-device interaction and medical outcomes.", "method": "Developed CapsDT, a Diffusion Transformer model, processing visual inputs and textual instructions to generate robotic control signals. Also created a capsule endoscopy robot system with a magnet-controlled capsule robot and a stomach simulator for dataset generation.", "result": "CapsDT achieved state-of-the-art performance in endoscopy tasks, with a 26.25% success rate in real-world simulation manipulation.", "conclusion": "CapsDT demonstrates robust performance as a vision-language generalist, validating its potential for practical applications in endoscopy robotics."}}
{"id": "2506.16447", "pdf": "https://arxiv.org/pdf/2506.16447", "abs": "https://arxiv.org/abs/2506.16447", "authors": ["Biao Yi", "Tiansheng Huang", "Sishuo Chen", "Tong Li", "Zheli Liu", "Zhixuan Chu", "Yiming Li"], "title": "Probe before You Talk: Towards Black-box Defense against Backdoor Unalignment for Large Language Models", "categories": ["cs.CR", "cs.CL"], "comment": "Accepted at ICLR 2025", "summary": "Backdoor unalignment attacks against Large Language Models (LLMs) enable the\nstealthy compromise of safety alignment using a hidden trigger while evading\nnormal safety auditing. These attacks pose significant threats to the\napplications of LLMs in the real-world Large Language Model as a Service\n(LLMaaS) setting, where the deployed model is a fully black-box system that can\nonly interact through text. Furthermore, the sample-dependent nature of the\nattack target exacerbates the threat. Instead of outputting a fixed label, the\nbackdoored LLM follows the semantics of any malicious command with the hidden\ntrigger, significantly expanding the target space. In this paper, we introduce\nBEAT, a black-box defense that detects triggered samples during inference to\ndeactivate the backdoor. It is motivated by an intriguing observation (dubbed\nthe probe concatenate effect), where concatenated triggered samples\nsignificantly reduce the refusal rate of the backdoored LLM towards a malicious\nprobe, while non-triggered samples have little effect. Specifically, BEAT\nidentifies whether an input is triggered by measuring the degree of distortion\nin the output distribution of the probe before and after concatenation with the\ninput. Our method addresses the challenges of sample-dependent targets from an\nopposite perspective. It captures the impact of the trigger on the refusal\nsignal (which is sample-independent) instead of sample-specific successful\nattack behaviors. It overcomes black-box access limitations by using multiple\nsampling to approximate the output distribution. Extensive experiments are\nconducted on various backdoor attacks and LLMs (including the closed-source\nGPT-3.5-turbo), verifying the effectiveness and efficiency of our defense.\nBesides, we also preliminarily verify that BEAT can effectively defend against\npopular jailbreak attacks, as they can be regarded as 'natural backdoors'.", "AI": {"tldr": "BEAT is a black-box defense method to detect and deactivate backdoor attacks in LLMs by measuring output distribution distortion when concatenating triggered samples with a probe.", "motivation": "Backdoor attacks in LLMs compromise safety alignment stealthily, posing threats in real-world LLMaaS settings due to sample-dependent targets and black-box access limitations.", "method": "BEAT detects triggered samples by observing the probe concatenate effect\u2014measuring output distribution distortion before and after concatenation with the input.", "result": "Extensive experiments on various backdoor attacks and LLMs (including GPT-3.5-turbo) confirm BEAT's effectiveness and efficiency. It also defends against jailbreak attacks.", "conclusion": "BEAT offers a robust defense against backdoor attacks by focusing on refusal signal distortion, overcoming black-box limitations, and showing promise against jailbreak attacks."}}
{"id": "2506.16802", "pdf": "https://arxiv.org/pdf/2506.16802", "abs": "https://arxiv.org/abs/2506.16802", "authors": ["Riccardo Corvi", "Davide Cozzolino", "Ekta Prashnani", "Shalini De Mello", "Koki Nagano", "Luisa Verdoliva"], "title": "Seeing What Matters: Generalizable AI-generated Video Detection with Forensic-Oriented Augmentation", "categories": ["cs.CV"], "comment": null, "summary": "Synthetic video generation is progressing very rapidly. The latest models can\nproduce very realistic high-resolution videos that are virtually\nindistinguishable from real ones. Although several video forensic detectors\nhave been recently proposed, they often exhibit poor generalization, which\nlimits their applicability in a real-world scenario. Our key insight to\novercome this issue is to guide the detector towards seeing what really\nmatters. In fact, a well-designed forensic classifier should focus on\nidentifying intrinsic low-level artifacts introduced by a generative\narchitecture rather than relying on high-level semantic flaws that characterize\na specific model. In this work, first, we study different generative\narchitectures, searching and identifying discriminative features that are\nunbiased, robust to impairments, and shared across models. Then, we introduce a\nnovel forensic-oriented data augmentation strategy based on the wavelet\ndecomposition and replace specific frequency-related bands to drive the model\nto exploit more relevant forensic cues. Our novel training paradigm improves\nthe generalizability of AI-generated video detectors, without the need for\ncomplex algorithms and large datasets that include multiple synthetic\ngenerators. To evaluate our approach, we train the detector using data from a\nsingle generative model and test it against videos produced by a wide range of\nother models. Despite its simplicity, our method achieves a significant\naccuracy improvement over state-of-the-art detectors and obtains excellent\nresults even on very recent generative models, such as NOVA and FLUX. Code and\ndata will be made publicly available.", "AI": {"tldr": "A novel method improves AI-generated video detection by focusing on low-level artifacts and using wavelet-based data augmentation, enhancing generalization without large datasets.", "motivation": "Existing video forensic detectors lack generalization, limiting real-world applicability. The paper aims to address this by focusing on intrinsic low-level artifacts rather than high-level flaws.", "method": "The study identifies discriminative features across generative models and introduces a wavelet-based data augmentation strategy to train detectors on relevant forensic cues.", "result": "The method significantly improves accuracy over state-of-the-art detectors, even on recent models like NOVA and FLUX, without needing large datasets.", "conclusion": "The proposed training paradigm enhances detector generalizability by focusing on intrinsic artifacts, offering a simpler yet effective solution for AI-generated video detection."}}
{"id": "2506.16174", "pdf": "https://arxiv.org/pdf/2506.16174", "abs": "https://arxiv.org/abs/2506.16174", "authors": ["Ismo Horppu", "Frederick Ayala", "Erlin Gulbenkoglu"], "title": "Hallucination Level of Artificial Intelligence Whisperer: Case Speech Recognizing Pantterinousut Rap Song", "categories": ["cs.LG", "I.5.4"], "comment": "15 pages, 10 figures", "summary": "All languages are peculiar. Some of them are considered more challenging to\nunderstand than others. The Finnish Language is known to be a complex language.\nAlso, when languages are used by artists, the pronunciation and meaning might\nbe more tricky to understand. Therefore, we are putting AI to a fun, yet\nchallenging trial: translating a Finnish rap song to text. We will compare the\nFaster Whisperer algorithm and YouTube's internal speech-to-text functionality.\nThe reference truth will be Finnish rap lyrics, which the main author's little\nbrother, Mc Timo, has written. Transcribing the lyrics will be challenging\nbecause the artist raps over synth music player by Syntikka Janne. The\nhallucination level and mishearing of AI speech-to-text extractions will be\nmeasured by comparing errors made against the original Finnish lyrics. The\nerror function is informal but still works for our case.", "AI": {"tldr": "The paper evaluates AI speech-to-text tools (Faster Whisperer and YouTube's internal function) for transcribing Finnish rap lyrics, measuring errors against original lyrics.", "motivation": "Finnish is complex, and artistic use (like rap) adds difficulty, making it a fun yet challenging test for AI transcription.", "method": "Compare Faster Whisperer and YouTube's speech-to-text against Mc Timo's Finnish rap lyrics, measuring errors due to music and artistic pronunciation.", "result": "The study measures AI hallucination and mishearing levels by comparing transcriptions to original lyrics.", "conclusion": "The informal error function provides insights into AI's performance on challenging linguistic tasks like Finnish rap."}}
{"id": "2506.16281", "pdf": "https://arxiv.org/pdf/2506.16281", "abs": "https://arxiv.org/abs/2506.16281", "authors": ["Martha Arbayani Zaidan", "Naser Hossein Motlagh", "Petteri Nurmi", "Tareq Hussein", "Markku Kulmala", "Tuukka Pet\u00e4j\u00e4", "Sasu Tarkoma"], "title": "Artificial Intelligence for Atmospheric Sciences: A Research Roadmap", "categories": ["cs.ET", "cs.AI"], "comment": null, "summary": "Atmospheric sciences are crucial for understanding environmental phenomena\nranging from air quality to extreme weather events, and climate change. Recent\nbreakthroughs in sensing, communication, computing, and Artificial Intelligence\n(AI) have significantly advanced atmospheric sciences, enabling the generation\nof vast amounts of data through long-term Earth observations and providing\npowerful tools for analyzing atmospheric phenomena and predicting natural\ndisasters. This paper contributes a critical interdisciplinary overview that\nbridges the fields of atmospheric science and computer science, highlighting\nthe transformative potential of AI in atmospheric research. We identify key\nchallenges associated with integrating AI into atmospheric research, including\nissues related to big data and infrastructure, and provide a detailed research\nroadmap that addresses both current and emerging challenges.", "AI": {"tldr": "The paper explores how AI advancements are transforming atmospheric sciences, addressing challenges like big data integration and proposing a research roadmap.", "motivation": "To bridge atmospheric science and computer science, leveraging AI for better understanding and prediction of environmental phenomena.", "method": "Provides a critical interdisciplinary overview and identifies key challenges in integrating AI into atmospheric research.", "result": "Highlights AI's transformative potential and outlines a roadmap for addressing current and emerging challenges.", "conclusion": "AI integration in atmospheric sciences offers significant advancements but requires solutions for big data and infrastructure issues."}}
{"id": "2506.16473", "pdf": "https://arxiv.org/pdf/2506.16473", "abs": "https://arxiv.org/abs/2506.16473", "authors": ["Sophie Chiang", "Guy Laban", "Hatice Gunes"], "title": "Do We Talk to Robots Like Therapists, and Do They Respond Accordingly? Language Alignment in AI Emotional Support", "categories": ["cs.HC", "cs.AI", "cs.CL"], "comment": null, "summary": "As conversational agents increasingly engage in emotionally supportive\ndialogue, it is important to understand how closely their interactions resemble\nthose in traditional therapy settings. This study investigates whether the\nconcerns shared with a robot align with those shared in human-to-human (H2H)\ntherapy sessions, and whether robot responses semantically mirror those of\nhuman therapists. We analyzed two datasets: one of interactions between users\nand professional therapists (Hugging Face's NLP Mental Health Conversations),\nand another involving supportive conversations with a social robot (QTrobot\nfrom LuxAI) powered by a large language model (LLM, GPT-3.5). Using sentence\nembeddings and K-means clustering, we assessed cross-agent thematic alignment\nby applying a distance-based cluster-fitting method that evaluates whether\nresponses from one agent type map to clusters derived from the other, and\nvalidated it using Euclidean distances. Results showed that 90.88% of robot\nconversation disclosures could be mapped to clusters from the human therapy\ndataset, suggesting shared topical structure. For matched clusters, we compared\nthe subjects as well as therapist and robot responses using Transformer,\nWord2Vec, and BERT embeddings, revealing strong semantic overlap in subjects'\ndisclosures in both datasets, as well as in the responses given to similar\nhuman disclosure themes across agent types (robot vs. human therapist). These\nfindings highlight both the parallels and boundaries of robot-led support\nconversations and their potential for augmenting mental health interventions.", "AI": {"tldr": "The study compares emotionally supportive conversations between humans and robots, finding strong thematic and semantic alignment with human therapy sessions.", "motivation": "To understand if robot-led support conversations resemble human therapy interactions and assess their potential in mental health interventions.", "method": "Analyzed datasets of human therapy sessions and robot interactions using sentence embeddings, K-means clustering, and distance-based cluster-fitting. Evaluated semantic overlap with Transformer, Word2Vec, and BERT embeddings.", "result": "90.88% of robot disclosures mapped to human therapy clusters, showing strong thematic and semantic alignment in subjects and responses.", "conclusion": "Robot-led support conversations share significant parallels with human therapy, suggesting potential for augmenting mental health interventions."}}
{"id": "2506.16805", "pdf": "https://arxiv.org/pdf/2506.16805", "abs": "https://arxiv.org/abs/2506.16805", "authors": ["Chao Chen", "Nobel Dang", "Juexiao Zhang", "Wenkai Sun", "Pengfei Zheng", "Xuhang He", "Yimeng Ye", "Taarun Srinivas", "Chen Feng"], "title": "Co-VisiON: Co-Visibility ReasONing on Sparse Image Sets of Indoor Scenes", "categories": ["cs.CV"], "comment": null, "summary": "Humans exhibit a remarkable ability to recognize co-visibility-the\noverlapping regions visible in multiple images-even when these images are\nsparsely distributed across a complex scene. This capability is foundational in\n3D vision and robotic perception. Despite significant progress in vision\nlearning, it remains unclear whether current vision models have reached\nhuman-level proficiency in co-visibility analysis. In this work, we introduce\nthe Co-Visibility reasONing (Co-VisiON) benchmark, designed to directly\nevaluate co-visibility reasoning on sparse image sets across over 1000 indoor\nscenarios. Our experiments reveal that while co-visibility is typically treated\nas a low-level feature matching task, it poses a significant challenge for\nexisting vision models under sparse conditions. Notably, a proprietary\nvision-language model outperforms all purely vision-based approaches, with all\nmodels lagging substantially behind human performance. This gap underscores the\nneed for more than basic pairwise vision processing-it calls for a\ncomprehensive spatial understanding through high-level reasoning across\nmultiple views. Inspired by human visual cognition, we propose a novel\nmulti-view baseline, Covis, which achieves top performance among pure vision\nmodels and narrows the gap to the proprietary VLM. We hope our benchmark and\nfindings will spur further advancements in developing vision models capable of\nrobust, high-level reasoning in challenging, sparse environments. Our dataset\nand source code can be found at: https://ai4ce.github.io/CoVISION", "AI": {"tldr": "The paper introduces the Co-VisiON benchmark to evaluate co-visibility reasoning in sparse image sets, revealing gaps between human performance and current vision models. A proposed multi-view baseline, Covis, narrows this gap.", "motivation": "To assess whether current vision models match human-level proficiency in co-visibility analysis, a critical skill in 3D vision and robotic perception.", "method": "The Co-VisiON benchmark evaluates co-visibility reasoning on sparse image sets across 1000+ indoor scenarios. A novel multi-view baseline, Covis, is proposed.", "result": "Existing vision models struggle with co-visibility under sparse conditions. A proprietary vision-language model outperforms vision-based approaches, but all lag behind humans. Covis narrows the gap.", "conclusion": "The benchmark highlights the need for high-level reasoning in vision models. Covis shows promise, but further advancements are needed to match human performance."}}
{"id": "2506.16196", "pdf": "https://arxiv.org/pdf/2506.16196", "abs": "https://arxiv.org/abs/2506.16196", "authors": ["Xun Wang", "Jing Xu", "Franziska Boenisch", "Michael Backes", "Christopher A. Choquette-Choo", "Adam Dziedzic"], "title": "Efficient and Privacy-Preserving Soft Prompt Transfer for LLMs", "categories": ["cs.LG"], "comment": "Accepted at ICML2025", "summary": "Prompting has become a dominant paradigm for adapting large language models\n(LLMs). While discrete (textual) prompts are widely used for their\ninterpretability, soft (parameter) prompts have recently gained traction in\nAPIs. This is because they can encode information from more training samples\nwhile minimizing the user's token usage, leaving more space in the context\nwindow for task-specific input. However, soft prompts are tightly coupled to\nthe LLM they are tuned on, limiting their generalization to other LLMs. This\nconstraint is particularly problematic for efficiency and privacy: (1) tuning\nprompts on each LLM incurs high computational costs, especially as LLMs\ncontinue to grow in size. Additionally, (2) when the LLM is hosted externally,\nsoft prompt tuning often requires sharing private data with the LLM provider.\nFor instance, this is the case with the NVIDIA NeMo API. To address these\nissues, we propose POST (Privacy Of Soft prompt Transfer), a framework that\nenables private tuning of soft prompts on a small model and subsequently\ntransfers these prompts to a larger LLM. POST uses knowledge distillation to\nderive a small model directly from the large LLM to improve prompt\ntransferability, tunes the soft prompt locally, optionally with differential\nprivacy guarantees, and transfers it back to the larger LLM using a small\npublic dataset. Our experiments show that POST reduces computational costs,\npreserves privacy, and effectively transfers high-utility soft prompts.", "AI": {"tldr": "POST enables private tuning of soft prompts on small models for transfer to larger LLMs, reducing costs and preserving privacy.", "motivation": "Soft prompts are tied to specific LLMs, raising efficiency and privacy concerns due to high computational costs and data sharing requirements.", "method": "POST uses knowledge distillation to create a small model from a large LLM, tunes soft prompts locally (with optional differential privacy), and transfers them back using a public dataset.", "result": "POST reduces computational costs, ensures privacy, and successfully transfers high-utility soft prompts.", "conclusion": "POST addresses efficiency and privacy issues in soft prompt tuning, offering a viable solution for LLM adaptation."}}
{"id": "2506.16288", "pdf": "https://arxiv.org/pdf/2506.16288", "abs": "https://arxiv.org/abs/2506.16288", "authors": ["Leo Gagnon", "Eric Elmoznino", "Sarthak Mittal", "Tom Marty", "Tejas Kasetty", "Dhanya Sridhar", "Guillaume Lajoie"], "title": "Next-Token Prediction Should be Ambiguity-Sensitive: A Meta-Learning Perspective", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "The rapid adaptation ability of auto-regressive foundation models is often\nattributed to the diversity of their pre-training data. This is because, from a\nBayesian standpoint, minimizing prediction error in such settings requires\nintegrating over all plausible latent hypotheses consistent with observations.\nWhile this behavior is desirable in principle, it often proves too ambitious in\npractice: under high ambiguity, the number of plausible latent alternatives\nmakes Bayes-optimal prediction computationally intractable. Cognitive science\nhas long recognized this limitation, suggesting that under such conditions,\nheuristics or information-seeking strategies are preferable to exhaustive\ninference. Translating this insight to next-token prediction, we hypothesize\nthat low- and high-ambiguity predictions pose different computational demands,\nmaking ambiguity-agnostic next-token prediction a detrimental inductive bias.\nTo test this, we introduce MetaHMM, a synthetic sequence meta-learning\nbenchmark with rich compositional structure and a tractable Bayesian oracle. We\nshow that Transformers indeed struggle with high-ambiguity predictions across\nmodel sizes. Motivated by cognitive theories, we propose a method to convert\npre-trained models into Monte Carlo predictors that decouple task inference\nfrom token prediction. Preliminary results show substantial gains in ambiguous\ncontexts through improved capacity allocation and test-time scalable inference,\nthough challenges remain.", "AI": {"tldr": "The paper explores the limitations of auto-regressive models in handling high-ambiguity predictions and proposes a method inspired by cognitive science to improve performance.", "motivation": "Auto-regressive models struggle with high-ambiguity predictions due to computational intractability, prompting the need for alternative strategies like heuristics or information-seeking methods.", "method": "The authors introduce MetaHMM, a synthetic benchmark, and propose converting pre-trained models into Monte Carlo predictors to decouple task inference from token prediction.", "result": "Transformers struggle with high-ambiguity predictions, but the proposed method shows preliminary gains in ambiguous contexts through better capacity allocation and scalable inference.", "conclusion": "The study highlights the potential of cognitive-inspired methods to address ambiguity in auto-regressive models, though challenges remain."}}
{"id": "2506.16552", "pdf": "https://arxiv.org/pdf/2506.16552", "abs": "https://arxiv.org/abs/2506.16552", "authors": ["Fengyu Cai", "Tong Chen", "Xinran Zhao", "Sihao Chen", "Hongming Zhang", "Sherry Tongshuang Wu", "Iryna Gurevych", "Heinz Koeppl"], "title": "Revela: Dense Retriever Learning via Language Modeling", "categories": ["cs.IR", "cs.CL"], "comment": null, "summary": "Dense retrievers play a vital role in accessing external and specialized\nknowledge to augment language models (LMs). Training dense retrievers typically\nrequires annotated query-document pairs, which are costly and hard to obtain in\nspecialized domains such as code-motivating growing interest in self-supervised\nretriever learning. Since LMs are trained to capture token-level dependencies\nthrough a self-supervised learning objective (i.e., next-token prediction), we\ncan analogously cast retrieval as learning dependencies among chunks of tokens.\nThis analogy naturally leads to the question: How can we adapt self-supervised\nlearning objectives in the spirit of language modeling to train retrievers?\n  To answer this question, we introduce Revela, a unified and scalable training\nframework for self-supervised retriever learning via language modeling. Revela\nmodels semantic dependencies among documents by conditioning next-token\nprediction on both local and cross-document context through an in-batch\nattention mechanism. This attention is weighted by retriever-computed\nsimilarity scores, enabling the retriever to be optimized as part of language\nmodeling. We evaluate Revela on both general-domain (BEIR) and domain-specific\n(CoIR) benchmarks across various retriever backbones. At a comparable parameter\nscale, Revela outperforms the previous best method with absolute improvements\nof 5.2 % (18.3 % relative) and 5.6 % (14.4 % relative) on NDCG@10,\nrespectively, underscoring its effectiveness. Performance increases with model\nsize, highlighting both the scalability of our approach and its promise for\nself-supervised retriever learning.", "AI": {"tldr": "Revela is a self-supervised retriever training framework that leverages language modeling to improve retrieval performance, outperforming prior methods on benchmarks.", "motivation": "Traditional dense retriever training relies on costly annotated query-document pairs, especially challenging in specialized domains like code. This motivates self-supervised approaches.", "method": "Revela adapts language modeling objectives to train retrievers by modeling semantic dependencies among documents using in-batch attention weighted by retriever-computed similarity scores.", "result": "Revela achieves absolute improvements of 5.2% and 5.6% on NDCG@10 for general-domain (BEIR) and domain-specific (CoIR) benchmarks, respectively, and scales well with model size.", "conclusion": "Revela demonstrates the effectiveness of self-supervised retriever learning via language modeling, offering scalability and superior performance."}}
{"id": "2506.16806", "pdf": "https://arxiv.org/pdf/2506.16806", "abs": "https://arxiv.org/abs/2506.16806", "authors": ["Fan Yang", "Yousong Zhu", "Xin Li", "Yufei Zhan", "Hongyin Zhao", "Shurong Zheng", "Yaowei Wang", "Ming Tang", "Jinqiao Wang"], "title": "FOCUS: Unified Vision-Language Modeling for Interactive Editing Driven by Referential Segmentation", "categories": ["cs.CV"], "comment": null, "summary": "Recent Large Vision Language Models (LVLMs) demonstrate promising\ncapabilities in unifying visual understanding and generative modeling, enabling\nboth accurate content understanding and flexible editing. However, current\napproaches treat \"what to see\" and \"how to edit\" separately: they either\nperform isolated object segmentation or utilize segmentation masks merely as\nconditional prompts for local edit generation tasks, often relying on multiple\ndisjointed models. To bridge these gaps, we introduce FOCUS, a unified LVLM\nthat integrates segmentation-aware perception and controllable object-centric\ngeneration within an end-to-end framework. FOCUS employs a dual-branch visual\nencoder to simultaneously capture global semantic context and fine-grained\nspatial details. In addition, we leverage a MoVQGAN-based visual tokenizer to\nproduce discrete visual tokens that enhance generation quality. To enable\naccurate and controllable image editing, we propose a progressive multi-stage\ntraining pipeline, where segmentation masks are jointly optimized and used as\nspatial condition prompts to guide the diffusion decoder. This strategy aligns\nvisual encoding, segmentation, and generation modules, effectively bridging\nsegmentation-aware perception with fine-grained visual synthesis. Extensive\nexperiments across three core tasks, including multimodal understanding,\nreferring segmentation accuracy, and controllable image generation, demonstrate\nthat FOCUS achieves strong performance by jointly optimizing visual perception\nand generative capabilities.", "AI": {"tldr": "FOCUS is a unified LVLM integrating segmentation-aware perception and controllable object-centric generation in an end-to-end framework, outperforming disjointed models.", "motivation": "Current LVLMs treat visual understanding and editing separately, relying on disjointed models, which FOCUS aims to unify.", "method": "FOCUS uses a dual-branch visual encoder, MoVQGAN-based tokenizer, and progressive multi-stage training with segmentation masks as spatial prompts.", "result": "FOCUS achieves strong performance in multimodal understanding, referring segmentation, and controllable image generation.", "conclusion": "FOCUS effectively bridges segmentation-aware perception with fine-grained visual synthesis, demonstrating joint optimization benefits."}}
{"id": "2506.16216", "pdf": "https://arxiv.org/pdf/2506.16216", "abs": "https://arxiv.org/abs/2506.16216", "authors": ["Charbel Bou Chaaya", "Abanoub M. Girgis", "Mehdi Bennis"], "title": "From Pixels to CSI: Distilling Latent Dynamics For Efficient Wireless Resource Management", "categories": ["cs.LG"], "comment": null, "summary": "In this work, we aim to optimize the radio resource management of a\ncommunication system between a remote controller and its device, whose state is\nrepresented through image frames, without compromising the performance of the\ncontrol task. We propose a novel machine learning (ML) technique to jointly\nmodel and predict the dynamics of the control system as well as the wireless\npropagation environment in latent space. Our method leverages two coupled\njoint-embedding predictive architectures (JEPAs): a control JEPA models the\ncontrol dynamics and guides the predictions of a wireless JEPA, which captures\nthe dynamics of the device's channel state information (CSI) through\ncross-modal conditioning. We then train a deep reinforcement learning (RL)\nalgorithm to derive a control policy from latent control dynamics and a power\npredictor to estimate scheduling intervals with favorable channel conditions\nbased on latent CSI representations. As such, the controller minimizes the\nusage of radio resources by utilizing the coupled JEPA networks to imagine the\ndevice's trajectory in latent space. We present simulation results on synthetic\nmultimodal data and show that our proposed approach reduces transmit power by\nover 50% while maintaining control performance comparable to baseline methods\nthat do not account for wireless optimization.", "AI": {"tldr": "Proposes a novel ML technique using coupled JEPAs to optimize radio resource management in control systems, reducing power usage by 50% without performance loss.", "motivation": "To optimize radio resource management in communication systems between controllers and devices without compromising control performance.", "method": "Uses two coupled JEPAs (control and wireless) to model dynamics, trains RL for control policy, and predicts power scheduling.", "result": "Reduces transmit power by over 50% while maintaining control performance comparable to baselines.", "conclusion": "The approach effectively minimizes radio resource usage by leveraging latent space predictions."}}
{"id": "2506.16313", "pdf": "https://arxiv.org/pdf/2506.16313", "abs": "https://arxiv.org/abs/2506.16313", "authors": ["Sajan Muhammad", "Salem Lahlou"], "title": "Improved Exploration in GFlownets via Enhanced Epistemic Neural Networks", "categories": ["cs.LG", "cs.AI", "I.2.6; I.2.8; G.3"], "comment": "Accepted to the EXAIT Workshop at ICML 2025", "summary": "Efficiently identifying the right trajectories for training remains an open\nproblem in GFlowNets. To address this, it is essential to prioritize\nexploration in regions of the state space where the reward distribution has not\nbeen sufficiently learned. This calls for uncertainty-driven exploration, in\nother words, the agent should be aware of what it does not know. This attribute\ncan be measured by joint predictions, which are particularly important for\ncombinatorial and sequential decision problems. In this research, we integrate\nepistemic neural networks (ENN) with the conventional architecture of GFlowNets\nto enable more efficient joint predictions and better uncertainty\nquantification, thereby improving exploration and the identification of optimal\ntrajectories. Our proposed algorithm, ENN-GFN-Enhanced, is compared to the\nbaseline method in GFlownets and evaluated in grid environments and structured\nsequence generation in various settings, demonstrating both its efficacy and\nefficiency.", "AI": {"tldr": "ENN-GFN-Enhanced integrates epistemic neural networks with GFlowNets for better uncertainty-driven exploration and trajectory identification.", "motivation": "The challenge of efficiently identifying optimal training trajectories in GFlowNets due to insufficient reward distribution learning.", "method": "Combines epistemic neural networks (ENN) with GFlowNets to improve joint predictions and uncertainty quantification.", "result": "ENN-GFN-Enhanced outperforms baseline methods in grid environments and structured sequence generation.", "conclusion": "The integration of ENN with GFlowNets enhances exploration and trajectory identification, proving effective and efficient."}}
{"id": "2506.16697", "pdf": "https://arxiv.org/pdf/2506.16697", "abs": "https://arxiv.org/abs/2506.16697", "authors": ["Zhicheng Lin"], "title": "From Prompts to Constructs: A Dual-Validity Framework for LLM Research in Psychology", "categories": ["cs.CY", "cs.AI", "cs.CL", "cs.HC"], "comment": null, "summary": "Large language models (LLMs) are rapidly being adopted across psychology,\nserving as research tools, experimental subjects, human simulators, and\ncomputational models of cognition. However, the application of human\nmeasurement tools to these systems can produce contradictory results, raising\nconcerns that many findings are measurement phantoms--statistical artifacts\nrather than genuine psychological phenomena. In this Perspective, we argue that\nbuilding a robust science of AI psychology requires integrating two of our\nfield's foundational pillars: the principles of reliable measurement and the\nstandards for sound causal inference. We present a dual-validity framework to\nguide this integration, which clarifies how the evidence needed to support a\nclaim scales with its scientific ambition. Using an LLM to classify text may\nrequire only basic accuracy checks, whereas claiming it can simulate anxiety\ndemands a far more rigorous validation process. Current practice systematically\nfails to meet these requirements, often treating statistical pattern matching\nas evidence of psychological phenomena. The same model output--endorsing \"I am\nanxious\"--requires different validation strategies depending on whether\nresearchers claim to measure, characterize, simulate, or model psychological\nconstructs. Moving forward requires developing computational analogues of\npsychological constructs and establishing clear, scalable standards of evidence\nrather than the uncritical application of human measurement tools.", "AI": {"tldr": "The paper discusses the challenges of applying human psychological measurement tools to large language models (LLMs) and proposes a dual-validity framework to ensure reliable and causally sound research in AI psychology.", "motivation": "Address concerns about contradictory results and measurement artifacts when using human tools on LLMs, aiming to build a robust science of AI psychology.", "method": "Proposes a dual-validity framework integrating reliable measurement principles and causal inference standards, scaling evidence requirements based on scientific ambition.", "result": "Current practices often misuse statistical pattern matching as evidence of psychological phenomena, lacking rigorous validation for higher claims like simulating anxiety.", "conclusion": "Future research should develop computational analogues of psychological constructs and establish scalable evidence standards, avoiding uncritical use of human tools."}}
{"id": "2506.16819", "pdf": "https://arxiv.org/pdf/2506.16819", "abs": "https://arxiv.org/abs/2506.16819", "authors": ["Yuchu Jiang", "Jiaming Chu", "Jian Zhao", "Xin Zhang", "Xu Yang", "Lei Jin", "Chi Zhang", "Xuelong Li"], "title": "Loupe: A Generalizable and Adaptive Framework for Image Forgery Detection", "categories": ["cs.CV", "cs.AI"], "comment": "6 pages, 2 figures, accepted by IJCAI 2025 workshop", "summary": "The proliferation of generative models has raised serious concerns about\nvisual content forgery. Existing deepfake detection methods primarily target\neither image-level classification or pixel-wise localization. While some\nachieve high accuracy, they often suffer from limited generalization across\nmanipulation types or rely on complex architectures. In this paper, we propose\nLoupe, a lightweight yet effective framework for joint deepfake detection and\nlocalization. Loupe integrates a patch-aware classifier and a segmentation\nmodule with conditional queries, allowing simultaneous global authenticity\nclassification and fine-grained mask prediction. To enhance robustness against\ndistribution shifts of test set, Loupe introduces a pseudo-label-guided\ntest-time adaptation mechanism by leveraging patch-level predictions to\nsupervise the segmentation head. Extensive experiments on the DDL dataset\ndemonstrate that Loupe achieves state-of-the-art performance, securing the\nfirst place in the IJCAI 2025 Deepfake Detection and Localization Challenge\nwith an overall score of 0.846. Our results validate the effectiveness of the\nproposed patch-level fusion and conditional query design in improving both\nclassification accuracy and spatial localization under diverse forgery\npatterns. The code is available at https://github.com/Kamichanw/Loupe.", "AI": {"tldr": "Loupe is a lightweight framework for joint deepfake detection and localization, combining patch-aware classification and segmentation with conditional queries. It achieves state-of-the-art performance and includes a test-time adaptation mechanism for robustness.", "motivation": "Addressing limitations of existing deepfake detection methods, which lack generalization or rely on complex architectures, by proposing a unified and efficient solution.", "method": "Loupe integrates a patch-aware classifier and segmentation module with conditional queries, enabling global classification and fine-grained mask prediction. It also uses pseudo-label-guided test-time adaptation for robustness.", "result": "Achieves state-of-the-art performance (0.846 score) on the DDL dataset, winning the IJCAI 2025 Challenge. Validates effectiveness in classification and localization under diverse forgery patterns.", "conclusion": "Loupe's patch-level fusion and conditional query design improve accuracy and localization, offering a robust and efficient solution for deepfake detection."}}
{"id": "2506.16234", "pdf": "https://arxiv.org/pdf/2506.16234", "abs": "https://arxiv.org/abs/2506.16234", "authors": ["Prakhar Verma", "David Arbour", "Sunav Choudhary", "Harshita Chopra", "Arno Solin", "Atanu R. Sinha"], "title": "Think Global, Act Local: Bayesian Causal Discovery with Language Models in Sequential Data", "categories": ["cs.LG"], "comment": "24 pages, preprint", "summary": "Causal discovery from observational data typically assumes full access to\ndata and availability of domain experts. In practice, data often arrive in\nbatches, and expert knowledge is scarce. Language Models (LMs) offer a\nsurrogate but come with their own issues-hallucinations, inconsistencies, and\nbias. We present BLANCE (Bayesian LM-Augmented Causal Estimation)-a hybrid\nBayesian framework that bridges these gaps by adaptively integrating sequential\nbatch data with LM-derived noisy, expert knowledge while accounting for both\ndata-induced and LM-induced biases. Our proposed representation shift from\nDirected Acyclic Graph (DAG) to Partial Ancestral Graph (PAG) accommodates\nambiguities within a coherent Bayesian framework, allowing grounding the global\nLM knowledge in local observational data. To guide LM interaction, we use a\nsequential optimization scheme that adaptively queries the most informative\nedges. Across varied datasets, BLANCE outperforms prior work in structural\naccuracy and extends to Bayesian parameter estimation, showing robustness to LM\nnoise.", "AI": {"tldr": "BLANCE is a Bayesian framework combining batch data and LM-derived knowledge for causal discovery, outperforming prior methods in accuracy and robustness.", "motivation": "Addressing challenges of batch data arrival and scarce expert knowledge in causal discovery, leveraging LMs while mitigating their biases and inconsistencies.", "method": "Uses a hybrid Bayesian framework integrating sequential batch data and LM-derived knowledge, shifting from DAG to PAG representation, and employs adaptive edge querying.", "result": "Outperforms prior methods in structural accuracy and extends to Bayesian parameter estimation, showing robustness to LM noise.", "conclusion": "BLANCE effectively bridges gaps in causal discovery by adaptively combining data and LM knowledge, offering improved accuracy and robustness."}}
{"id": "2506.16349", "pdf": "https://arxiv.org/pdf/2506.16349", "abs": "https://arxiv.org/abs/2506.16349", "authors": ["Nikola Jovanovi\u0107", "Ismail Labiad", "Tom\u00e1\u0161 Sou\u010dek", "Martin Vechev", "Pierre Fernandez"], "title": "Watermarking Autoregressive Image Generation", "categories": ["cs.LG", "cs.AI", "cs.CR", "cs.CV"], "comment": "Code: https://github.com/facebookresearch/wmar", "summary": "Watermarking the outputs of generative models has emerged as a promising\napproach for tracking their provenance. Despite significant interest in\nautoregressive image generation models and their potential for misuse, no prior\nwork has attempted to watermark their outputs at the token level. In this work,\nwe present the first such approach by adapting language model watermarking\ntechniques to this setting. We identify a key challenge: the lack of reverse\ncycle-consistency (RCC), wherein re-tokenizing generated image tokens\nsignificantly alters the token sequence, effectively erasing the watermark. To\naddress this and to make our method robust to common image transformations,\nneural compression, and removal attacks, we introduce (i) a custom\ntokenizer-detokenizer finetuning procedure that improves RCC, and (ii) a\ncomplementary watermark synchronization layer. As our experiments demonstrate,\nour approach enables reliable and robust watermark detection with theoretically\ngrounded p-values.", "AI": {"tldr": "First token-level watermarking for autoregressive image models, addressing reverse cycle-consistency and robustness to attacks.", "motivation": "Track provenance of generative model outputs, especially autoregressive image models, which lack prior token-level watermarking solutions.", "method": "Adapt language model watermarking, improve reverse cycle-consistency via tokenizer-detokenizer finetuning, and add a watermark synchronization layer.", "result": "Reliable and robust watermark detection with theoretically grounded p-values.", "conclusion": "The approach effectively watermarks autoregressive image model outputs, addressing key challenges like RCC and attack robustness."}}
{"id": "2506.16702", "pdf": "https://arxiv.org/pdf/2506.16702", "abs": "https://arxiv.org/abs/2506.16702", "authors": ["Zhicheng Lin"], "title": "Large Language Models as Psychological Simulators: A Methodological Guide", "categories": ["cs.CY", "cs.AI", "cs.CL", "cs.HC"], "comment": null, "summary": "Large language models (LLMs) offer emerging opportunities for psychological\nand behavioral research, but methodological guidance is lacking. This article\nprovides a framework for using LLMs as psychological simulators across two\nprimary applications: simulating roles and personas to explore diverse\ncontexts, and serving as computational models to investigate cognitive\nprocesses. For simulation, we present methods for developing psychologically\ngrounded personas that move beyond demographic categories, with strategies for\nvalidation against human data and use cases ranging from studying inaccessible\npopulations to prototyping research instruments. For cognitive modeling, we\nsynthesize emerging approaches for probing internal representations,\nmethodological advances in causal interventions, and strategies for relating\nmodel behavior to human cognition. We address overarching challenges including\nprompt sensitivity, temporal limitations from training data cutoffs, and\nethical considerations that extend beyond traditional human subjects review.\nThroughout, we emphasize the need for transparency about model capabilities and\nconstraints. Together, this framework integrates emerging empirical evidence\nabout LLM performance--including systematic biases, cultural limitations, and\nprompt brittleness--to help researchers wrangle these challenges and leverage\nthe unique capabilities of LLMs in psychological research.", "AI": {"tldr": "A framework for using LLMs in psychological research as simulators and cognitive models, addressing challenges like bias and ethics.", "motivation": "Lack of methodological guidance for leveraging LLMs in psychological and behavioral research.", "method": "Develop psychologically grounded personas for simulation and use LLMs as computational models for cognitive processes.", "result": "Provides strategies for validation, addressing biases, and ethical considerations, while emphasizing transparency.", "conclusion": "LLMs offer unique capabilities for psychological research but require careful handling of challenges like prompt sensitivity and cultural limitations."}}
{"id": "2506.16821", "pdf": "https://arxiv.org/pdf/2506.16821", "abs": "https://arxiv.org/abs/2506.16821", "authors": ["Can Lin", "Daniele Affinita", "Marco E. P. Zimmatore", "Daniele Nardi", "Domenico D. Bloisi", "Vincenzo Suriani"], "title": "Self-supervised Feature Extraction for Enhanced Ball Detection on Soccer Robots", "categories": ["cs.CV"], "comment": null, "summary": "Robust and accurate ball detection is a critical component for autonomous\nhumanoid soccer robots, particularly in dynamic and challenging environments\nsuch as RoboCup outdoor fields. However, traditional supervised approaches\nrequire extensive manual annotation, which is costly and time-intensive. To\novercome this problem, we present a self-supervised learning framework for\ndomain-adaptive feature extraction to enhance ball detection performance. The\nproposed approach leverages a general-purpose pretrained model to generate\npseudo-labels, which are then used in a suite of self-supervised pretext tasks\n-- including colorization, edge detection, and triplet loss -- to learn robust\nvisual features without relying on manual annotations. Additionally, a\nmodel-agnostic meta-learning (MAML) strategy is incorporated to ensure rapid\nadaptation to new deployment scenarios with minimal supervision. A new dataset\ncomprising 10,000 labeled images from outdoor RoboCup SPL matches is\nintroduced, used to validate the method, and made available to the community.\nExperimental results demonstrate that the proposed pipeline outperforms\nbaseline models in terms of accuracy, F1 score, and IoU, while also exhibiting\nfaster convergence.", "AI": {"tldr": "A self-supervised learning framework for robust ball detection in humanoid soccer robots, reducing reliance on manual annotations and improving performance.", "motivation": "Traditional supervised ball detection methods require costly manual annotations, prompting the need for a more efficient solution.", "method": "Uses a pretrained model for pseudo-labeling and self-supervised pretext tasks (colorization, edge detection, triplet loss) with MAML for rapid adaptation.", "result": "Outperforms baselines in accuracy, F1 score, and IoU, with faster convergence.", "conclusion": "The framework effectively enhances ball detection while minimizing manual annotation effort."}}
{"id": "2506.16237", "pdf": "https://arxiv.org/pdf/2506.16237", "abs": "https://arxiv.org/abs/2506.16237", "authors": ["Jacopo Iollo", "Geoffroy Oudoumanessah", "Carole Lartizien", "Michel Dojat", "Florence Forbes"], "title": "Active MRI Acquisition with Diffusion Guided Bayesian Experimental Design", "categories": ["cs.LG"], "comment": null, "summary": "A key challenge in maximizing the benefits of Magnetic Resonance Imaging\n(MRI) in clinical settings is to accelerate acquisition times without\nsignificantly degrading image quality. This objective requires a balance\nbetween under-sampling the raw k-space measurements for faster acquisitions and\ngathering sufficient raw information for high-fidelity image reconstruction and\nanalysis tasks. To achieve this balance, we propose to use sequential Bayesian\nexperimental design (BED) to provide an adaptive and task-dependent selection\nof the most informative measurements. Measurements are sequentially augmented\nwith new samples selected to maximize information gain on a posterior\ndistribution over target images. Selection is performed via a gradient-based\noptimization of a design parameter that defines a subsampling pattern. In this\nwork, we introduce a new active BED procedure that leverages diffusion-based\ngenerative models to handle the high dimensionality of the images and employs\nstochastic optimization to select among a variety of patterns while meeting the\nacquisition process constraints and budget. So doing, we show how our setting\ncan optimize, not only standard image reconstruction, but also any associated\nimage analysis task. The versatility and performance of our approach are\ndemonstrated on several MRI acquisitions.", "AI": {"tldr": "Proposes a sequential Bayesian experimental design (BED) method to optimize MRI acquisition by adaptively selecting informative measurements, balancing speed and quality.", "motivation": "Accelerate MRI acquisition times without degrading image quality by balancing under-sampling and sufficient raw data for high-fidelity reconstruction.", "method": "Uses sequential BED with gradient-based optimization to select measurements maximizing information gain, leveraging diffusion-based generative models and stochastic optimization.", "result": "Demonstrates versatility and performance in optimizing MRI acquisitions for both reconstruction and analysis tasks.", "conclusion": "The approach effectively balances acquisition speed and image quality, adaptable to various MRI tasks."}}
{"id": "2506.16406", "pdf": "https://arxiv.org/pdf/2506.16406", "abs": "https://arxiv.org/abs/2506.16406", "authors": ["Zhiyuan Liang", "Dongwen Tang", "Yuhao Zhou", "Xuanlei Zhao", "Mingjia Shi", "Wangbo Zhao", "Zekai Li", "Peihao Wang", "Konstantin Sch\u00fcrholt", "Damian Borth", "Michael M. Bronstein", "Yang You", "Zhangyang Wang", "Kai Wang"], "title": "Drag-and-Drop LLMs: Zero-Shot Prompt-to-Weights", "categories": ["cs.LG", "cs.AI"], "comment": "We propose a method that can generate LoRA parameters in seconds", "summary": "Modern Parameter-Efficient Fine-Tuning (PEFT) methods such as low-rank\nadaptation (LoRA) reduce the cost of customizing large language models (LLMs),\nyet still require a separate optimization run for every downstream dataset. We\nintroduce \\textbf{Drag-and-Drop LLMs (\\textit{DnD})}, a prompt-conditioned\nparameter generator that eliminates per-task training by mapping a handful of\nunlabeled task prompts directly to LoRA weight updates. A lightweight text\nencoder distills each prompt batch into condition embeddings, which are then\ntransformed by a cascaded hyper-convolutional decoder into the full set of LoRA\nmatrices. Once trained in a diverse collection of prompt-checkpoint pairs, DnD\nproduces task-specific parameters in seconds, yielding i) up to\n\\textbf{12,000$\\times$} lower overhead than full fine-tuning, ii) average gains\nup to \\textbf{30\\%} in performance over the strongest training LoRAs on unseen\ncommon-sense reasoning, math, coding, and multimodal benchmarks, and iii)\nrobust cross-domain generalization despite never seeing the target data or\nlabels. Our results demonstrate that prompt-conditioned parameter generation is\na viable alternative to gradient-based adaptation for rapidly specializing\nLLMs. Our project is available at\n\\href{https://jerryliang24.github.io/DnD}{https://jerryliang24.github.io/DnD}.", "AI": {"tldr": "DnD introduces a prompt-conditioned parameter generator for LLMs, eliminating per-task training and achieving high efficiency and performance gains.", "motivation": "Reduce the cost and overhead of customizing large language models (LLMs) by eliminating the need for separate optimization runs for each downstream dataset.", "method": "Uses a lightweight text encoder and hyper-convolutional decoder to map task prompts directly to LoRA weight updates, trained on diverse prompt-checkpoint pairs.", "result": "Achieves up to 12,000x lower overhead than full fine-tuning, 30% performance gains over LoRAs, and robust cross-domain generalization.", "conclusion": "Prompt-conditioned parameter generation is a viable alternative to gradient-based adaptation for rapidly specializing LLMs."}}
{"id": "2506.16962", "pdf": "https://arxiv.org/pdf/2506.16962", "abs": "https://arxiv.org/abs/2506.16962", "authors": ["Haoran Sun", "Yankai Jiang", "Wenjie Lou", "Yujie Zhang", "Wenjie Li", "Lilong Wang", "Mianxin Liu", "Lei Liu", "Xiaosong Wang"], "title": "Enhancing Step-by-Step and Verifiable Medical Reasoning in MLLMs", "categories": ["cs.CV", "cs.AI", "cs.CL"], "comment": null, "summary": "Multimodal large language models (MLLMs) have begun to demonstrate robust\nreasoning capabilities on general tasks, yet their application in the medical\ndomain remains in its early stages. Constructing chain-of-thought (CoT)\ntraining data is essential for bolstering the reasoning abilities of medical\nMLLMs. However, existing approaches exhibit a deficiency in offering a\ncomprehensive framework for searching and evaluating effective reasoning paths\ntowards critical diagnosis. To address this challenge, we propose Mentor-Intern\nCollaborative Search (MICS), a novel reasoning-path searching scheme to\ngenerate rigorous and effective medical CoT data. MICS first leverages mentor\nmodels to initialize the reasoning, one step at a time, then prompts each\nintern model to continue the thinking along those initiated paths, and finally\nselects the optimal reasoning path according to the overall reasoning\nperformance of multiple intern models. The reasoning performance is determined\nby an MICS-Score, which assesses the quality of generated reasoning paths.\nEventually, we construct MMRP, a multi-task medical reasoning dataset with\nranked difficulty, and Chiron-o1, a new medical MLLM devised via a curriculum\nlearning strategy, with robust visual question-answering and generalizable\nreasoning capabilities. Extensive experiments demonstrate that Chiron-o1,\ntrained on our CoT dataset constructed using MICS, achieves state-of-the-art\nperformance across a list of medical visual question answering and reasoning\nbenchmarks. Codes are available at GitHub - manglu097/Chiron-o1: Enhancing\nStep-by-Step and Verifiable Medical Reasoning in MLLMs", "AI": {"tldr": "MICS introduces a novel method to generate rigorous medical CoT data, improving MLLM reasoning in medicine.", "motivation": "Existing methods lack a comprehensive framework for effective reasoning paths in medical diagnosis.", "method": "MICS uses mentor-intern collaboration to search and evaluate reasoning paths, creating a ranked dataset (MMRP) and a new MLLM (Chiron-o1).", "result": "Chiron-o1 achieves state-of-the-art performance in medical reasoning benchmarks.", "conclusion": "MICS enhances medical MLLM reasoning, validated by superior benchmark results."}}
{"id": "2506.16826", "pdf": "https://arxiv.org/pdf/2506.16826", "abs": "https://arxiv.org/abs/2506.16826", "authors": ["Sattwik Sahu", "Agamdeep Singh", "Karthik Nambiar", "Srikanth Saripalli", "P. B. Sujit"], "title": "AnyTraverse: An off-road traversability framework with VLM and human operator in the loop", "categories": ["cs.CV", "cs.AI", "cs.RO"], "comment": null, "summary": "Off-road traversability segmentation enables autonomous navigation with\napplications in search-and-rescue, military operations, wildlife exploration,\nand agriculture. Current frameworks struggle due to significant variations in\nunstructured environments and uncertain scene changes, and are not adaptive to\nbe used for different robot types. We present AnyTraverse, a framework\ncombining natural language-based prompts with human-operator assistance to\ndetermine navigable regions for diverse robotic vehicles. The system segments\nscenes for a given set of prompts and calls the operator only when encountering\npreviously unexplored scenery or unknown class not part of the prompt in its\nregion-of-interest, thus reducing active supervision load while adapting to\nvarying outdoor scenes. Our zero-shot learning approach eliminates the need for\nextensive data collection or retraining. Our experimental validation includes\ntesting on RELLIS-3D, Freiburg Forest, and RUGD datasets and demonstrate\nreal-world deployment on multiple robot platforms. The results show that\nAnyTraverse performs better than GA-NAV and Off-seg while offering a\nvehicle-agnostic approach to off-road traversability that balances automation\nwith targeted human supervision.", "AI": {"tldr": "AnyTraverse is a framework for off-road traversability segmentation using natural language prompts and human-operator assistance, outperforming GA-NAV and Off-seg while reducing supervision needs.", "motivation": "Current frameworks struggle with unstructured environments and lack adaptability for diverse robot types, limiting autonomous navigation in off-road scenarios.", "method": "Combines natural language prompts with human-operator assistance, using zero-shot learning to avoid extensive data collection or retraining.", "result": "Validated on RELLIS-3D, Freiburg Forest, and RUGD datasets, AnyTraverse outperforms GA-NAV and Off-seg, offering a vehicle-agnostic solution.", "conclusion": "AnyTraverse balances automation with targeted human supervision, improving adaptability and performance in off-road traversability."}}
{"id": "2506.16253", "pdf": "https://arxiv.org/pdf/2506.16253", "abs": "https://arxiv.org/abs/2506.16253", "authors": ["Hadar Tal", "Oron Sabag"], "title": "Optimal Online Bookmaking for Any Number of Outcomes", "categories": ["cs.LG", "cs.GT", "cs.IT", "math.IT", "math.OC"], "comment": "Accepted for presentation at the Conference on Learning Theory (COLT)\n  2025", "summary": "We study the Online Bookmaking problem, where a bookmaker dynamically updates\nbetting odds on the possible outcomes of an event. In each betting round, the\nbookmaker can adjust the odds based on the cumulative betting behavior of\ngamblers, aiming to maximize profit while mitigating potential loss. We show\nthat for any event and any number of betting rounds, in a worst-case setting\nover all possible gamblers and outcome realizations, the bookmaker's optimal\nloss is the largest root of a simple polynomial. Our solution shows that\nbookmakers can be as fair as desired while avoiding financial risk, and the\nexplicit characterization reveals an intriguing relation between the\nbookmaker's regret and Hermite polynomials. We develop an efficient algorithm\nthat computes the optimal bookmaking strategy: when facing an optimal gambler,\nthe algorithm achieves the optimal loss, and in rounds where the gambler is\nsuboptimal, it reduces the achieved loss to the optimal opportunistic loss, a\nnotion that is related to subgame perfect Nash equilibrium. The key technical\ncontribution to achieve these results is an explicit characterization of the\nBellman-Pareto frontier, which unifies the dynamic programming updates for\nBellman's value function with the multi-criteria optimization framework of the\nPareto frontier in the context of vector repeated games.", "AI": {"tldr": "The paper analyzes the Online Bookmaking problem, showing the bookmaker's optimal loss is the largest root of a polynomial. It provides an efficient algorithm for optimal strategy, linking regret to Hermite polynomials.", "motivation": "To maximize profit while mitigating loss in dynamic betting scenarios, ensuring fairness and financial safety for bookmakers.", "method": "Develops an efficient algorithm based on the Bellman-Pareto frontier, unifying dynamic programming and multi-criteria optimization.", "result": "The bookmaker's optimal loss is characterized by a polynomial root, with the algorithm achieving optimal loss against optimal gamblers and reducing loss otherwise.", "conclusion": "Bookmakers can balance fairness and risk, with the solution revealing a connection between regret and Hermite polynomials."}}
{"id": "2506.16419", "pdf": "https://arxiv.org/pdf/2506.16419", "abs": "https://arxiv.org/abs/2506.16419", "authors": ["Daniel Fidel Harvey", "George Weale", "Berk Yilmaz"], "title": "Optimizing MoE Routers: Design, Implementation, and Evaluation in Transformer Models", "categories": ["cs.LG", "cs.AI", "68T07, 68T45"], "comment": "All authors contributed equally. 11 pages, 6 figures", "summary": "Mixture of Experts (MoE) architectures increase large language model\nscalability, yet their performance depends on the router module that moves\ntokens to specialized experts. Bad routing can load imbalance and reduced\naccuracy. This project designed and implemented different router architectures\nwithin Transformer models to fix these limitations. We experimented with six\ndistinct router variants Linear, Attention, Multi-Layer Perceptron (MLP),\nHybrid, Hash, and our new MLP-Hadamard. We characterized these routers using\nBERT and the Qwen1.5-MoE model, looking at parameter efficiency, inference\nlatency, routing entropy, and expert utilization patterns. Our evaluations\nshowed distinct trade-offs: Linear routers offer speed, while MLP and Attention\nrouters provide greater expressiveness. The MLP-Hadamard router shows a unique\ncapability for structured, sparse routing. We successfully replaced and\nfine-tuned custom routers within the complex, quantized Qwen1.5-MoE model. This\nwork provides a comparative analysis of MoE router designs and offers insights\ninto optimizing their performance for efficient and effective large-scale model\ndeployment.", "AI": {"tldr": "The paper explores router architectures in Mixture of Experts (MoE) models, comparing six variants for efficiency and performance, with MLP-Hadamard showing unique sparse routing capabilities.", "motivation": "To address load imbalance and accuracy issues in MoE models caused by poor routing, the study designs and evaluates various router architectures.", "method": "Six router variants (Linear, Attention, MLP, Hybrid, Hash, MLP-Hadamard) were tested in Transformer models (BERT, Qwen1.5-MoE), analyzing parameter efficiency, latency, entropy, and expert utilization.", "result": "Linear routers are faster, MLP/Attention routers are more expressive, and MLP-Hadamard excels in structured, sparse routing. Custom routers were successfully fine-tuned in Qwen1.5-MoE.", "conclusion": "The study provides a comparative analysis of MoE routers, offering insights for optimizing large-scale model deployment."}}
{"id": "2506.16975", "pdf": "https://arxiv.org/pdf/2506.16975", "abs": "https://arxiv.org/abs/2506.16975", "authors": ["Guan Zhe Hong", "Bhavya Vasudeva", "Vatsal Sharan", "Cyrus Rashtchian", "Prabhakar Raghavan", "Rina Panigrahy"], "title": "Latent Concept Disentanglement in Transformer-based Language Models", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": null, "summary": "When large language models (LLMs) use in-context learning (ICL) to solve a\nnew task, they seem to grasp not only the goal of the task but also core,\nlatent concepts in the demonstration examples. This begs the question of\nwhether transformers represent latent structures as part of their computation\nor whether they take shortcuts to solve the problem. Prior mechanistic work on\nICL does not address this question because it does not sufficiently examine the\nrelationship between the learned representation and the latent concept, and the\nconsidered problem settings often involve only single-step reasoning. In this\nwork, we examine how transformers disentangle and use latent concepts. We show\nthat in 2-hop reasoning tasks with a latent, discrete concept, the model\nsuccessfully identifies the latent concept and does step-by-step concept\ncomposition. In tasks parameterized by a continuous latent concept, we find\nlow-dimensional subspaces in the representation space where the geometry mimics\nthe underlying parameterization. Together, these results refine our\nunderstanding of ICL and the representation of transformers, and they provide\nevidence for highly localized structures in the model that disentangle latent\nconcepts in ICL tasks.", "AI": {"tldr": "The paper investigates whether transformers in LLMs represent latent structures during in-context learning (ICL) or take shortcuts. It shows transformers identify and compose latent concepts in discrete and continuous tasks.", "motivation": "To understand if transformers truly grasp latent concepts in ICL or rely on shortcuts, addressing gaps in prior mechanistic work.", "method": "Examines transformers in 2-hop reasoning tasks (discrete latent concepts) and continuous latent concept tasks, analyzing representation subspaces.", "result": "Transformers successfully identify and compose latent concepts in discrete tasks and mimic continuous parameterization in low-dimensional subspaces.", "conclusion": "The findings refine understanding of ICL, showing localized structures in transformers that disentangle latent concepts."}}
{"id": "2506.16842", "pdf": "https://arxiv.org/pdf/2506.16842", "abs": "https://arxiv.org/abs/2506.16842", "authors": ["Chaehyeon Song", "Dongjae Lee", "Jongwoo Lim", "Ayoung Kim"], "title": "Camera Calibration via Circular Patterns: A Comprehensive Framework with Measurement Uncertainty and Unbiased Projection Model", "categories": ["cs.CV", "cs.RO"], "comment": null, "summary": "Camera calibration using planar targets has been widely favored, and two\ntypes of control points have been mainly considered as measurements: the\ncorners of the checkerboard and the centroid of circles. Since a centroid is\nderived from numerous pixels, the circular pattern provides more precise\nmeasurements than the checkerboard. However, the existing projection model of\ncircle centroids is biased under lens distortion, resulting in low performance.\nTo surmount this limitation, we propose an unbiased projection model of the\ncircular pattern and demonstrate its superior accuracy compared to the\ncheckerboard. Complementing this, we introduce uncertainty into circular\npatterns to enhance calibration robustness and completeness. Defining centroid\nuncertainty improves the performance of calibration components, including\npattern detection, optimization, and evaluation metrics. We also provide\nguidelines for performing good camera calibration based on the evaluation\nmetric. The core concept of this approach is to model the boundary points of a\ntwo-dimensional shape as a Markov random field, considering its connectivity.\nThe shape distribution is propagated to the centroid uncertainty through an\nappropriate shape representation based on the Green theorem. Consequently, the\nresulting framework achieves marked gains in calibration accuracy and\nrobustness. The complete source code and demonstration video are available at\nhttps://github.com/chaehyeonsong/discocal.", "AI": {"tldr": "The paper proposes an unbiased projection model for circular patterns in camera calibration, addressing bias issues in existing models. It introduces centroid uncertainty to improve robustness and accuracy, outperforming checkerboard methods.", "motivation": "Existing projection models for circular patterns are biased under lens distortion, leading to low performance. The paper aims to overcome this limitation.", "method": "An unbiased projection model for circular patterns is introduced, along with centroid uncertainty to enhance calibration robustness. The method models boundary points as a Markov random field and propagates shape distribution to centroid uncertainty.", "result": "The proposed framework achieves superior accuracy and robustness compared to checkerboard-based calibration.", "conclusion": "The approach significantly improves camera calibration performance, with guidelines provided for optimal calibration. Source code and demonstrations are available."}}
{"id": "2506.16314", "pdf": "https://arxiv.org/pdf/2506.16314", "abs": "https://arxiv.org/abs/2506.16314", "authors": ["Emmanuel Gangler", "Emille E. O. Ishida", "Matwey V. Kornilov", "Vladimir Korolev", "Anastasia Lavrukhina", "Konstantin Malanchev", "Maria V. Pruzhinskaya", "Etienne Russeil", "Timofey Semenikhin", "Sreevarsha Sreejith", "Alina A. Volnova"], "title": "Signatures to help interpretability of anomalies", "categories": ["cs.LG", "astro-ph.IM"], "comment": "7 pages, 3 figure, proceedings of the International Conference on\n  Machine Learning for Astrophysics (ML4ASTRO2)", "summary": "Machine learning is often viewed as a black box when it comes to\nunderstanding its output, be it a decision or a score. Automatic anomaly\ndetection is no exception to this rule, and quite often the astronomer is left\nto independently analyze the data in order to understand why a given event is\ntagged as an anomaly. We introduce here idea of anomaly signature, whose aim is\nto help the interpretability of anomalies by highlighting which features\ncontributed to the decision.", "AI": {"tldr": "The paper introduces 'anomaly signatures' to improve interpretability in machine learning-based anomaly detection by highlighting contributing features.", "motivation": "Machine learning outputs, like anomaly detection, are often opaque, leaving users to manually analyze why events are flagged as anomalies.", "method": "The authors propose the concept of 'anomaly signatures' to identify and highlight features that contribute to anomaly detection decisions.", "result": "The approach aims to make anomaly detection more interpretable by clarifying the reasoning behind flagged anomalies.", "conclusion": "Anomaly signatures enhance transparency in machine learning, aiding users in understanding anomaly detection outputs."}}
{"id": "2506.16443", "pdf": "https://arxiv.org/pdf/2506.16443", "abs": "https://arxiv.org/abs/2506.16443", "authors": ["Jonas R. Naujoks", "Aleksander Krasowski", "Moritz Weckbecker", "Galip \u00dcmit Yolcu", "Thomas Wiegand", "Sebastian Lapuschkin", "Wojciech Samek", "Ren\u00e9 P. Klausen"], "title": "Leveraging Influence Functions for Resampling Data in Physics-Informed Neural Networks", "categories": ["cs.LG", "cs.AI", "physics.comp-ph"], "comment": "This article was presented at \"The 3rd World Conference on\n  eXplainable Artificial Intelligence\" (2025)", "summary": "Physics-informed neural networks (PINNs) offer a powerful approach to solving\npartial differential equations (PDEs), which are ubiquitous in the quantitative\nsciences. Applied to both forward and inverse problems across various\nscientific domains, PINNs have recently emerged as a valuable tool in the field\nof scientific machine learning. A key aspect of their training is that the data\n-- spatio-temporal points sampled from the PDE's input domain -- are readily\navailable. Influence functions, a tool from the field of explainable AI (XAI),\napproximate the effect of individual training points on the model, enhancing\ninterpretability. In the present work, we explore the application of influence\nfunction-based sampling approaches for the training data. Our results indicate\nthat such targeted resampling based on data attribution methods has the\npotential to enhance prediction accuracy in physics-informed neural networks,\ndemonstrating a practical application of an XAI method in PINN training.", "AI": {"tldr": "PINNs solve PDEs using neural networks. Influence functions from XAI improve training data sampling, boosting prediction accuracy.", "motivation": "Enhance PINN training by applying influence functions for targeted resampling, improving interpretability and accuracy.", "method": "Use influence functions to identify impactful training points and resample data for PINN training.", "result": "Targeted resampling improves prediction accuracy in PINNs.", "conclusion": "XAI methods like influence functions can optimize PINN training, demonstrating practical benefits in scientific machine learning."}}
{"id": "2506.17052", "pdf": "https://arxiv.org/pdf/2506.17052", "abs": "https://arxiv.org/abs/2506.17052", "authors": ["Jingtong Su", "Julia Kempe", "Karen Ullrich"], "title": "From Concepts to Components: Concept-Agnostic Attention Module Discovery in Transformers", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": null, "summary": "Transformers have achieved state-of-the-art performance across language and\nvision tasks. This success drives the imperative to interpret their internal\nmechanisms with the dual goals of enhancing performance and improving\nbehavioral control. Attribution methods help advance interpretability by\nassigning model outputs associated with a target concept to specific model\ncomponents. Current attribution research primarily studies multi-layer\nperceptron neurons and addresses relatively simple concepts such as factual\nassociations (e.g., Paris is located in France). This focus tends to overlook\nthe impact of the attention mechanism and lacks a unified approach for\nanalyzing more complex concepts. To fill these gaps, we introduce Scalable\nAttention Module Discovery (SAMD), a concept-agnostic method for mapping\narbitrary, complex concepts to specific attention heads of general transformer\nmodels. We accomplish this by representing each concept as a vector,\ncalculating its cosine similarity with each attention head, and selecting the\nTopK-scoring heads to construct the concept-associated attention module. We\nthen propose Scalar Attention Module Intervention (SAMI), a simple strategy to\ndiminish or amplify the effects of a concept by adjusting the attention module\nusing only a single scalar parameter. Empirically, we demonstrate SAMD on\nconcepts of varying complexity, and visualize the locations of their\ncorresponding modules. Our results demonstrate that module locations remain\nstable before and after LLM post-training, and confirm prior work on the\nmechanics of LLM multilingualism. Through SAMI, we facilitate jailbreaking on\nHarmBench (+72.7%) by diminishing \"safety\" and improve performance on the GSM8K\nbenchmark (+1.6%) by amplifying \"reasoning\". Lastly, we highlight the\ndomain-agnostic nature of our approach by suppressing the image classification\naccuracy of vision transformers on ImageNet.", "AI": {"tldr": "The paper introduces SAMD and SAMI, methods to map complex concepts to transformer attention heads and adjust their effects, improving interpretability and control.", "motivation": "To address gaps in current attribution research, which overlooks attention mechanisms and lacks a unified approach for complex concepts.", "method": "SAMD maps concepts to attention heads using cosine similarity, while SAMI adjusts module effects with a scalar parameter.", "result": "Demonstrates stable module locations, improves jailbreaking (+72.7%) and reasoning (+1.6%), and suppresses vision transformer accuracy.", "conclusion": "The approach is domain-agnostic, enhancing interpretability and behavioral control in transformers."}}
{"id": "2506.16852", "pdf": "https://arxiv.org/pdf/2506.16852", "abs": "https://arxiv.org/abs/2506.16852", "authors": ["Chaonan Ji", "Jinwei Qi", "Peng Zhang", "Bang Zhang", "Liefeng Bo"], "title": "Controllable and Expressive One-Shot Video Head Swapping", "categories": ["cs.CV"], "comment": "Project page: https://humanaigc.github.io/SwapAnyHead/", "summary": "In this paper, we propose a novel diffusion-based multi-condition\ncontrollable framework for video head swapping, which seamlessly transplant a\nhuman head from a static image into a dynamic video, while preserving the\noriginal body and background of target video, and further allowing to tweak\nhead expressions and movements during swapping as needed. Existing\nface-swapping methods mainly focus on localized facial replacement neglecting\nholistic head morphology, while head-swapping approaches struggling with\nhairstyle diversity and complex backgrounds, and none of these methods allow\nusers to modify the transplanted head expressions after swapping. To tackle\nthese challenges, our method incorporates several innovative strategies through\na unified latent diffusion paradigm. 1) Identity-preserving context fusion: We\npropose a shape-agnostic mask strategy to explicitly disentangle foreground\nhead identity features from background/body contexts, combining hair\nenhancement strategy to achieve robust holistic head identity preservation\nacross diverse hair types and complex backgrounds. 2) Expression-aware landmark\nretargeting and editing: We propose a disentangled 3DMM-driven retargeting\nmodule that decouples identity, expression, and head poses, minimizing the\nimpact of original expressions in input images and supporting expression\nediting. While a scale-aware retargeting strategy is further employed to\nminimize cross-identity expression distortion for higher transfer precision.\nExperimental results demonstrate that our method excels in seamless background\nintegration while preserving the identity of the source portrait, as well as\nshowcasing superior expression transfer capabilities applicable to both real\nand virtual characters.", "AI": {"tldr": "A diffusion-based framework for video head swapping that preserves identity and allows expression editing, outperforming existing methods.", "motivation": "Existing methods lack holistic head morphology handling, struggle with hairstyles and backgrounds, and don't allow post-swap expression edits.", "method": "Uses identity-preserving context fusion and expression-aware landmark retargeting within a latent diffusion paradigm.", "result": "Achieves seamless background integration, robust identity preservation, and superior expression transfer for real/virtual characters.", "conclusion": "The method effectively addresses limitations of current head-swapping techniques with innovative strategies."}}
{"id": "2506.16316", "pdf": "https://arxiv.org/pdf/2506.16316", "abs": "https://arxiv.org/abs/2506.16316", "authors": ["Huy Hoang Nguyen", "Han Zhou", "Matthew B. Blaschko", "Aleksei Tiulpin"], "title": "Bayesian Optimization over Bounded Domains with the Beta Product Kernel", "categories": ["cs.LG"], "comment": "Accepted as a conference paper at UAI 2025", "summary": "Bayesian optimization with Gaussian processes (GP) is commonly used to\noptimize black-box functions. The Mat\\'ern and the Radial Basis Function (RBF)\ncovariance functions are used frequently, but they do not make any assumptions\nabout the domain of the function, which may limit their applicability in\nbounded domains. To address the limitation, we introduce the Beta kernel, a\nnon-stationary kernel induced by a product of Beta distribution density\nfunctions. Such a formulation allows our kernel to naturally model functions on\nbounded domains. We present statistical evidence supporting the hypothesis that\nthe kernel exhibits an exponential eigendecay rate, based on empirical analyses\nof its spectral properties across different settings. Our experimental results\ndemonstrate the robustness of the Beta kernel in modeling functions with optima\nlocated near the faces or vertices of the unit hypercube. The experiments show\nthat our kernel consistently outperforms a wide range of kernels, including the\nwell-known Mat\\'ern and RBF, in different problems, including synthetic\nfunction optimization and the compression of vision and language models.", "AI": {"tldr": "The paper introduces the Beta kernel for Bayesian optimization, outperforming Mat\u00e9rn and RBF kernels in bounded domains.", "motivation": "Existing kernels like Mat\u00e9rn and RBF lack assumptions about function domains, limiting their effectiveness in bounded domains.", "method": "Proposes the Beta kernel, a non-stationary kernel based on Beta distributions, to model functions in bounded domains.", "result": "Empirical evidence shows the Beta kernel's exponential eigendecay and superior performance in synthetic and real-world tasks.", "conclusion": "The Beta kernel is robust and outperforms traditional kernels in bounded domains, enhancing optimization tasks."}}
{"id": "2506.16448", "pdf": "https://arxiv.org/pdf/2506.16448", "abs": "https://arxiv.org/abs/2506.16448", "authors": ["Tri Duc Ly", "Gia H. Ngo"], "title": "Consumer-friendly EEG-based Emotion Recognition System: A Multi-scale Convolutional Neural Network Approach", "categories": ["cs.LG", "cs.AI"], "comment": "29 pages, 10 figures", "summary": "EEG is a non-invasive, safe, and low-risk method to record\nelectrophysiological signals inside the brain. Especially with recent\ntechnology developments like dry electrodes, consumer-grade EEG devices, and\nrapid advances in machine learning, EEG is commonly used as a resource for\nautomatic emotion recognition. With the aim to develop a deep learning model\nthat can perform EEG-based emotion recognition in a real-life context, we\npropose a novel approach to utilize multi-scale convolutional neural networks\nto accomplish such tasks. By implementing feature extraction kernels with many\nratio coefficients as well as a new type of kernel that learns key information\nfrom four separate areas of the brain, our model consistently outperforms the\nstate-of-the-art TSception model in predicting valence, arousal, and dominance\nscores across many performance evaluation metrics.", "AI": {"tldr": "A novel deep learning model using multi-scale CNNs for EEG-based emotion recognition outperforms the state-of-the-art TSception model.", "motivation": "To develop a deep learning model for EEG-based emotion recognition in real-life contexts, leveraging recent EEG technology and machine learning advances.", "method": "Utilizes multi-scale CNNs with feature extraction kernels of varying ratios and a new kernel type that learns from four brain areas.", "result": "The model consistently outperforms TSception in predicting valence, arousal, and dominance scores across multiple metrics.", "conclusion": "The proposed approach is effective for EEG-based emotion recognition, demonstrating superior performance over existing methods."}}
{"id": "2506.17113", "pdf": "https://arxiv.org/pdf/2506.17113", "abs": "https://arxiv.org/abs/2506.17113", "authors": ["Shoubin Yu", "Yue Zhang", "Ziyang Wang", "Jaehong Yoon", "Mohit Bansal"], "title": "MEXA: Towards General Multimodal Reasoning with Dynamic Multi-Expert Aggregation", "categories": ["cs.CV", "cs.AI", "cs.CL"], "comment": "The first two authors contributed equally; Github link:\n  https://github.com/Yui010206/MEXA", "summary": "Combining pre-trained expert models offers substantial potential for scalable\nmultimodal reasoning, but building a unified framework remains challenging due\nto the increasing diversity of input modalities and task complexity. For\ninstance, medical diagnosis requires precise reasoning over structured clinical\ntables, while financial forecasting depends on interpreting plot-based data to\nmake informed predictions. To tackle this challenge, we introduce MEXA, a\ntraining-free framework that performs modality- and task-aware aggregation of\nmultiple expert models to enable effective multimodal reasoning across diverse\nand distinct domains. MEXA dynamically selects expert models based on the input\nmodality and the task-specific reasoning demands (i.e., skills). Each expert\nmodel, specialized in a modality task pair, generates interpretable textual\nreasoning outputs. MEXA then aggregates and reasons over these outputs using a\nLarge Reasoning Model (LRM) to produce the final answer. This modular design\nallows flexible and transparent multimodal reasoning across diverse domains\nwithout additional training overhead. We extensively evaluate our approach on\ndiverse multimodal benchmarks, including Video Reasoning, Audio Reasoning, 3D\nUnderstanding, and Medical QA. MEXA consistently delivers performance\nimprovements over strong multimodal baselines, highlighting the effectiveness\nand broad applicability of our expert-driven selection and aggregation in\ndiverse multimodal reasoning tasks.", "AI": {"tldr": "MEXA is a training-free framework for multimodal reasoning that dynamically selects and aggregates expert models based on input modality and task demands, achieving strong performance across diverse domains.", "motivation": "The increasing diversity of input modalities and task complexity in multimodal reasoning poses challenges for unified frameworks. MEXA addresses this by leveraging specialized expert models.", "method": "MEXA dynamically selects expert models for specific modality-task pairs, generates interpretable textual reasoning, and aggregates outputs using a Large Reasoning Model (LRM).", "result": "MEXA outperforms baselines in benchmarks like Video Reasoning, Audio Reasoning, 3D Understanding, and Medical QA.", "conclusion": "MEXA's modular, expert-driven approach enables flexible and transparent multimodal reasoning without additional training, demonstrating broad applicability."}}
{"id": "2506.16856", "pdf": "https://arxiv.org/pdf/2506.16856", "abs": "https://arxiv.org/abs/2506.16856", "authors": ["Jun Fu", "Bin Tian", "Haonan Chen", "Shi Meng", "Tingting Yao"], "title": "ParkFormer: A Transformer-Based Parking Policy with Goal Embedding and Pedestrian-Aware Control", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Autonomous parking plays a vital role in intelligent vehicle systems,\nparticularly in constrained urban environments where high-precision control is\nrequired. While traditional rule-based parking systems struggle with\nenvironmental uncertainties and lack adaptability in crowded or dynamic scenes,\nhuman drivers demonstrate the ability to park intuitively without explicit\nmodeling. Inspired by this observation, we propose a Transformer-based\nend-to-end framework for autonomous parking that learns from expert\ndemonstrations. The network takes as input surround-view camera images,\ngoal-point representations, ego vehicle motion, and pedestrian trajectories. It\noutputs discrete control sequences including throttle, braking, steering, and\ngear selection. A novel cross-attention module integrates BEV features with\ntarget points, and a GRU-based pedestrian predictor enhances safety by modeling\ndynamic obstacles. We validate our method on the CARLA 0.9.14 simulator in both\nvertical and parallel parking scenarios. Experiments show our model achieves a\nhigh success rate of 96.57\\%, with average positional and orientation errors of\n0.21 meters and 0.41 degrees, respectively. The ablation studies further\ndemonstrate the effectiveness of key modules such as pedestrian prediction and\ngoal-point attention fusion. The code and dataset will be released at:\nhttps://github.com/little-snail-f/ParkFormer.", "AI": {"tldr": "A Transformer-based end-to-end framework for autonomous parking learns from expert demonstrations, achieving high success rates and precision in simulated environments.", "motivation": "Traditional rule-based parking systems lack adaptability in dynamic environments, while human drivers park intuitively. This paper aims to bridge the gap by learning from human-like behavior.", "method": "The proposed framework uses surround-view camera images, goal-point representations, ego motion, and pedestrian trajectories as inputs. It outputs control sequences via a Transformer with cross-attention and a GRU-based pedestrian predictor.", "result": "The model achieves a 96.57% success rate in CARLA simulations, with low positional (0.21m) and orientation (0.41\u00b0) errors. Ablation studies confirm the importance of key modules.", "conclusion": "The framework demonstrates robust performance in autonomous parking, leveraging human-like learning and dynamic obstacle modeling for safety and precision."}}
{"id": "2506.16352", "pdf": "https://arxiv.org/pdf/2506.16352", "abs": "https://arxiv.org/abs/2506.16352", "authors": ["Theo Zangato", "Aomar Osmani", "Pegah Alizadeh"], "title": "Data-Driven Policy Mapping for Safe RL-based Energy Management Systems", "categories": ["cs.LG"], "comment": null, "summary": "Increasing global energy demand and renewable integration complexity have\nplaced buildings at the center of sustainable energy management. We present a\nthree-step reinforcement learning(RL)-based Building Energy Management System\n(BEMS) that combines clustering, forecasting, and constrained policy learning\nto address scalability, adaptability, and safety challenges. First, we cluster\nnon-shiftable load profiles to identify common consumption patterns, enabling\npolicy generalization and transfer without retraining for each new building.\nNext, we integrate an LSTM based forecasting module to anticipate future\nstates, improving the RL agents' responsiveness to dynamic conditions. Lastly,\ndomain-informed action masking ensures safe exploration and operation,\npreventing harmful decisions. Evaluated on real-world data, our approach\nreduces operating costs by up to 15% for certain building types, maintains\nstable environmental performance, and quickly classifies and optimizes new\nbuildings with limited data. It also adapts to stochastic tariff changes\nwithout retraining. Overall, this framework delivers scalable, robust, and\ncost-effective building energy management.", "AI": {"tldr": "A three-step RL-based BEMS combines clustering, forecasting, and constrained policy learning to improve scalability, adaptability, and safety in building energy management, reducing costs by up to 15%.", "motivation": "Addressing the challenges of scalability, adaptability, and safety in building energy management due to increasing global energy demand and renewable integration complexity.", "method": "1. Clustering non-shiftable load profiles for policy generalization. 2. LSTM-based forecasting for dynamic responsiveness. 3. Domain-informed action masking for safe operation.", "result": "Reduces operating costs by up to 15%, maintains stable environmental performance, and quickly optimizes new buildings with limited data. Adapts to tariff changes without retraining.", "conclusion": "The framework provides scalable, robust, and cost-effective building energy management."}}
{"id": "2506.16456", "pdf": "https://arxiv.org/pdf/2506.16456", "abs": "https://arxiv.org/abs/2506.16456", "authors": ["Jun Qi", "Chen-Yu Liu", "Sabato Marco Siniscalchi", "Chao-Han Huck Yang", "Min-Hsiu Hsieh"], "title": "Joint Tensor-Train Parameterization for Efficient and Expressive Low-Rank Adaptation", "categories": ["cs.LG", "cs.AI", "stat.ML"], "comment": "Preprint. Under Review", "summary": "Low-Rank Adaptation (LoRA) is widely recognized for its parameter-efficient\nfine-tuning of large-scale neural models. However, standard LoRA independently\noptimizes low-rank matrices, which inherently limits its expressivity and\ngeneralization capabilities. While classical tensor-train (TT) decomposition\ncan be separately employed on individual LoRA matrices, this work demonstrates\nthat the classical TT-based approach neither significantly improves parameter\nefficiency nor achieves substantial performance gains. This paper proposes\nTensorGuide, a novel tensor-train-guided adaptation framework to overcome these\nlimitations. TensorGuide generates two correlated low-rank LoRA matrices\nthrough a unified TT structure driven by controlled Gaussian noise. The\nresulting joint TT representation inherently provides structured, low-rank\nadaptations, significantly enhancing expressivity, generalization, and\nparameter efficiency without increasing the number of trainable parameters.\nTheoretically, we justify these improvements through neural tangent kernel\nanalyses, demonstrating superior optimization dynamics and enhanced\ngeneralization. Extensive experiments on quantum dot classification and GPT-2\nfine-tuning benchmarks demonstrate that TensorGuide-based LoRA consistently\noutperforms standard LoRA and TT-LoRA, achieving improved accuracy and\nscalability with fewer parameters.", "AI": {"tldr": "TensorGuide improves LoRA by using a tensor-train-guided framework to generate correlated low-rank matrices, enhancing expressivity, generalization, and parameter efficiency without extra parameters.", "motivation": "Standard LoRA's independent optimization of low-rank matrices limits expressivity and generalization, while classical TT decomposition fails to improve efficiency or performance.", "method": "TensorGuide employs a unified TT structure driven by controlled Gaussian noise to create correlated low-rank LoRA matrices.", "result": "TensorGuide outperforms standard LoRA and TT-LoRA in accuracy and scalability on quantum dot classification and GPT-2 fine-tuning benchmarks.", "conclusion": "TensorGuide provides a superior, parameter-efficient adaptation framework with theoretical and empirical validation."}}
{"id": "2506.17208", "pdf": "https://arxiv.org/pdf/2506.17208", "abs": "https://arxiv.org/abs/2506.17208", "authors": ["Matias Martinez", "Xavier Franch"], "title": "Dissecting the SWE-Bench Leaderboards: Profiling Submitters and Architectures of LLM- and Agent-Based Repair Systems", "categories": ["cs.SE", "cs.AI", "cs.CL"], "comment": null, "summary": "The rapid progress in Automated Program Repair (APR) has been driven by\nadvances in AI, particularly large language models (LLMs) and agent-based\nsystems. SWE-Bench is a recent benchmark designed to evaluate LLM-based repair\nsystems using real issues and pull requests mined from 12 popular open-source\nPython repositories. Its public leaderboards, SWE-Bench Lite and SWE-Bench\nVerified, have become central platforms for tracking progress and comparing\nsolutions. However, because the submission process does not require detailed\ndocumentation, the architectural design and origin of many solutions remain\nunclear. In this paper, we present the first comprehensive study of all\nsubmissions to the SWE-Bench Lite (68 entries) and Verified (79 entries)\nleaderboards, analyzing 67 unique approaches across dimensions such as\nsubmitter type, product availability, LLM usage, and system architecture. Our\nfindings reveal the dominance of proprietary LLMs (especially Claude 3.5/3.7),\nthe presence of both agentic and non-agentic designs, and a contributor base\nspanning from individual developers to large tech companies.", "AI": {"tldr": "A study analyzes 67 unique approaches in SWE-Bench submissions, revealing trends like proprietary LLM dominance and diverse contributor involvement.", "motivation": "To clarify the unclear architectural designs and origins of solutions in SWE-Bench submissions due to lack of detailed documentation.", "method": "Comprehensive analysis of 68 SWE-Bench Lite and 79 Verified entries, examining submitter type, product availability, LLM usage, and system architecture.", "result": "Dominance of proprietary LLMs (e.g., Claude 3.5/3.7), mix of agentic and non-agentic designs, and contributors ranging from individuals to large companies.", "conclusion": "The study highlights key trends in APR solutions, emphasizing the need for better documentation and transparency in future submissions."}}
{"id": "2506.16895", "pdf": "https://arxiv.org/pdf/2506.16895", "abs": "https://arxiv.org/abs/2506.16895", "authors": ["Fabian Gr\u00f6ger", "Shuo Wen", "Huyen Le", "Maria Brbi\u0107"], "title": "With Limited Data for Multimodal Alignment, Let the STRUCTURE Guide You", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": null, "summary": "Multimodal models have demonstrated powerful capabilities in complex tasks\nrequiring multimodal alignment including zero-shot classification and\ncross-modal retrieval. However, existing models typically rely on millions of\npaired multimodal samples, which are prohibitively expensive or infeasible to\nobtain in many domains. In this work, we explore the feasibility of building\nmultimodal models with limited amount of paired data by aligning pretrained\nunimodal foundation models. We show that high-quality alignment is possible\nwith as few as tens of thousands of paired samples$\\unicode{x2013}$less than\n$1\\%$ of the data typically used in the field. To achieve this, we introduce\nSTRUCTURE, an effective regularization technique that preserves the\nneighborhood geometry of the latent space of unimodal encoders. Additionally,\nwe show that aligning last layers is often suboptimal and demonstrate the\nbenefits of aligning the layers with the highest representational similarity\nacross modalities. These two components can be readily incorporated into\nexisting alignment methods, yielding substantial gains across 24 zero-shot\nimage classification and retrieval benchmarks, with average relative\nimprovement of $51.6\\%$ in classification and $91.8\\%$ in retrieval tasks. Our\nresults highlight the effectiveness and broad applicability of our framework\nfor limited-sample multimodal learning and offer a promising path forward for\nresource-constrained domains.", "AI": {"tldr": "The paper proposes STRUCTURE, a method to align pretrained unimodal models with limited paired data, achieving strong performance in multimodal tasks.", "motivation": "Existing multimodal models require vast paired datasets, which are costly or impractical in many domains. This work explores alignment with minimal paired data.", "method": "The method introduces STRUCTURE, a regularization technique preserving latent space geometry, and aligns layers with highest cross-modal similarity.", "result": "Achieves significant improvements (51.6% in classification, 91.8% in retrieval) across 24 benchmarks with minimal data.", "conclusion": "The framework is effective for limited-sample multimodal learning, offering a scalable solution for resource-constrained domains."}}
{"id": "2506.16380", "pdf": "https://arxiv.org/pdf/2506.16380", "abs": "https://arxiv.org/abs/2506.16380", "authors": ["Druva Dhakshinamoorthy", "Avikshit Jha", "Sabyasachi Majumdar", "Devdulal Ghosh", "Ranjita Chakraborty", "Hena Ray"], "title": "Classification of Cattle Behavior and Detection of Heat (Estrus) using Sensor Data", "categories": ["cs.LG", "I.5.1; I.5.4; I.2.10; I.2.6; C.3; J.2; H.4.2"], "comment": "6 pages, 5 figures. Druva Dhakshinamoorthy and Avikshit Jha\n  contributed equally as co-first authors. Work conducted during a summer\n  internship at CDAC Kolkata by students of BITS Pilani", "summary": "This paper presents a novel system for monitoring cattle behavior and\ndetecting estrus (heat) periods using sensor data and machine learning. We\ndesigned and deployed a low-cost Bluetooth-based neck collar equipped with\naccelerometer and gyroscope sensors to capture real-time behavioral data from\nreal cows, which was synced to the cloud. A labeled dataset was created using\nsynchronized CCTV footage to annotate behaviors such as feeding, rumination,\nlying, and others. We evaluated multiple machine learning models -- Support\nVector Machines (SVM), Random Forests (RF), and Convolutional Neural Networks\n(CNN) -- for behavior classification. Additionally, we implemented a Long\nShort-Term Memory (LSTM) model for estrus detection using behavioral patterns\nand anomaly detection. Our system achieved over 93% behavior classification\naccuracy and 96% estrus detection accuracy on a limited test set. The approach\noffers a scalable and accessible solution for precision livestock monitoring,\nespecially in resource-constrained environments.", "AI": {"tldr": "A novel Bluetooth-based collar system with sensors and machine learning monitors cattle behavior and detects estrus with high accuracy.", "motivation": "To provide a scalable, low-cost solution for precision livestock monitoring, especially in resource-limited settings.", "method": "Deployed Bluetooth collars with accelerometer and gyroscope sensors, used CCTV footage for labeling, and tested SVM, RF, CNN, and LSTM models for behavior classification and estrus detection.", "result": "Achieved 93% behavior classification accuracy and 96% estrus detection accuracy.", "conclusion": "The system is effective, scalable, and accessible for livestock monitoring."}}
{"id": "2506.16471", "pdf": "https://arxiv.org/pdf/2506.16471", "abs": "https://arxiv.org/abs/2506.16471", "authors": ["Tara Akhound-Sadegh", "Jungyoon Lee", "Avishek Joey Bose", "Valentin De Bortoli", "Arnaud Doucet", "Michael M. Bronstein", "Dominique Beaini", "Siamak Ravanbakhsh", "Kirill Neklyudov", "Alexander Tong"], "title": "Progressive Inference-Time Annealing of Diffusion Models for Sampling from Boltzmann Densities", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Sampling efficiently from a target unnormalized probability density remains a\ncore challenge, with relevance across countless high-impact scientific\napplications. A promising approach towards this challenge is the design of\namortized samplers that borrow key ideas, such as probability path design, from\nstate-of-the-art generative diffusion models. However, all existing\ndiffusion-based samplers remain unable to draw samples from distributions at\nthe scale of even simple molecular systems. In this paper, we propose\nProgressive Inference-Time Annealing (PITA), a novel framework to learn\ndiffusion-based samplers that combines two complementary interpolation\ntechniques: I.) Annealing of the Boltzmann distribution and II.) Diffusion\nsmoothing. PITA trains a sequence of diffusion models from high to low\ntemperatures by sequentially training each model at progressively higher\ntemperatures, leveraging engineered easy access to samples of the\ntemperature-annealed target density. In the subsequent step, PITA enables\nsimulating the trained diffusion model to procure training samples at a lower\ntemperature for the next diffusion model through inference-time annealing using\na novel Feynman-Kac PDE combined with Sequential Monte Carlo. Empirically, PITA\nenables, for the first time, equilibrium sampling of N-body particle systems,\nAlanine Dipeptide, and tripeptides in Cartesian coordinates with dramatically\nlower energy function evaluations. Code available at:\nhttps://github.com/taraak/pita", "AI": {"tldr": "PITA introduces a novel framework combining annealing and diffusion smoothing for efficient sampling from unnormalized densities, enabling equilibrium sampling of complex systems like N-body particles and peptides.", "motivation": "Efficient sampling from unnormalized densities is crucial for scientific applications, but existing diffusion-based samplers fail at molecular scales.", "method": "PITA combines annealing of the Boltzmann distribution and diffusion smoothing, training sequential diffusion models from high to low temperatures and using inference-time annealing with a novel Feynman-Kac PDE and Sequential Monte Carlo.", "result": "PITA achieves equilibrium sampling of complex systems (N-body particles, Alanine Dipeptide, tripeptides) with fewer energy evaluations.", "conclusion": "PITA advances diffusion-based sampling, enabling practical applications in molecular systems."}}
{"id": "2305.14597", "pdf": "https://arxiv.org/pdf/2305.14597", "abs": "https://arxiv.org/abs/2305.14597", "authors": ["Yiwen Ding", "Jiarui Liu", "Zhiheng Lyu", "Kun Zhang", "Bernhard Schoelkopf", "Zhijing Jin", "Rada Mihalcea"], "title": "Voices of Her: Analyzing Gender Differences in the AI Publication World", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "While several previous studies have analyzed gender bias in research, we are\nstill missing a comprehensive analysis of gender differences in the AI\ncommunity, covering diverse topics and different development trends. Using the\nAI Scholar dataset of 78K researchers in the field of AI, we identify several\ngender differences: (1) Although female researchers tend to have fewer overall\ncitations than males, this citation difference does not hold for all\nacademic-age groups; (2) There exist large gender homophily in co-authorship on\nAI papers; (3) Female first-authored papers show distinct linguistic styles,\nsuch as longer text, more positive emotion words, and more catchy titles than\nmale first-authored papers. Our analysis provides a window into the current\ndemographic trends in our AI community, and encourages more gender equality and\ndiversity in the future. Our code and data are at\nhttps://github.com/causalNLP/ai-scholar-gender.", "AI": {"tldr": "The paper analyzes gender differences in the AI research community, revealing disparities in citations, co-authorship homophily, and linguistic styles in papers authored by women versus men.", "motivation": "To address the lack of comprehensive gender bias analysis in AI research, covering diverse topics and trends.", "method": "Utilized the AI Scholar dataset of 78K researchers to examine citation patterns, co-authorship homophily, and linguistic styles in papers.", "result": "Found gender differences: citation gaps vary by age group, strong co-authorship homophily, and distinct linguistic styles in female-authored papers.", "conclusion": "Highlights current demographic trends in AI, advocating for greater gender equality and diversity."}}
{"id": "2506.16940", "pdf": "https://arxiv.org/pdf/2506.16940", "abs": "https://arxiv.org/abs/2506.16940", "authors": ["Annika Thomas", "Robaire Galliath", "Aleksander Garbuz", "Luke Anger", "Cormac O'Neill", "Trevor Johst", "Dami Thomas", "George Lordos", "Jonathan P. How"], "title": "LunarLoc: Segment-Based Global Localization on the Moon", "categories": ["cs.CV"], "comment": null, "summary": "Global localization is necessary for autonomous operations on the lunar\nsurface where traditional Earth-based navigation infrastructure, such as GPS,\nis unavailable. As NASA advances toward sustained lunar presence under the\nArtemis program, autonomous operations will be an essential component of tasks\nsuch as robotic exploration and infrastructure deployment. Tasks such as\nexcavation and transport of regolith require precise pose estimation, but\nproposed approaches such as visual-inertial odometry (VIO) accumulate odometry\ndrift over long traverses. Precise pose estimation is particularly important\nfor upcoming missions such as the ISRU Pilot Excavator (IPEx) that rely on\nautonomous agents to operate over extended timescales and varied terrain. To\nhelp overcome odometry drift over long traverses, we propose LunarLoc, an\napproach to global localization that leverages instance segmentation for\nzero-shot extraction of boulder landmarks from onboard stereo imagery. Segment\ndetections are used to construct a graph-based representation of the terrain,\nwhich is then aligned with a reference map of the environment captured during a\nprevious session using graph-theoretic data association. This method enables\naccurate and drift-free global localization in visually ambiguous settings.\nLunarLoc achieves sub-cm level accuracy in multi-session global localization\nexperiments, significantly outperforming the state of the art in lunar global\nlocalization. To encourage the development of further methods for global\nlocalization on the Moon, we release our datasets publicly with a playback\nmodule: https://github.com/mit-acl/lunarloc-data.", "AI": {"tldr": "LunarLoc is a global localization method for lunar surface operations, using instance segmentation and graph-based terrain alignment to achieve drift-free, sub-cm accuracy.", "motivation": "Autonomous lunar operations require precise pose estimation without Earth-based navigation like GPS, especially for tasks like robotic exploration and regolith transport.", "method": "LunarLoc uses instance segmentation to extract boulder landmarks from stereo imagery, constructs a terrain graph, and aligns it with a reference map using graph-theoretic data association.", "result": "Achieves sub-cm accuracy in multi-session global localization, outperforming existing lunar localization methods.", "conclusion": "LunarLoc provides a robust solution for lunar global localization, with publicly released datasets to foster further research."}}
{"id": "2506.16392", "pdf": "https://arxiv.org/pdf/2506.16392", "abs": "https://arxiv.org/abs/2506.16392", "authors": ["Gon\u00e7alo Granjal Cruz", "Balazs Renczes", "Mark C Runacres", "Jan Decuyper"], "title": "State-Space Kolmogorov Arnold Networks for Interpretable Nonlinear System Identification", "categories": ["cs.LG", "cs.SY", "eess.SY"], "comment": "Accepted for IEEE Control Systems Letters", "summary": "While accurate, black-box system identification models lack interpretability\nof the underlying system dynamics. This paper proposes State-Space\nKolmogorov-Arnold Networks (SS-KAN) to address this challenge by integrating\nKolmogorov-Arnold Networks within a state-space framework. The proposed model\nis validated on two benchmark systems: the Silverbox and the Wiener-Hammerstein\nbenchmarks. Results show that SS-KAN provides enhanced interpretability due to\nsparsity-promoting regularization and the direct visualization of its learned\nunivariate functions, which reveal system nonlinearities at the cost of\naccuracy when compared to state-of-the-art black-box models, highlighting\nSS-KAN as a promising approach for interpretable nonlinear system\nidentification, balancing accuracy and interpretability of nonlinear system\ndynamics.", "AI": {"tldr": "SS-KAN integrates Kolmogorov-Arnold Networks into a state-space framework for interpretable nonlinear system identification, balancing accuracy and interpretability.", "motivation": "Black-box models lack interpretability of system dynamics, prompting the need for a more transparent approach.", "method": "SS-KAN combines Kolmogorov-Arnold Networks with state-space modeling, validated on Silverbox and Wiener-Hammerstein benchmarks.", "result": "SS-KAN offers enhanced interpretability through sparsity-promoting regularization and visualization of learned univariate functions, though with slight accuracy trade-offs.", "conclusion": "SS-KAN is a promising method for interpretable nonlinear system identification, balancing accuracy and interpretability."}}
{"id": "2506.16475", "pdf": "https://arxiv.org/pdf/2506.16475", "abs": "https://arxiv.org/abs/2506.16475", "authors": ["Yaru Niu", "Yunzhe Zhang", "Mingyang Yu", "Changyi Lin", "Chenhao Li", "Yikai Wang", "Yuxiang Yang", "Wenhao Yu", "Tingnan Zhang", "Bingqing Chen", "Jonathan Francis", "Zhenzhen Li", "Jie Tan", "Ding Zhao"], "title": "Human2LocoMan: Learning Versatile Quadrupedal Manipulation with Human Pretraining", "categories": ["cs.RO", "cs.AI", "cs.LG"], "comment": null, "summary": "Quadrupedal robots have demonstrated impressive locomotion capabilities in\ncomplex environments, but equipping them with autonomous versatile manipulation\nskills in a scalable way remains a significant challenge. In this work, we\nintroduce a cross-embodiment imitation learning system for quadrupedal\nmanipulation, leveraging data collected from both humans and LocoMan, a\nquadruped equipped with multiple manipulation modes. Specifically, we develop a\nteleoperation and data collection pipeline, which unifies and modularizes the\nobservation and action spaces of the human and the robot. To effectively\nleverage the collected data, we propose an efficient modularized architecture\nthat supports co-training and pretraining on structured modality-aligned data\nacross different embodiments. Additionally, we construct the first manipulation\ndataset for the LocoMan robot, covering various household tasks in both\nunimanual and bimanual modes, supplemented by a corresponding human dataset. We\nvalidate our system on six real-world manipulation tasks, where it achieves an\naverage success rate improvement of 41.9% overall and 79.7% under\nout-of-distribution (OOD) settings compared to the baseline. Pretraining with\nhuman data contributes a 38.6% success rate improvement overall and 82.7% under\nOOD settings, enabling consistently better performance with only half the\namount of robot data. Our code, hardware, and data are open-sourced at:\nhttps://human2bots.github.io.", "AI": {"tldr": "A cross-embodiment imitation learning system for quadrupedal manipulation is introduced, leveraging human and robot data to improve success rates in real-world tasks.", "motivation": "Equipping quadrupedal robots with scalable autonomous manipulation skills is a significant challenge.", "method": "Developed a teleoperation and data collection pipeline, proposed a modularized architecture for co-training and pretraining, and constructed a manipulation dataset.", "result": "Achieved a 41.9% average success rate improvement overall and 79.7% under OOD settings; pretraining with human data contributed a 38.6% improvement.", "conclusion": "The system demonstrates scalable and efficient learning for quadrupedal manipulation, with open-sourced resources for further research."}}
{"id": "2312.04684", "pdf": "https://arxiv.org/pdf/2312.04684", "abs": "https://arxiv.org/abs/2312.04684", "authors": ["Zifan Xu", "Haozhu Wang", "Dmitriy Bespalov", "Xian Wu", "Peter Stone", "Yanjun Qi"], "title": "LaRS: Latent Reasoning Skills for Chain-of-Thought Reasoning", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Chain-of-thought (CoT) prompting is a popular in-context learning (ICL)\napproach for large language models (LLMs), especially when tackling complex\nreasoning tasks. Traditional ICL approaches construct prompts using examples\nthat contain questions similar to the input question. However, CoT prompting,\nwhich includes crucial intermediate reasoning steps (rationales) within its\nexamples, necessitates selecting examples based on these rationales rather than\nthe questions themselves. Existing methods require human experts or pre-trained\nLLMs to describe the skill, a high-level abstraction of rationales, to guide\nthe selection. These methods, however, are often costly and difficult to scale.\nInstead, this paper introduces a new approach named Latent Reasoning Skills\n(LaRS) that employs unsupervised learning to create a latent space\nrepresentation of rationales, with a latent variable called a reasoning skill.\nConcurrently, LaRS learns a reasoning policy to determine the required\nreasoning skill for a given question. Then the ICL examples are selected by\naligning the reasoning skills between past examples and the question. This\napproach is theoretically grounded and compute-efficient, eliminating the need\nfor auxiliary LLM inference or manual prompt design. Empirical results\ndemonstrate that LaRS consistently outperforms SOTA skill-based selection\nmethods, processing example banks four times faster, reducing LLM inferences\nduring the selection stage by half, and showing greater robustness to\nsub-optimal example banks.", "AI": {"tldr": "LaRS introduces unsupervised learning to create latent reasoning skills for efficient and scalable CoT prompting, outperforming existing methods.", "motivation": "Traditional CoT prompting methods are costly and hard to scale due to reliance on human experts or pre-trained LLMs for skill description.", "method": "LaRS uses unsupervised learning to create latent representations of rationales (reasoning skills) and a policy to align skills for example selection.", "result": "LaRS outperforms SOTA methods, processes example banks faster, reduces LLM inferences, and is robust to sub-optimal banks.", "conclusion": "LaRS offers a scalable, efficient, and robust alternative to traditional skill-based CoT prompting methods."}}
{"id": "2506.16950", "pdf": "https://arxiv.org/pdf/2506.16950", "abs": "https://arxiv.org/abs/2506.16950", "authors": ["Fanfei Li", "Thomas Klein", "Wieland Brendel", "Robert Geirhos", "Roland S. Zimmermann"], "title": "LAION-C: An Out-of-Distribution Benchmark for Web-Scale Vision Models", "categories": ["cs.CV", "cs.LG"], "comment": "ICML 2025 camera ready version", "summary": "Out-of-distribution (OOD) robustness is a desired property of computer vision\nmodels. Improving model robustness requires high-quality signals from\nrobustness benchmarks to quantify progress. While various benchmark datasets\nsuch as ImageNet-C were proposed in the ImageNet era, most ImageNet-C\ncorruption types are no longer OOD relative to today's large, web-scraped\ndatasets, which already contain common corruptions such as blur or JPEG\ncompression artifacts. Consequently, these benchmarks are no longer well-suited\nfor evaluating OOD robustness in the era of web-scale datasets. Indeed, recent\nmodels show saturating scores on ImageNet-era OOD benchmarks, indicating that\nit is unclear whether models trained on web-scale datasets truly become better\nat OOD generalization or whether they have simply been exposed to the test\ndistortions during training. To address this, we introduce LAION-C as a\nbenchmark alternative for ImageNet-C. LAION-C consists of six novel distortion\ntypes specifically designed to be OOD, even for web-scale datasets such as\nLAION. In a comprehensive evaluation of state-of-the-art models, we find that\nthe LAION-C dataset poses significant challenges to contemporary models,\nincluding MLLMs such as Gemini and GPT-4o. We additionally conducted a\npsychophysical experiment to evaluate the difficulty of our corruptions for\nhuman observers, enabling a comparison of models to lab-quality human\nrobustness data. We observe a paradigm shift in OOD generalization: from humans\noutperforming models, to the best models now matching or outperforming the best\nhuman observers.", "AI": {"tldr": "LAION-C is introduced as a new benchmark for OOD robustness, addressing limitations of older benchmarks like ImageNet-C by including novel distortions not found in web-scale datasets.", "motivation": "Existing benchmarks like ImageNet-C are no longer effective for evaluating OOD robustness due to their corruptions being common in modern web-scale datasets, leading to unclear progress in model generalization.", "method": "LAION-C is proposed with six novel distortion types designed to be OOD for web-scale datasets. State-of-the-art models, including MLLMs, are evaluated, and human robustness is compared via psychophysical experiments.", "result": "LAION-C proves challenging for contemporary models, with top models now matching or surpassing human performance in OOD generalization.", "conclusion": "LAION-C addresses the need for a modern OOD robustness benchmark, revealing a paradigm shift where models can now rival human robustness."}}
{"id": "2506.16396", "pdf": "https://arxiv.org/pdf/2506.16396", "abs": "https://arxiv.org/abs/2506.16396", "authors": ["Alexey Zakharov", "Shimon Whiteson"], "title": "GoalLadder: Incremental Goal Discovery with Vision-Language Models", "categories": ["cs.LG"], "comment": null, "summary": "Natural language can offer a concise and human-interpretable means of\nspecifying reinforcement learning (RL) tasks. The ability to extract rewards\nfrom a language instruction can enable the development of robotic systems that\ncan learn from human guidance; however, it remains a challenging problem,\nespecially in visual environments. Existing approaches that employ large,\npretrained language models either rely on non-visual environment\nrepresentations, require prohibitively large amounts of feedback, or generate\nnoisy, ill-shaped reward functions. In this paper, we propose a novel method,\n$\\textbf{GoalLadder}$, that leverages vision-language models (VLMs) to train RL\nagents from a single language instruction in visual environments. GoalLadder\nworks by incrementally discovering states that bring the agent closer to\ncompleting a task specified in natural language. To do so, it queries a VLM to\nidentify states that represent an improvement in agent's task progress and to\nrank them using pairwise comparisons. Unlike prior work, GoalLadder does not\ntrust VLM's feedback completely; instead, it uses it to rank potential goal\nstates using an ELO-based rating system, thus reducing the detrimental effects\nof noisy VLM feedback. Over the course of training, the agent is tasked with\nminimising the distance to the top-ranked goal in a learned embedding space,\nwhich is trained on unlabelled visual data. This key feature allows us to\nbypass the need for abundant and accurate feedback typically required to train\na well-shaped reward function. We demonstrate that GoalLadder outperforms\nexisting related methods on classic control and robotic manipulation\nenvironments with the average final success rate of $\\sim$95% compared to only\n$\\sim$45% of the best competitor.", "AI": {"tldr": "GoalLadder uses vision-language models (VLMs) to train RL agents from a single language instruction in visual environments, outperforming competitors with a 95% success rate.", "motivation": "To enable robotic systems to learn from human guidance by extracting rewards from language instructions, addressing challenges in visual environments.", "method": "Leverages VLMs to incrementally discover task-progress states, ranks them using pairwise comparisons and an ELO-based system, and minimizes distance to top-ranked goals in a learned embedding space.", "result": "Achieves an average final success rate of ~95%, significantly outperforming competitors (~45%).", "conclusion": "GoalLadder effectively bypasses the need for abundant feedback, providing a robust method for training RL agents from language instructions in visual environments."}}
{"id": "2506.16493", "pdf": "https://arxiv.org/pdf/2506.16493", "abs": "https://arxiv.org/abs/2506.16493", "authors": ["Mehreen Naeem", "Andrew Melnik", "Michael Beetz"], "title": "Grounding Language Models with Semantic Digital Twins for Robotic Planning", "categories": ["cs.RO", "cs.AI"], "comment": null, "summary": "We introduce a novel framework that integrates Semantic Digital Twins (SDTs)\nwith Large Language Models (LLMs) to enable adaptive and goal-driven robotic\ntask execution in dynamic environments. The system decomposes natural language\ninstructions into structured action triplets, which are grounded in contextual\nenvironmental data provided by the SDT. This semantic grounding allows the\nrobot to interpret object affordances and interaction rules, enabling action\nplanning and real-time adaptability. In case of execution failures, the LLM\nutilizes error feedback and SDT insights to generate recovery strategies and\niteratively revise the action plan. We evaluate our approach using tasks from\nthe ALFRED benchmark, demonstrating robust performance across various household\nscenarios. The proposed framework effectively combines high-level reasoning\nwith semantic environment understanding, achieving reliable task completion in\nthe face of uncertainty and failure.", "AI": {"tldr": "A framework integrating Semantic Digital Twins (SDTs) and Large Language Models (LLMs) for adaptive robotic task execution, using natural language instructions and real-time adaptability.", "motivation": "To enable robots to perform tasks in dynamic environments by interpreting natural language instructions and adapting to failures.", "method": "Decomposes instructions into action triplets grounded in SDT data, uses LLMs for planning and recovery strategies.", "result": "Demonstrated robust performance on ALFRED benchmark tasks, achieving reliable task completion despite uncertainty.", "conclusion": "The framework successfully combines high-level reasoning with semantic understanding for adaptive robotic task execution."}}
{"id": "2402.09404", "pdf": "https://arxiv.org/pdf/2402.09404", "abs": "https://arxiv.org/abs/2402.09404", "authors": ["Siwei Yang", "Bingchen Zhao", "Cihang Xie"], "title": "AQA-Bench: An Interactive Benchmark for Evaluating LLMs' Sequential Reasoning Ability", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "This paper introduces AQA-Bench, a novel benchmark to assess the sequential\nreasoning capabilities of large language models (LLMs) in algorithmic contexts,\nsuch as depth-first search (DFS). The key feature of our evaluation benchmark\nlies in its interactive evaluation protocol - for example, in DFS, the\navailability of each node's connected edge is contingent upon the model's\ntraversal to that node, thereby necessitating the LLM's ability to effectively\nremember visited nodes and strategize subsequent moves considering the possible\nenvironmental feedback in the future steps. We comprehensively build AQA-Bench\nwith three different algorithms, namely binary search, depth-first search, and\nbreadth-first search, and to evaluate the sequential reasoning ability of 14\ndifferent LLMs. Our investigations reveal several interesting findings: (1)\nClosed-source models like GPT-4 and Gemini generally show much stronger\nsequential reasoning ability, significantly outperforming open-source LLMs. (2)\nNaively providing in-context examples may inadvertently hurt few-shot\nperformance in an interactive environment due to over-fitting to examples. (3)\nInstead of using optimal steps from another test case as the in-context\nexample, a very limited number of predecessor steps in the current test case\nfollowing the optimal policy can substantially boost small models' performance.\n(4) The performance gap between weak models and strong models is greatly due to\nthe incapability of weak models to start well. (5) The scaling correlation\nbetween performance and model size is not always significant, sometimes even\nshowcasing an inverse trend. We hope our study can catalyze future work on\nadvancing the understanding and enhancement of LLMs' capabilities in sequential\nreasoning. The code is available at https://github.com/UCSC-VLAA/AQA-Bench.", "AI": {"tldr": "AQA-Bench is a new benchmark for evaluating sequential reasoning in LLMs using interactive tasks like DFS, revealing insights about model performance and in-context learning.", "motivation": "To assess and improve LLMs' sequential reasoning abilities in algorithmic tasks, addressing gaps in current evaluation methods.", "method": "Developed AQA-Bench with three algorithms (binary search, DFS, BFS) and evaluated 14 LLMs using an interactive protocol.", "result": "Closed-source models (e.g., GPT-4) outperformed open-source ones; in-context examples can hurt performance; small models benefit from predecessor steps.", "conclusion": "The study highlights key factors in LLMs' sequential reasoning and encourages further research to enhance these capabilities."}}
{"id": "2506.16960", "pdf": "https://arxiv.org/pdf/2506.16960", "abs": "https://arxiv.org/abs/2506.16960", "authors": ["Wenyang Luo", "Haina Qin", "Zewen Chen", "Libin Wang", "Dandan Zheng", "Yuming Li", "Yufan Liu", "Bing Li", "Weiming Hu"], "title": "Visual-Instructed Degradation Diffusion for All-in-One Image Restoration", "categories": ["cs.CV", "68U10", "I.4.4"], "comment": "CVPR2025 Final Version; Corresponding Author: Bing Li", "summary": "Image restoration tasks like deblurring, denoising, and dehazing usually need\ndistinct models for each degradation type, restricting their generalization in\nreal-world scenarios with mixed or unknown degradations. In this work, we\npropose \\textbf{Defusion}, a novel all-in-one image restoration framework that\nutilizes visual instruction-guided degradation diffusion. Unlike existing\nmethods that rely on task-specific models or ambiguous text-based priors,\nDefusion constructs explicit \\textbf{visual instructions} that align with the\nvisual degradation patterns. These instructions are grounded by applying\ndegradations to standardized visual elements, capturing intrinsic degradation\nfeatures while agnostic to image semantics. Defusion then uses these visual\ninstructions to guide a diffusion-based model that operates directly in the\ndegradation space, where it reconstructs high-quality images by denoising the\ndegradation effects with enhanced stability and generalizability. Comprehensive\nexperiments demonstrate that Defusion outperforms state-of-the-art methods\nacross diverse image restoration tasks, including complex and real-world\ndegradations.", "AI": {"tldr": "Defusion is an all-in-one image restoration framework using visual instruction-guided degradation diffusion, outperforming task-specific models for mixed or unknown degradations.", "motivation": "Existing models are limited to specific degradation types, lacking generalization for real-world mixed or unknown degradations.", "method": "Defusion constructs visual instructions aligned with degradation patterns, guiding a diffusion-based model to denoise degradation effects.", "result": "Defusion outperforms state-of-the-art methods across diverse restoration tasks, including complex and real-world degradations.", "conclusion": "Defusion offers a generalized, stable solution for image restoration, handling mixed or unknown degradations effectively."}}
{"id": "2506.16404", "pdf": "https://arxiv.org/pdf/2506.16404", "abs": "https://arxiv.org/abs/2506.16404", "authors": ["Alba Carballo-Castro", "Manuel Madeira", "Yiming Qin", "Dorina Thanou", "Pascal Frossard"], "title": "Generating Directed Graphs with Dual Attention and Asymmetric Encoding", "categories": ["cs.LG"], "comment": null, "summary": "Directed graphs naturally model systems with asymmetric, ordered\nrelationships, essential to applications in biology, transportation, social\nnetworks, and visual understanding. Generating such graphs enables tasks such\nas simulation, data augmentation and novel instance discovery; however,\ndirected graph generation remains underexplored. We identify two key factors\nlimiting progress in this direction: first, modeling edge directionality\nintroduces a substantially larger dependency space, making the underlying\ndistribution harder to learn; second, the absence of standardized benchmarks\nhinders rigorous evaluation. Addressing the former requires more expressive\nmodels that are sensitive to directional topologies. We propose Directo, the\nfirst generative model for directed graphs built upon the discrete flow\nmatching framework. Our approach combines: (i) principled positional encodings\ntailored to asymmetric pairwise relations, (ii) a dual-attention mechanism\ncapturing both incoming and outgoing dependencies, and (iii) a robust, discrete\ngenerative framework. To support evaluation, we introduce a benchmark suite\ncovering synthetic and real-world datasets. It shows that our method performs\nstrongly across diverse settings and even competes with specialized models for\nparticular classes, such as directed acyclic graphs. Our results highlight the\neffectiveness and generality of our approach, establishing a solid foundation\nfor future research in directed graph generation.", "AI": {"tldr": "The paper introduces Directo, the first generative model for directed graphs, addressing challenges in modeling edge directionality and lack of benchmarks. It combines positional encodings, dual-attention, and a discrete framework, outperforming specialized models.", "motivation": "Directed graphs are crucial in various fields, but their generation is underexplored due to challenges like complex dependency spaces and lack of standardized benchmarks.", "method": "Directo uses discrete flow matching, with tailored positional encodings, a dual-attention mechanism, and a robust generative framework.", "result": "Directo performs strongly across diverse settings, even competing with specialized models, and introduces a benchmark suite for evaluation.", "conclusion": "The paper establishes a solid foundation for directed graph generation, demonstrating Directo's effectiveness and generality."}}
{"id": "2506.16506", "pdf": "https://arxiv.org/pdf/2506.16506", "abs": "https://arxiv.org/abs/2506.16506", "authors": ["Ronald Skorobogat", "Karsten Roth", "Mariana-Iuliana Georgescu", "Zeynep Akata"], "title": "Subspace-Boosted Model Merging", "categories": ["cs.LG", "cs.AI", "cs.CV"], "comment": "21 pages (main + supp)", "summary": "Model merging enables the combination of multiple specialized expert models\ninto a single model capable of performing multiple tasks. However, the benefits\nof merging an increasing amount of specialized experts generally lead to\ndiminishing returns and reduced overall performance gains. In this work, we\noffer an explanation and analysis from a task arithmetic perspective; revealing\nthat as the merging process (across numerous existing merging methods)\ncontinues for more and more experts, the associated task vector space\nexperiences rank collapse. To mitigate this issue, we introduce Subspace\nBoosting, which operates on the singular value decomposed task vector space and\nmaintains task vector ranks. Subspace Boosting raises merging efficacy for up\nto 20 expert models by large margins of more than 10% when evaluated on vision\nbenchmarks. Moreover, we propose employing Higher-Order Generalized Singular\nValue Decomposition to further quantify task similarity, offering a new\ninterpretable perspective on model merging.", "AI": {"tldr": "Model merging combines expert models but faces diminishing returns due to rank collapse in task vector space. Subspace Boosting mitigates this, improving merging efficacy by over 10% for up to 20 models.", "motivation": "To address diminishing returns in model merging caused by rank collapse in task vector spaces.", "method": "Introduces Subspace Boosting, which maintains task vector ranks using singular value decomposition, and employs Higher-Order Generalized SVD for task similarity analysis.", "result": "Subspace Boosting improves merging efficacy by over 10% for up to 20 expert models on vision benchmarks.", "conclusion": "Subspace Boosting effectively mitigates rank collapse, enhancing model merging performance and providing interpretable task similarity insights."}}
{"id": "2404.12041", "pdf": "https://arxiv.org/pdf/2404.12041", "abs": "https://arxiv.org/abs/2404.12041", "authors": ["Siya Qi", "Lin Gui", "Yulan He", "Zheng Yuan"], "title": "A Survey of Automatic Hallucination Evaluation on Natural Language Generation", "categories": ["cs.CL", "cs.AI"], "comment": "30 pages", "summary": "The proliferation of Large Language Models (LLMs) has introduced a critical\nchallenge: accurate hallucination evaluation that ensures model reliability.\nWhile Automatic Hallucination Evaluation (AHE) has emerged as essential, the\nfield suffers from methodological fragmentation, hindering both theoretical\nunderstanding and practical advancement. This survey addresses this critical\ngap through a comprehensive analysis of 74 evaluation methods, revealing that\n74% specifically target LLMs, a paradigm shift that demands new evaluation\nframeworks. We formulate a unified evaluation pipeline encompassing datasets\nand benchmarks, evidence collection strategies, and comparison mechanisms,\nsystematically documenting the evolution from pre-LLM to post-LLM\nmethodologies. Beyond taxonomical organization, we identify fundamental\nlimitations in current approaches and their implications for real-world\ndeployment. To guide future research, we delineate key challenges and propose\nstrategic directions, including enhanced interpretability mechanisms and\nintegration of application-specific evaluation criteria, ultimately providing a\nroadmap for developing more robust and practical hallucination evaluation\nsystems.", "AI": {"tldr": "A survey analyzing 74 hallucination evaluation methods for LLMs, highlighting a shift in focus and proposing a unified pipeline to address fragmentation and improve reliability.", "motivation": "The challenge of accurate hallucination evaluation in LLMs due to methodological fragmentation and the need for new frameworks.", "method": "Comprehensive analysis of 74 evaluation methods, formulation of a unified pipeline, and identification of limitations.", "result": "74% of methods target LLMs, revealing a paradigm shift and the need for improved evaluation frameworks.", "conclusion": "Proposes strategic directions for future research, including interpretability and application-specific criteria, to enhance hallucination evaluation systems."}}
{"id": "2506.16991", "pdf": "https://arxiv.org/pdf/2506.16991", "abs": "https://arxiv.org/abs/2506.16991", "authors": ["Binbin Xiang", "Maciej Wielgosz", "Stefano Puliti", "Kamil Kr\u00e1l", "Martin Kr\u016f\u010dek", "Azim Missarov", "Rasmus Astrup"], "title": "ForestFormer3D: A Unified Framework for End-to-End Segmentation of Forest LiDAR 3D Point Clouds", "categories": ["cs.CV"], "comment": null, "summary": "The segmentation of forest LiDAR 3D point clouds, including both individual\ntree and semantic segmentation, is fundamental for advancing forest management\nand ecological research. However, current approaches often struggle with the\ncomplexity and variability of natural forest environments. We present\nForestFormer3D, a new unified and end-to-end framework designed for precise\nindividual tree and semantic segmentation. ForestFormer3D incorporates\nISA-guided query point selection, a score-based block merging strategy during\ninference, and a one-to-many association mechanism for effective training. By\ncombining these new components, our model achieves state-of-the-art performance\nfor individual tree segmentation on the newly introduced FOR-instanceV2\ndataset, which spans diverse forest types and regions. Additionally,\nForestFormer3D generalizes well to unseen test sets (Wytham woods and LAUTx),\nshowcasing its robustness across different forest conditions and sensor\nmodalities. The FOR-instanceV2 dataset and the ForestFormer3D code will be\nreleased soon.", "AI": {"tldr": "ForestFormer3D is a new framework for precise forest LiDAR point cloud segmentation, achieving state-of-the-art performance and robustness across diverse forests.", "motivation": "Current methods struggle with the complexity of natural forests, necessitating a more effective solution for tree and semantic segmentation.", "method": "ForestFormer3D uses ISA-guided query point selection, score-based block merging, and a one-to-many association mechanism for training.", "result": "The model excels on the FOR-instanceV2 dataset and generalizes well to unseen test sets like Wytham woods and LAUTx.", "conclusion": "ForestFormer3D is a robust, unified solution for forest segmentation, with plans to release the dataset and code."}}
{"id": "2506.16428", "pdf": "https://arxiv.org/pdf/2506.16428", "abs": "https://arxiv.org/abs/2506.16428", "authors": ["Dian Meng", "Zhiguang Cao", "Yaoxin Wu", "Yaqing Hou", "Hongwei Ge", "Qiang Zhang"], "title": "EFormer: An Effective Edge-based Transformer for Vehicle Routing Problems", "categories": ["cs.LG"], "comment": null, "summary": "Recent neural heuristics for the Vehicle Routing Problem (VRP) primarily rely\non node coordinates as input, which may be less effective in practical\nscenarios where real cost metrics-such as edge-based distances-are more\nrelevant. To address this limitation, we introduce EFormer, an Edge-based\nTransformer model that uses edge as the sole input for VRPs. Our approach\nemploys a precoder module with a mixed-score attention mechanism to convert\nedge information into temporary node embeddings. We also present a parallel\nencoding strategy characterized by a graph encoder and a node encoder, each\nresponsible for processing graph and node embeddings in distinct feature\nspaces, respectively. This design yields a more comprehensive representation of\nthe global relationships among edges. In the decoding phase, parallel context\nembedding and multi-query integration are used to compute separate attention\nmechanisms over the two encoded embeddings, facilitating efficient path\nconstruction. We train EFormer using reinforcement learning in an\nautoregressive manner. Extensive experiments on the Traveling Salesman Problem\n(TSP) and Capacitated Vehicle Routing Problem (CVRP) reveal that EFormer\noutperforms established baselines on synthetic datasets, including large-scale\nand diverse distributions. Moreover, EFormer demonstrates strong generalization\non real-world instances from TSPLib and CVRPLib. These findings confirm the\neffectiveness of EFormer's core design in solving VRPs.", "AI": {"tldr": "EFormer, an Edge-based Transformer model, improves VRP solutions by using edge inputs and parallel encoding, outperforming baselines on synthetic and real-world datasets.", "motivation": "Traditional neural heuristics for VRPs rely on node coordinates, which may not reflect real-world edge-based cost metrics effectively.", "method": "EFormer uses edge inputs, a precoder module for node embeddings, and parallel encoding (graph and node encoders) for global edge relationships. Decoding involves parallel context embedding and multi-query integration.", "result": "EFormer outperforms baselines on TSP and CVRP, including large-scale and diverse datasets, and generalizes well to real-world instances.", "conclusion": "EFormer's design effectively addresses VRP limitations by leveraging edge-based inputs and parallel encoding, demonstrating strong performance and generalization."}}
{"id": "2506.16546", "pdf": "https://arxiv.org/pdf/2506.16546", "abs": "https://arxiv.org/abs/2506.16546", "authors": ["Liyang Yu", "Tianyi Wang", "Junfeng Jiao", "Fengwu Shan", "Hongqing Chu", "Bingzhao Gao"], "title": "BIDA: A Bi-level Interaction Decision-making Algorithm for Autonomous Vehicles in Dynamic Traffic Scenarios", "categories": ["cs.RO", "cs.AI", "cs.ET", "cs.LG", "cs.SY", "eess.SY"], "comment": "6 pages, 3 figures, 4 tables, accepted for IEEE Intelligent Vehicles\n  (IV) Symposium 2025", "summary": "In complex real-world traffic environments, autonomous vehicles (AVs) need to\ninteract with other traffic participants while making real-time and\nsafety-critical decisions accordingly. The unpredictability of human behaviors\nposes significant challenges, particularly in dynamic scenarios, such as\nmulti-lane highways and unsignalized T-intersections. To address this gap, we\ndesign a bi-level interaction decision-making algorithm (BIDA) that integrates\ninteractive Monte Carlo tree search (MCTS) with deep reinforcement learning\n(DRL), aiming to enhance interaction rationality, efficiency and safety of AVs\nin dynamic key traffic scenarios. Specifically, we adopt three types of DRL\nalgorithms to construct a reliable value network and policy network, which\nguide the online deduction process of interactive MCTS by assisting in value\nupdate and node selection. Then, a dynamic trajectory planner and a trajectory\ntracking controller are designed and implemented in CARLA to ensure smooth\nexecution of planned maneuvers. Experimental evaluations demonstrate that our\nBIDA not only enhances interactive deduction and reduces computational costs,\nbut also outperforms other latest benchmarks, which exhibits superior safety,\nefficiency and interaction rationality under varying traffic conditions.", "AI": {"tldr": "A bi-level interaction decision-making algorithm (BIDA) combining MCTS and DRL improves AV safety and efficiency in dynamic traffic.", "motivation": "Address unpredictability of human behaviors in complex traffic scenarios like highways and T-intersections.", "method": "Integrates interactive MCTS with DRL for value and policy networks, plus dynamic trajectory planning in CARLA.", "result": "BIDA outperforms benchmarks, enhancing safety, efficiency, and interaction rationality.", "conclusion": "BIDA effectively improves AV decision-making in dynamic traffic environments."}}
{"id": "2406.04220", "pdf": "https://arxiv.org/pdf/2406.04220", "abs": "https://arxiv.org/abs/2406.04220", "authors": ["Shaina Raza", "Mizanur Rahman", "Michael R. Zhang"], "title": "BEADs: Bias Evaluation Across Domains", "categories": ["cs.CL", "cs.AI"], "comment": "under review", "summary": "Recent advancements in large language models (LLMs) have significantly\nimproved natural language processing (NLP) applications. However, these models\noften inherit biases from their training data. While several datasets exist for\nbias detection, most are limited to one or two NLP tasks, typically\nclassification or evaluation, and lack comprehensive coverage across a broader\nrange of tasks. To address this gap, we introduce the Bias Evaluations Across\nDomains (BEADs) dataset, designed to support a wide range of NLP tasks,\nincluding text classification, token classification, bias quantification, and\nbenign language generation. A key contribution of this work is the\ngold-standard annotation provided by GPT-4 for scalability, with expert\nverification to ensure high reliability. BEADs can be used for both fine-tuning\nmodels (for classification and generation tasks) and evaluating LLM behavior.\nOur findings show that BEADs effectively surfaces various biases during model\nfine-tuning and helps reduce biases in language generation tasks while\nmaintaining output quality. The dataset also highlights prevalent demographic\nbiases in LLMs during evaluation. We release BEADs as a practical resource for\ndetecting and mitigating bias across domains, supporting the development of\nresponsible AI systems. Project: https://vectorinstitute.github.io/BEAD/ Data:\nhttps://huggingface.co/datasets/shainar/BEAD", "AI": {"tldr": "The paper introduces the BEADs dataset to address the lack of comprehensive bias evaluation tools in NLP, supporting multiple tasks and leveraging GPT-4 annotations for scalability.", "motivation": "Existing bias detection datasets are limited in scope, often covering only one or two NLP tasks, which restricts their utility for broader bias mitigation efforts.", "method": "The authors develop the BEADs dataset, annotated by GPT-4 and verified by experts, to support diverse NLP tasks like classification, generation, and bias quantification.", "result": "BEADs effectively identifies biases during model fine-tuning, reduces biases in generation tasks, and highlights demographic biases in LLMs.", "conclusion": "BEADs is released as a resource for detecting and mitigating bias in NLP, promoting responsible AI development."}}
{"id": "2506.16994", "pdf": "https://arxiv.org/pdf/2506.16994", "abs": "https://arxiv.org/abs/2506.16994", "authors": ["Yasir Ali Farrukh", "Syed Wali", "Irfan Khan", "Nathaniel D. Bastian"], "title": "Prmpt2Adpt: Prompt-Based Zero-Shot Domain Adaptation for Resource-Constrained Environments", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "Unsupervised Domain Adaptation (UDA) is a critical challenge in real-world\nvision systems, especially in resource-constrained environments like drones,\nwhere memory and computation are limited. Existing prompt-driven UDA methods\ntypically rely on large vision-language models and require full access to\nsource-domain data during adaptation, limiting their applicability. In this\nwork, we propose Prmpt2Adpt, a lightweight and efficient zero-shot domain\nadaptation framework built around a teacher-student paradigm guided by\nprompt-based feature alignment. At the core of our method is a distilled and\nfine-tuned CLIP model, used as the frozen backbone of a Faster R-CNN teacher. A\nsmall set of low-level source features is aligned to the target domain\nsemantics-specified only through a natural language prompt-via Prompt-driven\nInstance Normalization (PIN). These semantically steered features are used to\nbriefly fine-tune the detection head of the teacher model. The adapted teacher\nthen generates high-quality pseudo-labels, which guide the on-the-fly\nadaptation of a compact student model. Experiments on the MDS-A dataset\ndemonstrate that Prmpt2Adpt achieves competitive detection performance compared\nto state-of-the-art methods, while delivering up to 7x faster adaptation and 5x\nfaster inference speed using few source images-making it a practical and\nscalable solution for real-time adaptation in low-resource domains.", "AI": {"tldr": "Prmpt2Adpt is a lightweight, zero-shot UDA framework using prompt-driven feature alignment and a teacher-student model for efficient domain adaptation in resource-limited settings.", "motivation": "Addressing the limitations of existing UDA methods, which rely on large models and full source data access, Prmpt2Adpt aims for practicality in low-resource environments like drones.", "method": "Uses a distilled CLIP model as a frozen backbone for a Faster R-CNN teacher, aligns source features to target semantics via Prompt-driven Instance Normalization (PIN), and fine-tunes the detection head. A student model is adapted using pseudo-labels from the teacher.", "result": "Achieves competitive detection performance on MDS-A dataset, with 7x faster adaptation and 5x faster inference speed using few source images.", "conclusion": "Prmpt2Adpt is a scalable, efficient solution for real-time domain adaptation in low-resource domains."}}
{"id": "2506.16436", "pdf": "https://arxiv.org/pdf/2506.16436", "abs": "https://arxiv.org/abs/2506.16436", "authors": ["Antonio Giulio Coretti", "Mattia Varile", "Mario Edoardo Bertaina"], "title": "An efficient neuromorphic approach for collision avoidance combining Stack-CNN with event cameras", "categories": ["cs.LG"], "comment": "18th International Conference on Space Operations - Safety and\n  sustainability of Space Operations (SSU)", "summary": "Space debris poses a significant threat, driving research into active and\npassive mitigation strategies. This work presents an innovative collision\navoidance system utilizing event-based cameras - a novel imaging technology\nwell-suited for Space Situational Awareness (SSA) and Space Traffic Management\n(STM). The system, employing a Stack-CNN algorithm (previously used for meteor\ndetection), analyzes real-time event-based camera data to detect faint moving\nobjects. Testing on terrestrial data demonstrates the algorithm's ability to\nenhance signal-to-noise ratio, offering a promising approach for on-board space\nimaging and improving STM/SSA operations.", "AI": {"tldr": "A collision avoidance system using event-based cameras and a Stack-CNN algorithm is proposed for space debris detection, showing promise for Space Situational Awareness and Traffic Management.", "motivation": "Space debris is a growing threat, necessitating advanced detection and mitigation strategies.", "method": "The system uses event-based cameras and a Stack-CNN algorithm to analyze real-time data for detecting faint moving objects.", "result": "Terrestrial testing shows the algorithm improves signal-to-noise ratio, enhancing detection capabilities.", "conclusion": "The approach is promising for on-board space imaging and improving STM/SSA operations."}}
{"id": "2506.16553", "pdf": "https://arxiv.org/pdf/2506.16553", "abs": "https://arxiv.org/abs/2506.16553", "authors": ["Soroush H. Zargarbashi", "Mohammad Sadegh Akhondzadeh", "Aleksandar Bojchevski"], "title": "One Sample is Enough to Make Conformal Prediction Robust", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Given any model, conformal prediction (CP) returns prediction sets guaranteed\nto include the true label with high adjustable probability. Robust CP (RCP)\nextends this to inputs with worst-case noise. A well-established approach is to\nuse randomized smoothing for RCP since it is applicable to any black-box model\nand provides smaller sets compared to deterministic methods. However, current\nsmoothing-based RCP requires many model forward passes per each input which is\ncomputationally expensive. We show that conformal prediction attains some\nrobustness even with a forward pass on a single randomly perturbed input. Using\nany binary certificate we propose a single sample robust CP (RCP1). Our\napproach returns robust sets with smaller average set size compared to SOTA\nmethods which use many (e.g. around 100) passes per input. Our key insight is\nto certify the conformal prediction procedure itself rather than individual\nscores. Our approach is agnostic to the setup (classification and regression).\nWe further extend our approach to smoothing-based robust conformal risk\ncontrol.", "AI": {"tldr": "The paper introduces RCP1, a single-sample robust conformal prediction method that reduces computational cost while maintaining robustness and smaller prediction sets compared to existing methods.", "motivation": "Current robust conformal prediction (RCP) methods using randomized smoothing are computationally expensive due to multiple model forward passes per input. The goal is to achieve robustness with fewer passes.", "method": "The authors propose RCP1, which uses a single randomly perturbed input and a binary certificate to certify the conformal prediction procedure itself, not individual scores. This method is applicable to classification and regression.", "result": "RCP1 achieves robust prediction sets with smaller average size compared to state-of-the-art methods that require many (e.g., 100) passes per input.", "conclusion": "RCP1 offers a computationally efficient and robust alternative to existing RCP methods, with broader applicability to different setups like conformal risk control."}}
{"id": "2407.02397", "pdf": "https://arxiv.org/pdf/2407.02397", "abs": "https://arxiv.org/abs/2407.02397", "authors": ["Manya Wadhwa", "Xinyu Zhao", "Junyi Jessy Li", "Greg Durrett"], "title": "Learning to Refine with Fine-Grained Natural Language Feedback", "categories": ["cs.CL"], "comment": "Code and models available at: https://github.com/ManyaWadhwa/DCR;\n  Findings of EMNLP 2024", "summary": "Recent work has explored the capability of large language models (LLMs) to\nidentify and correct errors in LLM-generated responses. These refinement\napproaches frequently evaluate what sizes of models are able to do refinement\nfor what problems, but less attention is paid to what effective feedback for\nrefinement looks like. In this work, we propose looking at refinement with\nfeedback as a composition of three distinct LLM competencies: (1) detection of\nbad generations; (2) fine-grained natural language critique generation; (3)\nrefining with fine-grained feedback. The first step can be implemented with a\nhigh-performing discriminative model and steps 2 and 3 can be implemented\neither via prompted or fine-tuned LLMs. A key property of the proposed Detect,\nCritique, Refine (\"DCR\") method is that the step 2 critique model can give\nfine-grained feedback about errors, made possible by offloading the\ndiscrimination to a separate model in step 1. We show that models of different\ncapabilities benefit from refining with DCR on the task of improving factual\nconsistency of document grounded summaries. Overall, DCR consistently\noutperforms existing end-to-end refinement approaches and current trained\nmodels not fine-tuned for factuality critiquing.", "AI": {"tldr": "The paper introduces the Detect, Critique, Refine (DCR) method for improving LLM-generated responses by breaking refinement into three steps: error detection, critique generation, and refinement with feedback. DCR outperforms existing approaches.", "motivation": "Existing refinement methods focus on model sizes and problem types but overlook effective feedback. The paper aims to address this gap by proposing a structured feedback approach.", "method": "DCR involves three steps: (1) detecting errors with a discriminative model, (2) generating fine-grained critiques, and (3) refining responses using feedback. Steps 2 and 3 use prompted or fine-tuned LLMs.", "result": "DCR improves factual consistency in document summaries and outperforms end-to-end refinement methods and non-factuality-tuned models.", "conclusion": "DCR provides a more effective framework for refining LLM outputs by leveraging structured feedback, demonstrating superior performance over existing methods."}}
{"id": "2506.17004", "pdf": "https://arxiv.org/pdf/2506.17004", "abs": "https://arxiv.org/abs/2506.17004", "authors": ["Hanlin Wu", "Pengfei Lin", "Ehsan Javanmardi", "Naren Bao", "Bo Qian", "Hao Si", "Manabu Tsukada"], "title": "A Synthetic Benchmark for Collaborative 3D Semantic Occupancy Prediction in V2X Autonomous Driving", "categories": ["cs.CV"], "comment": null, "summary": "3D semantic occupancy prediction is an emerging perception paradigm in\nautonomous driving, providing a voxel-level representation of both geometric\ndetails and semantic categories. However, the perception capability of a single\nvehicle is inherently constrained by occlusion, restricted sensor range, and\nnarrow viewpoints. To address these limitations, collaborative perception\nenables the exchange of complementary information, thereby enhancing the\ncompleteness and accuracy. In the absence of a dedicated dataset for\ncollaborative 3D semantic occupancy prediction, we augment an existing\ncollaborative perception dataset by replaying it in CARLA with a\nhigh-resolution semantic voxel sensor to provide dense and comprehensive\noccupancy annotations. In addition, we establish benchmarks with varying\nprediction ranges designed to systematically assess the impact of spatial\nextent on collaborative prediction. We further develop a baseline model that\nperforms inter-agent feature fusion via spatial alignment and attention\naggregation. Experimental results demonstrate that our baseline model\nconsistently outperforms single-agent models, with increasing gains observed as\nthe prediction range expands.", "AI": {"tldr": "The paper introduces collaborative 3D semantic occupancy prediction for autonomous driving, addressing limitations of single-vehicle perception by leveraging shared information. It augments an existing dataset with dense occupancy annotations and benchmarks varying prediction ranges. A baseline model with inter-agent feature fusion outperforms single-agent models, especially at larger ranges.", "motivation": "Single-vehicle perception is limited by occlusion, sensor range, and viewpoints. Collaborative perception can enhance completeness and accuracy by exchanging complementary information.", "method": "Augment an existing dataset with dense semantic voxel annotations in CARLA, establish benchmarks for varying prediction ranges, and develop a baseline model using spatial alignment and attention aggregation for inter-agent feature fusion.", "result": "The baseline model consistently outperforms single-agent models, with greater improvements as the prediction range increases.", "conclusion": "Collaborative 3D semantic occupancy prediction improves perception in autonomous driving, with demonstrated benefits over single-agent approaches, particularly for larger spatial extents."}}
{"id": "2506.16460", "pdf": "https://arxiv.org/pdf/2506.16460", "abs": "https://arxiv.org/abs/2506.16460", "authors": ["John Abascal", "Nicol\u00e1s Berrios", "Alina Oprea", "Jonathan Ullman", "Adam Smith", "Matthew Jagielski"], "title": "Black-Box Privacy Attacks on Shared Representations in Multitask Learning", "categories": ["cs.LG", "cs.CR"], "comment": "30 pages, 8 figures", "summary": "Multitask learning (MTL) has emerged as a powerful paradigm that leverages\nsimilarities among multiple learning tasks, each with insufficient samples to\ntrain a standalone model, to solve them simultaneously while minimizing data\nsharing across users and organizations. MTL typically accomplishes this goal by\nlearning a shared representation that captures common structure among the tasks\nby embedding data from all tasks into a common feature space. Despite being\ndesigned to be the smallest unit of shared information necessary to effectively\nlearn patterns across multiple tasks, these shared representations can\ninadvertently leak sensitive information about the particular tasks they were\ntrained on.\n  In this work, we investigate what information is revealed by the shared\nrepresentations through the lens of inference attacks. Towards this, we propose\na novel, black-box task-inference threat model where the adversary, given the\nembedding vectors produced by querying the shared representation on samples\nfrom a particular task, aims to determine whether that task was present when\ntraining the shared representation. We develop efficient, purely black-box\nattacks on machine learning models that exploit the dependencies between\nembeddings from the same task without requiring shadow models or labeled\nreference data. We evaluate our attacks across vision and language domains for\nmultiple use cases of MTL and demonstrate that even with access only to fresh\ntask samples rather than training data, a black-box adversary can successfully\ninfer a task's inclusion in training. To complement our experiments, we provide\ntheoretical analysis of a simplified learning setting and show a strict\nseparation between adversaries with training samples and fresh samples from the\ntarget task's distribution.", "AI": {"tldr": "The paper investigates privacy risks in multitask learning (MTL) by analyzing shared representations, proposing black-box task-inference attacks, and demonstrating their effectiveness across domains.", "motivation": "MTL's shared representations, while efficient, may leak sensitive task information, raising privacy concerns.", "method": "Proposes black-box task-inference attacks using embedding vectors without shadow models or labeled data.", "result": "Shows adversaries can infer task inclusion in training using fresh samples, validated across vision and language domains.", "conclusion": "Highlights privacy risks in MTL and provides theoretical insights into adversary capabilities."}}
{"id": "2506.16565", "pdf": "https://arxiv.org/pdf/2506.16565", "abs": "https://arxiv.org/abs/2506.16565", "authors": ["Yuxin Chen", "Jianglan Wei", "Chenfeng Xu", "Boyi Li", "Masayoshi Tomizuka", "Andrea Bajcsy", "Ran Tian"], "title": "Reimagination with Test-time Observation Interventions: Distractor-Robust World Model Predictions for Visual Model Predictive Control", "categories": ["cs.RO", "cs.AI", "cs.CV"], "comment": null, "summary": "World models enable robots to \"imagine\" future observations given current\nobservations and planned actions, and have been increasingly adopted as\ngeneralized dynamics models to facilitate robot learning. Despite their\npromise, these models remain brittle when encountering novel visual distractors\nsuch as objects and background elements rarely seen during training.\nSpecifically, novel distractors can corrupt action outcome predictions, causing\ndownstream failures when robots rely on the world model imaginations for\nplanning or action verification. In this work, we propose Reimagination with\nObservation Intervention (ReOI), a simple yet effective test-time strategy that\nenables world models to predict more reliable action outcomes in open-world\nscenarios where novel and unanticipated visual distractors are inevitable.\nGiven the current robot observation, ReOI first detects visual distractors by\nidentifying which elements of the scene degrade in physically implausible ways\nduring world model prediction. Then, it modifies the current observation to\nremove these distractors and bring the observation closer to the training\ndistribution. Finally, ReOI \"reimagines\" future outcomes with the modified\nobservation and reintroduces the distractors post-hoc to preserve visual\nconsistency for downstream planning and verification. We validate our approach\non a suite of robotic manipulation tasks in the context of action verification,\nwhere the verifier needs to select desired action plans based on predictions\nfrom a world model. Our results show that ReOI is robust to both\nin-distribution and out-of-distribution visual distractors. Notably, it\nimproves task success rates by up to 3x in the presence of novel distractors,\nsignificantly outperforming action verification that relies on world model\npredictions without imagination interventions.", "AI": {"tldr": "Reimagination with Observation Intervention (ReOI) improves world model robustness by detecting and removing visual distractors during predictions, enhancing action verification in robotic tasks.", "motivation": "World models struggle with novel visual distractors, corrupting predictions and causing downstream failures in robot planning.", "method": "ReOI detects distractors, modifies observations to remove them, reimagines outcomes, and reintroduces distractors post-hoc for consistency.", "result": "ReOI boosts task success rates by up to 3x in the presence of novel distractors, outperforming baseline methods.", "conclusion": "ReOI is a simple yet effective test-time strategy for reliable world model predictions in open-world scenarios."}}
{"id": "2407.09879", "pdf": "https://arxiv.org/pdf/2407.09879", "abs": "https://arxiv.org/abs/2407.09879", "authors": ["Sanchit Ahuja", "Kumar Tanmay", "Hardik Hansrajbhai Chauhan", "Barun Patra", "Kriti Aggarwal", "Luciano Del Corro", "Arindam Mitra", "Tejas Indulal Dhamecha", "Ahmed Awadallah", "Monojit Choudhary", "Vishrav Chaudhary", "Sunayana Sitaram"], "title": "sPhinX: Sample Efficient Multilingual Instruction Fine-Tuning Through N-shot Guided Prompting", "categories": ["cs.CL"], "comment": "20 pages, 12 tables, 5 figures", "summary": "Despite the remarkable success of large language models (LLMs) in English, a\nsignificant performance gap remains in non-English languages. To address this,\nwe introduce a novel approach for strategically constructing a multilingual\nsynthetic instruction tuning dataset, sPhinX. Unlike prior methods that\ndirectly translate fixed instruction-response pairs, sPhinX enhances diversity\nby selectively augmenting English instruction-response pairs with multilingual\ntranslations. Additionally, we propose LANGIT, a novel N-shot guided\nfine-tuning strategy, which further enhances model performance by incorporating\ncontextually relevant examples in each training sample. Our ablation study\nshows that our approach enhances the multilingual capabilities of Mistral-7B\nand Phi-3-Small improving performance by an average of 39.8% and 11.2%,\nrespectively, across multilingual benchmarks in reasoning, question answering,\nreading comprehension, and machine translation. Moreover, sPhinX maintains\nstrong performance on English LLM benchmarks while exhibiting minimal to no\ncatastrophic forgetting, even when trained on 51 languages.", "AI": {"tldr": "The paper introduces sPhinX, a multilingual synthetic instruction tuning dataset, and LANGIT, a fine-tuning strategy, to improve non-English performance of LLMs without sacrificing English capabilities.", "motivation": "Address the performance gap of LLMs in non-English languages compared to English.", "method": "Construct sPhinX by augmenting English instruction-response pairs with multilingual translations and use LANGIT for N-shot guided fine-tuning.", "result": "Improved Mistral-7B and Phi-3-Small performance by 39.8% and 11.2% respectively across multilingual benchmarks, with minimal catastrophic forgetting.", "conclusion": "The approach effectively enhances multilingual capabilities of LLMs while maintaining strong English performance."}}
{"id": "2506.17040", "pdf": "https://arxiv.org/pdf/2506.17040", "abs": "https://arxiv.org/abs/2506.17040", "authors": ["Lorenzo Tausani", "Paolo Muratore", "Morgan B. Talbot", "Giacomo Amerio", "Gabriel Kreiman", "Davide Zoccolan"], "title": "Stretching Beyond the Obvious: A Gradient-Free Framework to Unveil the Hidden Landscape of Visual Invariance", "categories": ["cs.CV", "cs.NE"], "comment": "21 pages, 9 figures", "summary": "Uncovering which features' combinations high-level visual units encode is\ncritical to understand how images are transformed into representations that\nsupport recognition. While existing feature visualization approaches typically\ninfer a unit's most exciting images, this is insufficient to reveal the\nmanifold of transformations under which responses remain invariant, which is\nkey to generalization in vision. Here we introduce Stretch-and-Squeeze (SnS),\nan unbiased, model-agnostic, and gradient-free framework to systematically\ncharacterize a unit's invariance landscape and its vulnerability to adversarial\nperturbations in both biological and artificial visual systems. SnS frames\nthese transformations as bi-objective optimization problems. To probe\ninvariance, SnS seeks image perturbations that maximally alter the\nrepresentation of a reference stimulus in a given processing stage while\npreserving unit activation. To probe adversarial sensitivity, SnS seeks\nperturbations that minimally alter the stimulus while suppressing unit\nactivation. Applied to convolutional neural networks (CNNs), SnS revealed image\nvariations that were further from a reference image in pixel-space than those\nproduced by affine transformations, while more strongly preserving the target\nunit's response. The discovered invariant images differed dramatically\ndepending on the choice of image representation used for optimization:\npixel-level changes primarily affected luminance and contrast, while stretching\nmid- and late-layer CNN representations altered texture and pose respectively.\nNotably, the invariant images from robust networks were more recognizable by\nhuman subjects than those from standard networks, supporting the higher\nfidelity of robust CNNs as models of the visual system.", "AI": {"tldr": "SnS is a framework to study visual unit invariance and adversarial sensitivity in CNNs, revealing transformation-specific responses and robustness differences.", "motivation": "To understand how visual units encode features and generalize, beyond just identifying exciting images.", "method": "SnS uses bi-objective optimization to probe invariance (preserving activation) and adversarial sensitivity (suppressing activation) in CNNs.", "result": "SnS uncovered transformation-specific responses (e.g., texture, pose) and showed robust CNNs produce more human-recognizable invariant images.", "conclusion": "SnS provides insights into visual unit invariance and supports robust CNNs as better models of the visual system."}}
{"id": "2506.16494", "pdf": "https://arxiv.org/pdf/2506.16494", "abs": "https://arxiv.org/abs/2506.16494", "authors": ["Amir Reza Vazifeh", "Jason W. Fleischer"], "title": "Manifold Learning for Personalized and Label-Free Detection of Cardiac Arrhythmias", "categories": ["cs.LG", "eess.SP"], "comment": null, "summary": "Electrocardiograms (ECGs) provide direct, non-invasive measurements of heart\nactivity and are well-established tools for detecting and monitoring\ncardiovascular disease. However, manual ECG analysis can be time-consuming and\nprone to errors. Machine learning has emerged as a promising approach for\nautomated heartbeat recognition and classification, but substantial variations\nin ECG signals make it challenging to develop generalizable models. ECG signals\ncan vary widely across individuals and leads, while datasets often follow\ndifferent labeling standards and may be biased, all of which greatly hinder\nsupervised methods. Conventional unsupervised methods, e.g. principal component\nanalysis, prioritize large (and often obvious) variances in the data and\ntypically overlook subtle yet clinically relevant patterns. If labels are\nmissing and/or variations are significant but small, both approaches fail.\nHere, we show that nonlinear dimensionality reduction (NLDR) can accommodate\nthese issues and identify medically relevant features in ECG signals, with no\nneed for training or prior information. Using the MLII and V1 leads of the\nMIT-BIH dataset, we demonstrate that t-distributed stochastic neighbor\nembedding and uniform manifold approximation and projection can discriminate\nindividual recordings in mixed populations with >= 90% accuracy and distinguish\ndifferent arrhythmias in individual patients with a median accuracy of 98.96%\nand a median F1-score of 91.02%. The results show that NLDR holds much promise\nfor cardiac monitoring, including the limiting cases of single-lead ECG and the\ncurrent 12-lead standard of care, and for personalized health care beyond\ncardiology.", "AI": {"tldr": "NLDR techniques like t-SNE and UMAP effectively analyze ECG signals without training, achieving high accuracy in distinguishing arrhythmias and individual recordings.", "motivation": "Manual ECG analysis is error-prone and time-consuming, while existing machine learning methods struggle with signal variability and lack of labeled data.", "method": "Nonlinear dimensionality reduction (NLDR) techniques (t-SNE and UMAP) are applied to ECG signals from the MIT-BIH dataset to identify medically relevant features without training.", "result": "NLDR achieved >=90% accuracy in discriminating individual recordings and 98.96% median accuracy with 91.02% F1-score for arrhythmia classification.", "conclusion": "NLDR shows promise for automated ECG analysis, including single-lead and 12-lead applications, and extends potential to personalized healthcare beyond cardiology."}}
{"id": "2506.16586", "pdf": "https://arxiv.org/pdf/2506.16586", "abs": "https://arxiv.org/abs/2506.16586", "authors": ["Ihor Pysmennyi", "Roman Kyslyi", "Kyrylo Kleshch"], "title": "AI-Driven Tools in Modern Software Quality Assurance: An Assessment of Benefits, Challenges, and Future Directions", "categories": ["cs.SE", "cs.AI"], "comment": "11 pages, 9 figures", "summary": "Traditional quality assurance (QA) methods face significant challenges in\naddressing the complexity, scale, and rapid iteration cycles of modern software\nsystems and are strained by limited resources available, leading to substantial\ncosts associated with poor quality. The object of this research is the Quality\nAssurance processes for modern distributed software applications. The subject\nof the research is the assessment of the benefits, challenges, and prospects of\nintegrating modern AI-oriented tools into quality assurance processes. We\nperformed comprehensive analysis of implications on both verification and\nvalidation processes covering exploratory test analyses, equivalence\npartitioning and boundary analyses, metamorphic testing, finding\ninconsistencies in acceptance criteria (AC), static analyses, test case\ngeneration, unit test generation, test suit optimization and assessment, end to\nend scenario execution. End to end regression of sample enterprise application\nutilizing AI-agents over generated test scenarios was implemented as a proof of\nconcept highlighting practical use of the study. The results, with only 8.3%\nflaky executions of generated test cases, indicate significant potential for\nthe proposed approaches. However, the study also identified substantial\nchallenges for practical adoption concerning generation of semantically\nidentical coverage, \"black box\" nature and lack of explainability from\nstate-of-the-art Large Language Models (LLMs), the tendency to correct mutated\ntest cases to match expected results, underscoring the necessity for thorough\nverification of both generated artifacts and test execution results. The\nresearch demonstrates AI's transformative potential for QA but highlights the\nimportance of a strategic approach to implementing these technologies,\nconsidering the identified limitations and the need for developing appropriate\nverification methodologies.", "AI": {"tldr": "The paper explores integrating AI tools into QA for modern software, showing promise but also challenges like explainability and verification.", "motivation": "Addressing the limitations of traditional QA methods in handling modern software complexity and scale.", "method": "Comprehensive analysis of AI integration in QA processes, including test generation and execution, with a proof-of-concept using AI-agents.", "result": "8.3% flaky test executions, indicating potential, but challenges like LLM explainability and verification needs were identified.", "conclusion": "AI has transformative potential for QA, but strategic implementation and verification methodologies are crucial."}}
{"id": "2407.14701", "pdf": "https://arxiv.org/pdf/2407.14701", "abs": "https://arxiv.org/abs/2407.14701", "authors": ["Michael C. Stern", "Maria M. Pi\u00f1ango"], "title": "Contextual modulation of language comprehension in a dynamic neural model of lexical meaning", "categories": ["cs.CL"], "comment": null, "summary": "We propose and computationally implement a dynamic neural model of lexical\nmeaning, and experimentally test its behavioral predictions. We demonstrate the\narchitecture and behavior of the model using as a test case the English lexical\nitem 'have', focusing on its polysemous use. In the model, 'have' maps to a\nsemantic space defined by two continuous conceptual dimensions, connectedness\nand control asymmetry, previously proposed to parameterize the conceptual\nsystem for language. The mapping is modeled as coupling between a neural node\nrepresenting the lexical item and neural fields representing the conceptual\ndimensions. While lexical knowledge is modeled as a stable coupling pattern,\nreal-time lexical meaning retrieval is modeled as the motion of neural\nactivation patterns between metastable states corresponding to semantic\ninterpretations or readings. Model simulations capture two previously reported\nempirical observations: (1) contextual modulation of lexical semantic\ninterpretation, and (2) individual variation in the magnitude of this\nmodulation. Simulations also generate a novel prediction that the by-trial\nrelationship between sentence reading time and acceptability should be\ncontextually modulated. An experiment combining self-paced reading and\nacceptability judgments replicates previous results and confirms the new model\nprediction. Altogether, results support a novel perspective on lexical\npolysemy: that the many related meanings of a word are metastable neural\nactivation states that arise from the nonlinear dynamics of neural populations\ngoverning interpretation on continuous semantic dimensions.", "AI": {"tldr": "A dynamic neural model of lexical meaning for polysemous words like 'have' is proposed, tested, and validated through simulations and experiments.", "motivation": "To explore how lexical polysemy arises from neural dynamics and continuous semantic dimensions.", "method": "A neural model maps 'have' to conceptual dimensions (connectedness, control asymmetry), simulating real-time meaning retrieval as activation patterns between metastable states.", "result": "Simulations replicate known effects (contextual modulation, individual variation) and predict a new relationship between reading time and acceptability. Experiments confirm predictions.", "conclusion": "Lexical polysemy emerges from nonlinear neural dynamics, with meanings as metastable states on continuous semantic dimensions."}}
{"id": "2506.17051", "pdf": "https://arxiv.org/pdf/2506.17051", "abs": "https://arxiv.org/abs/2506.17051", "authors": ["Florent Meyer", "Laurent Guichard", "Denis Coquenet", "Guillaume Gravier", "Yann Soullard", "Bertrand Co\u00fcasnon"], "title": "Relaxed syntax modeling in Transformers for future-proof license plate recognition", "categories": ["cs.CV"], "comment": null, "summary": "Effective license plate recognition systems are required to be resilient to\nconstant change, as new license plates are released into traffic daily. While\nTransformer-based networks excel in their recognition at first sight, we\nobserve significant performance drop over time which proves them unsuitable for\ntense production environments. Indeed, such systems obtain state-of-the-art\nresults on plates whose syntax is seen during training. Yet, we show they\nperform similarly to random guessing on future plates where legible characters\nare wrongly recognized due to a shift in their syntax. After highlighting the\nflows of positional and contextual information in Transformer encoder-decoders,\nwe identify several causes for their over-reliance on past syntax. Following,\nwe devise architectural cut-offs and replacements which we integrate into SaLT,\nan attempt at a Syntax-Less Transformer for syntax-agnostic modeling of license\nplate representations. Experiments on both real and synthetic datasets show\nthat our approach reaches top accuracy on past syntax and most importantly\nnearly maintains performance on future license plates. We further demonstrate\nthe robustness of our architecture enhancements by way of various ablations.", "AI": {"tldr": "The paper introduces SaLT, a Syntax-Less Transformer, to address performance drops in license plate recognition caused by syntax shifts in new plates. It maintains accuracy on both past and future plates.", "motivation": "Transformer-based networks perform poorly over time due to syntax shifts in new license plates, making them unreliable for production.", "method": "The authors analyze Transformer encoder-decoder flaws, propose architectural changes, and integrate them into SaLT for syntax-agnostic modeling.", "result": "SaLT achieves top accuracy on past syntax and maintains performance on future plates, as shown in experiments on real and synthetic datasets.", "conclusion": "SaLT's enhancements effectively address syntax dependency, proving robust in license plate recognition across varying syntaxes."}}
{"id": "2506.16500", "pdf": "https://arxiv.org/pdf/2506.16500", "abs": "https://arxiv.org/abs/2506.16500", "authors": ["Samir Khaki", "Xiuyu Li", "Junxian Guo", "Ligeng Zhu", "Chenfeng Xu", "Konstantinos N. Plataniotis", "Amir Yazdanbakhsh", "Kurt Keutzer", "Song Han", "Zhijian Liu"], "title": "SparseLoRA: Accelerating LLM Fine-Tuning with Contextual Sparsity", "categories": ["cs.LG"], "comment": "ICML 2025. The first three authors contributed equally to this work.\n  Project page: https://z-lab.ai/projects/sparselora", "summary": "Fine-tuning LLMs is both computationally and memory-intensive. While\nparameter-efficient fine-tuning methods, such as QLoRA and DoRA, reduce the\nnumber of trainable parameters and lower memory usage, they do not decrease\ncomputational cost. In some cases, they may even slow down fine-tuning. In this\npaper, we introduce SparseLoRA, a method that accelerates LLM fine-tuning\nthrough contextual sparsity. We propose a lightweight, training-free SVD\nsparsity estimator that dynamically selects a sparse subset of weights for loss\nand gradient computation. Also, we systematically analyze and address\nsensitivity across layers, tokens, and training steps. Our experimental results\nshow that SparseLoRA reduces computational cost by up to 2.2 times and a\nmeasured speedup of up to 1.6 times while maintaining accuracy across various\ndownstream tasks, including commonsense and arithmetic reasoning, code\ngeneration, and instruction following.", "AI": {"tldr": "SparseLoRA introduces contextual sparsity to accelerate LLM fine-tuning, reducing computational cost by up to 2.2\u00d7 and achieving 1.6\u00d7 speedup while maintaining accuracy.", "motivation": "Current parameter-efficient fine-tuning methods (e.g., QLoRA, DoRA) reduce memory usage but not computational cost, sometimes slowing fine-tuning. SparseLoRA addresses this gap.", "method": "Uses a lightweight, training-free SVD sparsity estimator to dynamically select sparse weights for loss/gradient computation, with systematic sensitivity analysis.", "result": "Achieves up to 2.2\u00d7 computational cost reduction and 1.6\u00d7 speedup, maintaining accuracy across tasks like reasoning, code generation, and instruction following.", "conclusion": "SparseLoRA effectively balances efficiency and performance, offering a practical solution for LLM fine-tuning."}}
{"id": "2506.16590", "pdf": "https://arxiv.org/pdf/2506.16590", "abs": "https://arxiv.org/abs/2506.16590", "authors": ["Zeyun Deng", "Jasorsi Ghosh", "Fiona Xie", "Yuzhe Lu", "Katia Sycara", "Joseph Campbell"], "title": "Energy-Based Transfer for Reinforcement Learning", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Reinforcement learning algorithms often suffer from poor sample efficiency,\nmaking them challenging to apply in multi-task or continual learning settings.\nEfficiency can be improved by transferring knowledge from a previously trained\nteacher policy to guide exploration in new but related tasks. However, if the\nnew task sufficiently differs from the teacher's training task, the transferred\nguidance may be sub-optimal and bias exploration toward low-reward behaviors.\nWe propose an energy-based transfer learning method that uses\nout-of-distribution detection to selectively issue guidance, enabling the\nteacher to intervene only in states within its training distribution. We\ntheoretically show that energy scores reflect the teacher's state-visitation\ndensity and empirically demonstrate improved sample efficiency and performance\nacross both single-task and multi-task settings.", "AI": {"tldr": "Proposes an energy-based transfer learning method for reinforcement learning, using out-of-distribution detection to improve sample efficiency by selectively applying teacher guidance.", "motivation": "Reinforcement learning struggles with sample efficiency, especially in multi-task or continual learning. Transferring knowledge from a teacher policy can help but may be sub-optimal if tasks differ too much.", "method": "Energy-based transfer learning with out-of-distribution detection to selectively apply teacher guidance in states within its training distribution.", "result": "Theoretical proof that energy scores reflect teacher's state-visitation density; empirical improvements in sample efficiency and performance in single-task and multi-task settings.", "conclusion": "The method effectively improves sample efficiency and performance by ensuring teacher guidance is only applied where appropriate."}}
{"id": "2408.01287", "pdf": "https://arxiv.org/pdf/2408.01287", "abs": "https://arxiv.org/abs/2408.01287", "authors": ["Yihao Ding", "Soyeon Caren Han", "Jean Lee", "Eduard Hovy"], "title": "Deep Learning based Visually Rich Document Content Understanding: A Survey", "categories": ["cs.CL", "cs.CV"], "comment": "Work in Progress", "summary": "Visually Rich Documents (VRDs) play a vital role in domains such as academia,\nfinance, healthcare, and marketing, as they convey information through a\ncombination of text, layout, and visual elements. Traditional approaches to\nextracting information from VRDs rely heavily on expert knowledge and manual\nannotation, making them labor-intensive and inefficient. Recent advances in\ndeep learning have transformed this landscape by enabling multimodal models\nthat integrate vision, language, and layout features through pretraining,\nsignificantly improving information extraction performance. This survey\npresents a comprehensive overview of deep learning-based frameworks for VRD\nContent Understanding (VRD-CU). We categorize existing methods based on their\nmodeling strategies and downstream tasks, and provide a comparative analysis of\nkey components, including feature representation, fusion techniques, model\narchitectures, and pretraining objectives. Additionally, we highlight the\nstrengths and limitations of each approach and discuss their suitability for\ndifferent applications. The paper concludes with a discussion of current\nchallenges and emerging trends, offering guidance for future research and\npractical deployment in real-world scenarios.", "AI": {"tldr": "A survey on deep learning-based frameworks for understanding Visually Rich Documents (VRDs), covering methods, comparisons, and future trends.", "motivation": "Traditional VRD information extraction is labor-intensive; deep learning offers efficient, multimodal solutions.", "method": "Categorizes and analyzes methods by modeling strategies, tasks, and components like feature representation and fusion.", "result": "Identifies strengths, limitations, and suitability of approaches for various applications.", "conclusion": "Highlights challenges and trends, guiding future research and real-world deployment."}}
{"id": "2506.17074", "pdf": "https://arxiv.org/pdf/2506.17074", "abs": "https://arxiv.org/abs/2506.17074", "authors": ["Wang Zhao", "Yan-Pei Cao", "Jiale Xu", "Yuejiang Dong", "Ying Shan"], "title": "Assembler: Scalable 3D Part Assembly via Anchor Point Diffusion", "categories": ["cs.CV"], "comment": "Technical Report. Project page: https://assembler3d.github.io", "summary": "We present Assembler, a scalable and generalizable framework for 3D part\nassembly that reconstructs complete objects from input part meshes and a\nreference image. Unlike prior approaches that mostly rely on deterministic part\npose prediction and category-specific training, Assembler is designed to handle\ndiverse, in-the-wild objects with varying part counts, geometries, and\nstructures. It addresses the core challenges of scaling to general 3D part\nassembly through innovations in task formulation, representation, and data.\nFirst, Assembler casts part assembly as a generative problem and employs\ndiffusion models to sample plausible configurations, effectively capturing\nambiguities arising from symmetry, repeated parts, and multiple valid\nassemblies. Second, we introduce a novel shape-centric representation based on\nsparse anchor point clouds, enabling scalable generation in Euclidean space\nrather than SE(3) pose prediction. Third, we construct a large-scale dataset of\nover 320K diverse part-object assemblies using a synthesis and filtering\npipeline built on existing 3D shape repositories. Assembler achieves\nstate-of-the-art performance on PartNet and is the first to demonstrate\nhigh-quality assembly for complex, real-world objects. Based on Assembler, we\nfurther introduce an interesting part-aware 3D modeling system that generates\nhigh-resolution, editable objects from images, demonstrating potential for\ninteractive and compositional design. Project page:\nhttps://assembler3d.github.io", "AI": {"tldr": "Assembler is a scalable framework for 3D part assembly using diffusion models and sparse anchor point clouds, achieving state-of-the-art performance on diverse objects.", "motivation": "To address the limitations of prior approaches in handling diverse, real-world objects with varying part counts and structures.", "method": "Uses diffusion models for generative part assembly and a shape-centric representation with sparse anchor point clouds. Constructs a large-scale dataset for training.", "result": "Achieves state-of-the-art performance on PartNet and demonstrates high-quality assembly for complex, real-world objects.", "conclusion": "Assembler advances 3D part assembly and enables interactive, compositional design through its innovative framework."}}
{"id": "2506.16507", "pdf": "https://arxiv.org/pdf/2506.16507", "abs": "https://arxiv.org/abs/2506.16507", "authors": ["Pragya Srivastava", "Harman Singh", "Rahul Madhavan", "Gandharv Patil", "Sravanti Addepalli", "Arun Suggala", "Rengarajan Aravamudhan", "Soumya Sharma", "Anirban Laha", "Aravindan Raghuveer", "Karthikeyan Shanmugam", "Doina Precup"], "title": "Robust Reward Modeling via Causal Rubrics", "categories": ["cs.LG"], "comment": null, "summary": "Reward models (RMs) are fundamental to aligning Large Language Models (LLMs)\nvia human feedback, yet they often suffer from reward hacking. They tend to\nlatch on to superficial or spurious attributes, such as response length or\nformatting, mistaking these cues learned from correlations in training data for\nthe true causal drivers of quality (e.g., factuality, relevance). This occurs\nbecause standard training objectives struggle to disentangle these factors,\nleading to brittle RMs and misaligned policies. We introduce Crome (Causally\nRobust Reward Modeling), a novel framework grounded in an explicit causal model\ndesigned to mitigate reward hacking. Crome employs the following synthetic\ntargeted augmentations during training: (1) Causal Augmentations, which are\npairs that differ along specific causal attributes, to enforce sensitivity\nalong each causal attribute individually, and (2) Neutral Augmentations, which\nare tie-label pairs varying primarily in spurious attributes, to enforce\ninvariance along spurious attributes. Notably, our augmentations are produced\nwithout any knowledge of spurious factors, via answer interventions only along\ncausal rubrics, that are identified by querying an oracle LLM. Empirically,\nCrome significantly outperforms standard baselines on RewardBench, improving\naverage accuracy by up to 5.4% and achieving gains of up to 13.2% and 7.2% in\nspecific categories. The robustness of Crome is further testified by the\nconsistent gains obtained in a Best-of-N inference setting across increasing N,\nacross various benchmarks, including the popular RewardBench (covering chat,\nchat-hard, safety, and reasoning tasks), the safety-focused WildGuardTest, and\nthe reasoning-specific GSM8k.", "AI": {"tldr": "Crome (Causally Robust Reward Modeling) is introduced to mitigate reward hacking in reward models (RMs) by using causal and neutral augmentations during training, improving accuracy and robustness.", "motivation": "Reward models often suffer from reward hacking by focusing on superficial attributes like response length instead of true quality drivers (e.g., factuality). Standard training fails to disentangle these factors, leading to misalignment.", "method": "Crome employs synthetic targeted augmentations: (1) Causal Augmentations to enforce sensitivity to causal attributes, and (2) Neutral Augmentations to enforce invariance to spurious attributes. These are generated via answer interventions without prior knowledge of spurious factors.", "result": "Crome outperforms baselines on RewardBench, improving average accuracy by up to 5.4%, with gains of 13.2% and 7.2% in specific categories. It also shows consistent robustness in Best-of-N inference across benchmarks.", "conclusion": "Crome effectively mitigates reward hacking, enhancing RM robustness and alignment, as demonstrated by significant performance improvements across diverse benchmarks."}}
{"id": "2506.16600", "pdf": "https://arxiv.org/pdf/2506.16600", "abs": "https://arxiv.org/abs/2506.16600", "authors": ["Khiem Le", "Tuan Tran", "Ting Hua", "Nitesh V. Chawla"], "title": "FLAME: Towards Federated Fine-Tuning Large Language Models Through Adaptive SMoE", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Existing resource-adaptive LoRA federated fine-tuning methods enable clients\nto fine-tune models using compressed versions of global LoRA matrices, in order\nto accommodate various compute resources across clients. This compression\nrequirement will lead to suboptimal performance due to information loss. To\naddress this, we propose FLAME, a novel federated learning framework based on\nthe Sparse Mixture-of-Experts (SMoE) architecture. Unlike prior approaches,\nFLAME retains full (uncompressed) global LoRA matrices and achieves client-side\nadaptability by varying the number of activated experts per client. However,\nincorporating SMoE into federated learning introduces unique challenges,\nspecifically, the mismatch in output magnitude from partial expert activation\nand the imbalance in expert training quality across clients. FLAME tackles\nthese challenges through a lightweight rescaling mechanism and an\nactivation-aware aggregation scheme. Empirical results across diverse\ncomputational settings demonstrate that FLAME consistently outperforms existing\nmethods, providing a robust and effective solution for resource-adaptive\nfederated learning.", "AI": {"tldr": "FLAME is a federated learning framework using Sparse Mixture-of-Experts (SMoE) to retain full LoRA matrices, addressing resource adaptability and outperforming prior methods.", "motivation": "Existing LoRA federated fine-tuning methods suffer from performance loss due to compression. FLAME aims to avoid this by leveraging SMoE for better adaptability.", "method": "FLAME uses SMoE to vary activated experts per client, with rescaling and activation-aware aggregation to handle output mismatch and expert imbalance.", "result": "FLAME outperforms existing methods across diverse computational settings, proving its robustness.", "conclusion": "FLAME provides an effective, resource-adaptive solution for federated learning without compromising performance."}}
{"id": "2408.06904", "pdf": "https://arxiv.org/pdf/2408.06904", "abs": "https://arxiv.org/abs/2408.06904", "authors": ["Zhihu Wang", "Shiwan Zhao", "Yu Wang", "Heyuan Huang", "Sitao Xie", "Yubo Zhang", "Jiaxin Shi", "Zhixing Wang", "Hongyan Li", "Junchi Yan"], "title": "Re-TASK: Revisiting LLM Tasks from Capability, Skill, and Knowledge Perspectives", "categories": ["cs.CL"], "comment": "ACL 2025 Findings; First three authors contributed equally", "summary": "The Chain-of-Thought (CoT) paradigm has become a pivotal method for solving\ncomplex problems with large language models (LLMs). However, its application to\ndomain-specific tasks remains challenging, as LLMs often fail to decompose\ntasks accurately or execute subtasks effectively. This paper introduces the\nRe-TASK framework, a novel theoretical model that revisits LLM tasks from\ncapability, skill, and knowledge perspectives, drawing on the principles of\nBloom's Taxonomy and Knowledge Space Theory. While CoT provides a\nworkflow-centric perspective on tasks, Re-TASK introduces a Chain-of-Learning\n(CoL) paradigm that highlights task dependencies on specific capability items,\nfurther broken down into their constituent knowledge and skill components. To\naddress CoT failures, we propose a Re-TASK prompting strategy, which\nstrengthens task-relevant capabilities through targeted knowledge injection and\nskill adaptation. Experiments across diverse domains demonstrate the\neffectiveness of Re-TASK. In particular, we achieve improvements of 45.00% on\nYi-1.5-9B and 24.50% on Llama3-Chinese-8B for legal tasks. These results\nhighlight the potential of Re-TASK to significantly enhance LLM performance and\nits applicability in specialized domains. We release our code and data at\nhttps://github.com/Uylee/Re-TASK.", "AI": {"tldr": "The paper introduces the Re-TASK framework, a novel model addressing the limitations of Chain-of-Thought (CoT) in domain-specific tasks by focusing on capability, skill, and knowledge. It proposes a Chain-of-Learning (CoL) paradigm and a prompting strategy, achieving significant performance improvements.", "motivation": "The motivation is to overcome the challenges of applying CoT to domain-specific tasks, where LLMs struggle with task decomposition and execution.", "method": "The method involves the Re-TASK framework, which revisits tasks from capability, skill, and knowledge perspectives, using Bloom's Taxonomy and Knowledge Space Theory. It introduces CoL and a prompting strategy for targeted knowledge and skill adaptation.", "result": "Experiments show improvements of 45.00% on Yi-1.5-9B and 24.50% on Llama3-Chinese-8B for legal tasks, demonstrating Re-TASK's effectiveness.", "conclusion": "Re-TASK enhances LLM performance in specialized domains, offering a promising approach for domain-specific task solving."}}
{"id": "2506.17101", "pdf": "https://arxiv.org/pdf/2506.17101", "abs": "https://arxiv.org/abs/2506.17101", "authors": ["Ke Li", "Chenyu Zhang", "Yuxin Ding", "Xianbiao Hu", "Ruwen Qin"], "title": "Acquiring and Accumulating Knowledge from Diverse Datasets for Multi-label Driving Scene Classification", "categories": ["cs.CV"], "comment": null, "summary": "Driving scene identification, which assigns multiple non-exclusive class\nlabels to a scene, provides the contextual awareness necessary for enhancing\nautonomous vehicles' ability to understand, reason about, and interact with the\ncomplex driving environment. As a multi-label classification problem, it is\nbetter tackled via multitasking learning. However, directly training a\nmulti-label classification model for driving scene identification through\nmultitask learning presents two main challenges: acquiring a balanced,\ncomprehensively annotated multi-label dataset and balancing learning across\ndifferent tasks. This paper introduces a novel learning system that synergizes\nknowledge acquisition and accumulation (KAA) with consistency-based active\nlearning (CAL) to address those challenges. KAA acquires and accumulates\nknowledge about scene identification from various single-label datasets via\nmonotask learning. Subsequently, CAL effectively resolves the knowledge gap\ncaused by the discrepancy between the marginal distributions of individual\nattributes and their joint distribution. An ablation study on our Driving Scene\nIdentification (DSI) dataset demonstrates a 56.1% performance increase over the\nbaseline model pretrained on ImageNet. Of this, KAA accounts for 31.3% of the\ngain, and CAL contributes 24.8%. Moreover, KAA-CAL stands out as the best\nperformer when compared to state-of-the-art (SOTA) multi-label models on two\npublic datasets, BDD100K and HSD, achieving this while using 85% less data. The\nDSI dataset and the implementation code for KAA-CAL are available at\nhttps://github.com/KELISBU/KAA-CAL .", "AI": {"tldr": "The paper introduces KAA-CAL, a novel learning system combining knowledge acquisition and accumulation with consistency-based active learning to improve multi-label driving scene identification, outperforming baselines and SOTA models with less data.", "motivation": "Enhancing autonomous vehicles' contextual awareness by addressing challenges in multi-label classification for driving scenes, such as dataset imbalance and task learning balance.", "method": "Uses KAA (knowledge acquisition and accumulation from single-label datasets) and CAL (consistency-based active learning to bridge knowledge gaps).", "result": "Achieves a 56.1% performance increase over baseline, with KAA contributing 31.3% and CAL 24.8%. Outperforms SOTA models on BDD100K and HSD using 85% less data.", "conclusion": "KAA-CAL effectively addresses multi-label classification challenges, improving driving scene identification performance and efficiency."}}
{"id": "2506.16528", "pdf": "https://arxiv.org/pdf/2506.16528", "abs": "https://arxiv.org/abs/2506.16528", "authors": ["Bornali Phukon", "Xiuwen Zheng", "Mark Hasegawa-Johnson"], "title": "Aligning ASR Evaluation with Human and LLM Judgments: Intelligibility Metrics Using Phonetic, Semantic, and NLI Approaches", "categories": ["cs.LG"], "comment": "5 pages, 2 figures, Interspeech 2025", "summary": "Traditional ASR metrics like WER and CER fail to capture intelligibility,\nespecially for dysarthric and dysphonic speech, where semantic alignment\nmatters more than exact word matches. ASR systems struggle with these speech\ntypes, often producing errors like phoneme repetitions and imprecise\nconsonants, yet the meaning remains clear to human listeners. We identify two\nkey challenges: (1) Existing metrics do not adequately reflect intelligibility,\nand (2) while LLMs can refine ASR output, their effectiveness in correcting ASR\ntranscripts of dysarthric speech remains underexplored. To address this, we\npropose a novel metric integrating Natural Language Inference (NLI) scores,\nsemantic similarity, and phonetic similarity. Our ASR evaluation metric\nachieves a 0.890 correlation with human judgments on Speech Accessibility\nProject data, surpassing traditional methods and emphasizing the need to\nprioritize intelligibility over error-based measures.", "AI": {"tldr": "A new metric combining NLI scores, semantic similarity, and phonetic similarity is proposed to better evaluate ASR intelligibility for dysarthric speech, outperforming traditional metrics like WER.", "motivation": "Traditional ASR metrics (e.g., WER, CER) fail to capture intelligibility for dysarthric/dysphonic speech, where semantic alignment is more critical than exact word matches.", "method": "Proposes a novel metric integrating Natural Language Inference (NLI) scores, semantic similarity, and phonetic similarity.", "result": "The new metric achieves a 0.890 correlation with human judgments, surpassing traditional methods.", "conclusion": "The study highlights the need to prioritize intelligibility over error-based measures in ASR evaluation, especially for dysarthric speech."}}
{"id": "2506.16608", "pdf": "https://arxiv.org/pdf/2506.16608", "abs": "https://arxiv.org/abs/2506.16608", "authors": ["Jiamin He", "A. Rupam Mahmood", "Martha White"], "title": "Distribution Parameter Actor-Critic: Shifting the Agent-Environment Boundary for Diverse Action Spaces", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "We introduce a novel reinforcement learning (RL) framework that treats\ndistribution parameters as actions, redefining the boundary between agent and\nenvironment. This reparameterization makes the new action space continuous,\nregardless of the original action type (discrete, continuous, mixed, etc.).\nUnder this new parameterization, we develop a generalized deterministic policy\ngradient estimator, Distribution Parameter Policy Gradient (DPPG), which has\nlower variance than the gradient in the original action space. Although\nlearning the critic over distribution parameters poses new challenges, we\nintroduce interpolated critic learning (ICL), a simple yet effective strategy\nto enhance learning, supported by insights from bandit settings. Building on\nTD3, a strong baseline for continuous control, we propose a practical\nDPPG-based actor-critic algorithm, Distribution Parameter Actor-Critic (DPAC).\nEmpirically, DPAC outperforms TD3 in MuJoCo continuous control tasks from\nOpenAI Gym and DeepMind Control Suite, and demonstrates competitive performance\non the same environments with discretized action spaces.", "AI": {"tldr": "A novel RL framework redefines agent-environment boundaries by treating distribution parameters as actions, enabling continuous action spaces. The DPPG method reduces gradient variance, and DPAC outperforms TD3 in continuous control tasks.", "motivation": "To address the challenge of handling diverse action types (discrete, continuous, mixed) in RL by reparameterizing actions as distribution parameters, simplifying the action space and improving learning efficiency.", "method": "Introduces DPPG, a deterministic policy gradient estimator for distribution parameters, and ICL for critic learning. DPAC, a practical actor-critic algorithm, builds on TD3.", "result": "DPAC outperforms TD3 in MuJoCo tasks and performs competitively in discretized action spaces.", "conclusion": "The framework and DPAC algorithm effectively generalize RL to diverse action spaces, demonstrating superior performance in continuous control tasks."}}
{"id": "2408.14352", "pdf": "https://arxiv.org/pdf/2408.14352", "abs": "https://arxiv.org/abs/2408.14352", "authors": ["Nicolas Yax", "Pierre-Yves Oudeyer", "Stefano Palminteri"], "title": "LogProber: Disentangling confidence from contamination in LLM responses", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "In machine learning, contamination refers to situations where testing data\nleak into the training set. The issue is particularly relevant for the\nevaluation of the performance of Large Language Models (LLMs), which are\ngenerally trained on gargantuan, and generally opaque, corpora of text scraped\nfrom the world wide web. Developing tools to detect contamination is therefore\ncrucial to be able to fairly and properly track the evolution of the\nperformance of LLMs. To date, only a few recent studies have attempted to\naddress the issue of quantifying and detecting contamination in short text\nsequences, such as those commonly found in benchmarks. However, these methods\nhave limitations that can sometimes render them impractical. In the present\npaper, we introduce LogProber, a novel, efficient algorithm that we show to be\nable to detect contamination in a black box setting that tries to tackle some\nof these drawbacks by focusing on the familiarity with the question rather than\nthe answer. Here, we explore the properties of the proposed method in\ncomparison with concurrent approaches, identify its advantages and limitations,\nand illustrate how different forms of contamination can go undetected depending\non the design of the detection algorithm.", "AI": {"tldr": "LogProber is a new algorithm designed to detect contamination in LLMs by focusing on question familiarity, addressing limitations of existing methods.", "motivation": "Contamination in LLMs, where test data leaks into training, undermines fair performance evaluation. Existing detection methods for short text sequences are limited.", "method": "LogProber detects contamination in a black-box setting by analyzing familiarity with questions rather than answers.", "result": "LogProber is shown to be efficient and effective, though some contamination forms may still evade detection based on algorithm design.", "conclusion": "LogProber offers a promising approach to contamination detection, but further refinement is needed to address its limitations."}}
{"id": "2506.17119", "pdf": "https://arxiv.org/pdf/2506.17119", "abs": "https://arxiv.org/abs/2506.17119", "authors": ["Teng Guo", "Jingjin Yu"], "title": "RGBTrack: Fast, Robust Depth-Free 6D Pose Estimation and Tracking", "categories": ["cs.CV", "cs.RO"], "comment": "Accepted to IROS 2025", "summary": "We introduce a robust framework, RGBTrack, for real-time 6D pose estimation\nand tracking that operates solely on RGB data, thereby eliminating the need for\ndepth input for such dynamic and precise object pose tracking tasks. Building\non the FoundationPose architecture, we devise a novel binary search strategy\ncombined with a render-and-compare mechanism to efficiently infer depth and\ngenerate robust pose hypotheses from true-scale CAD models. To maintain stable\ntracking in dynamic scenarios, including rapid movements and occlusions,\nRGBTrack integrates state-of-the-art 2D object tracking (XMem) with a Kalman\nfilter and a state machine for proactive object pose recovery. In addition,\nRGBTrack's scale recovery module dynamically adapts CAD models of unknown scale\nusing an initial depth estimate, enabling seamless integration with modern\ngenerative reconstruction techniques. Extensive evaluations on benchmark\ndatasets demonstrate that RGBTrack's novel depth-free approach achieves\ncompetitive accuracy and real-time performance, making it a promising practical\nsolution candidate for application areas including robotics, augmented reality,\nand computer vision.\n  The source code for our implementation will be made publicly available at\nhttps://github.com/GreatenAnoymous/RGBTrack.git.", "AI": {"tldr": "RGBTrack is a robust, real-time 6D pose estimation and tracking framework using only RGB data, eliminating depth input. It combines binary search, render-and-compare, and integrates 2D tracking with a Kalman filter for stability.", "motivation": "To address the challenge of dynamic and precise object pose tracking without relying on depth data, simplifying hardware requirements.", "method": "Uses a binary search strategy and render-and-compare with CAD models, integrates XMem 2D tracking, a Kalman filter, and a state machine for recovery. Includes a scale recovery module for unknown-scale CAD models.", "result": "Achieves competitive accuracy and real-time performance on benchmarks, suitable for robotics, AR, and computer vision.", "conclusion": "RGBTrack is a practical, depth-free solution for real-time pose tracking, with potential applications in diverse fields."}}
{"id": "2506.16548", "pdf": "https://arxiv.org/pdf/2506.16548", "abs": "https://arxiv.org/abs/2506.16548", "authors": ["Arjun Dosajh", "Mihika Sanghi"], "title": "Mr. Snuffleupagus at SemEval-2025 Task 4: Unlearning Factual Knowledge from LLMs Using Adaptive RMU", "categories": ["cs.LG", "I.2.7"], "comment": "7 pages, 2 figures, to be published in SemEval-2025", "summary": "Large Language Models (LLMs) have demonstrated remarkable capabilities in\nnatural language understanding and generation. However, their tendency to\nmemorize training data raises concerns regarding privacy, copyright compliance,\nand security, particularly in cases involving Personally Identifiable\nInformation (PII). Effective machine unlearning techniques are essential to\nmitigate these risks, yet existing methods remain underdeveloped for LLMs due\nto their open-ended output space. In this work, we apply the Adaptive\nRepresentation Misdirection Unlearning (RMU) technique to unlearn sensitive\ninformation from LLMs. Through extensive experiments, we analyze the effects of\nunlearning across different decoder layers to determine the most effective\nregions for sensitive information removal. Our technique ranked 4th on the\nofficial leaderboard of both 1B parameter and 7B parameter models.", "AI": {"tldr": "The paper introduces Adaptive Representation Misdirection Unlearning (RMU) to remove sensitive data from LLMs, addressing privacy and security concerns.", "motivation": "LLMs memorize training data, posing privacy and security risks, especially with PII. Current unlearning methods are inadequate for LLMs.", "method": "Applied RMU to unlearn sensitive info, analyzing effects across decoder layers to identify optimal regions for removal.", "result": "RMU ranked 4th on leaderboards for both 1B and 7B parameter models.", "conclusion": "RMU is effective for unlearning sensitive info in LLMs, addressing privacy concerns while maintaining model performance."}}
{"id": "2506.16623", "pdf": "https://arxiv.org/pdf/2506.16623", "abs": "https://arxiv.org/abs/2506.16623", "authors": ["Mobin Habibpour", "Fatemeh Afghah"], "title": "History-Augmented Vision-Language Models for Frontier-Based Zero-Shot Object Navigation", "categories": ["cs.RO", "cs.AI"], "comment": null, "summary": "Object Goal Navigation (ObjectNav) challenges robots to find objects in\nunseen environments, demanding sophisticated reasoning. While Vision-Language\nModels (VLMs) show potential, current ObjectNav methods often employ them\nsuperficially, primarily using vision-language embeddings for object-scene\nsimilarity checks rather than leveraging deeper reasoning. This limits\ncontextual understanding and leads to practical issues like repetitive\nnavigation behaviors. This paper introduces a novel zero-shot ObjectNav\nframework that pioneers the use of dynamic, history-aware prompting to more\ndeeply integrate VLM reasoning into frontier-based exploration. Our core\ninnovation lies in providing the VLM with action history context, enabling it\nto generate semantic guidance scores for navigation actions while actively\navoiding decision loops. We also introduce a VLM-assisted waypoint generation\nmechanism for refining the final approach to detected objects. Evaluated on the\nHM3D dataset within Habitat, our approach achieves a 46% Success Rate (SR) and\n24.8% Success weighted by Path Length (SPL). These results are comparable to\nstate-of-the-art zero-shot methods, demonstrating the significant potential of\nour history-augmented VLM prompting strategy for more robust and context-aware\nrobotic navigation.", "AI": {"tldr": "A novel zero-shot ObjectNav framework uses dynamic, history-aware prompting to integrate VLM reasoning deeply, improving navigation success and avoiding repetitive behaviors.", "motivation": "Current ObjectNav methods use VLMs superficially, limiting contextual understanding and causing issues like repetitive navigation. This paper aims to leverage deeper VLM reasoning for better performance.", "method": "The framework employs dynamic, history-aware prompting for VLM reasoning, action history context for semantic guidance scores, and a VLM-assisted waypoint generation mechanism.", "result": "Achieves 46% Success Rate (SR) and 24.8% SPL on HM3D dataset, comparable to state-of-the-art zero-shot methods.", "conclusion": "The history-augmented VLM prompting strategy shows significant potential for robust, context-aware robotic navigation."}}
{"id": "2409.00128", "pdf": "https://arxiv.org/pdf/2409.00128", "abs": "https://arxiv.org/abs/2409.00128", "authors": ["Ziyan Cui", "Ning Li", "Huaikang Zhou"], "title": "Can Large Language Models Replace Human Subjects? A Large-Scale Replication of Scenario-Based Experiments in Psychology and Management", "categories": ["cs.CL", "cs.AI", "econ.GN", "q-fin.EC"], "comment": "5 figures, 2 tables", "summary": "Artificial Intelligence (AI) is increasingly being integrated into scientific\nresearch, particularly in the social sciences, where understanding human\nbehavior is critical. Large Language Models (LLMs) have shown promise in\nreplicating human-like responses in various psychological experiments. We\nconducted a large-scale study replicating 156 psychological experiments from\ntop social science journals using three state-of-the-art LLMs (GPT-4, Claude\n3.5 Sonnet, and DeepSeek v3). Our results reveal that while LLMs demonstrate\nhigh replication rates for main effects (73-81%) and moderate to strong success\nwith interaction effects (46-63%), They consistently produce larger effect\nsizes than human studies, with Fisher Z values approximately 2-3 times higher\nthan human studies. Notably, LLMs show significantly lower replication rates\nfor studies involving socially sensitive topics such as race, gender and\nethics. When original studies reported null findings, LLMs produced significant\nresults at remarkably high rates (68-83%) - while this could reflect cleaner\ndata with less noise, as evidenced by narrower confidence intervals, it also\nsuggests potential risks of effect size overestimation. Our results demonstrate\nboth the promise and challenges of LLMs in psychological research, offering\nefficient tools for pilot testing and rapid hypothesis validation while\nenriching rather than replacing traditional human subject studies, yet\nrequiring more nuanced interpretation and human validation for complex social\nphenomena and culturally sensitive research questions.", "AI": {"tldr": "LLMs replicate psychological experiments with high success for main effects but overestimate effect sizes and struggle with socially sensitive topics.", "motivation": "To assess the potential of LLMs in replicating human psychological studies and identify their strengths and limitations.", "method": "Replicated 156 psychological experiments using GPT-4, Claude 3.5 Sonnet, and DeepSeek v3, comparing results to human studies.", "result": "LLMs showed high replication rates for main effects (73-81%) and moderate success with interaction effects (46-63%), but overestimated effect sizes and struggled with socially sensitive topics.", "conclusion": "LLMs are useful for pilot testing and hypothesis validation but require nuanced interpretation and human validation, especially for complex or sensitive research."}}
{"id": "2506.17134", "pdf": "https://arxiv.org/pdf/2506.17134", "abs": "https://arxiv.org/abs/2506.17134", "authors": ["Md Sakibur Sajal", "Marc Dandin"], "title": "Dynamic Watermark Generation for Digital Images using Perimeter Gated SPAD Imager PUFs", "categories": ["cs.CV"], "comment": "5 pages, 7 figures, accepted at MWSCAS 2025 Conference", "summary": "Digital image watermarks as a security feature can be derived from the\nimager's physically unclonable functions (PUFs) by utilizing the manufacturing\nvariations, i.e., the dark signal non-uniformity (DSNU). While a few\ndemonstrations focused on the CMOS image sensors (CIS) and active pixel sensors\n(APS), single photon avalanche diode (SPAD) imagers have never been\ninvestigated for this purpose. In this work, we have proposed a novel\nwatermarking technique using perimeter gated SPAD (pgSPAD) imagers. We utilized\nthe DSNU of three 64 x 64 pgSPAD imager chips, fabricated in a 0.35 {\\mu}m\nstandard CMOS process and analyzed the simulated watermarks for standard test\nimages from publicly available database. Our observation shows that both source\nidentification and tamper detection can be achieved using the proposed\nsource-scene-specific dynamic watermarks with a controllable\nsensitivity-robustness trade-off.", "AI": {"tldr": "A novel watermarking technique using pgSPAD imagers is proposed, leveraging DSNU for source identification and tamper detection with a controllable trade-off.", "motivation": "Existing watermarking methods focus on CMOS and APS, leaving SPAD imagers unexplored. This work addresses this gap.", "method": "Utilizes DSNU of 64x64 pgSPAD imager chips fabricated in 0.35\u03bcm CMOS to generate dynamic watermarks for test images.", "result": "Achieves source identification and tamper detection with a controllable sensitivity-robustness trade-off.", "conclusion": "The proposed pgSPAD-based watermarking is effective for security applications."}}
{"id": "2506.16550", "pdf": "https://arxiv.org/pdf/2506.16550", "abs": "https://arxiv.org/abs/2506.16550", "authors": ["Swagatam Das"], "title": "A Free Probabilistic Framework for Analyzing the Transformer-based Language Models", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "We outline an operator-theoretic framework for analyzing transformer-based\nlanguage models using the tools of free probability theory. By representing\ntoken embeddings and attention mechanisms as self-adjoint operators in a racial\nprobability space, we reinterpret attention as a non-commutative convolution\nand view the layer-wise propagation of representations as an evolution governed\nby free additive convolution. This formalism reveals a spectral dynamical\nsystem underpinning deep transformer stacks and offers insight into their\ninductive biases, generalization behavior, and entropy dynamics. We derive a\ngeneralization bound based on free entropy and demonstrate that the spectral\ntrace of transformer layers evolves predictably with depth. Our approach\nbridges neural architecture with non-commutative harmonic analysis, enabling\nprincipled analysis of information flow and structural complexity in large\nlanguage models", "AI": {"tldr": "A framework using free probability theory to analyze transformers, reinterpreting attention as non-commutative convolution and layer propagation as free additive convolution.", "motivation": "To provide a principled analysis of transformers' inductive biases, generalization, and entropy dynamics using operator-theoretic tools.", "method": "Represent token embeddings and attention as self-adjoint operators in a free probability space, modeling attention as non-commutative convolution and layer propagation as free additive convolution.", "result": "Reveals a spectral dynamical system in transformers, derives a free entropy-based generalization bound, and shows predictable spectral trace evolution with depth.", "conclusion": "Bridges neural architecture with non-commutative harmonic analysis, enabling deeper understanding of information flow and complexity in large language models."}}
{"id": "2506.16636", "pdf": "https://arxiv.org/pdf/2506.16636", "abs": "https://arxiv.org/abs/2506.16636", "authors": ["Rex Shen", "Lu Tian"], "title": "Latent Noise Injection for Private and Statistically Aligned Synthetic Data Generation", "categories": ["stat.ML", "cs.AI", "cs.LG"], "comment": null, "summary": "Synthetic Data Generation has become essential for scalable,\nprivacy-preserving statistical analysis. While standard approaches based on\ngenerative models, such as Normalizing Flows, have been widely used, they often\nsuffer from slow convergence in high-dimensional settings, frequently\nconverging more slowly than the canonical $1/\\sqrt{n}$ rate when approximating\nthe true data distribution.\n  To overcome these limitations, we propose a Latent Noise Injection method\nusing Masked Autoregressive Flows (MAF). Instead of directly sampling from the\ntrained model, our method perturbs each data point in the latent space and maps\nit back to the data domain. This construction preserves a one to one\ncorrespondence between observed and synthetic data, enabling synthetic outputs\nthat closely reflect the underlying distribution, particularly in challenging\nhigh-dimensional regimes where traditional sampling struggles.\n  Our procedure satisfies local $(\\epsilon, \\delta)$-differential privacy and\nintroduces a single perturbation parameter to control the privacy-utility\ntrade-off. Although estimators based on individual synthetic datasets may\nconverge slowly, we show both theoretically and empirically that aggregating\nacross $K$ studies in a meta analysis framework restores classical efficiency\nand yields consistent, reliable inference. We demonstrate that with a\nwell-calibrated perturbation parameter, Latent Noise Injection achieves strong\nstatistical alignment with the original data and robustness against membership\ninference attacks. These results position our method as a compelling\nalternative to conventional flow-based sampling for synthetic data sharing in\ndecentralized and privacy-sensitive domains, such as biomedical research.", "AI": {"tldr": "The paper proposes a Latent Noise Injection method using Masked Autoregressive Flows (MAF) to improve synthetic data generation, addressing slow convergence in high-dimensional settings and ensuring privacy.", "motivation": "Standard generative models like Normalizing Flows struggle with slow convergence in high dimensions and privacy concerns. The paper aims to overcome these limitations.", "method": "The method injects noise in the latent space of MAF, preserving a one-to-one correspondence between observed and synthetic data, and controls privacy-utility trade-off with a perturbation parameter.", "result": "The method achieves strong statistical alignment with original data, robustness against attacks, and restores efficiency when aggregated in meta-analysis.", "conclusion": "Latent Noise Injection is a promising alternative for privacy-sensitive synthetic data sharing, especially in fields like biomedical research."}}
{"id": "2410.10855", "pdf": "https://arxiv.org/pdf/2410.10855", "abs": "https://arxiv.org/abs/2410.10855", "authors": ["Yijiang Li", "Qingying Gao", "Tianwei Zhao", "Bingyang Wang", "Haoran Sun", "Haiyun Lyu", "Robert D. Hawkins", "Nuno Vasconcelos", "Tal Golan", "Dezhi Luo", "Hokin Deng"], "title": "Core Knowledge Deficits in Multi-Modal Language Models", "categories": ["cs.CL", "cs.AI", "cs.CV"], "comment": "Accepted by ICML 2025. Project page at\n  https://williamium3000.github.io/core-knowledge and code is available at\n  https://github.com/williamium3000/core-knowledge", "summary": "While Multi-modal Large Language Models (MLLMs) demonstrate impressive\nabilities over high-level perception and reasoning, their robustness in the\nwild remains limited, often falling short on tasks that are intuitive and\neffortless for humans. We examine the hypothesis that these deficiencies stem\nfrom the absence of core knowledge--rudimentary cognitive abilities innate to\nhumans from early childhood. To explore the core knowledge representation in\nMLLMs, we introduce CoreCognition, a large-scale benchmark encompassing 12 core\nknowledge concepts grounded in developmental cognitive science. We evaluate 230\nmodels with 11 different prompts, leading to a total of 2,530 data points for\nanalysis. Our experiments uncover four key findings, collectively demonstrating\ncore knowledge deficits in MLLMs: they consistently underperform and show\nreduced, or even absent, scalability on low-level abilities relative to\nhigh-level ones. Finally, we propose Concept Hacking, a novel controlled\nevaluation method that reveals MLLMs fail to progress toward genuine core\nknowledge understanding, but instead rely on shortcut learning as they scale.", "AI": {"tldr": "The paper investigates core knowledge deficits in Multi-modal Large Language Models (MLLMs) using the CoreCognition benchmark, revealing their underperformance and reliance on shortcut learning.", "motivation": "MLLMs lack robustness in intuitive tasks, hypothesized to stem from missing core knowledge\u2014innate human cognitive abilities.", "method": "Introduces CoreCognition, a benchmark with 12 core knowledge concepts, evaluating 230 models across 11 prompts (2,530 data points).", "result": "MLLMs underperform on low-level abilities, show poor scalability, and rely on shortcut learning rather than genuine understanding.", "conclusion": "MLLMs lack core knowledge representation, highlighting the need for improved foundational cognitive modeling."}}
{"id": "2506.17136", "pdf": "https://arxiv.org/pdf/2506.17136", "abs": "https://arxiv.org/abs/2506.17136", "authors": ["Dongdong Meng", "Sheng Li", "Hao Wu", "Guoping Wang", "Xueqing Yan"], "title": "Semi-Supervised Multi-Modal Medical Image Segmentation for Complex Situations", "categories": ["cs.CV"], "comment": "10 pages, 2 figures, accepted at MICCAI 2025", "summary": "Semi-supervised learning addresses the issue of limited annotations in\nmedical images effectively, but its performance is often inadequate for complex\nbackgrounds and challenging tasks. Multi-modal fusion methods can significantly\nimprove the accuracy of medical image segmentation by providing complementary\ninformation. However, they face challenges in achieving significant\nimprovements under semi-supervised conditions due to the challenge of\neffectively leveraging unlabeled data. There is a significant need to create an\neffective and reliable multi-modal learning strategy for leveraging unlabeled\ndata in semi-supervised segmentation. To address these issues, we propose a\nnovel semi-supervised multi-modal medical image segmentation approach, which\nleverages complementary multi-modal information to enhance performance with\nlimited labeled data. Our approach employs a multi-stage multi-modal fusion and\nenhancement strategy to fully utilize complementary multi-modal information,\nwhile reducing feature discrepancies and enhancing feature sharing and\nalignment. Furthermore, we effectively introduce contrastive mutual learning to\nconstrain prediction consistency across modalities, thereby facilitating the\nrobustness of segmentation results in semi-supervised tasks. Experimental\nresults on two multi-modal datasets demonstrate the superior performance and\nrobustness of the proposed framework, establishing its valuable potential for\nsolving medical image segmentation tasks in complex scenarios.", "AI": {"tldr": "A novel semi-supervised multi-modal medical image segmentation approach is proposed to enhance performance with limited labeled data by leveraging complementary multi-modal information and contrastive mutual learning.", "motivation": "Addressing the inadequacy of semi-supervised learning in complex medical image tasks and the challenges of multi-modal fusion under semi-supervised conditions.", "method": "Multi-stage multi-modal fusion and enhancement strategy, along with contrastive mutual learning to ensure prediction consistency across modalities.", "result": "Superior performance and robustness demonstrated on two multi-modal datasets.", "conclusion": "The framework shows valuable potential for solving medical image segmentation in complex scenarios."}}
{"id": "2506.16602", "pdf": "https://arxiv.org/pdf/2506.16602", "abs": "https://arxiv.org/abs/2506.16602", "authors": ["Siddharth Viswanath", "Rahul Singh", "Yanlei Zhang", "J. Adam Noah", "Joy Hirsch", "Smita Krishnaswamy"], "title": "SlepNet: Spectral Subgraph Representation Learning for Neural Dynamics", "categories": ["cs.LG"], "comment": null, "summary": "Graph neural networks have been useful in machine learning on\ngraph-structured data, particularly for node classification and some types of\ngraph classification tasks. However, they have had limited use in representing\npatterning of signals over graphs. Patterning of signals over graphs and in\nsubgraphs carries important information in many domains including neuroscience.\nNeural signals are spatiotemporally patterned, high dimensional and difficult\nto decode. Graph signal processing and associated GCN models utilize the graph\nFourier transform and are unable to efficiently represent spatially or\nspectrally localized signal patterning on graphs. Wavelet transforms have shown\npromise here, but offer non-canonical representations and cannot be tightly\nconfined to subgraphs. Here we propose SlepNet, a novel GCN architecture that\nuses Slepian bases rather than graph Fourier harmonics. In SlepNet, the Slepian\nharmonics optimally concentrate signal energy on specifically relevant\nsubgraphs that are automatically learned with a mask. Thus, they can produce\ncanonical and highly resolved representations of neural activity, focusing\nenergy of harmonics on areas of the brain which are activated. We evaluated\nSlepNet across three fMRI datasets, spanning cognitive and visual tasks, and\ntwo traffic dynamics datasets, comparing its performance against conventional\nGNNs and graph signal processing constructs. SlepNet outperforms the baselines\nin all datasets. Moreover, the extracted representations of signal patterns\nfrom SlepNet offers more resolution in distinguishing between similar patterns,\nand thus represent brain signaling transients as informative trajectories. Here\nwe have shown that these extracted trajectory representations can be used for\nother downstream untrained tasks. Thus we establish that SlepNet is useful both\nfor prediction and representation learning in spatiotemporal data.", "AI": {"tldr": "SlepNet, a novel GCN architecture using Slepian bases, outperforms traditional GNNs in representing and predicting spatiotemporal signal patterns on graphs, particularly in neuroscience and traffic dynamics.", "motivation": "Existing GNNs and graph signal processing methods struggle to efficiently represent localized signal patterning on graphs, which is crucial in domains like neuroscience.", "method": "SlepNet employs Slepian bases to optimally concentrate signal energy on relevant subgraphs, automatically learned with a mask, enabling canonical and high-resolution representations.", "result": "SlepNet outperforms baselines in fMRI and traffic datasets, offering better resolution in distinguishing similar patterns and enabling downstream tasks.", "conclusion": "SlepNet is effective for both prediction and representation learning in spatiotemporal data, providing superior performance and interpretability."}}
{"id": "2506.16653", "pdf": "https://arxiv.org/pdf/2506.16653", "abs": "https://arxiv.org/abs/2506.16653", "authors": ["Vladislav Belozerov", "Peter J Barclay", "Askhan Sami"], "title": "LLMs in Coding and their Impact on the Commercial Software Engineering Landscape", "categories": ["cs.SE", "cs.AI", "cs.LG"], "comment": null, "summary": "Large-language-model coding tools are now mainstream in software engineering.\nBut as these same tools move human effort up the development stack, they\npresent fresh dangers: 10% of real prompts leak private data, 42% of generated\nsnippets hide security flaws, and the models can even ``agree'' with wrong\nideas, a trait called sycophancy. We argue that firms must tag and review every\nAI-generated line of code, keep prompts and outputs inside private or\non-premises deployments, obey emerging safety regulations, and add tests that\ncatch sycophantic answers -- so they can gain speed without losing security and\naccuracy.", "AI": {"tldr": "AI coding tools pose risks like data leaks, security flaws, and sycophancy. Firms must review AI-generated code, secure deployments, follow regulations, and test for sycophancy.", "motivation": "Highlight the dangers of mainstream AI coding tools, including privacy leaks, security flaws, and sycophancy, to advocate for safer practices.", "method": "Proposes tagging and reviewing AI-generated code, securing prompts/outputs, adhering to regulations, and testing for sycophantic behavior.", "result": "Identifies risks: 10% prompts leak data, 42% snippets have flaws, and models exhibit sycophancy.", "conclusion": "Firms must implement safeguards to balance speed with security and accuracy in AI-assisted coding."}}
{"id": "2410.11331", "pdf": "https://arxiv.org/pdf/2410.11331", "abs": "https://arxiv.org/abs/2410.11331", "authors": ["Syed Abdul Gaffar Shakhadri", "Kruthika KR", "Rakshit Aralimatti"], "title": "SHAKTI: A 2.5 Billion Parameter Small Language Model Optimized for Edge AI and Low-Resource Environments", "categories": ["cs.CL", "cs.CV", "cs.LG"], "comment": "Paper in pdf format is 11 pages and contains 4 tables", "summary": "We introduce Shakti, a 2.5 billion parameter language model specifically\noptimized for resource-constrained environments such as edge devices, including\nsmartphones, wearables, and IoT systems. Shakti combines high-performance NLP\nwith optimized efficiency and precision, making it ideal for real-time AI\napplications where computational resources and memory are limited. With support\nfor vernacular languages and domain-specific tasks, Shakti excels in industries\nsuch as healthcare, finance, and customer service. Benchmark evaluations\ndemonstrate that Shakti performs competitively against larger models while\nmaintaining low latency and on-device efficiency, positioning it as a leading\nsolution for edge AI.", "AI": {"tldr": "Shakti is a 2.5B parameter language model optimized for edge devices, offering efficient, real-time NLP with support for vernacular languages and domain-specific tasks.", "motivation": "To address the need for high-performance NLP in resource-constrained environments like edge devices.", "method": "Optimizes efficiency and precision for edge devices, supports vernacular languages and domain-specific tasks.", "result": "Competes with larger models while maintaining low latency and on-device efficiency.", "conclusion": "Shakti is a leading solution for edge AI, ideal for industries like healthcare, finance, and customer service."}}
{"id": "2506.17137", "pdf": "https://arxiv.org/pdf/2506.17137", "abs": "https://arxiv.org/abs/2506.17137", "authors": ["Zhuonan Liang", "Dongnan Liu", "Jianan Fan", "Yaxuan Song", "Qiang Qu", "Yu Yao", "Peng Fu", "Weidong Cai"], "title": "On the Theory of Conditional Feature Alignment for Unsupervised Domain-Adaptive Counting", "categories": ["cs.CV"], "comment": "18 pages, 5 figures, 8 tables", "summary": "Object counting models suffer when deployed across domains with differing\ndensity variety, since density shifts are inherently task-relevant and violate\nstandard domain adaptation assumptions. To address this, we propose a\ntheoretical framework of conditional feature alignment. We first formalize the\nnotion of conditional divergence by partitioning each domain into subsets\n(e.g., object vs. background) and measuring divergences per condition. We then\nderive a joint error bound showing that, under discrete label spaces treated as\ncondition sets, aligning distributions conditionally leads to tighter bounds on\nthe combined source-target decision error than unconditional alignment. These\ninsights motivate a general conditional adaptation principle: by preserving\ntask-relevant variations while filtering out nuisance shifts, one can achieve\nsuperior cross-domain generalization for counting. We provide both defining\nconditional divergence then proving its benefit in lowering joint error and a\npractical adaptation strategy that preserves task-relevant information in\nunsupervised domain-adaptive counting. We demonstrate the effectiveness of our\napproach through extensive experiments on multiple counting datasets with\nvarying density distributions. The results show that our method outperforms\nexisting unsupervised domain adaptation methods, empirically validating the\ntheoretical insights on conditional feature alignment.", "AI": {"tldr": "The paper proposes a theoretical framework for conditional feature alignment to address domain adaptation challenges in object counting, showing improved performance over unconditional methods.", "motivation": "Standard domain adaptation fails for object counting due to density shifts, which are task-relevant. The paper aims to address this by aligning features conditionally.", "method": "The framework formalizes conditional divergence by partitioning domains into subsets (e.g., object vs. background) and aligns distributions per condition. A joint error bound is derived to justify conditional alignment.", "result": "Experiments on counting datasets show the method outperforms existing unsupervised domain adaptation techniques, validating the theoretical insights.", "conclusion": "Conditional feature alignment preserves task-relevant variations while filtering nuisance shifts, leading to superior cross-domain generalization for counting tasks."}}
{"id": "2506.16629", "pdf": "https://arxiv.org/pdf/2506.16629", "abs": "https://arxiv.org/abs/2506.16629", "authors": ["Eric V. Strobl"], "title": "Learning Causally Predictable Outcomes from Psychiatric Longitudinal Data", "categories": ["cs.LG", "q-bio.QM", "stat.ML"], "comment": "R code is available at github.com/ericstrobl/DEBIAS", "summary": "Causal inference in longitudinal biomedical data remains a central challenge,\nespecially in psychiatry, where symptom heterogeneity and latent confounding\nfrequently undermine classical estimators. Most existing methods for treatment\neffect estimation presuppose a fixed outcome variable and address confounding\nthrough observed covariate adjustment. However, the assumption of\nunconfoundedness may not hold for a fixed outcome in practice. To address this\nfoundational limitation, we directly optimize the outcome definition to\nmaximize causal identifiability. Our DEBIAS (Durable Effects with\nBackdoor-Invariant Aggregated Symptoms) algorithm learns non-negative,\nclinically interpretable weights for outcome aggregation, maximizing durable\ntreatment effects and empirically minimizing both observed and latent\nconfounding by leveraging the time-limited direct effects of prior treatments\nin psychiatric longitudinal data. The algorithm also furnishes an empirically\nverifiable test for outcome unconfoundedness. DEBIAS consistently outperforms\nstate-of-the-art methods in recovering causal effects for clinically\ninterpretable composite outcomes across comprehensive experiments in depression\nand schizophrenia.", "AI": {"tldr": "DEBIAS optimizes outcome definitions for causal inference in psychiatry, outperforming existing methods by addressing confounding through interpretable symptom aggregation.", "motivation": "Causal inference in psychiatry is challenged by symptom heterogeneity and latent confounding, which existing methods inadequately address due to fixed outcome assumptions.", "method": "DEBIAS learns non-negative, interpretable weights for symptom aggregation to maximize causal identifiability and minimize confounding, leveraging prior treatment effects.", "result": "DEBIAS outperforms state-of-the-art methods in recovering causal effects for depression and schizophrenia, with verifiable unconfoundedness tests.", "conclusion": "DEBIAS effectively addresses confounding in psychiatric longitudinal data by optimizing outcome definitions, offering a robust solution for causal inference."}}
{"id": "2506.16654", "pdf": "https://arxiv.org/pdf/2506.16654", "abs": "https://arxiv.org/abs/2506.16654", "authors": ["Vijay Prakash Dwivedi", "Charilaos Kanatsoulis", "Shenyang Huang", "Jure Leskovec"], "title": "Relational Deep Learning: Challenges, Foundations and Next-Generation Architectures", "categories": ["cs.LG", "cs.AI", "cs.DB"], "comment": null, "summary": "Graph machine learning has led to a significant increase in the capabilities\nof models that learn on arbitrary graph-structured data and has been applied to\nmolecules, social networks, recommendation systems, and transportation, among\nother domains. Data in multi-tabular relational databases can also be\nconstructed as 'relational entity graphs' for Relational Deep Learning (RDL) -\na new blueprint that enables end-to-end representation learning without\ntraditional feature engineering. Compared to arbitrary graph-structured data,\nrelational entity graphs have key properties: (i) their structure is defined by\nprimary-foreign key relationships between entities in different tables, (ii)\nthe structural connectivity is a function of the relational schema defining a\ndatabase, and (iii) the graph connectivity is temporal and heterogeneous in\nnature. In this paper, we provide a comprehensive review of RDL by first\nintroducing the representation of relational databases as relational entity\ngraphs, and then reviewing public benchmark datasets that have been used to\ndevelop and evaluate recent GNN-based RDL models. We discuss key challenges\nincluding large-scale multi-table integration and the complexities of modeling\ntemporal dynamics and heterogeneous data, while also surveying foundational\nneural network methods and recent architectural advances specialized for\nrelational entity graphs. Finally, we explore opportunities to unify these\ndistinct modeling challenges, highlighting how RDL converges multiple\nsub-fields in graph machine learning towards the design of foundation models\nthat can transform the processing of relational data.", "AI": {"tldr": "The paper reviews Relational Deep Learning (RDL), which transforms relational databases into relational entity graphs for end-to-end learning, addressing challenges like multi-table integration and temporal dynamics, and explores unifying these for foundation models.", "motivation": "To bridge the gap between graph machine learning and relational databases by introducing RDL, enabling representation learning without traditional feature engineering.", "method": "Represent relational databases as relational entity graphs, review benchmark datasets, and survey GNN-based methods and architectural advances for RDL.", "result": "Identifies key challenges (e.g., multi-table integration, temporal dynamics) and recent advances in RDL, proposing unification for foundation models.", "conclusion": "RDL converges graph machine learning sub-fields, offering potential for foundation models to revolutionize relational data processing."}}
{"id": "2410.13284", "pdf": "https://arxiv.org/pdf/2410.13284", "abs": "https://arxiv.org/abs/2410.13284", "authors": ["Yu-Neng Chuang", "Prathusha Kameswara Sarma", "Parikshit Gopalan", "John Boccio", "Sara Bolouki", "Xia Hu", "Helen Zhou"], "title": "Learning to Route LLMs with Confidence Tokens", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "Large language models (LLMs) have demonstrated impressive performance on\nseveral tasks and are increasingly deployed in real-world applications.\nHowever, especially in high-stakes settings, it becomes vital to know when the\noutput of an LLM may be unreliable. Depending on whether an answer is\ntrustworthy, a system can then choose to route the question to another expert,\nor otherwise fall back on a safe default behavior. In this work, we study the\nextent to which LLMs can reliably indicate confidence in their answers, and how\nthis notion of confidence can translate into downstream accuracy gains. We\npropose Self-Reflection with Error-based Feedback (Self-REF), a lightweight\ntraining strategy to teach LLMs to express confidence in whether their answers\nare correct in a reliable manner. Self-REF introduces confidence tokens into\nthe LLM, from which a confidence score can be extracted. Compared to\nconventional approaches such as verbalizing confidence and examining token\nprobabilities, we demonstrate empirically that confidence tokens show\nsignificant improvements in downstream routing and rejection learning tasks.", "AI": {"tldr": "The paper proposes Self-REF, a method to train LLMs to reliably express confidence in their answers, improving downstream accuracy.", "motivation": "In high-stakes settings, unreliable LLM outputs can be risky. Knowing when an answer is trustworthy allows systems to route questions appropriately or default to safe behavior.", "method": "Self-Reflection with Error-based Feedback (Self-REF) introduces confidence tokens into LLMs to extract reliable confidence scores.", "result": "Confidence tokens outperform conventional methods like verbalizing confidence or token probabilities, showing significant gains in routing and rejection tasks.", "conclusion": "Self-REF enhances LLM reliability by enabling accurate confidence expression, improving practical deployment in critical applications."}}
{"id": "2506.17144", "pdf": "https://arxiv.org/pdf/2506.17144", "abs": "https://arxiv.org/abs/2506.17144", "authors": ["Ritabrata Chakraborty", "Rajatsubhra Chakraborty", "Avijit Dasgupta", "Sandeep Chaurasia"], "title": "Do We Need Large VLMs for Spotting Soccer Actions?", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": "5 pages, 2 figures", "summary": "Traditional video-based tasks like soccer action spotting rely heavily on\nvisual inputs, often requiring complex and computationally expensive models to\nprocess dense video data. In this work, we propose a shift from this\nvideo-centric approach to a text-based task, making it lightweight and scalable\nby utilizing Large Language Models (LLMs) instead of Vision-Language Models\n(VLMs). We posit that expert commentary, which provides rich, fine-grained\ndescriptions and contextual cues such as excitement and tactical insights,\ncontains enough information to reliably spot key actions in a match. To\ndemonstrate this, we use the SoccerNet Echoes dataset, which provides\ntimestamped commentary, and employ a system of three LLMs acting as judges\nspecializing in outcome, excitement, and tactics. Each LLM evaluates sliding\nwindows of commentary to identify actions like goals, cards, and substitutions,\ngenerating accurate timestamps for these events. Our experiments show that this\nlanguage-centric approach performs effectively in detecting critical match\nevents, providing a lightweight and training-free alternative to traditional\nvideo-based methods for action spotting.", "AI": {"tldr": "The paper proposes a text-based approach using LLMs for soccer action spotting, replacing traditional video-centric methods, and demonstrates its effectiveness on the SoccerNet Echoes dataset.", "motivation": "To create a lightweight, scalable alternative to computationally expensive video-based action spotting by leveraging expert commentary and LLMs.", "method": "Utilizes three specialized LLMs (outcome, excitement, tactics) to evaluate timestamped commentary from SoccerNet Echoes, identifying key actions like goals and cards.", "result": "The language-centric approach effectively detects critical match events without training, offering a lightweight alternative to video-based methods.", "conclusion": "Text-based action spotting using LLMs is a viable, efficient alternative to traditional video-centric approaches."}}
{"id": "2506.16644", "pdf": "https://arxiv.org/pdf/2506.16644", "abs": "https://arxiv.org/abs/2506.16644", "authors": ["Eren Akbiyik", "Jo\u00e3o Almeida", "Rik Melis", "Ritu Sriram", "Viviana Petrescu", "Vilhj\u00e1lmur Vilhj\u00e1lmsson"], "title": "Semantic Outlier Removal with Embedding Models and LLMs", "categories": ["cs.LG", "cs.IR"], "comment": "Accepted to the 63rd Annual Meeting of the Association for\n  Computational Linguistics (ACL 2025) Industry Track, 10 pages", "summary": "Modern text processing pipelines demand robust methods to remove extraneous\ncontent while preserving a document's core message. Traditional approaches such\nas HTML boilerplate extraction or keyword filters often fail in multilingual\nsettings and struggle with context-sensitive nuances, whereas Large Language\nModels (LLMs) offer improved quality at high computational cost. We introduce\nSORE (Semantic Outlier Removal), a cost-effective, transparent method that\nleverages multilingual sentence embeddings and approximate nearest-neighbor\nsearch to identify and excise unwanted text segments. By first identifying core\ncontent via metadata embedding and then flagging segments that either closely\nmatch predefined outlier groups or deviate significantly from the core, SORE\nachieves near-LLM extraction precision at a fraction of the cost. Experiments\non HTML datasets demonstrate that SORE outperforms structural methods and yield\nhigh precision in diverse scenarios. Our system is currently deployed in\nproduction, processing millions of documents daily across multiple languages\nwhile maintaining both efficiency and accuracy. To facilitate reproducibility\nand further research, we release our implementation and evaluation datasets.", "AI": {"tldr": "SORE (Semantic Outlier Removal) is a cost-effective method using multilingual sentence embeddings and nearest-neighbor search to remove unwanted text segments, achieving high precision like LLMs but at lower cost.", "motivation": "Traditional text processing methods struggle with multilingual and context-sensitive content, while LLMs are costly. SORE aims to bridge this gap.", "method": "SORE uses metadata embedding to identify core content and flags segments matching outlier groups or deviating from the core.", "result": "SORE outperforms structural methods and achieves near-LLM precision in HTML datasets, processing millions of documents daily.", "conclusion": "SORE offers an efficient, accurate alternative to traditional and LLM-based methods, with released implementation for reproducibility."}}
{"id": "2506.16659", "pdf": "https://arxiv.org/pdf/2506.16659", "abs": "https://arxiv.org/abs/2506.16659", "authors": ["Athanasios Glentis", "Jiaxiang Li", "Andi Han", "Mingyi Hong"], "title": "A Minimalist Optimizer Design for LLM Pretraining", "categories": ["cs.LG", "cs.AI", "math.OC"], "comment": null, "summary": "Training large language models (LLMs) typically relies on adaptive optimizers\nsuch as Adam, which require significant memory to maintain first- and\nsecond-moment matrices, known as optimizer states. While recent works such as\nGaLore, Fira, and APOLLO have proposed state-compressed variants to reduce\nmemory consumption, a fundamental question remains: What is the minimal amount\nof optimizer state that is truly necessary to retain state-of-the-art\nperformance in LLM pretraining? In this work, we systematically investigate\nthis question using a bottom-up approach. We find that two memory- and\ncompute-efficient optimization techniques are particularly effective: (1)\ncolumn-wise gradient normalization significantly boosts the performance of\nplain SGD without requiring momentum; and (2) adding first-order momentum only\nto the output layer - where gradient variance is highest - yields performance\ncompetitive with fully adaptive methods such as Muon. Based on these insights,\nwe propose SCALE (Stochastic Column-normalized Last-layer Momentum), a new\noptimizer that combines column-normalized SGD with last-layer momentum, where\ncolumn normalization refers to normalizing the gradient along the output\ndimension. Across multiple LLaMA models (60M-1B), SCALE matches or exceeds the\nperformance of Adam while using only 35-45% of the total memory. It also\nconsistently outperforms memory-efficient optimizers such as GaLore, Fira, and\nAPOLLO, making it a strong candidate for large-scale pretraining under memory\nconstraints. For the LLaMA 7B model, SCALE outperforms the state-of-the-art\nmethod APOLLO in terms of both perplexity and memory consumption. In addition,\nour method serves as a minimalist baseline for more sophisticated optimizer\ndesign.", "AI": {"tldr": "SCALE, a new optimizer combining column-normalized SGD and last-layer momentum, matches or exceeds Adam's performance while using 35-45% less memory, outperforming other memory-efficient methods.", "motivation": "To determine the minimal optimizer state needed for state-of-the-art LLM pretraining performance and reduce memory consumption.", "method": "Systematic investigation using a bottom-up approach, focusing on column-wise gradient normalization and first-order momentum for the output layer.", "result": "SCALE matches or outperforms Adam and other memory-efficient optimizers (e.g., GaLore, Fira, APOLLO) in performance and memory efficiency.", "conclusion": "SCALE is a strong candidate for large-scale pretraining under memory constraints and serves as a minimalist baseline for future optimizer designs."}}
{"id": "2410.15865", "pdf": "https://arxiv.org/pdf/2410.15865", "abs": "https://arxiv.org/abs/2410.15865", "authors": ["Emily Cheng", "Francesca Franzon"], "title": "Principles of semantic and functional efficiency in grammatical patterning", "categories": ["cs.CL"], "comment": null, "summary": "Grammatical features such as number and gender serve two central functions in\nhuman languages. While they encode salient semantic attributes like numerosity\nand animacy, they also offload sentence processing cost by predictably linking\nwords together via grammatical agreement. Grammars exhibit consistent\norganizational patterns across diverse languages, invariably rooted in a\nsemantic foundation-a widely confirmed but still theoretically unexplained\nphenomenon. To explain the basis of universal grammatical patterns, we unify\ntwo fundamental properties of grammar, semantic encoding and agreement-based\npredictability, into a single information-theoretic objective under cognitive\nconstraints, accounting for variable communicative need. Our analyses reveal\nthat grammatical organization provably inherits from perceptual attributes, and\nour measurements on a diverse language sample show that grammars prioritize\nfunctional goals, promoting efficient language processing over semantic\nencoding.", "AI": {"tldr": "The paper explores how grammatical features like number and gender serve dual functions\u2014semantic encoding and agreement-based predictability\u2014and proposes an information-theoretic framework to explain universal grammatical patterns.", "motivation": "To explain the consistent organizational patterns of grammatical features across languages, which are rooted in semantics but lack theoretical explanation.", "method": "The study unifies semantic encoding and agreement-based predictability into an information-theoretic objective under cognitive constraints, analyzing perceptual attributes and measuring language samples.", "result": "Grammatical organization is shown to derive from perceptual attributes, with grammars prioritizing efficient processing over semantic encoding.", "conclusion": "Grammars universally balance semantic and functional goals, optimizing language processing efficiency."}}
{"id": "2506.17159", "pdf": "https://arxiv.org/pdf/2506.17159", "abs": "https://arxiv.org/abs/2506.17159", "authors": ["Qing Xu", "Yuxiang Luo", "Wenting Duan", "Zhen Chen"], "title": "Co-Seg++: Mutual Prompt-Guided Collaborative Learning for Versatile Medical Segmentation", "categories": ["cs.CV"], "comment": "Under Review", "summary": "Medical image analysis is critical yet challenged by the need of jointly\nsegmenting organs or tissues, and numerous instances for anatomical structures\nand tumor microenvironment analysis. Existing studies typically formulated\ndifferent segmentation tasks in isolation, which overlooks the fundamental\ninterdependencies between these tasks, leading to suboptimal segmentation\nperformance and insufficient medical image understanding. To address this\nissue, we propose a Co-Seg++ framework for versatile medical segmentation.\nSpecifically, we introduce a novel co-segmentation paradigm, allowing semantic\nand instance segmentation tasks to mutually enhance each other. We first devise\na spatio-temporal prompt encoder (STP-Encoder) to capture long-range spatial\nand temporal relationships between segmentation regions and image embeddings as\nprior spatial constraints. Moreover, we devise a multi-task collaborative\ndecoder (MTC-Decoder) that leverages cross-guidance to strengthen the\ncontextual consistency of both tasks, jointly computing semantic and instance\nsegmentation masks. Extensive experiments on diverse CT and histopathology\ndatasets demonstrate that the proposed Co-Seg++ outperforms state-of-the-arts\nin the semantic, instance, and panoptic segmentation of dental anatomical\nstructures, histopathology tissues, and nuclei instances. The source code is\navailable at https://github.com/xq141839/Co-Seg-Plus.", "AI": {"tldr": "Co-Seg++ is a framework for medical image segmentation that jointly performs semantic and instance segmentation, leveraging mutual enhancement between tasks for improved performance.", "motivation": "Existing methods treat segmentation tasks in isolation, ignoring interdependencies, leading to suboptimal results.", "method": "Introduces a co-segmentation paradigm with a spatio-temporal prompt encoder (STP-Encoder) and multi-task collaborative decoder (MTC-Decoder) for joint semantic and instance segmentation.", "result": "Outperforms state-of-the-art methods on CT and histopathology datasets for semantic, instance, and panoptic segmentation.", "conclusion": "Co-Seg++ effectively addresses interdependencies in segmentation tasks, improving medical image analysis."}}
{"id": "2506.16651", "pdf": "https://arxiv.org/pdf/2506.16651", "abs": "https://arxiv.org/abs/2506.16651", "authors": ["Guy Blanc", "Jane Lange", "Carmen Strassle", "Li-Yang Tan"], "title": "A Distributional-Lifting Theorem for PAC Learning", "categories": ["cs.LG", "cs.CC", "cs.DS"], "comment": "COLT 2025", "summary": "The apparent difficulty of efficient distribution-free PAC learning has led\nto a large body of work on distribution-specific learning. Distributional\nassumptions facilitate the design of efficient algorithms but also limit their\nreach and relevance. Towards addressing this, we prove a distributional-lifting\ntheorem: This upgrades a learner that succeeds with respect to a limited\ndistribution family $\\mathcal{D}$ to one that succeeds with respect to any\ndistribution $D^\\star$, with an efficiency overhead that scales with the\ncomplexity of expressing $D^\\star$ as a mixture of distributions in\n$\\mathcal{D}$.\n  Recent work of Blanc, Lange, Malik, and Tan considered the special case of\nlifting uniform-distribution learners and designed a lifter that uses a\nconditional sample oracle for $D^\\star$, a strong form of access not afforded\nby the standard PAC model. Their approach, which draws on ideas from\nsemi-supervised learning, first learns $D^\\star$ and then uses this information\nto lift.\n  We show that their approach is information-theoretically intractable with\naccess only to random examples, thereby giving formal justification for their\nuse of the conditional sample oracle. We then take a different approach that\nsidesteps the need to learn $D^\\star$, yielding a lifter that works in the\nstandard PAC model and enjoys additional advantages: it works for all base\ndistribution families, preserves the noise tolerance of learners, has better\nsample complexity, and is simpler.", "AI": {"tldr": "The paper introduces a distributional-lifting theorem to upgrade learners limited to specific distributions to work with any distribution, improving efficiency and relevance.", "motivation": "Address the limitations of distribution-specific learning by enabling efficient learning for any distribution without strong access requirements.", "method": "Prove a distributional-lifting theorem and develop a lifter that works in the standard PAC model, avoiding the need for conditional sample oracles.", "result": "The new lifter is efficient, works for all base distributions, preserves noise tolerance, and improves sample complexity.", "conclusion": "The approach simplifies and generalizes distribution-free learning, making it more practical and broadly applicable."}}
{"id": "2506.16683", "pdf": "https://arxiv.org/pdf/2506.16683", "abs": "https://arxiv.org/abs/2506.16683", "authors": ["Penglong Zhai", "Yifang Yuan", "Fanyi Di", "Jie Li", "Yue Liu", "Chen Li", "Jie Huang", "Sicong Wang", "Yao Xu", "Xin Li"], "title": "A Simple Contrastive Framework Of Item Tokenization For Generative Recommendation", "categories": ["cs.IR", "cs.AI"], "comment": "12 pages,7 figures", "summary": "Generative retrieval-based recommendation has emerged as a promising paradigm\naiming at directly generating the identifiers of the target candidates.\nHowever, in large-scale recommendation systems, this approach becomes\nincreasingly cumbersome due to the redundancy and sheer scale of the token\nspace. To overcome these limitations, recent research has explored the use of\nsemantic tokens as an alternative to ID tokens, which typically leveraged\nreconstruction-based strategies, like RQ-VAE, to quantize content embeddings\nand significantly reduce the embedding size. However, reconstructive\nquantization aims for the precise reconstruction of each item embedding\nindependently, which conflicts with the goal of generative retrieval tasks\nfocusing more on differentiating among items. Moreover, multi-modal side\ninformation of items, such as descriptive text and images, geographical\nknowledge in location-based recommendation services, has been shown to be\neffective in improving recommendations by providing richer contexts for\ninteractions. Nevertheless, effectively integrating such complementary\nknowledge into existing generative recommendation frameworks remains\nchallenging. To overcome these challenges, we propose a novel unsupervised deep\nquantization exclusively based on contrastive learning, named SimCIT (a Simple\nContrastive Item Tokenization framework). Specifically, different from existing\nreconstruction-based strategies, SimCIT propose to use a learnable residual\nquantization module to align with the signals from different modalities of the\nitems, which combines multi-modal knowledge alignment and semantic tokenization\nin a mutually beneficial contrastive learning framework. Extensive experiments\nacross public datasets and a large-scale industrial dataset from various\ndomains demonstrate SimCIT's effectiveness in LLM-based generative\nrecommendation.", "AI": {"tldr": "SimCIT introduces a contrastive learning-based quantization method for generative retrieval, improving efficiency and performance by aligning multi-modal item signals.", "motivation": "Addressing the redundancy and scale issues in generative retrieval-based recommendation, and the challenge of integrating multi-modal side information effectively.", "method": "Proposes SimCIT, an unsupervised deep quantization framework using contrastive learning and a learnable residual quantization module to align multi-modal item signals.", "result": "Demonstrates effectiveness across public and industrial datasets, enhancing generative recommendation performance.", "conclusion": "SimCIT successfully integrates multi-modal knowledge and improves generative retrieval efficiency and accuracy."}}
{"id": "2411.04291", "pdf": "https://arxiv.org/pdf/2411.04291", "abs": "https://arxiv.org/abs/2411.04291", "authors": ["Saketh Bachu", "Erfan Shayegani", "Rohit Lal", "Trishna Chakraborty", "Arindam Dutta", "Chengyu Song", "Yue Dong", "Nael Abu-Ghazaleh", "Amit K. Roy-Chowdhury"], "title": "Layer-wise Alignment: Examining Safety Alignment Across Image Encoder Layers in Vision Language Models", "categories": ["cs.CL", "cs.CV"], "comment": "Accepted by ICML 2025 as a spotlight poster", "summary": "Vision-language models (VLMs) have improved significantly in their\ncapabilities, but their complex architecture makes their safety alignment\nchallenging. In this paper, we reveal an uneven distribution of harmful\ninformation across the intermediate layers of the image encoder and show that\nskipping a certain set of layers and exiting early can increase the chance of\nthe VLM generating harmful responses. We call it as \"Image enCoder Early-exiT\"\nbased vulnerability (ICET). Our experiments across three VLMs: LLaVA-1.5,\nLLaVA-NeXT, and Llama 3.2, show that performing early exits from the image\nencoder significantly increases the likelihood of generating harmful outputs.\nTo tackle this, we propose a simple yet effective modification of the\nClipped-Proximal Policy Optimization (Clip-PPO) algorithm for performing\nlayer-wise multi-modal RLHF for VLMs. We term this as Layer-Wise PPO (L-PPO).\nWe evaluate our L-PPO algorithm across three multimodal datasets and show that\nit consistently reduces the harmfulness caused by early exits.", "AI": {"tldr": "The paper identifies a vulnerability (ICET) in VLMs where early exits from image encoder layers increase harmful outputs. It proposes Layer-Wise PPO (L-PPO) to mitigate this.", "motivation": "Addressing the safety alignment challenge in VLMs due to uneven harmful information distribution in intermediate layers.", "method": "Proposes L-PPO, a modified Clip-PPO algorithm, for layer-wise multi-modal RLHF to reduce harmful outputs from early exits.", "result": "Experiments on three VLMs show L-PPO effectively reduces harmfulness caused by ICET vulnerability.", "conclusion": "L-PPO is a simple yet effective solution to improve safety in VLMs by addressing layer-wise vulnerabilities."}}
{"id": "2506.17186", "pdf": "https://arxiv.org/pdf/2506.17186", "abs": "https://arxiv.org/abs/2506.17186", "authors": ["Ketil Malde"], "title": "YASMOT: Yet another stereo image multi-object tracker", "categories": ["cs.CV"], "comment": "5 pages", "summary": "There now exists many popular object detectors based on deep learning that\ncan analyze images and extract locations and class labels for occurrences of\nobjects. For image time series (i.e., video or sequences of stills), tracking\nobjects over time and preserving object identity can help to improve object\ndetection performance, and is necessary for many downstream tasks, including\nclassifying and predicting behaviors, and estimating total abundances. Here we\npresent yasmot, a lightweight and flexible object tracker that can process the\noutput from popular object detectors and track objects over time from either\nmonoscopic or stereoscopic camera configurations. In addition, it includes\nfunctionality to generate consensus detections from ensembles of object\ndetectors.", "AI": {"tldr": "yasmot is a lightweight, flexible object tracker for image time series, compatible with popular object detectors and supports monoscopic/stereoscopic cameras.", "motivation": "Tracking objects over time improves detection performance and aids downstream tasks like behavior classification and abundance estimation.", "method": "Processes outputs from object detectors, tracks objects over time, and generates consensus detections from detector ensembles.", "result": "A versatile tracker (yasmot) that works with various detectors and camera setups.", "conclusion": "yasmot provides a practical solution for object tracking in image time series, enhancing detection and enabling advanced analysis."}}
{"id": "2506.16656", "pdf": "https://arxiv.org/pdf/2506.16656", "abs": "https://arxiv.org/abs/2506.16656", "authors": ["Yaozhong Shi", "Zachary E. Ross", "Domniki Asimaki", "Kamyar Azizzadenesheli"], "title": "Mesh-Informed Neural Operator : A Transformer Generative Approach", "categories": ["cs.LG"], "comment": null, "summary": "Generative models in function spaces, situated at the intersection of\ngenerative modeling and operator learning, are attracting increasing attention\ndue to their immense potential in diverse scientific and engineering\napplications. While functional generative models are theoretically domain- and\ndiscretization-agnostic, current implementations heavily rely on the Fourier\nNeural Operator (FNO), limiting their applicability to regular grids and\nrectangular domains. To overcome these critical limitations, we introduce the\nMesh-Informed Neural Operator (MINO). By leveraging graph neural operators and\ncross-attention mechanisms, MINO offers a principled, domain- and\ndiscretization-agnostic backbone for generative modeling in function spaces.\nThis advancement significantly expands the scope of such models to more diverse\napplications in generative, inverse, and regression tasks. Furthermore, MINO\nprovides a unified perspective on integrating neural operators with general\nadvanced deep learning architectures. Finally, we introduce a suite of\nstandardized evaluation metrics that enable objective comparison of functional\ngenerative models, addressing another critical gap in the field.", "AI": {"tldr": "The paper introduces the Mesh-Informed Neural Operator (MINO) to overcome limitations of current functional generative models, expanding their applicability to diverse domains and tasks.", "motivation": "Current functional generative models rely on Fourier Neural Operators (FNO), restricting them to regular grids and rectangular domains. This limits their broader scientific and engineering applications.", "method": "MINO leverages graph neural operators and cross-attention mechanisms to create a domain- and discretization-agnostic backbone for generative modeling in function spaces.", "result": "MINO significantly broadens the applicability of functional generative models, enabling diverse applications in generative, inverse, and regression tasks. It also integrates neural operators with advanced deep learning architectures.", "conclusion": "The paper presents MINO as a principled solution to current limitations, introduces standardized evaluation metrics, and advances the field of functional generative modeling."}}
{"id": "2506.16688", "pdf": "https://arxiv.org/pdf/2506.16688", "abs": "https://arxiv.org/abs/2506.16688", "authors": ["Zhiying Qiu", "Tao Lin"], "title": "Fast and Stable Diffusion Planning through Variational Adaptive Weighting", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Diffusion models have recently shown promise in offline RL. However, these\nmethods often suffer from high training costs and slow convergence,\nparticularly when using transformer-based denoising backbones. While several\noptimization strategies have been proposed -- such as modified noise schedules,\nauxiliary prediction targets, and adaptive loss weighting -- challenges remain\nin achieving stable and efficient training. In particular, existing loss\nweighting functions typically rely on neural network approximators, which can\nbe ineffective in early training phases due to limited generalization capacity\nof MLPs when exposed to sparse feedback in the early training stages. In this\nwork, we derive a variationally optimal uncertainty-aware weighting function\nand introduce a closed-form polynomial approximation method for its online\nestimation under the flow-based generative modeling framework. We integrate our\nmethod into a diffusion planning pipeline and evaluate it on standard offline\nRL benchmarks. Experimental results on Maze2D and Kitchen tasks show that our\nmethod achieves competitive performance with up to 10 times fewer training\nsteps, highlighting its practical effectiveness.", "AI": {"tldr": "The paper introduces a novel uncertainty-aware weighting function for diffusion models in offline RL, improving training efficiency and stability with fewer steps.", "motivation": "Diffusion models in offline RL face high training costs and slow convergence, especially with transformer-based backbones, due to ineffective loss weighting functions.", "method": "The authors derive a variationally optimal uncertainty-aware weighting function and propose a closed-form polynomial approximation method for online estimation.", "result": "Experiments on Maze2D and Kitchen benchmarks show competitive performance with up to 10x fewer training steps.", "conclusion": "The proposed method enhances training efficiency and stability in diffusion-based offline RL, demonstrating practical effectiveness."}}
{"id": "2411.13100", "pdf": "https://arxiv.org/pdf/2411.13100", "abs": "https://arxiv.org/abs/2411.13100", "authors": ["Yunkee Chae", "Eunsik Shin", "Suntae Hwang", "Seungryeol Paik", "Kyogu Lee"], "title": "Song Form-aware Full-Song Text-to-Lyrics Generation with Multi-Level Granularity Syllable Count Control", "categories": ["cs.CL", "cs.AI"], "comment": "Accepted to Interspeech 2025", "summary": "Lyrics generation presents unique challenges, particularly in achieving\nprecise syllable control while adhering to song form structures such as verses\nand choruses. Conventional line-by-line approaches often lead to unnatural\nphrasing, underscoring the need for more granular syllable management. We\npropose a framework for lyrics generation that enables multi-level syllable\ncontrol at the word, phrase, line, and paragraph levels, aware of song form.\nOur approach generates complete lyrics conditioned on input text and song form,\nensuring alignment with specified syllable constraints. Generated lyrics\nsamples are available at: https://tinyurl.com/lyrics9999", "AI": {"tldr": "A framework for lyrics generation with multi-level syllable control, addressing challenges in natural phrasing and song form adherence.", "motivation": "Overcoming unnatural phrasing in conventional line-by-line lyrics generation by enabling precise syllable management.", "method": "Proposes a framework for lyrics generation with syllable control at word, phrase, line, and paragraph levels, aware of song form.", "result": "Generates complete lyrics aligned with input text, song form, and syllable constraints.", "conclusion": "The framework effectively addresses syllable control and song form adherence in lyrics generation."}}
{"id": "2506.17191", "pdf": "https://arxiv.org/pdf/2506.17191", "abs": "https://arxiv.org/abs/2506.17191", "authors": ["Israel Ju\u00e1rez-Jim\u00e9nez", "Tiffany Guadalupe Mart\u00ednez Paredes", "Jes\u00fas Garc\u00eda-Ram\u00edrez", "Eric Ramos Aguilar"], "title": "Facial Landmark Visualization and Emotion Recognition Through Neural Networks", "categories": ["cs.CV", "cs.AI"], "comment": "Best paper Award COMIA 2025", "summary": "Emotion recognition from facial images is a crucial task in human-computer\ninteraction, enabling machines to learn human emotions through facial\nexpressions. Previous studies have shown that facial images can be used to\ntrain deep learning models; however, most of these studies do not include a\nthrough dataset analysis. Visualizing facial landmarks can be challenging when\nextracting meaningful dataset insights; to address this issue, we propose\nfacial landmark box plots, a visualization technique designed to identify\noutliers in facial datasets. Additionally, we compare two sets of facial\nlandmark features: (i) the landmarks' absolute positions and (ii) their\ndisplacements from a neutral expression to the peak of an emotional expression.\nOur results indicate that a neural network achieves better performance than a\nrandom forest classifier.", "AI": {"tldr": "The paper proposes facial landmark box plots for dataset analysis and compares two facial landmark feature sets, finding neural networks outperform random forests in emotion recognition.", "motivation": "Improving emotion recognition from facial images by addressing the lack of thorough dataset analysis and visualization challenges.", "method": "Introduces facial landmark box plots for outlier identification and compares absolute positions vs. displacements of landmarks for emotion recognition.", "result": "Neural networks perform better than random forest classifiers in recognizing emotions from facial landmarks.", "conclusion": "The proposed visualization and feature comparison enhance emotion recognition, with neural networks being more effective."}}
{"id": "2506.16661", "pdf": "https://arxiv.org/pdf/2506.16661", "abs": "https://arxiv.org/abs/2506.16661", "authors": ["Felix Zhou", "Samson Zhou", "Vahab Mirrokni", "Alessandro Epasto", "Vincent Cohen-Addad"], "title": "Private Training & Data Generation by Clustering Embeddings", "categories": ["cs.LG", "cs.CR", "stat.ML"], "comment": null, "summary": "Deep neural networks often use large, high-quality datasets to achieve high\nperformance on many machine learning tasks. When training involves potentially\nsensitive data, this process can raise privacy concerns, as large models have\nbeen shown to unintentionally memorize and reveal sensitive information,\nincluding reconstructing entire training samples. Differential privacy (DP)\nprovides a robust framework for protecting individual data and in particular, a\nnew approach to privately training deep neural networks is to approximate the\ninput dataset with a privately generated synthetic dataset, before any\nsubsequent training algorithm. We introduce a novel principled method for DP\nsynthetic image embedding generation, based on fitting a Gaussian Mixture Model\n(GMM) in an appropriate embedding space using DP clustering. Our method\nprovably learns a GMM under separation conditions. Empirically, a simple\ntwo-layer neural network trained on synthetically generated embeddings achieves\nstate-of-the-art (SOTA) classification accuracy on standard benchmark datasets.\nAdditionally, we demonstrate that our method can generate realistic synthetic\nimages that achieve downstream classification accuracy comparable to SOTA\nmethods. Our method is quite general, as the encoder and decoder modules can be\nfreely substituted to suit different tasks. It is also highly scalable,\nconsisting only of subroutines that scale linearly with the number of samples\nand/or can be implemented efficiently in distributed systems.", "AI": {"tldr": "A novel method for generating differentially private synthetic image embeddings using Gaussian Mixture Models (GMM) achieves SOTA classification accuracy and realistic image generation.", "motivation": "Address privacy concerns in deep neural network training by preventing memorization of sensitive data through differential privacy (DP).", "method": "Privately generate synthetic datasets by fitting a GMM in an embedding space using DP clustering.", "result": "Achieves SOTA classification accuracy on benchmarks and generates realistic synthetic images.", "conclusion": "The method is general, scalable, and effective for privacy-preserving deep learning."}}
{"id": "2506.16723", "pdf": "https://arxiv.org/pdf/2506.16723", "abs": "https://arxiv.org/abs/2506.16723", "authors": ["Yuping Yan", "Yizhi Wang", "Yuanshuai Li", "Yaochu Jin"], "title": "TriCon-SF: A Triple-Shuffle and Contribution-Aware Serial Federated Learning Framework for Heterogeneous Healthcare Data", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Serial pipeline training is an efficient paradigm for handling data\nheterogeneity in cross-silo federated learning with low communication overhead.\nHowever, even without centralized aggregation, direct transfer of models\nbetween clients can violate privacy regulations and remain susceptible to\ngradient leakage and linkage attacks. Additionally, ensuring resilience against\nsemi-honest or malicious clients who may manipulate or misuse received models\nremains a grand challenge, particularly in privacy-sensitive domains such as\nhealthcare. To address these challenges, we propose TriCon-SF, a novel serial\nfederated learning framework that integrates triple shuffling and contribution\nawareness. TriCon-SF introduces three levels of randomization by shuffling\nmodel layers, data segments, and training sequences to break deterministic\nlearning patterns and disrupt potential attack vectors, thereby enhancing\nprivacy and robustness. In parallel, it leverages Shapley value methods to\ndynamically evaluate client contributions during training, enabling the\ndetection of dishonest behavior and enhancing system accountability. Extensive\nexperiments on non-IID healthcare datasets demonstrate that TriCon-SF\noutperforms standard serial and parallel federated learning in both accuracy\nand communication efficiency. Security analysis further supports its resilience\nagainst client-side privacy attacks.", "AI": {"tldr": "TriCon-SF is a serial federated learning framework with triple shuffling and contribution awareness, enhancing privacy, robustness, and accountability in cross-silo settings.", "motivation": "Address privacy violations, gradient leakage, and malicious client behavior in serial pipeline training for federated learning, especially in healthcare.", "method": "Integrates triple shuffling (model layers, data segments, training sequences) and Shapley value-based contribution evaluation.", "result": "Outperforms standard federated learning in accuracy and communication efficiency on non-IID healthcare datasets, with proven resilience against attacks.", "conclusion": "TriCon-SF effectively balances privacy, robustness, and efficiency in federated learning for sensitive domains."}}
{"id": "2411.16813", "pdf": "https://arxiv.org/pdf/2411.16813", "abs": "https://arxiv.org/abs/2411.16813", "authors": ["Svetlana Churina", "Kokil Jaidka"], "title": "Incivility and Rigidity: The Risks of Fine-Tuning LLMs for Political Argumentation", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "The incivility prevalent on platforms like Twitter (now X) and Reddit poses a\nchallenge for developing AI systems that can support productive and\nrhetorically sound political argumentation. In this study, we report\nexperiments with GPT-3.5 Turbo, fine-tuned on two contrasting datasets of\npolitical discussions: high-variance, high-incivility Twitter replies to U.S.\nCongress, and low-variance, low-incivility posts from Reddit's r/ChangeMyView.\nWe systematically evaluate how these data sources and prompting strategies\nshape the rhetorical framing and deliberative quality of model-generated\narguments. Our results show that Reddit-finetuned models produce safer but\nrhetorically rigid arguments, while cross-platform fine-tuning amplifies\ntoxicity. Prompting reduces specific toxic behaviors, such as personal attacks,\nbut fails to fully mitigate the influence of high-incivility training data. We\nintroduce and validate a rhetorical evaluation rubric and provide practical\nguidelines for deploying LLMs in content authoring, moderation, and\ndeliberation support.", "AI": {"tldr": "The study evaluates GPT-3.5 Turbo's performance in political argumentation, comparing fine-tuning on high-incivility Twitter data versus low-incivility Reddit data. Results show Reddit-finetuned models are safer but rigid, while cross-platform fine-tuning increases toxicity. Prompting helps but doesn't fully mitigate toxicity. A rhetorical evaluation rubric is introduced for LLM deployment.", "motivation": "To address the challenge of incivility in online political discussions and develop AI systems for productive argumentation.", "method": "Fine-tuning GPT-3.5 Turbo on high-incivility Twitter replies and low-incivility Reddit posts, evaluating rhetorical framing and deliberative quality.", "result": "Reddit-finetuned models produce safer but rigid arguments; cross-platform fine-tuning amplifies toxicity. Prompting reduces specific toxic behaviors but not fully.", "conclusion": "The study provides a rhetorical evaluation rubric and guidelines for deploying LLMs in content moderation and deliberation support."}}
{"id": "2506.17201", "pdf": "https://arxiv.org/pdf/2506.17201", "abs": "https://arxiv.org/abs/2506.17201", "authors": ["Jiaqi Li", "Junshu Tang", "Zhiyong Xu", "Longhuang Wu", "Yuan Zhou", "Shuai Shao", "Tianbao Yu", "Zhiguo Cao", "Qinglin Lu"], "title": "Hunyuan-GameCraft: High-dynamic Interactive Game Video Generation with Hybrid History Condition", "categories": ["cs.CV"], "comment": "Project page: https://hunyuan-gamecraft.github.io/", "summary": "Recent advances in diffusion-based and controllable video generation have\nenabled high-quality and temporally coherent video synthesis, laying the\ngroundwork for immersive interactive gaming experiences. However, current\nmethods face limitations in dynamics, generality, long-term consistency, and\nefficiency, which limit the ability to create various gameplay videos. To\naddress these gaps, we introduce Hunyuan-GameCraft, a novel framework for\nhigh-dynamic interactive video generation in game environments. To achieve\nfine-grained action control, we unify standard keyboard and mouse inputs into a\nshared camera representation space, facilitating smooth interpolation between\nvarious camera and movement operations. Then we propose a hybrid\nhistory-conditioned training strategy that extends video sequences\nautoregressively while preserving game scene information. Additionally, to\nenhance inference efficiency and playability, we achieve model distillation to\nreduce computational overhead while maintaining consistency across long\ntemporal sequences, making it suitable for real-time deployment in complex\ninteractive environments. The model is trained on a large-scale dataset\ncomprising over one million gameplay recordings across over 100 AAA games,\nensuring broad coverage and diversity, then fine-tuned on a carefully annotated\nsynthetic dataset to enhance precision and control. The curated game scene data\nsignificantly improves the visual fidelity, realism and action controllability.\nExtensive experiments demonstrate that Hunyuan-GameCraft significantly\noutperforms existing models, advancing the realism and playability of\ninteractive game video generation.", "AI": {"tldr": "Hunyuan-GameCraft is a framework for high-dynamic interactive video generation in games, addressing limitations in dynamics, generality, and efficiency. It unifies inputs, uses hybrid training, and employs model distillation for real-time deployment, outperforming existing models.", "motivation": "Current methods for video generation in games lack dynamics, generality, and efficiency, limiting gameplay video creation. Hunyuan-GameCraft aims to overcome these gaps.", "method": "Unifies keyboard/mouse inputs into a shared camera space, uses hybrid history-conditioned training, and applies model distillation for efficiency. Trained on a large dataset of gameplay recordings.", "result": "Outperforms existing models in realism and playability, with improved visual fidelity and action controllability.", "conclusion": "Hunyuan-GameCraft advances interactive game video generation, offering high realism and playability for real-time deployment."}}
{"id": "2506.16698", "pdf": "https://arxiv.org/pdf/2506.16698", "abs": "https://arxiv.org/abs/2506.16698", "authors": ["Dinesh Ramasamy", "Shakti Kumar", "Chris Cadonic", "Jiaxin Yang", "Sohini Roychowdhury", "Esam Abdel Rhman", "Srihari Reddy"], "title": "SIDE: Semantic ID Embedding for effective learning from sequences", "categories": ["cs.LG"], "comment": "7 pages, 4 images, 6 tables", "summary": "Sequence-based recommendations models are driving the state-of-the-art for\nindustrial ad-recommendation systems. Such systems typically deal with user\nhistories or sequence lengths ranging in the order of O(10^3) to O(10^4)\nevents. While adding embeddings at this scale is manageable in pre-trained\nmodels, incorporating them into real-time prediction models is challenging due\nto both storage and inference costs. To address this scaling challenge, we\npropose a novel approach that leverages vector quantization (VQ) to inject a\ncompact Semantic ID (SID) as input to the recommendation models instead of a\ncollection of embeddings. Our method builds on recent works of SIDs by\nintroducing three key innovations: (i) a multi-task VQ-VAE framework, called VQ\nfusion that fuses multiple content embeddings and categorical predictions into\na single Semantic ID; (ii) a parameter-free, highly granular SID-to-embedding\nconversion technique, called SIDE, that is validated with two content embedding\ncollections, thereby eliminating the need for a large parameterized lookup\ntable; and (iii) a novel quantization method called Discrete-PCA (DPCA) which\ngeneralizes and enhances residual quantization techniques. The proposed\nenhancements when applied to a large-scale industrial ads-recommendation system\nachieves 2.4X improvement in normalized entropy (NE) gain and 3X reduction in\ndata footprint compared to traditional SID methods.", "AI": {"tldr": "The paper proposes a novel approach using vector quantization (VQ) to create compact Semantic IDs (SIDs) for ad-recommendation systems, improving efficiency and performance.", "motivation": "Handling large-scale user histories in real-time ad-recommendation systems is challenging due to storage and inference costs.", "method": "Introduces VQ fusion (multi-task VQ-VAE), SIDE (SID-to-embedding conversion), and DPCA (Discrete-PCA) for efficient SID generation.", "result": "Achieves 2.4X improvement in normalized entropy gain and 3X reduction in data footprint.", "conclusion": "The proposed method enhances scalability and performance in industrial ad-recommendation systems."}}
{"id": "2506.16732", "pdf": "https://arxiv.org/pdf/2506.16732", "abs": "https://arxiv.org/abs/2506.16732", "authors": ["Fanchen Bu", "Kijung Shin"], "title": "On Training-Test (Mis)alignment in Unsupervised Combinatorial Optimization: Observation, Empirical Exploration, and Analysis", "categories": ["cs.LG", "cs.AI", "cs.DM", "math.PR"], "comment": "2nd Workshop on Test-Time Adaptation: Putting Updates to the Test @\n  ICML 2025", "summary": "In unsupervised combinatorial optimization (UCO), during training, one aims\nto have continuous decisions that are promising in a probabilistic sense for\neach training instance, which enables end-to-end training on initially discrete\nand non-differentiable problems. At the test time, for each test instance,\nstarting from continuous decisions, derandomization is typically applied to\nobtain the final deterministic decisions. Researchers have developed more and\nmore powerful test-time derandomization schemes to enhance the empirical\nperformance and the theoretical guarantee of UCO methods. However, we notice a\nmisalignment between training and testing in the existing UCO methods.\nConsequently, lower training losses do not necessarily entail better\npost-derandomization performance, even for the training instances without any\ndata distribution shift. Empirically, we indeed observe such undesirable cases.\nWe explore a preliminary idea to better align training and testing in UCO by\nincluding a differentiable version of derandomization into training. Our\nempirical exploration shows that such an idea indeed improves training-test\nalignment, but also introduces nontrivial challenges into training.", "AI": {"tldr": "The paper highlights a misalignment between training and testing in unsupervised combinatorial optimization (UCO) and proposes a preliminary idea to align them by integrating differentiable derandomization into training.", "motivation": "Existing UCO methods suffer from a misalignment where lower training losses don't guarantee better post-derandomization performance, even without data distribution shifts.", "method": "The paper explores integrating a differentiable version of derandomization into the training process to align training and testing phases.", "result": "Empirical results show improved alignment but also introduce new training challenges.", "conclusion": "The preliminary idea improves training-test alignment but reveals nontrivial training challenges, suggesting further research is needed."}}
{"id": "2411.19930", "pdf": "https://arxiv.org/pdf/2411.19930", "abs": "https://arxiv.org/abs/2411.19930", "authors": ["Daixuan Cheng", "Shaohan Huang", "Ziyu Zhu", "Xintong Zhang", "Wayne Xin Zhao", "Zhongzhi Luan", "Bo Dai", "Zhenliang Zhang"], "title": "On Domain-Adaptive Post-Training for Multimodal Large Language Models", "categories": ["cs.CL", "cs.CV", "cs.LG"], "comment": "https://huggingface.co/AdaptLLM", "summary": "Adapting general multimodal large language models (MLLMs) to specific\ndomains, such as scientific and industrial fields, is highly significant in\npromoting their practical applications. This paper systematically investigates\ndomain adaptation of MLLMs via post-training, focusing on data synthesis,\ntraining pipeline, and task evaluation. (1) Data Synthesis: Using only\nopen-source models, we develop a generate-then-filter pipeline that curates\ndiverse visual instruction tasks based on domain-specific image-caption pairs.\nThe resulting data surpass the data synthesized by manual rules or strong\nclosed-source models in enhancing domain-specific performance. (2) Training\nPipeline: Unlike general MLLMs that typically adopt a two-stage training\nparadigm, we find that a single-stage approach is more effective for domain\nadaptation. (3) Task Evaluation: We conduct extensive experiments in\nhigh-impact domains such as biomedicine, food, and remote sensing, by\npost-training a variety of MLLMs and then evaluating MLLM performance on\nvarious domain-specific tasks. Finally, we fully open-source our models, code,\nand data to encourage future research in this area.", "AI": {"tldr": "The paper explores domain adaptation for multimodal large language models (MLLMs) via post-training, focusing on data synthesis, training pipeline, and task evaluation, achieving superior results in specialized fields.", "motivation": "To enhance the practical application of MLLMs in scientific and industrial domains by adapting them through post-training.", "method": "Develops a generate-then-filter data synthesis pipeline, adopts a single-stage training approach, and evaluates performance in high-impact domains.", "result": "The synthesized data and single-stage training outperform manual rules and closed-source models, demonstrating effectiveness in domain-specific tasks.", "conclusion": "The study successfully adapts MLLMs to specialized domains, with open-sourced models, code, and data to foster further research."}}
{"id": "2506.17202", "pdf": "https://arxiv.org/pdf/2506.17202", "abs": "https://arxiv.org/abs/2506.17202", "authors": ["Teng Li", "Quanfeng Lu", "Lirui Zhao", "Hao Li", "Xizhou Zhu", "Yu Qiao", "Jun Zhang", "Wenqi Shao"], "title": "UniFork: Exploring Modality Alignment for Unified Multimodal Understanding and Generation", "categories": ["cs.CV"], "comment": "Code: https://github.com/tliby/UniFork", "summary": "Unified image understanding and generation has emerged as a promising\nparadigm in multimodal artificial intelligence. Despite recent progress, the\noptimal architectural design for such unified models remains an open challenge.\nIn this work, we start by analyzing the modality alignment behaviors of\ntask-specific expert models for understanding and generation, as well as\ncurrent unified models. Our analysis reveals a crucial observation:\nunderstanding tasks benefit from a progressively increasing modality alignment\nacross network depth, which helps build up semantic information for better\ncomprehension; In contrast, generation tasks follow a different trend: modality\nalignment increases in the early layers but decreases in the deep layers to\nrecover spatial details. These divergent alignment patterns create a\nfundamental conflict in fully shared Transformer backbones, where a uniform\nrepresentational flow often leads to performance compromises across two tasks.\nMotivated by this finding, we introduce UniFork, a novel Y-shaped architecture\nthat shares the shallow layers for cross-task representation learning, while\nemploying task-specific branches in deeper layers to avoid task interference.\nThis design effectively balances shared learning and task specialization.\nThrough extensive ablation experiments, we demonstrate that Unifork\nconsistently outperforms conventional fully shared Transformer architectures,\nand achieves performance on par with or better than task-specific models.", "AI": {"tldr": "UniFork, a Y-shaped architecture, balances shared learning and task specialization for unified image understanding and generation, outperforming fully shared Transformer models.", "motivation": "The divergent modality alignment patterns in understanding and generation tasks create conflicts in fully shared Transformer backbones, leading to performance compromises.", "method": "Analyzes modality alignment behaviors, then introduces UniFork with shared shallow layers and task-specific deeper branches.", "result": "UniFork outperforms fully shared Transformer architectures and matches or exceeds task-specific models.", "conclusion": "UniFork effectively resolves the conflict in unified models by balancing shared and task-specific learning."}}
{"id": "2506.16704", "pdf": "https://arxiv.org/pdf/2506.16704", "abs": "https://arxiv.org/abs/2506.16704", "authors": ["Cynthia Dwork", "Lunjia Hu", "Han Shao"], "title": "How Many Domains Suffice for Domain Generalization? A Tight Characterization via the Domain Shattering Dimension", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "We study a fundamental question of domain generalization: given a family of\ndomains (i.e., data distributions), how many randomly sampled domains do we\nneed to collect data from in order to learn a model that performs reasonably\nwell on every seen and unseen domain in the family? We model this problem in\nthe PAC framework and introduce a new combinatorial measure, which we call the\ndomain shattering dimension. We show that this dimension characterizes the\ndomain sample complexity. Furthermore, we establish a tight quantitative\nrelationship between the domain shattering dimension and the classic VC\ndimension, demonstrating that every hypothesis class that is learnable in the\nstandard PAC setting is also learnable in our setting.", "AI": {"tldr": "The paper introduces the domain shattering dimension to quantify the number of domains needed for domain generalization, linking it to VC dimension.", "motivation": "To address how many domains are required to learn a model that generalizes well across seen and unseen domains.", "method": "Model the problem in the PAC framework and propose the domain shattering dimension as a combinatorial measure.", "result": "The domain shattering dimension characterizes domain sample complexity and relates to VC dimension, showing PAC-learnable classes remain learnable.", "conclusion": "The domain shattering dimension provides a theoretical foundation for domain generalization, bridging it with classic learning theory."}}
{"id": "2506.16753", "pdf": "https://arxiv.org/pdf/2506.16753", "abs": "https://arxiv.org/abs/2506.16753", "authors": ["Kosuke Nakanishi", "Akihiro Kubo", "Yuji Yasui", "Shin Ishii"], "title": "Off-Policy Actor-Critic for Adversarial Observation Robustness: Virtual Alternative Training via Symmetric Policy Evaluation", "categories": ["cs.LG", "cs.AI", "cs.RO"], "comment": "ICML2025 poster, 39 pages, 6 figures, 13 tables. arXiv admin note:\n  text overlap with arXiv:2409.00418", "summary": "Recently, robust reinforcement learning (RL) methods designed to handle\nadversarial input observations have received significant attention, motivated\nby RL's inherent vulnerabilities. While existing approaches have demonstrated\nreasonable success, addressing worst-case scenarios over long time horizons\nrequires both minimizing the agent's cumulative rewards for adversaries and\ntraining agents to counteract them through alternating learning. However, this\nprocess introduces mutual dependencies between the agent and the adversary,\nmaking interactions with the environment inefficient and hindering the\ndevelopment of off-policy methods. In this work, we propose a novel off-policy\nmethod that eliminates the need for additional environmental interactions by\nreformulating adversarial learning as a soft-constrained optimization problem.\nOur approach is theoretically supported by the symmetric property of policy\nevaluation between the agent and the adversary. The implementation is available\nat https://github.com/nakanakakosuke/VALT_SAC.", "AI": {"tldr": "Proposes a novel off-policy RL method for adversarial robustness by reformulating adversarial learning as a soft-constrained optimization, eliminating extra environmental interactions.", "motivation": "Address inefficiencies and dependencies in existing adversarial RL methods, which hinder off-policy development.", "method": "Reformulates adversarial learning as a soft-constrained optimization, leveraging symmetric policy evaluation.", "result": "Theoretically supported method that avoids additional environmental interactions.", "conclusion": "Offers a practical and efficient solution for adversarial RL with potential for broader off-policy applications."}}
{"id": "2412.14860", "pdf": "https://arxiv.org/pdf/2412.14860", "abs": "https://arxiv.org/abs/2412.14860", "authors": ["Junyi Li", "Hwee Tou Ng"], "title": "Think&Cite: Improving Attributed Text Generation with Self-Guided Tree Search and Progress Reward Modeling", "categories": ["cs.CL"], "comment": "ACL 2025", "summary": "Despite their outstanding capabilities, large language models (LLMs) are\nprone to hallucination and producing factually incorrect information. This\nchallenge has spurred efforts in attributed text generation, which prompts LLMs\nto generate content with supporting evidence. In this paper, we propose a novel\nframework, called Think&Cite, and formulate attributed text generation as a\nmulti-step reasoning problem integrated with search. Specifically, we propose\nSelf-Guided Monte Carlo Tree Search (SG-MCTS), which capitalizes on the\nself-reflection capability of LLMs to reason about the intermediate states of\nMCTS for guiding the tree expansion process. To provide reliable and\ncomprehensive feedback, we introduce Progress Reward Modeling to measure the\nprogress of tree search from the root to the current state from two aspects,\ni.e., generation and attribution progress. We conduct extensive experiments on\nthree datasets and the results show that our approach significantly outperforms\nbaseline approaches.", "AI": {"tldr": "Think&Cite is a framework for attributed text generation in LLMs, using Self-Guided Monte Carlo Tree Search (SG-MCTS) and Progress Reward Modeling to improve accuracy and evidence support.", "motivation": "LLMs often produce incorrect information (hallucination), prompting the need for attributed text generation with supporting evidence.", "method": "Proposes SG-MCTS, leveraging LLMs' self-reflection for multi-step reasoning and search integration, with Progress Reward Modeling for feedback.", "result": "Outperforms baselines on three datasets, demonstrating improved accuracy and attribution.", "conclusion": "Think&Cite effectively addresses LLM hallucination by integrating reasoning and search, validated by strong experimental results."}}
{"id": "2506.17212", "pdf": "https://arxiv.org/pdf/2506.17212", "abs": "https://arxiv.org/abs/2506.17212", "authors": ["Tianjiao Yu", "Vedant Shah", "Muntasir Wahed", "Ying Shen", "Kiet A. Nguyen", "Ismini Lourentzou"], "title": "Part$^{2}$GS: Part-aware Modeling of Articulated Objects using 3D Gaussian Splatting", "categories": ["cs.CV", "cs.AI", "cs.LG", "cs.RO"], "comment": null, "summary": "Articulated objects are common in the real world, yet modeling their\nstructure and motion remains a challenging task for 3D reconstruction methods.\nIn this work, we introduce Part$^{2}$GS, a novel framework for modeling\narticulated digital twins of multi-part objects with high-fidelity geometry and\nphysically consistent articulation. Part$^{2}$GS leverages a part-aware 3D\nGaussian representation that encodes articulated components with learnable\nattributes, enabling structured, disentangled transformations that preserve\nhigh-fidelity geometry. To ensure physically consistent motion, we propose a\nmotion-aware canonical representation guided by physics-based constraints,\nincluding contact enforcement, velocity consistency, and vector-field\nalignment. Furthermore, we introduce a field of repel points to prevent part\ncollisions and maintain stable articulation paths, significantly improving\nmotion coherence over baselines. Extensive evaluations on both synthetic and\nreal-world datasets show that Part$^{2}$GS consistently outperforms\nstate-of-the-art methods by up to 10$\\times$ in Chamfer Distance for movable\nparts.", "AI": {"tldr": "Part$^{2}$GS is a novel framework for modeling articulated objects with high-fidelity geometry and physically consistent motion, outperforming state-of-the-art methods.", "motivation": "Articulated objects are common but challenging to model accurately in 3D reconstruction due to their complex structure and motion.", "method": "Part$^{2}$GS uses a part-aware 3D Gaussian representation with learnable attributes and physics-based constraints (contact enforcement, velocity consistency, vector-field alignment) to ensure consistent motion. A field of repel points prevents part collisions.", "result": "Part$^{2}$GS outperforms state-of-the-art methods by up to 10\u00d7 in Chamfer Distance for movable parts on synthetic and real-world datasets.", "conclusion": "The framework effectively models articulated objects with high fidelity and physical consistency, setting a new benchmark for such tasks."}}
{"id": "2506.16736", "pdf": "https://arxiv.org/pdf/2506.16736", "abs": "https://arxiv.org/abs/2506.16736", "authors": ["John Lazarsfeld", "Georgios Piliouras", "Ryann Sim", "Stratis Skoulakis"], "title": "Optimism Without Regularization: Constant Regret in Zero-Sum Games", "categories": ["cs.LG", "cs.GT"], "comment": null, "summary": "This paper studies the optimistic variant of Fictitious Play for learning in\ntwo-player zero-sum games. While it is known that Optimistic FTRL -- a\nregularized algorithm with a bounded stepsize parameter -- obtains constant\nregret in this setting, we show for the first time that similar, optimal rates\nare also achievable without regularization: we prove for two-strategy games\nthat Optimistic Fictitious Play (using any tiebreaking rule) obtains only\nconstant regret, providing surprising new evidence on the ability of\nnon-no-regret algorithms for fast learning in games. Our proof technique\nleverages a geometric view of Optimistic Fictitious Play in the dual space of\npayoff vectors, where we show a certain energy function of the iterates remains\nbounded over time. Additionally, we also prove a regret lower bound of\n$\\Omega(\\sqrt{T})$ for Alternating Fictitious Play. In the unregularized\nregime, this separates the ability of optimism and alternation in achieving\n$o(\\sqrt{T})$ regret.", "AI": {"tldr": "Optimistic Fictitious Play achieves constant regret in two-strategy zero-sum games without regularization, outperforming Alternating Fictitious Play.", "motivation": "To explore whether non-no-regret algorithms like Optimistic Fictitious Play can achieve fast learning rates in games, similar to regularized methods.", "method": "Analyzes Optimistic Fictitious Play in the dual space of payoff vectors, using a geometric proof technique to show bounded energy of iterates.", "result": "Optimistic Fictitious Play achieves constant regret, while Alternating Fictitious Play has a regret lower bound of \u03a9(\u221aT).", "conclusion": "Optimism enables faster learning (constant regret) compared to alternation in unregularized settings, highlighting its potential for efficient game learning."}}
{"id": "2506.16754", "pdf": "https://arxiv.org/pdf/2506.16754", "abs": "https://arxiv.org/abs/2506.16754", "authors": ["Jongmin Park", "Seunghoon Han", "Won-Yong Shin", "Sungsu Lim"], "title": "Metapath-based Hyperbolic Contrastive Learning for Heterogeneous Graph Embedding", "categories": ["cs.LG", "cs.AI", "cs.SI"], "comment": "14 pages, 9 figures", "summary": "The hyperbolic space, characterized by a constant negative curvature and\nexponentially expanding space, aligns well with the structural properties of\nheterogeneous graphs. However, although heterogeneous graphs inherently possess\ndiverse power-law structures, most hyperbolic heterogeneous graph embedding\nmodels rely on a single hyperbolic space. This approach may fail to effectively\ncapture the diverse power-law structures within heterogeneous graphs. To\naddress this limitation, we propose a Metapath-based Hyperbolic Contrastive\nLearning framework (MHCL), which uses multiple hyperbolic spaces to capture\ndiverse complex structures within heterogeneous graphs. Specifically, by\nlearning each hyperbolic space to describe the distribution of complex\nstructures corresponding to each metapath, it is possible to capture semantic\ninformation effectively. Since metapath embeddings represent distinct semantic\ninformation, preserving their discriminability is important when aggregating\nthem to obtain node representations. Therefore, we use a contrastive learning\napproach to optimize MHCL and improve the discriminability of metapath\nembeddings. In particular, our contrastive learning method minimizes the\ndistance between embeddings of the same metapath and maximizes the distance\nbetween those of different metapaths in hyperbolic space, thereby improving the\nseparability of metapath embeddings with distinct semantic information. We\nconduct comprehensive experiments to evaluate the effectiveness of MHCL. The\nexperimental results demonstrate that MHCL outperforms state-of-the-art\nbaselines in various graph machine learning tasks, effectively capturing the\ncomplex structures of heterogeneous graphs.", "AI": {"tldr": "MHCL uses multiple hyperbolic spaces and contrastive learning to better capture diverse power-law structures in heterogeneous graphs, outperforming baselines.", "motivation": "Existing hyperbolic heterogeneous graph embedding models use a single hyperbolic space, failing to capture diverse power-law structures.", "method": "Proposes MHCL, leveraging multiple hyperbolic spaces and contrastive learning to preserve semantic discriminability of metapath embeddings.", "result": "MHCL outperforms state-of-the-art baselines in graph machine learning tasks.", "conclusion": "MHCL effectively captures complex structures in heterogeneous graphs by using multiple hyperbolic spaces and contrastive learning."}}
{"id": "2502.12685", "pdf": "https://arxiv.org/pdf/2502.12685", "abs": "https://arxiv.org/abs/2502.12685", "authors": ["Yuki Ichihara", "Yuu Jinnai", "Kaito Ariu", "Tetsuro Morimura", "Eiji Uchibe"], "title": "Theoretical Guarantees for Minimum Bayes Risk Decoding", "categories": ["cs.CL"], "comment": null, "summary": "Minimum Bayes Risk (MBR) decoding optimizes output selection by maximizing\nthe expected utility value of an underlying human distribution. While prior\nwork has shown the effectiveness of MBR decoding through empirical evaluation,\nfew studies have analytically investigated why the method is effective. As a\nresult of our analysis, we show that, given the size $n$ of the reference\nhypothesis set used in computation, MBR decoding approaches the optimal\nsolution with high probability at a rate of $O\\left(n^{-\\frac{1}{2}}\\right)$,\nunder certain assumptions, even though the language space $Y$ is significantly\nlarger $|Y|\\gg n$. This result helps to theoretically explain the strong\nperformance observed in several prior empirical studies on MBR decoding. In\naddition, we provide the performance gap for maximum-a-posteriori (MAP)\ndecoding and compare it to MBR decoding. The result of this paper indicates\nthat MBR decoding tends to converge to the optimal solution faster than MAP\ndecoding in several cases.", "AI": {"tldr": "MBR decoding approaches optimality at rate O(n^(-1/2)) with high probability, outperforming MAP decoding in convergence speed.", "motivation": "To analytically explain the effectiveness of MBR decoding, which has been empirically validated but lacks theoretical understanding.", "method": "Theoretical analysis of MBR decoding's convergence rate and comparison with MAP decoding under certain assumptions.", "result": "MBR decoding converges to the optimal solution at rate O(n^(-1/2)) even when the language space is much larger than the reference set.", "conclusion": "MBR decoding is theoretically justified for its strong performance and converges faster than MAP decoding in many cases."}}
{"id": "2506.17213", "pdf": "https://arxiv.org/pdf/2506.17213", "abs": "https://arxiv.org/abs/2506.17213", "authors": ["Xiuyu Yang", "Shuhan Tan", "Philipp Kr\u00e4henb\u00fchl"], "title": "Long-term Traffic Simulation with Interleaved Autoregressive Motion and Scenario Generation", "categories": ["cs.CV", "cs.AI", "cs.RO"], "comment": "Preprint. Project page: https://orangesodahub.github.io/InfGen Code:\n  https://github.com/OrangeSodahub/infgen", "summary": "An ideal traffic simulator replicates the realistic long-term point-to-point\ntrip that a self-driving system experiences during deployment. Prior models and\nbenchmarks focus on closed-loop motion simulation for initial agents in a\nscene. This is problematic for long-term simulation. Agents enter and exit the\nscene as the ego vehicle enters new regions. We propose InfGen, a unified\nnext-token prediction model that performs interleaved closed-loop motion\nsimulation and scene generation. InfGen automatically switches between\nclosed-loop motion simulation and scene generation mode. It enables stable\nlong-term rollout simulation. InfGen performs at the state-of-the-art in\nshort-term (9s) traffic simulation, and significantly outperforms all other\nmethods in long-term (30s) simulation. The code and model of InfGen will be\nreleased at https://orangesodahub.github.io/InfGen", "AI": {"tldr": "InfGen is a unified model for long-term traffic simulation, combining closed-loop motion simulation and scene generation, outperforming existing methods.", "motivation": "Existing traffic simulators focus on short-term closed-loop motion, lacking capability for long-term point-to-point trip simulation.", "method": "InfGen uses a next-token prediction model to interleave closed-loop motion simulation and scene generation, switching modes automatically.", "result": "InfGen achieves state-of-the-art performance in short-term (9s) simulation and excels in long-term (30s) simulation.", "conclusion": "InfGen enables stable long-term traffic simulation and will be publicly released."}}
{"id": "2506.16744", "pdf": "https://arxiv.org/pdf/2506.16744", "abs": "https://arxiv.org/abs/2506.16744", "authors": ["Eion Tyacke", "Kunal Gupta", "Jay Patel", "Rui Li"], "title": "IsoNet: Causal Analysis of Multimodal Transformers for Neuromuscular Gesture Classification", "categories": ["cs.LG", "cs.RO", "eess.SP"], "comment": null, "summary": "Hand gestures are a primary output of the human motor system, yet the\ndecoding of their neuromuscular signatures remains a bottleneck for basic\nneuroscience and assistive technologies such as prosthetics. Traditional\nhuman-machine interface pipelines rely on a single biosignal modality, but\nmultimodal fusion can exploit complementary information from sensors. We\nsystematically compare linear and attention-based fusion strategies across\nthree architectures: a Multimodal MLP, a Multimodal Transformer, and a\nHierarchical Transformer, evaluating performance on scenarios with unimodal and\nmultimodal inputs. Experiments use two publicly available datasets: NinaPro DB2\n(sEMG and accelerometer) and HD-sEMG 65-Gesture (high-density sEMG and force).\nAcross both datasets, the Hierarchical Transformer with attention-based fusion\nconsistently achieved the highest accuracy, surpassing the multimodal and best\nsingle-modality linear-fusion MLP baseline by over 10% on NinaPro DB2 and 3.7%\non HD-sEMG. To investigate how modalities interact, we introduce an Isolation\nNetwork that selectively silences unimodal or cross-modal attention pathways,\nquantifying each group of token interactions' contribution to downstream\ndecisions. Ablations reveal that cross-modal interactions contribute\napproximately 30% of the decision signal across transformer layers,\nhighlighting the importance of attention-driven fusion in harnessing\ncomplementary modality information. Together, these findings reveal when and\nhow multimodal fusion would enhance biosignal classification and also provides\nmechanistic insights of human muscle activities. The study would be beneficial\nin the design of sensor arrays for neurorobotic systems.", "AI": {"tldr": "The paper explores multimodal fusion for decoding hand gestures using biosignals, comparing linear and attention-based strategies. The Hierarchical Transformer with attention-based fusion outperformed others, with cross-modal interactions contributing significantly to decisions.", "motivation": "Decoding neuromuscular signatures of hand gestures is crucial for neuroscience and assistive technologies, but traditional methods rely on single biosignal modalities. Multimodal fusion can leverage complementary sensor data.", "method": "The study compares linear and attention-based fusion strategies across three architectures (Multimodal MLP, Multimodal Transformer, Hierarchical Transformer) using datasets NinaPro DB2 and HD-sEMG 65-Gesture. An Isolation Network analyzes modality interactions.", "result": "The Hierarchical Transformer with attention-based fusion achieved the highest accuracy, outperforming baselines by over 10% on NinaPro DB2 and 3.7% on HD-sEMG. Cross-modal interactions contributed ~30% to decisions.", "conclusion": "Attention-driven multimodal fusion enhances biosignal classification, providing insights into human muscle activities. The findings aid in designing sensor arrays for neurorobotic systems."}}
{"id": "2506.16782", "pdf": "https://arxiv.org/pdf/2506.16782", "abs": "https://arxiv.org/abs/2506.16782", "authors": ["Youjin Kong"], "title": "What Is the Point of Equality in Machine Learning Fairness? Beyond Equality of Opportunity", "categories": ["cs.LG", "cs.AI", "cs.CY"], "comment": "Accepted for presentation at ACM FAccT 2025; under final review\n  (minor revision) at an ACM journal", "summary": "Fairness in machine learning (ML) has become a rapidly growing area of\nresearch. But why, in the first place, is unfairness in ML morally wrong? And\nwhy should we care about improving fairness? Most fair-ML research implicitly\nappeals to distributive equality: the idea that desirable goods and benefits,\nsuch as opportunities (e.g., Barocas et al., 2023), should be equally\ndistributed across society. Unfair ML models, then, are seen as wrong because\nthey unequally distribute such benefits. This paper argues that this exclusive\nfocus on distributive equality offers an incomplete and potentially misleading\nethical foundation. Grounding ML fairness in egalitarianism -- the view that\nequality is a fundamental moral and social ideal -- requires challenging\nstructural inequality: systematic, institutional, and durable arrangements that\nprivilege some groups while disadvantaging others. Structural inequality\nmanifests through ML systems in two primary forms: allocative harms (e.g.,\neconomic loss) and representational harms (e.g., stereotypes, erasure). While\ndistributive equality helps address allocative harms, it fails to explain why\nrepresentational harms are wrong -- why it is wrong for ML systems to reinforce\nsocial hierarchies that stratify people into superior and inferior groups --\nand why ML systems should aim to foster a society where people relate as equals\n(i.e., relational equality). To address these limitations, the paper proposes a\nmultifaceted egalitarian framework for ML fairness that integrates both\ndistributive and relational equality. Drawing on critical social and political\nphilosophy, this framework offers a more comprehensive ethical foundation for\ntackling the full spectrum of harms perpetuated by ML systems. The paper also\noutlines practical pathways for implementing the framework across the ML\npipeline.", "AI": {"tldr": "The paper critiques the focus on distributive equality in fair-ML research, advocating for a broader egalitarian framework that addresses both allocative and representational harms.", "motivation": "Current fair-ML research primarily relies on distributive equality, which inadequately addresses representational harms and structural inequality. The paper seeks a more comprehensive ethical foundation.", "method": "The paper proposes a multifaceted egalitarian framework integrating distributive and relational equality, drawing on critical social and political philosophy.", "result": "The framework provides a more holistic approach to ML fairness, addressing both allocative and representational harms, and suggests practical implementation pathways.", "conclusion": "A broader egalitarian approach is necessary for ML fairness to tackle structural inequality and foster relational equality, offering a more complete ethical foundation."}}
{"id": "2502.12911", "pdf": "https://arxiv.org/pdf/2502.12911", "abs": "https://arxiv.org/abs/2502.12911", "authors": ["Zheng Yuan", "Hao Chen", "Zijin Hong", "Qinggang Zhang", "Feiran Huang", "Qing Li", "Xiao Huang"], "title": "Knapsack Optimization-based Schema Linking for LLM-based Text-to-SQL Generation", "categories": ["cs.CL", "cs.DB"], "comment": null, "summary": "Generating SQLs from user queries is a long-standing challenge, where the\naccuracy of initial schema linking significantly impacts subsequent SQL\ngeneration performance. However, current schema linking models still struggle\nwith missing relevant schema elements or an excess of redundant ones. A crucial\nreason for this is that commonly used metrics, recall and precision, fail to\ncapture relevant element missing and thus cannot reflect actual schema linking\nperformance. Motivated by this, we propose enhanced schema linking metrics by\nintroducing a restricted missing indicator. Accordingly, we introduce Knapsack\noptimization-based Schema Linking Approach (KaSLA), a plug-in schema linking\nmethod designed to prevent the missing of relevant schema elements while\nminimizing the inclusion of redundant ones. KaSLA employs a hierarchical\nlinking strategy that first identifies the optimal table linking and\nsubsequently links columns within the selected table to reduce linking\ncandidate space. In each linking process, it utilizes a knapsack optimization\napproach to link potentially relevant elements while accounting for a limited\ntolerance of potentially redundant ones. With this optimization, KaSLA-1.6B\nachieves superior schema linking results compared to large-scale LLMs,\nincluding deepseek-v3 with the state-of-the-art (SOTA) schema linking method.\nExtensive experiments on Spider and BIRD benchmarks verify that KaSLA can\nsignificantly improve the SQL generation performance of SOTA Text2SQL models by\nsubstituting their schema linking processes.", "AI": {"tldr": "The paper introduces KaSLA, a schema linking method using knapsack optimization to improve SQL generation by reducing missing and redundant schema elements.", "motivation": "Current schema linking models struggle with missing or redundant schema elements, and existing metrics like recall and precision fail to capture these issues effectively.", "method": "Proposes KaSLA, a hierarchical linking method using knapsack optimization to link tables and columns while minimizing redundancy.", "result": "KaSLA outperforms large-scale LLMs like deepseek-v3 and improves SQL generation performance on Spider and BIRD benchmarks.", "conclusion": "KaSLA effectively enhances schema linking and boosts SQL generation accuracy in Text2SQL models."}}
{"id": "2506.17218", "pdf": "https://arxiv.org/pdf/2506.17218", "abs": "https://arxiv.org/abs/2506.17218", "authors": ["Zeyuan Yang", "Xueyang Yu", "Delin Chen", "Maohao Shen", "Chuang Gan"], "title": "Machine Mental Imagery: Empower Multimodal Reasoning with Latent Visual Tokens", "categories": ["cs.CV", "cs.AI"], "comment": "Project page: https://vlm-mirage.github.io/", "summary": "Vision-language models (VLMs) excel at multimodal understanding, yet their\ntext-only decoding forces them to verbalize visual reasoning, limiting\nperformance on tasks that demand visual imagination. Recent attempts train VLMs\nto render explicit images, but the heavy image-generation pre-training often\nhinders the reasoning ability. Inspired by the way humans reason with mental\nimagery-the internal construction and manipulation of visual cues-we\ninvestigate whether VLMs can reason through interleaved multimodal trajectories\nwithout producing explicit images. To this end, we present a Machine Mental\nImagery framework, dubbed as Mirage, which augments VLM decoding with latent\nvisual tokens alongside ordinary text. Concretely, whenever the model chooses\nto ``think visually'', it recasts its hidden states as next tokens, thereby\ncontinuing a multimodal trajectory without generating pixel-level images. Begin\nby supervising the latent tokens through distillation from ground-truth image\nembeddings, we then switch to text-only supervision to make the latent\ntrajectory align tightly with the task objective. A subsequent reinforcement\nlearning stage further enhances the multimodal reasoning capability.\nExperiments on diverse benchmarks demonstrate that Mirage unlocks stronger\nmultimodal reasoning without explicit image generation.", "AI": {"tldr": "Mirage enhances VLMs by using latent visual tokens for reasoning without explicit image generation, improving multimodal performance.", "motivation": "VLMs struggle with tasks requiring visual imagination due to text-only decoding. Existing methods using image-generation pre-training hinder reasoning.", "method": "Mirage introduces latent visual tokens alongside text, supervised via distillation and reinforcement learning, avoiding pixel-level images.", "result": "Mirage improves multimodal reasoning on benchmarks without generating explicit images.", "conclusion": "Mirage enables stronger multimodal reasoning in VLMs by leveraging latent visual tokens, avoiding the limitations of explicit image generation."}}
{"id": "2506.16787", "pdf": "https://arxiv.org/pdf/2506.16787", "abs": "https://arxiv.org/abs/2506.16787", "authors": ["Jiashun Cheng", "Aochuan Chen", "Nuo Chen", "Ziqi Gao", "Yuhan Li", "Jia Li", "Fugee Tsung"], "title": "Revisiting LoRA through the Lens of Parameter Redundancy: Spectral Encoding Helps", "categories": ["cs.LG"], "comment": "18 pages; Accepted to ACL 2025 Findings", "summary": "Low-Rank Adaptation (LoRA) has emerged as a prominent technique for\nfine-tuning large foundation models. Despite its successes, the substantial\nparameter redundancy, which limits the capacity and efficiency of LoRA, has\nbeen recognized as a bottleneck. In this work, we systematically investigate\nthe impact of redundancy in fine-tuning LoRA and reveal that reducing density\nredundancy does not degrade expressiveness. Based on this insight, we introduce\n\\underline{S}pectral-\\underline{e}ncoding \\underline{L}ow-\\underline{R}ank\n\\underline{A}daptation (SeLoRA), which harnesses the robust expressiveness of\nspectral bases to re-parameterize LoRA from a sparse spectral subspace.\nDesigned with simplicity, SeLoRA enables seamless integration with various LoRA\nvariants for performance boosting, serving as a scalable plug-and-play\nframework. Extensive experiments substantiate that SeLoRA achieves greater\nefficiency with fewer parameters, delivering superior performance enhancements\nover strong baselines on various downstream tasks, including commonsense\nreasoning, math reasoning, and code generation.", "AI": {"tldr": "SeLoRA improves LoRA by reducing parameter redundancy using spectral bases, enhancing efficiency and performance without losing expressiveness.", "motivation": "Address the bottleneck of parameter redundancy in LoRA, which limits its capacity and efficiency.", "method": "Introduces SeLoRA, which re-parameterizes LoRA using spectral bases from a sparse spectral subspace.", "result": "SeLoRA achieves greater efficiency with fewer parameters and outperforms baselines on tasks like reasoning and code generation.", "conclusion": "SeLoRA is a scalable, plug-and-play framework that enhances LoRA's performance and efficiency."}}
{"id": "2506.16791", "pdf": "https://arxiv.org/pdf/2506.16791", "abs": "https://arxiv.org/abs/2506.16791", "authors": ["Nick Erickson", "Lennart Purucker", "Andrej Tschalzev", "David Holzm\u00fcller", "Prateek Mutalik Desai", "and David Salinas", "Frank Hutter"], "title": "TabArena: A Living Benchmark for Machine Learning on Tabular Data", "categories": ["cs.LG", "cs.AI"], "comment": "51 pages. Code available at https://tabarena.ai/code; examples at\n  https://tabarena.ai/code-examples; dataset curation at\n  https://tabarena.ai/data-tabular-ml-iid-study and\n  https://tabarena.ai/dataset-curation", "summary": "With the growing popularity of deep learning and foundation models for\ntabular data, the need for standardized and reliable benchmarks is higher than\never. However, current benchmarks are static. Their design is not updated even\nif flaws are discovered, model versions are updated, or new models are\nreleased. To address this, we introduce TabArena, the first continuously\nmaintained living tabular benchmarking system. To launch TabArena, we manually\ncurate a representative collection of datasets and well-implemented models,\nconduct a large-scale benchmarking study to initialize a public leaderboard,\nand assemble a team of experienced maintainers. Our results highlight the\ninfluence of validation method and ensembling of hyperparameter configurations\nto benchmark models at their full potential. While gradient-boosted trees are\nstill strong contenders on practical tabular datasets, we observe that deep\nlearning methods have caught up under larger time budgets with ensembling. At\nthe same time, foundation models excel on smaller datasets. Finally, we show\nthat ensembles across models advance the state-of-the-art in tabular machine\nlearning and investigate the contributions of individual models. We launch\nTabArena with a public leaderboard, reproducible code, and maintenance\nprotocols to create a living benchmark available at https://tabarena.ai.", "AI": {"tldr": "TabArena introduces a continuously maintained benchmarking system for tabular data, addressing flaws in static benchmarks by curating datasets, models, and a public leaderboard.", "motivation": "Current benchmarks for tabular data are static and outdated, failing to adapt to new models or discovered flaws.", "method": "TabArena manually curates datasets and models, conducts large-scale benchmarking, and establishes a maintenance team.", "result": "Gradient-boosted trees remain strong, deep learning catches up with ensembling, and foundation models excel on smaller datasets. Ensembles advance state-of-the-art.", "conclusion": "TabArena provides a living benchmark with a public leaderboard, reproducible code, and maintenance protocols."}}
{"id": "2502.14709", "pdf": "https://arxiv.org/pdf/2502.14709", "abs": "https://arxiv.org/abs/2502.14709", "authors": ["Zichun Yu", "Fei Peng", "Jie Lei", "Arnold Overwijk", "Wen-tau Yih", "Chenyan Xiong"], "title": "Group-Level Data Selection for Efficient Pretraining", "categories": ["cs.CL", "cs.LG"], "comment": null, "summary": "In this paper, we introduce Group-MATES, an efficient group-level data\nselection approach to optimize the speed-quality frontier of language model\npretraining. Specifically, Group-MATES parameterizes costly group-level\nselection with a relational data influence model. To train this model, we\nsample training trajectories of the language model and collect oracle data\ninfluences alongside. The relational data influence model approximates the\noracle data influence by weighting individual influence with relationships\namong training data. To enable efficient selection with our relational data\ninfluence model, we partition the dataset into small clusters using\nrelationship weights and select data within each cluster independently.\nExperiments on DCLM 400M-4x, 1B-1x, and 3B-1x show that Group-MATES achieves\n3.5%-9.4% relative performance gains over random selection across 22 downstream\ntasks, nearly doubling the improvements achieved by state-of-the-art individual\ndata selection baselines. Furthermore, Group-MATES reduces the number of tokens\nrequired to reach a certain downstream performance by up to 1.75x,\nsubstantially elevating the speed-quality frontier. Further analyses highlight\nthe critical role of relationship weights in the relational data influence\nmodel and the effectiveness of our cluster-based inference. Our code is\nopen-sourced at https://github.com/facebookresearch/Group-MATES.", "AI": {"tldr": "Group-MATES optimizes language model pretraining by using a relational data influence model for efficient group-level data selection, achieving significant performance gains and reducing token requirements.", "motivation": "To improve the speed-quality frontier of language model pretraining by addressing the inefficiency of individual data selection methods.", "method": "Group-MATES uses a relational data influence model, trained with sampled trajectories and oracle data influences, and partitions datasets into clusters for efficient selection.", "result": "Achieves 3.5%-9.4% performance gains over random selection and reduces token requirements by up to 1.75x.", "conclusion": "Group-MATES effectively elevates the speed-quality frontier, with relationship weights and cluster-based inference playing critical roles."}}
{"id": "2506.17220", "pdf": "https://arxiv.org/pdf/2506.17220", "abs": "https://arxiv.org/abs/2506.17220", "authors": ["Jisu Nam", "Soowon Son", "Dahyun Chung", "Jiyoung Kim", "Siyoon Jin", "Junhwa Hur", "Seungryong Kim"], "title": "Emergent Temporal Correspondences from Video Diffusion Transformers", "categories": ["cs.CV"], "comment": "Project page is available at https:/cvlab-kaist.github.io/DiffTrack", "summary": "Recent advancements in video diffusion models based on Diffusion Transformers\n(DiTs) have achieved remarkable success in generating temporally coherent\nvideos. Yet, a fundamental question persists: how do these models internally\nestablish and represent temporal correspondences across frames? We introduce\nDiffTrack, the first quantitative analysis framework designed to answer this\nquestion. DiffTrack constructs a dataset of prompt-generated video with pseudo\nground-truth tracking annotations and proposes novel evaluation metrics to\nsystematically analyze how each component within the full 3D attention\nmechanism of DiTs (e.g., representations, layers, and timesteps) contributes to\nestablishing temporal correspondences. Our analysis reveals that query-key\nsimilarities in specific, but not all, layers play a critical role in temporal\nmatching, and that this matching becomes increasingly prominent during the\ndenoising process. We demonstrate practical applications of DiffTrack in\nzero-shot point tracking, where it achieves state-of-the-art performance\ncompared to existing vision foundation and self-supervised video models.\nFurther, we extend our findings to motion-enhanced video generation with a\nnovel guidance method that improves temporal consistency of generated videos\nwithout additional training. We believe our work offers crucial insights into\nthe inner workings of video DiTs and establishes a foundation for further\nresearch and applications leveraging their temporal understanding.", "AI": {"tldr": "DiffTrack is a framework for analyzing how video diffusion models (DiTs) establish temporal correspondences, revealing key insights and enabling applications like zero-shot tracking and motion-enhanced video generation.", "motivation": "To understand how video diffusion models internally represent temporal correspondences across frames, which remains an open question despite their success.", "method": "DiffTrack constructs a dataset with pseudo ground-truth tracking annotations and proposes metrics to analyze the 3D attention mechanism in DiTs, focusing on layers, timesteps, and representations.", "result": "Query-key similarities in specific layers are critical for temporal matching, becoming more prominent during denoising. DiffTrack achieves state-of-the-art in zero-shot tracking and improves video generation consistency.", "conclusion": "DiffTrack provides insights into DiTs' temporal understanding, enabling further research and applications in video generation and tracking."}}
{"id": "2506.16790", "pdf": "https://arxiv.org/pdf/2506.16790", "abs": "https://arxiv.org/abs/2506.16790", "authors": ["Senmiao Wang", "Yupeng Chen", "Yushun Zhang", "Ruoyu Sun", "Tian Ding"], "title": "Exploring and Improving Initialization for Deep Graph Neural Networks: A Signal Propagation Perspective", "categories": ["cs.LG"], "comment": "Published in TMLR (2025)", "summary": "Graph Neural Networks (GNNs) often suffer from performance degradation as the\nnetwork depth increases. This paper addresses this issue by introducing\ninitialization methods that enhance signal propagation (SP) within GNNs. We\npropose three key metrics for effective SP in GNNs: forward propagation,\nbackward propagation, and graph embedding variation (GEV). While the first two\nmetrics derive from classical SP theory, the third is specifically designed for\nGNNs. We theoretically demonstrate that a broad range of commonly used\ninitialization methods for GNNs, which exhibit performance degradation with\nincreasing depth, fail to control these three metrics simultaneously. To deal\nwith this limitation, a direct exploitation of the SP analysis--searching for\nweight initialization variances that optimize the three metrics--is shown to\nsignificantly enhance the SP in deep GCNs. This approach is called Signal\nPropagation on Graph-guided Initialization (SPoGInit). Our experiments\ndemonstrate that SPoGInit outperforms commonly used initialization methods on\nvarious tasks and architectures. Notably, SPoGInit enables performance\nimprovements as GNNs deepen, which represents a significant advancement in\naddressing depth-related challenges and highlights the validity and\neffectiveness of the SP analysis framework.", "AI": {"tldr": "The paper introduces SPoGInit, a method to improve signal propagation in deep GNNs by optimizing initialization variances for three key metrics, addressing performance degradation with depth.", "motivation": "GNNs suffer from performance degradation as depth increases, prompting the need for better initialization methods to enhance signal propagation.", "method": "Proposes SPoGInit, which optimizes weight initialization variances for forward/backward propagation and graph embedding variation (GEV) to improve signal propagation in deep GNNs.", "result": "SPoGInit outperforms common initialization methods, enabling performance improvements as GNNs deepen.", "conclusion": "SPoGInit effectively addresses depth-related challenges in GNNs, validating the SP analysis framework."}}
{"id": "2506.16795", "pdf": "https://arxiv.org/pdf/2506.16795", "abs": "https://arxiv.org/abs/2506.16795", "authors": ["Chengpeng Hu", "Ziming Wang", "Bo Yuan", "Jialin Liu", "Chengqi Zhang", "Xin Yao"], "title": "Robust Dynamic Material Handling via Adaptive Constrained Evolutionary Reinforcement Learning", "categories": ["cs.NE", "cs.AI"], "comment": null, "summary": "Dynamic material handling (DMH) involves the assignment of dynamically\narriving material transporting tasks to suitable vehicles in real time for\nminimising makespan and tardiness. In real-world scenarios, historical task\nrecords are usually available, which enables the training of a decision policy\non multiple instances consisting of historical records. Recently, reinforcement\nlearning has been applied to solve DMH. Due to the occurrence of dynamic events\nsuch as new tasks, adaptability is highly required. Solving DMH is challenging\nsince constraints including task delay should be satisfied. A feedback is\nreceived only when all tasks are served, which leads to sparse reward. Besides,\nmaking the best use of limited computational resources and historical records\nfor training a robust policy is crucial. The time allocated to different\nproblem instances would highly impact the learning process. To tackle those\nchallenges, this paper proposes a novel adaptive constrained evolutionary\nreinforcement learning (ACERL) approach, which maintains a population of actors\nfor diverse exploration. ACERL accesses each actor for tackling sparse rewards\nand constraint violation to restrict the behaviour of the policy. Moreover,\nACERL adaptively selects the most beneficial training instances for improving\nthe policy. Extensive experiments on eight training and eight unseen test\ninstances demonstrate the outstanding performance of ACERL compared with\nseveral state-of-the-art algorithms. Policies trained by ACERL can schedule the\nvehicles while fully satisfying the constraints. Additional experiments on 40\nunseen noised instances show the robust performance of ACERL. Cross-validation\nfurther presents the overall effectiveness of ACREL. Besides, a rigorous\nablation study highlights the coordination and benefits of each ingredient of\nACERL.", "AI": {"tldr": "The paper proposes ACERL, an adaptive constrained evolutionary reinforcement learning approach, to solve dynamic material handling (DMH) problems efficiently by minimizing makespan and tardiness while satisfying constraints.", "motivation": "DMH requires real-time task assignment to vehicles, but faces challenges like dynamic events, sparse rewards, and constraint satisfaction. Historical data and limited computational resources further complicate policy training.", "method": "ACERL uses a population of actors for diverse exploration, tackles sparse rewards and constraint violations, and adaptively selects beneficial training instances.", "result": "ACERL outperforms state-of-the-art algorithms, satisfies constraints, and shows robustness in unseen and noisy instances. Ablation studies confirm its effectiveness.", "conclusion": "ACERL is a robust and effective solution for DMH, demonstrating superior performance and adaptability in dynamic environments."}}
{"id": "2502.14802", "pdf": "https://arxiv.org/pdf/2502.14802", "abs": "https://arxiv.org/abs/2502.14802", "authors": ["Bernal Jim\u00e9nez Guti\u00e9rrez", "Yiheng Shu", "Weijian Qi", "Sizhe Zhou", "Yu Su"], "title": "From RAG to Memory: Non-Parametric Continual Learning for Large Language Models", "categories": ["cs.CL", "cs.AI"], "comment": "ICML 2025. Code and data are available at:\n  https://github.com/OSU-NLP-Group/HippoRAG", "summary": "Our ability to continuously acquire, organize, and leverage knowledge is a\nkey feature of human intelligence that AI systems must approximate to unlock\ntheir full potential. Given the challenges in continual learning with large\nlanguage models (LLMs), retrieval-augmented generation (RAG) has become the\ndominant way to introduce new information. However, its reliance on vector\nretrieval hinders its ability to mimic the dynamic and interconnected nature of\nhuman long-term memory. Recent RAG approaches augment vector embeddings with\nvarious structures like knowledge graphs to address some of these gaps, namely\nsense-making and associativity. However, their performance on more basic\nfactual memory tasks drops considerably below standard RAG. We address this\nunintended deterioration and propose HippoRAG 2, a framework that outperforms\nstandard RAG comprehensively on factual, sense-making, and associative memory\ntasks. HippoRAG 2 builds upon the Personalized PageRank algorithm used in\nHippoRAG and enhances it with deeper passage integration and more effective\nonline use of an LLM. This combination pushes this RAG system closer to the\neffectiveness of human long-term memory, achieving a 7% improvement in\nassociative memory tasks over the state-of-the-art embedding model while also\nexhibiting superior factual knowledge and sense-making memory capabilities.\nThis work paves the way for non-parametric continual learning for LLMs. Code\nand data are available at https://github.com/OSU-NLP-Group/HippoRAG.", "AI": {"tldr": "HippoRAG 2 improves RAG by enhancing retrieval with deeper passage integration and LLM use, outperforming standard RAG in factual, sense-making, and associative memory tasks.", "motivation": "Addressing the limitations of standard RAG in mimicking human long-term memory dynamics, particularly in factual, sense-making, and associative tasks.", "method": "Proposes HippoRAG 2, which enhances the Personalized PageRank algorithm with deeper passage integration and effective LLM use.", "result": "Achieves a 7% improvement in associative memory tasks over state-of-the-art models, with superior factual and sense-making capabilities.", "conclusion": "HippoRAG 2 advances non-parametric continual learning for LLMs, bridging the gap between AI and human memory effectiveness."}}
{"id": "2506.17221", "pdf": "https://arxiv.org/pdf/2506.17221", "abs": "https://arxiv.org/abs/2506.17221", "authors": ["Zhangyang Qi", "Zhixiong Zhang", "Yizhou Yu", "Jiaqi Wang", "Hengshuang Zhao"], "title": "VLN-R1: Vision-Language Navigation via Reinforcement Fine-Tuning", "categories": ["cs.CV"], "comment": "project page: www.vlnr1.github.io", "summary": "Vision-Language Navigation (VLN) is a core challenge in embodied AI,\nrequiring agents to navigate real-world environments using natural language\ninstructions. Current language model-based navigation systems operate on\ndiscrete topological graphs, limiting path planning to predefined node\nconnections. We propose VLN-R1, an end-to-end framework that leverages Large\nVision-Language Models (LVLM) to directly translate egocentric video streams\ninto continuous navigation actions, adopting GRPO-based training inspired by\nDeepSeek-R1. To enable effective training, we first construct the VLN-Ego\ndataset using a 3D simulator, Habitat, and propose Long-Short Memory Sampling\nto balance historical and current observations. While large language models can\nsupervise complete textual instructions, they lack fine-grained action-level\ncontrol. Our framework employs a two-stage training approach: a) Supervised\nfine-tuning (SFT) to align the model's action sequence text predictions with\nexpert demonstrations, followed by b) Reinforcement fine-tuning (RFT) enhanced\nwith a Time-Decayed Reward (TDR) mechanism that strategically weights\nmulti-step future actions. Experimental results show VLN-R1 achieves strong\nperformance on VLN-CE benchmark. VLN-R1 proves LVLMs can drive embodied\nnavigation and enhance task-specific reasoning through data-efficient,\nreward-driven post-training.", "AI": {"tldr": "VLN-R1 is an end-to-end framework using Large Vision-Language Models (LVLM) for continuous navigation, trained with GRPO-based methods and a two-stage approach (SFT and RFT), achieving strong results on VLN-CE.", "motivation": "Current VLN systems rely on discrete graphs, limiting flexibility. VLN-R1 aims to enable continuous navigation using LVLMs for better adaptability.", "method": "Leverages LVLMs to translate egocentric video into actions, uses GRPO-based training, and a two-stage approach (SFT for alignment, RFT with Time-Decayed Reward).", "result": "VLN-R1 performs well on VLN-CE, demonstrating LVLMs' potential for embodied navigation and task-specific reasoning.", "conclusion": "VLN-R1 shows LVLMs can effectively drive continuous navigation and improve reasoning through data-efficient, reward-driven training."}}
{"id": "2506.16815", "pdf": "https://arxiv.org/pdf/2506.16815", "abs": "https://arxiv.org/abs/2506.16815", "authors": ["Kai Yang", "Shaoyu Dou", "Pan Luo", "Xin Wang", "H. Vincent Poor"], "title": "Robust Group Anomaly Detection for Quasi-Periodic Network Time Series", "categories": ["cs.LG"], "comment": "Published in IEEE Transactions on Network Science and Engineering", "summary": "Many real-world multivariate time series are collected from a network of\nphysical objects embedded with software, electronics, and sensors. The\nquasi-periodic signals generated by these objects often follow a similar\nrepetitive and periodic pattern, but have variations in the period, and come in\ndifferent lengths caused by timing (synchronization) errors. Given a multitude\nof such quasi-periodic time series, can we build machine learning models to\nidentify those time series that behave differently from the majority of the\nobservations? In addition, can the models help human experts to understand how\nthe decision was made? We propose a sequence to Gaussian Mixture Model\n(seq2GMM) framework. The overarching goal of this framework is to identify\nunusual and interesting time series within a network time series database. We\nfurther develop a surrogate-based optimization algorithm that can efficiently\ntrain the seq2GMM model. Seq2GMM exhibits strong empirical performance on a\nplurality of public benchmark datasets, outperforming state-of-the-art anomaly\ndetection techniques by a significant margin. We also theoretically analyze the\nconvergence property of the proposed training algorithm and provide numerical\nresults to substantiate our theoretical claims.", "AI": {"tldr": "The paper proposes a seq2GMM framework for detecting unusual quasi-periodic time series in networks, outperforming existing methods.", "motivation": "To identify anomalous time series in networks with quasi-periodic signals and provide interpretable decisions.", "method": "Develops a sequence to Gaussian Mixture Model (seq2GMM) and a surrogate-based optimization algorithm for training.", "result": "Seq2GMM outperforms state-of-the-art anomaly detection methods on benchmark datasets.", "conclusion": "The framework is effective for anomaly detection, with theoretical and empirical validation."}}
{"id": "2506.16822", "pdf": "https://arxiv.org/pdf/2506.16822", "abs": "https://arxiv.org/abs/2506.16822", "authors": ["Daniel Frau-Alfaro", "Julio Casta\u00f1o-Amoros", "Santiago Puente", "Pablo Gil", "Roberto Calandra"], "title": "Learning Dexterous Object Handover", "categories": ["cs.RO", "cs.AI"], "comment": "Paper accepted for presentation in RoMan 2025", "summary": "Object handover is an important skill that we use daily when interacting with\nother humans. To deploy robots in collaborative setting, like houses, being\nable to receive and handing over objects safely and efficiently becomes a\ncrucial skill. In this work, we demonstrate the use of Reinforcement Learning\n(RL) for dexterous object handover between two multi-finger hands. Key to this\ntask is the use of a novel reward function based on dual quaternions to\nminimize the rotation distance, which outperforms other rotation\nrepresentations such as Euler and rotation matrices. The robustness of the\ntrained policy is experimentally evaluated by testing w.r.t. objects that are\nnot included in the training distribution, and perturbations during the\nhandover process. The results demonstrate that the trained policy successfully\nperform this task, achieving a total success rate of 94% in the best-case\nscenario after 100 experiments, thereby showing the robustness of our policy\nwith novel objects. In addition, the best-case performance of the policy\ndecreases by only 13.8% when the other robot moves during the handover, proving\nthat our policy is also robust to this type of perturbation, which is common in\nreal-world object handovers.", "AI": {"tldr": "RL-based object handover between multi-finger hands using dual quaternions for rotation distance, achieving 94% success rate and robustness to novel objects and perturbations.", "motivation": "To enable robots to perform safe and efficient object handovers in collaborative settings, a crucial skill for real-world deployment.", "method": "Uses Reinforcement Learning with a novel reward function based on dual quaternions to minimize rotation distance, outperforming Euler and rotation matrices.", "result": "Achieves 94% success rate in best-case scenarios, robust to novel objects and perturbations (only 13.8% performance drop when the other robot moves).", "conclusion": "The RL-based policy is effective and robust for dexterous object handover, suitable for real-world applications."}}
{"id": "2502.14911", "pdf": "https://arxiv.org/pdf/2502.14911", "abs": "https://arxiv.org/abs/2502.14911", "authors": ["Jann Railey Montalan", "Jimson Paulo Layacan", "David Demitri Africa", "Richell Isaiah Flores", "Michael T. Lopez II", "Theresa Denise Magsajo", "Anjanette Cayabyab", "William Chandra Tjhi"], "title": "Batayan: A Filipino NLP benchmark for evaluating Large Language Models", "categories": ["cs.CL", "cs.AI"], "comment": "Accepted to ACL 2025 (Main Conference)", "summary": "Recent advances in large language models (LLMs) have demonstrated remarkable\ncapabilities on widely benchmarked high-resource languages. However, linguistic\nnuances of under-resourced languages remain unexplored. We introduce Batayan, a\nholistic Filipino benchmark that systematically evaluates LLMs across three key\nnatural language processing (NLP) competencies: understanding, reasoning, and\ngeneration. Batayan consolidates eight tasks, three of which have not existed\nprior for Filipino corpora, covering both Tagalog and code-switched Taglish\nutterances. Our rigorous, native-speaker-driven adaptation and validation\nprocesses ensures fluency and authenticity to the complex morphological and\nsyntactic structures of Filipino, alleviating the pervasive translationese bias\nin existing Filipino corpora. We report empirical results on a variety of\nopen-source and commercial LLMs, highlighting significant performance gaps that\nsignal the under-representation of Filipino in pre-training corpora, the unique\nhurdles in modeling Filipino's rich morphology and construction, and the\nimportance of explicit Filipino language support. Moreover, we discuss the\npractical challenges encountered in dataset construction and propose principled\nsolutions for building culturally and linguistically-faithful resources in\nunder-represented languages. We also provide a public evaluation suite as a\nclear foundation for iterative, community-driven progress in Filipino NLP.", "AI": {"tldr": "Batayan is a Filipino benchmark evaluating LLMs on understanding, reasoning, and generation, addressing gaps in under-resourced languages like Filipino.", "motivation": "To address the lack of exploration of linguistic nuances in under-resourced languages, particularly Filipino, and the translationese bias in existing corpora.", "method": "Introduces Batayan, a holistic benchmark with eight tasks (three novel for Filipino), covering Tagalog and Taglish, validated by native speakers for fluency and authenticity.", "result": "Reveals performance gaps in LLMs for Filipino, highlighting under-representation in pre-training, challenges in modeling morphology, and the need for explicit language support.", "conclusion": "Batayan provides a foundation for Filipino NLP progress, emphasizing culturally faithful dataset construction and community-driven development."}}
{"id": "2506.06561", "pdf": "https://arxiv.org/pdf/2506.06561", "abs": "https://arxiv.org/abs/2506.06561", "authors": ["Ho Yin 'Sam' Ng", "Ting-Yao Hsu", "Aashish Anantha Ramakrishnan", "Branislav Kveton", "Nedim Lipka", "Franck Dernoncourt", "Dongwon Lee", "Tong Yu", "Sungchul Kim", "Ryan A. Rossi", "Ting-Hao 'Kenneth' Huang"], "title": "LaMP-Cap: Personalized Figure Caption Generation With Multimodal Figure Profiles", "categories": ["cs.CL", "cs.AI", "cs.CV"], "comment": "The LaMP-CAP dataset is publicly available at:\n  https://github.com/Crowd-AI-Lab/lamp-cap", "summary": "Figure captions are crucial for helping readers understand and remember a\nfigure's key message. Many models have been developed to generate these\ncaptions, helping authors compose better quality captions more easily. Yet,\nauthors almost always need to revise generic AI-generated captions to match\ntheir writing style and the domain's style, highlighting the need for\npersonalization. Despite language models' personalization (LaMP) advances,\nthese technologies often focus on text-only settings and rarely address\nscenarios where both inputs and profiles are multimodal. This paper introduces\nLaMP-Cap, a dataset for personalized figure caption generation with multimodal\nfigure profiles. For each target figure, LaMP-Cap provides not only the needed\ninputs, such as figure images, but also up to three other figures from the same\ndocument--each with its image, caption, and figure-mentioning paragraphs--as a\nprofile to characterize the context. Experiments with four LLMs show that using\nprofile information consistently helps generate captions closer to the original\nauthor-written ones. Ablation studies reveal that images in the profile are\nmore helpful than figure-mentioning paragraphs, highlighting the advantage of\nusing multimodal profiles over text-only ones.", "AI": {"tldr": "LaMP-Cap introduces a dataset for personalized figure caption generation using multimodal profiles, improving caption quality by leveraging context from related figures.", "motivation": "Existing AI-generated captions lack personalization and rarely use multimodal inputs, necessitating a solution that incorporates both text and visual context.", "method": "LaMP-Cap provides multimodal profiles (images, captions, and paragraphs) for target figures, tested with four LLMs to evaluate caption quality.", "result": "Using profile information improves caption generation, with images in profiles proving more beneficial than text-only context.", "conclusion": "Multimodal profiles enhance personalized caption generation, offering better alignment with author-written captions."}}
{"id": "2506.16824", "pdf": "https://arxiv.org/pdf/2506.16824", "abs": "https://arxiv.org/abs/2506.16824", "authors": ["Thomas Marwitz", "Alexander Colsmann", "Ben Breitung", "Christoph Brabec", "Christoph Kirchlechner", "Eva Blasco", "Gabriel Cadilha Marques", "Horst Hahn", "Michael Hirtz", "Pavel A. Levkin", "Yolita M. Eggeler", "Tobias Schl\u00f6der", "Pascal Friederich"], "title": "Predicting New Research Directions in Materials Science using Large Language Models and Concept Graphs", "categories": ["cs.LG"], "comment": null, "summary": "Due to an exponential increase in published research articles, it is\nimpossible for individual scientists to read all publications, even within\ntheir own research field. In this work, we investigate the use of large\nlanguage models (LLMs) for the purpose of extracting the main concepts and\nsemantic information from scientific abstracts in the domain of materials\nscience to find links that were not noticed by humans and thus to suggest\ninspiring near/mid-term future research directions. We show that LLMs can\nextract concepts more efficiently than automated keyword extraction methods to\nbuild a concept graph as an abstraction of the scientific literature. A machine\nlearning model is trained to predict emerging combinations of concepts, i.e.\nnew research ideas, based on historical data. We demonstrate that integrating\nsemantic concept information leads to an increased prediction performance. The\napplicability of our model is demonstrated in qualitative interviews with\ndomain experts based on individualized model suggestions. We show that the\nmodel can inspire materials scientists in their creative thinking process by\npredicting innovative combinations of topics that have not yet been\ninvestigated.", "AI": {"tldr": "LLMs are used to extract main concepts from materials science abstracts, building a concept graph to predict new research ideas, outperforming keyword methods and inspiring scientists.", "motivation": "The overwhelming volume of research publications makes it impossible for scientists to read everything, necessitating automated methods to extract and link concepts.", "method": "LLMs extract semantic information to build a concept graph; a machine learning model predicts emerging concept combinations based on historical data.", "result": "LLMs outperform keyword extraction, and integrating semantic information improves prediction performance, inspiring scientists with novel topic combinations.", "conclusion": "The model effectively aids materials scientists by predicting innovative research directions, demonstrating the value of LLMs in literature analysis."}}
{"id": "2506.16844", "pdf": "https://arxiv.org/pdf/2506.16844", "abs": "https://arxiv.org/abs/2506.16844", "authors": ["Victor Alejandre", "Concha Bielza", "Pedro Larra\u00f1aga"], "title": "Bandwidth Selectors on Semiparametric Bayesian Networks", "categories": ["cs.LG", "cs.AI", "stat.ML", "I.2.6; I.5.1; G.3"], "comment": "37 pages, 15 figures. Submitted to Information Sciences", "summary": "Semiparametric Bayesian networks (SPBNs) integrate parametric and\nnon-parametric probabilistic models, offering flexibility in learning complex\ndata distributions from samples. In particular, kernel density estimators\n(KDEs) are employed for the non-parametric component. Under the assumption of\ndata normality, the normal rule is used to learn the bandwidth matrix for the\nKDEs in SPBNs. This matrix is the key hyperparameter that controls the\ntrade-off between bias and variance. However, real-world data often deviates\nfrom normality, potentially leading to suboptimal density estimation and\nreduced predictive performance. This paper first establishes the theoretical\nframework for the application of state-of-the-art bandwidth selectors and\nsubsequently evaluates their impact on SPBN performance. We explore the\napproaches of cross-validation and plug-in selectors, assessing their\neffectiveness in enhancing the learning capability and applicability of SPBNs.\nTo support this investigation, we have extended the open-source package\nPyBNesian for SPBNs with the additional bandwidth selection techniques and\nconducted extensive experimental analyses. Our results demonstrate that the\nproposed bandwidth selectors leverage increasing information more effectively\nthan the normal rule, which, despite its robustness, stagnates with more data.\nIn particular, unbiased cross-validation generally outperforms the normal rule,\nhighlighting its advantage in high sample size scenarios.", "AI": {"tldr": "The paper evaluates advanced bandwidth selectors for Semiparametric Bayesian Networks (SPBNs), showing they outperform the traditional normal rule, especially in high sample size scenarios.", "motivation": "Real-world data often deviates from normality, making the normal rule for bandwidth selection in SPBNs suboptimal. This paper aims to improve density estimation and predictive performance by exploring better bandwidth selectors.", "method": "The paper applies cross-validation and plug-in selectors for bandwidth selection in SPBNs, extending the PyBNesian package with these techniques. Theoretical analysis and extensive experiments are conducted.", "result": "Unbiased cross-validation outperforms the normal rule, especially with larger datasets, leveraging information more effectively.", "conclusion": "Advanced bandwidth selectors enhance SPBN performance, with cross-validation being particularly effective for high sample sizes."}}
{"id": "2502.18108", "pdf": "https://arxiv.org/pdf/2502.18108", "abs": "https://arxiv.org/abs/2502.18108", "authors": ["Laura Perez-Beltrachini", "Mirella Lapata"], "title": "Uncertainty Quantification in Retrieval Augmented Question Answering", "categories": ["cs.CL"], "comment": null, "summary": "Retrieval augmented Question Answering (QA) helps QA models overcome\nknowledge gaps by incorporating retrieved evidence, typically a set of\npassages, alongside the question at test time. Previous studies show that this\napproach improves QA performance and reduces hallucinations, without, however,\nassessing whether the retrieved passages are indeed useful at answering\ncorrectly. In this work, we propose to quantify the uncertainty of a QA model\nvia estimating the utility of the passages it is provided with. We train a\nlightweight neural model to predict passage utility for a target QA model and\nshow that while simple information theoretic metrics can predict answer\ncorrectness up to a certain extent, our approach efficiently approximates or\noutperforms more expensive sampling-based methods. Code and data are available\nat https://github.com/lauhaide/ragu.", "AI": {"tldr": "The paper proposes a method to quantify uncertainty in retrieval-augmented QA by predicting passage utility, outperforming simpler metrics.", "motivation": "Assess the usefulness of retrieved passages in QA models, which prior work did not evaluate.", "method": "Train a lightweight neural model to predict passage utility for QA models.", "result": "The approach efficiently approximates or outperforms more expensive sampling-based methods.", "conclusion": "The proposed method effectively quantifies passage utility, improving QA model performance."}}
{"id": "2506.15728", "pdf": "https://arxiv.org/pdf/2506.15728", "abs": "https://arxiv.org/abs/2506.15728", "authors": ["Jiangnan Zhao", "Hanbo Xu", "Cifu Xu", "Wenlong Yin", "Laixin Luo", "Gang Liu", "Yan Wang"], "title": "Smartphone-integrated RPA-CRISPR-Cas12a Detection System with Microneedle Sampling for Point-of-Care Diagnosis of Potato Late Blight in Early Stage", "categories": ["q-bio.QM", "cs.CV", "q-bio.BM"], "comment": "32 pages,7 figures,1 table", "summary": "Potato late blight, caused by the oomycete pathogen Phytophthora infestans,\nis one of the most devastating diseases affecting potato crops in the history.\nAlthough conventional detection methods of plant diseases such as PCR and LAMP\nare highly sensitive and specific, they rely on bulky and expensive laboratory\nequipment and involve complex operations, making them impracticable for\npoint-of care diagnosis in the field. Here in this study, we report a portable\nRPA-CRISPR based diagnosis system for plant disease, integrating smartphone for\nacquisition and analysis of fluorescent images. A polyvinyl alcohol (PVA)\nmicroneedle patch was employed for sample extraction on the plant leaves within\none minute, the DNA extraction efficiency achieved 56 ug/mg, which is\napproximately 3 times to the traditional CTAB methods (18 ug/mg). The system of\nRPA-CRISPR-Cas12a isothermal assay was established to specifically target P.\ninfestans with no cross-reactivity observed against closely-related species (P.\nsojae, P. capsici). The system demonstrated a detection limit of 2 pg/uL for P.\ninfestans genomic DNA, offering sensitivity comparable to that of benchtop\nlaboratory equipment. The system demonstrates the early-stage diagnosis\ncapability by achieving a approximately 80% and 100% detection rate on the\nthird and fourth day post-inoculation respectively, before visible symptoms\nobserved on the leaves. The smartphone-based \"sample-to-result\" system\ndecouples the limitations of traditional methods that rely heavily on\nspecialized equipment, offering a promising way for early-stage plant disease\ndetection and control in the field.", "AI": {"tldr": "A portable RPA-CRISPR system with smartphone integration enables rapid, sensitive, and specific detection of potato late blight, outperforming traditional methods.", "motivation": "Traditional disease detection methods like PCR and LAMP are impractical for field use due to their complexity and reliance on lab equipment.", "method": "The study combines RPA-CRISPR-Cas12a isothermal assay with a PVA microneedle patch for sample extraction and smartphone-based image analysis.", "result": "The system detects P. infestans with high sensitivity (2 pg/uL), no cross-reactivity, and early-stage diagnosis (80-100% detection before symptoms appear).", "conclusion": "This portable system offers a practical solution for early plant disease detection in the field, overcoming limitations of conventional methods."}}
{"id": "2506.16840", "pdf": "https://arxiv.org/pdf/2506.16840", "abs": "https://arxiv.org/abs/2506.16840", "authors": ["Zeyneddin Oz", "Shreyas Korde", "Marius Bock", "Kristof Van Laerhoven"], "title": "FedFitTech: A Baseline in Federated Learning for Fitness Tracking", "categories": ["cs.LG"], "comment": "This submission includes a total of 7 pages and 6 figures", "summary": "Rapid evolution of sensors and resource-efficient machine learning models\nhave spurred the widespread adoption of wearable fitness tracking devices.\nEquipped with inertial sensors, such devices can continuously capture physical\nmovements for fitness technology (FitTech), enabling applications from sports\noptimization to preventive healthcare. Traditional centralized learning\napproaches to detect fitness activities struggle with privacy concerns,\nregulatory constraints, and communication inefficiencies. In contrast,\nFederated Learning (FL) enables a decentralized model training by communicating\nmodel updates rather than private wearable sensor data. Applying FL to FitTech\npresents unique challenges, such as data imbalance, lack of labelled data,\nheterogeneous user activity patterns, and trade-offs between personalization\nand generalization. To simplify research on FitTech in FL, we present the\nFedFitTech baseline, under the Flower framework, which is publicly available\nand widely used by both industry and academic researchers. Additionally, to\nillustrate its usage, this paper presents a case study that implements a system\nbased on the FedFitTech baseline, incorporating a client-side early stopping\nstrategy and comparing the results. For instance, this system allows wearable\ndevices to optimize the trade-off between capturing common fitness activity\npatterns and preserving individuals' nuances, thereby enhancing both the\nscalability and efficiency of privacy-aware fitness tracking applications.\nResults show that this reduces overall redundant communications by 13 percent,\nwhile maintaining the overall recognition performance at a negligible\nrecognition cost by 1 percent. Thus, FedFitTech baseline creates a foundation\nfor a wide range of new research and development opportunities in FitTech, and\nit is available as open-source at:\nhttps://github.com/adap/flower/tree/main/baselines/fedfittech", "AI": {"tldr": "The paper introduces FedFitTech, a baseline for Federated Learning (FL) in wearable fitness tracking (FitTech), addressing privacy and efficiency challenges. It reduces communication redundancy by 13% with minimal performance loss.", "motivation": "Traditional centralized learning for fitness activity detection faces privacy, regulatory, and communication issues. FL offers a decentralized alternative but poses challenges like data imbalance and personalization-generalization trade-offs.", "method": "The authors propose FedFitTech under the Flower framework, featuring client-side early stopping and a case study to demonstrate its application.", "result": "FedFitTech reduces redundant communications by 13% while maintaining recognition performance with only a 1% cost.", "conclusion": "FedFitTech provides a scalable, efficient, and privacy-aware solution for FitTech, fostering new research opportunities. It is open-source and available for use."}}
{"id": "2506.16884", "pdf": "https://arxiv.org/pdf/2506.16884", "abs": "https://arxiv.org/abs/2506.16884", "authors": ["Jacopo Graldi", "Alessandro Breccia", "Giulia Lanzillotta", "Thomas Hofmann", "Lorenzo Noci"], "title": "The Importance of Being Lazy: Scaling Limits of Continual Learning", "categories": ["cs.LG", "cs.AI", "stat.ML"], "comment": "Proceedings of the 42nd International Conference on Machine Learning\n  (2025). JG and AB contributed equally to this work", "summary": "Despite recent efforts, neural networks still struggle to learn in\nnon-stationary environments, and our understanding of catastrophic forgetting\n(CF) is far from complete. In this work, we perform a systematic study on the\nimpact of model scale and the degree of feature learning in continual learning.\nWe reconcile existing contradictory observations on scale in the literature, by\ndifferentiating between lazy and rich training regimes through a variable\nparameterization of the architecture. We show that increasing model width is\nonly beneficial when it reduces the amount of feature learning, yielding more\nlaziness. Using the framework of dynamical mean field theory, we then study the\ninfinite width dynamics of the model in the feature learning regime and\ncharacterize CF, extending prior theoretical results limited to the lazy\nregime. We study the intricate relationship between feature learning, task\nnon-stationarity, and forgetting, finding that high feature learning is only\nbeneficial with highly similar tasks. We identify a transition modulated by\ntask similarity where the model exits an effectively lazy regime with low\nforgetting to enter a rich regime with significant forgetting. Finally, our\nfindings reveal that neural networks achieve optimal performance at a critical\nlevel of feature learning, which depends on task non-stationarity and transfers\nacross model scales. This work provides a unified perspective on the role of\nscale and feature learning in continual learning.", "AI": {"tldr": "The paper explores how model scale and feature learning impact continual learning, reconciling contradictory findings by distinguishing between lazy and rich training regimes. It shows that wider models reduce feature learning, mitigating catastrophic forgetting (CF), and identifies a critical feature learning level for optimal performance.", "motivation": "To better understand catastrophic forgetting in continual learning and reconcile conflicting observations about the role of model scale and feature learning.", "method": "Uses variable parameterization to differentiate lazy and rich training regimes, analyzes infinite width dynamics with dynamical mean field theory, and studies the relationship between feature learning, task similarity, and forgetting.", "result": "Wider models reduce feature learning (laziness), mitigating CF. High feature learning benefits only highly similar tasks, with a transition between lazy and rich regimes. Optimal performance occurs at a critical feature learning level.", "conclusion": "The study provides a unified perspective on scale and feature learning in continual learning, highlighting the importance of balancing feature learning and task non-stationarity to minimize forgetting."}}
{"id": "2502.18443", "pdf": "https://arxiv.org/pdf/2502.18443", "abs": "https://arxiv.org/abs/2502.18443", "authors": ["Jake Poznanski", "Aman Rangapur", "Jon Borchardt", "Jason Dunkelberger", "Regan Huff", "Daniel Lin", "Aman Rangapur", "Christopher Wilhelm", "Kyle Lo", "Luca Soldaini"], "title": "olmOCR: Unlocking Trillions of Tokens in PDFs with Vision Language Models", "categories": ["cs.CL"], "comment": null, "summary": "PDF documents have the potential to provide trillions of novel, high-quality\ntokens for training language models. However, these documents come in a\ndiversity of types with differing formats and visual layouts that pose a\nchallenge when attempting to extract and faithfully represent the underlying\ncontent for language model use. Traditional open source tools often produce\nlower quality extractions compared to vision language models (VLMs), but\nreliance on the best VLMs can be prohibitively costly (e.g., over $6,240 USD\nper million PDF pages for GPT-4o) or infeasible if the PDFs cannot be sent to\nproprietary APIs. We present olmOCR, an open-source toolkit for processing PDFs\ninto clean, linearized plain text in natural reading order while preserving\nstructured content like sections, tables, lists, equations, and more. Our\ntoolkit runs a fine-tuned 7B vision language model (VLM) trained on\nolmOCR-mix-0225, a sample of 260,000 pages from over 100,000 crawled PDFs with\ndiverse properties, including graphics, handwritten text and poor quality\nscans. olmOCR is optimized for large-scale batch processing, able to scale\nflexibly to different hardware setups and can convert a million PDF pages for\nonly $176 USD. To aid comparison with existing systems, we also introduce\nolmOCR-Bench, a curated set of 1,400 PDFs capturing many content types that\nremain challenging even for the best tools and VLMs, including formulas,\ntables, tiny fonts, old scans, and more. We find olmOCR outperforms even top\nVLMs including GPT-4o, Gemini Flash 2 and Qwen-2.5-VL. We openly release all\ncomponents of olmOCR: our fine-tuned VLM model, training code and data, an\nefficient inference pipeline that supports vLLM and SGLang backends, and\nbenchmark olmOCR-Bench.", "AI": {"tldr": "olmOCR is an open-source toolkit for high-quality PDF text extraction, outperforming top VLMs like GPT-4o, at a fraction of the cost.", "motivation": "PDFs offer vast training data for language models, but diverse formats and layouts make extraction challenging. Existing tools are either low-quality or prohibitively expensive.", "method": "olmOCR uses a fine-tuned 7B vision language model trained on a diverse dataset (olmOCR-mix-0225) and is optimized for large-scale batch processing.", "result": "olmOCR outperforms top VLMs (e.g., GPT-4o) and processes a million PDF pages for only $176 USD.", "conclusion": "olmOCR provides a cost-effective, high-quality solution for PDF text extraction, with all components openly released."}}
{"id": "2506.15815", "pdf": "https://arxiv.org/pdf/2506.15815", "abs": "https://arxiv.org/abs/2506.15815", "authors": ["Narayan Kandel", "Daljit Singh J. S. Dhillon"], "title": "GratNet: A Photorealistic Neural Shader for Diffractive Surfaces", "categories": ["cs.GR", "cs.CV"], "comment": null, "summary": "Structural coloration is commonly modeled using wave optics for reliable and\nphotorealistic rendering of natural, quasi-periodic and complex nanostructures.\nSuch models often rely on dense, preliminary or preprocessed data to accurately\ncapture the nuanced variations in diffractive surface reflectances. This heavy\ndata dependency warrants implicit neural representation which has not been\naddressed comprehensively in the current literature. In this paper, we present\na multi-layer perceptron (MLP) based method for data-driven rendering of\ndiffractive surfaces with high accuracy and efficiency. We primarily approach\nthis problem from a data compression perspective to devise a nuanced training\nand modeling method which is attuned to the domain and range characteristics of\ndiffractive reflectance datasets. Importantly, our approach avoids over-fitting\nand has robust resampling behavior. Using Peak-Signal-to-Noise (PSNR),\nStructural Similarity Index Measure (SSIM) and a flipping difference evaluator\n(FLIP) as evaluation metrics, we demonstrate the high-quality reconstruction of\nthe ground-truth. In comparison to a recent state-of-the-art offline,\nwave-optical, forward modeling approach, our method reproduces subjectively\nsimilar results with significant performance gains. We reduce the memory\nfootprint of the raw datasets by two orders of magnitude in general. Lastly, we\ndepict the working of our method with actual surface renderings.", "AI": {"tldr": "A neural network-based method for efficient and accurate rendering of diffractive surfaces, reducing memory usage significantly.", "motivation": "Addressing the heavy data dependency in structural coloration models by leveraging implicit neural representation.", "method": "Uses a multi-layer perceptron (MLP) for data-driven rendering, focusing on data compression and avoiding over-fitting.", "result": "Achieves high-quality reconstruction with significant performance gains and reduces memory footprint by two orders of magnitude.", "conclusion": "The method offers a robust and efficient alternative to traditional wave-optical approaches for diffractive surface rendering."}}
{"id": "2506.16846", "pdf": "https://arxiv.org/pdf/2506.16846", "abs": "https://arxiv.org/abs/2506.16846", "authors": ["Antonio Consoloa", "Edoardo Amaldi", "Emilio Carrizosa"], "title": "Soft decision trees for survival analysis", "categories": ["cs.LG", "math.OC"], "comment": null, "summary": "Decision trees are popular in survival analysis for their interpretability\nand ability to model complex relationships. Survival trees, which predict the\ntiming of singular events using censored historical data, are typically built\nthrough heuristic approaches. Recently, there has been growing interest in\nglobally optimized trees, where the overall tree is trained by minimizing the\nerror function over all its parameters. We propose a new soft survival tree\nmodel (SST), with a soft splitting rule at each branch node, trained via a\nnonlinear optimization formulation amenable to decomposition. Since SSTs\nprovide for every input vector a specific survival function associated to a\nsingle leaf node, they satisfy the conditional computation property and inherit\nthe related benefits. SST and the training formulation combine flexibility with\ninterpretability: any smooth survival function (parametric, semiparametric, or\nnonparametric) estimated through maximum likelihood can be used, and each leaf\nnode of an SST yields a cluster of distinct survival functions which are\nassociated to the data points routed to it. Numerical experiments on 15\nwell-known datasets show that SSTs, with parametric and spline-based\nsemiparametric survival functions, trained using an adaptation of the\nnode-based decomposition algorithm proposed by Consolo et al. (2024) for soft\nregression trees, outperform three benchmark survival trees in terms of four\nwidely-used discrimination and calibration measures. SSTs can also be extended\nto consider group fairness.", "AI": {"tldr": "The paper introduces a soft survival tree (SST) model with soft splitting rules, trained via nonlinear optimization, outperforming benchmarks in survival analysis.", "motivation": "To improve survival tree models by combining interpretability with global optimization and flexibility in survival function estimation.", "method": "Proposes SST with soft splitting rules, trained via nonlinear optimization and decomposition, supporting various survival functions (parametric, semiparametric, nonparametric).", "result": "SSTs outperform three benchmark survival trees on 15 datasets in discrimination and calibration measures.", "conclusion": "SSTs offer a flexible, interpretable, and high-performing approach to survival analysis, with potential for fairness extensions."}}
{"id": "2506.16899", "pdf": "https://arxiv.org/pdf/2506.16899", "abs": "https://arxiv.org/abs/2506.16899", "authors": ["Jonas Wagner", "Simon M\u00fcller", "Christian N\u00e4ther", "Jan-Philipp Stegh\u00f6fer", "Andreas Both"], "title": "Towards Effective Complementary Security Analysis using Large Language Models", "categories": ["cs.CR", "cs.AI"], "comment": "8 pages, 6 figures", "summary": "A key challenge in security analysis is the manual evaluation of potential\nsecurity weaknesses generated by static application security testing (SAST)\ntools. Numerous false positives (FPs) in these reports reduce the effectiveness\nof security analysis. We propose using Large Language Models (LLMs) to improve\nthe assessment of SAST findings. We investigate the ability of LLMs to reduce\nFPs while trying to maintain a perfect true positive rate, using datasets\nextracted from the OWASP Benchmark (v1.2) and a real-world software project.\nOur results indicate that advanced prompting techniques, such as\nChain-of-Thought and Self-Consistency, substantially improve FP detection.\nNotably, some LLMs identified approximately 62.5% of FPs in the OWASP Benchmark\ndataset without missing genuine weaknesses. Combining detections from different\nLLMs would increase this FP detection to approximately 78.9%. Additionally, we\ndemonstrate our approach's generalizability using a real-world dataset covering\nfive SAST tools, three programming languages, and infrastructure files. The\nbest LLM detected 33.85% of all FPs without missing genuine weaknesses, while\ncombining detections from different LLMs would increase this detection to\n38.46%. Our findings highlight the potential of LLMs to complement traditional\nSAST tools, enhancing automation and reducing resources spent addressing false\nalarms.", "AI": {"tldr": "LLMs improve SAST tool effectiveness by reducing false positives (FPs) while maintaining true positives, using advanced prompting techniques like Chain-of-Thought and Self-Consistency.", "motivation": "Manual evaluation of SAST tool reports is resource-intensive due to high false positives, necessitating automation.", "method": "LLMs are tested on datasets from OWASP Benchmark and real-world projects, using advanced prompting techniques.", "result": "LLMs identified up to 62.5% FPs in OWASP and 33.85% in real-world data; combining models improved detection further.", "conclusion": "LLMs can enhance SAST tools by automating FP reduction, saving resources and improving security analysis."}}
{"id": "2502.18452", "pdf": "https://arxiv.org/pdf/2502.18452", "abs": "https://arxiv.org/abs/2502.18452", "authors": ["Mollie Shichman", "Claire Bonial", "Austin Blodgett", "Taylor Hudson", "Francis Ferraro", "Rachel Rudinger"], "title": "FRIDA to the Rescue! Analyzing Synthetic Data Effectiveness in Object-Based Common Sense Reasoning for Disaster Response", "categories": ["cs.CL", "cs.AI"], "comment": "8 pages, 3 figures, 5 tables", "summary": "During Human Robot Interactions in disaster relief scenarios, Large Language\nModels (LLMs) have the potential for substantial physical reasoning to assist\nin mission objectives. However, these capabilities are often found only in\nlarger models, which are frequently not reasonable to deploy on robotic\nsystems. To meet our problem space requirements, we introduce a dataset and\npipeline to create Field Reasoning and Instruction Decoding Agent (FRIDA)\nmodels. In our pipeline, domain experts and linguists combine their knowledge\nto make high-quality few-shot prompts used to generate synthetic data for\nfine-tuning. We hand-curate datasets for this few-shot prompting and for\nevaluation to improve LLM reasoning on both general and disaster-specific\nobjects. We concurrently run an ablation study to understand which kinds of\nsynthetic data most affect performance. We fine-tune several small\ninstruction-tuned models and find that ablated FRIDA models only trained on\nobjects' physical state and function data outperformed both the FRIDA models\ntrained on all synthetic data and the base models in our customized evaluation.\nWe demonstrate that the FRIDA pipeline is capable of instilling physical common\nsense with minimal data.", "AI": {"tldr": "The paper introduces FRIDA, a pipeline for fine-tuning small LLMs to enhance physical reasoning in disaster relief scenarios, outperforming larger models with minimal data.", "motivation": "Large LLMs are impractical for robotic deployment in disaster relief, necessitating smaller, efficient models with strong physical reasoning.", "method": "Domain experts and linguists create high-quality few-shot prompts to generate synthetic data for fine-tuning small instruction-tuned models.", "result": "Ablated FRIDA models, trained only on objects' physical state and function data, outperformed both full FRIDA models and base models in evaluations.", "conclusion": "The FRIDA pipeline effectively instills physical common sense in small LLMs with minimal data, proving viable for disaster relief applications."}}
{"id": "2506.15849", "pdf": "https://arxiv.org/pdf/2506.15849", "abs": "https://arxiv.org/abs/2506.15849", "authors": ["Kirill Muravyev", "Vasily Yuryev", "Oleg Bulichev", "Dmitry Yudin", "Konstantin Yakovlev"], "title": "PRISM-Loc: a Lightweight Long-range LiDAR Localization in Urban Environments with Topological Maps", "categories": ["cs.RO", "cs.CV"], "comment": "This version was submitted and rejected from IROS 2025 conference", "summary": "Localization in the environment is one of the crucial tasks of navigation of\na mobile robot or a self-driving vehicle. For long-range routes, performing\nlocalization within a dense global lidar map in real time may be difficult, and\nthe creation of such a map may require much memory. To this end, leveraging\ntopological maps may be useful. In this work, we propose PRISM-Loc -- a\ntopological map-based approach for localization in large environments. The\nproposed approach leverages a twofold localization pipeline, which consists of\nglobal place recognition and estimation of the local pose inside the found\nlocation. For local pose estimation, we introduce an original lidar scan\nmatching algorithm, which is based on 2D features and point-based optimization.\nWe evaluate the proposed method on the ITLP-Campus dataset on a 3 km route, and\ncompare it against the state-of-the-art metric map-based and place\nrecognition-based competitors. The results of the experiments show that the\nproposed method outperforms its competitors both quality-wise and\ncomputationally-wise.", "AI": {"tldr": "PRISM-Loc is a topological map-based localization method for large environments, combining global place recognition and local pose estimation, outperforming competitors in quality and computational efficiency.", "motivation": "Localization in large environments using dense global lidar maps is memory-intensive and computationally challenging, prompting the need for efficient alternatives like topological maps.", "method": "PRISM-Loc uses a twofold pipeline: global place recognition and local pose estimation with a novel 2D feature-based lidar scan matching algorithm.", "result": "Evaluated on a 3 km route, PRISM-Loc outperforms state-of-the-art metric map-based and place recognition-based methods in both quality and computational efficiency.", "conclusion": "PRISM-Loc is an effective solution for large-scale localization, offering superior performance and efficiency compared to existing methods."}}
{"id": "2506.16853", "pdf": "https://arxiv.org/pdf/2506.16853", "abs": "https://arxiv.org/abs/2506.16853", "authors": ["Semin Kim", "Yeonwoo Cha", "Jaehoon Yoo", "Seunghoon Hong"], "title": "Reward-Agnostic Prompt Optimization for Text-to-Image Diffusion Models", "categories": ["cs.LG"], "comment": "28 pages, Under review", "summary": "We investigate a general approach for improving user prompts in text-to-image\n(T2I) diffusion models by finding prompts that maximize a reward function\nspecified at test-time. Although diverse reward models are used for evaluating\nimage generation, existing automated prompt engineering methods typically\ntarget specific reward configurations. Consequently, these specialized designs\nexhibit suboptimal performance when applied to new prompt engineering scenarios\ninvolving different reward models. To address this limitation, we introduce\nRATTPO (Reward-Agnostic Test-Time Prompt Optimization), a flexible test-time\noptimization method applicable across various reward scenarios without\nmodification. RATTPO iteratively searches for optimized prompts by querying\nlarge language models (LLMs) \\textit{without} requiring reward-specific task\ndescriptions. Instead, it uses the optimization trajectory and a novel\nreward-aware feedback signal (termed a \"hint\") as context. Empirical results\ndemonstrate the versatility of RATTPO, effectively enhancing user prompts\nacross diverse reward setups that assess various generation aspects, such as\naesthetics, general human preference, or spatial relationships between objects.\nRATTPO surpasses other test-time search baselines in search efficiency, using\nup to 3.5 times less inference budget, and, given sufficient inference budget,\nachieves performance comparable to learning-based baselines that require\nreward-specific fine-tuning. The code is available at\nhttps://github.com/seminkim/RATTPO.", "AI": {"tldr": "RATTPO is a reward-agnostic method for optimizing prompts in text-to-image models, outperforming specialized approaches in efficiency and adaptability across diverse reward scenarios.", "motivation": "Existing prompt engineering methods are tailored to specific rewards, limiting their adaptability to new scenarios. RATTPO aims to address this by being universally applicable.", "method": "RATTPO iteratively refines prompts using LLMs, leveraging optimization trajectories and reward-aware hints without requiring reward-specific task descriptions.", "result": "RATTPO improves prompts across diverse rewards (e.g., aesthetics, human preference) and is more efficient, using up to 3.5x fewer resources than baselines.", "conclusion": "RATTPO is a versatile and efficient solution for prompt optimization, matching or surpassing specialized methods without reward-specific fine-tuning."}}
{"id": "2506.16925", "pdf": "https://arxiv.org/pdf/2506.16925", "abs": "https://arxiv.org/abs/2506.16925", "authors": ["Jack Griffiths", "Steven A. Wrathmall", "Simon A. Gardiner"], "title": "Single-shot thermometry of simulated Bose--Einstein condensates using artificial intelligence", "categories": ["cond-mat.quant-gas", "cs.AI", "physics.comp-ph"], "comment": null, "summary": "Precise determination of thermodynamic parameters in ultracold Bose gases\nremains challenging due to the destructive nature of conventional measurement\ntechniques and inherent experimental uncertainties. We demonstrate an\nartificial intelligence approach for rapid, non-destructive estimation of the\nchemical potential and temperature from single-shot, in situ imaged density\nprofiles of finite-temperature Bose gases. Our convolutional neural network is\ntrained exclusively on quasi-2D `pancake' condensates in harmonic trap\nconfigurations. It achieves parameter extraction within fractions of a second.\nThe model also demonstrates zero-shot generalisation across both trap geometry\nand thermalisation dynamics, successfully estimating thermodynamic parameters\nfor toroidally trapped condensates with errors of only a few nanokelvin despite\nno prior exposure to such geometries during training, and maintaining\npredictive accuracy during dynamic thermalisation processes after a relatively\nbrief evolution without explicit training on non-equilibrium states. These\nresults suggest that supervised learning can overcome traditional limitations\nin ultracold atom thermometry, with extension to broader geometric\nconfigurations, temperature ranges, and additional parameters potentially\nenabling comprehensive real-time analysis of quantum gas experiments. Such\ncapabilities could significantly streamline experimental workflows whilst\nimproving measurement precision across a range of quantum fluid systems.", "AI": {"tldr": "AI-driven method for non-destructive, rapid estimation of thermodynamic parameters in ultracold Bose gases using convolutional neural networks.", "motivation": "Conventional techniques for measuring thermodynamic parameters in ultracold Bose gases are destructive and prone to experimental uncertainties.", "method": "A convolutional neural network trained on quasi-2D 'pancake' condensates in harmonic traps estimates chemical potential and temperature from single-shot density profiles.", "result": "The model achieves rapid parameter extraction, generalizes to untrained trap geometries (e.g., toroidal), and maintains accuracy during dynamic thermalization.", "conclusion": "Supervised learning can overcome traditional thermometry limitations, enabling real-time, precise analysis of quantum gas experiments."}}
{"id": "2503.01807", "pdf": "https://arxiv.org/pdf/2503.01807", "abs": "https://arxiv.org/abs/2503.01807", "authors": ["Hamish Ivison", "Muru Zhang", "Faeze Brahman", "Pang Wei Koh", "Pradeep Dasigi"], "title": "Large-Scale Data Selection for Instruction Tuning", "categories": ["cs.CL"], "comment": "Updated, new baselines, removed some typos", "summary": "Selecting high-quality training data from a larger pool is a crucial step\nwhen instruction-tuning language models, as carefully curated datasets often\nproduce models that outperform those trained on much larger, noisier datasets.\nAutomated data selection approaches for instruction-tuning are typically tested\nby selecting small datasets (roughly 10k samples) from small pools (100-200k\nsamples). However, popular deployed instruction-tuned models often train on\nhundreds of thousands to millions of samples, subsampled from even larger data\npools. We present a systematic study of how well data selection methods scale\nto these settings, selecting up to 2.5M samples from pools of up to 5.8M\nsamples and evaluating across 7 diverse tasks. We show that many recently\nproposed methods fall short of random selection in this setting (while using\nmore compute), and even decline in performance when given access to larger\npools of data to select over. However, we find that a variant of\nrepresentation-based data selection (RDS+), which uses weighted mean pooling of\npretrained LM hidden states, consistently outperforms more complex methods\nacross all settings tested -- all whilst being more compute-efficient. Our\nfindings highlight that the scaling properties of proposed automated selection\nmethods should be more closely examined. We release our code, data, and models\nat https://github.com/hamishivi/automated-instruction-selection.", "AI": {"tldr": "The paper evaluates data selection methods for instruction-tuning language models at scale, finding that many recent methods underperform random selection, while a simpler method (RDS+) consistently excels.", "motivation": "To study how well automated data selection methods scale to large datasets, as most prior work focuses on smaller datasets.", "method": "Systematically tests data selection methods, selecting up to 2.5M samples from pools of up to 5.8M, and evaluates across 7 tasks.", "result": "Many recent methods fail to outperform random selection, while RDS+ consistently performs better and is more compute-efficient.", "conclusion": "Scaling properties of data selection methods need closer examination; RDS+ is a robust and efficient choice."}}
{"id": "2506.15851", "pdf": "https://arxiv.org/pdf/2506.15851", "abs": "https://arxiv.org/abs/2506.15851", "authors": ["Qiyuan Wu", "Mark Campbell"], "title": "Semantic and Feature Guided Uncertainty Quantification of Visual Localization for Autonomous Vehicles", "categories": ["cs.RO", "cs.CV"], "comment": "Accepted by ICRA 2025", "summary": "The uncertainty quantification of sensor measurements coupled with deep\nlearning networks is crucial for many robotics systems, especially for\nsafety-critical applications such as self-driving cars. This paper develops an\nuncertainty quantification approach in the context of visual localization for\nautonomous driving, where locations are selected based on images. Key to our\napproach is to learn the measurement uncertainty using light-weight sensor\nerror model, which maps both image feature and semantic information to\n2-dimensional error distribution. Our approach enables uncertainty estimation\nconditioned on the specific context of the matched image pair, implicitly\ncapturing other critical, unannotated factors (e.g., city vs highway, dynamic\nvs static scenes, winter vs summer) in a latent manner. We demonstrate the\naccuracy of our uncertainty prediction framework using the Ithaca365 dataset,\nwhich includes variations in lighting and weather (sunny, night, snowy). Both\nthe uncertainty quantification of the sensor+network is evaluated, along with\nBayesian localization filters using unique sensor gating method. Results show\nthat the measurement error does not follow a Gaussian distribution with poor\nweather and lighting conditions, and is better predicted by our Gaussian\nMixture model.", "AI": {"tldr": "The paper presents a method for uncertainty quantification in visual localization for autonomous driving, using a lightweight sensor error model to predict measurement uncertainty based on image features and semantics.", "motivation": "Accurate uncertainty quantification is vital for safety-critical robotics applications like self-driving cars, especially under varying environmental conditions.", "method": "A lightweight sensor error model maps image features and semantic information to a 2D error distribution, capturing contextual factors implicitly. The approach is tested on the Ithaca365 dataset under diverse conditions.", "result": "Measurement errors under poor weather and lighting conditions are non-Gaussian and better predicted by a Gaussian Mixture model.", "conclusion": "The proposed method effectively quantifies uncertainty in visual localization, improving accuracy in challenging conditions."}}
{"id": "2506.16855", "pdf": "https://arxiv.org/pdf/2506.16855", "abs": "https://arxiv.org/abs/2506.16855", "authors": ["Shaoyu Dou", "Kai Yang", "Yang Jiao", "Chengbo Qiu", "Kui Ren"], "title": "Anomaly Detection in Event-triggered Traffic Time Series via Similarity Learning", "categories": ["cs.LG"], "comment": "16 pages, 14 figures. Published in IEEE Transactions on Dependable\n  and Secure Computing. arXiv admin note: substantial text overlap with\n  arXiv:2207.08159", "summary": "Time series analysis has achieved great success in cyber security such as\nintrusion detection and device identification. Learning similarities among\nmultiple time series is a crucial problem since it serves as the foundation for\ndownstream analysis. Due to the complex temporal dynamics of the\nevent-triggered time series, it often remains unclear which similarity metric\nis appropriate for security-related tasks, such as anomaly detection and\nclustering. The overarching goal of this paper is to develop an unsupervised\nlearning framework that is capable of learning similarities among a set of\nevent-triggered time series. From the machine learning vantage point, the\nproposed framework harnesses the power of both hierarchical multi-resolution\nsequential autoencoders and the Gaussian Mixture Model (GMM) to effectively\nlearn the low-dimensional representations from the time series. Finally, the\nobtained similarity measure can be easily visualized for the explanation. The\nproposed framework aspires to offer a stepping stone that gives rise to a\nsystematic approach to model and learn similarities among a multitude of\nevent-triggered time series. Through extensive qualitative and quantitative\nexperiments, it is revealed that the proposed method outperforms\nstate-of-the-art methods considerably.", "AI": {"tldr": "The paper proposes an unsupervised learning framework for measuring similarities in event-triggered time series, combining hierarchical autoencoders and GMM for improved performance in security tasks.", "motivation": "The challenge of selecting appropriate similarity metrics for security-related time series analysis, such as anomaly detection and clustering, drives the need for an unsupervised framework.", "method": "The framework uses hierarchical multi-resolution sequential autoencoders and Gaussian Mixture Model (GMM) to learn low-dimensional representations of time series.", "result": "The proposed method outperforms state-of-the-art techniques in qualitative and quantitative experiments.", "conclusion": "The framework provides a systematic approach for modeling and learning similarities in event-triggered time series, with potential applications in cyber security."}}
{"id": "2506.16929", "pdf": "https://arxiv.org/pdf/2506.16929", "abs": "https://arxiv.org/abs/2506.16929", "authors": ["Mohon Raihan", "Plabon Kumar Saha", "Rajan Das Gupta", "A Z M Tahmidul Kabir", "Afia Anjum Tamanna", "Md. Harun-Ur-Rashid", "Adnan Bin Abdus Salam", "Md Tanvir Anjum", "A Z M Ahteshamul Kabir"], "title": "A deep learning and machine learning approach to predict neonatal death in the context of S\u00e3o Paulo", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Neonatal death is still a concerning reality for underdeveloped and even some\ndeveloped countries. Worldwide data indicate that 26.693 babies out of 1,000\nbirths die, according to Macro Trades. To reduce this number, early prediction\nof endangered babies is crucial. Such prediction enables the opportunity to\ntake ample care of the child and mother so that early child death can be\navoided. In this context, machine learning was used to determine whether a\nnewborn baby is at risk. To train the predictive model, historical data of 1.4\nmillion newborns was used. Machine learning and deep learning techniques such\nas logical regression, K-nearest neighbor, random forest classifier, extreme\ngradient boosting (XGBoost), convolutional neural network, and long short-term\nmemory (LSTM) were implemented using the dataset to identify the most accurate\nmodel for predicting neonatal mortality. Among the machine learning algorithms,\nXGBoost and random forest classifier achieved the best accuracy with 94%, while\namong the deep learning models, LSTM delivered the highest accuracy with 99%.\nTherefore, using LSTM appears to be the most suitable approach to predict\nwhether precautionary measures for a child are necessary.", "AI": {"tldr": "The paper proposes using machine learning (XGBoost, random forest) and deep learning (LSTM) to predict neonatal mortality, with LSTM achieving 99% accuracy.", "motivation": "Neonatal death remains a global issue; early prediction can save lives by enabling timely care.", "method": "Used historical data of 1.4M newborns to train models like logistic regression, KNN, random forest, XGBoost, CNN, and LSTM.", "result": "XGBoost and random forest achieved 94% accuracy; LSTM outperformed with 99%.", "conclusion": "LSTM is the most effective for predicting neonatal mortality and guiding precautionary measures."}}
{"id": "2503.02832", "pdf": "https://arxiv.org/pdf/2503.02832", "abs": "https://arxiv.org/abs/2503.02832", "authors": ["Songming Zhang", "Xue Zhang", "Tong Zhang", "Bojie Hu", "Yufeng Chen", "Jinan Xu"], "title": "AlignDistil: Token-Level Language Model Alignment as Adaptive Policy Distillation", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "ACL 2025 Main Conference, code available at:\n  https://github.com/songmzhang/AlignDistil", "summary": "In modern large language models (LLMs), LLM alignment is of crucial\nimportance and is typically achieved through methods such as reinforcement\nlearning from human feedback (RLHF) and direct preference optimization (DPO).\nHowever, in most existing methods for LLM alignment, all tokens in the response\nare optimized using a sparse, response-level reward or preference annotation.\nThe ignorance of token-level rewards may erroneously punish high-quality tokens\nor encourage low-quality tokens, resulting in suboptimal performance and slow\nconvergence speed. To address this issue, we propose AlignDistil, an\nRLHF-equivalent distillation method for token-level reward optimization.\nSpecifically, we introduce the reward learned by DPO into the RLHF objective\nand theoretically prove the equivalence between this objective and a\ntoken-level distillation process, where the teacher distribution linearly\ncombines the logits from the DPO model and a reference model. On this basis, we\nfurther bridge the accuracy gap between the reward from the DPO model and the\npure reward model, by building a contrastive DPO reward with a normal and a\nreverse DPO model. Moreover, to avoid under- and over-optimization on different\ntokens, we design a token adaptive logit extrapolation mechanism to construct\nan appropriate teacher distribution for each token. Experimental results\ndemonstrate the superiority of our AlignDistil over existing methods and\nshowcase fast convergence due to its token-level distributional reward\noptimization.", "AI": {"tldr": "AlignDistil is a token-level reward optimization method for LLM alignment, improving performance and convergence by addressing the limitations of sparse response-level rewards.", "motivation": "Existing LLM alignment methods use sparse response-level rewards, which can misalign token-level quality, leading to suboptimal performance and slow convergence.", "method": "AlignDistil integrates DPO rewards into RLHF, proving equivalence to token-level distillation. It uses contrastive DPO rewards and adaptive logit extrapolation for balanced optimization.", "result": "AlignDistil outperforms existing methods, showing faster convergence and better performance due to token-level reward optimization.", "conclusion": "AlignDistil effectively addresses token-level misalignment in LLMs, offering a superior and efficient alternative to traditional alignment methods."}}
{"id": "2506.15888", "pdf": "https://arxiv.org/pdf/2506.15888", "abs": "https://arxiv.org/abs/2506.15888", "authors": ["Md Sakibur Sajal", "Hunter Guthrie", "Marc Dandin"], "title": "Bias Variation Compensation in Perimeter-Gated SPAD TRNGs", "categories": ["physics.ins-det", "cs.AR", "cs.CR", "cs.CV"], "comment": "5 pages, 8 figures, 1 software, accepted at MWSCAS 2025 conference", "summary": "Random number generators that utilize arrays of entropy source elements\nsuffer from bias variation (BV). Despite the availability of efficient\ndebiasing algorithms, optimized implementations of hardware friendly options\ndepend on the bit bias in the raw bit streams and cannot accommodate a wide BV.\nIn this work, we present a 64 x 64 array of perimeter gated single photon\navalanche diodes (pgSPADs), fabricated in a 0.35 {\\mu}m standard CMOS\ntechnology, as a source of entropy to generate random binary strings with a BV\ncompensation technique. By applying proper gate voltages based on the devices'\nnative dark count rates, we demonstrate less than 1% BV for a raw-bit\ngeneration rate of 2 kHz/pixel at room temperature. The raw bits were debiased\nusing the classical iterative Von Neumann's algorithm and the debiased bits\nwere found to pass all of the 16 tests from NIST's Statistical Test Suite.", "AI": {"tldr": "A 64x64 array of pgSPADs in 0.35\u03bcm CMOS is used as an entropy source for random binary strings, achieving <1% BV and passing NIST tests after Von Neumann debiasing.", "motivation": "Address bias variation (BV) in entropy-based random number generators, as current debiasing methods struggle with wide BV.", "method": "Utilize a 64x64 pgSPAD array with gate voltage tuning based on dark count rates, then apply Von Neumann debiasing.", "result": "Achieved <1% BV at 2 kHz/pixel, with debiased bits passing all 16 NIST tests.", "conclusion": "The pgSPAD array with BV compensation is effective for high-quality random number generation."}}
{"id": "2506.16862", "pdf": "https://arxiv.org/pdf/2506.16862", "abs": "https://arxiv.org/abs/2506.16862", "authors": ["Qian Qi"], "title": "Optimal Depth of Neural Networks", "categories": ["cs.LG", "math.OC"], "comment": null, "summary": "Determining the optimal depth of a neural network is a fundamental yet\nchallenging problem, typically resolved through resource-intensive\nexperimentation. This paper introduces a formal theoretical framework to\naddress this question by recasting the forward pass of a deep network,\nspecifically a Residual Network (ResNet), as an optimal stopping problem. We\nmodel the layer-by-layer evolution of hidden representations as a sequential\ndecision process where, at each layer, a choice is made between halting\ncomputation to make a prediction or continuing to a deeper layer for a\npotentially more refined representation. This formulation captures the\nintrinsic trade-off between accuracy and computational cost. Our primary\ntheoretical contribution is a proof that, under a plausible condition of\ndiminishing returns on the residual functions, the expected optimal stopping\ndepth is provably finite, even in an infinite-horizon setting. We leverage this\ninsight to propose a novel and practical regularization term, $\\mathcal{L}_{\\rm\ndepth}$, that encourages the network to learn representations amenable to\nefficient, early exiting. We demonstrate the generality of our framework by\nextending it to the Transformer architecture and exploring its connection to\ncontinuous-depth models via free-boundary problems. Empirical validation on\nImageNet confirms that our regularizer successfully induces the theoretically\npredicted behavior, leading to significant gains in computational efficiency\nwithout compromising, and in some cases improving, final model accuracy.", "AI": {"tldr": "The paper introduces a theoretical framework to determine the optimal depth of neural networks by modeling the forward pass as an optimal stopping problem, proving finite stopping depth under diminishing returns, and proposing a practical regularization term for early exiting.", "motivation": "The challenge of determining neural network depth through costly experimentation motivates a formal theoretical approach to balance accuracy and computational efficiency.", "method": "The forward pass of a ResNet is recast as an optimal stopping problem, with a proof of finite stopping depth under diminishing returns. A regularization term, $\\mathcal{L}_{\\rm depth}$, is proposed to encourage early exiting.", "result": "Empirical validation on ImageNet shows the regularizer improves computational efficiency without sacrificing accuracy, sometimes even enhancing it.", "conclusion": "The framework provides a principled way to optimize network depth, with practical benefits demonstrated in computational efficiency and accuracy."}}
{"id": "2506.17039", "pdf": "https://arxiv.org/pdf/2506.17039", "abs": "https://arxiv.org/abs/2506.17039", "authors": ["Elizabeth Fons", "Alejandro Sztrajman", "Yousef El-Laham", "Luciana Ferrer", "Svitlana Vyetrenko", "Manuela Veloso"], "title": "LSCD: Lomb-Scargle Conditioned Diffusion for Time series Imputation", "categories": ["cs.LG", "cs.AI"], "comment": "In ICML 2025", "summary": "Time series with missing or irregularly sampled data are a persistent\nchallenge in machine learning. Many methods operate on the frequency-domain,\nrelying on the Fast Fourier Transform (FFT) which assumes uniform sampling,\ntherefore requiring prior interpolation that can distort the spectra. To\naddress this limitation, we introduce a differentiable Lomb--Scargle layer that\nenables a reliable computation of the power spectrum of irregularly sampled\ndata. We integrate this layer into a novel score-based diffusion model (LSCD)\nfor time series imputation conditioned on the entire signal spectrum.\nExperiments on synthetic and real-world benchmarks demonstrate that our method\nrecovers missing data more accurately than purely time-domain baselines, while\nsimultaneously producing consistent frequency estimates. Crucially, our method\ncan be easily integrated into learning frameworks, enabling broader adoption of\nspectral guidance in machine learning approaches involving incomplete or\nirregular data.", "AI": {"tldr": "A differentiable Lomb-Scargle layer is introduced for computing power spectra of irregularly sampled data, integrated into a score-based diffusion model (LSCD) for accurate time series imputation.", "motivation": "Addressing challenges in machine learning posed by missing or irregularly sampled time series data, avoiding distortions from interpolation required by FFT.", "method": "Proposes a differentiable Lomb-Scargle layer for spectral computation and integrates it into a score-based diffusion model (LSCD) for imputation.", "result": "Outperforms time-domain baselines in accuracy for missing data recovery and provides consistent frequency estimates.", "conclusion": "The method enables spectral guidance in machine learning for incomplete or irregular data, with potential for broader adoption."}}
{"id": "2503.05298", "pdf": "https://arxiv.org/pdf/2503.05298", "abs": "https://arxiv.org/abs/2503.05298", "authors": ["Nikolai Ilinykh", "Shalom Lappin", "Asad Sayeed", "Sharid Lo\u00e1iciga"], "title": "Coreference as an indicator of context scope in multimodal narrative", "categories": ["cs.CL"], "comment": "19 pages, 4 tables. Accepted to GEM2 Workshop: Generation, Evaluation\n  & Metrics at ACL 2025", "summary": "We demonstrate that large multimodal language models differ substantially\nfrom humans in the distribution of coreferential expressions in a visual\nstorytelling task. We introduce a number of metrics to quantify the\ncharacteristics of coreferential patterns in both human- and machine-written\ntexts. Humans distribute coreferential expressions in a way that maintains\nconsistency across texts and images, interleaving references to different\nentities in a highly varied way. Machines are less able to track mixed\nreferences, despite achieving perceived improvements in generation quality.\nMaterials, metrics, and code for our study are available at\nhttps://github.com/GU-CLASP/coreference-context-scope.", "AI": {"tldr": "Large multimodal models differ from humans in coreferential expression distribution in visual storytelling, with humans maintaining consistency and variety, while machines struggle despite improved generation quality.", "motivation": "To compare how humans and machines distribute coreferential expressions in visual storytelling tasks and highlight differences in consistency and variety.", "method": "Introduces metrics to quantify coreferential patterns in human- and machine-written texts, analyzing distribution and consistency across texts and images.", "result": "Humans interleave references to entities more variably and consistently, while machines struggle with mixed references despite better generation quality.", "conclusion": "The study reveals gaps in machine performance in handling coreferential expressions compared to humans, with tools and metrics made available for further research."}}
{"id": "2506.16050", "pdf": "https://arxiv.org/pdf/2506.16050", "abs": "https://arxiv.org/abs/2506.16050", "authors": ["Jiawen Yu", "Jieji Ren", "Yang Chang", "Qiaojun Yu", "Xuan Tong", "Boyang Wang", "Yan Song", "You Li", "Xinji Mai", "Wenqiang Zhang"], "title": "Noise Fusion-based Distillation Learning for Anomaly Detection in Complex Industrial Environments", "categories": ["cs.RO", "cs.CV"], "comment": "IROS 2025 Oral", "summary": "Anomaly detection and localization in automated industrial manufacturing can\nsignificantly enhance production efficiency and product quality. Existing\nmethods are capable of detecting surface defects in pre-defined or controlled\nimaging environments. However, accurately detecting workpiece defects in\ncomplex and unstructured industrial environments with varying views, poses and\nillumination remains challenging. We propose a novel anomaly detection and\nlocalization method specifically designed to handle inputs with perturbative\npatterns. Our approach introduces a new framework based on a collaborative\ndistillation heterogeneous teacher network (HetNet), an adaptive local-global\nfeature fusion module, and a local multivariate Gaussian noise generation\nmodule. HetNet can learn to model the complex feature distribution of normal\npatterns using limited information about local disruptive changes. We conducted\nextensive experiments on mainstream benchmarks. HetNet demonstrates superior\nperformance with approximately 10% improvement across all evaluation metrics on\nMSC-AD under industrial conditions, while achieving state-of-the-art results on\nother datasets, validating its resilience to environmental fluctuations and its\ncapability to enhance the reliability of industrial anomaly detection systems\nacross diverse scenarios. Tests in real-world environments further confirm that\nHetNet can be effectively integrated into production lines to achieve robust\nand real-time anomaly detection. Codes, images and videos are published on the\nproject website at: https://zihuatanejoyu.github.io/HetNet/", "AI": {"tldr": "A novel anomaly detection method (HetNet) improves industrial defect detection in complex environments by 10%, using collaborative distillation and adaptive feature fusion.", "motivation": "Existing methods struggle with defect detection in unstructured industrial settings due to varying conditions like illumination and poses.", "method": "Proposes HetNet, combining collaborative distillation, adaptive local-global feature fusion, and Gaussian noise generation for robust anomaly detection.", "result": "HetNet achieves a 10% improvement on MSC-AD and state-of-the-art results on other datasets, proving resilience to environmental changes.", "conclusion": "HetNet is effective for real-time, robust anomaly detection in industrial settings, validated by real-world tests."}}
{"id": "2506.16890", "pdf": "https://arxiv.org/pdf/2506.16890", "abs": "https://arxiv.org/abs/2506.16890", "authors": ["Sebastian H\u00f6nel", "Jonas Nordqvist"], "title": "From Lab to Factory: Pitfalls and Guidelines for Self-/Unsupervised Defect Detection on Low-Quality Industrial Images", "categories": ["cs.LG", "cs.CV", "stat.AP", "62-06", "G.3; I.4; I.5"], "comment": "18 pages, 7 figures, 1 table. Camera-ready version for the 2025\n  conference European Conference on Machine Learning and Principles and\n  Practice of Knowledge Discovery in Databases (ECML PKDD '25)", "summary": "The detection and localization of quality-related problems in industrially\nmass-produced products has historically relied on manual inspection, which is\ncostly and error-prone. Machine learning has the potential to replace manual\nhandling. As such, the desire is to facilitate an unsupervised (or\nself-supervised) approach, as it is often impossible to specify all conceivable\ndefects ahead of time. A plethora of prior works have demonstrated the aptitude\nof common reconstruction-, embedding-, and synthesis-based methods in\nlaboratory settings. However, in practice, we observe that most methods do not\nhandle low data quality well or exude low robustness in unfavorable, but\ntypical real-world settings. For practitioners it may be very difficult to\nidentify the actual underlying problem when such methods underperform. Worse,\noften-reported metrics (e.g., AUROC) are rarely suitable in practice and may\ngive misleading results. In our setting, we attempt to identify subtle\nanomalies on the surface of blasted forged metal parts, using rather\nlow-quality RGB imagery only, which is a common industrial setting. We\nspecifically evaluate two types of state-of-the-art models that allow us to\nidentify and improve quality issues in production data, without having to\nobtain new data. Our contribution is to provide guardrails for practitioners\nthat allow them to identify problems related to, e.g., (lack of) robustness or\ninvariance, in either the chosen model or the data reliably in similar\nscenarios. Furthermore, we exemplify common pitfalls in and shortcomings of\nlikelihood-based approaches and outline a framework for proper empirical risk\nestimation that is more suitable for real-world scenarios.", "AI": {"tldr": "The paper addresses challenges in unsupervised machine learning for detecting quality-related issues in industrial production, focusing on robustness and practical applicability.", "motivation": "Manual inspection is costly and error-prone; unsupervised ML can improve efficiency but struggles with low data quality and robustness in real-world settings.", "method": "Evaluates two state-of-the-art models for anomaly detection on low-quality RGB images of blasted forged metal parts, focusing on robustness and invariance.", "result": "Identifies common pitfalls in likelihood-based approaches and proposes a framework for better empirical risk estimation in real-world scenarios.", "conclusion": "Provides practical guardrails for practitioners to improve model and data quality in industrial anomaly detection."}}
{"id": "2506.17041", "pdf": "https://arxiv.org/pdf/2506.17041", "abs": "https://arxiv.org/abs/2506.17041", "authors": ["Joshua Schraven", "Alexander Windmann", "Oliver Niggemann"], "title": "MAWIFlow Benchmark: Realistic Flow-Based Evaluation for Network Intrusion Detection", "categories": ["cs.LG", "cs.AI"], "comment": "11 pages, 3 figures", "summary": "Benchmark datasets for network intrusion detection commonly rely on\nsynthetically generated traffic, which fails to reflect the statistical\nvariability and temporal drift encountered in operational environments. This\npaper introduces MAWIFlow, a flow-based benchmark derived from the MAWILAB v1.1\ndataset, designed to enable realistic and reproducible evaluation of anomaly\ndetection methods. A reproducible preprocessing pipeline is presented that\ntransforms raw packet captures into flow representations conforming to the\nCICFlowMeter format, while preserving MAWILab's original anomaly labels. The\nresulting datasets comprise temporally distinct samples from January 2011,\n2016, and 2021, drawn from trans-Pacific backbone traffic.\n  To establish reference baselines, traditional machine learning methods,\nincluding Decision Trees, Random Forests, XGBoost, and Logistic Regression, are\ncompared to a deep learning model based on a CNN-BiLSTM architecture. Empirical\nresults demonstrate that tree-based classifiers perform well on temporally\nstatic data but experience significant performance degradation over time. In\ncontrast, the CNN-BiLSTM model maintains better performance, thus showing\nimproved generalization. These findings underscore the limitations of synthetic\nbenchmarks and static models, and motivate the adoption of realistic datasets\nwith explicit temporal structure. All datasets, pipeline code, and model\nimplementations are made publicly available to foster transparency and\nreproducibility.", "AI": {"tldr": "MAWIFlow is a realistic flow-based benchmark for network intrusion detection, derived from MAWILab v1.1, addressing limitations of synthetic datasets. It includes temporally distinct samples and evaluates traditional and deep learning methods, showing CNN-BiLSTM's superior generalization.", "motivation": "Existing synthetic datasets lack statistical variability and temporal drift, limiting realistic evaluation of anomaly detection methods.", "method": "MAWIFlow transforms raw packet captures into flow representations (CICFlowMeter format) with preserved anomaly labels. Traditional ML and CNN-BiLSTM models are compared.", "result": "Tree-based models degrade over time, while CNN-BiLSTM maintains performance, highlighting the need for realistic datasets with temporal structure.", "conclusion": "Realistic benchmarks like MAWIFlow are crucial for evaluating anomaly detection methods. Publicly available datasets and code promote transparency."}}
{"id": "2503.05328", "pdf": "https://arxiv.org/pdf/2503.05328", "abs": "https://arxiv.org/abs/2503.05328", "authors": ["Anar Yeginbergen", "Maite Oronoz", "Rodrigo Agerri"], "title": "Dynamic Knowledge Integration for Evidence-Driven Counter-Argument Generation with Large Language Models", "categories": ["cs.CL", "cs.AI"], "comment": "ACL 2025", "summary": "This paper investigates the role of dynamic external knowledge integration in\nimproving counter-argument generation using Large Language Models (LLMs). While\nLLMs have shown promise in argumentative tasks, their tendency to generate\nlengthy, potentially unfactual responses highlights the need for more\ncontrolled and evidence-based approaches. We introduce a new manually curated\ndataset of argument and counter-argument pairs specifically designed to balance\nargumentative complexity with evaluative feasibility. We also propose a new\nLLM-as-a-Judge evaluation methodology that shows a stronger correlation with\nhuman judgments compared to traditional reference-based metrics. Our\nexperimental results demonstrate that integrating dynamic external knowledge\nfrom the web significantly improves the quality of generated counter-arguments,\nparticularly in terms of relatedness, persuasiveness, and factuality. The\nfindings suggest that combining LLMs with real-time external knowledge\nretrieval offers a promising direction for developing more effective and\nreliable counter-argumentation systems.", "AI": {"tldr": "The paper explores dynamic external knowledge integration to enhance counter-argument generation in LLMs, introducing a curated dataset and a new evaluation method. Results show improved counter-argument quality.", "motivation": "LLMs often produce lengthy or unfactual responses in argumentative tasks, necessitating controlled, evidence-based approaches.", "method": "Introduces a manually curated dataset and an LLM-as-a-Judge evaluation method, integrating dynamic external knowledge from the web.", "result": "Dynamic knowledge integration improves counter-argument quality in relatedness, persuasiveness, and factuality.", "conclusion": "Combining LLMs with real-time knowledge retrieval is promising for reliable counter-argumentation systems."}}
{"id": "2506.16201", "pdf": "https://arxiv.org/pdf/2506.16201", "abs": "https://arxiv.org/abs/2506.16201", "authors": ["Sen Wang", "Le Wang", "Sanping Zhou", "Jingyi Tian", "Jiayi Li", "Haowen Sun", "Wei Tang"], "title": "FlowRAM: Grounding Flow Matching Policy with Region-Aware Mamba Framework for Robotic Manipulation", "categories": ["cs.RO", "cs.CV"], "comment": null, "summary": "Robotic manipulation in high-precision tasks is essential for numerous\nindustrial and real-world applications where accuracy and speed are required.\nYet current diffusion-based policy learning methods generally suffer from low\ncomputational efficiency due to the iterative denoising process during\ninference. Moreover, these methods do not fully explore the potential of\ngenerative models for enhancing information exploration in 3D environments. In\nresponse, we propose FlowRAM, a novel framework that leverages generative\nmodels to achieve region-aware perception, enabling efficient multimodal\ninformation processing. Specifically, we devise a Dynamic Radius Schedule,\nwhich allows adaptive perception, facilitating transitions from global scene\ncomprehension to fine-grained geometric details. Furthermore, we integrate\nstate space models to integrate multimodal information, while preserving linear\ncomputational complexity. In addition, we employ conditional flow matching to\nlearn action poses by regressing deterministic vector fields, simplifying the\nlearning process while maintaining performance. We verify the effectiveness of\nthe FlowRAM in the RLBench, an established manipulation benchmark, and achieve\nstate-of-the-art performance. The results demonstrate that FlowRAM achieves a\nremarkable improvement, particularly in high-precision tasks, where it\noutperforms previous methods by 12.0% in average success rate. Additionally,\nFlowRAM is able to generate physically plausible actions for a variety of\nreal-world tasks in less than 4 time steps, significantly increasing inference\nspeed.", "AI": {"tldr": "FlowRAM is a novel framework using generative models for efficient robotic manipulation, improving precision and speed over diffusion-based methods.", "motivation": "Addressing the inefficiency of diffusion-based policy learning and underutilization of generative models in 3D environments for robotic tasks.", "method": "Proposes FlowRAM with Dynamic Radius Schedule for adaptive perception, state space models for multimodal integration, and conditional flow matching for action pose learning.", "result": "Achieves 12.0% higher success rate in high-precision tasks and faster inference (under 4 steps) in RLBench.", "conclusion": "FlowRAM outperforms existing methods in precision and efficiency, demonstrating its potential for real-world applications."}}
{"id": "2506.16965", "pdf": "https://arxiv.org/pdf/2506.16965", "abs": "https://arxiv.org/abs/2506.16965", "authors": ["\u00c7a\u011fatay Demirel"], "title": "RocketStack: A level-aware deep recursive ensemble learning framework with exploratory feature fusion and model pruning dynamics", "categories": ["cs.LG", "stat.ML"], "comment": "32 pages, 1 graphical abstract, 7 figures, 9 tables, 2 supplementary\n  figures", "summary": "Ensemble learning remains a cornerstone of machine learning, with stacking\nused to integrate predictions from multiple base learners through a meta-model.\nHowever, deep stacking remains rare, as most designs prioritize horizontal\ndiversity over recursive depth due to model complexity, feature redundancy, and\ncomputational burden. To address these challenges, RocketStack, a level-aware\nrecursive ensemble framework, is introduced and explored up to ten stacking\nlevels, extending beyond prior architectures. The framework incrementally\nprunes weaker learners at each level, enabling deeper stacking without\nexcessive complexity. To mitigate early performance saturation, mild Gaussian\nnoise is added to out-of-fold (OOF) scores before pruning, and compared against\nstrict OOF pruning. Further both per-level and periodic feature compressions\nare explored using attention-based selection, Simple, Fast, Efficient (SFE)\nfilter, and autoencoders. Across 33 datasets (23 binary, 10 multi-class),\nlinear-trend tests confirmed rising accuracy with depth in most variants, and\nthe top performing meta-model at each level increasingly outperformed the\nstrongest standalone ensemble. In the binary subset, periodic SFE with mild\nOOF-score randomization reached 97.08% at level 10, 5.14% above the\nstrict-pruning configuration and cut runtime by 10.5% relative to no\ncompression. In the multi-class subset, periodic attention selection reached\n98.60% at level 10, exceeding the strongest baseline by 6.11%, while reducing\nruntime by 56.1% and feature dimensionality by 74% compared to no compression.\nThese findings highlight mild randomization as an effective regularizer and\nperiodic compression as a stabilizer. Echoing the design of multistage rockets\nin aerospace (prune, compress, propel) RocketStack achieves deep recursive\nensembling with tractable complexity.", "AI": {"tldr": "RocketStack introduces a level-aware recursive ensemble framework for deep stacking, addressing complexity and redundancy through pruning, noise, and feature compression, achieving higher accuracy and efficiency.", "motivation": "To overcome challenges like model complexity, feature redundancy, and computational burden in deep stacking, RocketStack aims to enable deeper ensemble learning with tractable complexity.", "method": "The framework uses incremental pruning of weaker learners, mild Gaussian noise on OOF scores, and feature compression (attention-based, SFE filter, autoencoders) to stabilize and optimize performance.", "result": "RocketStack achieved 97.08% accuracy (binary) and 98.60% (multi-class) at level 10, outperforming baselines by 5.14% and 6.11%, respectively, while reducing runtime and feature dimensionality.", "conclusion": "Mild randomization and periodic compression are effective for deep recursive ensembling, making RocketStack a scalable and efficient solution."}}
{"id": "2506.17065", "pdf": "https://arxiv.org/pdf/2506.17065", "abs": "https://arxiv.org/abs/2506.17065", "authors": ["Abdellah Rahmani", "Pascal Frossard"], "title": "Flow-Based Non-stationary Temporal Regime Causal Structure Learning", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Understanding causal relationships in multivariate time series is crucial in\nmany scenarios, such as those dealing with financial or neurological data. Many\nsuch time series exhibit multiple regimes, i.e., consecutive temporal segments\nwith a priori unknown boundaries, with each regime having its own causal\nstructure. Inferring causal dependencies and regime shifts is critical for\nanalyzing the underlying processes. However, causal structure learning in this\nsetting is challenging due to (1) non stationarity, i.e., each regime can have\nits own causal graph and mixing function, and (2) complex noise distributions,\nwhich may be non Gaussian or heteroscedastic. Existing causal discovery\napproaches cannot address these challenges, since generally assume stationarity\nor Gaussian noise with constant variance. Hence, we introduce FANTOM, a unified\nframework for causal discovery that handles non stationary processes along with\nnon Gaussian and heteroscedastic noises. FANTOM simultaneously infers the\nnumber of regimes and their corresponding indices and learns each regime's\nDirected Acyclic Graph. It uses a Bayesian Expectation Maximization algorithm\nthat maximizes the evidence lower bound of the data log likelihood. On the\ntheoretical side, we prove, under mild assumptions, that temporal\nheteroscedastic causal models, introduced in FANTOM's formulation, are\nidentifiable in both stationary and non stationary settings. In addition,\nextensive experiments on synthetic and real data show that FANTOM outperforms\nexisting methods.", "AI": {"tldr": "FANTOM is a framework for causal discovery in non-stationary, non-Gaussian, heteroscedastic multivariate time series, identifying regimes and their causal structures.", "motivation": "Existing methods fail to address non-stationarity and complex noise in time series, limiting causal analysis.", "method": "FANTOM uses a Bayesian Expectation Maximization algorithm to infer regimes and their Directed Acyclic Graphs.", "result": "Theoretical identifiability is proven, and experiments show FANTOM outperforms existing methods.", "conclusion": "FANTOM effectively handles non-stationary, complex-noise time series, advancing causal discovery."}}
{"id": "2503.05888", "pdf": "https://arxiv.org/pdf/2503.05888", "abs": "https://arxiv.org/abs/2503.05888", "authors": ["Bang Nguyen", "Tingting Du", "Mengxia Yu", "Lawrence Angrave", "Meng Jiang"], "title": "QG-SMS: Enhancing Test Item Analysis via Student Modeling and Simulation", "categories": ["cs.CL", "cs.AI", "cs.CY", "cs.LG"], "comment": "Camera Ready - ACL 2025 Main", "summary": "While the Question Generation (QG) task has been increasingly adopted in\neducational assessments, its evaluation remains limited by approaches that lack\na clear connection to the educational values of test items. In this work, we\nintroduce test item analysis, a method frequently used by educators to assess\ntest question quality, into QG evaluation. Specifically, we construct pairs of\ncandidate questions that differ in quality across dimensions such as topic\ncoverage, item difficulty, item discrimination, and distractor efficiency. We\nthen examine whether existing QG evaluation approaches can effectively\ndistinguish these differences. Our findings reveal significant shortcomings in\nthese approaches with respect to accurately assessing test item quality in\nrelation to student performance. To address this gap, we propose a novel QG\nevaluation framework, QG-SMS, which leverages Large Language Model for Student\nModeling and Simulation to perform test item analysis. As demonstrated in our\nextensive experiments and human evaluation study, the additional perspectives\nintroduced by the simulated student profiles lead to a more effective and\nrobust assessment of test items.", "AI": {"tldr": "The paper introduces test item analysis into Question Generation (QG) evaluation, revealing shortcomings in existing methods and proposing a novel framework, QG-SMS, using Large Language Models for better assessment.", "motivation": "Current QG evaluation lacks alignment with educational values. The study aims to bridge this gap by incorporating test item analysis to assess question quality.", "method": "Pairs of candidate questions differing in quality (topic coverage, difficulty, etc.) are constructed. Existing QG evaluation methods are tested, and a new framework, QG-SMS, using Large Language Models for student modeling, is proposed.", "result": "Existing QG evaluation methods fail to accurately assess test item quality. QG-SMS, with simulated student profiles, provides more effective and robust evaluations.", "conclusion": "QG-SMS improves QG evaluation by leveraging simulated student modeling, addressing the limitations of current approaches."}}
{"id": "2506.16299", "pdf": "https://arxiv.org/pdf/2506.16299", "abs": "https://arxiv.org/abs/2506.16299", "authors": ["Yueji Ma", "Yanzun Meng", "Dong Xiao", "Zuoqiang Shi", "Bin Wang"], "title": "Wavelet-based Global Orientation and Surface Reconstruction for Point Clouds", "categories": ["cs.CG", "cs.CV"], "comment": "22Pages", "summary": "Unoriented surface reconstruction is an important task in computer graphics\nand has extensive applications. Based on the compact support of wavelet and\northogonality properties, classic wavelet surface reconstruction achieves good\nand fast reconstruction. However, this method can only handle oriented points.\nDespite some improved attempts for unoriented points, such as iWSR, these\nmethods perform poorly on sparse point clouds. To address these shortcomings,\nwe propose a wavelet-based method to represent the mollified indicator function\nand complete both the orientation and surface reconstruction tasks. We use the\nmodifying kernel function to smoothen out discontinuities on the surface,\naligning with the continuity of the wavelet basis function. During the\ncalculation of coefficient, we fully utilize the properties of the\nconvolutional kernel function to shift the modifying computation onto wavelet\nbasis to accelerate. In addition, we propose a novel method for constructing\nthe divergence-free function field and using them to construct the additional\nhomogeneous constraints to improve the effectiveness and stability. Extensive\nexperiments demonstrate that our method achieves state-of-the-art performance\nin both orientation and reconstruction for sparse models. We align the matrix\nconstruction with the compact support property of wavelet basis functions to\nfurther accelerate our method, resulting in efficient performance on CPU. Our\nsource codes will be released on GitHub.", "AI": {"tldr": "A wavelet-based method for unoriented surface reconstruction is proposed, addressing limitations of existing methods for sparse point clouds by using mollified indicator functions and divergence-free fields.", "motivation": "Existing wavelet-based methods for surface reconstruction are limited to oriented points or perform poorly on sparse point clouds, necessitating a more robust solution.", "method": "The method uses wavelet basis functions and a modifying kernel to smoothen discontinuities, accelerates computation via convolutional kernel properties, and introduces divergence-free fields for stability.", "result": "The method achieves state-of-the-art performance in orientation and reconstruction for sparse models, with efficient CPU performance.", "conclusion": "The proposed method effectively addresses the shortcomings of prior approaches, offering improved performance and stability for unoriented surface reconstruction."}}
{"id": "2506.17007", "pdf": "https://arxiv.org/pdf/2506.17007", "abs": "https://arxiv.org/abs/2506.17007", "authors": ["Marco Jiralerspong", "Esther Derman", "Danilo Vucetic", "Nikolay Malkin", "Bilun Sun", "Tianyu Zhang", "Pierre-Luc Bacon", "Gauthier Gidel"], "title": "Robust Reinforcement Learning for Discrete Compositional Generation via General Soft Operators", "categories": ["cs.LG"], "comment": null, "summary": "A major bottleneck in scientific discovery involves narrowing a large\ncombinatorial set of objects, such as proteins or molecules, to a small set of\npromising candidates. While this process largely relies on expert knowledge,\nrecent methods leverage reinforcement learning (RL) to enhance this filtering.\nThey achieve this by estimating proxy reward functions from available datasets\nand using regularization to generate more diverse candidates. These reward\nfunctions are inherently uncertain, raising a particularly salient challenge\nfor scientific discovery. In this work, we show that existing methods, often\nframed as sampling proportional to a reward function, are inadequate and yield\nsuboptimal candidates, especially in large search spaces. To remedy this issue,\nwe take a robust RL approach and introduce a unified operator that seeks\nrobustness to the uncertainty of the proxy reward function. This general\noperator targets peakier sampling distributions while encompassing known soft\nRL operators. It also leads us to a novel algorithm that identifies\nhigher-quality, diverse candidates in both synthetic and real-world tasks.\nUltimately, our work offers a new, flexible perspective on discrete\ncompositional generation tasks. Code: https://github.com/marcojira/tgm.", "AI": {"tldr": "The paper addresses the challenge of narrowing large combinatorial sets in scientific discovery by improving reinforcement learning methods to handle uncertain proxy rewards, introducing a robust RL operator for better candidate generation.", "motivation": "Existing methods for filtering combinatorial sets (e.g., proteins, molecules) rely on uncertain proxy rewards, leading to suboptimal candidate selection, especially in large search spaces.", "method": "The authors propose a robust RL approach with a unified operator to handle reward uncertainty, aiming for peakier sampling distributions and encompassing soft RL operators.", "result": "The introduced algorithm outperforms existing methods, generating higher-quality, diverse candidates in synthetic and real-world tasks.", "conclusion": "The work provides a flexible, robust framework for discrete compositional generation tasks, enhancing scientific discovery."}}
{"id": "2506.17073", "pdf": "https://arxiv.org/pdf/2506.17073", "abs": "https://arxiv.org/abs/2506.17073", "authors": ["Valeria Vuk", "Cristina Sarasua", "Fabrizio Gilardi"], "title": "LLM-Based Bot Broadens the Range of Arguments in Online Discussions, Even When Transparently Disclosed as AI", "categories": ["cs.CY", "cs.AI"], "comment": null, "summary": "A wide range of participation is essential for democracy, as it helps prevent\nthe dominance of extreme views, erosion of legitimacy, and political\npolarization. However, engagement in online political discussions often\nfeatures a limited spectrum of views due to high levels of self-selection and\nthe tendency of online platforms to facilitate exchanges primarily among\nlike-minded individuals. This study examines whether an LLM-based bot can widen\nthe scope of perspectives expressed by participants in online discussions\nthrough two pre-registered randomized experiments conducted in a chatroom. We\nevaluate the impact of a bot that actively monitors discussions, identifies\nmissing arguments, and introduces them into the conversation. The results\nindicate that our bot significantly expands the range of arguments, as measured\nby both objective and subjective metrics. Furthermore, disclosure of the bot as\nAI does not significantly alter these effects. These findings suggest that\nLLM-based moderation tools can positively influence online political discourse.", "AI": {"tldr": "An LLM-based bot was tested in online political discussions to widen perspectives. It successfully expanded argument diversity, even when disclosed as AI, suggesting positive effects on discourse.", "motivation": "To address limited perspectives in online political discussions caused by self-selection and like-minded interactions, which can harm democracy.", "method": "Two pre-registered randomized experiments in a chatroom using an LLM bot to identify and introduce missing arguments.", "result": "The bot significantly expanded argument diversity, with no major impact from AI disclosure.", "conclusion": "LLM-based moderation tools can positively influence online political discourse by broadening perspectives."}}
{"id": "2503.10486", "pdf": "https://arxiv.org/pdf/2503.10486", "abs": "https://arxiv.org/abs/2503.10486", "authors": ["Gaurav Kumar Gupta", "Pranal Pande", "Nirajan Acharya", "Aniket Kumar Singh", "Suman Niroula"], "title": "LLMs in Disease Diagnosis: A Comparative Study of DeepSeek-R1 and O3 Mini Across Chronic Health Conditions", "categories": ["cs.CL", "cs.AI"], "comment": "12 pages, 3 figures", "summary": "Large Language Models (LLMs) are revolutionizing medical diagnostics by\nenhancing both disease classification and clinical decision-making. In this\nstudy, we evaluate the performance of two LLM- based diagnostic tools, DeepSeek\nR1 and O3 Mini, using a structured dataset of symptoms and diagnoses. We\nassessed their predictive accuracy at both the disease and category levels, as\nwell as the reliability of their confidence scores. DeepSeek R1 achieved a\ndisease-level accuracy of 76% and an overall accuracy of 82%, outperforming O3\nMini, which attained 72% and 75% respectively. Notably, DeepSeek R1\ndemonstrated exceptional performance in Mental Health, Neurological Disorders,\nand Oncology, where it reached 100% accuracy, while O3 Mini excelled in\nAutoimmune Disease classification with 100% accuracy. Both models, however,\nstruggled with Respiratory Disease classification, recording accuracies of only\n40% for DeepSeek R1 and 20% for O3 Mini. Additionally, the analysis of\nconfidence scores revealed that DeepSeek R1 provided high-confidence\npredictions in 92% of cases, compared to 68% for O3 Mini. Ethical\nconsiderations regarding bias, model interpretability, and data privacy are\nalso discussed to ensure the responsible integration of LLMs into clinical\npractice. Overall, our findings offer valuable insights into the strengths and\nlimitations of LLM-based diagnostic systems and provide a roadmap for future\nenhancements in AI-driven healthcare.", "AI": {"tldr": "The study evaluates two LLM-based diagnostic tools, DeepSeek R1 and O3 Mini, showing DeepSeek R1 outperforms O3 Mini in accuracy and confidence scores, with notable strengths in Mental Health, Neurological Disorders, and Oncology, but weaknesses in Respiratory Diseases. Ethical considerations are highlighted.", "motivation": "To assess the performance and reliability of LLM-based diagnostic tools in medical diagnostics, comparing their accuracy and confidence scores across various disease categories.", "method": "Evaluation of DeepSeek R1 and O3 Mini using a structured dataset of symptoms and diagnoses, measuring predictive accuracy at disease and category levels, and analyzing confidence scores.", "result": "DeepSeek R1 achieved higher accuracy (76% disease-level, 82% overall) and confidence (92% high-confidence predictions) than O3 Mini (72%, 75%, 68%). Both struggled with Respiratory Diseases.", "conclusion": "The study highlights the potential and limitations of LLM-based diagnostics, emphasizing the need for ethical considerations and future improvements in AI-driven healthcare."}}
{"id": "2506.16401", "pdf": "https://arxiv.org/pdf/2506.16401", "abs": "https://arxiv.org/abs/2506.16401", "authors": ["Chunhou Ji", "Qiumeng Li"], "title": "TrajSceneLLM: A Multimodal Perspective on Semantic GPS Trajectory Analysis", "categories": ["cs.CY", "cs.CV"], "comment": "Under review for ACM SIGSPATIAL 2025", "summary": "GPS trajectory data reveals valuable patterns of human mobility and urban\ndynamics, supporting a variety of spatial applications. However, traditional\nmethods often struggle to extract deep semantic representations and incorporate\ncontextual map information. We propose TrajSceneLLM, a multimodal perspective\nfor enhancing semantic understanding of GPS trajectories. The framework\nintegrates visualized map images (encoding spatial context) and textual\ndescriptions generated through LLM reasoning (capturing temporal sequences and\nmovement dynamics). Separate embeddings are generated for each modality and\nthen concatenated to produce trajectory scene embeddings with rich semantic\ncontent which are further paired with a simple MLP classifier. We validate the\nproposed framework on Travel Mode Identification (TMI), a critical task for\nanalyzing travel choices and understanding mobility behavior. Our experiments\nshow that these embeddings achieve significant performance improvement,\nhighlighting the advantage of our LLM-driven method in capturing deep\nspatio-temporal dependencies and reducing reliance on handcrafted features.\nThis semantic enhancement promises significant potential for diverse downstream\napplications and future research in geospatial artificial intelligence. The\nsource code and dataset are publicly available at:\nhttps://github.com/februarysea/TrajSceneLLM.", "AI": {"tldr": "TrajSceneLLM enhances GPS trajectory analysis by combining map images and LLM-generated text for rich semantic embeddings, improving performance in tasks like Travel Mode Identification.", "motivation": "Traditional methods lack deep semantic understanding and contextual map integration in GPS trajectory analysis.", "method": "TrajSceneLLM integrates map images (spatial context) and LLM-generated text (temporal dynamics) to create semantic embeddings, paired with an MLP classifier.", "result": "Experiments show significant performance gains in Travel Mode Identification, capturing spatio-temporal dependencies and reducing reliance on handcrafted features.", "conclusion": "The framework offers potential for diverse geospatial AI applications, with code and data publicly available."}}
{"id": "2506.17029", "pdf": "https://arxiv.org/pdf/2506.17029", "abs": "https://arxiv.org/abs/2506.17029", "authors": ["Leizhen Wang", "Peibo Duan", "Cheng Lyu", "Zewen Wang", "Zhiqiang He", "Nan Zheng", "Zhenliang Ma"], "title": "Scalable and Reliable Multi-agent Reinforcement Learning for Traffic Assignment", "categories": ["cs.LG"], "comment": null, "summary": "The evolution of metropolitan cities and the increase in travel demands\nimpose stringent requirements on traffic assignment methods. Multi-agent\nreinforcement learning (MARL) approaches outperform traditional methods in\nmodeling adaptive routing behavior without requiring explicit system dynamics,\nwhich is beneficial for real-world deployment. However, MARL frameworks face\nchallenges in scalability and reliability when managing extensive networks with\nsubstantial travel demand, which limiting their practical applicability in\nsolving large-scale traffic assignment problems. To address these challenges,\nthis study introduces MARL-OD-DA, a new MARL framework for the traffic\nassignment problem, which redefines agents as origin-destination (OD) pair\nrouters rather than individual travelers, significantly enhancing scalability.\nAdditionally, a Dirichlet-based action space with action pruning and a reward\nfunction based on the local relative gap are designed to enhance solution\nreliability and improve convergence efficiency. Experiments demonstrate that\nthe proposed MARL framework effectively handles medium-sized networks with\nextensive and varied city-level OD demand, surpassing existing MARL methods.\nWhen implemented in the SiouxFalls network, MARL-OD-DA achieves better\nassignment solutions in 10 steps, with a relative gap that is 94.99% lower than\nthat of conventional methods.", "AI": {"tldr": "A new MARL framework, MARL-OD-DA, improves scalability and reliability for traffic assignment by redefining agents as OD pair routers and using a Dirichlet-based action space with pruning.", "motivation": "Address scalability and reliability challenges of MARL in large-scale traffic assignment problems.", "method": "Introduces MARL-OD-DA with OD pair routers, Dirichlet-based action space, action pruning, and a local relative gap reward function.", "result": "Outperforms existing MARL methods, achieving a 94.99% lower relative gap in the SiouxFalls network.", "conclusion": "MARL-OD-DA is effective for medium-sized networks with varied city-level OD demand, enhancing practical applicability."}}
{"id": "2506.17093", "pdf": "https://arxiv.org/pdf/2506.17093", "abs": "https://arxiv.org/abs/2506.17093", "authors": ["Konstantin Usevich", "Clara D\u00e9rand", "Ricardo Borsoi", "Marianne Clausel"], "title": "Identifiability of Deep Polynomial Neural Networks", "categories": ["cs.LG", "cs.AI", "math.AG", "stat.ML", "68T07, 62R01, 15A69, 14M99"], "comment": "1 figure", "summary": "Polynomial Neural Networks (PNNs) possess a rich algebraic and geometric\nstructure. However, their identifiability -- a key property for ensuring\ninterpretability -- remains poorly understood. In this work, we present a\ncomprehensive analysis of the identifiability of deep PNNs, including\narchitectures with and without bias terms. Our results reveal an intricate\ninterplay between activation degrees and layer widths in achieving\nidentifiability. As special cases, we show that architectures with\nnon-increasing layer widths are generically identifiable under mild conditions,\nwhile encoder-decoder networks are identifiable when the decoder widths do not\ngrow too rapidly. Our proofs are constructive and center on a connection\nbetween deep PNNs and low-rank tensor decompositions, and Kruskal-type\nuniqueness theorems. This yields both generic conditions determined by the\narchitecture, and effective conditions that depend on the network's parameters.\nWe also settle an open conjecture on the expected dimension of PNN's\nneurovarieties, and provide new bounds on the activation degrees required for\nit to reach its maximum.", "AI": {"tldr": "The paper analyzes the identifiability of deep Polynomial Neural Networks (PNNs), revealing how activation degrees and layer widths affect identifiability, with specific results for non-increasing and encoder-decoder architectures.", "motivation": "Understanding the identifiability of PNNs is crucial for their interpretability, but this property remains poorly understood.", "method": "The study connects deep PNNs to low-rank tensor decompositions and uses Kruskal-type uniqueness theorems to analyze identifiability.", "result": "Non-increasing layer widths and certain decoder width conditions ensure identifiability. The paper also resolves a conjecture on neurovarieties' dimensions and provides bounds on activation degrees.", "conclusion": "The work offers comprehensive insights into PNN identifiability, with constructive proofs and practical conditions for achieving it."}}
{"id": "2503.11280", "pdf": "https://arxiv.org/pdf/2503.11280", "abs": "https://arxiv.org/abs/2503.11280", "authors": ["Bryan Wilie", "Samuel Cahyawijaya", "Junxian He", "Pascale Fung"], "title": "High-Dimensional Interlingual Representations of Large Language Models", "categories": ["cs.CL"], "comment": null, "summary": "Large language models (LLMs) trained on massive multilingual datasets hint at\nthe formation of interlingual constructs--a shared subspace in the\nrepresentation space. However, evidence regarding this phenomenon is mixed,\nleaving it unclear whether these models truly develop unified interlingual\nrepresentations, or present a partially aligned constructs. We explore 31\ndiverse languages varying on their resource-levels, typologies, and\ngeographical regions; and find that multilingual LLMs exhibit inconsistent\ncross-lingual alignments. To address this, we propose an interlingual\nrepresentation framework identifying both the shared interlingual semantic\nsubspace and fragmented components, existed due to representational\nlimitations. We introduce Interlingual Local Overlap (ILO) score to quantify\ninterlingual alignment by comparing the local neighborhood structures of\nhigh-dimensional representations. We utilize ILO to investigate the impact of\nsingle-language fine-tuning on the interlingual representations in multilingual\nLLMs. Our results indicate that training exclusively on a single language\ndisrupts the alignment in early layers, while freezing these layers preserves\nthe alignment of interlingual representations, leading to improved\ncross-lingual generalization. These results validate our framework and metric\nfor evaluating interlingual representation, and further underscore that\ninterlingual alignment is crucial for scalable multilingual learning.", "AI": {"tldr": "Multilingual LLMs show inconsistent cross-lingual alignments. A new framework and ILO score quantify alignment, revealing that single-language fine-tuning disrupts early layers, while freezing them preserves alignment.", "motivation": "To clarify whether multilingual LLMs develop unified interlingual representations or partially aligned constructs, given mixed evidence.", "method": "Analyzed 31 diverse languages, proposed an interlingual representation framework, and introduced the ILO score to measure alignment. Tested the impact of single-language fine-tuning.", "result": "Single-language fine-tuning disrupts alignment in early layers; freezing these layers preserves alignment and improves cross-lingual generalization.", "conclusion": "Interlingual alignment is crucial for scalable multilingual learning, validated by the proposed framework and ILO metric."}}
{"id": "2506.16597", "pdf": "https://arxiv.org/pdf/2506.16597", "abs": "https://arxiv.org/abs/2506.16597", "authors": ["Anupma Choudhary", "Sohith Bandari", "B. S. Kushvah", "C. Swastik"], "title": "Exoplanet Classification through Vision Transformers with Temporal Image Analysis", "categories": ["astro-ph.EP", "astro-ph.IM", "cs.CV"], "comment": "Accepted for publication in the Astronomical Journal", "summary": "The classification of exoplanets has been a longstanding challenge in\nastronomy, requiring significant computational and observational resources.\nTraditional methods demand substantial effort, time, and cost, highlighting the\nneed for advanced machine learning techniques to enhance classification\nefficiency. In this study, we propose a methodology that transforms raw light\ncurve data from NASA's Kepler mission into Gramian Angular Fields (GAFs) and\nRecurrence Plots (RPs) using the Gramian Angular Difference Field and\nrecurrence plot techniques. These transformed images serve as inputs to the\nVision Transformer (ViT) model, leveraging its ability to capture intricate\ntemporal dependencies. We assess the performance of the model through recall,\nprecision, and F1 score metrics, using a 5-fold cross-validation approach to\nobtain a robust estimate of the model's performance and reduce evaluation bias.\nOur comparative analysis reveals that RPs outperform GAFs, with the ViT model\nachieving an 89.46$\\%$ recall and an 85.09$\\%$ precision rate, demonstrating\nits significant capability in accurately identifying exoplanetary transits.\nDespite using under-sampling techniques to address class imbalance, dataset\nsize reduction remains a limitation. This study underscores the importance of\nfurther research into optimizing model architectures to enhance automation,\nperformance, and generalization of the model.", "AI": {"tldr": "A machine learning approach using Vision Transformer (ViT) with transformed light curve data (GAFs and RPs) improves exoplanet classification, achieving high recall and precision, though dataset size is a limitation.", "motivation": "Traditional exoplanet classification methods are resource-intensive, necessitating efficient machine learning solutions.", "method": "Transform Kepler mission light curves into GAFs and RPs, then classify using ViT, evaluated via 5-fold cross-validation.", "result": "ViT with RPs achieves 89.46% recall and 85.09% precision, outperforming GAFs.", "conclusion": "The study highlights ViT's potential for exoplanet classification but calls for further research to optimize models and address dataset limitations."}}
{"id": "2506.17035", "pdf": "https://arxiv.org/pdf/2506.17035", "abs": "https://arxiv.org/abs/2506.17035", "authors": ["Jo\u00e3o Matos", "Ben Van Calster", "Leo Anthony Celi", "Paula Dhiman", "Judy Wawira Gichoya", "Richard D. Riley", "Chris Russell", "Sara Khalid", "Gary S. Collins"], "title": "Critical Appraisal of Fairness Metrics in Clinical Predictive AI", "categories": ["cs.LG"], "comment": "32 pages, 1 figure, 2 tables, 5 boxes, 4 linked supplementary\n  materials", "summary": "Predictive artificial intelligence (AI) offers an opportunity to improve\nclinical practice and patient outcomes, but risks perpetuating biases if\nfairness is inadequately addressed. However, the definition of \"fairness\"\nremains unclear. We conducted a scoping review to identify and critically\nappraise fairness metrics for clinical predictive AI. We defined a \"fairness\nmetric\" as a measure quantifying whether a model discriminates (societally)\nagainst individuals or groups defined by sensitive attributes. We searched five\ndatabases (2014-2024), screening 820 records, to include 41 studies, and\nextracted 62 fairness metrics. Metrics were classified by\nperformance-dependency, model output level, and base performance metric,\nrevealing a fragmented landscape with limited clinical validation and\noverreliance on threshold-dependent measures. Eighteen metrics were explicitly\ndeveloped for healthcare, including only one clinical utility metric. Our\nfindings highlight conceptual challenges in defining and quantifying fairness\nand identify gaps in uncertainty quantification, intersectionality, and\nreal-world applicability. Future work should prioritise clinically meaningful\nmetrics.", "AI": {"tldr": "A scoping review identified 62 fairness metrics for clinical predictive AI, revealing fragmentation, limited validation, and gaps in clinical relevance and real-world applicability.", "motivation": "To address the unclear definition of fairness in AI and its risks of perpetuating biases in clinical practice.", "method": "Conducted a scoping review of five databases (2014-2024), screening 820 records to include 41 studies and extract 62 fairness metrics. Metrics were classified by performance-dependency, model output level, and base performance metric.", "result": "Found a fragmented landscape with limited clinical validation, overreliance on threshold-dependent measures, and only one clinical utility metric among 18 healthcare-specific metrics.", "conclusion": "Highlights conceptual challenges in fairness definition and gaps in uncertainty quantification, intersectionality, and real-world applicability, urging prioritization of clinically meaningful metrics."}}
{"id": "2506.17103", "pdf": "https://arxiv.org/pdf/2506.17103", "abs": "https://arxiv.org/abs/2506.17103", "authors": ["Shruti Sadanand Dongare", "Amun Kharel", "Jonathan Samuel", "Xiaona Zhou"], "title": "TransDreamerV3: Implanting Transformer In DreamerV3", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "This paper introduces TransDreamerV3, a reinforcement learning model that\nenhances the DreamerV3 architecture by integrating a transformer encoder. The\nmodel is designed to improve memory and decision-making capabilities in complex\nenvironments. We conducted experiments on Atari-Boxing, Atari-Freeway,\nAtari-Pong, and Crafter tasks, where TransDreamerV3 demonstrated improved\nperformance over DreamerV3, particularly in the Atari-Freeway and Crafter\ntasks. While issues in the Minecraft task and limited training across all tasks\nwere noted, TransDreamerV3 displays advancement in world model-based\nreinforcement learning, leveraging transformer architectures.", "AI": {"tldr": "TransDreamerV3, an enhanced DreamerV3 with a transformer encoder, improves memory and decision-making in complex tasks like Atari and Crafter, though it faces challenges in Minecraft.", "motivation": "To enhance DreamerV3's capabilities by integrating a transformer encoder for better memory and decision-making in complex environments.", "method": "Integrates a transformer encoder into the DreamerV3 architecture and tests it on Atari-Boxing, Atari-Freeway, Atari-Pong, and Crafter tasks.", "result": "Outperforms DreamerV3, especially in Atari-Freeway and Crafter, but struggles with Minecraft and limited training.", "conclusion": "TransDreamerV3 advances world model-based RL using transformers, despite some limitations."}}
{"id": "2503.16031", "pdf": "https://arxiv.org/pdf/2503.16031", "abs": "https://arxiv.org/abs/2503.16031", "authors": ["Sai Kartheek Reddy Kasu", "Shankar Biradar", "Sunil Saumya"], "title": "Deceptive Humor: A Synthetic Multilingual Benchmark Dataset for Bridging Fabricated Claims with Humorous Content", "categories": ["cs.CL"], "comment": "7 Pages, 2 figures, 7 tables", "summary": "In the evolving landscape of online discourse, misinformation increasingly\nadopts humorous tones to evade detection and gain traction. This work\nintroduces Deceptive Humor as a novel research direction, emphasizing how false\nnarratives, when coated in humor, can become more difficult to detect and more\nlikely to spread. To support research in this space, we present the Deceptive\nHumor Dataset (DHD) a collection of humor-infused comments derived from\nfabricated claims using the ChatGPT-4o model. Each entry is labeled with a\nSatire Level (from 1 for subtle satire to 3 for overt satire) and categorized\ninto five humor types: Dark Humor, Irony, Social Commentary, Wordplay, and\nAbsurdity. The dataset spans English, Telugu, Hindi, Kannada, Tamil, and their\ncode-mixed forms, making it a valuable resource for multilingual analysis. DHD\noffers a structured foundation for understanding how humor can serve as a\nvehicle for the propagation of misinformation, subtly enhancing its reach and\nimpact. Strong baselines are established to encourage further research and\nmodel development in this emerging area.", "AI": {"tldr": "The paper introduces Deceptive Humor, a method where misinformation uses humor to evade detection, and presents the Deceptive Humor Dataset (DHD) for research.", "motivation": "To study how humor-coated misinformation spreads and evades detection, highlighting the need for tools to analyze this phenomenon.", "method": "Creation of the DHD dataset with humor-infused comments labeled by Satire Level and humor type, spanning multiple languages.", "result": "DHD provides a structured resource for analyzing humor's role in misinformation, with established baselines for future research.", "conclusion": "The work underscores the subtle impact of humor in spreading misinformation and encourages further research in this area."}}
{"id": "2506.16627", "pdf": "https://arxiv.org/pdf/2506.16627", "abs": "https://arxiv.org/abs/2506.16627", "authors": ["Haotian Yin", "Aleksander Plocharski", "Michal Jan Wlodarczyk", "Mikolaj Kida", "Przemyslaw Musialski"], "title": "FlatCAD: Fast Curvature Regularization of Neural SDFs for CAD Models", "categories": ["cs.GR", "cs.CV", "cs.LG", "65D18, 68U05, 68T07, 53A07", "I.3.5; I.3.7; I.2.6"], "comment": "12 page, 10 figures, preprint", "summary": "Neural signed-distance fields (SDFs) have become a versatile backbone for\ngeometric learning, yet enforcing developable, CAD-style behavior still hinges\non Gaussian curvature penalties that require full Hessian evaluation and\nsecond-order automatic differentiation, both of which are costly in memory and\nruntime. We present a curvature proxy that regularizes only the mixed\nsecond-order term (Weingarten term), allowing the two principal curvatures to\nadapt freely to data while suppressing unwanted warp. Two complementary\ninstantiations realize this idea: (i) a finite-difference proxy that replaces\neach Hessian entry with four forward SDF evaluations and a single first-order\ngradient, and (ii) an autodiff proxy that computes the same mixed derivative\nvia one Hessian-vector product, sidestepping explicit full Hessian assembly and\nremaining faster in practice. Both variants converge to the exact mixed second\nderivative, thus preserving the intended geometric bias without incurring full\nsecond-order graphs. On the ABC benchmarks, the proxies match or exceed the\nreconstruction fidelity of Hessian-based baselines while reducing GPU memory\nuse and wall-clock time by a factor of two. Because the method is drop-in and\nframework-agnostic, it opens a practical path toward scalable, curvature-aware\nSDF learning for engineering-grade shape reconstruction.", "AI": {"tldr": "A new curvature proxy method for neural SDFs reduces computational costs while maintaining accuracy, enabling scalable CAD-style shape reconstruction.", "motivation": "Traditional methods for enforcing developable behavior in neural SDFs rely on costly Gaussian curvature penalties involving full Hessian evaluation and second-order autodiff.", "method": "Proposes two proxies: (i) a finite-difference proxy using four SDF evaluations and a gradient, and (ii) an autodiff proxy using a Hessian-vector product, both avoiding full Hessian assembly.", "result": "On ABC benchmarks, the proxies match or exceed baseline fidelity while halving GPU memory and runtime.", "conclusion": "The method offers a practical, scalable solution for curvature-aware SDF learning in engineering-grade shape reconstruction."}}
{"id": "2506.17047", "pdf": "https://arxiv.org/pdf/2506.17047", "abs": "https://arxiv.org/abs/2506.17047", "authors": ["Haolin Liu", "Adrien Siproudhis", "Samuel Experton", "Peter Lorenz", "Christina Boura", "Thomas Peyrin"], "title": "Navigating the Deep: Signature Extraction on Deep Neural Networks", "categories": ["cs.LG", "cs.CR"], "comment": "26 pages", "summary": "Neural network model extraction has emerged in recent years as an important\nsecurity concern, as adversaries attempt to recover a network's parameters via\nblack-box queries. A key step in this process is signature extraction, which\naims to recover the absolute values of the network's weights layer by layer.\nPrior work, notably by Carlini et al. (2020), introduced a technique inspired\nby differential cryptanalysis to extract neural network parameters. However,\ntheir method suffers from several limitations that restrict its applicability\nto networks with a few layers only. Later works focused on improving sign\nextraction, but largely relied on the assumption that signature extraction\nitself was feasible.\n  In this work, we revisit and refine the signature extraction process by\nsystematically identifying and addressing for the first time critical\nlimitations of Carlini et al.'s signature extraction method. These limitations\ninclude rank deficiency and noise propagation from deeper layers. To overcome\nthese challenges, we propose efficient algorithmic solutions for each of the\nidentified issues, greatly improving the efficiency of signature extraction.\nOur approach permits the extraction of much deeper networks than was previously\npossible. We validate our method through extensive experiments on ReLU-based\nneural networks, demonstrating significant improvements in extraction depth and\naccuracy. For instance, our extracted network matches the target network on at\nleast 95% of the input space for each of the eight layers of a neural network\ntrained on the CIFAR-10 dataset, while previous works could barely extract the\nfirst three layers. Our results represent a crucial step toward practical\nattacks on larger and more complex neural network architectures.", "AI": {"tldr": "This paper refines neural network signature extraction, addressing limitations of prior methods to enable deeper network extraction with higher accuracy.", "motivation": "Neural network model extraction is a security concern, but prior methods like Carlini et al.'s suffer from limitations (e.g., rank deficiency, noise propagation) restricting their applicability to shallow networks.", "method": "The authors systematically identify and address these limitations, proposing efficient algorithmic solutions to improve signature extraction for deeper networks.", "result": "Experiments on ReLU-based networks show significant improvements, with successful extraction of eight layers (95% accuracy on CIFAR-10), surpassing prior work's three-layer limit.", "conclusion": "The refined method advances practical attacks on deeper and more complex neural networks, marking a crucial step in neural network security research."}}
{"id": "2506.17128", "pdf": "https://arxiv.org/pdf/2506.17128", "abs": "https://arxiv.org/abs/2506.17128", "authors": ["Botao Zhu", "Xianbin Wang"], "title": "Rapid and Continuous Trust Evaluation for Effective Task Collaboration Through Siamese Model", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Trust is emerging as an effective tool to ensure the successful completion of\ncollaborative tasks within collaborative systems. However, rapidly and\ncontinuously evaluating the trustworthiness of collaborators during task\nexecution is a significant challenge due to distributed devices, complex\noperational environments, and dynamically changing resources. To tackle this\nchallenge, this paper proposes a Siamese-enabled rapid and continuous trust\nevaluation framework (SRCTE) to facilitate effective task collaboration. First,\nthe communication and computing resource attributes of the collaborator in a\ntrusted state, along with historical collaboration data, are collected and\nrepresented using an attributed control flow graph (ACFG) that captures\ntrust-related semantic information and serves as a reference for comparison\nwith data collected during task execution. At each time slot of task execution,\nthe collaborator's communication and computing resource attributes, as well as\ntask completion effectiveness, are collected in real time and represented with\nan ACFG to convey their trust-related semantic information. A Siamese model,\nconsisting of two shared-parameter Structure2vec networks, is then employed to\nlearn the deep semantics of each pair of ACFGs and generate their embeddings.\nFinally, the similarity between the embeddings of each pair of ACFGs is\ncalculated to determine the collaborator's trust value at each time slot. A\nreal system is built using two Dell EMC 5200 servers and a Google Pixel 8 to\ntest the effectiveness of the proposed SRCTE framework. Experimental results\ndemonstrate that SRCTE converges rapidly with only a small amount of data and\nachieves a high anomaly trust detection rate compared to the baseline\nalgorithm.", "AI": {"tldr": "The paper proposes a Siamese-enabled rapid and continuous trust evaluation framework (SRCTE) for collaborative systems, using ACFGs and a Siamese model to assess trustworthiness dynamically.", "motivation": "Trust evaluation in collaborative systems is challenging due to distributed devices, dynamic environments, and changing resources.", "method": "Uses ACFGs to represent trust-related data and a Siamese model (Structure2vec networks) to compare embeddings for trust evaluation.", "result": "SRCTE converges quickly with minimal data and achieves high anomaly detection rates compared to baselines.", "conclusion": "The SRCTE framework effectively addresses dynamic trust evaluation in collaborative systems."}}
{"id": "2504.05154", "pdf": "https://arxiv.org/pdf/2504.05154", "abs": "https://arxiv.org/abs/2504.05154", "authors": ["Geyang Guo", "Tarek Naous", "Hiromi Wakaki", "Yukiko Nishimura", "Yuki Mitsufuji", "Alan Ritter", "Wei Xu"], "title": "CARE: Assessing the Impact of Multilingual Human Preference Learning on Cultural Awareness", "categories": ["cs.CL"], "comment": "28 pages", "summary": "Language Models (LMs) are typically tuned with human preferences to produce\nhelpful responses, but the impact of preference tuning on the ability to handle\nculturally diverse queries remains understudied. In this paper, we\nsystematically analyze how native human cultural preferences can be\nincorporated into the preference learning process to train more culturally\naware LMs. We introduce CARE, a multilingual resource containing 3,490\nculturally specific questions and 31.7k responses with native judgments. We\ndemonstrate how a modest amount of high-quality native preferences improves\ncultural awareness across various LMs, outperforming larger generic preference\ndata. Our analyses reveal that models with stronger initial cultural\nperformance benefit more from alignment, leading to gaps among models developed\nin different regions with varying access to culturally relevant data. CARE will\nbe made publicly available at https://github.com/Guochry/CARE.", "AI": {"tldr": "The paper introduces CARE, a multilingual resource to enhance cultural awareness in Language Models (LMs) by incorporating native human cultural preferences, showing improved performance over generic data.", "motivation": "To address the understudied impact of preference tuning on LMs' ability to handle culturally diverse queries.", "method": "Introduces CARE, a resource with 3,490 culturally specific questions and 31.7k responses, used to train culturally aware LMs.", "result": "Modest high-quality native preferences improve cultural awareness in LMs, outperforming larger generic datasets. Models with stronger initial cultural performance benefit more.", "conclusion": "CARE enhances cultural awareness in LMs, highlighting disparities in model performance based on regional data access. The resource will be publicly available."}}
{"id": "2506.16652", "pdf": "https://arxiv.org/pdf/2506.16652", "abs": "https://arxiv.org/abs/2506.16652", "authors": ["Guang Yin", "Yitong Li", "Yixuan Wang", "Dale McConachie", "Paarth Shah", "Kunimatsu Hashimoto", "Huan Zhang", "Katherine Liu", "Yunzhu Li"], "title": "CodeDiffuser: Attention-Enhanced Diffusion Policy via VLM-Generated Code for Instruction Ambiguity", "categories": ["cs.RO", "cs.CV", "cs.LG", "cs.SE"], "comment": "Accepted to Robotics: Science and Systems (RSS) 2025. The first three\n  authors contributed equally. Project Page:\n  https://robopil.github.io/code-diffuser/", "summary": "Natural language instructions for robotic manipulation tasks often exhibit\nambiguity and vagueness. For instance, the instruction \"Hang a mug on the mug\ntree\" may involve multiple valid actions if there are several mugs and branches\nto choose from. Existing language-conditioned policies typically rely on\nend-to-end models that jointly handle high-level semantic understanding and\nlow-level action generation, which can result in suboptimal performance due to\ntheir lack of modularity and interpretability. To address these challenges, we\nintroduce a novel robotic manipulation framework that can accomplish tasks\nspecified by potentially ambiguous natural language. This framework employs a\nVision-Language Model (VLM) to interpret abstract concepts in natural language\ninstructions and generates task-specific code - an interpretable and executable\nintermediate representation. The generated code interfaces with the perception\nmodule to produce 3D attention maps that highlight task-relevant regions by\nintegrating spatial and semantic information, effectively resolving ambiguities\nin instructions. Through extensive experiments, we identify key limitations of\ncurrent imitation learning methods, such as poor adaptation to language and\nenvironmental variations. We show that our approach excels across challenging\nmanipulation tasks involving language ambiguity, contact-rich manipulation, and\nmulti-object interactions.", "AI": {"tldr": "A framework using Vision-Language Models (VLMs) to interpret ambiguous natural language instructions for robotic manipulation, generating executable code and 3D attention maps to resolve ambiguities.", "motivation": "Address ambiguity and vagueness in natural language instructions for robotic tasks, overcoming limitations of end-to-end models lacking modularity and interpretability.", "method": "Uses a VLM to interpret instructions and generate task-specific code, interfacing with perception to produce 3D attention maps integrating spatial and semantic information.", "result": "Outperforms in tasks with language ambiguity, contact-rich manipulation, and multi-object interactions, highlighting limitations of current imitation learning methods.", "conclusion": "The framework effectively resolves ambiguities in instructions and improves robotic manipulation performance, offering modularity and interpretability."}}
{"id": "2506.17067", "pdf": "https://arxiv.org/pdf/2506.17067", "abs": "https://arxiv.org/abs/2506.17067", "authors": ["Zhuo Xu", "Tianyue Zheng", "Linglong Dai"], "title": "Empowering Near-Field Communications in Low-Altitude Economy with LLM: Fundamentals, Potentials, Solutions, and Future Directions", "categories": ["eess.SP", "cs.IT", "cs.LG", "math.IT"], "comment": null, "summary": "The low-altitude economy (LAE) is gaining significant attention from academia\nand industry. Fortunately, LAE naturally aligns with near-field communications\nin extremely large-scale MIMO (XL-MIMO) systems. By leveraging near-field\nbeamfocusing, LAE can precisely direct beam energy to unmanned aerial vehicles,\nwhile the additional distance dimension boosts overall spectrum efficiency.\nHowever, near-field communications in LAE still face several challenges, such\nas the increase in signal processing complexity and the necessity of\ndistinguishing between far and near-field users. Inspired by the large language\nmodels (LLM) with powerful ability to handle complex problems, we apply LLM to\nsolve challenges of near-field communications in LAE. The objective of this\narticle is to provide a comprehensive analysis and discussion on LLM-empowered\nnear-field communications in LAE. Specifically, we first introduce fundamentals\nof LLM and near-field communications, including the key advantages of LLM and\nkey characteristics of near-field communications. Then, we reveal the\nopportunities and challenges of near-field communications in LAE. To address\nthese challenges, we present a LLM-based scheme for near-field communications\nin LAE, and provide a case study which jointly distinguishes far and near-field\nusers and designs multi-user precoding matrix. Finally, we outline and\nhighlight several future research directions and open issues.", "AI": {"tldr": "The paper explores using large language models (LLMs) to address challenges in near-field communications for low-altitude economy (LAE) systems, proposing a scheme for user distinction and precoding.", "motivation": "LAE aligns with near-field communications in XL-MIMO, but faces challenges like signal complexity and user distinction. LLMs offer a solution due to their problem-solving capabilities.", "method": "Introduces LLM fundamentals and near-field communication characteristics, then proposes an LLM-based scheme for user distinction and precoding in LAE.", "result": "A case study demonstrates the scheme's effectiveness in distinguishing users and designing precoding matrices.", "conclusion": "The paper highlights future research directions for LLM-empowered near-field communications in LAE."}}
{"id": "2506.17139", "pdf": "https://arxiv.org/pdf/2506.17139", "abs": "https://arxiv.org/abs/2506.17139", "authors": ["Michael Plainer", "Hao Wu", "Leon Klein", "Stephan G\u00fcnnemann", "Frank No\u00e9"], "title": "Consistent Sampling and Simulation: Molecular Dynamics with Energy-Based Diffusion Models", "categories": ["cs.LG", "cs.AI", "physics.chem-ph", "physics.comp-ph", "stat.ML"], "comment": null, "summary": "Diffusion models have recently gained significant attention due to their\neffectiveness in various scientific domains, including biochemistry. When\ntrained on equilibrium molecular distributions, diffusion models provide both:\na generative procedure to sample equilibrium conformations and associated\nforces derived from the model's scores. However, using the forces for\ncoarse-grained molecular dynamics simulations uncovers inconsistencies in the\nsamples generated via classical diffusion inference and simulation, despite\nboth originating from the same model. Particularly at the small diffusion\ntimesteps required for simulations, diffusion models fail to satisfy the\nFokker-Planck equation, which governs how the score should evolve over time. We\ninterpret this deviation as an indication of the observed inconsistencies and\npropose an energy-based diffusion model with a Fokker-Planck-derived\nregularization term enforcing consistency. We demonstrate the effectiveness of\nour approach on toy systems, alanine dipeptide, and introduce a\nstate-of-the-art transferable Boltzmann emulator for dipeptides that supports\nsimulation and demonstrates enhanced consistency and efficient sampling.", "AI": {"tldr": "Diffusion models trained on equilibrium molecular distributions show inconsistencies in generated samples and forces, especially at small timesteps. A new energy-based model with Fokker-Planck regularization improves consistency and sampling.", "motivation": "Address inconsistencies in diffusion models for molecular dynamics, particularly at small timesteps, where they fail to satisfy the Fokker-Planck equation.", "method": "Propose an energy-based diffusion model with a Fokker-Planck-derived regularization term to enforce consistency.", "result": "Demonstrated effectiveness on toy systems and alanine dipeptide, introducing a state-of-the-art transferable Boltzmann emulator for dipeptides.", "conclusion": "The proposed model enhances consistency and sampling efficiency, addressing limitations of classical diffusion inference."}}
{"id": "2504.07385", "pdf": "https://arxiv.org/pdf/2504.07385", "abs": "https://arxiv.org/abs/2504.07385", "authors": ["Sher Badshah", "Ali Emami", "Hassan Sajjad"], "title": "TALE: A Tool-Augmented Framework for Reference-Free Evaluation of Large Language Models", "categories": ["cs.CL", "cs.AI", "I.2.7"], "comment": null, "summary": "As Large Language Models (LLMs) become increasingly integrated into\nreal-world, autonomous applications, relying on static, pre-annotated\nreferences for evaluation poses significant challenges in cost, scalability,\nand completeness. We propose Tool-Augmented LLM Evaluation (TALE), a framework\nto assess LLM outputs without predetermined ground-truth answers. Unlike\nconventional metrics that compare to fixed references or depend solely on\nLLM-as-a-judge knowledge, TALE employs an agent with tool-access capabilities\nthat actively retrieves and synthesizes external evidence. It iteratively\ngenerates web queries, collects information, summarizes findings, and refines\nsubsequent searches through reflection. By shifting away from static\nreferences, TALE aligns with free-form question-answering tasks common in\nreal-world scenarios. Experimental results on multiple free-form QA benchmarks\nshow that TALE not only outperforms standard reference-based metrics for\nmeasuring response accuracy but also achieves substantial to near-perfect\nagreement with human evaluations. TALE enhances the reliability of LLM\nevaluations in real-world, dynamic scenarios without relying on static\nreferences.", "AI": {"tldr": "TALE is a tool-augmented framework for evaluating LLM outputs without static references, using dynamic evidence retrieval and synthesis.", "motivation": "Static references for LLM evaluation are costly, unscalable, and incomplete, limiting real-world applicability.", "method": "TALE employs an agent with tool-access to iteratively retrieve, synthesize, and refine external evidence for evaluation.", "result": "TALE outperforms reference-based metrics and aligns closely with human evaluations on free-form QA benchmarks.", "conclusion": "TALE enhances LLM evaluation reliability in dynamic, real-world scenarios by eliminating dependency on static references."}}
{"id": "2506.16827", "pdf": "https://arxiv.org/pdf/2506.16827", "abs": "https://arxiv.org/abs/2506.16827", "authors": ["Grzegorz Gruszczynski", "Michal Jan Wlodarczyk", "Jakub J Meixner", "Przemyslaw Musialski"], "title": "Beyond Blur: A Fluid Perspective on Generative Diffusion Models", "categories": ["cs.GR", "cs.CV", "cs.LG", "I.2.6; I.4.10; I.4.8"], "comment": "11 pages, 8 figures, pre-print, supplementary pseudocode in appendix", "summary": "We propose a novel PDE-driven corruption process for generative image\nsynthesis based on advection-diffusion processes which generalizes existing\nPDE-based approaches. Our forward pass formulates image corruption via a\nphysically motivated PDE that couples directional advection with isotropic\ndiffusion and Gaussian noise, controlled by dimensionless numbers (Peclet,\nFourier). We implement this PDE numerically through a GPU-accelerated custom\nLattice Boltzmann solver for fast evaluation. To induce realistic turbulence,\nwe generate stochastic velocity fields that introduce coherent motion and\ncapture multi-scale mixing. In the generative process, a neural network learns\nto reverse the advection-diffusion operator thus constituting a novel\ngenerative model. We discuss how previous methods emerge as specific cases of\nour operator, demonstrating that our framework generalizes prior PDE-based\ncorruption techniques. We illustrate how advection improves the diversity and\nquality of the generated images while keeping the overall color palette\nunaffected. This work bridges fluid dynamics, dimensionless PDE theory, and\ndeep generative modeling, offering a fresh perspective on physically informed\nimage corruption processes for diffusion-based synthesis.", "AI": {"tldr": "A novel PDE-driven corruption process for generative image synthesis using advection-diffusion, generalizing existing PDE-based methods.", "motivation": "To bridge fluid dynamics and deep generative modeling by introducing a physically motivated PDE for image corruption, improving diversity and quality in generated images.", "method": "Formulates corruption via a PDE combining advection, diffusion, and noise, implemented with a GPU-accelerated Lattice Boltzmann solver. A neural network reverses the process for generation.", "result": "Generalizes prior PDE-based techniques, enhances image diversity and quality without altering color palettes.", "conclusion": "The framework offers a fresh, physics-informed approach to image corruption in diffusion-based synthesis."}}
{"id": "2506.17155", "pdf": "https://arxiv.org/pdf/2506.17155", "abs": "https://arxiv.org/abs/2506.17155", "authors": ["Samin Yeasar Arnob", "Scott Fujimoto", "Doina Precup"], "title": "Sparse-Reg: Improving Sample Complexity in Offline Reinforcement Learning using Sparsity", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "In this paper, we investigate the use of small datasets in the context of\noffline reinforcement learning (RL). While many common offline RL benchmarks\nemploy datasets with over a million data points, many offline RL applications\nrely on considerably smaller datasets. We show that offline RL algorithms can\noverfit on small datasets, resulting in poor performance. To address this\nchallenge, we introduce \"Sparse-Reg\": a regularization technique based on\nsparsity to mitigate overfitting in offline reinforcement learning, enabling\neffective learning in limited data settings and outperforming state-of-the-art\nbaselines in continuous control.", "AI": {"tldr": "The paper explores offline RL with small datasets, introduces 'Sparse-Reg' to prevent overfitting, and shows improved performance in limited data settings.", "motivation": "Many offline RL applications use small datasets, but existing benchmarks focus on large datasets, leading to overfitting issues.", "method": "Introduces 'Sparse-Reg', a sparsity-based regularization technique for offline RL.", "result": "Outperforms state-of-the-art baselines in continuous control tasks.", "conclusion": "Sparse-Reg effectively mitigates overfitting in small dataset offline RL, enabling better performance."}}
{"id": "2506.17169", "pdf": "https://arxiv.org/pdf/2506.17169", "abs": "https://arxiv.org/abs/2506.17169", "authors": ["Denis Larionov", "Nikolay Bazenkov", "Mikhail Kiselev"], "title": "Continual Learning with Columnar Spiking Neural Networks", "categories": ["cs.NE", "cs.AI"], "comment": "12 pages, 3 figures", "summary": "This study investigates columnar-organized spiking neural networks (SNNs) for\ncontinual learning and catastrophic forgetting. Using CoLaNET (Columnar Layered\nNetwork), we show that microcolumns adapt most efficiently to new tasks when\nthey lack shared structure with prior learning. We demonstrate how CoLaNET\nhyperparameters govern the trade-off between retaining old knowledge\n(stability) and acquiring new information (plasticity). Our optimal\nconfiguration learns ten sequential MNIST tasks effectively, maintaining 92%\naccuracy on each. It shows low forgetting, with only 4% performance degradation\non the first task after training on nine subsequent tasks.", "AI": {"tldr": "CoLaNET, a columnar-organized SNN, effectively balances stability and plasticity in continual learning, achieving 92% accuracy on sequential MNIST tasks with minimal forgetting.", "motivation": "To address catastrophic forgetting in continual learning using columnar-organized SNNs.", "method": "Utilizes CoLaNET with microcolumns that adapt efficiently to new tasks when lacking shared prior structure. Hyperparameters balance stability and plasticity.", "result": "Optimal configuration achieves 92% accuracy per task and only 4% degradation on the first task after nine subsequent tasks.", "conclusion": "CoLaNET demonstrates efficient continual learning with low forgetting, highlighting the role of hyperparameters in stability-plasticity trade-offs."}}
{"id": "2504.21625", "pdf": "https://arxiv.org/pdf/2504.21625", "abs": "https://arxiv.org/abs/2504.21625", "authors": ["Jiaming Wang", "Yunke Zhao", "Peng Ding", "Jun Kuang", "Zongyu Wang", "Xuezhi Cao", "Xunliang Cai"], "title": "Ask, Fail, Repeat: Meeseeks, an Iterative Feedback Benchmark for LLMs' Multi-turn Instruction-Following Ability", "categories": ["cs.CL"], "comment": null, "summary": "The ability to follow instructions accurately is fundamental for Large\nLanguage Models (LLMs) to serve as reliable agents in real-world applications.\nFor complex instructions, LLMs often struggle to fulfill all requirements in a\nsingle attempt. In practice, users typically provide iterative feedback until\nthe LLM generates a response that meets all requirements. However, existing\ninstruction-following benchmarks are either single-turn or introduce new\nrequirements in each turn without allowing self-correction. To address this\ngap, we propose Meeseeks. Meeseeks simulates realistic human-LLM interactions\nthrough an iterative feedback framework, which enables models to self-correct\nbased on specific requirement failures in each turn, better reflecting\nreal-world user-end usage patterns. Meanwhile, the benchmark implements a\ncomprehensive evaluation system with 38 capability tags organized across three\ndimensions: Intent Recognition, Granular Content Validation, and Output\nStructure Validation. Through rigorous evaluation across LLMs, Meeseeks\nprovides valuable insights into LLMs' instruction-following capabilities in\nmulti-turn scenarios.", "AI": {"tldr": "Meeseeks is a benchmark for evaluating LLMs' ability to follow multi-turn instructions with iterative feedback, addressing gaps in existing benchmarks.", "motivation": "Existing benchmarks for LLMs' instruction-following are single-turn or lack self-correction, failing to reflect real-world iterative feedback scenarios.", "method": "Meeseeks introduces an iterative feedback framework simulating human-LLM interactions, allowing models to self-correct based on requirement failures. It includes a 38-tag evaluation system across three dimensions.", "result": "Meeseeks provides insights into LLMs' instruction-following in multi-turn scenarios, highlighting their capabilities and limitations.", "conclusion": "Meeseeks fills a critical gap in evaluating LLMs' iterative instruction-following, offering a realistic and comprehensive benchmark for real-world applications."}}
{"id": "2506.17110", "pdf": "https://arxiv.org/pdf/2506.17110", "abs": "https://arxiv.org/abs/2506.17110", "authors": ["Teng Guo", "Baichuan Huang", "Jingjin Yu"], "title": "Monocular One-Shot Metric-Depth Alignment for RGB-Based Robot Grasping", "categories": ["cs.RO", "cs.CV"], "comment": "Accepted to IROS 2025", "summary": "Accurate 6D object pose estimation is a prerequisite for successfully\ncompleting robotic prehensile and non-prehensile manipulation tasks. At\npresent, 6D pose estimation for robotic manipulation generally relies on depth\nsensors based on, e.g., structured light, time-of-flight, and stereo-vision,\nwhich can be expensive, produce noisy output (as compared with RGB cameras),\nand fail to handle transparent objects. On the other hand, state-of-the-art\nmonocular depth estimation models (MDEMs) provide only affine-invariant depths\nup to an unknown scale and shift. Metric MDEMs achieve some successful\nzero-shot results on public datasets, but fail to generalize. We propose a\nnovel framework, Monocular One-shot Metric-depth Alignment (MOMA), to recover\nmetric depth from a single RGB image, through a one-shot adaptation building on\nMDEM techniques. MOMA performs scale-rotation-shift alignments during camera\ncalibration, guided by sparse ground-truth depth points, enabling accurate\ndepth estimation without additional data collection or model retraining on the\ntesting setup. MOMA supports fine-tuning the MDEM on transparent objects,\ndemonstrating strong generalization capabilities. Real-world experiments on\ntabletop 2-finger grasping and suction-based bin-picking applications show MOMA\nachieves high success rates in diverse tasks, confirming its effectiveness.", "AI": {"tldr": "MOMA is a framework for accurate metric depth estimation from a single RGB image, addressing limitations of current depth sensors and MDEMs.", "motivation": "Current depth sensors are expensive and noisy, while MDEMs lack metric accuracy. MOMA aims to provide a cost-effective, accurate solution.", "method": "MOMA uses one-shot adaptation with scale-rotation-shift alignments during calibration, guided by sparse ground-truth depth points.", "result": "MOMA achieves high success rates in real-world robotic tasks like grasping and bin-picking.", "conclusion": "MOMA effectively generalizes and improves depth estimation for robotic manipulation without additional data or retraining."}}
{"id": "2506.17171", "pdf": "https://arxiv.org/pdf/2506.17171", "abs": "https://arxiv.org/abs/2506.17171", "authors": ["Vitalii Bondar", "Vira Babenko", "Roman Trembovetskyi", "Yurii Korobeinyk", "Viktoriya Dzyuba"], "title": "Deep generative models as the probability transformation functions", "categories": ["cs.LG", "68T07"], "comment": "12 pages, 6 figures, accepted for publication in \"ICIST 2025 Springer\n  Proceedings\"", "summary": "This paper introduces a unified theoretical perspective that views deep\ngenerative models as probability transformation functions. Despite the apparent\ndifferences in architecture and training methodologies among various types of\ngenerative models - autoencoders, autoregressive models, generative adversarial\nnetworks, normalizing flows, diffusion models, and flow matching - we\ndemonstrate that they all fundamentally operate by transforming simple\npredefined distributions into complex target data distributions. This unifying\nperspective facilitates the transfer of methodological improvements between\nmodel architectures and provides a foundation for developing universal\ntheoretical approaches, potentially leading to more efficient and effective\ngenerative modeling techniques.", "AI": {"tldr": "A unified view of deep generative models as probability transformation functions, showing commonality across diverse architectures.", "motivation": "To bridge the apparent differences in generative model architectures and training methods by identifying their shared underlying principle.", "method": "Analyzes various generative models (autoencoders, autoregressive models, GANs, normalizing flows, diffusion models, flow matching) as transformations of simple distributions into complex data distributions.", "result": "Demonstrates that all these models fundamentally perform probability transformations, enabling methodological cross-pollination.", "conclusion": "This unified perspective supports theoretical advancements and more efficient generative modeling techniques."}}
{"id": "2506.17204", "pdf": "https://arxiv.org/pdf/2506.17204", "abs": "https://arxiv.org/abs/2506.17204", "authors": ["Guozheng Ma", "Lu Li", "Zilin Wang", "Li Shen", "Pierre-Luc Bacon", "Dacheng Tao"], "title": "Network Sparsity Unlocks the Scaling Potential of Deep Reinforcement Learning", "categories": ["cs.LG", "cs.AI"], "comment": "Accepted to ICML 2025", "summary": "Effectively scaling up deep reinforcement learning models has proven\nnotoriously difficult due to network pathologies during training, motivating\nvarious targeted interventions such as periodic reset and architectural\nadvances such as layer normalization. Instead of pursuing more complex\nmodifications, we show that introducing static network sparsity alone can\nunlock further scaling potential beyond their dense counterparts with\nstate-of-the-art architectures. This is achieved through simple one-shot random\npruning, where a predetermined percentage of network weights are randomly\nremoved once before training. Our analysis reveals that, in contrast to naively\nscaling up dense DRL networks, such sparse networks achieve both higher\nparameter efficiency for network expressivity and stronger resistance to\noptimization challenges like plasticity loss and gradient interference. We\nfurther extend our evaluation to visual and streaming RL scenarios,\ndemonstrating the consistent benefits of network sparsity.", "AI": {"tldr": "Introducing static network sparsity via one-shot random pruning improves scaling in deep reinforcement learning, outperforming dense networks in efficiency and optimization resistance.", "motivation": "Scaling deep reinforcement learning is challenging due to training pathologies, prompting the need for simpler solutions beyond complex interventions.", "method": "One-shot random pruning removes a fixed percentage of network weights before training, creating sparse networks.", "result": "Sparse networks achieve higher parameter efficiency and better resistance to optimization issues like plasticity loss and gradient interference.", "conclusion": "Network sparsity is a simple yet effective method to enhance scaling in deep reinforcement learning, with consistent benefits across various scenarios."}}
{"id": "2505.02819", "pdf": "https://arxiv.org/pdf/2505.02819", "abs": "https://arxiv.org/abs/2505.02819", "authors": ["Dmitriy Shopkhoev", "Ammar Ali", "Magauiya Zhussip", "Valentin Malykh", "Stamatios Lefkimmiatis", "Nikos Komodakis", "Sergey Zagoruyko"], "title": "ReplaceMe: Network Simplification via Depth Pruning and Transformer Block Linearization", "categories": ["cs.CL"], "comment": null, "summary": "We introduce ReplaceMe, a generalized training-free depth pruning method that\neffectively replaces transformer blocks with a linear operation, while\nmaintaining high performance for low compression ratios. In contrast to\nconventional pruning approaches that require additional training or\nfine-tuning, our approach requires only a small calibration dataset that is\nused to estimate a linear transformation, which approximates the pruned blocks.\nThe estimated linear mapping can be seamlessly merged with the remaining\ntransformer blocks, eliminating the need for any additional network parameters.\nOur experiments show that ReplaceMe consistently outperforms other\ntraining-free approaches and remains highly competitive with state-of-the-art\npruning methods that involve extensive retraining/fine-tuning and architectural\nmodifications. Applied to several large language models (LLMs), ReplaceMe\nachieves up to 25% pruning while retaining approximately 90% of the original\nmodel's performance on open benchmarks - without any training or healing steps,\nresulting in minimal computational overhead (see Fig.1). We provide an\nopen-source library implementing ReplaceMe alongside several state-of-the-art\ndepth pruning techniques, available at https://github.com/mts-ai/ReplaceMe.", "AI": {"tldr": "ReplaceMe is a training-free depth pruning method for transformers, replacing blocks with linear operations while maintaining performance, outperforming other training-free methods and competing with retraining-based approaches.", "motivation": "To simplify pruning in transformers without requiring additional training or fine-tuning, reducing computational overhead.", "method": "Uses a small calibration dataset to estimate a linear transformation approximating pruned blocks, seamlessly merging it with remaining blocks.", "result": "Achieves up to 25% pruning with ~90% performance retention on LLMs, outperforming training-free methods and competing with retraining-based ones.", "conclusion": "ReplaceMe offers efficient, training-free pruning with minimal overhead, demonstrated by strong performance on LLMs."}}
{"id": "2506.17198", "pdf": "https://arxiv.org/pdf/2506.17198", "abs": "https://arxiv.org/abs/2506.17198", "authors": ["Jianglong Ye", "Keyi Wang", "Chengjing Yuan", "Ruihan Yang", "Yiquan Li", "Jiyue Zhu", "Yuzhe Qin", "Xueyan Zou", "Xiaolong Wang"], "title": "Dex1B: Learning with 1B Demonstrations for Dexterous Manipulation", "categories": ["cs.RO", "cs.CV"], "comment": "Accepted to RSS 2025. Project page: https://jianglongye.com/dex1b", "summary": "Generating large-scale demonstrations for dexterous hand manipulation remains\nchallenging, and several approaches have been proposed in recent years to\naddress this. Among them, generative models have emerged as a promising\nparadigm, enabling the efficient creation of diverse and physically plausible\ndemonstrations. In this paper, we introduce Dex1B, a large-scale, diverse, and\nhigh-quality demonstration dataset produced with generative models. The dataset\ncontains one billion demonstrations for two fundamental tasks: grasping and\narticulation. To construct it, we propose a generative model that integrates\ngeometric constraints to improve feasibility and applies additional conditions\nto enhance diversity. We validate the model on both established and newly\nintroduced simulation benchmarks, where it significantly outperforms prior\nstate-of-the-art methods. Furthermore, we demonstrate its effectiveness and\nrobustness through real-world robot experiments. Our project page is at\nhttps://jianglongye.com/dex1b", "AI": {"tldr": "Dex1B is a large-scale dataset of one billion demonstrations for dexterous hand manipulation tasks, generated using a novel generative model with geometric constraints and diversity conditions.", "motivation": "Creating large-scale, diverse, and physically plausible demonstrations for dexterous hand manipulation is challenging, and generative models offer a promising solution.", "method": "A generative model integrates geometric constraints for feasibility and additional conditions for diversity to produce the Dex1B dataset.", "result": "The model outperforms prior methods on simulation benchmarks and shows effectiveness in real-world robot experiments.", "conclusion": "Dex1B advances dexterous manipulation by providing a high-quality, scalable dataset, validated in simulations and real-world applications."}}
{"id": "2506.17182", "pdf": "https://arxiv.org/pdf/2506.17182", "abs": "https://arxiv.org/abs/2506.17182", "authors": ["Yuli Slavutsky", "Ozgur Beker", "David Blei", "Bianca Dumitrascu"], "title": "Variational Learning of Disentangled Representations", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "Disentangled representations enable models to separate factors of variation\nthat are shared across experimental conditions from those that are\ncondition-specific. This separation is essential in domains such as biomedical\ndata analysis, where generalization to new treatments, patients, or species\ndepends on isolating stable biological signals from context-dependent effects.\nWhile extensions of the variational autoencoder (VAE) framework have been\nproposed to address this problem, they frequently suffer from leakage between\nlatent representations, limiting their ability to generalize to unseen\nconditions. Here, we introduce DISCoVeR, a new variational framework that\nexplicitly separates condition-invariant and condition-specific factors.\nDISCoVeR integrates three key components: (i) a dual-latent architecture that\nmodels shared and specific factors separately; (ii) two parallel\nreconstructions that ensure both representations remain informative; and (iii)\na novel max-min objective that encourages clean separation without relying on\nhandcrafted priors, while making only minimal assumptions. Theoretically, we\nshow that this objective maximizes data likelihood while promoting\ndisentanglement, and that it admits a unique equilibrium. Empirically, we\ndemonstrate that DISCoVeR achieves improved disentanglement on synthetic\ndatasets, natural images, and single-cell RNA-seq data. Together, these results\nestablish DISCoVeR as a principled approach for learning disentangled\nrepresentations in multi-condition settings.", "AI": {"tldr": "DISCoVeR is a new variational framework for disentangling condition-invariant and condition-specific factors in data, improving generalization in multi-condition settings.", "motivation": "To address leakage in latent representations of existing VAE extensions, which limits generalization to unseen conditions in domains like biomedical data analysis.", "method": "Introduces DISCoVeR with a dual-latent architecture, parallel reconstructions, and a max-min objective for clean separation without handcrafted priors.", "result": "Achieves improved disentanglement on synthetic datasets, natural images, and single-cell RNA-seq data.", "conclusion": "DISCoVeR is a principled approach for learning disentangled representations in multi-condition settings."}}
{"id": "2506.17219", "pdf": "https://arxiv.org/pdf/2506.17219", "abs": "https://arxiv.org/abs/2506.17219", "authors": ["Yanzhi Zhang", "Zhaoxi Zhang", "Haoxiang Guan", "Yilin Cheng", "Yitong Duan", "Chen Wang", "Yue Wang", "Shuxin Zheng", "Jiyan He"], "title": "No Free Lunch: Rethinking Internal Feedback for LLM Reasoning", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Reinforcement learning has emerged as a powerful paradigm for post-training\nlarge language models (LLMs) to improve reasoning. Approaches like\nReinforcement Learning from Human Feedback (RLHF) and Reinforcement Learning\nwith Verifiable Rewards (RLVR) have shown strong results, but they require\nextensive external supervision. We investigate an alternative class of methods,\nReinforcement Learning from Internal Feedback (RLIF), which relies solely on\nintrinsic model-derived signals instead of external rewards. In particular, we\nleverage unsupervised reward proxies such as token-level entropy,\ntrajectory-level entropy, and self-certainty. Our theoretical analysis shows\nthese internal objectives are partially equivalent, and we empirically evaluate\nvarious RLIF strategies on challenging math reasoning benchmarks. Experimental\nresults demonstrate that RLIF can boost the reasoning performance of base LLMs\nat the beginning phase of the training, matching or surpassing RLVR techniques\non these tasks. However, when training progresses, performance degrades even\nbelow the model before training. Moreover, we find that RLIF yields little\nimprovement for instruction-tuned models, indicating diminishing returns of\nintrinsic feedback once an LLM is already instruction-tuned. We further analyze\nthis limitation by mixing model weights and explain the reason of RLIF's\ntraining behaviors, providing practical guidelines for integrating internal\nfeedback signals into LLM training. We hope our analysis of internal feedback\nwill inform more principled and effective strategies for LLM post-training.", "AI": {"tldr": "RLIF (Reinforcement Learning from Internal Feedback) uses intrinsic signals like token-level entropy to improve LLM reasoning, matching RLVR early but degrading later, especially for instruction-tuned models.", "motivation": "To explore alternatives to externally supervised RL methods (RLHF, RLVR) by leveraging intrinsic model-derived signals for LLM post-training.", "method": "Proposes RLIF, using unsupervised reward proxies (token-level entropy, trajectory-level entropy, self-certainty) and evaluates on math reasoning benchmarks.", "result": "RLIF boosts reasoning early but degrades later, underperforming pre-training levels. It shows minimal improvement for instruction-tuned models.", "conclusion": "RLIF has early promise but limitations, suggesting careful integration of internal feedback signals for effective LLM post-training."}}
{"id": "2505.07796", "pdf": "https://arxiv.org/pdf/2505.07796", "abs": "https://arxiv.org/abs/2505.07796", "authors": ["Xingjin Wang", "Howe Tissue", "Lu Wang", "Linjing Li", "Daniel Dajun Zeng"], "title": "Learning Dynamics in Continual Pre-Training for Large Language Models", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "Accepted to ICML2025 (Oral)", "summary": "Continual Pre-Training (CPT) has become a popular and effective method to\napply strong foundation models to specific downstream tasks. In this work, we\nexplore the learning dynamics throughout the CPT process for large language\nmodels. We specifically focus on how general and downstream domain performance\nevolves at each training step, with domain performance measured via validation\nlosses. We have observed that the CPT loss curve fundamentally characterizes\nthe transition from one curve to another hidden curve, and could be described\nby decoupling the effects of distribution shift and learning rate annealing. We\nderive a CPT scaling law that combines the two factors, enabling the prediction\nof loss at any (continual) training steps and across learning rate schedules\n(LRS) in CPT. Our formulation presents a comprehensive understanding of several\ncritical factors in CPT, including loss potential, peak learning rate, training\nsteps, replay ratio, etc. Moreover, our approach can be adapted to customize\ntraining hyper-parameters to different CPT goals such as balancing general and\ndomain-specific performance. Extensive experiments demonstrate that our scaling\nlaw holds across various CPT datasets and training hyper-parameters.", "AI": {"tldr": "The paper explores learning dynamics in Continual Pre-Training (CPT) for large language models, focusing on performance evolution and loss curves. It introduces a scaling law to predict loss and optimize hyper-parameters.", "motivation": "To understand how general and domain-specific performance evolves during CPT and to derive a predictive scaling law for loss and hyper-parameter optimization.", "method": "Analyzes CPT loss curves, decouples distribution shift and learning rate annealing effects, and derives a scaling law combining these factors.", "result": "The scaling law accurately predicts loss across training steps and learning rate schedules, validated by extensive experiments.", "conclusion": "The proposed scaling law provides a comprehensive framework for optimizing CPT, balancing general and domain-specific performance."}}
{"id": "2506.17206", "pdf": "https://arxiv.org/pdf/2506.17206", "abs": "https://arxiv.org/abs/2506.17206", "authors": ["Yukun Huang", "Yanning Zhou", "Jianan Wang", "Kaiyi Huang", "Xihui Liu"], "title": "DreamCube: 3D Panorama Generation via Multi-plane Synchronization", "categories": ["cs.GR", "cs.CV", "cs.LG"], "comment": "Project page: https://yukun-huang.github.io/DreamCube/", "summary": "3D panorama synthesis is a promising yet challenging task that demands\nhigh-quality and diverse visual appearance and geometry of the generated\nomnidirectional content. Existing methods leverage rich image priors from\npre-trained 2D foundation models to circumvent the scarcity of 3D panoramic\ndata, but the incompatibility between 3D panoramas and 2D single views limits\ntheir effectiveness. In this work, we demonstrate that by applying multi-plane\nsynchronization to the operators from 2D foundation models, their capabilities\ncan be seamlessly extended to the omnidirectional domain. Based on this design,\nwe further introduce DreamCube, a multi-plane RGB-D diffusion model for 3D\npanorama generation, which maximizes the reuse of 2D foundation model priors to\nachieve diverse appearances and accurate geometry while maintaining multi-view\nconsistency. Extensive experiments demonstrate the effectiveness of our\napproach in panoramic image generation, panoramic depth estimation, and 3D\nscene generation.", "AI": {"tldr": "DreamCube extends 2D foundation models to 3D panorama generation using multi-plane synchronization, achieving diverse and accurate results.", "motivation": "The scarcity of 3D panoramic data and incompatibility between 3D panoramas and 2D single views limit existing methods.", "method": "Applies multi-plane synchronization to 2D foundation models and introduces DreamCube, a multi-plane RGB-D diffusion model.", "result": "Effective in panoramic image generation, depth estimation, and 3D scene generation.", "conclusion": "DreamCube successfully leverages 2D priors for high-quality 3D panorama synthesis."}}
{"id": "2506.17187", "pdf": "https://arxiv.org/pdf/2506.17187", "abs": "https://arxiv.org/abs/2506.17187", "authors": ["Kanumuri Nithin Varma", "Babak Hassibi"], "title": "Optimal Implicit Bias in Linear Regression", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "Most modern learning problems are over-parameterized, where the number of\nlearnable parameters is much greater than the number of training data points.\nIn this over-parameterized regime, the training loss typically has infinitely\nmany global optima that completely interpolate the data with varying\ngeneralization performance. The particular global optimum we converge to\ndepends on the implicit bias of the optimization algorithm. The question we\naddress in this paper is, ``What is the implicit bias that leads to the best\ngeneralization performance?\". To find the optimal implicit bias, we provide a\nprecise asymptotic analysis of the generalization performance of interpolators\nobtained from the minimization of convex functions/potentials for\nover-parameterized linear regression with non-isotropic Gaussian data. In\nparticular, we obtain a tight lower bound on the best generalization error\npossible among this class of interpolators in terms of the\nover-parameterization ratio, the variance of the noise in the labels, the\neigenspectrum of the data covariance, and the underlying distribution of the\nparameter to be estimated. Finally, we find the optimal convex implicit bias\nthat achieves this lower bound under certain sufficient conditions involving\nthe log-concavity of the distribution of a Gaussian convolved with the prior of\nthe true underlying parameter.", "AI": {"tldr": "The paper analyzes the implicit bias in over-parameterized linear regression, identifying the optimal bias for best generalization performance under specific conditions.", "motivation": "To determine the implicit bias that yields the best generalization performance in over-parameterized learning problems.", "method": "Asymptotic analysis of generalization performance for interpolators from convex potential minimization in non-isotropic Gaussian data settings.", "result": "A tight lower bound on the best generalization error is derived, and the optimal convex implicit bias achieving this bound is identified under log-concavity conditions.", "conclusion": "The study provides insights into the optimal implicit bias for generalization in over-parameterized linear regression, with potential applications in improving learning algorithms."}}
{"id": "2403.04311", "pdf": "https://arxiv.org/pdf/2403.04311", "abs": "https://arxiv.org/abs/2403.04311", "authors": ["Deepti Raghavan", "Keshav Santhanam", "Muhammad Shahir Rahman", "Nayani Modugula", "Luis Gaspar Schroeder", "Maximilien Cura", "Houjun Liu", "Pratiksha Thaker", "Philip Levis", "Matei Zaharia"], "title": "Alto: Orchestrating Distributed Compound AI Systems with Nested Ancestry", "categories": ["cs.AI", "cs.CL", "cs.DC", "cs.IR"], "comment": null, "summary": "Compound AI applications chain together subcomponents such as generative\nlanguage models, document retrievers, and embedding models. Applying\ntraditional systems optimizations such as parallelism and pipelining in\ncompound AI systems is difficult because each component has different\nconstraints in terms of the granularity and type of data that it ingests. New\ndata is often generated during intermediate computations, and text streams may\nbe split into smaller, independent fragments (such as documents to sentences)\nwhich may then be re-aggregated at later parts of the computation. Due to this\ncomplexity, existing systems to serve compound AI queries do not fully take\nadvantage of parallelism and pipelining opportunities.\n  We present Alto, a framework that automatically optimizes execution of\ncompound AI queries through streaming and parallelism. Bento introduces a new\nabstraction called nested ancestry, a metadata hierarchy that allows the system\nto correctly track partial outputs and aggregate data across the heterogeneous\nconstraints of the components of compound AI applications. This metadata is\nautomatically inferred from the programming model, allowing developers to\nexpress complex dataflow patterns without needing to reason manually about the\ndetails of routing and aggregation. Implementations of four applications in\nAlto outperform or match implementations in LangGraph, a popular existing AI\nprogramming framework. Alto implementations match or improve latency by between\n10-30%.", "AI": {"tldr": "Alto is a framework optimizing compound AI queries with streaming and parallelism, using nested ancestry for metadata tracking, improving latency by 10-30%.", "motivation": "Existing systems struggle with parallelism and pipelining in compound AI due to heterogeneous component constraints and dynamic data generation.", "method": "Alto introduces nested ancestry, a metadata hierarchy for tracking and aggregating data across components, inferred automatically from the programming model.", "result": "Alto implementations outperform or match LangGraph, reducing latency by 10-30% in four applications.", "conclusion": "Alto effectively optimizes compound AI queries, simplifying complex dataflow patterns for developers."}}
{"id": "2505.07968", "pdf": "https://arxiv.org/pdf/2505.07968", "abs": "https://arxiv.org/abs/2505.07968", "authors": ["Weiyi Wu", "Xinwen Xu", "Chongyang Gao", "Xingjian Diao", "Siting Li", "Lucas A. Salas", "Jiang Gui"], "title": "Assessing and Mitigating Medical Knowledge Drift and Conflicts in Large Language Models", "categories": ["cs.CL"], "comment": null, "summary": "Large Language Models (LLMs) have great potential in the field of health\ncare, yet they face great challenges in adapting to rapidly evolving medical\nknowledge. This can lead to outdated or contradictory treatment suggestions.\nThis study investigated how LLMs respond to evolving clinical guidelines,\nfocusing on concept drift and internal inconsistencies. We developed the\nDriftMedQA benchmark to simulate guideline evolution and assessed the temporal\nreliability of various LLMs. Our evaluation of seven state-of-the-art models\nacross 4,290 scenarios demonstrated difficulties in rejecting outdated\nrecommendations and frequently endorsing conflicting guidance. Additionally, we\nexplored two mitigation strategies: Retrieval-Augmented Generation and\npreference fine-tuning via Direct Preference Optimization. While each method\nimproved model performance, their combination led to the most consistent and\nreliable results. These findings underscore the need to improve LLM robustness\nto temporal shifts to ensure more dependable applications in clinical practice.\nThe dataset is available at https://huggingface.co/datasets/RDBH/DriftMed.", "AI": {"tldr": "The study examines how LLMs handle evolving medical guidelines, revealing challenges like outdated recommendations and inconsistencies. It introduces DriftMedQA for testing and proposes mitigation strategies.", "motivation": "To address the challenges LLMs face in adapting to rapidly changing medical knowledge, ensuring reliable healthcare applications.", "method": "Developed the DriftMedQA benchmark to simulate guideline evolution, evaluated seven LLMs, and tested mitigation strategies like Retrieval-Augmented Generation and Direct Preference Optimization.", "result": "LLMs struggled with outdated and conflicting recommendations. Mitigation strategies improved performance, with combined methods yielding the best results.", "conclusion": "Enhancing LLM robustness to temporal shifts is crucial for dependable clinical use. The DriftMedQA dataset supports further research."}}
{"id": "2009.06364", "pdf": "https://arxiv.org/pdf/2009.06364", "abs": "https://arxiv.org/abs/2009.06364", "authors": ["Patrick Wenzel", "Rui Wang", "Nan Yang", "Qing Cheng", "Qadeer Khan", "Lukas von Stumberg", "Niclas Zeller", "Daniel Cremers"], "title": "4Seasons: A Cross-Season Dataset for Multi-Weather SLAM in Autonomous Driving", "categories": ["cs.CV"], "comment": "German Conference on Pattern Recognition (GCPR 2020)", "summary": "We present a novel dataset covering seasonal and challenging perceptual\nconditions for autonomous driving. Among others, it enables research on visual\nodometry, global place recognition, and map-based re-localization tracking. The\ndata was collected in different scenarios and under a wide variety of weather\nconditions and illuminations, including day and night. This resulted in more\nthan 350 km of recordings in nine different environments ranging from\nmulti-level parking garage over urban (including tunnels) to countryside and\nhighway. We provide globally consistent reference poses with up-to centimeter\naccuracy obtained from the fusion of direct stereo visual-inertial odometry\nwith RTK-GNSS. The full dataset is available at\nhttps://go.vision.in.tum.de/4seasons.", "AI": {"tldr": "A novel dataset for autonomous driving research, covering diverse seasonal and perceptual conditions, with 350+ km of recordings in varied environments and accurate reference poses.", "motivation": "To address the lack of datasets that cover challenging perceptual conditions (e.g., weather, illumination) for autonomous driving tasks like visual odometry and place recognition.", "method": "Data collection in nine environments (urban, countryside, highway, etc.) under varied conditions, using stereo visual-inertial odometry fused with RTK-GNSS for centimeter-accurate reference poses.", "result": "A comprehensive dataset with 350+ km of recordings, supporting research in visual odometry, place recognition, and re-localization.", "conclusion": "The dataset fills a gap in autonomous driving research by providing diverse and challenging conditions, enabling robust algorithm development."}}
{"id": "2506.17211", "pdf": "https://arxiv.org/pdf/2506.17211", "abs": "https://arxiv.org/abs/2506.17211", "authors": ["Xuechen Zhang", "Zijian Huang", "Yingcong Li", "Chenshun Ni", "Jiasi Chen", "Samet Oymak"], "title": "BREAD: Branched Rollouts from Expert Anchors Bridge SFT & RL for Reasoning", "categories": ["cs.LG"], "comment": null, "summary": "Small language models (SLMs) struggle to learn complex reasoning behaviors,\nespecially when high-quality traces are scarce or difficult to learn from. The\nstandard training approach combines a supervised fine-tuning (SFT) stage, often\nto distill capabilities of a larger model, followed by a reinforcement learning\n(RL)stage such as Group Relative Policy Optimization (GRPO). In this paper, we\ninvestigate the fundamental limitations of this SFT + RL paradigm and propose\nmethods to overcome them. Under a suitable theoretical model, we demonstrate\nthat the SFT + RL strategy can fail completely when (1) the expert's traces are\ntoo difficult for the small model to express, or (2) the small model's\ninitialization has exponentially small likelihood of success. To address these,\nwe introduce BREAD: a GRPO variant that unifies the SFT and RL stages via\npartial expert guidance and branched rollouts. When self-generated traces fail,\nBREAD adaptively inserts short expert prefixes/hints, allowing the small model\nto complete the rest of the reasoning path, and ensuring that each update\nincludes at least one successful trace. This mechanism both densifies the\nreward signal and induces a natural learning curriculum. BREAD requires fewer\nthan 40% of ground-truth traces, consistently outperforming standard GRPO while\nspeeding up the training by about 3 times. Importantly, we demonstrate that\nBREAD helps the model solve problems that are otherwise unsolvable by the SFT +\nRL strategy, highlighting how branched rollouts and expert guidance can\nsubstantially boost SLM reasoning.", "AI": {"tldr": "BREAD, a GRPO variant, improves small language model reasoning by unifying SFT and RL stages with expert guidance and branched rollouts, outperforming standard methods.", "motivation": "Small language models (SLMs) struggle with complex reasoning due to limitations in the SFT + RL paradigm, especially when expert traces are hard to express or initialization is poor.", "method": "Introduces BREAD, which combines SFT and RL via partial expert guidance and branched rollouts, inserting expert hints when self-generated traces fail.", "result": "BREAD requires fewer than 40% of ground-truth traces, outperforms GRPO, speeds up training by 3x, and solves problems unsolvable by SFT + RL.", "conclusion": "BREAD's branched rollouts and expert guidance significantly enhance SLM reasoning, overcoming fundamental limitations of the SFT + RL approach."}}
{"id": "2404.10498", "pdf": "https://arxiv.org/pdf/2404.10498", "abs": "https://arxiv.org/abs/2404.10498", "authors": ["Shijing Hu", "Zhihui Lu", "Xin Xu", "Ruijun Deng", "Xin Du", "Qiang Duan"], "title": "LAECIPS: Large Vision Model Assisted Adaptive Edge-Cloud Collaboration for IoT-based Embodied Intelligence System", "categories": ["cs.AI", "cs.CV", "cs.DC"], "comment": null, "summary": "Embodied intelligence (EI) enables manufacturing systems to flexibly\nperceive, reason, adapt, and operate within dynamic shop floor environments. In\nsmart manufacturing, a representative EI scenario is robotic visual inspection,\nwhere industrial robots must accurately inspect components on rapidly changing,\nheterogeneous production lines. This task requires both high inference accuracy\nespecially for uncommon defects and low latency to match production speeds,\ndespite evolving lighting, part geometries, and surface conditions. To meet\nthese needs, we propose LAECIPS, a large vision model-assisted adaptive\nedge-cloud collaboration framework for IoT-based embodied intelligence systems.\nLAECIPS decouples large vision models in the cloud from lightweight models on\nthe edge, enabling plug-and-play model adaptation and continual learning.\nThrough a hard input mining-based inference strategy, LAECIPS routes complex\nand uncertain inspection cases to the cloud while handling routine tasks at the\nedge, achieving both high accuracy and low latency. Experiments conducted on a\nreal-world robotic semantic segmentation system for visual inspection\ndemonstrate significant improvements in accuracy, processing latency, and\ncommunication overhead compared to state-of-the-art methods. LAECIPS provides a\npractical and scalable foundation for embodied intelligence in smart\nmanufacturing, especially in adaptive robotic inspection and quality control\nscenarios.", "AI": {"tldr": "LAECIPS is a framework combining edge-cloud collaboration and large vision models for robotic visual inspection in smart manufacturing, improving accuracy and latency.", "motivation": "The need for high accuracy and low latency in robotic visual inspection for dynamic manufacturing environments.", "method": "LAECIPS decouples large vision models in the cloud from lightweight edge models, using hard input mining to route tasks adaptively.", "result": "Significant improvements in accuracy, latency, and communication overhead compared to state-of-the-art methods.", "conclusion": "LAECIPS offers a scalable solution for embodied intelligence in smart manufacturing, particularly for adaptive inspection and quality control."}}
{"id": "2505.13487", "pdf": "https://arxiv.org/pdf/2505.13487", "abs": "https://arxiv.org/abs/2505.13487", "authors": ["Ashwin Kumar", "Yuzi He", "Aram H. Markosyan", "Bobbie Chern", "Imanol Arrieta-Ibarra"], "title": "Detecting Prefix Bias in LLM-based Reward Models", "categories": ["cs.CL"], "comment": null, "summary": "Reinforcement Learning with Human Feedback (RLHF) has emerged as a key\nparadigm for task-specific fine-tuning of language models using human\npreference data. While numerous publicly available preference datasets provide\npairwise comparisons of responses, the potential for biases in the resulting\nreward models remains underexplored. In this work, we introduce novel methods\nto detect and evaluate prefix bias -- a systematic shift in model preferences\ntriggered by minor variations in query prefixes -- in LLM-based reward models\ntrained on such datasets. We leverage these metrics to reveal significant\nbiases in preference models across racial and gender dimensions. Our\ncomprehensive evaluation spans diverse open-source preference datasets and\nreward model architectures, demonstrating susceptibility to this kind of bias\nregardless of the underlying model architecture. Furthermore, we propose a data\naugmentation strategy to mitigate these biases, showing its effectiveness in\nreducing the impact of prefix bias. Our findings highlight the critical need\nfor bias-aware dataset design and evaluation in developing fair and reliable\nreward models, contributing to the broader discourse on fairness in AI.", "AI": {"tldr": "The paper investigates prefix bias in LLM-based reward models trained on human preference data, revealing biases in racial and gender dimensions. It proposes a data augmentation strategy to mitigate these biases.", "motivation": "To address underexplored biases in reward models derived from human preference datasets, particularly prefix bias triggered by minor query variations.", "method": "Introduces novel methods to detect and evaluate prefix bias, tests these on diverse datasets and reward model architectures, and proposes a data augmentation strategy for mitigation.", "result": "Reveals significant biases in reward models across racial and gender dimensions, showing susceptibility regardless of architecture. The proposed mitigation strategy effectively reduces bias impact.", "conclusion": "Highlights the need for bias-aware dataset design and evaluation to ensure fair and reliable reward models, contributing to fairness in AI."}}
{"id": "2211.05781", "pdf": "https://arxiv.org/pdf/2211.05781", "abs": "https://arxiv.org/abs/2211.05781", "authors": ["Xiaowei Hu", "Min Shi", "Weiyun Wang", "Sitong Wu", "Linjie Xing", "Wenhai Wang", "Xizhou Zhu", "Lewei Lu", "Jie Zhou", "Xiaogang Wang", "Yu Qiao", "Jifeng Dai"], "title": "Demystify Transformers & Convolutions in Modern Image Deep Networks", "categories": ["cs.CV"], "comment": "This paper was accepted to IEEE Transactions on Pattern Analysis and\n  Machine Intelligence (IEEE TPAMI). All models and codes used in this study\n  are publicly available at https://github.com/OpenGVLab/STM-Evaluation", "summary": "Vision transformers have gained popularity recently, leading to the\ndevelopment of new vision backbones with improved features and consistent\nperformance gains. However, these advancements are not solely attributable to\nnovel feature transformation designs; certain benefits also arise from advanced\nnetwork-level and block-level architectures. This paper aims to identify the\nreal gains of popular convolution and attention operators through a detailed\nstudy. We find that the key difference among these feature transformation\nmodules, such as attention or convolution, lies in their spatial feature\naggregation approach, known as the \"spatial token mixer\" (STM). To facilitate\nan impartial comparison, we introduce a unified architecture to neutralize the\nimpact of divergent network-level and block-level designs. Subsequently,\nvarious STMs are integrated into this unified framework for comprehensive\ncomparative analysis. Our experiments on various tasks and an analysis of\ninductive bias show a significant performance boost due to advanced\nnetwork-level and block-level designs, but performance differences persist\namong different STMs. Our detailed analysis also reveals various findings about\ndifferent STMs, including effective receptive fields, invariance, and\nadversarial robustness tests.", "AI": {"tldr": "The paper investigates the performance gains of vision transformers, attributing them to spatial token mixers (STMs) and advanced network/block-level designs. A unified framework is introduced for fair comparison, revealing persistent performance differences among STMs.", "motivation": "To understand the real contributions of convolution and attention operators in vision transformers, beyond novel feature transformations, by focusing on spatial feature aggregation (STMs).", "method": "Introduces a unified architecture to neutralize network/block-level design differences, integrating various STMs for comparative analysis across tasks.", "result": "Advanced network/block-level designs boost performance, but STMs still show differences in effectiveness, receptive fields, invariance, and robustness.", "conclusion": "The study highlights the importance of STMs and advanced designs in vision transformers, providing insights for future architecture improvements."}}
{"id": "2506.15723", "pdf": "https://arxiv.org/pdf/2506.15723", "abs": "https://arxiv.org/abs/2506.15723", "authors": ["Irina G. Tanashkina", "Alexey S. Tanashkin", "Alexander S. Maksimchuik", "Anna Yu. Poshivailo"], "title": "Modern approaches to building effective interpretable models of the property market using machine learning", "categories": ["q-fin.ST", "cs.LG", "econ.GN", "q-fin.EC", "stat.AP"], "comment": "42 pages, 22 figures", "summary": "In this article, we review modern approaches to building interpretable models\nof property markets using machine learning on the base of mass valuation of\nproperty in the Primorye region, Russia. The researcher, lacking expertise in\nthis topic, encounters numerous difficulties in the effort to build a good\nmodel. The main source of this is the huge difference between noisy real market\ndata and ideal data which is very common in all types of tutorials on machine\nlearning. This paper covers all stages of modeling: the collection of initial\ndata, identification of outliers, the search and analysis of patterns in data,\nthe formation and final choice of price factors, the building of the model, and\nthe evaluation of its efficiency. For each stage, we highlight potential issues\nand describe sound methods for overcoming emerging difficulties on actual\nexamples. We show that the combination of classical linear regression with\ninterpolation methods of geostatistics allows to build an effective model for\nland parcels. For flats, when many objects are attributed to one spatial point\nthe application of geostatistical methods is difficult. Therefore we suggest\nlinear regression with automatic generation and selection of additional rules\non the base of decision trees, so called the RuleFit method. Thus we show, that\ndespite the strong restriction as the requirement of interpretability which is\nimportant in practical aspects, for example, legal matters, it is still\npossible to build effective models of real property markets.", "AI": {"tldr": "The paper reviews interpretable machine learning models for property markets in Primorye, Russia, addressing challenges like noisy data and proposing methods like linear regression with geostatistics for land and RuleFit for flats.", "motivation": "To address the gap between noisy real-world property market data and idealized tutorial data, and to build interpretable models for practical legal applications.", "method": "Combines classical linear regression with geostatistics for land parcels and RuleFit (linear regression with decision tree-generated rules) for flats.", "result": "Demonstrates effective interpretable models for property markets despite data challenges.", "conclusion": "Interpretable models are feasible for real property markets, balancing effectiveness and legal practicality."}}
{"id": "2405.04300", "pdf": "https://arxiv.org/pdf/2405.04300", "abs": "https://arxiv.org/abs/2405.04300", "authors": ["Mustafa F Abdelwahed", "Joan Espasa", "Alice Toniolo", "Ian P. Gent"], "title": "Behaviour Planning: A Toolkit for Diverse Planning", "categories": ["cs.AI"], "comment": null, "summary": "Diverse planning approaches are utilised in real-world applications like risk\nmanagement, automated streamed data analysis, and malware detection. The\ncurrent diverse planning formulations encode the diversity model as a distance\nfunction, which is computational inexpensive when comparing two plans. However,\nsuch modelling approach limits what can be encoded as measure of diversity, as\nwell as the ability to explain why two plans are different. This paper\nintroduces a novel approach to the diverse planning problem, allowing for more\nexpressive modelling of diversity using a n-dimensional grid representation,\nwhere each dimension corresponds to a user-defined feature. Furthermore, we\npresent a novel toolkit that generates diverse plans based on such customisable\ndiversity models, called \\emph{Behaviour Planning}. We provide an\nimplementation for behaviour planning using planning-as-satisfiability. An\nempirical evaluation of our implementation shows that behaviour planning\nsignificantly outperforms the current diverse planning method in generating\ndiverse plans measured on our new customisable diversity models. Our\nimplementation is the first diverse planning approach to support planning\ncategories beyond classical planning, such as over-subscription and numerical\nplanning.", "AI": {"tldr": "The paper introduces a novel approach to diverse planning using an n-dimensional grid for expressive diversity modeling and a toolkit called Behaviour Planning, outperforming current methods.", "motivation": "Current diverse planning methods are limited in encoding diversity and explaining plan differences.", "method": "Proposes an n-dimensional grid representation for diversity and a toolkit (Behaviour Planning) using planning-as-satisfiability.", "result": "Empirical evaluation shows Behaviour Planning outperforms current methods in generating diverse plans.", "conclusion": "The approach supports broader planning categories and offers customizable diversity models."}}
{"id": "2505.14015", "pdf": "https://arxiv.org/pdf/2505.14015", "abs": "https://arxiv.org/abs/2505.14015", "authors": ["Tai D. Nguyen", "Long H. Pham", "Jun Sun"], "title": "AUTOLAW: Enhancing Legal Compliance in Large Language Models via Case Law Generation and Jury-Inspired Deliberation", "categories": ["cs.CL"], "comment": null, "summary": "The rapid advancement of domain-specific large language models (LLMs) in\nfields like law necessitates frameworks that account for nuanced regional legal\ndistinctions, which are critical for ensuring compliance and trustworthiness.\nExisting legal evaluation benchmarks often lack adaptability and fail to\naddress diverse local contexts, limiting their utility in dynamically evolving\nregulatory landscapes. To address these gaps, we propose AutoLaw, a novel\nviolation detection framework that combines adversarial data generation with a\njury-inspired deliberation process to enhance legal compliance of LLMs. Unlike\nstatic approaches, AutoLaw dynamically synthesizes case law to reflect local\nregulations and employs a pool of LLM-based \"jurors\" to simulate judicial\ndecision-making. Jurors are ranked and selected based on synthesized legal\nexpertise, enabling a deliberation process that minimizes bias and improves\ndetection accuracy. Evaluations across three benchmarks: Law-SG, Case-SG\n(legality), and Unfair-TOS (policy), demonstrate AutoLaw's effectiveness:\nadversarial data generation improves LLM discrimination, while the jury-based\nvoting strategy significantly boosts violation detection rates. Our results\nhighlight the framework's ability to adaptively probe legal misalignments and\ndeliver reliable, context-aware judgments, offering a scalable solution for\nevaluating and enhancing LLMs in legally sensitive applications.", "AI": {"tldr": "AutoLaw is a dynamic legal violation detection framework for LLMs, combining adversarial data generation and jury-inspired deliberation to improve compliance and accuracy in diverse legal contexts.", "motivation": "Existing legal evaluation benchmarks lack adaptability and fail to address regional legal nuances, limiting their utility in evolving regulatory landscapes.", "method": "AutoLaw uses adversarial data generation and a jury-inspired deliberation process with ranked LLM-based jurors to simulate judicial decision-making.", "result": "AutoLaw improves LLM discrimination and boosts violation detection rates across benchmarks (Law-SG, Case-SG, Unfair-TOS).", "conclusion": "AutoLaw offers a scalable, context-aware solution for evaluating and enhancing LLMs in legally sensitive applications."}}
{"id": "2301.01147", "pdf": "https://arxiv.org/pdf/2301.01147", "abs": "https://arxiv.org/abs/2301.01147", "authors": ["Patrick Wenzel", "Nan Yang", "Rui Wang", "Niclas Zeller", "Daniel Cremers"], "title": "4Seasons: Benchmarking Visual SLAM and Long-Term Localization for Autonomous Driving in Challenging Conditions", "categories": ["cs.CV"], "comment": "Published in International Journal of Computer Vision (IJCV). arXiv\n  admin note: substantial text overlap with arXiv:2009.06364", "summary": "In this paper, we present a novel visual SLAM and long-term localization\nbenchmark for autonomous driving in challenging conditions based on the\nlarge-scale 4Seasons dataset. The proposed benchmark provides drastic\nappearance variations caused by seasonal changes and diverse weather and\nillumination conditions. While significant progress has been made in advancing\nvisual SLAM on small-scale datasets with similar conditions, there is still a\nlack of unified benchmarks representative of real-world scenarios for\nautonomous driving. We introduce a new unified benchmark for jointly evaluating\nvisual odometry, global place recognition, and map-based visual localization\nperformance which is crucial to successfully enable autonomous driving in any\ncondition. The data has been collected for more than one year, resulting in\nmore than 300 km of recordings in nine different environments ranging from a\nmulti-level parking garage to urban (including tunnels) to countryside and\nhighway. We provide globally consistent reference poses with up to\ncentimeter-level accuracy obtained from the fusion of direct stereo-inertial\nodometry with RTK GNSS. We evaluate the performance of several state-of-the-art\nvisual odometry and visual localization baseline approaches on the benchmark\nand analyze their properties. The experimental results provide new insights\ninto current approaches and show promising potential for future research. Our\nbenchmark and evaluation protocols will be available at\nhttps://go.vision.in.tum.de/4seasons.", "AI": {"tldr": "A new visual SLAM and long-term localization benchmark for autonomous driving, based on the 4Seasons dataset, addresses appearance variations from seasonal and weather changes, offering a unified evaluation for visual odometry, place recognition, and localization.", "motivation": "Current benchmarks lack representation of real-world autonomous driving scenarios with diverse conditions. The 4Seasons dataset fills this gap by providing data with seasonal, weather, and illumination variations.", "method": "The benchmark uses a large-scale dataset (300+ km, nine environments) with centimeter-level accurate reference poses from stereo-inertial odometry and RTK GNSS fusion. It evaluates state-of-the-art visual odometry and localization methods.", "result": "Evaluation of baseline approaches reveals insights into current methods and highlights potential for future research.", "conclusion": "The benchmark is a valuable resource for advancing autonomous driving research in challenging conditions, with data and protocols publicly available."}}
{"id": "2506.15743", "pdf": "https://arxiv.org/pdf/2506.15743", "abs": "https://arxiv.org/abs/2506.15743", "authors": ["Tobias Grafke"], "title": "Sampling conditioned diffusions via Pathspace Projected Monte Carlo", "categories": ["stat.ML", "cs.LG", "math.PR", "math.ST", "stat.TH"], "comment": null, "summary": "We present an algorithm to sample stochastic differential equations\nconditioned on rather general constraints, including integral constraints,\nendpoint constraints, and stochastic integral constraints. The algorithm is a\npathspace Metropolis-adjusted manifold sampling scheme, which samples\nstochastic paths on the submanifold of realizations that adhere to the\nconditioning constraint. We demonstrate the effectiveness of the algorithm by\nsampling a dynamical condensation phase transition, conditioning a random walk\non a fixed Levy stochastic area, conditioning a stochastic nonlinear wave\nequation on high amplitude waves, and sampling a stochastic partial\ndifferential equation model of turbulent pipe flow conditioned on\nrelaminarization events.", "AI": {"tldr": "An algorithm for sampling stochastic differential equations under general constraints, using a pathspace Metropolis-adjusted manifold sampling scheme.", "motivation": "To address the challenge of sampling stochastic paths that adhere to various constraints (integral, endpoint, stochastic integral).", "method": "Pathspace Metropolis-adjusted manifold sampling to sample paths on the submanifold of realizations meeting constraints.", "result": "Effective sampling demonstrated in diverse scenarios, including dynamical condensation, random walks, stochastic nonlinear waves, and turbulent pipe flow.", "conclusion": "The algorithm successfully samples constrained stochastic differential equations, proving versatile across multiple applications."}}
{"id": "2405.04443", "pdf": "https://arxiv.org/pdf/2405.04443", "abs": "https://arxiv.org/abs/2405.04443", "authors": ["Simon Werner", "Katharina Christ", "Laura Bernardy", "Marion G. M\u00fcller", "Achim Rettinger"], "title": "POV Learning: Individual Alignment of Multimodal Models using Human Perception", "categories": ["cs.AI"], "comment": null, "summary": "Aligning machine learning systems with human expectations is mostly attempted\nby training with manually vetted human behavioral samples, typically explicit\nfeedback. This is done on a population level since the context that is\ncapturing the subjective Point-Of-View (POV) of a concrete person in a specific\nsituational context is not retained in the data. However, we argue that\nalignment on an individual level can boost the subjective predictive\nperformance for the individual user interacting with the system considerably.\nSince perception differs for each person, the same situation is observed\ndifferently. Consequently, the basis for decision making and the subsequent\nreasoning processes and observable reactions differ. We hypothesize that\nindividual perception patterns can be used for improving the alignment on an\nindividual level. We test this, by integrating perception information into\nmachine learning systems and measuring their predictive performance\nwrt.~individual subjective assessments. For our empirical study, we collect a\nnovel data set of multimodal stimuli and corresponding eye tracking sequences\nfor the novel task of Perception-Guided Crossmodal Entailment and tackle it\nwith our Perception-Guided Multimodal Transformer. Our findings suggest that\nexploiting individual perception signals for the machine learning of subjective\nhuman assessments provides a valuable cue for individual alignment. It does not\nonly improve the overall predictive performance from the point-of-view of the\nindividual user but might also contribute to steering AI systems towards every\nperson's individual expectations and values.", "AI": {"tldr": "The paper proposes improving machine learning alignment with individual human expectations by incorporating personal perception patterns, tested via a novel dataset and a Perception-Guided Multimodal Transformer.", "motivation": "Current alignment methods rely on population-level data, missing individual context. The authors argue individual perception can enhance predictive performance for specific users.", "method": "They integrate perception information into ML systems, using a novel dataset of multimodal stimuli and eye-tracking sequences, and develop a Perception-Guided Multimodal Transformer.", "result": "Individual perception signals improve predictive performance from the user's POV and align AI systems with personal expectations.", "conclusion": "Leveraging individual perception aids in better alignment and performance, potentially steering AI toward personalized expectations and values."}}
{"id": "2505.16637", "pdf": "https://arxiv.org/pdf/2505.16637", "abs": "https://arxiv.org/abs/2505.16637", "authors": ["Wenjie Yang", "Mao Zheng", "Mingyang Song", "Zheng Li", "Sitong Wang"], "title": "SSR-Zero: Simple Self-Rewarding Reinforcement Learning for Machine Translation", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "Large language models (LLMs) have recently demonstrated remarkable\ncapabilities in machine translation (MT). However, most advanced MT-specific\nLLMs heavily rely on external supervision signals during training, such as\nhuman-annotated reference data or trained reward models (RMs), which are often\nexpensive to obtain and challenging to scale. To overcome this limitation, we\npropose a Simple Self-Rewarding (SSR) Reinforcement Learning (RL) framework for\nMT that is reference-free, fully online, and relies solely on self-judging\nrewards. Training with SSR using 13K monolingual examples and Qwen-2.5-7B as\nthe backbone, our model SSR-Zero-7B outperforms existing MT-specific LLMs,\ne.g., TowerInstruct-13B and GemmaX-28-9B, as well as larger general LLMs like\nQwen2.5-32B-Instruct in English $\\leftrightarrow$ Chinese translation tasks\nfrom WMT23, WMT24, and Flores200 benchmarks. Furthermore, by augmenting SSR\nwith external supervision from COMET, our strongest model, SSR-X-Zero-7B,\nachieves state-of-the-art performance in English $\\leftrightarrow$ Chinese\ntranslation, surpassing all existing open-source models under 72B parameters\nand even outperforming closed-source models, e.g., GPT-4o and Gemini 1.5 Pro.\nOur analysis highlights the effectiveness of the self-rewarding mechanism\ncompared to the external LLM-as-a-judge approach in MT and demonstrates its\ncomplementary benefits when combined with trained RMs. Our findings provide\nvaluable insight into the potential of self-improving RL methods. We have\npublicly released our code, data and models.", "AI": {"tldr": "The paper introduces a Simple Self-Rewarding (SSR) Reinforcement Learning framework for machine translation, eliminating the need for expensive external supervision. SSR outperforms existing models and achieves state-of-the-art results when combined with COMET.", "motivation": "To address the high cost and scalability issues of external supervision in training advanced MT-specific LLMs.", "method": "Proposes a reference-free, online SSR RL framework using self-judging rewards, trained with 13K monolingual examples and Qwen-2.5-7B.", "result": "SSR-Zero-7B outperforms existing models, and SSR-X-Zero-7B achieves state-of-the-art performance in English-Chinese translation.", "conclusion": "Self-rewarding mechanisms are effective and complementary to external supervision, offering insights into self-improving RL methods."}}
{"id": "2312.06799", "pdf": "https://arxiv.org/pdf/2312.06799", "abs": "https://arxiv.org/abs/2312.06799", "authors": ["Shaobo Xia", "Jun Yue", "Kacper Kania", "Leyuan Fang", "Andrea Tagliasacchi", "Kwang Moo Yi", "Weiwei Sun"], "title": "Weakly Supervised Point Cloud Segmentation via Conservative Propagation of Scene-level Labels", "categories": ["cs.CV", "cs.LG"], "comment": "The first two authors contributed equally; Project website:\n  https://densify-your-labels.github.io/", "summary": "We propose a weakly supervised semantic segmentation method for point clouds\nthat predicts \"per-point\" labels from just \"whole-scene\" annotations. The key\nchallenge here is the discrepancy between the target of dense per-point\nsemantic prediction and training losses derived from only scene-level labels.\nTo address this, in addition to the typical weakly-supervised setup that\nsupervises all points with the scene label, we propose to conservatively\npropagate the scene-level labels to points selectively. Specifically, we\nover-segment point cloud features via unsupervised clustering in the entire\ndataset and form primitives. We then associate scene-level labels with\nprimitives through bipartite matching. Then, we allow labels to pass through\nthis primitive-label relationship, while further encouraging features to form\nnarrow clusters around the primitives. Importantly, through bipartite matching,\nthis additional pathway through which labels flow, only propagates scene labels\nto the most relevant points, reducing the potential negative impact caused by\nthe global approach that existing methods take. We evaluate our method on\nScanNet and S3DIS datasets, outperforming the state of the art by a large\nmargin.", "AI": {"tldr": "A weakly supervised method for semantic segmentation in point clouds uses scene-level labels to predict per-point labels by selectively propagating labels via unsupervised clustering and bipartite matching, outperforming state-of-the-art methods.", "motivation": "Address the challenge of dense per-point semantic prediction with only scene-level labels, reducing negative impacts of global label propagation.", "method": "Over-segment point cloud features via unsupervised clustering, form primitives, associate scene-level labels with primitives through bipartite matching, and encourage narrow feature clusters.", "result": "Outperforms state-of-the-art methods on ScanNet and S3DIS datasets by a large margin.", "conclusion": "The proposed selective label propagation method effectively bridges the gap between scene-level labels and per-point predictions, achieving superior performance."}}
{"id": "2506.15753", "pdf": "https://arxiv.org/pdf/2506.15753", "abs": "https://arxiv.org/abs/2506.15753", "authors": ["Oluwaseyi Giwa", "Muhammad Ahmed Mohsin", "Muhammad Ali Jamshed"], "title": "Quantum Fisher-Preconditioned Reinforcement Learning: From Single-Qubit Control to Rayleigh-Fading Link Adaptation", "categories": ["quant-ph", "cs.LG", "cs.SY", "eess.SY"], "comment": "5 pages, 3 figures, submitted to IEEE Communications Letters", "summary": "In this letter, we propose Quantum-Preconditioned Policy Gradient (QPPG), a\nnatural gradient-based algorithm for link adaptation that whitens policy\nupdates using the full inverse quantum Fisher information with Tikhonov\nregularization. QPPG bridges classical and quantum geometry, achieving stable\nlearning even under noise. Evaluated on classical and quantum environments,\nincluding noisy single-qubit Gym tasks and Rayleigh-fading channels, QPPG\nconverges 4 times faster than REINFORCE and sustains a 1 dB gain under\nuncertainty. It reaches a 90 percent return in one hundred episodes with high\nnoise robustness, showcasing the advantages of full QFI-based preconditioning\nfor scalable quantum reinforcement learning.", "AI": {"tldr": "QPPG is a quantum-enhanced policy gradient algorithm using full inverse quantum Fisher information for stable, noise-robust learning, outperforming REINFORCE in speed and performance.", "motivation": "To bridge classical and quantum geometry for stable reinforcement learning under noise, leveraging quantum Fisher information for better policy updates.", "method": "QPPG whitens policy updates using full inverse quantum Fisher information with Tikhonov regularization, tested on classical and quantum environments.", "result": "Converges 4x faster than REINFORCE, sustains 1 dB gain under uncertainty, and achieves 90% return in 100 episodes with noise robustness.", "conclusion": "QPPG demonstrates scalable quantum reinforcement learning advantages through full QFI-based preconditioning."}}
{"id": "2407.17734", "pdf": "https://arxiv.org/pdf/2407.17734", "abs": "https://arxiv.org/abs/2407.17734", "authors": ["Kaitao Chen", "Mianxin Liu", "Fang Yan", "Lei Ma", "Xiaoming Shi", "Lilong Wang", "Xiaosong Wang", "Lifeng Zhu", "Zhe Wang", "Mu Zhou", "Shaoting Zhang"], "title": "Cost-effective Instruction Learning for Pathology Vision and Language Analysis", "categories": ["cs.AI", "cs.CL", "cs.CV"], "comment": null, "summary": "The advent of vision-language models fosters the interactive conversations\nbetween AI-enabled models and humans. Yet applying these models into clinics\nmust deal with daunting challenges around large-scale training data, financial,\nand computational resources. Here we propose a cost-effective instruction\nlearning framework for conversational pathology named as CLOVER. CLOVER only\ntrains a lightweight module and uses instruction tuning while freezing the\nparameters of the large language model. Instead of using costly GPT-4, we\npropose well-designed prompts on GPT-3.5 for building generation-based\ninstructions, emphasizing the utility of pathological knowledge derived from\nthe Internet source. To augment the use of instructions, we construct a\nhigh-quality set of template-based instructions in the context of digital\npathology. From two benchmark datasets, our findings reveal the strength of\nhybrid-form instructions in the visual question-answer in pathology. Extensive\nresults show the cost-effectiveness of CLOVER in answering both open-ended and\nclosed-ended questions, where CLOVER outperforms strong baselines that possess\n37 times more training parameters and use instruction data generated from\nGPT-4. Through the instruction tuning, CLOVER exhibits robustness of few-shot\nlearning in the external clinical dataset. These findings demonstrate that\ncost-effective modeling of CLOVER could accelerate the adoption of rapid\nconversational applications in the landscape of digital pathology.", "AI": {"tldr": "CLOVER is a cost-effective instruction learning framework for conversational pathology, using lightweight training and GPT-3.5 prompts to outperform larger models.", "motivation": "Addressing challenges like high costs and resource demands in applying vision-language models to clinics.", "method": "Trains a lightweight module with instruction tuning, uses GPT-3.5 prompts, and constructs template-based instructions for digital pathology.", "result": "Outperforms baselines with fewer parameters, excels in visual Q&A, and shows robustness in few-shot learning.", "conclusion": "CLOVER's cost-effective approach can accelerate conversational AI adoption in digital pathology."}}
{"id": "2505.18110", "pdf": "https://arxiv.org/pdf/2505.18110", "abs": "https://arxiv.org/abs/2505.18110", "authors": ["Zinuo Li", "Xian Zhang", "Yongxin Guo", "Mohammed Bennamoun", "Farid Boussaid", "Girish Dwivedi", "Luqi Gong", "Qiuhong Ke"], "title": "Watch and Listen: Understanding Audio-Visual-Speech Moments with Multimodal LLM", "categories": ["cs.CL"], "comment": null, "summary": "Humans naturally understand moments in a video by integrating visual and\nauditory cues. For example, localizing a scene in the video like \"A scientist\npassionately speaks on wildlife conservation as dramatic orchestral music\nplays, with the audience nodding and applauding\" requires simultaneous\nprocessing of visual, audio, and speech signals. However, existing models often\nstruggle to effectively fuse and interpret audio information, limiting their\ncapacity for comprehensive video temporal understanding. To address this, we\npresent TriSense, a triple-modality large language model designed for holistic\nvideo temporal understanding through the integration of visual, audio, and\nspeech modalities. Central to TriSense is a Query-Based Connector that\nadaptively reweights modality contributions based on the input query, enabling\nrobust performance under modality dropout and allowing flexible combinations of\navailable inputs. To support TriSense's multimodal capabilities, we introduce\nTriSense-2M, a high-quality dataset of over 2 million curated samples generated\nvia an automated pipeline powered by fine-tuned LLMs. TriSense-2M includes\nlong-form videos and diverse modality combinations, facilitating broad\ngeneralization. Extensive experiments across multiple benchmarks demonstrate\nthe effectiveness of TriSense and its potential to advance multimodal video\nanalysis. Code and dataset will be publicly released.", "AI": {"tldr": "TriSense is a triple-modality LLM integrating visual, audio, and speech for holistic video understanding, featuring adaptive modality weighting and supported by a 2M-sample dataset.", "motivation": "Existing models struggle with fusing audio-visual-speech cues, limiting comprehensive video temporal understanding.", "method": "TriSense uses a Query-Based Connector to adaptively reweight modalities and is trained on TriSense-2M, a dataset of 2M curated samples.", "result": "TriSense shows robust performance under modality dropout and advances multimodal video analysis.", "conclusion": "TriSense effectively integrates multiple modalities for video understanding, with potential for broader applications."}}
{"id": "2403.10173", "pdf": "https://arxiv.org/pdf/2403.10173", "abs": "https://arxiv.org/abs/2403.10173", "authors": ["Soikat Hasan Ahmed", "Jan Finkbeiner", "Emre Neftci"], "title": "Efficient Event-Based Object Detection: A Hybrid Neural Network with Spatial and Temporal Attention", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Event cameras offer high temporal resolution and dynamic range with minimal\nmotion blur, making them promising for robust object detection. While Spiking\nNeural Networks (SNNs) on neuromorphic hardware are often considered for\nenergy-efficient and low latency event-based data processing, they often fall\nshort of Artificial Neural Networks (ANNs) in accuracy and flexibility. Here,\nwe introduce Attention-based Hybrid SNN-ANN backbones for event-based object\ndetection to leverage the strengths of both SNN and ANN architectures. A novel\nAttention-based SNN-ANN bridge module captures sparse spatial and temporal\nrelations from the SNN layer and converts them into dense feature maps for the\nANN part of the backbone. Additionally, we present a variant that integrates\nDWConvL-STMs to the ANN blocks to capture slower dynamics. This multi-timescale\nnetwork combines fast SNN processing for short timesteps with long-term dense\nRNN processing, effectively capturing both fast and slow dynamics. Experimental\nresults demonstrate that our proposed method surpasses SNN-based approaches by\nsignificant margins, with results comparable to existing ANN and RNN-based\nmethods. Unlike ANN-only networks, the hybrid setup allows us to implement the\nSNN blocks on digital neuromorphic hardware to investigate the feasibility of\nour approach. Extensive ablation studies and implementation on neuromorphic\nhardware confirm the effectiveness of our proposed modules and architectural\nchoices. Our hybrid SNN-ANN architectures pave the way for ANN-like performance\nat a drastically reduced parameter, latency, and power budget.", "AI": {"tldr": "A hybrid SNN-ANN architecture with attention and multi-timescale processing improves event-based object detection, combining SNN efficiency with ANN accuracy.", "motivation": "Event cameras provide high temporal resolution and dynamic range, but SNNs, while energy-efficient, lag behind ANNs in accuracy and flexibility.", "method": "Proposes an Attention-based Hybrid SNN-ANN backbone with a bridge module for sparse-to-dense feature conversion and integrates DWConvL-STMs for multi-timescale dynamics.", "result": "Outperforms SNN-based methods and matches ANN/RNN performance, with potential for neuromorphic hardware implementation.", "conclusion": "The hybrid architecture achieves ANN-like performance with lower latency, power, and parameter costs, advancing event-based detection."}}
{"id": "2506.15760", "pdf": "https://arxiv.org/pdf/2506.15760", "abs": "https://arxiv.org/abs/2506.15760", "authors": ["Shuangbao Paul Wang", "Jianzhou Mao", "Eric Sakk"], "title": "Compilation, Optimization, Error Mitigation, and Machine Learning in Quantum Algorithms", "categories": ["quant-ph", "cs.LG"], "comment": null, "summary": "This paper discusses the compilation, optimization, and error mitigation of\nquantum algorithms, essential steps to execute real-world quantum algorithms.\nQuantum algorithms running on a hybrid platform with QPU and CPU/GPU take\nadvantage of existing high-performance computing power with quantum-enabled\nexponential speedups. The proposed approximate quantum Fourier transform (AQFT)\nfor quantum algorithm optimization improves the circuit execution on top of an\nexponential speed-ups the quantum Fourier transform has provided.", "AI": {"tldr": "The paper focuses on optimizing and mitigating errors in quantum algorithms, introducing an approximate quantum Fourier transform (AQFT) to enhance execution efficiency.", "motivation": "To leverage hybrid quantum-classical computing for real-world quantum algorithm execution, combining QPU and CPU/GPU power.", "method": "Proposes an approximate quantum Fourier transform (AQFT) for optimizing quantum circuits, building on the exponential speedups of quantum Fourier transform.", "result": "Improved circuit execution efficiency and performance in hybrid quantum-classical platforms.", "conclusion": "AQFT enhances quantum algorithm optimization, making real-world execution more feasible."}}
{"id": "2411.05943", "pdf": "https://arxiv.org/pdf/2411.05943", "abs": "https://arxiv.org/abs/2411.05943", "authors": ["Takuya Ito", "Murray Campbell", "Lior Horesh", "Tim Klinger", "Parikshit Ram"], "title": "Quantifying artificial intelligence through algorithmic generalization", "categories": ["cs.AI", "cs.CL", "cs.LG", "cs.LO"], "comment": null, "summary": "The rapid development of artificial intelligence (AI) systems has created an\nurgent need for their scientific quantification. While their fluency across a\nvariety of domains is impressive, AI systems fall short on tests requiring\nalgorithmic reasoning -- a glaring limitation given the necessity for\ninterpretable and reliable technology. Despite a surge of reasoning benchmarks\nemerging from the academic community, no theoretical framework exists to\nquantify algorithmic reasoning in AI systems. Here, we adopt a framework from\ncomputational complexity theory to quantify algorithmic generalization using\nalgebraic expressions: algebraic circuit complexity. Algebraic circuit\ncomplexity theory -- the study of algebraic expressions as circuit models -- is\na natural framework to study the complexity of algorithmic computation.\nAlgebraic circuit complexity enables the study of generalization by defining\nbenchmarks in terms of the computational requirements to solve a problem.\nMoreover, algebraic circuits are generic mathematical objects; an arbitrarily\nlarge number of samples can be generated for a specified circuit, making it an\nideal experimental sandbox for the data-hungry models that are used today. In\nthis Perspective, we adopt tools from algebraic circuit complexity, apply them\nto formalize a science of algorithmic generalization, and address key\nchallenges for its successful application to AI science.", "AI": {"tldr": "The paper proposes using algebraic circuit complexity to quantify algorithmic reasoning in AI systems, addressing the lack of a theoretical framework for this purpose.", "motivation": "AI systems lack interpretability and reliability in algorithmic reasoning, despite their fluency in other domains. Existing benchmarks lack a theoretical foundation.", "method": "Adopts algebraic circuit complexity theory to formalize algorithmic generalization, using algebraic expressions as circuit models.", "result": "Introduces a framework to study generalization by defining benchmarks based on computational requirements, leveraging algebraic circuits for scalable experimentation.", "conclusion": "The approach provides a theoretical foundation for quantifying algorithmic reasoning in AI, addressing key challenges in AI science."}}
{"id": "2505.18436", "pdf": "https://arxiv.org/pdf/2505.18436", "abs": "https://arxiv.org/abs/2505.18436", "authors": ["AbdelRahim Elmadany", "Sang Yun Kwon", "Hawau Olamide Toyin", "Alcides Alcoba Inciarte", "Hanan Aldarmaki", "Muhammad Abdul-Mageed"], "title": "Voice of a Continent: Mapping Africa's Speech Technology Frontier", "categories": ["cs.CL"], "comment": null, "summary": "Africa's rich linguistic diversity remains significantly underrepresented in\nspeech technologies, creating barriers to digital inclusion. To alleviate this\nchallenge, we systematically map the continent's speech space of datasets and\ntechnologies, leading to a new comprehensive benchmark SimbaBench for\ndownstream African speech tasks. Using SimbaBench, we introduce the Simba\nfamily of models, achieving state-of-the-art performance across multiple\nAfrican languages and speech tasks. Our benchmark analysis reveals critical\npatterns in resource availability, while our model evaluation demonstrates how\ndataset quality, domain diversity, and language family relationships influence\nperformance across languages. Our work highlights the need for expanded speech\ntechnology resources that better reflect Africa's linguistic diversity and\nprovides a solid foundation for future research and development efforts toward\nmore inclusive speech technologies.", "AI": {"tldr": "The paper introduces SimbaBench, a benchmark for African speech tasks, and the Simba model family, achieving top performance. It highlights gaps in speech technology resources for Africa's diverse languages.", "motivation": "Africa's linguistic diversity is underrepresented in speech technologies, hindering digital inclusion. The paper aims to address this gap.", "method": "The authors systematically map Africa's speech datasets and technologies, creating SimbaBench. They then develop the Simba model family and evaluate performance across languages.", "result": "Simba models achieve state-of-the-art performance. Analysis shows resource availability and dataset quality impact performance across languages.", "conclusion": "The work underscores the need for more inclusive speech technology resources in Africa and provides a foundation for future research."}}
{"id": "2404.13953", "pdf": "https://arxiv.org/pdf/2404.13953", "abs": "https://arxiv.org/abs/2404.13953", "authors": ["Yinzhe Xu", "Huajian Huang", "Yingshu Chen", "Sai-Kit Yeung"], "title": "360VOTS: Visual Object Tracking and Segmentation in Omnidirectional Videos", "categories": ["cs.CV"], "comment": "arXiv admin note: substantial text overlap with arXiv:2307.14630", "summary": "Visual object tracking and segmentation in omnidirectional videos are\nchallenging due to the wide field-of-view and large spherical distortion\nbrought by 360{\\deg} images. To alleviate these problems, we introduce a novel\nrepresentation, extended bounding field-of-view (eBFoV), for target\nlocalization and use it as the foundation of a general 360 tracking framework\nwhich is applicable for both omnidirectional visual object tracking and\nsegmentation tasks. Building upon our previous work on omnidirectional visual\nobject tracking (360VOT), we propose a comprehensive dataset and benchmark that\nincorporates a new component called omnidirectional video object segmentation\n(360VOS). The 360VOS dataset includes 290 sequences accompanied by dense\npixel-wise masks and covers a broader range of target categories. To support\nboth the development and evaluation of algorithms in this domain, we divide the\ndataset into a training subset with 170 sequences and a testing subset with 120\nsequences. Furthermore, we tailor evaluation metrics for both omnidirectional\ntracking and segmentation to ensure rigorous assessment. Through extensive\nexperiments, we benchmark state-of-the-art approaches and demonstrate the\neffectiveness of our proposed 360 tracking framework and training dataset.\nHomepage: https://360vots.hkustvgd.com/", "AI": {"tldr": "The paper introduces a novel representation (eBFoV) for target localization in omnidirectional videos, proposes a dataset (360VOS) for tracking and segmentation, and benchmarks state-of-the-art methods.", "motivation": "Challenges in visual object tracking and segmentation in 360\u00b0 videos due to distortion and wide field-of-view.", "method": "Proposes eBFoV for localization and a 360 tracking framework, along with a dataset (360VOS) for training and testing.", "result": "Benchmarked state-of-the-art methods, showing the framework's effectiveness.", "conclusion": "The proposed framework and dataset advance omnidirectional tracking and segmentation."}}
{"id": "2506.15766", "pdf": "https://arxiv.org/pdf/2506.15766", "abs": "https://arxiv.org/abs/2506.15766", "authors": ["Seung-Joo Lee", "Andre Lukas"], "title": "Approximate Ricci-flat Metrics for Calabi-Yau Manifolds", "categories": ["hep-th", "cs.LG", "math.DG"], "comment": "15 pages, 6 figures", "summary": "We outline a method to determine analytic K\\\"ahler potentials with associated\napproximately Ricci-flat K\\\"ahler metrics on Calabi-Yau manifolds. Key\ningredients are numerically calculating Ricci-flat K\\\"ahler potentials via\nmachine learning techniques and fitting the numerical results to Donaldson's\nAnsatz. We apply this method to the Dwork family of quintic hypersurfaces in\n$\\mathbb{P}^4$ and an analogous one-parameter family of bi-cubic CY\nhypersurfaces in $\\mathbb{P}^2\\times\\mathbb{P}^2$. In each case, a relatively\nsimple analytic expression is obtained for the approximately Ricci-flat\nK\\\"ahler potentials, including the explicit dependence on the complex structure\nparameter. We find that these K\\\"ahler potentials only depend on the modulus of\nthe complex structure parameter.", "AI": {"tldr": "A method to find analytic K\u00e4hler potentials for approximately Ricci-flat metrics on Calabi-Yau manifolds using machine learning and Donaldson's Ansatz, applied to specific hypersurface families.", "motivation": "To determine simple analytic expressions for K\u00e4hler potentials on Calabi-Yau manifolds, facilitating the study of Ricci-flat metrics.", "method": "Numerically calculate Ricci-flat K\u00e4hler potentials via machine learning, fit results to Donaldson's Ansatz, and apply to specific hypersurface families.", "result": "Obtained simple analytic expressions for K\u00e4hler potentials, showing dependence only on the modulus of the complex structure parameter.", "conclusion": "The method successfully yields analytic K\u00e4hler potentials, useful for further studies in Calabi-Yau geometry."}}
{"id": "2411.07940", "pdf": "https://arxiv.org/pdf/2411.07940", "abs": "https://arxiv.org/abs/2411.07940", "authors": ["M\u00e9lanie Roschewitz", "Raghav Mehta", "Charles Jones", "Ben Glocker"], "title": "Automatic dataset shift identification to support safe deployment of medical imaging AI", "categories": ["cs.AI", "cs.CV"], "comment": "Accepted at MICCAI 2025. This version is an extended version with\n  additional experimental results. Code available at\n  https://github.com/biomedia-mira/shift_identification", "summary": "Shifts in data distribution can substantially harm the performance of\nclinical AI models and lead to misdiagnosis. Hence, various methods have been\ndeveloped to detect the presence of such shifts at deployment time. However,\nthe root causes of dataset shifts are diverse, and the choice of shift\nmitigation strategies is highly dependent on the precise type of shift\nencountered at test time. As such, detecting test-time dataset shift is not\nsufficient: precisely identifying which type of shift has occurred is critical.\nIn this work, we propose the first unsupervised dataset shift identification\nframework for imaging datasets, effectively distinguishing between prevalence\nshift (caused by a change in the label distribution), covariate shift (caused\nby a change in input characteristics) and mixed shifts (simultaneous prevalence\nand covariate shifts). We discuss the importance of self-supervised encoders\nfor detecting subtle covariate shifts and propose a novel shift detector\nleveraging both self-supervised encoders and task model outputs for improved\nshift detection. We show the effectiveness of the proposed shift identification\nframework across three different imaging modalities (chest radiography, digital\nmammography, and retinal fundus images) on five types of real-world dataset\nshifts using five large publicly available datasets.", "AI": {"tldr": "Proposes an unsupervised framework to identify types of dataset shifts (prevalence, covariate, mixed) in clinical AI models, improving shift detection accuracy.", "motivation": "Data distribution shifts harm clinical AI performance, but existing methods only detect shifts without identifying their types, limiting mitigation strategies.", "method": "Uses self-supervised encoders and task model outputs to distinguish between prevalence, covariate, and mixed shifts in imaging datasets.", "result": "Effective across three imaging modalities and five real-world dataset shifts, demonstrating improved shift identification.", "conclusion": "The framework enhances shift detection precision, aiding targeted mitigation strategies for clinical AI models."}}
{"id": "2505.19675", "pdf": "https://arxiv.org/pdf/2505.19675", "abs": "https://arxiv.org/abs/2505.19675", "authors": ["Liqin Ye", "Agam Shah", "Chao Zhang", "Sudheer Chava"], "title": "Calibrating Pre-trained Language Classifiers on LLM-generated Noisy Labels via Iterative Refinement", "categories": ["cs.CL", "cs.AI"], "comment": "Accepted at KDD'25", "summary": "The traditional process of creating labeled datasets is labor-intensive and\nexpensive. Recent breakthroughs in open-source large language models (LLMs)\nhave opened up a new avenue in generating labeled datasets automatically for\nvarious natural language processing (NLP) tasks, providing an alternative to\nsuch an expensive annotation process. However, the reliability of such\nauto-generated labels remains a significant concern due to inherent\ninaccuracies. When learning from noisy labels, the model's generalization is\nlikely to be harmed as it is prone to overfit to those label noises. While\nprevious studies in learning from noisy labels mainly focus on synthetic noise\nand real-world noise, LLM-generated label noise receives less attention. In\nthis paper, we propose SiDyP: Simplex Label Diffusion with Dynamic Prior to\ncalibrate the classifier's prediction, thus enhancing its robustness towards\nLLM-generated noisy labels. SiDyP retrieves potential true label candidates by\nneighborhood label distribution in text embedding space and iteratively refines\nnoisy candidates using a simplex diffusion model. Our framework can increase\nthe performance of the BERT classifier fine-tuned on both zero-shot and\nfew-shot LLM-generated noisy label datasets by an average of 7.21% and 7.30%\nrespectively. We demonstrate the effectiveness of SiDyP by conducting extensive\nbenchmarking for different LLMs over a variety of NLP tasks. Our code is\navailable on Github.", "AI": {"tldr": "SiDyP improves classifier robustness against noisy labels from LLMs by refining them using a simplex diffusion model, boosting performance by ~7%.", "motivation": "Traditional labeled dataset creation is costly, and LLM-generated labels, while cheaper, introduce noise that harms model generalization.", "method": "SiDyP refines noisy labels by leveraging neighborhood label distribution in embedding space and iterative simplex diffusion.", "result": "Performance of BERT classifiers improved by 7.21% (zero-shot) and 7.30% (few-shot) on LLM-generated noisy datasets.", "conclusion": "SiDyP effectively enhances robustness to LLM-generated label noise, validated across various NLP tasks and LLMs."}}
{"id": "2404.14177", "pdf": "https://arxiv.org/pdf/2404.14177", "abs": "https://arxiv.org/abs/2404.14177", "authors": ["Guanhua Zhao", "Yu Gu", "Xuhan Sheng", "Yujie Hu", "Jian Zhang"], "title": "Label-guided Facial Retouching Reversion", "categories": ["cs.CV"], "comment": "ICME2025 Oral", "summary": "With the popularity of social media platforms and retouching tools, more\npeople are beautifying their facial photos, posing challenges for fields\nrequiring photo authenticity. To address this issue, some work has proposed\nmakeup removal methods, but they cannot revert images involving geometric\ndeformations caused by retouching. To tackle the problem of facial retouching\nreversion, we propose a framework, dubbed Re-Face, which consists of three\ncomponents: a facial retouching detector, an image reversion model named FaceR,\nand a color correction module called Hierarchical Adaptive Instance\nNormalization (H-AdaIN). FaceR can utilize labels generated by the facial\nretouching detector as guidance to revert the retouched facial images. Then,\ncolor correction is performed using H-AdaIN to address the issue of color\nshift. Extensive experiments demonstrate the effectiveness of our framework and\neach module.", "AI": {"tldr": "The paper proposes Re-Face, a framework to revert facial retouching in photos, addressing geometric deformations and color shifts.", "motivation": "The rise of social media and retouching tools has increased photo beautification, challenging authenticity. Existing methods fail to revert geometric deformations.", "method": "Re-Face includes a retouching detector, FaceR for image reversion, and H-AdaIN for color correction.", "result": "Experiments show the framework's effectiveness in reverting retouched images.", "conclusion": "Re-Face successfully addresses facial retouching reversion, including geometric and color issues."}}
{"id": "2506.15771", "pdf": "https://arxiv.org/pdf/2506.15771", "abs": "https://arxiv.org/abs/2506.15771", "authors": ["Robert Kent", "Benjamin Lienhard", "Gregory Lafyatis", "Daniel J. Gauthier"], "title": "Superconducting Qubit Readout Using Next-Generation Reservoir Computing", "categories": ["quant-ph", "cs.LG"], "comment": null, "summary": "Quantum processors require rapid and high-fidelity simultaneous measurements\nof many qubits. While superconducting qubits are among the leading modalities\ntoward a useful quantum processor, their readout remains a bottleneck.\nTraditional approaches to processing measurement data often struggle to account\nfor crosstalk present in frequency-multiplexed readout, the preferred method to\nreduce the resource overhead. Recent approaches to address this challenge use\nneural networks to improve the state-discrimination fidelity. However, they are\ncomputationally expensive to train and evaluate, resulting in increased latency\nand poor scalability as the number of qubits increases. We present an\nalternative machine learning approach based on next-generation reservoir\ncomputing that constructs polynomial features from the measurement signals and\nmaps them to the corresponding qubit states. This method is highly\nparallelizable, avoids the costly nonlinear activation functions common in\nneural networks, and supports real-time training, enabling fast evaluation,\nadaptability, and scalability. Despite its lower computational complexity, our\nreservoir approach is able to maintain high qubit-state-discrimination\nfidelity. Relative to traditional methods, our approach achieves error\nreductions of up to 50% and 11% on single- and five-qubit datasets,\nrespectively, and delivers up to 2.5x crosstalk reduction on the five-qubit\ndataset. Compared with recent machine-learning methods, evaluating our model\nrequires 100x fewer multiplications for single-qubit and 2.5x fewer for\nfive-qubit models. This work demonstrates that reservoir computing can enhance\nqubit-state discrimination while maintaining scalability for future quantum\nprocessors.", "AI": {"tldr": "A reservoir computing-based method improves qubit-state discrimination in quantum processors, offering high fidelity, scalability, and reduced computational cost compared to traditional and neural network approaches.", "motivation": "Superconducting qubits face readout bottlenecks, especially with crosstalk in frequency-multiplexed readout. Neural networks, though effective, are computationally expensive and lack scalability.", "method": "The paper proposes a reservoir computing approach that constructs polynomial features from measurement signals and maps them to qubit states, avoiding costly nonlinear activations and enabling real-time training.", "result": "The method reduces errors by up to 50% (single-qubit) and 11% (five-qubit), cuts crosstalk by 2.5x, and requires 100x fewer multiplications than neural networks.", "conclusion": "Reservoir computing enhances qubit-state discrimination with scalability and efficiency, making it viable for future quantum processors."}}
{"id": "2412.18091", "pdf": "https://arxiv.org/pdf/2412.18091", "abs": "https://arxiv.org/abs/2412.18091", "authors": ["Lixian Jing", "Jianpeng Qi", "Junyu Dong", "Yanwei Yu"], "title": "AutoSculpt: A Pattern-based Model Auto-pruning Framework Using Reinforcement Learning and Graph Learning", "categories": ["cs.AI"], "comment": "I have identified a significant and fundamental flaw in the\n  methodology described in Section 3 of the manuscript. This flaw pertains to a\n  critical error in the implementation of the model's training procedure, which\n  renders the reported performance metrics unreliable. This issue is not\n  correctable through an erratum or replacement as it undermines the core\n  findings and validity of the entire study", "summary": "As deep neural networks (DNNs) are increasingly deployed on edge devices,\noptimizing models for constrained computational resources is critical. Existing\nauto-pruning methods face challenges due to the diversity of DNN models,\nvarious operators (e.g., filters), and the difficulty in balancing pruning\ngranularity with model accuracy. To address these limitations, we introduce\nAutoSculpt, a pattern-based automated pruning framework designed to enhance\nefficiency and accuracy by leveraging graph learning and deep reinforcement\nlearning (DRL). AutoSculpt automatically identifies and prunes regular patterns\nwithin DNN architectures that can be recognized by existing inference engines,\nenabling runtime acceleration. Three key steps in AutoSculpt include: (1)\nConstructing DNNs as graphs to encode their topology and parameter\ndependencies, (2) embedding computationally efficient pruning patterns, and (3)\nutilizing DRL to iteratively refine auto-pruning strategies until the optimal\nbalance between compression and accuracy is achieved. Experimental results\ndemonstrate the effectiveness of AutoSculpt across various architectures,\nincluding ResNet, MobileNet, VGG, and Vision Transformer, achieving pruning\nrates of up to 90% and nearly 18% improvement in FLOPs reduction, outperforming\nall baselines. The codes can be available at\nhttps://anonymous.4open.science/r/AutoSculpt-DDA0", "AI": {"tldr": "AutoSculpt is a pattern-based automated pruning framework using graph learning and DRL to optimize DNNs for edge devices, achieving high pruning rates and efficiency.", "motivation": "Optimizing DNNs for edge devices is challenging due to model diversity and pruning-accuracy trade-offs.", "method": "AutoSculpt constructs DNNs as graphs, embeds pruning patterns, and uses DRL to refine pruning strategies.", "result": "Achieves up to 90% pruning rates and 18% FLOPs reduction, outperforming baselines.", "conclusion": "AutoSculpt effectively balances compression and accuracy, enhancing DNN efficiency for edge deployment."}}
{"id": "2505.21523", "pdf": "https://arxiv.org/pdf/2505.21523", "abs": "https://arxiv.org/abs/2505.21523", "authors": ["Chengzhi Liu", "Zhongxing Xu", "Qingyue Wei", "Juncheng Wu", "James Zou", "Xin Eric Wang", "Yuyin Zhou", "Sheng Liu"], "title": "More Thinking, Less Seeing? Assessing Amplified Hallucination in Multimodal Reasoning Models", "categories": ["cs.CL", "cs.AI", "cs.CV"], "comment": null, "summary": "Test-time compute has empowered multimodal large language models to generate\nextended reasoning chains, yielding strong performance on tasks such as\nmultimodal math reasoning. However, this improved reasoning ability often comes\nwith increased hallucination: as generations become longer, models tend to\ndrift away from image-grounded content and rely more heavily on language\npriors. Attention analysis shows that longer reasoning chains lead to reduced\nfocus on visual inputs, which contributes to hallucination. To systematically\nstudy this phenomenon, we introduce RH-AUC, a metric that quantifies how a\nmodel's perception accuracy changes with reasoning length, allowing us to\nevaluate whether the model preserves visual grounding during reasoning. We also\nrelease RH-Bench, a diagnostic benchmark that spans a variety of multimodal\ntasks, designed to assess the trade-off between reasoning ability and\nhallucination. Our analysis reveals that (i) larger models typically achieve a\nbetter balance between reasoning and perception, and (ii) this balance is\ninfluenced more by the types and domains of training data than by its overall\nvolume. These findings underscore the importance of evaluation frameworks that\njointly consider both reasoning quality and perceptual fidelity.", "AI": {"tldr": "The paper studies how longer reasoning chains in multimodal models increase hallucination, introduces RH-AUC and RH-Bench for evaluation, and finds that larger models and training data types influence the balance between reasoning and perception.", "motivation": "To understand the trade-off between extended reasoning and hallucination in multimodal models, as longer reasoning chains reduce visual grounding.", "method": "Introduces RH-AUC to measure perception accuracy with reasoning length and RH-Bench for evaluating reasoning-perception trade-offs.", "result": "Larger models balance reasoning and perception better, influenced by training data types/domains rather than volume.", "conclusion": "Joint evaluation of reasoning quality and perceptual fidelity is crucial for multimodal models."}}
{"id": "2404.15564", "pdf": "https://arxiv.org/pdf/2404.15564", "abs": "https://arxiv.org/abs/2404.15564", "authors": ["Jun Huang", "Yan Liu"], "title": "Guided AbsoluteGrad: Magnitude of Gradients Matters to Explanation's Localization and Saliency", "categories": ["cs.CV", "cs.AI", "cs.HC", "cs.LG"], "comment": "CAI2024 Camera-ready Submission and Correction", "summary": "This paper proposes a new gradient-based XAI method called Guided\nAbsoluteGrad for saliency map explanations. We utilize both positive and\nnegative gradient magnitudes and employ gradient variance to distinguish the\nimportant areas for noise deduction. We also introduce a novel evaluation\nmetric named ReCover And Predict (RCAP), which considers the Localization and\nVisual Noise Level objectives of the explanations. We propose two propositions\nfor these two objectives and prove the necessity of evaluating them. We\nevaluate Guided AbsoluteGrad with seven gradient-based XAI methods using the\nRCAP metric and other SOTA metrics in three case studies: (1) ImageNet dataset\nwith ResNet50 model; (2) International Skin Imaging Collaboration (ISIC)\ndataset with EfficientNet model; (3) the Places365 dataset with DenseNet161\nmodel. Our method surpasses other gradient-based approaches, showcasing the\nquality of enhanced saliency map explanations through gradient magnitude.", "AI": {"tldr": "A new gradient-based XAI method, Guided AbsoluteGrad, is introduced for saliency maps, using gradient magnitudes and variance for noise reduction. A novel metric, RCAP, evaluates explanations. The method outperforms others in three case studies.", "motivation": "To improve saliency map explanations by leveraging gradient magnitudes and reducing noise, while introducing a robust evaluation metric (RCAP) for better assessment.", "method": "Guided AbsoluteGrad uses positive/negative gradient magnitudes and gradient variance for noise deduction. RCAP evaluates explanations based on Localization and Visual Noise Level objectives.", "result": "Guided AbsoluteGrad outperforms seven gradient-based XAI methods in three case studies (ImageNet, ISIC, Places365) using RCAP and other metrics.", "conclusion": "The proposed method enhances saliency map quality by effectively utilizing gradient magnitudes and introduces a reliable evaluation framework (RCAP)."}}
{"id": "2506.15782", "pdf": "https://arxiv.org/pdf/2506.15782", "abs": "https://arxiv.org/abs/2506.15782", "authors": ["Nicolas Boull\u00e9", "Matthew J. Colbrook", "Gustav Conradie"], "title": "Convergent Methods for Koopman Operators on Reproducing Kernel Hilbert Spaces", "categories": ["math.NA", "cs.LG", "cs.NA", "math.DS", "math.SP", "stat.ML", "37A30, 37M10, 37N10, 47A10, 47B32, 47B33, 65P99"], "comment": null, "summary": "Data-driven spectral analysis of Koopman operators is a powerful tool for\nunderstanding numerous real-world dynamical systems, from neuronal activity to\nvariations in sea surface temperature. The Koopman operator acts on a function\nspace and is most commonly studied on the space of square-integrable functions.\nHowever, defining it on a suitable reproducing kernel Hilbert space (RKHS)\noffers numerous practical advantages, including pointwise predictions with\nerror bounds, improved spectral properties that facilitate computations, and\nmore efficient algorithms, particularly in high dimensions. We introduce the\nfirst general, provably convergent, data-driven algorithms for computing\nspectral properties of Koopman and Perron--Frobenius operators on RKHSs. These\nmethods efficiently compute spectra and pseudospectra with error control and\nspectral measures while exploiting the RKHS structure to avoid the large-data\nlimits required in the $L^2$ settings. The function space is determined by a\nuser-specified kernel, eliminating the need for quadrature-based sampling as in\n$L^2$ and enabling greater flexibility with finite, externally provided\ndatasets. Using the Solvability Complexity Index hierarchy, we construct\nadversarial dynamical systems for these problems to show that no algorithm can\nsucceed in fewer limits, thereby proving the optimality of our algorithms.\nNotably, this impossibility extends to randomized algorithms and datasets. We\ndemonstrate the effectiveness of our algorithms on challenging,\nhigh-dimensional datasets arising from real-world measurements and\nhigh-fidelity numerical simulations, including turbulent channel flow,\nmolecular dynamics of a binding protein, Antarctic sea ice concentration, and\nNorthern Hemisphere sea surface height. The algorithms are publicly available\nin the software package $\\texttt{SpecRKHS}$.", "AI": {"tldr": "The paper introduces data-driven algorithms for spectral analysis of Koopman operators on RKHS, offering advantages like pointwise predictions, improved spectral properties, and efficiency in high dimensions. The methods are proven optimal and tested on real-world datasets.", "motivation": "To overcome limitations of traditional $L^2$ methods for Koopman operator analysis, the paper aims to leverage RKHS for better computational efficiency, flexibility, and accuracy in spectral analysis.", "method": "The authors develop general, provably convergent algorithms for computing spectral properties of Koopman and Perron--Frobenius operators on RKHS, using user-specified kernels and avoiding large-data limits.", "result": "The algorithms efficiently compute spectra, pseudospectra, and spectral measures, demonstrating effectiveness on high-dimensional real-world datasets like turbulent flow and molecular dynamics.", "conclusion": "The proposed RKHS-based methods are optimal and outperform traditional $L^2$ approaches, with practical applications showcased in diverse fields. The algorithms are available in $\texttt{SpecRKHS}$."}}
{"id": "2501.07674", "pdf": "https://arxiv.org/pdf/2501.07674", "abs": "https://arxiv.org/abs/2501.07674", "authors": ["Haokun Zhao", "Jinyi Han", "Jiaqing Liang", "Yanghua Xiao", "Xiaojun Meng", "Jiansheng Wei"], "title": "CDS: Knowledge Component-Driven Data Synthesis Guided by Cognitive Diagnosis Theory", "categories": ["cs.AI"], "comment": null, "summary": "Large Language Models (LLMs) have achieved significant advancements, but the\nincreasing complexity of tasks and higher performance demands highlight the\nneed for continuous improvement. Some approaches utilize synthetic data\ngenerated by advanced LLMs based on evaluation results to train models.\nHowever, conventional evaluation methods fail to provide detailed, fine-grained\nprofiles of LLMs, limiting their guidance for data synthesis. In this paper, we\nintroduce the Cognitive Diagnostic Synthesis (CDS) method, which incorporates a\ndiagnostic process inspired by Cognitive Diagnosis Theory (CDT) to refine\nevaluation results and characterize model profiles at the knowledge component\nlevel. Based on these diagnostics, we propose two diagnosis-synthesis\nstrategies for weakness-targeted data synthesis. Additionally, we present an\nenhanced data augmentation and selection pipeline to improve the quality and\ndiversity of synthesized data. Our experiments with several open-source models\nshow significant improvements across multiple benchmarks, achieving up to 6.00%\nimprovement in code generation, 13.10% in mathematical reasoning, and 5.43% in\nacademic exams. Code and data are available on GitHub.", "AI": {"tldr": "The paper introduces Cognitive Diagnostic Synthesis (CDS), a method to improve LLM performance by refining evaluations and targeting weaknesses for data synthesis, achieving notable benchmark improvements.", "motivation": "Current evaluation methods lack fine-grained insights, limiting effective data synthesis for LLM improvement.", "method": "CDS uses Cognitive Diagnosis Theory (CDT) for detailed model profiling and employs diagnosis-synthesis strategies and enhanced data augmentation.", "result": "Experiments show improvements: 6.00% in code generation, 13.10% in math reasoning, and 5.43% in academic exams.", "conclusion": "CDS effectively enhances LLM performance by refining evaluations and targeted data synthesis."}}
{"id": "2506.01495", "pdf": "https://arxiv.org/pdf/2506.01495", "abs": "https://arxiv.org/abs/2506.01495", "authors": ["Ping Wu", "Guobin Shen", "Dongcheng Zhao", "Yuwei Wang", "Yiting Dong", "Yu Shi", "Enmeng Lu", "Feifei Zhao", "Yi Zeng"], "title": "CVC: A Large-Scale Chinese Value Rule Corpus for Value Alignment of Large Language Models", "categories": ["cs.CL"], "comment": null, "summary": "Ensuring that Large Language Models (LLMs) align with mainstream human values\nand ethical norms is crucial for the safe and sustainable development of AI.\nCurrent value evaluation and alignment are constrained by Western cultural bias\nand incomplete domestic frameworks reliant on non-native rules; furthermore,\nthe lack of scalable, rule-driven scenario generation methods makes evaluations\ncostly and inadequate across diverse cultural contexts. To address these\nchallenges, we propose a hierarchical value framework grounded in core Chinese\nvalues, encompassing three main dimensions, 12 core values, and 50 derived\nvalues. Based on this framework, we construct a large-scale Chinese Values\nCorpus (CVC) containing over 250,000 value rules enhanced and expanded through\nhuman annotation. Experimental results show that CVC-guided scenarios\noutperform direct generation ones in value boundaries and content diversity. In\nthe evaluation across six sensitive themes (e.g., surrogacy, suicide), seven\nmainstream LLMs preferred CVC-generated options in over 70.5% of cases, while\nfive Chinese human annotators showed an 87.5% alignment with CVC, confirming\nits universality, cultural relevance, and strong alignment with Chinese values.\nAdditionally, we construct 400,000 rule-based moral dilemma scenarios that\nobjectively capture nuanced distinctions in conflicting value prioritization\nacross 17 LLMs. Our work establishes a culturally-adaptive benchmarking\nframework for comprehensive value evaluation and alignment, representing\nChinese characteristics. All data are available at\nhttps://huggingface.co/datasets/Beijing-AISI/CVC, and the code is available at\nhttps://github.com/Beijing-AISI/CVC.", "AI": {"tldr": "The paper proposes a hierarchical Chinese value framework and a large-scale Chinese Values Corpus (CVC) to address cultural bias in LLM alignment, showing improved performance in value boundaries and diversity.", "motivation": "Current LLM value alignment suffers from Western cultural bias and lacks scalable evaluation methods, especially for non-Western contexts like China.", "method": "Developed a hierarchical value framework (3 dimensions, 12 core values, 50 derived values) and constructed CVC with 250,000+ annotated rules. Evaluated using scenarios and moral dilemmas.", "result": "CVC-guided scenarios outperformed direct generation, with LLMs preferring CVC options in 70.5% of cases and human annotators aligning 87.5%. Also created 400,000 moral dilemma scenarios.", "conclusion": "The work provides a culturally-adaptive benchmarking framework for LLM value alignment, emphasizing Chinese values and universality."}}
{"id": "2405.06593", "pdf": "https://arxiv.org/pdf/2405.06593", "abs": "https://arxiv.org/abs/2405.06593", "authors": ["Thomas Manzini", "Priyankari Perali", "Raisa Karnik", "Mihir Godbole", "Hasnat Abdullah", "Robin Murphy"], "title": "Non-Uniform Spatial Alignment Errors in sUAS Imagery From Wide-Area Disasters", "categories": ["cs.CV"], "comment": "6 pages, 4 figures", "summary": "This work presents the first quantitative study of alignment errors between\nsmall uncrewed aerial systems (sUAS) georectified imagery and a priori building\npolygons and finds that alignment errors are non-uniform and irregular, which\nnegatively impacts field robotics systems and human-robot interfaces that rely\non geospatial information. There are no efforts that have considered the\nalignment of a priori spatial data with georectified sUAS imagery, possibly\nbecause straight-forward linear transformations often remedy any misalignment\nin satellite imagery. However, an attempt to develop machine learning models\nfor an sUAS field robotics system for disaster response from nine wide-area\ndisasters using the CRASAR-U-DROIDs dataset uncovered serious translational\nalignment errors. The analysis considered 21,608 building polygons in 51\northomosaic images, covering 16787.2 Acres (26.23 square miles), and 7,880\nadjustment annotations, averaging 75.36 pixels and an average intersection over\nunion of 0.65. Further analysis found no uniformity among the angle and\ndistance metrics of the building polygon alignments, presenting an average\ncircular variance of 0.28 and an average distance variance of 0.45 pixels2,\nmaking it impossible to use the linear transform used to align satellite\nimagery. The study's primary contribution is alerting field robotics and\nhuman-robot interaction (HRI) communities to the problem of spatial alignment\nand that a new method will be needed to automate and communicate the alignment\nof spatial data in sUAS georectified imagery. This paper also contributes a\ndescription of the updated CRASAR-U-DROIDs dataset of sUAS imagery, which\ncontains building polygons and human-curated corrections to spatial\nmisalignment for further research in field robotics and HRI.", "AI": {"tldr": "The study highlights non-uniform alignment errors between sUAS georectified imagery and building polygons, impacting robotics and HRI systems, and calls for new alignment methods.", "motivation": "Alignment errors in sUAS imagery negatively affect field robotics and HRI systems, yet prior work hasn't addressed this issue due to reliance on linear transformations for satellite imagery.", "method": "Analyzed 21,608 building polygons in 51 orthomosaic images from the CRASAR-U-DROIDs dataset, measuring alignment errors and variances.", "result": "Found non-uniform alignment errors (average circular variance 0.28, distance variance 0.45 pixels\u00b2), making linear transforms ineffective.", "conclusion": "The study raises awareness of spatial alignment challenges in sUAS imagery and contributes an updated dataset for further research."}}
{"id": "2506.15799", "pdf": "https://arxiv.org/pdf/2506.15799", "abs": "https://arxiv.org/abs/2506.15799", "authors": ["Andrew Wagenmaker", "Mitsuhiko Nakamoto", "Yunchu Zhang", "Seohong Park", "Waleed Yagoub", "Anusha Nagabandi", "Abhishek Gupta", "Sergey Levine"], "title": "Steering Your Diffusion Policy with Latent Space Reinforcement Learning", "categories": ["cs.RO", "cs.LG"], "comment": null, "summary": "Robotic control policies learned from human demonstrations have achieved\nimpressive results in many real-world applications. However, in scenarios where\ninitial performance is not satisfactory, as is often the case in novel\nopen-world settings, such behavioral cloning (BC)-learned policies typically\nrequire collecting additional human demonstrations to further improve their\nbehavior -- an expensive and time-consuming process. In contrast, reinforcement\nlearning (RL) holds the promise of enabling autonomous online policy\nimprovement, but often falls short of achieving this due to the large number of\nsamples it typically requires. In this work we take steps towards enabling fast\nautonomous adaptation of BC-trained policies via efficient real-world RL.\nFocusing in particular on diffusion policies -- a state-of-the-art BC\nmethodology -- we propose diffusion steering via reinforcement learning (DSRL):\nadapting the BC policy by running RL over its latent-noise space. We show that\nDSRL is highly sample efficient, requires only black-box access to the BC\npolicy, and enables effective real-world autonomous policy improvement.\nFurthermore, DSRL avoids many of the challenges associated with finetuning\ndiffusion policies, obviating the need to modify the weights of the base policy\nat all. We demonstrate DSRL on simulated benchmarks, real-world robotic tasks,\nand for adapting pretrained generalist policies, illustrating its sample\nefficiency and effective performance at real-world policy improvement.", "AI": {"tldr": "DSRL enables efficient autonomous improvement of BC-trained policies via RL in latent-noise space, avoiding costly human demonstrations and policy weight modifications.", "motivation": "Improving BC-learned policies traditionally requires expensive additional human demonstrations, while RL lacks sample efficiency. DSRL bridges this gap.", "method": "DSRL adapts BC policies by running RL over their latent-noise space, requiring only black-box access and no weight modifications.", "result": "DSRL is highly sample-efficient, effective in real-world tasks, and avoids challenges of finetuning diffusion policies.", "conclusion": "DSRL offers a practical solution for autonomous policy improvement, demonstrated across simulations and real-world applications."}}
{"id": "2501.10114", "pdf": "https://arxiv.org/pdf/2501.10114", "abs": "https://arxiv.org/abs/2501.10114", "authors": ["Alan Chan", "Kevin Wei", "Sihao Huang", "Nitarshan Rajkumar", "Elija Perrier", "Seth Lazar", "Gillian K. Hadfield", "Markus Anderljung"], "title": "Infrastructure for AI Agents", "categories": ["cs.AI"], "comment": "Accepted to TMLR", "summary": "AI agents plan and execute interactions in open-ended environments. For\nexample, OpenAI's Operator can use a web browser to do product comparisons and\nbuy online goods. Much research on making agents useful and safe focuses on\ndirectly modifying their behaviour, such as by training them to follow user\ninstructions. Direct behavioural modifications are useful, but do not fully\naddress how heterogeneous agents will interact with each other and other\nactors. Rather, we will need external protocols and systems to shape such\ninteractions. For instance, agents will need more efficient protocols to\ncommunicate with each other and form agreements. Attributing an agent's actions\nto a particular human or other legal entity can help to establish trust, and\nalso disincentivize misuse. Given this motivation, we propose the concept of\n\\textbf{agent infrastructure}: technical systems and shared protocols external\nto agents that are designed to mediate and influence their interactions with\nand impacts on their environments. Just as the Internet relies on protocols\nlike HTTPS, our work argues that agent infrastructure will be similarly\nindispensable to ecosystems of agents. We identify three functions for agent\ninfrastructure: 1) attributing actions, properties, and other information to\nspecific agents, their users, or other actors; 2) shaping agents' interactions;\nand 3) detecting and remedying harmful actions from agents. We provide an\nincomplete catalog of research directions for such functions. For each\ndirection, we include analysis of use cases, infrastructure adoption,\nrelationships to existing (internet) infrastructure, limitations, and open\nquestions. Making progress on agent infrastructure can prepare society for the\nadoption of more advanced agents.", "AI": {"tldr": "The paper proposes 'agent infrastructure'\u2014external systems and protocols to mediate AI agent interactions, addressing trust, communication, and safety in open-ended environments.", "motivation": "Heterogeneous AI agents need protocols for interaction and trust, as direct behavioral modifications alone are insufficient.", "method": "Introduces the concept of agent infrastructure with three functions: action attribution, interaction shaping, and harm detection/remediation.", "result": "Identifies research directions for agent infrastructure, analyzing use cases, adoption, and limitations.", "conclusion": "Agent infrastructure is essential for advanced AI ecosystems, akin to internet protocols, and requires further research."}}
{"id": "2506.02404", "pdf": "https://arxiv.org/pdf/2506.02404", "abs": "https://arxiv.org/abs/2506.02404", "authors": ["Yilin Xiao", "Junnan Dong", "Chuang Zhou", "Su Dong", "Qian-wen Zhang", "Di Yin", "Xing Sun", "Xiao Huang"], "title": "GraphRAG-Bench: Challenging Domain-Specific Reasoning for Evaluating Graph Retrieval-Augmented Generation", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Graph Retrieval Augmented Generation (GraphRAG) has garnered increasing\nrecognition for its potential to enhance large language models (LLMs) by\nstructurally organizing domain-specific corpora and facilitating complex\nreasoning. However, current evaluations of GraphRAG models predominantly rely\non traditional question-answering datasets. Their limited scope in questions\nand evaluation metrics fails to comprehensively assess the reasoning capacity\nimprovements enabled by GraphRAG models. To address this gap, we introduce\nGraphRAG-Bench, a large-scale, domain-specific benchmark designed to rigorously\nevaluate GraphRAG models. Our benchmark offers three key superiorities: \\((i)\\)\nChallenging question design. Featuring college-level, domain-specific questions\nthat demand multi-hop reasoning, the benchmark ensures that simple content\nretrieval is insufficient for problem-solving. For example, some questions\nrequire mathematical reasoning or programming. \\((ii)\\) Diverse task coverage.\nThe dataset includes a broad spectrum of reasoning tasks, multiple-choice,\ntrue/false, multi-select, open-ended, and fill-in-the-blank. It spans 16\ndisciplines in twenty core textbooks. \\((iii)\\) Holistic evaluation framework.\nGraphRAG-Bench provides comprehensive assessment across the entire GraphRAG\npipeline, including graph construction, knowledge retrieval, and answer\ngeneration. Beyond final-answer correctness, it evaluates the logical coherence\nof the reasoning process. By applying nine contemporary GraphRAG methods to\nGraphRAG-Bench, we demonstrate its utility in quantifying how graph-based\nstructuring improves model reasoning capabilities. Our analysis reveals\ncritical insights about graph architectures, retrieval efficacy, and reasoning\ncapabilities, offering actionable guidance for the research community.", "AI": {"tldr": "GraphRAG-Bench is introduced to rigorously evaluate GraphRAG models with challenging, domain-specific questions, diverse tasks, and a holistic framework, revealing insights into graph architectures and reasoning improvements.", "motivation": "Current evaluations of GraphRAG models lack comprehensive assessment of reasoning capacity improvements, relying on limited question-answering datasets.", "method": "GraphRAG-Bench features college-level, domain-specific questions requiring multi-hop reasoning, diverse task types, and a holistic evaluation framework covering the entire GraphRAG pipeline.", "result": "The benchmark demonstrates the utility of graph-based structuring in improving reasoning capabilities, revealing insights into graph architectures and retrieval efficacy.", "conclusion": "GraphRAG-Bench provides actionable guidance for the research community by quantifying the benefits of GraphRAG models and highlighting critical aspects of their performance."}}
{"id": "2407.12395", "pdf": "https://arxiv.org/pdf/2407.12395", "abs": "https://arxiv.org/abs/2407.12395", "authors": ["Sheng Miao", "Jiaxin Huang", "Dongfeng Bai", "Weichao Qiu", "Bingbing Liu", "Andreas Geiger", "Yiyi Liao"], "title": "Efficient Depth-Guided Urban View Synthesis", "categories": ["cs.CV"], "comment": "ECCV2024, Project page: https://xdimlab.github.io/EDUS/", "summary": "Recent advances in implicit scene representation enable high-fidelity street\nview novel view synthesis. However, existing methods optimize a neural radiance\nfield for each scene, relying heavily on dense training images and extensive\ncomputation resources. To mitigate this shortcoming, we introduce a new method\ncalled Efficient Depth-Guided Urban View Synthesis (EDUS) for fast feed-forward\ninference and efficient per-scene fine-tuning. Different from prior\ngeneralizable methods that infer geometry based on feature matching, EDUS\nleverages noisy predicted geometric priors as guidance to enable generalizable\nurban view synthesis from sparse input images. The geometric priors allow us to\napply our generalizable model directly in the 3D space, gaining robustness\nacross various sparsity levels. Through comprehensive experiments on the\nKITTI-360 and Waymo datasets, we demonstrate promising generalization abilities\non novel street scenes. Moreover, our results indicate that EDUS achieves\nstate-of-the-art performance in sparse view settings when combined with fast\ntest-time optimization.", "AI": {"tldr": "EDUS introduces a depth-guided method for efficient urban view synthesis from sparse images, outperforming existing methods in sparse settings.", "motivation": "Existing methods for novel view synthesis require dense training images and extensive computation, limiting practicality.", "method": "EDUS uses noisy predicted geometric priors to guide generalizable urban view synthesis, enabling robust performance with sparse inputs.", "result": "EDUS achieves state-of-the-art performance in sparse view settings and shows promising generalization on novel street scenes.", "conclusion": "EDUS offers a practical solution for efficient and generalizable urban view synthesis, especially in sparse input scenarios."}}
{"id": "2506.15836", "pdf": "https://arxiv.org/pdf/2506.15836", "abs": "https://arxiv.org/abs/2506.15836", "authors": ["Ziv Aharoni", "Bashar Huleihel", "Henry D Pfister", "Haim H Permuter"], "title": "Code Rate Optimization via Neural Polar Decoders", "categories": ["cs.IT", "cs.LG", "math.IT"], "comment": null, "summary": "This paper proposes a method to optimize communication code rates via the\napplication of neural polar decoders (NPDs). Employing this approach enables\nsimultaneous optimization of code rates over input distributions while\nproviding a practical coding scheme within the framework of polar codes. The\nproposed approach is designed for scenarios where the channel model is unknown,\ntreating the channel as a black box that produces output samples from input\nsamples. We employ polar codes to achieve our objectives, using NPDs to\nestimate mutual information (MI) between the channel inputs and outputs, and\noptimize a parametric model of the input distribution. The methodology involves\na two-phase process: a training phase and an inference phase. In the training\nphase, two steps are repeated interchangeably. First, the estimation step\nestimates the MI of the channel inputs and outputs via NPDs. Second, the\nimprovement step optimizes the input distribution parameters to maximize the MI\nestimate obtained by the NPDs. In the inference phase, the optimized model is\nused to construct polar codes. This involves incorporating the Honda-Yamamoto\n(HY) scheme to accommodate the optimized input distributions and list decoding\nto enhance decoding performance. Experimental results on memoryless and\nfinite-state channels (FSCs) demonstrate the effectiveness of our approach,\nparticularly in cases where the channel's capacity-achieving input distribution\nis non-uniform. For these cases, we show significant improvements in MI and bit\nerror rates (BERs) over those achieved by uniform and independent and\nidentically distributed (i.i.d.) input distributions, validating our method for\nblock lengths up to 1024. This scalable approach has potential applications in\nreal-world communication systems, bridging theoretical capacity estimation and\npractical coding performance.", "AI": {"tldr": "The paper introduces neural polar decoders (NPDs) to optimize communication code rates, especially for unknown channel models, by estimating mutual information (MI) and optimizing input distributions.", "motivation": "To address scenarios where the channel model is unknown, treating it as a black box, and to improve code rates and decoding performance beyond uniform input distributions.", "method": "A two-phase process: training (MI estimation and input distribution optimization via NPDs) and inference (constructing polar codes using the optimized model, HY scheme, and list decoding).", "result": "Significant improvements in MI and BERs for non-uniform input distributions, validated for block lengths up to 1024, outperforming uniform and i.i.d. distributions.", "conclusion": "The scalable method effectively bridges theoretical capacity estimation and practical coding, with potential real-world applications in communication systems."}}
{"id": "2501.15602", "pdf": "https://arxiv.org/pdf/2501.15602", "abs": "https://arxiv.org/abs/2501.15602", "authors": ["Zeyu Gan", "Yun Liao", "Yong Liu"], "title": "Rethinking External Slow-Thinking: From Snowball Errors to Probability of Correct Reasoning", "categories": ["cs.AI", "cs.CL"], "comment": "Published as a conference paper in ICML 2025", "summary": "Test-time scaling, which is also often referred to as slow-thinking, has been\ndemonstrated to enhance multi-step reasoning in large language models (LLMs).\nHowever, despite its widespread utilization, the mechanisms underlying\nslow-thinking methods remain poorly understood. This paper explores the\nmechanisms of external slow-thinking from a theoretical standpoint. We begin by\nexamining the snowball error effect within the LLM reasoning process and\nconnect it to the likelihood of correct reasoning using information theory.\nBuilding on this, we show that external slow-thinking methods can be\ninterpreted as strategies to mitigate the error probability. We further provide\na comparative analysis of popular external slow-thinking approaches, ranging\nfrom simple to complex, highlighting their differences and interrelationships.\nOur findings suggest that the efficacy of these methods is not primarily\ndetermined by the specific framework employed, and that expanding the search\nscope or the model's internal reasoning capacity may yield more sustained\nimprovements in the long term. We open-source our code at\nhttps://github.com/ZyGan1999/Snowball-Errors-and-Probability.", "AI": {"tldr": "The paper investigates the mechanisms of external slow-thinking (test-time scaling) in LLMs, linking it to reducing error probability in reasoning. It compares various methods and suggests broader search scope or internal reasoning improvements may be more effective.", "motivation": "To understand the poorly understood mechanisms behind slow-thinking methods in LLMs and their impact on reasoning errors.", "method": "Theoretical analysis of snowball errors in LLM reasoning, connecting it to information theory, and comparative analysis of slow-thinking approaches.", "result": "External slow-thinking methods mitigate error probability, but efficacy depends more on search scope or internal reasoning capacity than specific frameworks.", "conclusion": "Expanding search scope or internal reasoning capacity may offer more sustained improvements in LLM reasoning than specific slow-thinking frameworks."}}
{"id": "2506.06619", "pdf": "https://arxiv.org/pdf/2506.06619", "abs": "https://arxiv.org/abs/2506.06619", "authors": ["Jesse Woo", "Fateme Hashemi Chaleshtori", "Ana Marasovi\u0107", "Kenneth Marino"], "title": "BriefMe: A Legal NLP Benchmark for Assisting with Legal Briefs", "categories": ["cs.CL"], "comment": "ACL Findings 2025; 10 pages main, 5 pages references, 37 pages\n  appendix", "summary": "A core part of legal work that has been under-explored in Legal NLP is the\nwriting and editing of legal briefs. This requires not only a thorough\nunderstanding of the law of a jurisdiction, from judgments to statutes, but\nalso the ability to make new arguments to try to expand the law in a new\ndirection and make novel and creative arguments that are persuasive to judges.\nTo capture and evaluate these legal skills in language models, we introduce\nBRIEFME, a new dataset focused on legal briefs. It contains three tasks for\nlanguage models to assist legal professionals in writing briefs: argument\nsummarization, argument completion, and case retrieval. In this work, we\ndescribe the creation of these tasks, analyze them, and show how current models\nperform. We see that today's large language models (LLMs) are already quite\ngood at the summarization and guided completion tasks, even beating\nhuman-generated headings. Yet, they perform poorly on other tasks in our\nbenchmark: realistic argument completion and retrieving relevant legal cases.\nWe hope this dataset encourages more development in Legal NLP in ways that will\nspecifically aid people in performing legal work.", "AI": {"tldr": "The paper introduces BRIEFME, a dataset for evaluating language models in legal brief writing tasks like summarization, argument completion, and case retrieval. While LLMs excel in summarization and guided completion, they struggle with realistic argument completion and case retrieval.", "motivation": "Legal brief writing is under-explored in Legal NLP. It requires understanding law and crafting persuasive arguments, skills not yet fully captured in language models.", "method": "The authors created BRIEFME, a dataset with three tasks: argument summarization, argument completion, and case retrieval. They evaluated current LLMs on these tasks.", "result": "LLMs perform well on summarization and guided completion but poorly on realistic argument completion and case retrieval.", "conclusion": "BRIEFME aims to spur Legal NLP development to better assist legal professionals, highlighting current model limitations."}}
{"id": "2408.03291", "pdf": "https://arxiv.org/pdf/2408.03291", "abs": "https://arxiv.org/abs/2408.03291", "authors": ["Lianwei Yang", "Haisong Gong", "Haokun Lin", "Yichen Wu", "Zhenan Sun", "Qingyi Gu"], "title": "DopQ-ViT: Towards Distribution-Friendly and Outlier-Aware Post-Training Quantization for Vision Transformers", "categories": ["cs.CV"], "comment": null, "summary": "Vision Transformers (ViTs) have gained significant attention, but their high\ncomputing cost limits the practical applications. While post-training\nquantization (PTQ) reduces model size and speeds up inference, it often\ndegrades performance, especially in low-bit settings. We identify two key\nreasons for the performance degradation: 1) existing quantization methods fail\nto align with the power-law distribution of post-Softmax activations, and 2)\nreparameterizing post-LayerNorm activations leads to a performance drop due to\nthe significant influence of outliers in the scaling factors. To address these\nchallenges, we propose DopQ-ViT, a Distribution-friendly and Outlier-aware\nPost-training Quantization method for ViTs. First, DopQ-ViT introduces the Tan\nQuantizer (TanQ), which better preserves the power-law distribution of\npost-Softmax activations by focusing more on values near 1. Second, DopQ-ViT\npresents the MAD-guided Optimal Scaling Factor (MOSF), which selects the\noptimal scaling factor without introducing additional calculations. Extensive\nexperiments across various ViT models and quantization settings demonstrate\nthat DopQ-ViT, with the help of TanQ and MOSF, outperforms previous PTQ methods\non both classification and detection tasks.", "AI": {"tldr": "DopQ-ViT improves Vision Transformer (ViT) quantization by addressing power-law distribution alignment and outlier issues, outperforming prior methods.", "motivation": "High computing costs and performance degradation in low-bit quantization of ViTs limit practical applications.", "method": "Proposes DopQ-ViT with Tan Quantizer (TanQ) for power-law distribution alignment and MAD-guided Optimal Scaling Factor (MOSF) for outlier handling.", "result": "DopQ-ViT outperforms previous post-training quantization methods in classification and detection tasks.", "conclusion": "DopQ-ViT effectively addresses quantization challenges in ViTs, enhancing performance and practicality."}}
{"id": "2506.15906", "pdf": "https://arxiv.org/pdf/2506.15906", "abs": "https://arxiv.org/abs/2506.15906", "authors": ["Sawan Kumar", "Tapas Tripura", "Rajdip Nayek", "Souvik Chakraborty"], "title": "From Local Interactions to Global Operators: Scalable Gaussian Process Operator for Physical Systems", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "Operator learning offers a powerful paradigm for solving parametric partial\ndifferential equations (PDEs), but scaling probabilistic neural operators such\nas the recently proposed Gaussian Processes Operators (GPOs) to\nhigh-dimensional, data-intensive regimes remains a significant challenge. In\nthis work, we introduce a novel, scalable GPO, which capitalizes on sparsity,\nlocality, and structural information through judicious kernel design.\nAddressing the fundamental limitation of cubic computational complexity, our\nmethod leverages nearest-neighbor-based local kernel approximations in the\nspatial domain, sparse kernel approximation in the parameter space, and\nstructured Kronecker factorizations to enable tractable inference on\nlarge-scale datasets and high-dimensional input. While local approximations\noften introduce accuracy trade-offs due to limited kernel interactions, we\novercome this by embedding operator-aware kernel structures and employing\nexpressive, task-informed mean functions derived from neural operator\narchitectures. Through extensive evaluations on a broad class of nonlinear PDEs\n- including Navier-Stokes, wave advection, Darcy flow, and Burgers' equations -\nwe demonstrate that our framework consistently achieves high accuracy across\nvarying discretization scales. These results underscore the potential of our\napproach to bridge the gap between scalability and fidelity in GPO, offering a\ncompelling foundation for uncertainty-aware modeling in complex physical\nsystems.", "AI": {"tldr": "A scalable Gaussian Process Operator (GPO) method is proposed, leveraging sparsity, locality, and structured kernels to address computational challenges in high-dimensional PDEs.", "motivation": "To overcome the scalability limitations of probabilistic neural operators like GPOs in data-intensive, high-dimensional PDE settings.", "method": "Uses nearest-neighbor-based local kernel approximations, sparse kernel approximation in parameter space, and Kronecker factorizations. Incorporates operator-aware kernel structures and neural operator-derived mean functions.", "result": "Achieves high accuracy across various nonlinear PDEs (e.g., Navier-Stokes, Burgers' equations) at different discretization scales.", "conclusion": "The method bridges scalability and fidelity in GPOs, enabling uncertainty-aware modeling for complex physical systems."}}
{"id": "2502.07527", "pdf": "https://arxiv.org/pdf/2502.07527", "abs": "https://arxiv.org/abs/2502.07527", "authors": ["Yingce Xia", "Peiran Jin", "Shufang Xie", "Liang He", "Chuan Cao", "Renqian Luo", "Guoqing Liu", "Yue Wang", "Zequn Liu", "Yuan-Jyue Chen", "Zekun Guo", "Yeqi Bai", "Pan Deng", "Yaosen Min", "Ziheng Lu", "Hongxia Hao", "Han Yang", "Jielan Li", "Chang Liu", "Jia Zhang", "Jianwei Zhu", "Ran Bi", "Kehan Wu", "Wei Zhang", "Kaiyuan Gao", "Qizhi Pei", "Qian Wang", "Xixian Liu", "Yanting Li", "Houtian Zhu", "Yeqing Lu", "Mingqian Ma", "Zun Wang", "Tian Xie", "Krzysztof Maziarz", "Marwin Segler", "Zhao Yang", "Zilong Chen", "Yu Shi", "Shuxin Zheng", "Lijun Wu", "Chen Hu", "Peggy Dai", "Tie-Yan Liu", "Haiguang Liu", "Tao Qin"], "title": "Nature Language Model: Deciphering the Language of Nature for Scientific Discovery", "categories": ["cs.AI", "cs.LG"], "comment": "95 pages", "summary": "Foundation models have revolutionized natural language processing and\nartificial intelligence, significantly enhancing how machines comprehend and\ngenerate human languages. Inspired by the success of these foundation models,\nresearchers have developed foundation models for individual scientific domains,\nincluding small molecules, materials, proteins, DNA, RNA and even cells.\nHowever, these models are typically trained in isolation, lacking the ability\nto integrate across different scientific domains. Recognizing that entities\nwithin these domains can all be represented as sequences, which together form\nthe \"language of nature\", we introduce Nature Language Model (NatureLM), a\nsequence-based science foundation model designed for scientific discovery.\nPre-trained with data from multiple scientific domains, NatureLM offers a\nunified, versatile model that enables various applications including: (i)\ngenerating and optimizing small molecules, proteins, RNA, and materials using\ntext instructions; (ii) cross-domain generation/design, such as\nprotein-to-molecule and protein-to-RNA generation; and (iii) top performance\nacross different domains, matching or surpassing state-of-the-art specialist\nmodels. NatureLM offers a promising generalist approach for various scientific\ntasks, including drug discovery (hit generation/optimization, ADMET\noptimization, synthesis), novel material design, and the development of\ntherapeutic proteins or nucleotides. We have developed NatureLM models in\ndifferent sizes (1 billion, 8 billion, and 46.7 billion parameters) and\nobserved a clear improvement in performance as the model size increases.", "AI": {"tldr": "NatureLM is a unified, sequence-based foundation model for multiple scientific domains, enabling cross-domain applications and outperforming specialist models.", "motivation": "Existing foundation models for scientific domains operate in isolation, lacking integration. NatureLM addresses this by unifying diverse domains under a single model.", "method": "NatureLM is pre-trained on data from multiple scientific domains, representing entities as sequences. It supports tasks like cross-domain generation and optimization.", "result": "NatureLM matches or surpasses state-of-the-art specialist models, with performance improving as model size increases (1B to 46.7B parameters).", "conclusion": "NatureLM is a versatile, generalist model promising for scientific discovery, drug development, and material design."}}
{"id": "2506.06751", "pdf": "https://arxiv.org/pdf/2506.06751", "abs": "https://arxiv.org/abs/2506.06751", "authors": ["Mikhail Salnikov", "Dmitrii Korzh", "Ivan Lazichny", "Elvir Karimov", "Artyom Iudin", "Ivan Oseledets", "Oleg Y. Rogov", "Natalia Loukachevitch", "Alexander Panchenko", "Elena Tutubalina"], "title": "Geopolitical biases in LLMs: what are the \"good\" and the \"bad\" countries according to contemporary language models", "categories": ["cs.CL"], "comment": null, "summary": "This paper evaluates geopolitical biases in LLMs with respect to various\ncountries though an analysis of their interpretation of historical events with\nconflicting national perspectives (USA, UK, USSR, and China). We introduce a\nnovel dataset with neutral event descriptions and contrasting viewpoints from\ndifferent countries. Our findings show significant geopolitical biases, with\nmodels favoring specific national narratives. Additionally, simple debiasing\nprompts had a limited effect in reducing these biases. Experiments with\nmanipulated participant labels reveal models' sensitivity to attribution,\nsometimes amplifying biases or recognizing inconsistencies, especially with\nswapped labels. This work highlights national narrative biases in LLMs,\nchallenges the effectiveness of simple debiasing methods, and offers a\nframework and dataset for future geopolitical bias research.", "AI": {"tldr": "The paper evaluates geopolitical biases in LLMs by analyzing their interpretations of historical events from conflicting national perspectives (USA, UK, USSR, China). It introduces a dataset with neutral event descriptions and contrasting viewpoints, revealing significant biases favoring specific narratives. Simple debiasing methods were ineffective, and label manipulation experiments showed models' sensitivity to attribution.", "motivation": "To assess and highlight the presence of geopolitical biases in LLMs, particularly in their interpretations of historical events with conflicting national perspectives, and to evaluate the effectiveness of debiasing methods.", "method": "The study introduces a novel dataset with neutral event descriptions and contrasting national viewpoints. It evaluates LLMs' responses, tests simple debiasing prompts, and conducts experiments with manipulated participant labels to analyze bias sensitivity.", "result": "Findings reveal significant geopolitical biases in LLMs, favoring certain national narratives. Simple debiasing prompts had limited impact, and label manipulation experiments showed models' sensitivity to attribution, sometimes amplifying biases or recognizing inconsistencies.", "conclusion": "The work underscores the presence of national narrative biases in LLMs, challenges the efficacy of simple debiasing techniques, and provides a framework and dataset for future research on geopolitical bias."}}
{"id": "2408.08872", "pdf": "https://arxiv.org/pdf/2408.08872", "abs": "https://arxiv.org/abs/2408.08872", "authors": ["Le Xue", "Manli Shu", "Anas Awadalla", "Jun Wang", "An Yan", "Senthil Purushwalkam", "Honglu Zhou", "Viraj Prabhu", "Yutong Dai", "Michael S Ryoo", "Shrikant Kendre", "Jieyu Zhang", "Shaoyen Tseng", "Gustavo A Lujan-Moreno", "Matthew L Olson", "Musashi Hinck", "David Cobbley", "Vasudev Lal", "Can Qin", "Shu Zhang", "Chia-Chih Chen", "Ning Yu", "Juntao Tan", "Tulika Manoj Awalgaonkar", "Shelby Heinecke", "Huan Wang", "Yejin Choi", "Ludwig Schmidt", "Zeyuan Chen", "Silvio Savarese", "Juan Carlos Niebles", "Caiming Xiong", "Ran Xu"], "title": "xGen-MM (BLIP-3): A Family of Open Large Multimodal Models", "categories": ["cs.CV", "cs.AI", "cs.CL"], "comment": null, "summary": "This paper introduces BLIP-3, an open framework for developing Large\nMultimodal Models (LMMs). The framework comprises meticulously curated\ndatasets, a training recipe, model architectures, and a resulting suite of\nLMMs. We release 4B and 14B models, including both the pre-trained base model\nand the instruction fine-tuned ones. Our models undergo rigorous evaluation\nacross a range of tasks, including both single and multi-image benchmarks. Our\nmodels demonstrate competitive performance among open-source LMMs with similar\nmodel sizes. Our resulting LMMs demonstrate competitive performance among\nopen-source LMMs with similar model sizes, with the ability to comprehend\ninterleaved image-text inputs. Our training code, models, and all datasets used\nin this work, including the three largescale datasets we create and the\npreprocessed ones, will be open-sourced to better support the research\ncommunity.", "AI": {"tldr": "BLIP-3 is an open framework for Large Multimodal Models (LMMs), offering datasets, training recipes, and models (4B & 14B). It shows competitive performance and supports interleaved image-text inputs. All resources will be open-sourced.", "motivation": "To provide a comprehensive, open framework for developing LMMs and support the research community with datasets, models, and training code.", "method": "The framework includes curated datasets, training recipes, and model architectures. Models are pre-trained and fine-tuned, then evaluated on single and multi-image tasks.", "result": "BLIP-3 models achieve competitive performance among open-source LMMs of similar size, with strong comprehension of interleaved image-text inputs.", "conclusion": "BLIP-3 advances LMM development by offering open resources and competitive models, fostering further research in multimodal AI."}}
{"id": "2506.15958", "pdf": "https://arxiv.org/pdf/2506.15958", "abs": "https://arxiv.org/abs/2506.15958", "authors": ["Lucas Amoudruz", "Petr Karnakov", "Petros Koumoutsakos"], "title": "Contactless Precision Steering of Particles in a Fluid inside a Cube with Rotating Walls", "categories": ["physics.flu-dyn", "cs.LG", "cs.RO"], "comment": null, "summary": "Contactless manipulation of small objects is essential for biomedical and\nchemical applications, such as cell analysis, assisted fertilisation, and\nprecision chemistry. Established methods, including optical, acoustic, and\nmagnetic tweezers, are now complemented by flow control techniques that use\nflow-induced motion to enable precise and versatile manipulation. However,\ntrapping multiple particles in fluid remains a challenge. This study introduces\na novel control algorithm capable of steering multiple particles in flow. The\nsystem uses rotating disks to generate flow fields that transport particles to\nprecise locations. Disk rotations are governed by a feedback control policy\nbased on the Optimising a Discrete Loss (ODIL) framework, which combines fluid\ndynamics equations with path objectives into a single loss function. Our\nexperiments, conducted in both simulations and with the physical device,\ndemonstrate the capability of the approach to transport two beads\nsimultaneously to predefined locations, advancing robust contactless particle\nmanipulation for biomedical applications.", "AI": {"tldr": "A novel control algorithm for steering multiple particles in flow using rotating disks and feedback control, enabling precise contactless manipulation for biomedical applications.", "motivation": "Contactless manipulation of small objects is crucial for biomedical and chemical applications, but trapping multiple particles in fluid remains challenging.", "method": "Uses rotating disks to generate flow fields and a feedback control policy based on the ODIL framework, combining fluid dynamics with path objectives.", "result": "Successfully demonstrated simultaneous transport of two beads to predefined locations in simulations and physical experiments.", "conclusion": "Advances robust contactless particle manipulation, enhancing versatility for biomedical uses."}}
{"id": "2502.11422", "pdf": "https://arxiv.org/pdf/2502.11422", "abs": "https://arxiv.org/abs/2502.11422", "authors": ["Hui Wang", "Xufeng Zhang", "Chaoxu Mu"], "title": "Planning of Heuristics: Strategic Planning on Large Language Models with Monte Carlo Tree Search for Automating Heuristic Optimization", "categories": ["cs.AI"], "comment": "17 pages, 8 figures", "summary": "Heuristics have achieved great success in solving combinatorial optimization\nproblems~(COPs). However, heuristics designed by humans require too much domain\nknowledge and testing time. Since Large Language Models~(LLMs) possess strong\ncapabilities to understand and generate content with a knowledge base that\ncovers various domains, they offer potential ways to automatically optimize\nheuristics. To this end, we propose Planning of Heuristics~(PoH), an\noptimization method that integrates LLM self-reflection with Monte Carlo Tree\nSearch, a well-known planning algorithm. PoH iteratively refines generated\nheuristics by evaluating their performance and providing improvement\nsuggestions. Our method enables to iteratively evaluate the generated\nheuristics~(states) and improve them based on the improvement\nsuggestions~(actions) and evaluation results~(rewards), by effectively\nsimulating future states to search for paths with higher rewards. In this\npaper, we apply PoH to solve the Traveling Salesman Problem and the Flow Shop\nScheduling Problem. The experimental results show that PoH outperforms\nhand-crafted heuristics and other Automatic Heuristic Design methods based on\nLLMs, and achieves the state-of-the-art performance in automating heuristic\noptimization with LLMs to solve tested COPs, especially with large sizes.", "AI": {"tldr": "PoH integrates LLM self-reflection with Monte Carlo Tree Search to automate heuristic optimization for COPs, outperforming hand-crafted and other LLM-based methods.", "motivation": "Human-designed heuristics for COPs require extensive domain knowledge and testing time, while LLMs offer potential for automated optimization.", "method": "PoH combines LLM self-reflection and Monte Carlo Tree Search to iteratively refine heuristics by evaluating performance and simulating future states for higher rewards.", "result": "PoH achieves state-of-the-art performance in solving the Traveling Salesman Problem and Flow Shop Scheduling Problem, especially for large sizes.", "conclusion": "PoH demonstrates the effectiveness of LLMs in automating heuristic optimization for COPs, surpassing traditional and other LLM-based approaches."}}
{"id": "2506.07245", "pdf": "https://arxiv.org/pdf/2506.07245", "abs": "https://arxiv.org/abs/2506.07245", "authors": ["Wenxuan Xie", "Yaxun Dai", "Wenhao Jiang"], "title": "SDE-SQL: Enhancing Text-to-SQL Generation in Large Language Models via Self-Driven Exploration with SQL Probes", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Recent advancements in large language models (LLMs) have significantly\nimproved performance on the Text-to-SQL task. However, prior approaches\ntypically rely on static, pre-processed database information provided at\ninference time, which limits the model's ability to fully understand the\ndatabase contents. Without dynamic interaction, LLMs are constrained to fixed,\nhuman-provided context and cannot autonomously explore the underlying data. To\naddress this limitation, we propose SDE-SQL, a framework that enables large\nlanguage models to perform self-driven exploration of databases during\ninference. This is accomplished by generating and executing SQL probes, which\nallow the model to actively retrieve information from the database and\niteratively update its understanding of the data. Unlike prior methods, SDE-SQL\noperates in a zero-shot setting, without relying on any question-SQL pairs as\nin-context demonstrations. When evaluated on the BIRD benchmark with\nQwen2.5-72B-Instruct, SDE-SQL achieves an 8.02% relative improvement in\nexecution accuracy over the vanilla Qwen2.5-72B-Instruct baseline, establishing\na new state-of-the-art among methods based on open-source models without\nsupervised fine-tuning (SFT) or model ensembling. Moreover, with SFT, the\nperformance of SDE-SQL can be further enhanced, yielding an additional 0.52%\nimprovement.", "AI": {"tldr": "SDE-SQL enables LLMs to dynamically explore databases during inference, improving Text-to-SQL performance without relying on static context or in-context demonstrations.", "motivation": "Prior methods limit LLMs by using static database info, preventing autonomous exploration. SDE-SQL addresses this by allowing dynamic interaction.", "method": "SDE-SQL generates and executes SQL probes to iteratively retrieve and update database understanding, operating in a zero-shot setting.", "result": "Achieves 8.02% relative improvement in execution accuracy on BIRD benchmark, setting a new SOTA for open-source models without SFT or ensembling.", "conclusion": "SDE-SQL enhances LLM performance in Text-to-SQL tasks through dynamic exploration, with potential for further gains via SFT."}}
{"id": "2409.13609", "pdf": "https://arxiv.org/pdf/2409.13609", "abs": "https://arxiv.org/abs/2409.13609", "authors": ["Ting Liu", "Zunnan Xu", "Yue Hu", "Liangtao Shi", "Zhiqiang Wang", "Quanjun Yin"], "title": "MaPPER: Multimodal Prior-guided Parameter Efficient Tuning for Referring Expression Comprehension", "categories": ["cs.CV", "cs.AI", "cs.CL"], "comment": "EMNLP 2024 main", "summary": "Referring Expression Comprehension (REC), which aims to ground a local visual\nregion via natural language, is a task that heavily relies on multimodal\nalignment. Most existing methods utilize powerful pre-trained models to\ntransfer visual/linguistic knowledge by full fine-tuning. However, full\nfine-tuning the entire backbone not only breaks the rich prior knowledge\nembedded in the pre-training, but also incurs significant computational costs.\nMotivated by the recent emergence of Parameter-Efficient Transfer Learning\n(PETL) methods, we aim to solve the REC task in an effective and efficient\nmanner. Directly applying these PETL methods to the REC task is inappropriate,\nas they lack the specific-domain abilities for precise local visual perception\nand visual-language alignment. Therefore, we propose a novel framework of\nMultimodal Prior-guided Parameter Efficient Tuning, namely MaPPER.\nSpecifically, MaPPER comprises Dynamic Prior Adapters guided by an aligned\nprior, and Local Convolution Adapters to extract precise local semantics for\nbetter visual perception. Moreover, the Prior-Guided Text module is proposed to\nfurther utilize the prior for facilitating the cross-modal alignment.\nExperimental results on three widely-used benchmarks demonstrate that MaPPER\nachieves the best accuracy compared to the full fine-tuning and other PETL\nmethods with only 1.41% tunable backbone parameters. Our code is available at\nhttps://github.com/liuting20/MaPPER.", "AI": {"tldr": "The paper proposes MaPPER, a parameter-efficient framework for Referring Expression Comprehension (REC), addressing inefficiencies of full fine-tuning by leveraging multimodal alignment and local visual perception.", "motivation": "Full fine-tuning pre-trained models for REC breaks prior knowledge and is computationally expensive. Parameter-Efficient Transfer Learning (PETL) lacks domain-specific abilities for REC.", "method": "MaPPER uses Dynamic Prior Adapters and Local Convolution Adapters for precise local visual perception, and a Prior-Guided Text module for cross-modal alignment.", "result": "MaPPER outperforms full fine-tuning and other PETL methods on benchmarks, achieving top accuracy with only 1.41% tunable parameters.", "conclusion": "MaPPER is an effective and efficient solution for REC, balancing performance and computational cost."}}
{"id": "2506.16007", "pdf": "https://arxiv.org/pdf/2506.16007", "abs": "https://arxiv.org/abs/2506.16007", "authors": ["Peizhi Wu", "Rong Kang", "Tieying Zhang", "Jianjun Chen", "Ryan Marcus", "Zachary G. Ives"], "title": "Data-Agnostic Cardinality Learning from Imperfect Workloads", "categories": ["cs.DB", "cs.LG"], "comment": "14 pages. Technical Report (Extended Version)", "summary": "Cardinality estimation (CardEst) is a critical aspect of query optimization.\nTraditionally, it leverages statistics built directly over the data. However,\norganizational policies (e.g., regulatory compliance) may restrict global data\naccess. Fortunately, query-driven cardinality estimation can learn CardEst\nmodels using query workloads. However, existing query-driven models often\nrequire access to data or summaries for best performance, and they assume\nperfect training workloads with complete and balanced join templates (or join\ngraphs). Such assumptions rarely hold in real-world scenarios, in which join\ntemplates are incomplete and imbalanced. We present GRASP, a data-agnostic\ncardinality learning system designed to work under these real-world\nconstraints. GRASP's compositional design generalizes to unseen join templates\nand is robust to join template imbalance. It also introduces a new per-table\nCardEst model that handles value distribution shifts for range predicates, and\na novel learned count sketch model that captures join correlations across base\nrelations. Across three database instances, we demonstrate that GRASP\nconsistently outperforms existing query-driven models on imperfect workloads,\nboth in terms of estimation accuracy and query latency. Remarkably, GRASP\nachieves performance comparable to, or even surpassing, traditional approaches\nbuilt over the underlying data on the complex CEB-IMDb-full benchmark --\ndespite operating without any data access and using only 10% of all possible\njoin templates.", "AI": {"tldr": "GRASP is a data-agnostic cardinality estimation system that outperforms existing query-driven models on imperfect workloads, achieving accuracy and latency comparable to traditional methods without data access.", "motivation": "Organizational policies often restrict global data access, and existing query-driven models rely on unrealistic assumptions about training workloads (complete and balanced join templates). GRASP addresses these real-world constraints.", "method": "GRASP uses a compositional design for generalization to unseen join templates, a per-table model for range predicates, and a learned count sketch for join correlations.", "result": "GRASP outperforms existing query-driven models on imperfect workloads and matches traditional methods on the CEB-IMDb-full benchmark using only 10% of join templates.", "conclusion": "GRASP is a robust, data-agnostic solution for cardinality estimation, effective even under real-world constraints."}}
{"id": "2503.11702", "pdf": "https://arxiv.org/pdf/2503.11702", "abs": "https://arxiv.org/abs/2503.11702", "authors": ["Alberto Coffrini", "Paolo Barsocchi", "Francesco Furfari", "Antonino Crivello", "Alessio Ferrari"], "title": "LLM-Guided Indoor Navigation with Multimodal Map Understanding", "categories": ["cs.AI", "cs.CL", "cs.LG"], "comment": "7 pages, 3 figures, 5 tables", "summary": "Indoor navigation presents unique challenges due to complex layouts and the\nunavailability of GNSS signals. Existing solutions often struggle with\ncontextual adaptation, and typically require dedicated hardware. In this work,\nwe explore the potential of a Large Language Model (LLM), i.e., ChatGPT, to\ngenerate natural, context-aware navigation instructions from indoor map images.\nWe design and evaluate test cases across different real-world environments,\nanalyzing the effectiveness of LLMs in interpreting spatial layouts, handling\nuser constraints, and planning efficient routes. Our findings demonstrate the\npotential of LLMs for supporting personalized indoor navigation, with an\naverage of 86.59% correct indications and a maximum of 97.14%. The proposed\nsystem achieves high accuracy and reasoning performance. These results have key\nimplications for AI-driven navigation and assistive technologies.", "AI": {"tldr": "The paper explores using ChatGPT to generate context-aware indoor navigation instructions from map images, achieving high accuracy (86.59%-97.14%).", "motivation": "Indoor navigation is challenging due to complex layouts and lack of GNSS signals; existing solutions lack contextual adaptation and require dedicated hardware.", "method": "The study evaluates ChatGPT's ability to interpret spatial layouts, handle user constraints, and plan routes using indoor map images across real-world environments.", "result": "The system achieves an average of 86.59% correct indications, with a peak of 97.14%, demonstrating high accuracy and reasoning.", "conclusion": "LLMs like ChatGPT show strong potential for personalized indoor navigation and AI-driven assistive technologies."}}
{"id": "2506.08897", "pdf": "https://arxiv.org/pdf/2506.08897", "abs": "https://arxiv.org/abs/2506.08897", "authors": ["Hiba Khey", "Amine Lakhder", "Salma Rouichi", "Imane El Ghabi", "Kamal Hejjaoui", "Younes En-nahli", "Fahd Kalloubi", "Moez Amri"], "title": "PlantBert: An Open Source Language Model for Plant Science", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "The rapid advancement of transformer-based language models has catalyzed\nbreakthroughs in biomedical and clinical natural language processing; however,\nplant science remains markedly underserved by such domain-adapted tools. In\nthis work, we present PlantBert, a high-performance, open-source language model\nspecifically tailored for extracting structured knowledge from plant\nstress-response literature. Built upon the DeBERTa architecture-known for its\ndisentangled attention and robust contextual encoding-PlantBert is fine-tuned\non a meticulously curated corpus of expert-annotated abstracts, with a primary\nfocus on lentil (Lens culinaris) responses to diverse abiotic and biotic\nstressors. Our methodology combines transformer-based modeling with\nrule-enhanced linguistic post-processing and ontology-grounded entity\nnormalization, enabling PlantBert to capture biologically meaningful\nrelationships with precision and semantic fidelity. The underlying corpus is\nannotated using a hierarchical schema aligned with the Crop Ontology,\nencompassing molecular, physiological, biochemical, and agronomic dimensions of\nplant adaptation. PlantBert exhibits strong generalization capabilities across\nentity types and demonstrates the feasibility of robust domain adaptation in\nlow-resource scientific fields. By providing a scalable and reproducible\nframework for high-resolution entity recognition, PlantBert bridges a critical\ngap in agricultural NLP and paves the way for intelligent, data-driven systems\nin plant genomics, phenomics, and agronomic knowledge discovery. Our model is\npublicly released to promote transparency and accelerate cross-disciplinary\ninnovation in computational plant science.", "AI": {"tldr": "PlantBert is a transformer-based language model tailored for plant science, fine-tuned on expert-annotated abstracts to extract structured knowledge about plant stress responses, particularly in lentils.", "motivation": "Plant science lacks domain-adapted NLP tools despite advancements in transformer models. PlantBert addresses this gap by providing a specialized solution for extracting structured knowledge from plant stress-response literature.", "method": "PlantBert is built on DeBERTa, fine-tuned on annotated abstracts, and enhanced with linguistic post-processing and ontology-based normalization. It uses a hierarchical schema aligned with the Crop Ontology.", "result": "PlantBert shows strong generalization across entity types and demonstrates robust domain adaptation in low-resource fields. It enables high-resolution entity recognition in plant science.", "conclusion": "PlantBert bridges a critical gap in agricultural NLP, offering a scalable framework for knowledge extraction and fostering innovation in computational plant science. The model is open-source to promote transparency and collaboration."}}
{"id": "2410.11215", "pdf": "https://arxiv.org/pdf/2410.11215", "abs": "https://arxiv.org/abs/2410.11215", "authors": ["Suorong Yang", "Peng Ye", "Wanli Ouyang", "Dongzhan Zhou", "Furao Shen"], "title": "A CLIP-Powered Framework for Robust and Generalizable Data Selection", "categories": ["cs.CV"], "comment": "ICLR 2025 Spotlight", "summary": "Large-scale datasets have been pivotal to the advancements of deep learning\nmodels in recent years, but training on such large datasets invariably incurs\nsubstantial storage and computational overhead. Meanwhile, real-world datasets\noften contain redundant and noisy data, imposing a negative impact on training\nefficiency and model performance. Data selection has shown promise in\nidentifying the most representative samples from the entire dataset, which aims\nto minimize the performance gap with reduced training costs. Existing works\ntypically rely on single-modality information to assign importance scores for\nindividual samples, which may lead to inaccurate assessments, especially when\ndealing with noisy or corrupted samples. To address this limitation, we propose\na novel CLIP-powered data selection framework that leverages multimodal\ninformation for more robust and generalizable sample selection. Specifically,\nour framework consists of three key modules-dataset adaptation, sample scoring,\nand selection optimization-that together harness extensive pre-trained\nmultimodal knowledge to comprehensively assess sample influence and optimize\nthe selection results through multi-objective optimization. Extensive\nexperiments demonstrate that our approach consistently outperforms existing\nstate-of-the-art baselines on various benchmark datasets. Notably, our method\neffectively removes noisy or damaged samples from the dataset, enabling it to\nachieve even higher performance with less data. This indicates that it is not\nonly a way to accelerate training but can also improve overall data quality.", "AI": {"tldr": "A CLIP-powered data selection framework improves training efficiency and model performance by leveraging multimodal information to identify and remove noisy or redundant samples.", "motivation": "Large datasets often contain redundant or noisy data, negatively impacting training efficiency and model performance. Existing methods rely on single-modality information, which may be inaccurate.", "method": "Proposes a framework with three modules: dataset adaptation, sample scoring, and selection optimization, using multimodal pre-trained knowledge for robust sample selection.", "result": "Outperforms state-of-the-art baselines, removes noisy samples, and achieves higher performance with less data.", "conclusion": "The framework not only accelerates training but also improves data quality, demonstrating the value of multimodal information in data selection."}}
{"id": "2506.16079", "pdf": "https://arxiv.org/pdf/2506.16079", "abs": "https://arxiv.org/abs/2506.16079", "authors": ["Prakrut Kotecha", "Aditya Shirwatkar", "Shishir Kolathaya"], "title": "Investigating Lagrangian Neural Networks for Infinite Horizon Planning in Quadrupedal Locomotion", "categories": ["cs.RO", "cs.LG"], "comment": "6 pages, 5 figures, Accepted at Advances in Robotics (AIR) Conference\n  2025", "summary": "Lagrangian Neural Networks (LNNs) present a principled and interpretable\nframework for learning the system dynamics by utilizing inductive biases. While\ntraditional dynamics models struggle with compounding errors over long\nhorizons, LNNs intrinsically preserve the physical laws governing any system,\nenabling accurate and stable predictions essential for sustainable locomotion.\nThis work evaluates LNNs for infinite horizon planning in quadrupedal robots\nthrough four dynamics models: (1) full-order forward dynamics (FD) training and\ninference, (2) diagonalized representation of Mass Matrix in full order FD, (3)\nfull-order inverse dynamics (ID) training with FD inference, (4) reduced-order\nmodeling via torso centre-of-mass (CoM) dynamics. Experiments demonstrate that\nLNNs bring improvements in sample efficiency (10x) and superior prediction\naccuracy (up to 2-10x) compared to baseline methods. Notably, the\ndiagonalization approach of LNNs reduces computational complexity while\nretaining some interpretability, enabling real-time receding horizon control.\nThese findings highlight the advantages of LNNs in capturing the underlying\nstructure of system dynamics in quadrupeds, leading to improved performance and\nefficiency in locomotion planning and control. Additionally, our approach\nachieves a higher control frequency than previous LNN methods, demonstrating\nits potential for real-world deployment on quadrupeds.", "AI": {"tldr": "LNNs improve sample efficiency and prediction accuracy in quadrupedal robot dynamics, enabling real-time control and better locomotion planning.", "motivation": "Traditional dynamics models struggle with long-term errors, while LNNs preserve physical laws for stable predictions.", "method": "Evaluated four LNN-based dynamics models: full-order FD, diagonalized FD, full-order ID with FD inference, and reduced-order CoM dynamics.", "result": "LNNs achieve 10x sample efficiency, 2-10x accuracy gains, and real-time control with reduced computational complexity.", "conclusion": "LNNs excel in capturing system dynamics for quadrupeds, enhancing performance and efficiency in locomotion planning and control."}}
{"id": "2503.19990", "pdf": "https://arxiv.org/pdf/2503.19990", "abs": "https://arxiv.org/abs/2503.19990", "authors": ["Kexian Tang", "Junyao Gao", "Yanhong Zeng", "Haodong Duan", "Yanan Sun", "Zhening Xing", "Wenran Liu", "Kaifeng Lyu", "Kai Chen"], "title": "LEGO-Puzzles: How Good Are MLLMs at Multi-Step Spatial Reasoning?", "categories": ["cs.AI"], "comment": "11 pages, 3 figures", "summary": "Multi-step spatial reasoning entails understanding and reasoning about\nspatial relationships across multiple sequential steps, which is crucial for\ntackling complex real-world applications, such as robotic manipulation,\nautonomous navigation, and automated assembly. To assess how well current\nMultimodal Large Language Models (MLLMs) have acquired this fundamental\ncapability, we introduce LEGO-Puzzles, a scalable benchmark designed to\nevaluate both spatial understanding and sequential reasoning in MLLMs through\nLEGO-based tasks. LEGO-Puzzles consists of 1,100 carefully curated visual\nquestion-answering (VQA) samples spanning 11 distinct tasks, ranging from basic\nspatial understanding to complex multi-step reasoning. Based on LEGO-Puzzles,\nwe conduct a comprehensive evaluation of 20 state-of-the-art MLLMs and uncover\nsignificant limitations in their spatial reasoning capabilities: even the most\npowerful MLLMs can answer only about half of the test cases, whereas human\nparticipants achieve over 90% accuracy. Furthermore, based on LEGO-Puzzles, we\ndesign generation tasks to investigate whether MLLMs can transfer their spatial\nunderstanding and reasoning abilities to image generation. Our experiments show\nthat only GPT-4o and Gemini-2.0-Flash exhibit a limited ability to follow these\ninstructions, while other MLLMs either replicate the input image or generate\ncompletely irrelevant outputs. Overall, LEGO-Puzzles exposes critical\ndeficiencies in existing MLLMs' spatial understanding and sequential reasoning\ncapabilities, and underscores the need for further advancements in multimodal\nspatial reasoning.", "AI": {"tldr": "LEGO-Puzzles benchmark evaluates MLLMs' spatial reasoning, revealing significant gaps compared to humans, with GPT-4o and Gemini-2.0-Flash showing limited success in generation tasks.", "motivation": "Assess MLLMs' spatial and sequential reasoning for real-world applications like robotics and navigation.", "method": "Introduce LEGO-Puzzles, a VQA benchmark with 1,100 samples across 11 tasks, and evaluate 20 MLLMs.", "result": "MLLMs score ~50% accuracy vs. humans' 90%; only GPT-4o and Gemini-2.0-Flash show limited generation ability.", "conclusion": "MLLMs lack robust spatial reasoning, highlighting the need for further advancements in multimodal reasoning."}}
{"id": "2506.11903", "pdf": "https://arxiv.org/pdf/2506.11903", "abs": "https://arxiv.org/abs/2506.11903", "authors": ["Raphael Scheible-Schmitt", "Johann Frei"], "title": "GeistBERT: Breathing Life into German NLP", "categories": ["cs.CL"], "comment": null, "summary": "Advances in transformer-based language models have highlighted the benefits\nof language-specific pre-training on high-quality corpora. In this context,\nGerman NLP stands to gain from updated architectures and modern datasets\ntailored to the linguistic characteristics of the German language. GeistBERT\nseeks to improve German language processing by incrementally training on a\ndiverse corpus and optimizing model performance across various NLP tasks. It\nwas pre-trained using fairseq with standard hyperparameters, initialized from\nGottBERT weights, and trained on a large-scale German corpus using Whole Word\nMasking (WWM). Based on the pre-trained model, we derived extended-input\nvariants using Nystr\\\"omformer and Longformer architectures with support for\nsequences up to 8k tokens. While these long-context models were not evaluated\non dedicated long-context benchmarks, they are included in our release. We\nassessed all models on NER (CoNLL 2003, GermEval 2014) and text classification\n(GermEval 2018 fine/coarse, 10kGNAD) using $F_1$ score and accuracy. The\nGeistBERT models achieved strong performance, leading all tasks among the base\nmodels and setting a new state-of-the-art (SOTA). Notably, the base models\noutperformed larger models in several tasks. To support the German NLP research\ncommunity, we are releasing GeistBERT under the MIT license.", "AI": {"tldr": "GeistBERT improves German NLP by pre-training on a diverse corpus and optimizing performance across tasks, achieving SOTA results.", "motivation": "To enhance German language processing by leveraging updated architectures and tailored datasets.", "method": "Incremental training on a German corpus using Whole Word Masking, extended with Nystr\u00f6mformer and Longformer for long-context support.", "result": "Achieved top performance in NER and text classification tasks, outperforming larger models.", "conclusion": "GeistBERT sets a new SOTA for German NLP and is released under MIT license to support research."}}
{"id": "2410.21086", "pdf": "https://arxiv.org/pdf/2410.21086", "abs": "https://arxiv.org/abs/2410.21086", "authors": ["Jiyao Wang", "Xiao Yang", "Zhenyu Wang", "Ximeng Wei", "Ange Wang", "Dengbo He", "Kaishun Wu"], "title": "Efficient Mixture-of-Expert for Video-based Driver State and Physiological Multi-task Estimation in Conditional Autonomous Driving", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Road safety remains a critical challenge worldwide, with approximately 1.35\nmillion fatalities annually attributed to traffic accidents, often due to human\nerrors. As we advance towards higher levels of vehicle automation, challenges\nstill exist, as driving with automation can cognitively over-demand drivers if\nthey engage in non-driving-related tasks (NDRTs), or lead to drowsiness if\ndriving was the sole task. This calls for the urgent need for an effective\nDriver Monitoring System (DMS) that can evaluate cognitive load and drowsiness\nin SAE Level-2/3 autonomous driving contexts. In this study, we propose a novel\nmulti-task DMS, termed VDMoE, which leverages RGB video input to monitor driver\nstates non-invasively. By utilizing key facial features to minimize\ncomputational load and integrating remote Photoplethysmography (rPPG) for\nphysiological insights, our approach enhances detection accuracy while\nmaintaining efficiency. Additionally, we optimize the Mixture-of-Experts (MoE)\nframework to accommodate multi-modal inputs and improve performance across\ndifferent tasks. A novel prior-inclusive regularization method is introduced to\nalign model outputs with statistical priors, thus accelerating convergence and\nmitigating overfitting risks. We validate our method with the creation of a new\ndataset (MCDD), which comprises RGB video and physiological indicators from 42\nparticipants, and two public datasets. Our findings demonstrate the\neffectiveness of VDMoE in monitoring driver states, contributing to safer\nautonomous driving systems. The code and data will be released.", "AI": {"tldr": "The paper proposes VDMoE, a multi-task Driver Monitoring System (DMS) using RGB video and rPPG to detect cognitive load and drowsiness in autonomous driving, with improved accuracy and efficiency.", "motivation": "Addressing the need for effective DMS in SAE Level-2/3 autonomous driving to mitigate risks like cognitive overload and drowsiness caused by human errors or automation.", "method": "VDMoE leverages facial features and rPPG, optimizes the Mixture-of-Experts framework, and introduces prior-inclusive regularization for better performance.", "result": "Validated on a new dataset (MCDD) and public datasets, VDMoE shows effectiveness in monitoring driver states.", "conclusion": "VDMoE enhances safety in autonomous driving by accurately detecting driver states, with code and data to be released."}}
{"id": "2506.16089", "pdf": "https://arxiv.org/pdf/2506.16089", "abs": "https://arxiv.org/abs/2506.16089", "authors": ["Sean Moushegian", "Taposh Banerjee", "Vahid Tarokh"], "title": "Diffusion-Based Hypothesis Testing and Change-Point Detection", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "Score-based methods have recently seen increasing popularity in modeling and\ngeneration. Methods have been constructed to perform hypothesis testing and\nchange-point detection with score functions, but these methods are in general\nnot as powerful as their likelihood-based peers. Recent works consider\ngeneralizing the score-based Fisher divergence into a diffusion-divergence by\ntransforming score functions via multiplication with a matrix-valued function\nor a weight matrix. In this paper, we extend the score-based hypothesis test\nand change-point detection stopping rule into their diffusion-based analogs.\nAdditionally, we theoretically quantify the performance of these\ndiffusion-based algorithms and study scenarios where optimal performance is\nachievable. We propose a method of numerically optimizing the weight matrix and\npresent numerical simulations to illustrate the advantages of diffusion-based\nalgorithms.", "AI": {"tldr": "The paper extends score-based hypothesis testing and change-point detection to diffusion-based methods, optimizing performance with a weight matrix and demonstrating advantages through simulations.", "motivation": "Score-based methods are less powerful than likelihood-based ones, prompting the generalization of score-based Fisher divergence into diffusion-divergence for improved performance.", "method": "Extends score-based tests to diffusion-based analogs, optimizes weight matrix numerically, and evaluates performance theoretically and via simulations.", "result": "Theoretical quantification of diffusion-based algorithms' performance and scenarios for optimality, with numerical simulations showing advantages.", "conclusion": "Diffusion-based algorithms outperform score-based methods, with optimized weight matrices enhancing performance, supported by theoretical and empirical evidence."}}
{"id": "2504.09440", "pdf": "https://arxiv.org/pdf/2504.09440", "abs": "https://arxiv.org/abs/2504.09440", "authors": ["MingShan Liu", "Jialing Fang"], "title": "Enhancing Mathematical Reasoning in Large Language Models with Self-Consistency-Based Hallucination Detection", "categories": ["cs.AI"], "comment": null, "summary": "Large language models (LLMs) have demonstrated strong mathematical reasoning\ncapabilities but remain susceptible to hallucinations producing plausible yet\nincorrect statements especially in theorem proving, symbolic manipulation, and\nnumerical computation. While self-consistency (SC) has been explored as a means\nto improve factuality in LLMs, existing approaches primarily apply SC to\nfinal-answer selection, neglecting the logical consistency of intermediate\nreasoning steps. In this work, we introduce a structured self-consistency\nframework designed to enhance the reliability of mathematical reasoning. Our\nmethod enforces self-consistency across intermediate steps and final outputs,\nreducing logical inconsistencies and hallucinations. We evaluate our approach\nacross three core mathematical tasks: theorem proving, symbolic transformation,\nand numerical computation. Experimental results demonstrate that SC\nsignificantly improves proof validity, symbolic reasoning accuracy, and\nnumerical stability while maintaining computational efficiency. Further\nanalysis reveals that structured self-consistency not only enhances\nproblem-solving accuracy but also reduces the variance of model-generated\noutputs. These findings highlight self-consistency as a robust mechanism for\nimproving mathematical reasoning in LLMs, paving the way for more reliable and\ninterpretable AI-driven mathematics.", "AI": {"tldr": "A structured self-consistency framework improves LLM reliability in mathematical reasoning by enforcing consistency in intermediate steps and final outputs, reducing hallucinations and enhancing accuracy.", "motivation": "LLMs exhibit strong mathematical reasoning but suffer from hallucinations, especially in theorem proving, symbolic manipulation, and numerical computation. Existing self-consistency methods focus on final answers, ignoring intermediate logical consistency.", "method": "Introduces a structured self-consistency framework to enforce consistency across reasoning steps and outputs, evaluated on theorem proving, symbolic transformation, and numerical computation.", "result": "SC improves proof validity, symbolic reasoning accuracy, and numerical stability while reducing output variance, maintaining computational efficiency.", "conclusion": "Structured self-consistency enhances LLM reliability in mathematical tasks, offering a path to more interpretable and accurate AI-driven mathematics."}}
{"id": "2506.12307", "pdf": "https://arxiv.org/pdf/2506.12307", "abs": "https://arxiv.org/abs/2506.12307", "authors": ["Xiaotian Zhang", "Yuan Wang", "Zhaopeng Feng", "Ruizhe Chen", "Zhijie Zhou", "Yan Zhang", "Hongxia Xu", "Jian Wu", "Zuozhu Liu"], "title": "Med-U1: Incentivizing Unified Medical Reasoning in LLMs via Large-scale Reinforcement Learning", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Medical Question-Answering (QA) encompasses a broad spectrum of tasks,\nincluding multiple choice questions (MCQ), open-ended text generation, and\ncomplex computational reasoning. Despite this variety, a unified framework for\ndelivering high-quality medical QA has yet to emerge. Although recent progress\nin reasoning-augmented large language models (LLMs) has shown promise, their\nability to achieve comprehensive medical understanding is still largely\nunexplored. In this paper, we present Med-U1, a unified framework for robust\nreasoning across medical QA tasks with diverse output formats, ranging from\nMCQs to complex generation and computation tasks. Med-U1 employs pure\nlarge-scale reinforcement learning with mixed rule-based binary reward\nfunctions, incorporating a length penalty to manage output verbosity. With\nmulti-objective reward optimization, Med-U1 directs LLMs to produce concise and\nverifiable reasoning chains. Empirical results reveal that Med-U1 significantly\nimproves performance across multiple challenging Med-QA benchmarks, surpassing\neven larger specialized and proprietary models. Furthermore, Med-U1\ndemonstrates robust generalization to out-of-distribution (OOD) tasks.\nExtensive analysis presents insights into training strategies, reasoning chain\nlength control, and reward design for medical LLMs. Our code is available here.", "AI": {"tldr": "Med-U1 is a unified framework for medical QA tasks, using reinforcement learning to improve performance and generalization across diverse formats.", "motivation": "The lack of a unified framework for high-quality medical QA tasks, despite recent advancements in LLMs, motivates the development of Med-U1.", "method": "Med-U1 employs large-scale reinforcement learning with mixed rule-based binary rewards and a length penalty to optimize reasoning chains.", "result": "Med-U1 outperforms specialized and proprietary models on Med-QA benchmarks and shows robust OOD generalization.", "conclusion": "Med-U1 provides a scalable solution for medical QA, with insights into training, reasoning control, and reward design for LLMs."}}
{"id": "2410.23623", "pdf": "https://arxiv.org/pdf/2410.23623", "abs": "https://arxiv.org/abs/2410.23623", "authors": ["Xiufeng Song", "Xiao Guo", "Jiache Zhang", "Qirui Li", "Lei Bai", "Xiaoming Liu", "Guangtao Zhai", "Xiaohong Liu"], "title": "On Learning Multi-Modal Forgery Representation for Diffusion Generated Video Detection", "categories": ["cs.CV"], "comment": "10 pages, 9 figures, published in NeurIPS 2024", "summary": "Large numbers of synthesized videos from diffusion models pose threats to\ninformation security and authenticity, leading to an increasing demand for\ngenerated content detection. However, existing video-level detection algorithms\nprimarily focus on detecting facial forgeries and often fail to identify\ndiffusion-generated content with a diverse range of semantics. To advance the\nfield of video forensics, we propose an innovative algorithm named Multi-Modal\nDetection(MM-Det) for detecting diffusion-generated videos. MM-Det utilizes the\nprofound perceptual and comprehensive abilities of Large Multi-modal Models\n(LMMs) by generating a Multi-Modal Forgery Representation (MMFR) from LMM's\nmulti-modal space, enhancing its ability to detect unseen forgery content.\nBesides, MM-Det leverages an In-and-Across Frame Attention (IAFA) mechanism for\nfeature augmentation in the spatio-temporal domain. A dynamic fusion strategy\nhelps refine forgery representations for the fusion. Moreover, we construct a\ncomprehensive diffusion video dataset, called Diffusion Video Forensics (DVF),\nacross a wide range of forgery videos. MM-Det achieves state-of-the-art\nperformance in DVF, demonstrating the effectiveness of our algorithm. Both\nsource code and DVF are available at https://github.com/SparkleXFantasy/MM-Det.", "AI": {"tldr": "MM-Det is a novel algorithm for detecting diffusion-generated videos, leveraging multi-modal models and attention mechanisms for improved performance.", "motivation": "The rise of synthesized videos from diffusion models threatens information security, but existing detection methods fail to address diverse semantic content.", "method": "MM-Det uses Large Multi-modal Models (LMMs) to generate Multi-Modal Forgery Representation (MMFR) and employs an In-and-Across Frame Attention (IAFA) mechanism for feature augmentation. A dynamic fusion strategy refines forgery representations.", "result": "MM-Det achieves state-of-the-art performance on the Diffusion Video Forensics (DVF) dataset.", "conclusion": "MM-Det effectively detects diffusion-generated videos, advancing video forensics with its multi-modal approach and attention mechanisms."}}
{"id": "2506.16224", "pdf": "https://arxiv.org/pdf/2506.16224", "abs": "https://arxiv.org/abs/2506.16224", "authors": ["Bishwajit Prasad Gond", "Rajneekant", "Pushkar Kishore", "Durga Prasad Mohapatra"], "title": "Malware Classification Leveraging NLP & Machine Learning for Enhanced Accuracy", "categories": ["cs.CR", "cs.LG"], "comment": null, "summary": "This paper investigates the application of natural language processing\n(NLP)-based n-gram analysis and machine learning techniques to enhance malware\nclassification. We explore how NLP can be used to extract and analyze textual\nfeatures from malware samples through n-grams, contiguous string or API call\nsequences. This approach effectively captures distinctive linguistic patterns\namong malware and benign families, enabling finer-grained classification. We\ndelve into n-gram size selection, feature representation, and classification\nalgorithms. While evaluating our proposed method on real-world malware samples,\nwe observe significantly improved accuracy compared to the traditional methods.\nBy implementing our n-gram approach, we achieved an accuracy of 99.02% across\nvarious machine learning algorithms by using hybrid feature selection technique\nto address high dimensionality. Hybrid feature selection technique reduces the\nfeature set to only 1.6% of the original features.", "AI": {"tldr": "The paper proposes using NLP-based n-gram analysis and machine learning for malware classification, achieving 99.02% accuracy with hybrid feature selection.", "motivation": "To improve malware classification by leveraging NLP techniques to analyze textual features from malware samples.", "method": "Uses n-gram analysis for feature extraction, explores n-gram size selection, feature representation, and classification algorithms, and employs hybrid feature selection to reduce dimensionality.", "result": "Achieved 99.02% accuracy, reducing features to 1.6% of the original set.", "conclusion": "The NLP-based n-gram approach significantly enhances malware classification accuracy compared to traditional methods."}}
{"id": "2504.15699", "pdf": "https://arxiv.org/pdf/2504.15699", "abs": "https://arxiv.org/abs/2504.15699", "authors": ["Ning Wang", "Zihan Yan", "Weiyang Li", "Chuan Ma", "He Chen", "Tao Xiang"], "title": "Advancing Embodied Agent Security: From Safety Benchmarks to Input Moderation", "categories": ["cs.AI"], "comment": "9 pages", "summary": "Embodied agents exhibit immense potential across a multitude of domains,\nmaking the assurance of their behavioral safety a fundamental prerequisite for\ntheir widespread deployment. However, existing research predominantly\nconcentrates on the security of general large language models, lacking\nspecialized methodologies for establishing safety benchmarks and input\nmoderation tailored to embodied agents. To bridge this gap, this paper\nintroduces a novel input moderation framework, meticulously designed to\nsafeguard embodied agents. This framework encompasses the entire pipeline,\nincluding taxonomy definition, dataset curation, moderator architecture, model\ntraining, and rigorous evaluation. Notably, we introduce EAsafetyBench, a\nmeticulously crafted safety benchmark engineered to facilitate both the\ntraining and stringent assessment of moderators specifically designed for\nembodied agents. Furthermore, we propose Pinpoint, an innovative\nprompt-decoupled input moderation scheme that harnesses a masked attention\nmechanism to effectively isolate and mitigate the influence of functional\nprompts on moderation tasks. Extensive experiments conducted on diverse\nbenchmark datasets and models validate the feasibility and efficacy of the\nproposed approach. The results demonstrate that our methodologies achieve an\nimpressive average detection accuracy of 94.58%, surpassing the performance of\nexisting state-of-the-art techniques, alongside an exceptional moderation\nprocessing time of merely 0.002 seconds per instance.", "AI": {"tldr": "The paper introduces a novel input moderation framework for embodied agents, including a safety benchmark (EAsafetyBench) and a prompt-decoupled moderation scheme (Pinpoint), achieving high accuracy and efficiency.", "motivation": "Existing research lacks specialized safety methodologies for embodied agents, necessitating a tailored approach to ensure behavioral safety.", "method": "The framework includes taxonomy definition, dataset curation, moderator architecture, model training, and evaluation. It introduces EAsafetyBench and Pinpoint, a prompt-decoupled moderation scheme using masked attention.", "result": "The approach achieves 94.58% average detection accuracy and 0.002 seconds per instance moderation time, outperforming existing methods.", "conclusion": "The proposed framework effectively addresses the safety gap for embodied agents, demonstrating high accuracy and efficiency."}}
{"id": "2506.13610", "pdf": "https://arxiv.org/pdf/2506.13610", "abs": "https://arxiv.org/abs/2506.13610", "authors": ["Abdullah Al Shafi", "Rowzatul Zannat", "Abdul Muntakim", "Mahmudul Hasan"], "title": "A Structured Dataset of Disease-Symptom Associations to Improve Diagnostic Accuracy", "categories": ["cs.CL"], "comment": "Preprint", "summary": "Disease-symptom datasets are significant and in demand for medical research,\ndisease diagnosis, clinical decision-making, and AI-driven health management\napplications. These datasets help identify symptom patterns associated with\nspecific diseases, thus improving diagnostic accuracy and enabling early\ndetection. The dataset presented in this study systematically compiles\ndisease-symptom relationships from various online sources, medical literature,\nand publicly available health databases. The data was gathered through\nanalyzing peer-reviewed medical articles, clinical case studies, and\ndisease-symptom association reports. Only the verified medical sources were\nincluded in the dataset, while those from non-peer-reviewed and anecdotal\nsources were excluded. The dataset is structured in a tabular format, where the\nfirst column represents diseases, and the remaining columns represent symptoms.\nEach symptom cell contains a binary value (1 or 0), indicating whether a\nsymptom is associated with a disease (1 for presence, 0 for absence). Thereby,\nthis structured representation makes the dataset very useful for a wide range\nof applications, including machine learning-based disease prediction, clinical\ndecision support systems, and epidemiological studies. Although there are some\nadvancements in the field of disease-symptom datasets, there is a significant\ngap in structured datasets for the Bangla language. This dataset aims to bridge\nthat gap by facilitating the development of multilingual medical informatics\ntools and improving disease prediction models for underrepresented linguistic\ncommunities. Further developments should include region-specific diseases and\nfurther fine-tuning of symptom associations for better diagnostic performance", "AI": {"tldr": "A structured disease-symptom dataset compiled from verified medical sources, presented in a binary tabular format, aims to improve diagnostic accuracy and support AI-driven health applications, with a focus on addressing gaps in Bangla-language datasets.", "motivation": "To meet the demand for reliable disease-symptom datasets for medical research, diagnosis, and AI applications, while addressing the lack of structured datasets for underrepresented languages like Bangla.", "method": "Systematic compilation from peer-reviewed medical articles, clinical studies, and verified sources, structured in a binary tabular format (diseases vs. symptoms).", "result": "A structured dataset useful for machine learning, clinical decision support, and epidemiological studies, with potential for multilingual applications.", "conclusion": "The dataset bridges a gap in Bangla-language resources and highlights the need for region-specific disease inclusion and symptom association refinement for better diagnostics."}}
{"id": "2411.05261", "pdf": "https://arxiv.org/pdf/2411.05261", "abs": "https://arxiv.org/abs/2411.05261", "authors": ["Yingying Fang", "Zihao Jin", "Shaojie Guo", "Jinda Liu", "Zhiling Yue", "Yijian Gao", "Junzhi Ning", "Zhi Li", "Simon Walsh", "Guang Yang"], "title": "Cyclic Vision-Language Manipulator: Towards Reliable and Fine-Grained Image Interpretation for Automated Report Generation", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.LG"], "comment": null, "summary": "Despite significant advancements in automated report generation, the\nopaqueness of text interpretability continues to cast doubt on the reliability\nof the content produced. This paper introduces a novel approach to identify\nspecific image features in X-ray images that influence the outputs of report\ngeneration models. Specifically, we propose Cyclic Vision-Language Manipulator\nCVLM, a module to generate a manipulated X-ray from an original X-ray and its\nreport from a designated report generator. The essence of CVLM is that cycling\nmanipulated X-rays to the report generator produces altered reports aligned\nwith the alterations pre-injected into the reports for X-ray generation,\nachieving the term \"cyclic manipulation\". This process allows direct comparison\nbetween original and manipulated X-rays, clarifying the critical image features\ndriving changes in reports and enabling model users to assess the reliability\nof the generated texts. Empirical evaluations demonstrate that CVLM can\nidentify more precise and reliable features compared to existing explanation\nmethods, significantly enhancing the transparency and applicability of\nAI-generated reports.", "AI": {"tldr": "The paper introduces CVLM, a method to identify image features in X-rays that influence AI-generated reports, enhancing transparency and reliability.", "motivation": "To address the opacity and unreliability of AI-generated reports by clarifying which image features drive report changes.", "method": "Proposes Cyclic Vision-Language Manipulator (CVLM), which manipulates X-rays and reports cyclically to pinpoint critical features.", "result": "CVLM identifies more precise features than existing methods, improving report transparency.", "conclusion": "CVLM enhances the reliability and applicability of AI-generated reports by clarifying feature influences."}}
{"id": "2506.16233", "pdf": "https://arxiv.org/pdf/2506.16233", "abs": "https://arxiv.org/abs/2506.16233", "authors": ["Chenrui Ma", "Zechang Sun", "Tao Jing", "Zheng Cai", "Yuan-Sen Ting", "Song Huang", "Mingyu Li"], "title": "Can AI Dream of Unseen Galaxies? Conditional Diffusion Model for Galaxy Morphology Augmentation", "categories": ["astro-ph.GA", "cs.LG"], "comment": "We have submitted to AAS journals. See another independent work for\n  further reference -- Category-based Galaxy Image Generation via Diffusion\n  Models (Fan, Tang et al.). Comments are welcome", "summary": "Observational astronomy relies on visual feature identification to detect\ncritical astrophysical phenomena. While machine learning (ML) increasingly\nautomates this process, models often struggle with generalization in\nlarge-scale surveys due to the limited representativeness of labeled datasets\n-- whether from simulations or human annotation -- a challenge pronounced for\nrare yet scientifically valuable objects. To address this, we propose a\nconditional diffusion model to synthesize realistic galaxy images for\naugmenting ML training data. Leveraging the Galaxy Zoo 2 dataset which contains\nvisual feature -- galaxy image pairs from volunteer annotation, we demonstrate\nthat our model generates diverse, high-fidelity galaxy images closely adhere to\nthe specified morphological feature conditions. Moreover, this model enables\ngenerative extrapolation to project well-annotated data into unseen domains and\nadvancing rare object detection. Integrating synthesized images into ML\npipelines improves performance in standard morphology classification, boosting\ncompleteness and purity by up to 30\\% across key metrics. For rare object\ndetection, using early-type galaxies with prominent dust lane features (\n$\\sim$0.1\\% in GZ2 dataset) as a test case, our approach doubled the number of\ndetected instances from 352 to 872, compared to previous studies based on\nvisual inspection. This study highlights the power of generative models to\nbridge gaps between scarce labeled data and the vast, uncharted parameter space\nof observational astronomy and sheds insight for future astrophysical\nfoundation model developments. Our project homepage is available at\nhttps://galaxysd-webpage.streamlit.app/.", "AI": {"tldr": "A conditional diffusion model is proposed to generate realistic galaxy images for augmenting ML training data, improving classification and rare object detection in astronomy.", "motivation": "Address the challenge of limited representativeness in labeled datasets for ML models in astronomy, especially for rare objects.", "method": "Use a conditional diffusion model trained on the Galaxy Zoo 2 dataset to synthesize diverse, high-fidelity galaxy images based on specified morphological features.", "result": "Improved ML performance in morphology classification (up to 30% boost) and doubled rare object detection (from 352 to 872 instances).", "conclusion": "Generative models can bridge gaps in labeled data, enhancing ML applications in astronomy and informing future astrophysical models."}}
{"id": "2504.20007", "pdf": "https://arxiv.org/pdf/2504.20007", "abs": "https://arxiv.org/abs/2504.20007", "authors": ["Anita Srbinovska", "Angela Srbinovska", "Vivek Senthil", "Adrian Martin", "John McCluskey", "Jonathan Bateman", "Ernest Fokou\u00e9"], "title": "Towards AI-Driven Policing: Interdisciplinary Knowledge Discovery from Police Body-Worn Camera Footage", "categories": ["cs.AI", "cs.CV"], "comment": "7 pages, 3 figures, and 1 table", "summary": "This paper proposes a novel interdisciplinary framework for analyzing police\nbody-worn camera (BWC) footage from the Rochester Police Department (RPD) using\nadvanced artificial intelligence (AI) and statistical machine learning (ML)\ntechniques. Our goal is to detect, classify, and analyze patterns of\ninteraction between police officers and civilians to identify key behavioral\ndynamics, such as respect, disrespect, escalation, and de-escalation. We apply\nmultimodal data analysis by integrating image, audio, and natural language\nprocessing (NLP) techniques to extract meaningful insights from BWC footage.\nThe framework incorporates speaker separation, transcription, and large\nlanguage models (LLMs) to produce structured, interpretable summaries of\npolice-civilian encounters. We also employ a custom evaluation pipeline to\nassess transcription quality and behavior detection accuracy in high-stakes,\nreal-world policing scenarios. Our methodology, computational techniques, and\nfindings outline a practical approach for law enforcement review, training, and\naccountability processes while advancing the frontiers of knowledge discovery\nfrom complex police BWC data.", "AI": {"tldr": "A novel AI and ML framework analyzes police BWC footage to detect and classify interaction patterns, integrating multimodal data for insights on behavior dynamics like respect and escalation.", "motivation": "To identify key behavioral dynamics in police-civilian interactions for law enforcement review, training, and accountability.", "method": "Uses multimodal data analysis (image, audio, NLP), speaker separation, transcription, LLMs, and a custom evaluation pipeline.", "result": "Produces structured summaries of encounters and assesses transcription and behavior detection accuracy.", "conclusion": "The framework advances knowledge discovery from BWC data and supports practical law enforcement applications."}}
{"id": "2506.13681", "pdf": "https://arxiv.org/pdf/2506.13681", "abs": "https://arxiv.org/abs/2506.13681", "authors": ["Rylan Schaeffer", "Joshua Kazdan", "Yegor Denisov-Blanch"], "title": "Min-p, Max Exaggeration: A Critical Analysis of Min-p Sampling in Language Models", "categories": ["cs.CL", "cs.LG"], "comment": null, "summary": "Sampling from language models impacts the quality and diversity of outputs,\naffecting both research and real-world applications. Recently, Nguyen et al.\n2024's \"Turning Up the Heat: Min-p Sampling for Creative and Coherent LLM\nOutputs\" introduced a new sampler called min-p, claiming it achieves superior\nquality and diversity over established samplers such as basic, top-k, and top-p\nsampling. The significance of these claims was underscored by the paper's\nrecognition as the 18th highest-scoring submission to ICLR 2025 and selection\nfor an Oral presentation. This paper conducts a comprehensive re-examination of\nthe evidence supporting min-p and reaches different conclusions from the\noriginal paper's four lines of evidence. First, the original paper's human\nevaluations omitted data, conducted statistical tests incorrectly, and\ndescribed qualitative feedback inaccurately; our reanalysis demonstrates min-p\ndid not outperform baselines in quality, diversity, or a trade-off between\nquality and diversity; in response to our findings, the authors of the original\npaper conducted a new human evaluation using a different implementation, task,\nand rubric that nevertheless provides further evidence min-p does not improve\nover baselines. Second, comprehensively sweeping the original paper's NLP\nbenchmarks reveals min-p does not surpass baselines when controlling for the\nnumber of hyperparameters. Third, the original paper's LLM-as-a-Judge\nevaluations lack methodological clarity and appear inconsistently reported.\nFourth, community adoption claims (49k GitHub repositories, 1.1M GitHub stars)\nwere found to be unsubstantiated, leading to their removal; the revised\nadoption claim remains misleading. We conclude that evidence presented in the\noriginal paper fails to support claims that min-p improves quality, diversity,\nor a trade-off between quality and diversity.", "AI": {"tldr": "The paper re-examines claims about the min-p sampling method, finding no evidence it outperforms baselines in quality, diversity, or trade-offs, contrary to the original study.", "motivation": "To critically evaluate the evidence supporting min-p sampling's superiority over existing methods.", "method": "Reanalysis of human evaluations, NLP benchmarks, LLM-as-a-Judge evaluations, and community adoption claims from the original paper.", "result": "Min-p does not outperform baselines in quality, diversity, or trade-offs; original claims were unsupported or misleading.", "conclusion": "The evidence does not support min-p's claimed advantages over established sampling methods."}}
{"id": "2411.15397", "pdf": "https://arxiv.org/pdf/2411.15397", "abs": "https://arxiv.org/abs/2411.15397", "authors": ["Leonidas Gee", "Wing Yan Li", "Viktoriia Sharmanska", "Novi Quadrianto"], "title": "Efficient Online Inference of Vision Transformers by Training-Free Tokenization", "categories": ["cs.CV"], "comment": null, "summary": "The cost of deploying vision transformers increasingly represents a barrier\nto wider industrial adoption. Existing compression techniques require\nadditional end-to-end fine-tuning or incur a significant drawback to runtime,\nmaking them ill-suited for online (real-time) inference, where a prediction is\nmade on any new input as it comes in. We introduce the $\\textbf{Visual Word\nTokenizer}$ (VWT), a training-free method for reducing energy costs while\nretaining performance and runtime. The VWT groups visual subwords (image\npatches) that are frequently used into visual words while infrequent ones\nremain intact. To do so, $\\textit{intra}$-image or $\\textit{inter}$-image\nstatistics are leveraged to identify similar visual concepts for sequence\ncompression. Experimentally, we demonstrate a reduction in wattage of up to 25%\nwith only a 20% increase in runtime at most. Comparative approaches of 8-bit\nquantization and token merging achieve a lower or similar energy efficiency but\nexact a higher toll on runtime (up to 100% or more). Our results indicate that\nVWTs are well-suited for efficient online inference with a marginal compromise\non performance.", "AI": {"tldr": "The paper introduces the Visual Word Tokenizer (VWT), a training-free method to reduce energy costs in vision transformers while maintaining performance and runtime, making it suitable for real-time inference.", "motivation": "The high cost of deploying vision transformers and the limitations of existing compression techniques (requiring fine-tuning or increasing runtime) hinder industrial adoption, especially for real-time inference.", "method": "VWT groups frequently used visual subwords (image patches) into visual words, leveraging intra- or inter-image statistics for sequence compression without additional training.", "result": "VWT reduces wattage by up to 25% with only a 20% runtime increase, outperforming 8-bit quantization and token merging in energy efficiency and runtime impact.", "conclusion": "VWT is effective for efficient online inference with minimal performance compromise, offering a practical solution for industrial applications."}}
{"id": "2506.16283", "pdf": "https://arxiv.org/pdf/2506.16283", "abs": "https://arxiv.org/abs/2506.16283", "authors": ["Mike Nguyen", "Nicole M\u00fccke"], "title": "Random feature approximation for general spectral methods", "categories": ["stat.ML", "cs.LG"], "comment": "arXiv admin note: substantial text overlap with arXiv:2308.15434,\n  arXiv:2412.17518", "summary": "Random feature approximation is arguably one of the most widely used\ntechniques for kernel methods in large-scale learning algorithms. In this work,\nwe analyze the generalization properties of random feature methods, extending\nprevious results for Tikhonov regularization to a broad class of spectral\nregularization techniques. This includes not only explicit methods but also\nimplicit schemes such as gradient descent and accelerated algorithms like the\nHeavy-Ball and Nesterov method. Through this framework, we enable a theoretical\nanalysis of neural networks and neural operators through the lens of the Neural\nTangent Kernel (NTK) approach trained via gradient descent. For our estimators\nwe obtain optimal learning rates over regularity classes (even for classes that\nare not included in the reproducing kernel Hilbert space), which are defined\nthrough appropriate source conditions. This improves or completes previous\nresults obtained in related settings for specific kernel algorithms.", "AI": {"tldr": "Analyzes generalization properties of random feature methods, extending Tikhonov regularization to spectral techniques, including gradient descent and accelerated algorithms, with optimal learning rates.", "motivation": "To broaden the theoretical understanding of random feature methods and their generalization properties, extending beyond Tikhonov regularization to include implicit schemes like gradient descent and neural networks.", "method": "Extends spectral regularization techniques to analyze random feature methods, including explicit and implicit schemes (e.g., gradient descent, Heavy-Ball, Nesterov). Uses Neural Tangent Kernel (NTK) for neural networks.", "result": "Achieves optimal learning rates over regularity classes, even for those outside the reproducing kernel Hilbert space, improving previous results.", "conclusion": "The framework provides a comprehensive theoretical analysis of random feature methods and neural networks, offering optimal learning rates and extending prior work."}}
{"id": "2505.09518", "pdf": "https://arxiv.org/pdf/2505.09518", "abs": "https://arxiv.org/abs/2505.09518", "authors": ["Maris F. L. Galesloot", "Roman Andriushchenko", "Milan \u010ce\u0161ka", "Sebastian Junges", "Nils Jansen"], "title": "Robust Finite-Memory Policy Gradients for Hidden-Model POMDPs", "categories": ["cs.AI", "cs.LG"], "comment": "Accepted for publication at IJCAI 2025", "summary": "Partially observable Markov decision processes (POMDPs) model specific\nenvironments in sequential decision-making under uncertainty. Critically,\noptimal policies for POMDPs may not be robust against perturbations in the\nenvironment. Hidden-model POMDPs (HM-POMDPs) capture sets of different\nenvironment models, that is, POMDPs with a shared action and observation space.\nThe intuition is that the true model is hidden among a set of potential models,\nand it is unknown which model will be the environment at execution time. A\npolicy is robust for a given HM-POMDP if it achieves sufficient performance for\neach of its POMDPs.We compute such robust policies by combining two orthogonal\ntechniques: (1) a deductive formal verification technique that supports\ntractable robust policy evaluation by computing a worst-case POMDP within the\nHM-POMDP, and (2) subgradient ascent to optimize the candidate policy for a\nworst-case POMDP. The empirical evaluation shows that, compared to various\nbaselines, our approach (1) produces policies that are more robust and\ngeneralize better to unseen POMDPs, and (2) scales to HM-POMDPs that consist of\nover a hundred thousand environments.", "AI": {"tldr": "The paper introduces Hidden-model POMDPs (HM-POMDPs) to address non-robustness in POMDP policies. It combines formal verification and subgradient ascent to compute robust policies, showing improved robustness and scalability.", "motivation": "Optimal POMDP policies lack robustness against environmental perturbations. HM-POMDPs model uncertainty by considering multiple potential environments, aiming to find policies that perform well across all.", "method": "The approach combines deductive formal verification to identify worst-case POMDPs and subgradient ascent to optimize policies for robustness.", "result": "Empirical results demonstrate the method produces more robust policies, generalizes better to unseen POMDPs, and scales to large HM-POMDPs (over 100,000 environments).", "conclusion": "The proposed method effectively computes robust policies for HM-POMDPs, outperforming baselines in robustness and scalability."}}
{"id": "2506.14028", "pdf": "https://arxiv.org/pdf/2506.14028", "abs": "https://arxiv.org/abs/2506.14028", "authors": ["Xueqing Peng", "Lingfei Qian", "Yan Wang", "Ruoyu Xiang", "Yueru He", "Yang Ren", "Mingyang Jiang", "Jeff Zhao", "Huan He", "Yi Han", "Yun Feng", "Yuechen Jiang", "Yupeng Cao", "Haohang Li", "Yangyang Yu", "Xiaoyu Wang", "Penglei Gao", "Shengyuan Lin", "Keyi Wang", "Shanshan Yang", "Yilun Zhao", "Zhiwei Liu", "Peng Lu", "Jerry Huang", "Suyuchen Wang", "Triantafillos Papadopoulos", "Polydoros Giannouris", "Efstathia Soufleri", "Nuo Chen", "Guojun Xiong", "Zhiyang Deng", "Yijia Zhao", "Mingquan Lin", "Meikang Qiu", "Kaleb E Smith", "Arman Cohan", "Xiao-Yang Liu", "Jimin Huang", "Alejandro Lopez-Lira", "Xi Chen", "Junichi Tsujii", "Jian-Yun Nie", "Sophia Ananiadou", "Qianqian Xie"], "title": "MultiFinBen: A Multilingual, Multimodal, and Difficulty-Aware Benchmark for Financial LLM Evaluation", "categories": ["cs.CL"], "comment": null, "summary": "Recent advances in large language models (LLMs) have accelerated progress in\nfinancial NLP and applications, yet existing benchmarks remain limited to\nmonolingual and unimodal settings, often over-relying on simple tasks and\nfailing to reflect the complexity of real-world financial communication. We\nintroduce MultiFinBen, the first multilingual and multimodal benchmark tailored\nto the global financial domain, evaluating LLMs across modalities (text,\nvision, audio) and linguistic settings (monolingual, bilingual, multilingual)\non domain-specific tasks. We introduce two novel tasks, including PolyFiQA-Easy\nand PolyFiQA-Expert, the first multilingual financial benchmarks requiring\nmodels to perform complex reasoning over mixed-language inputs; and EnglishOCR\nand SpanishOCR, the first OCR-embedded financial QA tasks challenging models to\nextract and reason over information from visual-text financial documents.\nMoreover, we propose a dynamic, difficulty-aware selection mechanism and curate\na compact, balanced benchmark rather than simple aggregation existing datasets.\nExtensive evaluation of 22 state-of-the-art models reveals that even the\nstrongest models, despite their general multimodal and multilingual\ncapabilities, struggle dramatically when faced with complex cross-lingual and\nmultimodal tasks in financial domain. MultiFinBen is publicly released to\nfoster transparent, reproducible, and inclusive progress in financial studies\nand applications.", "AI": {"tldr": "MultiFinBen is a multilingual, multimodal benchmark for evaluating LLMs in the financial domain, introducing novel tasks and revealing gaps in current models' capabilities.", "motivation": "Existing benchmarks for financial NLP are limited to monolingual and unimodal settings, failing to capture real-world complexity.", "method": "Introduces MultiFinBen with tasks like PolyFiQA and OCR-embedded QA, using a dynamic difficulty-aware selection mechanism.", "result": "Evaluation of 22 models shows struggles with complex cross-lingual and multimodal financial tasks.", "conclusion": "MultiFinBen aims to advance transparent and inclusive progress in financial NLP."}}
{"id": "2412.11224", "pdf": "https://arxiv.org/pdf/2412.11224", "abs": "https://arxiv.org/abs/2412.11224", "authors": ["Shrisha Bharadwaj", "Haiwen Feng", "Giorgio Becherini", "Victoria Fernandez Abrevaya", "Michael J. Black"], "title": "GenLit: Reformulating Single-Image Relighting as Video Generation", "categories": ["cs.CV", "cs.GR"], "comment": null, "summary": "Manipulating the illumination of a 3D scene within a single image represents\na fundamental challenge in computer vision and graphics. This problem has\ntraditionally been addressed using inverse rendering techniques, which involve\nexplicit 3D asset reconstruction and costly ray-tracing simulations. Meanwhile,\nrecent advancements in visual foundation models suggest that a new paradigm\ncould soon be possible -- one that replaces explicit physical models with\nnetworks that are trained on large amounts of image and video data. In this\npaper, we exploit the physical world understanding of a video diffusion model,\nparticularly Stable Video Diffusion, to relight a single image. We introduce\nGenLit, a framework that distills the ability of a graphics engine to perform\nlight manipulation into a video-generation model, enabling users to directly\ninsert and manipulate a point light in the 3D world within a given image, and\ngenerate results directly as a video sequence. We find that a model fine-tuned\non only a small synthetic dataset generalizes to real-world scenes, enabling\nsingle-image relighting with plausible and convincing shadows. Our results\nhighlight the ability of video foundation models to capture rich information\nabout lighting, material, and, shape and our findings indicate that such\nmodels, with minimal training, can be used to perform relighting without\nexplicit asset reconstruction or complex ray tracing. Project page:\nhttps://genlit.is.tue.mpg.de/.", "AI": {"tldr": "GenLit uses a video diffusion model (Stable Video Diffusion) to relight single images without explicit 3D reconstruction or ray tracing, achieving plausible results with minimal training.", "motivation": "Traditional inverse rendering for scene relighting is costly and complex. Recent visual foundation models offer a simpler, data-driven alternative.", "method": "GenLit distills light manipulation capabilities from a graphics engine into a video-generation model, enabling direct point-light manipulation in images.", "result": "The model generalizes to real-world scenes with convincing shadows, even when fine-tuned on a small synthetic dataset.", "conclusion": "Video foundation models can effectively perform relighting without explicit 3D reconstruction, showcasing their potential for lighting and material understanding."}}
{"id": "2506.16289", "pdf": "https://arxiv.org/pdf/2506.16289", "abs": "https://arxiv.org/abs/2506.16289", "authors": ["Oswaldo Ludwig"], "title": "The Condition Number as a Scale-Invariant Proxy for Information Encoding in Neural Units", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "This paper explores the relationship between the condition number of a neural\nnetwork's weight tensor and the extent of information encoded by the associated\nprocessing unit, viewed through the lens of information theory. We argue that a\nhigh condition number, though not sufficient for effective knowledge encoding,\nmay indicate that the unit has learned to selectively amplify and compress\ninformation. We formalize this intuition, particularly for linear units with\nGaussian inputs, linking the condition number and the transformation's\nlog-volume scaling factor to the characteristics of the output entropy and the\ngeometric properties of the learned transformation. Our analysis demonstrates\nthat for a fixed weight norm, a concentrated distribution of singular values\n(high condition number) corresponds to reduced overall information transfer,\nindicating a specialized and efficient encoding strategy. Furthermore, we\npresent a practical case study where these principles are applied to guide\nselective fine-tuning of a multimodal Large Language Model, aiming to mitigate\ncatastrophic forgetting during cross-modal adaptation. Unlike many existing\ncatastrophic forgetting mitigation methods that rely on access to pre-training\nstatistics, which are often unavailable, our selective fine-tuning approach\noffers a way to bypass this common requirement.", "AI": {"tldr": "The paper links a neural network's weight tensor condition number to information encoding efficiency, showing high condition numbers indicate selective amplification and compression. It applies this to mitigate catastrophic forgetting in multimodal models.", "motivation": "To understand how the condition number of neural network weights relates to information encoding and use this insight to improve model fine-tuning.", "method": "Theoretical analysis of linear units with Gaussian inputs, linking condition number to output entropy and geometric properties, followed by a practical case study on selective fine-tuning.", "result": "High condition numbers correspond to reduced information transfer, indicating specialized encoding. Selective fine-tuning successfully mitigates catastrophic forgetting without pre-training statistics.", "conclusion": "The condition number is a useful indicator of information encoding efficiency, and selective fine-tuning based on this principle can improve model adaptation."}}
{"id": "2505.20094", "pdf": "https://arxiv.org/pdf/2505.20094", "abs": "https://arxiv.org/abs/2505.20094", "authors": ["Qi Li", "Kun Li", "Haozhi Han", "Honghui Shang", "Xinfu He", "Yunquan Zhang", "Hong An", "Ting Cao", "Mao Yang"], "title": "SwarmThinkers: Learning Physically Consistent Atomic KMC Transitions at Scale", "categories": ["cs.AI"], "comment": null, "summary": "Can a scientific simulation system be physically consistent, interpretable by\ndesign, and scalable across regimes--all at once? Despite decades of progress,\nthis trifecta remains elusive. Classical methods like Kinetic Monte Carlo\nensure thermodynamic accuracy but scale poorly; learning-based methods offer\nefficiency but often sacrifice physical consistency and interpretability. We\npresent SwarmThinkers, a reinforcement learning framework that recasts\natomic-scale simulation as a physically grounded swarm intelligence system.\nEach diffusing particle is modeled as a local decision-making agent that\nselects transitions via a shared policy network trained under thermodynamic\nconstraints. A reweighting mechanism fuses learned preferences with transition\nrates, preserving statistical fidelity while enabling interpretable, step-wise\ndecision making. Training follows a centralized-training,\ndecentralized-execution paradigm, allowing the policy to generalize across\nsystem sizes, concentrations, and temperatures without retraining. On a\nbenchmark simulating radiation-induced Fe-Cu alloy precipitation, SwarmThinkers\nis the first system to achieve full-scale, physically consistent simulation on\na single A100 GPU, previously attainable only via OpenKMC on a supercomputer.\nIt delivers up to 4963x (3185x on average) faster computation with 485x lower\nmemory usage. By treating particles as decision-makers, not passive samplers,\nSwarmThinkers marks a paradigm shift in scientific simulation--one that unifies\nphysical consistency, interpretability, and scalability through agent-driven\nintelligence.", "AI": {"tldr": "SwarmThinkers is a reinforcement learning framework for atomic-scale simulation, combining physical consistency, interpretability, and scalability by modeling particles as decision-making agents.", "motivation": "Classical methods like Kinetic Monte Carlo are accurate but inefficient, while learning-based methods sacrifice physical consistency and interpretability. SwarmThinkers aims to unify these qualities.", "method": "Particles are modeled as agents using a shared policy network trained under thermodynamic constraints. A reweighting mechanism ensures statistical fidelity and interpretability.", "result": "Achieves full-scale, physically consistent simulation on a single GPU, outperforming supercomputer-based methods with up to 4963x faster computation and 485x lower memory usage.", "conclusion": "SwarmThinkers represents a paradigm shift by unifying physical consistency, interpretability, and scalability through agent-driven intelligence."}}
{"id": "2506.14111", "pdf": "https://arxiv.org/pdf/2506.14111", "abs": "https://arxiv.org/abs/2506.14111", "authors": ["Essential AI", ":", "Andrew Hojel", "Michael Pust", "Tim Romanski", "Yash Vanjani", "Ritvik Kapila", "Mohit Parmar", "Adarsh Chaluvaraju", "Alok Tripathy", "Anil Thomas", "Ashish Tanwer", "Darsh J Shah", "Ishaan Shah", "Karl Stratos", "Khoi Nguyen", "Kurt Smith", "Michael Callahan", "Peter Rushton", "Philip Monk", "Platon Mazarakis", "Saad Jamal", "Saurabh Srivastava", "Somanshu Singla", "Ashish Vaswani"], "title": "Essential-Web v1.0: 24T tokens of organized web data", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "include MegaMath-Web-Pro", "summary": "Data plays the most prominent role in how language models acquire skills and\nknowledge. The lack of massive, well-organized pre-training datasets results in\ncostly and inaccessible data pipelines. We present Essential-Web v1.0, a\n24-trillion-token dataset in which every document is annotated with a\ntwelve-category taxonomy covering topic, format, content complexity, and\nquality. Taxonomy labels are produced by EAI-Distill-0.5b, a fine-tuned\n0.5b-parameter model that achieves an annotator agreement within 3% of\nQwen2.5-32B-Instruct. With nothing more than SQL-style filters, we obtain\ncompetitive web-curated datasets in math (-8.0% relative to SOTA), web code\n(+14.3%), STEM (+24.5%) and medical (+8.6%). Essential-Web v1.0 is available on\nHuggingFace: https://huggingface.co/datasets/EssentialAI/essential-web-v1.0", "AI": {"tldr": "Essential-Web v1.0 is a 24-trillion-token dataset with a twelve-category taxonomy, enabling efficient data filtering for competitive performance in specialized domains like math, web code, STEM, and medical.", "motivation": "The lack of massive, well-organized pre-training datasets leads to costly and inaccessible data pipelines, hindering language model development.", "method": "The dataset is annotated using EAI-Distill-0.5b, a fine-tuned model achieving high annotator agreement. SQL-style filters are used to curate specialized datasets.", "result": "Competitive performance in math (-8.0% relative to SOTA), web code (+14.3%), STEM (+24.5%), and medical (+8.6%) domains.", "conclusion": "Essential-Web v1.0 provides a scalable, high-quality dataset solution for diverse language model applications."}}
{"id": "2412.13183", "pdf": "https://arxiv.org/pdf/2412.13183", "abs": "https://arxiv.org/abs/2412.13183", "authors": ["Guoxing Sun", "Rishabh Dabral", "Heming Zhu", "Pascal Fua", "Christian Theobalt", "Marc Habermann"], "title": "Real-time Free-view Human Rendering from Sparse-view RGB Videos using Double Unprojected Textures", "categories": ["cs.CV"], "comment": "Accepted at CVPR 2025, Project page:\n  https://vcai.mpi-inf.mpg.de/projects/DUT/", "summary": "Real-time free-view human rendering from sparse-view RGB inputs is a\nchallenging task due to the sensor scarcity and the tight time budget. To\nensure efficiency, recent methods leverage 2D CNNs operating in texture space\nto learn rendering primitives. However, they either jointly learn geometry and\nappearance, or completely ignore sparse image information for geometry\nestimation, significantly harming visual quality and robustness to unseen body\nposes. To address these issues, we present Double Unprojected Textures, which\nat the core disentangles coarse geometric deformation estimation from\nappearance synthesis, enabling robust and photorealistic 4K rendering in\nreal-time. Specifically, we first introduce a novel image-conditioned template\ndeformation network, which estimates the coarse deformation of the human\ntemplate from a first unprojected texture. This updated geometry is then used\nto apply a second and more accurate texture unprojection. The resulting texture\nmap has fewer artifacts and better alignment with input views, which benefits\nour learning of finer-level geometry and appearance represented by Gaussian\nsplats. We validate the effectiveness and efficiency of the proposed method in\nquantitative and qualitative experiments, which significantly surpasses other\nstate-of-the-art methods. Project page:\nhttps://vcai.mpi-inf.mpg.de/projects/DUT/", "AI": {"tldr": "The paper introduces Double Unprojected Textures (DUT) for real-time, high-quality human rendering from sparse RGB inputs by disentangling geometry and appearance estimation.", "motivation": "Addressing the challenges of sensor scarcity and tight time budgets in real-time human rendering, the paper aims to improve visual quality and robustness to unseen poses.", "method": "DUT uses a two-step process: first, a coarse geometric deformation is estimated from an unprojected texture, then a second, more accurate texture unprojection refines the geometry and appearance using Gaussian splats.", "result": "The method achieves robust and photorealistic 4K rendering in real-time, outperforming state-of-the-art techniques in quality and efficiency.", "conclusion": "DUT effectively disentangles geometry and appearance, enabling high-quality real-time rendering from sparse inputs."}}
{"id": "2506.16332", "pdf": "https://arxiv.org/pdf/2506.16332", "abs": "https://arxiv.org/abs/2506.16332", "authors": ["Lukas Gonon", "Rodrigo Mart\u00ednez-Pe\u00f1a", "Juan-Pablo Ortega"], "title": "Feedback-driven recurrent quantum neural network universality", "categories": ["quant-ph", "cs.LG"], "comment": "31 pages", "summary": "Quantum reservoir computing uses the dynamics of quantum systems to process\ntemporal data, making it particularly well-suited for learning with noisy\nintermediate-scale quantum devices. Early experimental proposals, such as the\nrestarting and rewinding protocols, relied on repeating previous steps of the\nquantum map to avoid backaction. However, this approach compromises real-time\nprocessing and increases computational overhead. Recent developments have\nintroduced alternative protocols that address these limitations. These include\nonline, mid-circuit measurement, and feedback techniques, which enable\nreal-time computation while preserving the input history. Among these, the\nfeedback protocol stands out for its ability to process temporal information\nwith comparatively fewer components. Despite this potential advantage, the\ntheoretical foundations of feedback-based quantum reservoir computing remain\nunderdeveloped, particularly with regard to the universality and the\napproximation capabilities of this approach. This paper addresses this issue by\npresenting a recurrent quantum neural network architecture that extends a class\nof existing feedforward models to a dynamic, feedback-driven reservoir setting.\nWe provide theoretical guarantees for variational recurrent quantum neural\nnetworks, including approximation bounds and universality results. Notably, our\nanalysis demonstrates that the model is universal with linear readouts, making\nit both powerful and experimentally accessible. These results pave the way for\npractical and theoretically grounded quantum reservoir computing with real-time\nprocessing capabilities.", "AI": {"tldr": "The paper introduces a recurrent quantum neural network for feedback-based quantum reservoir computing, addressing underdeveloped theoretical foundations and demonstrating universality with linear readouts.", "motivation": "To overcome limitations of early quantum reservoir computing protocols (e.g., restarting/rewinding) and develop a theoretically grounded, real-time processing approach.", "method": "Proposes a recurrent quantum neural network architecture extending feedforward models to a feedback-driven reservoir setting, with theoretical analysis.", "result": "The model is universal with linear readouts, offering approximation bounds and practical accessibility.", "conclusion": "The work advances practical, theoretically sound quantum reservoir computing with real-time capabilities."}}
{"id": "2505.20246", "pdf": "https://arxiv.org/pdf/2505.20246", "abs": "https://arxiv.org/abs/2505.20246", "authors": ["Jiahao Qiu", "Fulian Xiao", "Yimin Wang", "Yuchen Mao", "Yijia Chen", "Xinzhe Juan", "Shu Zhang", "Siran Wang", "Xuan Qi", "Tongcheng Zhang", "Zixin Yao", "Jiacheng Guo", "Yifu Lu", "Charles Argon", "Jundi Cui", "Daixin Chen", "Junran Zhou", "Shuyao Zhou", "Zhanpeng Zhou", "Ling Yang", "Shilong Liu", "Hongru Wang", "Kaixuan Huang", "Xun Jiang", "Yuming Cao", "Yue Chen", "Yunfei Chen", "Zhengyi Chen", "Ruowei Dai", "Mengqiu Deng", "Jiye Fu", "Yunting Gu", "Zijie Guan", "Zirui Huang", "Xiaoyan Ji", "Yumeng Jiang", "Delong Kong", "Haolong Li", "Jiaqi Li", "Ruipeng Li", "Tianze Li", "Zhuoran Li", "Haixia Lian", "Mengyue Lin", "Xudong Liu", "Jiayi Lu", "Jinghan Lu", "Wanyu Luo", "Ziyue Luo", "Zihao Pu", "Zhi Qiao", "Ruihuan Ren", "Liang Wan", "Ruixiang Wang", "Tianhui Wang", "Yang Wang", "Zeyu Wang", "Zihua Wang", "Yujia Wu", "Zhaoyi Wu", "Hao Xin", "Weiao Xing", "Ruojun Xiong", "Weijie Xu", "Yao Shu", "Yao Xiao", "Xiaorui Yang", "Yuchen Yang", "Nan Yi", "Jiadong Yu", "Yangyuxuan Yu", "Huiting Zeng", "Danni Zhang", "Yunjie Zhang", "Zhaoyu Zhang", "Zhiheng Zhang", "Xiaofeng Zheng", "Peirong Zhou", "Linyan Zhong", "Xiaoyin Zong", "Ying Zhao", "Zhenxin Chen", "Lin Ding", "Xiaoyu Gao", "Bingbing Gong", "Yichao Li", "Yang Liao", "Guang Ma", "Tianyuan Ma", "Xinrui Sun", "Tianyi Wang", "Han Xia", "Ruobing Xian", "Gen Ye", "Tengfei Yu", "Wentao Zhang", "Yuxi Wang", "Xi Gao", "Mengdi Wang"], "title": "On Path to Multimodal Historical Reasoning: HistBench and HistAgent", "categories": ["cs.AI", "cs.CL"], "comment": "17 pages, 7 figures", "summary": "Recent advances in large language models (LLMs) have led to remarkable\nprogress across domains, yet their capabilities in the humanities, particularly\nhistory, remain underexplored. Historical reasoning poses unique challenges for\nAI, involving multimodal source interpretation, temporal inference, and\ncross-linguistic analysis. While general-purpose agents perform well on many\nexisting benchmarks, they lack the domain-specific expertise required to engage\nwith historical materials and questions. To address this gap, we introduce\nHistBench, a new benchmark of 414 high-quality questions designed to evaluate\nAI's capacity for historical reasoning and authored by more than 40 expert\ncontributors. The tasks span a wide range of historical problems-from factual\nretrieval based on primary sources to interpretive analysis of manuscripts and\nimages, to interdisciplinary challenges involving archaeology, linguistics, or\ncultural history. Furthermore, the benchmark dataset spans 29 ancient and\nmodern languages and covers a wide range of historical periods and world\nregions. Finding the poor performance of LLMs and other agents on HistBench, we\nfurther present HistAgent, a history-specific agent equipped with carefully\ndesigned tools for OCR, translation, archival search, and image understanding\nin History. On HistBench, HistAgent based on GPT-4o achieves an accuracy of\n27.54% pass@1 and 36.47% pass@2, significantly outperforming LLMs with online\nsearch and generalist agents, including GPT-4o (18.60%), DeepSeek-R1(14.49%)\nand Open Deep Research-smolagents(20.29% pass@1 and 25.12% pass@2). These\nresults highlight the limitations of existing LLMs and generalist agents and\ndemonstrate the advantages of HistAgent for historical reasoning.", "AI": {"tldr": "The paper introduces HistBench, a benchmark for evaluating AI's historical reasoning, and HistAgent, a specialized AI agent for history, which outperforms general-purpose LLMs.", "motivation": "To address the underexplored capabilities of LLMs in humanities, particularly history, due to unique challenges like multimodal interpretation and temporal inference.", "method": "Developed HistBench (414 expert-authored questions) and HistAgent (a history-specific AI with tools like OCR, translation, and archival search).", "result": "HistAgent (based on GPT-4o) achieved 27.54% pass@1 and 36.47% pass@2, outperforming generalist agents like GPT-4o (18.60%).", "conclusion": "Specialized agents like HistAgent are more effective for historical reasoning than general-purpose LLMs, highlighting their limitations in this domain."}}
{"id": "2310.17143", "pdf": "https://arxiv.org/pdf/2310.17143", "abs": "https://arxiv.org/abs/2310.17143", "authors": ["Zhicheng Lin"], "title": "Techniques for supercharging academic writing with generative AI", "categories": ["cs.CY", "cs.CL"], "comment": "Published in: Nature Biomedical Engineering, 2025", "summary": "Academic writing is an indispensable yet laborious part of the research\nenterprise. This Perspective maps out principles and methods for using\ngenerative artificial intelligence (AI), specifically large language models\n(LLMs), to elevate the quality and efficiency of academic writing. We introduce\na human-AI collaborative framework that delineates the rationale (why), process\n(how), and nature (what) of AI engagement in writing. The framework pinpoints\nboth short-term and long-term reasons for engagement and their underlying\nmechanisms (e.g., cognitive offloading and imaginative stimulation). It reveals\nthe role of AI throughout the writing process, conceptualized through a\ntwo-stage model for human-AI collaborative writing, and the nature of AI\nassistance in writing, represented through a model of writing-assistance types\nand levels. Building on this framework, we describe effective prompting\ntechniques for incorporating AI into the writing routine (outlining, drafting,\nand editing) as well as strategies for maintaining rigorous scholarship,\nadhering to varied journal policies, and avoiding overreliance on AI.\nUltimately, the prudent integration of AI into academic writing can ease the\ncommunication burden, empower authors, accelerate discovery, and promote\ndiversity in science.", "AI": {"tldr": "The paper proposes a human-AI collaborative framework for academic writing, detailing why, how, and what AI can assist with, while emphasizing effective prompting and avoiding overreliance.", "motivation": "To enhance the quality and efficiency of academic writing using generative AI (LLMs) while maintaining scholarly rigor.", "method": "Introduces a framework with rationale, process, and nature of AI engagement, including a two-stage model for human-AI collaboration and writing-assistance types.", "result": "Effective prompting techniques and strategies for AI integration in outlining, drafting, and editing, ensuring adherence to journal policies.", "conclusion": "Prudent AI integration can ease communication, empower authors, accelerate discovery, and promote diversity in science."}}
{"id": "2501.00848", "pdf": "https://arxiv.org/pdf/2501.00848", "abs": "https://arxiv.org/abs/2501.00848", "authors": ["Yiming Zhang", "Zicheng Zhang", "Xinyi Wei", "Xiaohong Liu", "Guangtao Zhai", "Xiongkuo Min"], "title": "IllusionBench+: A Large-scale and Comprehensive Benchmark for Visual Illusion Understanding in Vision-Language Models", "categories": ["cs.CV"], "comment": null, "summary": "Current Visual Language Models (VLMs) show impressive image understanding but\nstruggle with visual illusions, especially in real-world scenarios. Existing\nbenchmarks focus on classical cognitive illusions, which have been learned by\nstate-of-the-art (SOTA) VLMs, revealing issues such as hallucinations and\nlimited perceptual abilities. To address this gap, we introduce IllusionBench,\na comprehensive visual illusion dataset that encompasses not only classic\ncognitive illusions but also real-world scene illusions. This dataset features\n1,051 images, 5,548 question-answer pairs, and 1,051 golden text descriptions\nthat address the presence, causes, and content of the illusions. We evaluate\nten SOTA VLMs on this dataset using true-or-false, multiple-choice, and\nopen-ended tasks. In addition to real-world illusions, we design trap illusions\nthat resemble classical patterns but differ in reality, highlighting\nhallucination issues in SOTA models. The top-performing model, GPT-4o, achieves\n80.59% accuracy on true-or-false tasks and 76.75% on multiple-choice questions,\nbut still lags behind human performance. In the semantic description task,\nGPT-4o's hallucinations on classical illusions result in low scores for trap\nillusions, even falling behind some open-source models. IllusionBench is, to\nthe best of our knowledge, the largest and most comprehensive benchmark for\nvisual illusions in VLMs to date.", "AI": {"tldr": "IllusionBench is a new dataset for evaluating VLMs on visual illusions, including classic and real-world scenarios, revealing performance gaps compared to humans.", "motivation": "Existing benchmarks for VLMs focus on classical illusions, which SOTA models have mastered, but fail to address real-world illusions and hallucination issues.", "method": "The authors introduce IllusionBench, a dataset with 1,051 images, 5,548 QA pairs, and golden descriptions, evaluating ten SOTA VLMs via true-or-false, multiple-choice, and open-ended tasks.", "result": "GPT-4o performs best but still lags behind humans, especially in semantic descriptions of trap illusions.", "conclusion": "IllusionBench highlights VLMs' limitations in handling visual illusions, providing a comprehensive benchmark for future improvements."}}
{"id": "2506.16394", "pdf": "https://arxiv.org/pdf/2506.16394", "abs": "https://arxiv.org/abs/2506.16394", "authors": ["Zelin Xiao", "Jia Gu", "Song Xi Chen"], "title": "Identifying Heterogeneity in Distributed Learning", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "We study methods for identifying heterogeneous parameter components in\ndistributed M-estimation with minimal data transmission. One is based on a\nre-normalized Wald test, which is shown to be consistent as long as the number\nof distributed data blocks $K$ is of a smaller order of the minimum block\nsample size {and the level of heterogeneity is dense}. The second one is an\nextreme contrast test (ECT) based on the difference between the largest and\nsmallest component-wise estimated parameters among data blocks. By introducing\na sample splitting procedure, the ECT can avoid the bias accumulation arising\nfrom the M-estimation procedures, and exhibits consistency for $K$ being much\nlarger than the sample size while the heterogeneity is sparse. The ECT\nprocedure is easy to operate and communication-efficient. A combination of the\nWald and the extreme contrast tests is formulated to attain more robust power\nunder varying levels of sparsity of the heterogeneity. We also conduct\nintensive numerical experiments to compare the family-wise error rate (FWER)\nand the power of the proposed methods. Additionally, we conduct a case study to\npresent the implementation and validity of the proposed methods.", "AI": {"tldr": "The paper proposes two methods for identifying heterogeneous parameters in distributed M-estimation with minimal data transmission: a re-normalized Wald test for dense heterogeneity and an extreme contrast test (ECT) for sparse heterogeneity. A combination of both methods is suggested for robustness. Numerical experiments and a case study validate the methods.", "motivation": "To address the challenge of identifying heterogeneous parameter components in distributed M-estimation efficiently, with minimal data transmission.", "method": "1. Re-normalized Wald test for dense heterogeneity. 2. Extreme contrast test (ECT) with sample splitting for sparse heterogeneity. 3. Combined approach for robustness.", "result": "The Wald test is consistent for smaller K, while ECT works for larger K. The combined method shows robust power under varying sparsity. Numerical experiments confirm effectiveness.", "conclusion": "The proposed methods are effective, communication-efficient, and validated through experiments and a case study."}}
{"id": "2505.22960", "pdf": "https://arxiv.org/pdf/2505.22960", "abs": "https://arxiv.org/abs/2505.22960", "authors": ["Yongjin Yang", "Euiin Yi", "Jongwoo Ko", "Kimin Lee", "Zhijing Jin", "Se-Young Yun"], "title": "Revisiting Multi-Agent Debate as Test-Time Scaling: A Systematic Study of Conditional Effectiveness", "categories": ["cs.AI", "cs.LG"], "comment": "Preprint, under review", "summary": "The remarkable growth in large language model (LLM) capabilities has spurred\nexploration into multi-agent systems, with debate frameworks emerging as a\npromising avenue for enhanced problem-solving. These multi-agent debate (MAD)\napproaches, where agents collaboratively present, critique, and refine\narguments, potentially offer improved reasoning, robustness, and diverse\nperspectives over monolithic models. Despite prior studies leveraging MAD, a\nsystematic understanding of its effectiveness compared to self-agent methods,\nparticularly under varying conditions, remains elusive. This paper seeks to\nfill this gap by conceptualizing MAD as a test-time computational scaling\ntechnique, distinguished by collaborative refinement and diverse exploration\ncapabilities. We conduct a comprehensive empirical investigation comparing MAD\nwith strong self-agent test-time scaling baselines on mathematical reasoning\nand safety-related tasks. Our study systematically examines the influence of\ntask difficulty, model scale, and agent diversity on MAD's performance. Key\nfindings reveal that, for mathematical reasoning, MAD offers limited advantages\nover self-agent scaling but becomes more effective with increased problem\ndifficulty and decreased model capability, while agent diversity shows little\nbenefit. Conversely, for safety tasks, MAD's collaborative refinement can\nincrease vulnerability, but incorporating diverse agent configurations\nfacilitates a gradual reduction in attack success through the collaborative\nrefinement process. We believe our findings provide critical guidance for the\nfuture development of more effective and strategically deployed MAD systems.", "AI": {"tldr": "Multi-agent debate (MAD) is explored as a test-time scaling technique, showing limited benefits for math tasks but potential risks and benefits for safety tasks depending on conditions.", "motivation": "To systematically understand MAD's effectiveness compared to self-agent methods, especially under varying conditions like task difficulty and model scale.", "method": "Conceptualizes MAD as a test-time computational scaling technique and conducts empirical comparisons with self-agent baselines on math and safety tasks.", "result": "MAD offers limited advantages for math reasoning but becomes more effective with harder problems or weaker models. For safety tasks, MAD can increase vulnerability but benefits from diverse agent configurations.", "conclusion": "The findings guide future development of MAD systems by highlighting its conditional effectiveness and strategic deployment needs."}}
{"id": "2406.12593", "pdf": "https://arxiv.org/pdf/2406.12593", "abs": "https://arxiv.org/abs/2406.12593", "authors": ["Tuan-Luc Huynh", "Thuy-Trang Vu", "Weiqing Wang", "Yinwei Wei", "Trung Le", "Dragan Gasevic", "Yuan-Fang Li", "Thanh-Toan Do"], "title": "PromptDSI: Prompt-based Rehearsal-free Instance-wise Incremental Learning for Document Retrieval", "categories": ["cs.IR", "cs.AI", "cs.CL", "cs.LG"], "comment": "ECML PKDD 2025 Research track. Camera-ready version. Code is\n  available at https://github.com/LouisDo2108/PromptDSI", "summary": "Differentiable Search Index (DSI) utilizes pre-trained language models to\nperform indexing and document retrieval via end-to-end learning without relying\non external indexes. However, DSI requires full re-training to index new\ndocuments, causing significant computational inefficiencies. Continual learning\n(CL) offers a solution by enabling the model to incrementally update without\nfull re-training. Existing CL solutions in document retrieval rely on memory\nbuffers or generative models for rehearsal, which is infeasible when accessing\nprevious training data is restricted due to privacy concerns. To this end, we\nintroduce PromptDSI, a prompt-based, rehearsal-free continual learning approach\nfor document retrieval. PromptDSI follows the Prompt-based Continual Learning\n(PCL) framework, using learnable prompts to efficiently index new documents\nwithout accessing previous documents or queries. To improve retrieval latency,\nwe remove the initial forward pass of PCL, which otherwise greatly increases\ntraining and inference time, with a negligible trade-off in performance.\nAdditionally, we introduce a novel topic-aware prompt pool that employs neural\ntopic embeddings as fixed keys, eliminating the instability of prompt key\noptimization while maintaining competitive performance with existing PCL prompt\npools. In a challenging rehearsal-free continual learning setup, we demonstrate\nthat PromptDSI variants outperform rehearsal-based baselines, match the strong\ncache-based baseline in mitigating forgetting, and significantly improving\nretrieval performance on new corpora.", "AI": {"tldr": "PromptDSI introduces a prompt-based, rehearsal-free continual learning method for document retrieval, improving efficiency and performance without accessing previous data.", "motivation": "Address computational inefficiencies in DSI by enabling incremental updates without full re-training, while respecting privacy constraints.", "method": "Uses learnable prompts and a topic-aware prompt pool to index new documents without accessing past data, optimizing retrieval latency.", "result": "Outperforms rehearsal-based baselines, matches cache-based baselines in mitigating forgetting, and improves retrieval on new corpora.", "conclusion": "PromptDSI offers an efficient, privacy-preserving solution for continual learning in document retrieval."}}
{"id": "2501.00912", "pdf": "https://arxiv.org/pdf/2501.00912", "abs": "https://arxiv.org/abs/2501.00912", "authors": ["Jiaxin Ge", "Zora Zhiruo Wang", "Xuhui Zhou", "Yi-Hao Peng", "Sanjay Subramanian", "Qinyue Tan", "Maarten Sap", "Alane Suhr", "Daniel Fried", "Graham Neubig", "Trevor Darrell"], "title": "AutoPresent: Designing Structured Visuals from Scratch", "categories": ["cs.CV", "cs.CL"], "comment": null, "summary": "Designing structured visuals such as presentation slides is essential for\ncommunicative needs, necessitating both content creation and visual planning\nskills. In this work, we tackle the challenge of automated slide generation,\nwhere models produce slide presentations from natural language (NL)\ninstructions. We first introduce the SlidesBench benchmark, the first benchmark\nfor slide generation with 7k training and 585 testing examples derived from 310\nslide decks across 10 domains. SlidesBench supports evaluations that are\n(i)reference-based to measure similarity to a target slide, and\n(ii)reference-free to measure the design quality of generated slides alone. We\nbenchmark end-to-end image generation and program generation methods with a\nvariety of models, and find that programmatic methods produce higher-quality\nslides in user-interactable formats. Built on the success of program\ngeneration, we create AutoPresent, an 8B Llama-based model trained on 7k pairs\nof instructions paired with code for slide generation, and achieve results\ncomparable to the closed-source model GPT-4o. We further explore iterative\ndesign refinement where the model is tasked to self-refine its own output, and\nwe found that this process improves the slide's quality. We hope that our work\nwill provide a basis for future work on generating structured visuals.", "AI": {"tldr": "The paper introduces SlidesBench, a benchmark for automated slide generation, and AutoPresent, a model for generating slides from natural language instructions, achieving results comparable to GPT-4o.", "motivation": "To automate slide generation, addressing the need for both content creation and visual planning skills.", "method": "Introduces SlidesBench for evaluation, benchmarks image and program generation methods, and develops AutoPresent, an 8B Llama-based model trained on instruction-code pairs.", "result": "Programmatic methods yield higher-quality slides; AutoPresent matches GPT-4o's performance; iterative refinement improves slide quality.", "conclusion": "The work lays a foundation for future research in generating structured visuals."}}
{"id": "2506.16416", "pdf": "https://arxiv.org/pdf/2506.16416", "abs": "https://arxiv.org/abs/2506.16416", "authors": ["Alexander Timans", "Rajeev Verma", "Eric Nalisnick", "Christian A. Naesseth"], "title": "On Continuous Monitoring of Risk Violations under Unknown Shift", "categories": ["stat.ML", "cs.LG"], "comment": "AT and RV are joint first authors. Accepted at the Conference on\n  Uncertainty in Artificial Intelligence (UAI 2025)", "summary": "Machine learning systems deployed in the real world must operate under\ndynamic and often unpredictable distribution shifts. This challenges the\nvalidity of statistical safety assurances on the system's risk established\nbeforehand. Common risk control frameworks rely on fixed assumptions and lack\nmechanisms to continuously monitor deployment reliability. In this work, we\npropose a general framework for the real-time monitoring of risk violations in\nevolving data streams. Leveraging the 'testing by betting' paradigm, we propose\na sequential hypothesis testing procedure to detect violations of bounded risks\nassociated with the model's decision-making mechanism, while ensuring control\non the false alarm rate. Our method operates under minimal assumptions on the\nnature of encountered shifts, rendering it broadly applicable. We illustrate\nthe effectiveness of our approach by monitoring risks in outlier detection and\nset prediction under a variety of shifts.", "AI": {"tldr": "A framework for real-time risk monitoring in machine learning systems under dynamic distribution shifts, using sequential hypothesis testing to detect risk violations with controlled false alarm rates.", "motivation": "Machine learning systems face unpredictable distribution shifts in real-world deployments, challenging pre-established safety assurances. Existing frameworks lack adaptability for continuous reliability monitoring.", "method": "Proposes a sequential hypothesis testing procedure based on 'testing by betting' to detect risk violations in evolving data streams, with minimal assumptions on shifts.", "result": "Demonstrates effectiveness in monitoring risks for outlier detection and set prediction under various shifts.", "conclusion": "The framework provides a broadly applicable solution for real-time risk monitoring in dynamic environments, ensuring reliability with controlled false alarms."}}
{"id": "2506.00618", "pdf": "https://arxiv.org/pdf/2506.00618", "abs": "https://arxiv.org/abs/2506.00618", "authors": ["Jingyi Yang", "Shuai Shao", "Dongrui Liu", "Jing Shao"], "title": "RiOSWorld: Benchmarking the Risk of Multimodal Computer-Use Agents", "categories": ["cs.AI"], "comment": "40 pages, 6 figures, Project Page:\n  https://yjyddq.github.io/RiOSWorld.github.io/", "summary": "With the rapid development of multimodal large language models (MLLMs), they\nare increasingly deployed as autonomous computer-use agents capable of\naccomplishing complex computer tasks. However, a pressing issue arises: Can the\nsafety risk principles designed and aligned for general MLLMs in dialogue\nscenarios be effectively transferred to real-world computer-use scenarios?\nExisting research on evaluating the safety risks of MLLM-based computer-use\nagents suffers from several limitations: it either lacks realistic interactive\nenvironments, or narrowly focuses on one or a few specific risk types. These\nlimitations ignore the complexity, variability, and diversity of real-world\nenvironments, thereby restricting comprehensive risk evaluation for\ncomputer-use agents. To this end, we introduce \\textbf{RiOSWorld}, a benchmark\ndesigned to evaluate the potential risks of MLLM-based agents during real-world\ncomputer manipulations. Our benchmark includes 492 risky tasks spanning various\ncomputer applications, involving web, social media, multimedia, os, email, and\noffice software. We categorize these risks into two major classes based on\ntheir risk source: (i) User-originated risks and (ii) Environmental risks. For\nthe evaluation, we evaluate safety risks from two perspectives: (i) Risk goal\nintention and (ii) Risk goal completion. Extensive experiments with multimodal\nagents on \\textbf{RiOSWorld} demonstrate that current computer-use agents\nconfront significant safety risks in real-world scenarios. Our findings\nhighlight the necessity and urgency of safety alignment for computer-use agents\nin real-world computer manipulation, providing valuable insights for developing\ntrustworthy computer-use agents. Our benchmark is publicly available at\nhttps://yjyddq.github.io/RiOSWorld.github.io/.", "AI": {"tldr": "The paper introduces RIOSWorld, a benchmark to evaluate safety risks of MLLM-based computer-use agents in real-world scenarios, highlighting significant risks and the need for safety alignment.", "motivation": "Existing safety risk evaluations for MLLM-based computer-use agents lack realistic environments or focus narrowly, ignoring real-world complexity and diversity.", "method": "RIOSWorld includes 492 risky tasks across various computer applications, categorizing risks into user-originated and environmental, evaluated from intention and completion perspectives.", "result": "Experiments show current computer-use agents face significant safety risks in real-world scenarios.", "conclusion": "The findings emphasize the urgency of safety alignment for trustworthy computer-use agents, with RIOSWorld providing a valuable benchmark."}}
{"id": "2410.08316", "pdf": "https://arxiv.org/pdf/2410.08316", "abs": "https://arxiv.org/abs/2410.08316", "authors": ["Yinuo Ren", "Tesi Xiao", "Michael Shavlovsky", "Lexing Ying", "Holakou Rahmanian"], "title": "COS-DPO: Conditioned One-Shot Multi-Objective Fine-Tuning Framework", "categories": ["cs.LG", "cs.CL", "math.OC"], "comment": "Published at UAI 2025", "summary": "In LLM alignment and many other ML applications, one often faces the\nMulti-Objective Fine-Tuning (MOFT) problem, i.e., fine-tuning an existing model\nwith datasets labeled w.r.t. different objectives simultaneously. To address\nthe challenge, we propose a Conditioned One-Shot fine-tuning framework\n(COS-DPO) that extends the Direct Preference Optimization technique, originally\ndeveloped for efficient LLM alignment with preference data, to accommodate the\nMOFT settings. By direct conditioning on the weight across auxiliary\nobjectives, our Weight-COS-DPO method enjoys an efficient one-shot training\nprocess for profiling the Pareto front and is capable of achieving\ncomprehensive trade-off solutions even in the post-training stage. Based on our\ntheoretical findings on the linear transformation properties of the loss\nfunction, we further propose the Temperature-COS-DPO method that augments the\ntemperature parameter to the model input, enhancing the flexibility of\npost-training control over the trade-offs between the main and auxiliary\nobjectives. We demonstrate the effectiveness and efficiency of the COS-DPO\nframework through its applications to various tasks, including the\nLearning-to-Rank (LTR) and LLM alignment tasks, highlighting its viability for\nlarge-scale ML deployments.", "AI": {"tldr": "The paper introduces COS-DPO, a framework for Multi-Objective Fine-Tuning (MOFT) in LLM alignment and ML tasks, extending Direct Preference Optimization to handle multiple objectives efficiently.", "motivation": "Addressing the challenge of fine-tuning models with datasets labeled for different objectives simultaneously (MOFT problem).", "method": "Proposes Conditioned One-Shot fine-tuning (COS-DPO), including Weight-COS-DPO for Pareto front profiling and Temperature-COS-DPO for flexible trade-off control.", "result": "Demonstrates effectiveness in tasks like Learning-to-Rank and LLM alignment, showing viability for large-scale ML.", "conclusion": "COS-DPO provides efficient and flexible solutions for MOFT, enhancing post-training trade-off control."}}
{"id": "2501.07076", "pdf": "https://arxiv.org/pdf/2501.07076", "abs": "https://arxiv.org/abs/2501.07076", "authors": ["Tongxu Zhang", "Bei Wang"], "title": "Representation Learning of Point Cloud Upsampling in Global and Local Inputs", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "In recent years, point cloud upsampling has been widely applied in tasks such\nas 3D reconstruction and object recognition. This study proposed a novel\nframework, ReLPU, which enhances upsampling performance by explicitly learning\nfrom both global and local structural features of point clouds. Specifically,\nwe extracted global features from uniformly segmented inputs (Average Segments)\nand local features from patch-based inputs of the same point cloud. These two\ntypes of features were processed through parallel autoencoders, fused, and then\nfed into a shared decoder for upsampling. This dual-input design improved\nfeature completeness and cross-scale consistency, especially in sparse and\nnoisy regions. Our framework was applied to several state-of-the-art\nautoencoder-based networks and validated on standard datasets. Experimental\nresults demonstrated consistent improvements in geometric fidelity and\nrobustness. In addition, saliency maps confirmed that parallel global-local\nlearning significantly enhanced the interpretability and performance of point\ncloud upsampling.", "AI": {"tldr": "ReLPU is a novel point cloud upsampling framework that learns global and local features via parallel autoencoders, improving performance and interpretability.", "motivation": "Point cloud upsampling is crucial for tasks like 3D reconstruction and object recognition, but existing methods lack feature completeness and cross-scale consistency, especially in sparse/noisy regions.", "method": "ReLPU extracts global features from uniformly segmented inputs and local features from patch-based inputs, processes them through parallel autoencoders, fuses them, and uses a shared decoder for upsampling.", "result": "Experiments show improved geometric fidelity, robustness, and interpretability, with saliency maps confirming the benefits of global-local learning.", "conclusion": "ReLPU enhances point cloud upsampling by leveraging dual-input learning, offering better performance and interpretability for sparse/noisy data."}}
{"id": "2506.16522", "pdf": "https://arxiv.org/pdf/2506.16522", "abs": "https://arxiv.org/abs/2506.16522", "authors": ["Pedro Rodr\u00edguez Fern\u00e1ndez", "Christian Svinth", "Alex Hagen"], "title": "Improvement of Nuclide Detection through Graph Spectroscopic Analysis Framework and its Application to Nuclear Facility Upset Detection", "categories": ["physics.ins-det", "cs.LG", "physics.data-an"], "comment": null, "summary": "We present a method to improve the detection limit for radionuclides using\nspectroscopic radiation detectors and the arrival time of each detected\nradiation quantum. We enable this method using a neural network with an\nattention mechanism. We illustrate the method on the detection of Cesium\nrelease from a nuclear facility during an upset, and our method shows $2\\times$\nimprovement over the traditional spectroscopic method. We hypothesize that our\nmethod achieves this performance increase by modulating its detection\nprobability by the overall rate of probable detections, specifically by\nadapting detection thresholds based on temporal event distributions and local\nspectral features, and show evidence to this effect. We believe this method is\napplicable broadly and may be more successful for radionuclides with more\ncomplicated decay chains than Cesium; we also note that our method can\ngeneralize beyond the addition of arrival time and could integrate other data\nabout each detection event, such as pulse quality, location in detector, or\neven combining the energy and time from detections in different detectors.", "AI": {"tldr": "A neural network with attention improves radionuclide detection by 2x using arrival time data, adaptable to complex decay chains and additional event data.", "motivation": "To enhance detection limits for radionuclides by leveraging temporal and spectral data, addressing limitations of traditional spectroscopic methods.", "method": "Uses a neural network with attention, modulating detection probability based on event rate, temporal distributions, and spectral features.", "result": "Demonstrates a 2x improvement in detection limit for Cesium, with potential for broader application to complex radionuclides.", "conclusion": "The method is scalable, adaptable to additional data, and promising for improving radionuclide detection in various scenarios."}}
{"id": "2506.04287", "pdf": "https://arxiv.org/pdf/2506.04287", "abs": "https://arxiv.org/abs/2506.04287", "authors": ["Yongjin Yang", "Sinjae Kang", "Juyong Lee", "Dongjun Lee", "Se-Young Yun", "Kimin Lee"], "title": "Automated Skill Discovery for Language Agents through Exploration and Iterative Feedback", "categories": ["cs.AI", "cs.LG"], "comment": "Preprint, under review", "summary": "Training large language model (LLM) agents to acquire necessary skills and\nperform diverse tasks within an environment is gaining interest as a means to\nenable open-endedness. However, creating the training dataset for their skill\nacquisition faces several challenges. Manual trajectory collection requires\nsignificant human effort. Another approach, where LLMs directly propose tasks\nto learn, is often invalid, as the LLMs lack knowledge of which tasks are\nactually feasible. Moreover, the generated data may not provide a meaningful\nlearning signal, as agents often already perform well on the proposed tasks. To\naddress this, we propose a novel automatic skill discovery framework EXIF for\nLLM-powered agents, designed to improve the feasibility of generated target\nbehaviors while accounting for the agents' capabilities. Our method adopts an\nexploration-first strategy by employing an exploration agent (Alice) to train\nthe target agent (Bob) to learn essential skills in the environment.\nSpecifically, Alice first interacts with the environment to retrospectively\ngenerate a feasible, environment-grounded skill dataset, which is then used to\ntrain Bob. Crucially, we incorporate an iterative feedback loop, where Alice\nevaluates Bob's performance to identify areas for improvement. This feedback\nthen guides Alice's next round of exploration, forming a closed-loop data\ngeneration process. Experiments on Webshop and Crafter demonstrate EXIF's\nability to effectively discover meaningful skills and iteratively expand the\ncapabilities of the trained agent without any human intervention, achieving\nsubstantial performance improvements. Interestingly, we observe that setting\nAlice to the same model as Bob also notably improves performance, demonstrating\nEXIF's potential for building a self-evolving system.", "AI": {"tldr": "EXIF is a framework for LLM-powered agents to automatically discover feasible skills and improve performance through an exploration-first strategy and iterative feedback loop.", "motivation": "Challenges in creating training datasets for LLM agents, such as manual effort and invalid task proposals, drive the need for an automated skill discovery method.", "method": "EXIF uses an exploration agent (Alice) to generate feasible skills and train the target agent (Bob), with an iterative feedback loop to refine learning.", "result": "Experiments show EXIF effectively discovers skills and improves agent performance without human intervention, even when Alice and Bob are the same model.", "conclusion": "EXIF enables self-evolving LLM agents by automating skill discovery and iterative improvement, demonstrating significant performance gains."}}
{"id": "2410.18077", "pdf": "https://arxiv.org/pdf/2410.18077", "abs": "https://arxiv.org/abs/2410.18077", "authors": ["Peter Shaw", "James Cohan", "Jacob Eisenstein", "Kenton Lee", "Jonathan Berant", "Kristina Toutanova"], "title": "ALTA: Compiler-Based Analysis of Transformers", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": "TMLR 2025", "summary": "We propose a new programming language called ALTA and a compiler that can map\nALTA programs to Transformer weights. ALTA is inspired by RASP, a language\nproposed by Weiss et al. (2021), and Tracr (Lindner et al., 2023), a compiler\nfrom RASP programs to Transformer weights. ALTA complements and extends this\nprior work, offering the ability to express loops and to compile programs to\nUniversal Transformers, among other advantages. ALTA allows us to\nconstructively show how Transformers can represent length-invariant algorithms\nfor computing parity and addition, as well as a solution to the SCAN benchmark\nof compositional generalization tasks, without requiring intermediate\nscratchpad decoding steps. We also propose tools to analyze cases where the\nexpressibility of an algorithm is established, but end-to-end training on a\ngiven training set fails to induce behavior consistent with the desired\nalgorithm. To this end, we explore training from ALTA execution traces as a\nmore fine-grained supervision signal. This enables additional experiments and\ntheoretical analyses relating the learnability of various algorithms to data\navailability and modeling decisions, such as positional encodings. We make the\nALTA framework -- language specification, symbolic interpreter, and weight\ncompiler -- available to the community to enable further applications and\ninsights.", "AI": {"tldr": "ALTA is a new programming language and compiler that maps programs to Transformer weights, extending prior work by supporting loops and Universal Transformers. It demonstrates Transformer capabilities for tasks like parity, addition, and SCAN, and introduces tools for analyzing training failures.", "motivation": "To extend the expressiveness of Transformer programming languages (like RASP and Tracr) by supporting loops and Universal Transformers, and to provide tools for analyzing algorithm learnability.", "method": "ALTA is designed as a programming language with a compiler to Transformer weights. It includes symbolic interpretation and tools for training from execution traces.", "result": "ALTA successfully compiles programs for tasks like parity, addition, and SCAN without scratchpad decoding. It also enables analysis of training failures and learnability.", "conclusion": "ALTA advances Transformer programming by supporting more complex algorithms and providing tools for deeper analysis. The framework is open-sourced for community use."}}
{"id": "2501.09481", "pdf": "https://arxiv.org/pdf/2501.09481", "abs": "https://arxiv.org/abs/2501.09481", "authors": ["Jan Skvrna", "Lukas Neumann"], "title": "MonoSOWA: Scalable monocular 3D Object detector Without human Annotations", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": null, "summary": "Inferring object 3D position and orientation from a single RGB camera is a\nfoundational task in computer vision with many important applications.\nTraditionally, 3D object detection methods are trained in a fully-supervised\nsetup, requiring LiDAR and vast amounts of human annotations, which are\nlaborious, costly, and do not scale well with the ever-increasing amounts of\ndata being captured.\n  We present a novel method to train a 3D object detector from a single RGB\ncamera without domain-specific human annotations, making orders of magnitude\nmore data available for training. The method uses newly proposed Local Object\nMotion Model to disentangle object movement source between subsequent frames,\nis approximately 700 times faster than previous work and compensates camera\nfocal length differences to aggregate multiple datasets.\n  The method is evaluated on three public datasets, where despite using no\nhuman labels, it outperforms prior work by a significant margin. It also shows\nits versatility as a pre-training tool for fully-supervised training and shows\nthat combining pseudo-labels from multiple datasets can achieve comparable\naccuracy to using human labels from a single dataset. The source code and model\nare available at https://github.com/jskvrna/MonoSOWA.", "AI": {"tldr": "A novel method trains a 3D object detector from a single RGB camera without human annotations, using a Local Object Motion Model, outperforming prior work and enabling scalable training.", "motivation": "Traditional 3D object detection relies on costly LiDAR and human annotations, limiting scalability. This work aims to eliminate the need for domain-specific annotations and leverage abundant RGB data.", "method": "Proposes a Local Object Motion Model to disentangle object movement between frames, compensates for camera focal length differences, and aggregates multiple datasets. It is 700x faster than previous methods.", "result": "Evaluated on three public datasets, the method outperforms prior work without human labels and shows versatility as a pre-training tool, achieving accuracy comparable to human-labeled data.", "conclusion": "The method enables scalable 3D object detection without human annotations, outperforms existing approaches, and is adaptable for pre-training and multi-dataset pseudo-labeling."}}
{"id": "2506.16658", "pdf": "https://arxiv.org/pdf/2506.16658", "abs": "https://arxiv.org/abs/2506.16658", "authors": ["Wenlong Ji", "Yihan Pan", "Ruihao Zhu", "Lihua Lei"], "title": "Multi-Armed Bandits With Machine Learning-Generated Surrogate Rewards", "categories": ["math.ST", "cs.LG", "stat.ML", "stat.TH"], "comment": null, "summary": "Multi-armed bandit (MAB) is a widely adopted framework for sequential\ndecision-making under uncertainty. Traditional bandit algorithms rely solely on\nonline data, which tends to be scarce as it must be gathered during the online\nphase when the arms are actively pulled. However, in many practical settings,\nrich auxiliary data, such as covariates of past users, is available prior to\ndeploying any arms. We introduce a new setting for MAB where pre-trained\nmachine learning (ML) models are applied to convert side information and\nhistorical data into \\emph{surrogate rewards}. A prominent feature of this\nsetting is that the surrogate rewards may exhibit substantial bias, as true\nreward data is typically unavailable in the offline phase, forcing ML\npredictions to heavily rely on extrapolation. To address the issue, we propose\nthe Machine Learning-Assisted Upper Confidence Bound (MLA-UCB) algorithm, which\ncan be applied to any reward prediction model and any form of auxiliary data.\nWhen the predicted and true rewards are jointly Gaussian, it provably improves\nthe cumulative regret, provided that the correlation is non-zero -- even in\ncases where the mean surrogate reward completely misaligns with the true mean\nrewards. Notably, our method requires no prior knowledge of the covariance\nmatrix between true and surrogate rewards. We compare MLA-UCB with the standard\nUCB on a range of numerical studies and show a sizable efficiency gain even\nwhen the size of the offline data and the correlation between predicted and\ntrue rewards are moderate.", "AI": {"tldr": "The paper introduces MLA-UCB, a bandit algorithm leveraging pre-trained ML models to use surrogate rewards from auxiliary data, improving regret even with biased predictions.", "motivation": "Traditional MAB algorithms rely on scarce online data, but auxiliary data (e.g., user covariates) is often available. This work aims to exploit such data despite potential bias in surrogate rewards.", "method": "Proposes MLA-UCB, which integrates surrogate rewards from ML models into UCB, requiring no prior knowledge of reward covariance. It handles biased predictions and works under Gaussian assumptions.", "result": "MLA-UCB provably reduces cumulative regret if predicted and true rewards are correlated, even with misaligned means. Numerical studies show efficiency gains over standard UCB.", "conclusion": "MLA-UCB effectively leverages auxiliary data and ML predictions to enhance MAB performance, even with biased surrogate rewards, without needing prior covariance knowledge."}}
{"id": "2506.08134", "pdf": "https://arxiv.org/pdf/2506.08134", "abs": "https://arxiv.org/abs/2506.08134", "authors": ["Qiyao Wei", "Samuel Holt", "Jing Yang", "Markus Wulfmeier", "Mihaela van der Schaar"], "title": "The AI Imperative: Scaling High-Quality Peer Review in Machine Learning", "categories": ["cs.AI", "cs.CY", "68T50, 68T07", "I.2.7; H.5.3"], "comment": "18 pages, 3 figures. Position paper", "summary": "Peer review, the bedrock of scientific advancement in machine learning (ML),\nis strained by a crisis of scale. Exponential growth in manuscript submissions\nto premier ML venues such as NeurIPS, ICML, and ICLR is outpacing the finite\ncapacity of qualified reviewers, leading to concerns about review quality,\nconsistency, and reviewer fatigue. This position paper argues that AI-assisted\npeer review must become an urgent research and infrastructure priority. We\nadvocate for a comprehensive AI-augmented ecosystem, leveraging Large Language\nModels (LLMs) not as replacements for human judgment, but as sophisticated\ncollaborators for authors, reviewers, and Area Chairs (ACs). We propose\nspecific roles for AI in enhancing factual verification, guiding reviewer\nperformance, assisting authors in quality improvement, and supporting ACs in\ndecision-making. Crucially, we contend that the development of such systems\nhinges on access to more granular, structured, and ethically-sourced peer\nreview process data. We outline a research agenda, including illustrative\nexperiments, to develop and validate these AI assistants, and discuss\nsignificant technical and ethical challenges. We call upon the ML community to\nproactively build this AI-assisted future, ensuring the continued integrity and\nscalability of scientific validation, while maintaining high standards of peer\nreview.", "AI": {"tldr": "The paper advocates for AI-assisted peer review in ML to address the crisis of scale, proposing AI as collaborators to enhance review quality and efficiency.", "motivation": "The exponential growth in ML manuscript submissions is straining peer review, leading to concerns about quality and reviewer fatigue.", "method": "Proposes using Large Language Models (LLMs) as collaborators for authors, reviewers, and Area Chairs, focusing on factual verification, reviewer guidance, and decision support.", "result": "Outlines a research agenda for developing AI-assisted review systems, emphasizing the need for structured and ethical review data.", "conclusion": "Calls for proactive development of AI-assisted peer review to maintain scientific integrity and scalability."}}
{"id": "2411.00412", "pdf": "https://arxiv.org/pdf/2411.00412", "abs": "https://arxiv.org/abs/2411.00412", "authors": ["Bohan Lyu", "Yadi Cao", "Duncan Watson-Parris", "Leon Bergen", "Taylor Berg-Kirkpatrick", "Rose Yu"], "title": "Adapting While Learning: Grounding LLMs for Scientific Problems with Intelligent Tool Usage Adaptation", "categories": ["cs.LG", "cs.AI", "cs.CL", "I.2.6; I.2.7"], "comment": "37 pages, 16 figures", "summary": "Large Language Models (LLMs) demonstrate promising capabilities in solving\nscientific problems but often suffer from the issue of hallucination. While\nintegrating LLMs with tools can mitigate this issue, models fine-tuned on tool\nusage become overreliant on them and incur unnecessary costs. Inspired by how\nhuman experts assess problem complexity before selecting solutions, we propose\na novel two-component fine-tuning method, Adapting While Learning (AWL). In the\nfirst component, World Knowledge Learning (WKL), LLMs internalize scientific\nknowledge by learning from tool-generated solutions. In the second component,\nTool Usage Adaptation (TUA), we categorize problems as easy or hard based on\nthe model's accuracy, and train it to maintain direct reasoning for easy\nproblems while switching to tools for hard ones. We validate our method on six\nscientific benchmark datasets across climate science, epidemiology, physics,\nand other domains. Compared to the original instruct model (8B), models\npost-trained with AWL achieve 29.11% higher answer accuracy and 12.72% better\ntool usage accuracy, even surpassing state-of-the-art models including GPT-4o\nand Claude-3.5 on four custom-created datasets. Our code is open-source at\nhttps://github.com/Rose-STL-Lab/Adapting-While-Learning.", "AI": {"tldr": "AWL fine-tuning method improves LLMs by combining knowledge learning and adaptive tool usage, boosting accuracy and efficiency.", "motivation": "Address LLMs' hallucination and overreliance on tools by mimicking human problem-solving strategies.", "method": "Two-component fine-tuning: World Knowledge Learning (WKL) for knowledge internalization and Tool Usage Adaptation (TUA) for adaptive tool use based on problem difficulty.", "result": "29.11% higher answer accuracy and 12.72% better tool usage accuracy, outperforming GPT-4o and Claude-3.5 on custom datasets.", "conclusion": "AWL effectively balances knowledge and tool usage, enhancing LLM performance in scientific domains."}}
{"id": "2502.01816", "pdf": "https://arxiv.org/pdf/2502.01816", "abs": "https://arxiv.org/abs/2502.01816", "authors": ["Kavitha Viswanathan", "Shashwat Pathak", "Piyush Bharambe", "Harsh Choudhary", "Amit Sethi"], "title": "Low-Resource Video Super-Resolution using Memory, Wavelets, and Deformable Convolutions", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "The tradeoff between reconstruction quality and compute required for video\nsuper-resolution (VSR) remains a formidable challenge in its adoption for\ndeployment on resource-constrained edge devices. While transformer-based VSR\nmodels have set new benchmarks for reconstruction quality in recent years,\nthese require substantial computational resources. On the other hand,\nlightweight models that have been introduced even recently struggle to deliver\nstate-of-the-art reconstruction. We propose a novel lightweight and\nparameter-efficient neural architecture for VSR that achieves state-of-the-art\nreconstruction accuracy with just 2.3 million parameters. Our model enhances\ninformation utilization based on several architectural attributes. Firstly, it\nuses 2D wavelet decompositions strategically interlayered with learnable\nconvolutional layers to utilize the inductive prior of spatial sparsity of\nedges in visual data. Secondly, it uses a single memory tensor to capture\ninter-frame temporal information while avoiding the computational cost of\nprevious memory-based schemes. Thirdly, it uses residual deformable\nconvolutions for implicit inter-frame object alignment that improve upon\ndeformable convolutions by enhancing spatial information in inter-frame feature\ndifferences. Architectural insights from our model can pave the way for\nreal-time VSR on the edge, such as display devices for streaming data.", "AI": {"tldr": "A lightweight neural architecture for VSR achieves state-of-the-art accuracy with only 2.3M parameters, balancing quality and compute for edge devices.", "motivation": "Addressing the tradeoff between reconstruction quality and computational resources in VSR for edge devices.", "method": "Uses 2D wavelet decompositions, a single memory tensor for temporal info, and residual deformable convolutions for alignment.", "result": "Achieves state-of-the-art reconstruction accuracy with minimal parameters.", "conclusion": "The model enables real-time VSR on edge devices, advancing deployment for streaming displays."}}
{"id": "2506.16666", "pdf": "https://arxiv.org/pdf/2506.16666", "abs": "https://arxiv.org/abs/2506.16666", "authors": ["Meenatchi Sundaram Muthu Selva Annamalai", "Borja Balle", "Jamie Hayes", "Georgios Kaissis", "Emiliano De Cristofaro"], "title": "The Hitchhiker's Guide to Efficient, End-to-End, and Tight DP Auditing", "categories": ["cs.CR", "cs.LG"], "comment": null, "summary": "This paper systematizes research on auditing Differential Privacy (DP)\ntechniques, aiming to identify key insights into the current state of the art\nand open challenges. First, we introduce a comprehensive framework for\nreviewing work in the field and establish three cross-contextual desiderata\nthat DP audits should target--namely, efficiency, end-to-end-ness, and\ntightness. Then, we systematize the modes of operation of state-of-the-art DP\nauditing techniques, including threat models, attacks, and evaluation\nfunctions. This allows us to highlight key details overlooked by prior work,\nanalyze the limiting factors to achieving the three desiderata, and identify\nopen research problems. Overall, our work provides a reusable and systematic\nmethodology geared to assess progress in the field and identify friction points\nand future directions for our community to focus on.", "AI": {"tldr": "The paper systematizes research on auditing Differential Privacy (DP) techniques, introducing a framework and identifying key insights, challenges, and open problems.", "motivation": "To provide a structured review of DP auditing techniques, highlighting gaps and future research directions.", "method": "Introduces a framework with three desiderata (efficiency, end-to-end-ness, tightness) and systematizes DP auditing techniques, including threat models and attacks.", "result": "Identifies overlooked details, limiting factors, and open research problems in DP auditing.", "conclusion": "Offers a reusable methodology to assess progress and guide future research in DP auditing."}}
{"id": "2506.08898", "pdf": "https://arxiv.org/pdf/2506.08898", "abs": "https://arxiv.org/abs/2506.08898", "authors": ["Mingfeng Fan", "Jianan Zhou", "Yifeng Zhang", "Yaoxin Wu", "Jinbiao Chen", "Guillaume Adrien Sartoretti"], "title": "Preference-Driven Multi-Objective Combinatorial Optimization with Conditional Computation", "categories": ["cs.AI"], "comment": "22 pages, 6 figures, under review", "summary": "Recent deep reinforcement learning methods have achieved remarkable success\nin solving multi-objective combinatorial optimization problems (MOCOPs) by\ndecomposing them into multiple subproblems, each associated with a specific\nweight vector. However, these methods typically treat all subproblems equally\nand solve them using a single model, hindering the effective exploration of the\nsolution space and thus leading to suboptimal performance. To overcome the\nlimitation, we propose POCCO, a novel plug-and-play framework that enables\nadaptive selection of model structures for subproblems, which are subsequently\noptimized based on preference signals rather than explicit reward values.\nSpecifically, we design a conditional computation block that routes subproblems\nto specialized neural architectures. Moreover, we propose a preference-driven\noptimization algorithm that learns pairwise preferences between winning and\nlosing solutions. We evaluate the efficacy and versatility of POCCO by applying\nit to two state-of-the-art neural methods for MOCOPs. Experimental results\nacross four classic MOCOP benchmarks demonstrate its significant superiority\nand strong generalization.", "AI": {"tldr": "POCCO is a plug-and-play framework for MOCOPs that adaptively selects model structures for subproblems and optimizes them using preference signals, outperforming existing methods.", "motivation": "Existing methods treat all subproblems equally with a single model, limiting solution space exploration and performance.", "method": "POCCO uses a conditional computation block to route subproblems to specialized architectures and a preference-driven optimization algorithm for learning pairwise preferences.", "result": "POCCO significantly outperforms state-of-the-art methods across four MOCOP benchmarks, showing strong generalization.", "conclusion": "POCCO's adaptive and preference-driven approach enhances performance and versatility in solving MOCOPs."}}
{"id": "2411.04105", "pdf": "https://arxiv.org/pdf/2411.04105", "abs": "https://arxiv.org/abs/2411.04105", "authors": ["Guan Zhe Hong", "Nishanth Dikkala", "Enming Luo", "Cyrus Rashtchian", "Xin Wang", "Rina Panigrahy"], "title": "A Implies B: Circuit Analysis in LLMs for Propositional Logical Reasoning", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": null, "summary": "Due to the size and complexity of modern large language models (LLMs), it has\nproven challenging to uncover the underlying mechanisms that models use to\nsolve reasoning problems. For instance, is their reasoning for a specific\nproblem localized to certain parts of the network? Do they break down the\nreasoning problem into modular components that are then executed as sequential\nsteps as we go deeper in the model? To better understand the reasoning\ncapability of LLMs, we study a minimal propositional logic problem that\nrequires combining multiple facts to arrive at a solution. By studying this\nproblem on Mistral and Gemma models, up to 27B parameters, we illuminate the\ncore components the models use to solve such logic problems. From a mechanistic\ninterpretability point of view, we use causal mediation analysis to uncover the\npathways and components of the LLMs' reasoning processes. Then, we offer\nfine-grained insights into the functions of attention heads in different\nlayers. We not only find a sparse circuit that computes the answer, but we\ndecompose it into sub-circuits that have four distinct and modular uses.\nFinally, we reveal that three distinct models -- Mistral-7B, Gemma-2-9B and\nGemma-2-27B -- contain analogous but not identical mechanisms.", "AI": {"tldr": "The paper investigates the reasoning mechanisms of large language models (LLMs) by analyzing a minimal propositional logic problem, revealing modular sub-circuits and analogous mechanisms across models.", "motivation": "To understand how LLMs solve reasoning problems, including whether reasoning is localized or modular, and to uncover the underlying pathways and components.", "method": "Uses causal mediation analysis on Mistral and Gemma models (up to 27B parameters) to study attention heads and decompose reasoning into sub-circuits.", "result": "Identifies a sparse circuit with four modular sub-circuits and finds analogous but not identical mechanisms in Mistral-7B, Gemma-2-9B, and Gemma-2-27B.", "conclusion": "LLMs employ modular and analogous reasoning mechanisms, with insights into attention head functions and sub-circuit roles."}}
{"id": "2502.08884", "pdf": "https://arxiv.org/pdf/2502.08884", "abs": "https://arxiv.org/abs/2502.08884", "authors": ["R. Kenny Jones", "Paul Guerrero", "Niloy J. Mitra", "Daniel Ritchie"], "title": "ShapeLib: Designing a library of programmatic 3D shape abstractions with Large Language Models", "categories": ["cs.CV", "cs.AI", "cs.GR"], "comment": null, "summary": "We present ShapeLib, the first method that leverages the priors of LLMs to\ndesign libraries of programmatic 3D shape abstractions. Our system accepts two\nforms of design intent: text descriptions of functions to include in the\nlibrary and a seed set of exemplar shapes. We discover abstractions that match\nthis design intent with a guided LLM workflow that first proposes, and then\nvalidates, different ways of applying and implementing functions. We learn\nrecognition networks that map shapes to programs with these newly discovered\nabstractions by training on data produced by LLM authored synthetic data\ngeneration procedures. Across modeling domains (split by shape category), we\nfind that LLMs, when thoughtfully combined with geometric reasoning, can be\nguided to author a library of abstraction functions that generalize to shapes\noutside of the seed set. This framework addresses a long-standing shape\nanalysis problem of how to discover reusable abstraction functions while\nexposing interpretable, semantically aligned interfaces. We find that ShapeLib\nprovides distinct advantages over prior alternative abstraction discovery works\nin terms of generalization, usability, and maintaining plausibility under\nmanipulation. Finally, we demonstrate that ShapeLib's abstraction functions\nunlock a number of downstream applications, combining LLM reasoning over shape\nprograms with geometry processing to support shape editing and generation.", "AI": {"tldr": "ShapeLib uses LLM priors to design 3D shape abstraction libraries, combining text descriptions and exemplar shapes. It validates abstractions via LLM workflows and trains recognition networks on synthetic data. The method generalizes well and supports downstream applications like shape editing.", "motivation": "To address the challenge of discovering reusable, interpretable abstraction functions for 3D shapes, leveraging LLMs for improved generalization and usability.", "method": "ShapeLib combines LLM-guided workflows to propose and validate abstractions, trains recognition networks on synthetic data, and integrates geometric reasoning.", "result": "ShapeLib outperforms prior works in generalization, usability, and plausibility, enabling applications like shape editing and generation.", "conclusion": "ShapeLib successfully leverages LLMs for 3D shape abstraction, offering a scalable and interpretable solution with practical downstream benefits."}}
{"id": "2506.16903", "pdf": "https://arxiv.org/pdf/2506.16903", "abs": "https://arxiv.org/abs/2506.16903", "authors": ["Arnaud Verdant", "William Guicquero", "J\u00e9r\u00f4me Chossat"], "title": "RCNet: $\u0394\u03a3$ IADCs as Recurrent AutoEncoders", "categories": ["cs.AR", "cs.LG"], "comment": null, "summary": "This paper proposes a deep learning model (RCNet) for Delta-Sigma\n($\\Delta\\Sigma$) ADCs. Recurrent Neural Networks (RNNs) allow to describe both\nmodulators and filters. This analogy is applied to Incremental ADCs (IADC).\nHigh-end optimizers combined with full-custom losses are used to define\nadditional hardware design constraints: quantized weights, signal saturation,\ntemporal noise injection, devices area. Focusing on DC conversion, our early\nresults demonstrate that $SNR$ defined as an Effective Number Of Bits (ENOB)\ncan be optimized under a certain hardware mapping complexity. The proposed\nRCNet succeeded to provide design tradeoffs in terms of $SNR$ ($>$13bit) versus\narea constraints ($<$14pF total capacitor) at a given $OSR$ (80 samples).\nInterestingly, it appears that the best RCNet architectures do not necessarily\nrely on high-order modulators, leveraging additional topology exploration\ndegrees of freedom.", "AI": {"tldr": "The paper introduces RCNet, a deep learning model for Delta-Sigma ADCs, using RNNs to optimize hardware design constraints and achieve high SNR under area limits.", "motivation": "To leverage deep learning for optimizing Delta-Sigma ADCs, addressing hardware constraints like quantized weights and area while improving SNR.", "method": "Uses RNNs (RCNet) to model modulators and filters, combined with high-end optimizers and custom losses for hardware constraints.", "result": "Achieves SNR (>13bit ENOB) under area constraints (<14pF) at OSR=80, showing tradeoffs without needing high-order modulators.", "conclusion": "RCNet effectively explores design tradeoffs, demonstrating that optimal architectures may not require high-order modulators."}}
{"id": "2506.13404", "pdf": "https://arxiv.org/pdf/2506.13404", "abs": "https://arxiv.org/abs/2506.13404", "authors": ["Xialie Zhuang", "Peixian Ma", "Zhikai Jia", "Shiwei Liu", "Zheng Cao"], "title": "A Technical Study into 0.5B Reasoning Language Models", "categories": ["cs.AI"], "comment": null, "summary": "The ongoing evolution of language models has led to the development of\nlarge-scale architectures that demonstrate exceptional performance across a\nwide range of tasks. However, these models come with significant computational\nand energy demands, as well as potential privacy implications. In this context,\nSmall Reasoning Language Models (SRLMs) with approximately 0.5 billion\nparameters present a compelling alternative due to their remarkable\ncomputational efficiency and cost effectiveness, particularly in\nresource-constrained environments. Despite these advantages, the limited\ncapacity of 0.5 billion parameter models poses challenges in handling complex\ntasks such as mathematical reasoning and code generation. This research\ninvestigates various training strategies, including supervised fine-tuning\n(SFT), knowledge distillation (KD), and reinforcement learning (RL), as well as\ntheir hybrid implementations, to enhance the performance of 0.5B SRLMs. We\nanalyze effective methodologies to bridge the performance gap between SRLMS and\nlarger models and present insights into optimal training pipelines tailored for\nthese smaller architectures. Through extensive experimental validation and\nanalysis, our work aims to provide actionable recommendations for maximizing\nthe reasoning capabilities of 0.5B models.", "AI": {"tldr": "Small Reasoning Language Models (SRLMs) with 0.5B parameters offer efficiency but struggle with complex tasks. This research explores training strategies (SFT, KD, RL) to enhance their performance.", "motivation": "Large language models are resource-intensive; SRLMs provide a cost-effective alternative but need performance improvements for complex tasks.", "method": "Investigates supervised fine-tuning (SFT), knowledge distillation (KD), reinforcement learning (RL), and hybrid methods to enhance 0.5B SRLMs.", "result": "Identifies effective methodologies to bridge the performance gap between SRLMs and larger models.", "conclusion": "Provides actionable recommendations for optimizing 0.5B SRLMs' reasoning capabilities."}}
{"id": "2411.05091", "pdf": "https://arxiv.org/pdf/2411.05091", "abs": "https://arxiv.org/abs/2411.05091", "authors": ["Agnibh Dasgupta", "Abdullah Tanvir", "Xin Zhong"], "title": "Watermarking Language Models through Language Models", "categories": ["cs.LG", "cs.CL", "cs.CR"], "comment": null, "summary": "Watermarking the outputs of large language models (LLMs) is critical for\nprovenance tracing, content regulation, and model accountability. Existing\napproaches often rely on access to model internals or are constrained by static\nrules and token-level perturbations. Moreover, the idea of steering generative\nbehavior via prompt-based instruction control remains largely underexplored. We\nintroduce a prompt-guided watermarking framework that operates entirely at the\ninput level and requires no access to model parameters or decoding logits. The\nframework comprises three cooperating components: a Prompting LM that\nsynthesizes watermarking instructions from user prompts, a Marking LM that\ngenerates watermarked outputs conditioned on these instructions, and a\nDetecting LM trained to classify whether a response carries an embedded\nwatermark. This modular design enables dynamic watermarking that adapts to\nindividual prompts while remaining compatible with diverse LLM architectures,\nincluding both proprietary and open-weight models. We evaluate the framework\nover 25 combinations of Prompting and Marking LMs, such as GPT-4o, Mistral,\nLLaMA3, and DeepSeek. Experimental results show that watermark signals\ngeneralize across architectures and remain robust under fine-tuning, model\ndistillation, and prompt-based adversarial attacks, demonstrating the\neffectiveness and robustness of the proposed approach.", "AI": {"tldr": "A prompt-guided watermarking framework for LLMs operates at the input level, requiring no model internals, and adapts dynamically to prompts while being robust across architectures.", "motivation": "To address the need for provenance tracing, content regulation, and model accountability in LLMs without relying on model internals or static rules.", "method": "A modular framework with three components: Prompting LM (synthesizes watermarking instructions), Marking LM (generates watermarked outputs), and Detecting LM (classifies watermarks).", "result": "Watermark signals generalize across architectures (e.g., GPT-4o, Mistral) and remain robust under fine-tuning, distillation, and adversarial attacks.", "conclusion": "The framework is effective, adaptable, and robust for watermarking LLM outputs."}}
{"id": "2503.17193", "pdf": "https://arxiv.org/pdf/2503.17193", "abs": "https://arxiv.org/abs/2503.17193", "authors": ["Xiaojin Lu", "Taoran yue", "Jiaxi cai", "Yuanping Chen", "Cuihong Lv", "Shibing Chu"], "title": "MSCA-Net:Multi-Scale Context Aggregation Network for Infrared Small Target Detection", "categories": ["cs.CV"], "comment": null, "summary": "In complex environments, detecting tiny infrared targets has always been\nchallenging because of the low contrast and high noise levels inherent in\ninfrared images. These factors often lead to the loss of crucial details during\nfeature extraction. Moreover, existing detection methods have limitations in\nadequately integrating global and local information, which constrains the\nefficiency and accuracy of infrared small target detection. To address these\nchallenges, this paper proposes a network architecture named MSCA-Net, which\nintegrates three key components: Multi-Scale Enhanced Dilated Attention\nmechanism (MSEDA), Positional Convolutional Block Attention Module (PCBAM), and\nChannel Aggregation Feature Fusion Block (CAB). Specifically, MSEDA employs a\nmulti-scale feature fusion attention mechanism to adaptively aggregate\ninformation across different scales, enriching feature representation. PCBAM\ncaptures the correlation between global and local features through a\ncorrelation matrix-based strategy, enabling deep feature interaction. Moreover,\nCAB enhances the representation of critical features by assigning greater\nweights to them, integrating both low-level and high-level information, and\nthereby improving the models detection performance in complex backgrounds. The\nexperimental results demonstrate that MSCA-Net achieves strong small target\ndetection performance in complex backgrounds. Specifically, it attains mIoU\nscores of 78.43%, 94.56%, and 67.08% on the NUAA-SIRST, NUDT-SIRST, and\nIRTSD-1K datasets, respectively, underscoring its effectiveness and strong\npotential for real-world applications.", "AI": {"tldr": "MSCA-Net, a novel network architecture, improves infrared small target detection by integrating multi-scale and attention mechanisms, achieving high mIoU scores on benchmark datasets.", "motivation": "Detecting tiny infrared targets is challenging due to low contrast, high noise, and inadequate integration of global and local information in existing methods.", "method": "Proposes MSCA-Net with Multi-Scale Enhanced Dilated Attention (MSEDA), Positional Convolutional Block Attention Module (PCBAM), and Channel Aggregation Feature Fusion Block (CAB) to enhance feature representation and interaction.", "result": "Achieves mIoU scores of 78.43%, 94.56%, and 67.08% on NUAA-SIRST, NUDT-SIRST, and IRTSD-1K datasets, respectively.", "conclusion": "MSCA-Net demonstrates strong performance and potential for real-world applications in complex infrared target detection."}}
{"id": "2506.16918", "pdf": "https://arxiv.org/pdf/2506.16918", "abs": "https://arxiv.org/abs/2506.16918", "authors": ["Dhananjeyan Jeyaraj", "Hamidreza Eivazi", "Jendrik-Alexander Tr\u00f6ger", "Stefan Wittek", "Stefan Hartmann", "Andreas Rausch"], "title": "A Neural Operator based Hybrid Microscale Model for Multiscale Simulation of Rate-Dependent Materials", "categories": ["physics.comp-ph", "cs.CE", "cs.LG"], "comment": null, "summary": "The behavior of materials is influenced by a wide range of phenomena\noccurring across various time and length scales. To better understand the\nimpact of microstructure on macroscopic response, multiscale modeling\nstrategies are essential. Numerical methods, such as the $\\text{FE}^2$\napproach, account for micro-macro interactions to predict the global response\nin a concurrent manner. However, these methods are computationally intensive\ndue to the repeated evaluations of the microscale. This challenge has led to\nthe integration of deep learning techniques into computational homogenization\nframeworks to accelerate multiscale simulations. In this work, we employ neural\noperators to predict the microscale physics, resulting in a hybrid model that\ncombines data-driven and physics-based approaches. This allows for\nphysics-guided learning and provides flexibility for different materials and\nspatial discretizations. We apply this method to time-dependent solid mechanics\nproblems involving viscoelastic material behavior, where the state is\nrepresented by internal variables only at the microscale. The constitutive\nrelations of the microscale are incorporated into the model architecture and\nthe internal variables are computed based on established physical principles.\nThe results for homogenized stresses ($<6\\%$ error) show that the approach is\ncomputationally efficient ($\\sim 100 \\times$ faster).", "AI": {"tldr": "The paper introduces a hybrid multiscale modeling approach combining deep learning (neural operators) with physics-based methods to efficiently predict microscale behavior and accelerate simulations in viscoelastic solid mechanics.", "motivation": "To address the computational intensity of traditional multiscale modeling methods like FE\u00b2, which require repeated microscale evaluations, by integrating deep learning for faster and flexible simulations.", "method": "Uses neural operators to predict microscale physics, blending data-driven and physics-based approaches. The model incorporates microscale constitutive relations and computes internal variables based on physical principles.", "result": "Achieves accurate homogenized stresses (<6% error) and significant computational efficiency (~100x faster).", "conclusion": "The hybrid approach successfully balances accuracy and speed, demonstrating its potential for practical applications in multiscale modeling of viscoelastic materials."}}
{"id": "2308.12053", "pdf": "https://arxiv.org/pdf/2308.12053", "abs": "https://arxiv.org/abs/2308.12053", "authors": ["Leander Weber", "Jim Berend", "Moritz Weckbecker", "Alexander Binder", "Thomas Wiegand", "Wojciech Samek", "Sebastian Lapuschkin"], "title": "Efficient and Flexible Neural Network Training through Layer-wise Feedback Propagation", "categories": ["cs.LG", "cs.AI", "cs.NE", "I.2.6"], "comment": null, "summary": "Gradient-based optimization has been a cornerstone of machine learning that\nenabled the vast advances of Artificial Intelligence (AI) development over the\npast decades. However, this type of optimization requires differentiation, and\nwith recent evidence of the benefits of non-differentiable (e.g. neuromorphic)\narchitectures over classical models w.r.t. efficiency, such constraints can\nbecome limiting in the future. We present Layer-wise Feedback Propagation\n(LFP), a novel training principle for neural network-like predictors that\nutilizes methods from the domain of explainability to decompose a reward to\nindividual neurons based on their respective contributions. Leveraging these\nneuron-wise rewards, our method then implements a greedy approach reinforcing\nhelpful parts of the network and weakening harmful ones. While having\ncomparable computational complexity to gradient descent, LFP does not require\ngradient computation and generates sparse and thereby memory- and\nenergy-efficient parameter updates and models. We establish the convergence of\nLFP theoretically and empirically, demonstrating its effectiveness on various\nmodels and datasets. Via two applications - neural network pruning and the\napproximation-free training of Spiking Neural Networks (SNNs) - we demonstrate\nthat LFP combines increased efficiency in terms of computation and\nrepresentation with flexibility w.r.t. choice of model architecture and\nobjective function. Our code is available at\nhttps://github.com/leanderweber/layerwise-feedback-propagation.", "AI": {"tldr": "Layer-wise Feedback Propagation (LFP) is a novel training method for neural networks that avoids gradient computation, using explainability techniques to decompose rewards to neurons. It is efficient and flexible, demonstrated in pruning and training Spiking Neural Networks (SNNs).", "motivation": "Gradient-based optimization is limited by its reliance on differentiation, which may not suit non-differentiable architectures like neuromorphic systems. LFP addresses this by offering an alternative training principle.", "method": "LFP decomposes rewards to individual neurons based on their contributions, then greedily reinforces helpful neurons and weakens harmful ones. It avoids gradients and produces sparse updates.", "result": "LFP achieves comparable performance to gradient descent while being more memory- and energy-efficient. It is effective for neural network pruning and SNN training.", "conclusion": "LFP provides a flexible, efficient alternative to gradient-based optimization, suitable for diverse architectures and objectives, with theoretical and empirical validation."}}
{"id": "2411.09642", "pdf": "https://arxiv.org/pdf/2411.09642", "abs": "https://arxiv.org/abs/2411.09642", "authors": ["Alkis Kalavasis", "Anay Mehrotra", "Grigoris Velegkas"], "title": "On the Limits of Language Generation: Trade-Offs Between Hallucination and Mode Collapse", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.DS", "stat.ML"], "comment": "Accepted for presentation at the 57th Symposium on Theory of\n  Computing (STOC 2025)", "summary": "Specifying all desirable properties of a language model is challenging, but\ncertain requirements seem essential. Given samples from an unknown language,\nthe trained model should produce valid strings not seen in training and be\nexpressive enough to capture the language's full richness. Otherwise,\noutputting invalid strings constitutes \"hallucination,\" and failing to capture\nthe full range leads to \"mode collapse.\" We ask if a language model can meet\nboth requirements.\n  We investigate this within a statistical language generation setting building\non Gold and Angluin. Here, the model receives random samples from a\ndistribution over an unknown language K, which belongs to a possibly infinite\ncollection of languages. The goal is to generate unseen strings from K. We say\nthe model generates from K with consistency and breadth if, as training size\nincreases, its output converges to all unseen strings in K.\n  Kleinberg and Mullainathan [KM24] asked if consistency and breadth in\nlanguage generation are possible. We answer this negatively: for a large class\nof language models, including next-token prediction models, this is impossible\nfor most collections of candidate languages. This contrasts with [KM24]'s\nresult, showing consistent generation without breadth is possible for any\ncountable collection of languages. Our finding highlights that generation with\nbreadth fundamentally differs from generation without breadth.\n  As a byproduct, we establish near-tight bounds on the number of samples\nneeded for generation with or without breadth.\n  Finally, our results offer hope: consistent generation with breadth is\nachievable for any countable collection of languages when negative examples\n(strings outside K) are available alongside positive ones. This suggests that\npost-training feedback, which encodes negative examples, can be crucial in\nreducing hallucinations while limiting mode collapse.", "AI": {"tldr": "The paper explores whether language models can generate valid, unseen strings (consistency) while capturing the full richness of a language (breadth). It finds this impossible for most models without negative examples but achievable with them.", "motivation": "To determine if language models can avoid hallucinations (invalid outputs) and mode collapse (limited expressiveness) by meeting both consistency and breadth requirements.", "method": "Investigates within a statistical language generation framework, building on Gold and Angluin, using random samples from an unknown language. Analyzes convergence of model outputs to unseen strings.", "result": "Negative answer: most models, including next-token predictors, cannot achieve both consistency and breadth without negative examples. However, it's possible with negative examples.", "conclusion": "Post-training feedback (negative examples) is crucial for reducing hallucinations and mode collapse, enabling consistent generation with breadth."}}
{"id": "2503.19740", "pdf": "https://arxiv.org/pdf/2503.19740", "abs": "https://arxiv.org/abs/2503.19740", "authors": ["Chengan Che", "Chao Wang", "Tom Vercauteren", "Sophia Tsoka", "Luis C. Garcia-Peraza-Herrera"], "title": "Surg-3M: A Dataset and Foundation Model for Perception in Surgical Settings", "categories": ["cs.CV"], "comment": "15 pages", "summary": "Advancements in computer-assisted surgical procedures heavily rely on\naccurate visual data interpretation from camera systems used during surgeries.\nTraditional open-access datasets focusing on surgical procedures are often\nlimited by their small size, typically consisting of fewer than 100 videos with\nless than 100K images. To address these constraints, a new dataset called\nSurg-3M has been compiled using a novel aggregation pipeline that collects\nhigh-resolution videos from online sources. Featuring an extensive collection\nof over 4K surgical videos totaling 938 hours of high-quality footage across\nmultiple procedure types, Surg-3M offers a comprehensive resource surpassing\nexisting alternatives in size and scope, including two novel tasks. To\ndemonstrate the effectiveness of this dataset, we present SurgFM, a\nself-supervised foundation model pretrained on Surg-3M that achieves impressive\nresults in downstream tasks such as surgical phase recognition, action\nrecognition, and tool presence detection. Combining key components from\nConvNeXt, DINO, and an innovative augmented distillation method, SurgFM\nexhibits exceptional performance compared to specialist architectures across\nvarious benchmarks. Our experimental results show that SurgFM outperforms\nstate-of-the-art models in multiple downstream tasks, including significant\ngains in surgical phase recognition (+8.9pp, +4.7pp, and +3.9pp of Jaccard in\nAutoLaparo, M2CAI16, and Cholec80), action recognition (+3.1pp of mAP in\nCholecT50) and tool presence detection (+4.6pp of mAP in Cholec80). Moreover,\neven when using only half of the data, SurgFM outperforms state-of-the-art\nmodels in AutoLaparo and achieves state-of-the-art performance in Cholec80.\nBoth Surg-3M and SurgFM have significant potential to accelerate progress\ntowards developing autonomous robotic surgery systems.", "AI": {"tldr": "A new dataset, Surg-3M, and a foundation model, SurgFM, are introduced to address limitations in surgical procedure datasets, achieving state-of-the-art performance in various tasks.", "motivation": "Traditional surgical datasets are small and limited. Surg-3M and SurgFM aim to provide a larger, more comprehensive resource for computer-assisted surgical advancements.", "method": "Surg-3M aggregates high-resolution surgical videos. SurgFM combines ConvNeXt, DINO, and augmented distillation for self-supervised pretraining.", "result": "SurgFM outperforms state-of-the-art models in surgical phase recognition, action recognition, and tool presence detection, even with reduced data.", "conclusion": "Surg-3M and SurgFM significantly advance autonomous robotic surgery development."}}
{"id": "2506.16938", "pdf": "https://arxiv.org/pdf/2506.16938", "abs": "https://arxiv.org/abs/2506.16938", "authors": ["Sebastian Nagies", "Emiliano Tolotti", "Davide Pastorello", "Enrico Blanzieri"], "title": "Enhancing Expressivity of Quantum Neural Networks Based on the SWAP test", "categories": ["quant-ph", "cs.ET", "cs.LG"], "comment": "15 pages, 7 figures", "summary": "Parameterized quantum circuits represent promising architectures for machine\nlearning applications, yet many lack clear connections to classical models,\npotentially limiting their ability to translate the wide success of classical\nneural networks to the quantum realm. We examine a specific type of quantum\nneural network (QNN) built exclusively from SWAP test circuits, and discuss its\nmathematical equivalence to a classical two-layer feedforward network with\nquadratic activation functions under amplitude encoding. Our analysis across\nclassical real-world and synthetic datasets reveals that while this\narchitecture can successfully learn many practical tasks, it exhibits\nfundamental expressivity limitations due to violating the universal\napproximation theorem, particularly failing on harder problems like the parity\ncheck function. To address this limitation, we introduce a circuit modification\nusing generalized SWAP test circuits that effectively implements classical\nneural networks with product layers. This enhancement enables successful\nlearning of parity check functions in arbitrary dimensions which we\nanalytically argue to be impossible for the original architecture beyond two\ndimensions regardless of network size. Our results establish a framework for\nenhancing QNN expressivity through classical task analysis and demonstrate that\nour SWAP test-based architecture offers broad representational capacity,\nsuggesting potential promise also for quantum learning tasks.", "AI": {"tldr": "The paper explores a quantum neural network (QNN) based on SWAP test circuits, showing its equivalence to a classical two-layer feedforward network with quadratic activations. It identifies expressivity limitations and proposes a modified circuit to overcome them, enabling tasks like parity checks.", "motivation": "To bridge the gap between quantum and classical neural networks by analyzing a SWAP test-based QNN and addressing its expressivity limitations.", "method": "Examines a QNN built from SWAP test circuits, compares it to classical networks, and introduces a modified circuit using generalized SWAP tests.", "result": "The original QNN has expressivity limitations (e.g., fails on parity checks), but the modified version successfully learns such tasks.", "conclusion": "The enhanced SWAP test-based QNN offers broader representational capacity, suggesting promise for quantum learning tasks."}}
{"id": "2311.06835", "pdf": "https://arxiv.org/pdf/2311.06835", "abs": "https://arxiv.org/abs/2311.06835", "authors": ["Qizhou Wang", "Guansong Pang", "Mahsa Salehi", "Xiaokun Xia", "Christopher Leckie"], "title": "Open-Set Graph Anomaly Detection via Normal Structure Regularisation", "categories": ["cs.LG", "cs.AI", "cs.SI"], "comment": "Accepted by ICLR 2025", "summary": "This paper considers an important Graph Anomaly Detection (GAD) task, namely\nopen-set GAD, which aims to train a detection model using a small number of\nnormal and anomaly nodes (referred to as seen anomalies) to detect both seen\nanomalies and unseen anomalies (i.e., anomalies that cannot be illustrated the\ntraining anomalies). Those labelled training data provide crucial prior\nknowledge about abnormalities for GAD models, enabling substantially reduced\ndetection errors. However, current supervised GAD methods tend to\nover-emphasise fitting the seen anomalies, leading to many errors of detecting\nthe unseen anomalies as normal nodes. Further, existing open-set AD models were\nintroduced to handle Euclidean data, failing to effectively capture\ndiscriminative features from graph structure and node attributes for GAD. In\nthis work, we propose a novel open-set GAD approach, namely normal structure\nregularisation (NSReg), to achieve generalised detection ability to unseen\nanomalies, while maintaining its effectiveness on detecting seen anomalies. The\nkey idea in NSReg is to introduce a regularisation term that enforces the\nlearning of compact, semantically-rich representations of normal nodes based on\ntheir structural relations to other nodes. When being optimised with supervised\nanomaly detection losses, the regularisation term helps incorporate strong\nnormality into the modelling, and thus, it effectively avoids over-fitting the\nseen anomalies and learns a better normality decision boundary, largely\nreducing the false negatives of detecting unseen anomalies as normal. Extensive\nempirical results on seven real-world datasets show that NSReg significantly\noutperforms state-of-the-art competing methods by at least 14% AUC-ROC on the\nunseen anomaly classes and by 10% AUC-ROC on all anomaly classes.", "AI": {"tldr": "The paper introduces NSReg, a novel open-set Graph Anomaly Detection (GAD) method, to improve detection of unseen anomalies while maintaining performance on seen anomalies.", "motivation": "Current supervised GAD methods over-fit seen anomalies, leading to poor detection of unseen anomalies. Existing open-set AD models fail to handle graph data effectively.", "method": "Proposes NSReg, which uses a regularization term to learn compact, semantically-rich normal node representations based on structural relations.", "result": "NSReg outperforms state-of-the-art methods by 14% AUC-ROC on unseen anomalies and 10% on all anomalies.", "conclusion": "NSReg effectively reduces false negatives for unseen anomalies and improves overall detection performance."}}
{"id": "2412.04628", "pdf": "https://arxiv.org/pdf/2412.04628", "abs": "https://arxiv.org/abs/2412.04628", "authors": ["Taneesh Gupta", "Rahul Madhavan", "Xuchao Zhang", "Nagarajan Natarajan", "Chetan Bansal", "Saravan Rajmohan"], "title": "Multi-Preference Optimization: Generalizing DPO via Set-Level Contrasts", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": null, "summary": "Direct Preference Optimization (DPO) has become a popular approach for\naligning language models using pairwise preferences. However, in practical\npost-training pipelines, on-policy generation typically yields multiple\ncandidate responses per prompt, which are scored by a reward model to guide\nlearning. In this setting, we propose $\\textbf{Multi-Preference Optimization\n(MPO)}$, a generalization of DPO that optimizes over entire sets of responses\nby extending the Bradley-Terry model to groupwise comparisons between chosen\nand rejected sets. To further enhance learning, MPO employs deviation-based\nweighting, which emphasizes outlier responses that deviate most from the mean\nreward, effectively inducing a self-paced curriculum. We theoretically prove\nthat MPO reduces alignment bias at a rate of\n$\\mathcal{O}\\left(\\frac{1}{\\sqrt{n}}\\right)$ with respect to the number of\nresponses per query. Empirically, MPO achieves state-of-the-art performance on\nthe UltraFeedback benchmark and yields up to $\\sim 17.5\\%$ improvement over the\nstate-of-the-art baseline in length-controlled win rate on AlpacaEval2,\nestablishing a new baseline for preference-based alignment", "AI": {"tldr": "MPO extends DPO for aligning language models by optimizing over sets of responses, using groupwise comparisons and deviation-based weighting, achieving state-of-the-art performance.", "motivation": "DPO is limited to pairwise preferences, while practical pipelines involve multiple candidate responses per prompt. MPO addresses this gap.", "method": "MPO generalizes DPO by extending the Bradley-Terry model to groupwise comparisons and employs deviation-based weighting for outlier emphasis.", "result": "MPO reduces alignment bias theoretically and achieves up to 17.5% improvement in win rate on benchmarks.", "conclusion": "MPO sets a new baseline for preference-based alignment, outperforming existing methods."}}
{"id": "2504.05253", "pdf": "https://arxiv.org/pdf/2504.05253", "abs": "https://arxiv.org/abs/2504.05253", "authors": ["Ben Lonnqvist", "Elsa Scialom", "Abdulkadir Gokce", "Zehra Merchant", "Michael H. Herzog", "Martin Schrimpf"], "title": "Contour Integration Underlies Human-Like Vision", "categories": ["cs.CV"], "comment": "ICML Camera Ready", "summary": "Despite the tremendous success of deep learning in computer vision, models\nstill fall behind humans in generalizing to new input distributions. Existing\nbenchmarks do not investigate the specific failure points of models by\nanalyzing performance under many controlled conditions. Our study\nsystematically dissects where and why models struggle with contour integration\n-- a hallmark of human vision -- by designing an experiment that tests object\nrecognition under various levels of object fragmentation. Humans (n=50) perform\nat high accuracy, even with few object contours present. This is in contrast to\nmodels which exhibit substantially lower sensitivity to increasing object\ncontours, with most of the over 1,000 models we tested barely performing above\nchance. Only at very large scales ($\\sim5B$ training dataset size) do models\nbegin to approach human performance. Importantly, humans exhibit an integration\nbias -- a preference towards recognizing objects made up of directional\nfragments over directionless fragments. We find that not only do models that\nshare this property perform better at our task, but that this bias also\nincreases with model training dataset size, and training models to exhibit\ncontour integration leads to high shape bias. Taken together, our results\nsuggest that contour integration is a hallmark of object vision that underlies\nobject recognition performance, and may be a mechanism learned from data at\nscale.", "AI": {"tldr": "The paper investigates why deep learning models lag behind humans in generalizing to new input distributions, focusing on contour integration in object recognition. It finds humans outperform models, especially with fragmented objects, and identifies an integration bias in humans that improves model performance when replicated.", "motivation": "To understand the failure points of deep learning models in generalizing to new input distributions, specifically in contour integration, a key aspect of human vision.", "method": "The study designs an experiment testing object recognition under varying levels of object fragmentation, comparing human performance (n=50) with over 1,000 models.", "result": "Humans perform well even with few contours, while models struggle unless trained on very large datasets (~5B). Models mimicking human integration bias perform better, and this bias increases with dataset size.", "conclusion": "Contour integration is crucial for object recognition, likely learned from large-scale data, and replicating human biases can improve model performance."}}
{"id": "2506.17015", "pdf": "https://arxiv.org/pdf/2506.17015", "abs": "https://arxiv.org/abs/2506.17015", "authors": ["Dominic Schuh", "Janik Kreit", "Evan Berkowitz", "Lena Funcke", "Thomas Luu", "Kim A. Nicoli", "Marcel Rodekamp"], "title": "Simulating Correlated Electrons with Symmetry-Enforced Normalizing Flows", "categories": ["cond-mat.str-el", "cs.LG", "hep-lat"], "comment": "9 pages, 7 figures", "summary": "We present the first proof of principle that normalizing flows can accurately\nlearn the Boltzmann distribution of the fermionic Hubbard model - a key\nframework for describing the electronic structure of graphene and related\nmaterials. State-of-the-art methods like Hybrid Monte Carlo often suffer from\nergodicity issues near the time-continuum limit, leading to biased estimates.\nLeveraging symmetry-aware architectures as well as independent and identically\ndistributed sampling, our approach resolves these issues and achieves\nsignificant speed-ups over traditional methods.", "AI": {"tldr": "Normalizing flows effectively learn the Boltzmann distribution for the fermionic Hubbard model, overcoming ergodicity issues and outperforming traditional methods.", "motivation": "Addressing ergodicity issues in state-of-the-art methods like Hybrid Monte Carlo, which bias estimates near the time-continuum limit.", "method": "Uses symmetry-aware architectures and independent, identically distributed sampling.", "result": "Achieves accurate learning of the Boltzmann distribution and significant speed-ups over traditional methods.", "conclusion": "Demonstrates the potential of normalizing flows for fermionic Hubbard models, offering improved accuracy and efficiency."}}
{"id": "2401.03756", "pdf": "https://arxiv.org/pdf/2401.03756", "abs": "https://arxiv.org/abs/2401.03756", "authors": ["Masahiro Kato", "Kyohei Okumura", "Takuya Ishihara", "Toru Kitagawa"], "title": "Adaptive Experimental Design for Policy Learning", "categories": ["cs.LG", "cs.AI", "econ.EM", "stat.ME", "stat.ML"], "comment": "arXiv admin note: text overlap with arXiv:2302.02988", "summary": "This study investigates the contextual best arm identification (BAI) problem,\naiming to design an adaptive experiment to identify the best treatment arm\nconditioned on contextual information (covariates). We consider a\ndecision-maker who assigns treatment arms to experimental units during an\nexperiment and recommends the estimated best treatment arm based on the\ncontexts at the end of the experiment. The decision-maker uses a policy for\nrecommendations, which is a function that provides the estimated best treatment\narm given the contexts. In our evaluation, we focus on the worst-case expected\nregret, a relative measure between the expected outcomes of an optimal policy\nand our proposed policy. We derive a lower bound for the expected simple regret\nand then propose a strategy called Adaptive Sampling-Policy Learning (PLAS). We\nprove that this strategy is minimax rate-optimal in the sense that its leading\nfactor in the regret upper bound matches the lower bound as the number of\nexperimental units increases.", "AI": {"tldr": "The paper addresses the contextual best arm identification problem, proposing an adaptive experiment design to identify the best treatment arm based on covariates. It introduces a policy for recommendations and evaluates performance using worst-case expected regret. The proposed PLAS strategy is proven minimax rate-optimal.", "motivation": "To solve the contextual BAI problem by designing adaptive experiments that efficiently identify the best treatment arm given contextual information.", "method": "Proposes the Adaptive Sampling-Policy Learning (PLAS) strategy, which adaptively assigns treatments and learns a recommendation policy. Derives a lower bound for expected simple regret and evaluates PLAS against it.", "result": "PLAS is shown to be minimax rate-optimal, with its regret upper bound matching the derived lower bound as the number of experimental units grows.", "conclusion": "The PLAS strategy effectively addresses the contextual BAI problem, achieving optimal performance in terms of expected regret."}}
{"id": "2501.06589", "pdf": "https://arxiv.org/pdf/2501.06589", "abs": "https://arxiv.org/abs/2501.06589", "authors": ["Muru Zhang", "Mayank Mishra", "Zhongzhu Zhou", "William Brandon", "Jue Wang", "Yoon Kim", "Jonathan Ragan-Kelley", "Shuaiwen Leon Song", "Ben Athiwaratkun", "Tri Dao"], "title": "Ladder-residual: parallelism-aware architecture for accelerating large model inference with communication overlapping", "categories": ["cs.LG", "cs.CL", "cs.DC"], "comment": "ICML 2025", "summary": "Large language model inference is both memory-intensive and time-consuming,\noften requiring distributed algorithms to efficiently scale. Various model\nparallelism strategies are used in multi-gpu training and inference to\npartition computation across multiple devices, reducing memory load and\ncomputation time. However, using model parallelism necessitates communication\nof information between GPUs, which has been a major bottleneck and limits the\ngains obtained by scaling up the number of devices. We introduce Ladder\nResidual, a simple architectural modification applicable to all residual-based\nmodels that enables straightforward overlapping that effectively hides the\nlatency of communication. Our insight is that in addition to systems\noptimization, one can also redesign the model architecture to decouple\ncommunication from computation. While Ladder Residual can allow\ncommunication-computation decoupling in conventional parallelism patterns, we\nfocus on Tensor Parallelism in this paper, which is particularly bottlenecked\nby its heavy communication. For a Transformer model with 70B parameters,\napplying Ladder Residual to all its layers can achieve 29% end-to-end wall\nclock speed up at inference time with TP sharding over 8 devices. We refer the\nresulting Transformer model as the Ladder Transformer. We train a 1B and 3B\nLadder Transformer from scratch and observe comparable performance to a\nstandard dense transformer baseline. We also show that it is possible to\nconvert parts of the Llama-3.1 8B model to our Ladder Residual architecture\nwith minimal accuracy degradation by only retraining for 3B tokens. We release\nour code for training and inference for easier replication of experiments.", "AI": {"tldr": "Ladder Residual, a modification for residual-based models, hides communication latency in multi-GPU inference, improving speed by 29% for a 70B parameter model.", "motivation": "Large language model inference is memory and time-intensive, with communication between GPUs being a bottleneck in distributed setups.", "method": "Introduces Ladder Residual, an architectural change to decouple communication from computation, tested with Tensor Parallelism.", "result": "Achieves 29% speedup for a 70B parameter model; comparable performance in 1B and 3B models; minimal accuracy loss when adapting Llama-3.1 8B.", "conclusion": "Ladder Residual effectively reduces communication bottlenecks, enabling faster inference without significant performance trade-offs."}}
{"id": "2504.07836", "pdf": "https://arxiv.org/pdf/2504.07836", "abs": "https://arxiv.org/abs/2504.07836", "authors": ["Junli Liu", "Qizhi Chen", "Zhigang Wang", "Yiwen Tang", "Yiting Zhang", "Chi Yan", "Dong Wang", "Bin Zhao", "Xuelong Li"], "title": "AerialVG: A Challenging Benchmark for Aerial Visual Grounding by Exploring Positional Relations", "categories": ["cs.CV", "cs.AI"], "comment": "8 pages, 6 figures", "summary": "Visual grounding (VG) aims to localize target objects in an image based on\nnatural language descriptions. In this paper, we propose AerialVG, a new task\nfocusing on visual grounding from aerial views. Compared to traditional VG,\nAerialVG poses new challenges, \\emph{e.g.}, appearance-based grounding is\ninsufficient to distinguish among multiple visually similar objects, and\npositional relations should be emphasized. Besides, existing VG models struggle\nwhen applied to aerial imagery, where high-resolution images cause significant\ndifficulties. To address these challenges, we introduce the first AerialVG\ndataset, consisting of 5K real-world aerial images, 50K manually annotated\ndescriptions, and 103K objects. Particularly, each annotation in AerialVG\ndataset contains multiple target objects annotated with relative spatial\nrelations, requiring models to perform comprehensive spatial reasoning.\nFurthermore, we propose an innovative model especially for the AerialVG task,\nwhere a Hierarchical Cross-Attention is devised to focus on target regions, and\na Relation-Aware Grounding module is designed to infer positional relations.\nExperimental results validate the effectiveness of our dataset and method,\nhighlighting the importance of spatial reasoning in aerial visual grounding.\nThe code and dataset will be released.", "AI": {"tldr": "The paper introduces AerialVG, a new task for visual grounding in aerial views, addressing challenges like distinguishing visually similar objects and emphasizing positional relations. It presents a dataset of 5K aerial images with 50K descriptions and 103K objects, and proposes a model with Hierarchical Cross-Attention and Relation-Aware Grounding modules. Results show the method's effectiveness and the importance of spatial reasoning.", "motivation": "Traditional visual grounding (VG) struggles with aerial imagery due to high-resolution challenges and insufficient appearance-based grounding. AerialVG aims to address these gaps by focusing on spatial reasoning and positional relations.", "method": "The paper introduces the AerialVG dataset (5K images, 50K descriptions, 103K objects) and proposes a model with Hierarchical Cross-Attention for target region focus and a Relation-Aware Grounding module for positional relation inference.", "result": "Experimental results demonstrate the effectiveness of the proposed dataset and method, emphasizing the role of spatial reasoning in aerial visual grounding.", "conclusion": "The work highlights the importance of spatial reasoning in aerial VG, introduces a novel dataset, and presents a model that outperforms existing methods. The code and dataset will be released."}}
{"id": "2506.17036", "pdf": "https://arxiv.org/pdf/2506.17036", "abs": "https://arxiv.org/abs/2506.17036", "authors": ["Sina Aghaee Dabaghan Fard", "Minhee Kim", "Akash Deep", "Jaesung Lee"], "title": "Bayesian Joint Model of Multi-Sensor and Failure Event Data for Multi-Mode Failure Prediction", "categories": ["stat.ME", "cs.LG", "stat.ML"], "comment": null, "summary": "Modern industrial systems are often subject to multiple failure modes, and\ntheir conditions are monitored by multiple sensors, generating multiple\ntime-series signals. Additionally, time-to-failure data are commonly available.\nAccurately predicting a system's remaining useful life (RUL) requires\neffectively leveraging multi-sensor time-series data alongside multi-mode\nfailure event data. In most existing models, failure modes and RUL prediction\nare performed independently, ignoring the inherent relationship between these\ntwo tasks. Some models integrate multiple failure modes and event prediction\nusing black-box machine learning approaches, which lack statistical rigor and\ncannot characterize the inherent uncertainty in the model and data. This paper\nintroduces a unified approach to jointly model the multi-sensor time-series\ndata and failure time concerning multiple failure modes. This proposed model\nintegrate a Cox proportional hazards model, a Convolved Multi-output Gaussian\nProcess, and multinomial failure mode distributions in a hierarchical Bayesian\nframework with corresponding priors, enabling accurate prediction with robust\nuncertainty quantification. Posterior distributions are effectively obtained by\nVariational Bayes, and prediction is performed with Monte Carlo sampling. The\nadvantages of the proposed model is validated through extensive numerical and\ncase studies with jet-engine dataset.", "AI": {"tldr": "The paper proposes a unified Bayesian framework to jointly model multi-sensor time-series data and failure modes for accurate RUL prediction with uncertainty quantification.", "motivation": "Existing models treat failure modes and RUL prediction independently or use black-box ML, lacking statistical rigor and uncertainty characterization.", "method": "Integrates Cox proportional hazards, Convolved Multi-output Gaussian Process, and multinomial failure mode distributions in a hierarchical Bayesian framework, using Variational Bayes and Monte Carlo sampling.", "result": "Validated through numerical and case studies on a jet-engine dataset, showing accurate predictions with robust uncertainty quantification.", "conclusion": "The proposed model effectively combines multi-sensor data and failure modes, offering statistically rigorous and uncertainty-aware RUL predictions."}}
{"id": "2402.08801", "pdf": "https://arxiv.org/pdf/2402.08801", "abs": "https://arxiv.org/abs/2402.08801", "authors": ["Leuson Da Silva", "Jordan Samhi", "Foutse Khomh"], "title": "LLMs and Stack Overflow Discussions: Reliability, Impact, and Challenges", "categories": ["cs.SE", "cs.AI"], "comment": "63 pages, 11 figures", "summary": "Since its release in November 2022, ChatGPT has shaken up Stack Overflow, the\npremier platform for developers queries on programming and software\ndevelopment. Demonstrating an ability to generate instant, human-like responses\nto technical questions, ChatGPT has ignited debates within the developer\ncommunity about the evolving role of human-driven platforms in the age of\ngenerative AI. Two months after ChatGPT release, Meta released its answer with\nits own Large Language Model (LLM) called LLaMA: the race was on. We conducted\nan empirical study analyzing questions from Stack Overflow and using these LLMs\nto address them. This way, we aim to (i) quantify the reliability of LLMs\nanswers and their potential to replace Stack Overflow in the long term; (ii)\nidentify and understand why LLMs fail; (iii) measure users activity evolution\nwith Stack Overflow over time; and (iv) compare LLMs together. Our empirical\nresults are unequivocal: ChatGPT and LLaMA challenge human expertise, yet do\nnot outperform it for some domains, while a significant decline in user posting\nactivity has been observed. Furthermore, we also discuss the impact of our\nfindings regarding the usage and development of new LLMs and provide guidelines\nfor future challenges faced by users and researchers.", "AI": {"tldr": "The paper examines the impact of ChatGPT and LLaMA on Stack Overflow, analyzing their reliability, failure reasons, user activity trends, and comparative performance. Results show LLMs challenge but don't surpass human expertise, with declining user activity.", "motivation": "To assess the potential of LLMs like ChatGPT and LLaMA to replace human-driven platforms like Stack Overflow and understand their limitations.", "method": "Empirical study using Stack Overflow questions and responses from ChatGPT and LLaMA.", "result": "LLMs challenge human expertise but don't outperform it in some domains; user activity on Stack Overflow declined.", "conclusion": "The findings highlight LLMs' limitations and provide guidelines for future research and usage, emphasizing the continued relevance of human expertise."}}
{"id": "2502.01208", "pdf": "https://arxiv.org/pdf/2502.01208", "abs": "https://arxiv.org/abs/2502.01208", "authors": ["Xiaotong Ji", "Shyam Sundhar Ramesh", "Matthieu Zimmer", "Ilija Bogunovic", "Jun Wang", "Haitham Bou Ammar"], "title": "On Almost Surely Safe Alignment of Large Language Models at Inference-Time", "categories": ["cs.LG", "cs.CL"], "comment": null, "summary": "We introduce a novel inference-time alignment approach for LLMs that aims to\ngenerate safe responses almost surely, i.e., with probability approaching one.\nOur approach models the generation of safe responses as a constrained Markov\nDecision Process (MDP) within the LLM's latent space. We augment a safety state\nthat tracks the evolution of safety constraints and dynamically penalize unsafe\ngenerations to ensure the generation of safe responses. Consequently, we\ndemonstrate formal safety guarantees w.r.t. the given cost model upon solving\nthe MDP in the latent space with sufficiently large penalties. Building on this\nfoundation, we propose InferenceGuard, a practical implementation that safely\naligns LLMs without modifying the model weights. Empirically, we demonstrate\nthat InferenceGuard effectively balances safety and task performance,\noutperforming existing inference-time alignment methods in generating safe and\naligned responses. Our findings contribute to the advancement of safer LLM\ndeployment through alignment at inference-time, thus presenting a promising\nalternative to resource-intensive, overfitting-prone alignment techniques like\nRLHF.", "AI": {"tldr": "A novel inference-time alignment method, InferenceGuard, ensures safe LLM responses by modeling safety as a constrained MDP in latent space, achieving formal safety guarantees without modifying model weights.", "motivation": "To generate safe LLM responses almost surely, avoiding resource-intensive methods like RLHF.", "method": "Models safe response generation as a constrained MDP in latent space, dynamically penalizing unsafe outputs.", "result": "InferenceGuard outperforms existing methods in balancing safety and task performance.", "conclusion": "InferenceGuard offers a practical, safer alternative for LLM alignment at inference-time."}}
{"id": "2504.08584", "pdf": "https://arxiv.org/pdf/2504.08584", "abs": "https://arxiv.org/abs/2504.08584", "authors": ["Mahshad Lotfinia", "Arash Tayebiarasteh", "Samaneh Samiei", "Mehdi Joodaki", "Soroosh Tayebi Arasteh"], "title": "Boosting multi-demographic federated learning for chest radiograph analysis using general-purpose self-supervised representations", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": "Published in European Journal of Radiology Artificial Intelligence", "summary": "Reliable artificial intelligence (AI) models for medical image analysis often\ndepend on large and diverse labeled datasets. Federated learning (FL) offers a\ndecentralized and privacy-preserving approach to training but struggles in\nhighly non-independent and identically distributed (non-IID) settings, where\ninstitutions with more representative data may experience degraded performance.\nMoreover, existing large-scale FL studies have been limited to adult datasets,\nneglecting the unique challenges posed by pediatric data, which introduces\nadditional non-IID variability. To address these limitations, we analyzed\nn=398,523 adult chest radiographs from diverse institutions across multiple\ncountries and n=9,125 pediatric images, leveraging transfer learning from\ngeneral-purpose self-supervised image representations to classify pneumonia and\ncases with no abnormality. Using state-of-the-art vision transformers, we found\nthat FL improved performance only for smaller adult datasets (P<0.001) but\ndegraded performance for larger datasets (P<0.064) and pediatric cases\n(P=0.242). However, equipping FL with self-supervised weights significantly\nenhanced outcomes across pediatric cases (P=0.031) and most adult datasets\n(P<0.008), except the largest dataset (P=0.052). These findings underscore the\npotential of easily deployable general-purpose self-supervised image\nrepresentations to address non-IID challenges in clinical FL applications and\nhighlight their promise for enhancing patient outcomes and advancing pediatric\nhealthcare, where data scarcity and variability remain persistent obstacles.", "AI": {"tldr": "FL struggles with non-IID data, especially pediatric datasets. Self-supervised learning improves FL performance in pediatric and most adult cases.", "motivation": "Address performance degradation of FL in non-IID settings, particularly for pediatric data, using self-supervised learning.", "method": "Analyzed adult and pediatric chest radiographs using FL and transfer learning with self-supervised image representations.", "result": "FL improved smaller adult datasets but degraded larger ones and pediatric cases. Self-supervised weights enhanced pediatric and most adult datasets.", "conclusion": "Self-supervised learning can mitigate non-IID challenges in FL, benefiting pediatric healthcare despite data scarcity."}}
{"id": "2506.17063", "pdf": "https://arxiv.org/pdf/2506.17063", "abs": "https://arxiv.org/abs/2506.17063", "authors": ["Samer Lahoud", "Kinda Khawam"], "title": "Client Selection Strategies for Federated Semantic Communications in Heterogeneous IoT Networks", "categories": ["cs.NI", "cs.LG"], "comment": null, "summary": "The exponential growth of IoT devices presents critical challenges in\nbandwidth-constrained wireless networks, particularly regarding efficient data\ntransmission and privacy preservation. This paper presents a novel federated\nsemantic communication (SC) framework that enables collaborative training of\nbandwidth-efficient models for image reconstruction across heterogeneous IoT\ndevices. By leveraging SC principles to transmit only semantic features, our\napproach dramatically reduces communication overhead while preserving\nreconstruction quality. We address the fundamental challenge of client\nselection in federated learning environments where devices exhibit significant\ndisparities in dataset sizes and data distributions. Our framework implements\nthree distinct client selection strategies that explore different trade-offs\nbetween system performance and fairness in resource allocation. The system\nemploys an end-to-end SC architecture with semantic bottlenecks, coupled with a\nloss-based aggregation mechanism that naturally adapts to client heterogeneity.\nExperimental evaluation on image data demonstrates that while Utilitarian\nselection achieves the highest reconstruction quality, Proportional Fairness\nmaintains competitive performance while significantly reducing participation\ninequality and improving computational efficiency. These results establish that\nfederated SC can successfully balance reconstruction quality, resource\nefficiency, and fairness in heterogeneous IoT deployments, paving the way for\nsustainable and privacy-preserving edge intelligence applications.", "AI": {"tldr": "A federated semantic communication framework for IoT devices reduces bandwidth usage and preserves privacy by transmitting only semantic features, addressing client selection challenges in heterogeneous environments.", "motivation": "The rapid growth of IoT devices strains bandwidth-constrained networks, necessitating efficient data transmission and privacy solutions.", "method": "The paper introduces a federated SC framework with three client selection strategies, semantic bottlenecks, and a loss-based aggregation mechanism for heterogeneous IoT devices.", "result": "Utilitarian selection yields the best reconstruction quality, while Proportional Fairness reduces participation inequality and improves efficiency.", "conclusion": "Federated SC balances quality, efficiency, and fairness, enabling sustainable, privacy-preserving edge intelligence."}}
{"id": "2403.16354", "pdf": "https://arxiv.org/pdf/2403.16354", "abs": "https://arxiv.org/abs/2403.16354", "authors": ["Kyla H. Levin", "Nicolas van Kempen", "Emery D. Berger", "Stephen N. Freund"], "title": "ChatDBG: Augmenting Debugging with Large Language Models", "categories": ["cs.SE", "cs.AI", "cs.LG", "cs.PL"], "comment": "22 pages, https://doi.org/10.1145/3729355", "summary": "Debugging is a critical but challenging task for programmers. This paper\nproposes ChatDBG, an AI-powered debugging assistant. ChatDBG integrates large\nlanguage models (LLMs) to significantly enhance the capabilities and\nuser-friendliness of conventional debuggers. ChatDBG lets programmers engage in\na collaborative dialogue with the debugger, allowing them to pose complex\nquestions about program state, perform root cause analysis for crashes or\nassertion failures, and explore open-ended queries like \"why is x null?\". To\nhandle these queries, ChatDBG grants the LLM autonomy to \"take the wheel\": it\ncan act as an independent agent capable of querying and controlling the\ndebugger to navigate through stacks and inspect program state. It then reports\nits findings and yields back control to the programmer. By leveraging the\nreal-world knowledge embedded in LLMs, ChatDBG can diagnose issues identifiable\nonly through the use of domain-specific reasoning. Our ChatDBG prototype\nintegrates with standard debuggers including LLDB and GDB for native code and\nPdb for Python. Our evaluation across a diverse set of code, including C/C++\ncode with known bugs and a suite of Python code including standalone scripts\nand Jupyter notebooks, demonstrates that ChatDBG can successfully analyze root\ncauses, explain bugs, and generate accurate fixes for a wide range of\nreal-world errors. For the Python programs, a single query led to an actionable\nbug fix 67% of the time; one additional follow-up query increased the success\nrate to 85%. ChatDBG has seen rapid uptake; it has already been downloaded more\nthan 75,000 times.", "AI": {"tldr": "ChatDBG is an AI-powered debugging assistant using LLMs to enhance debuggers, enabling collaborative dialogue for root cause analysis and bug fixes.", "motivation": "Debugging is challenging; ChatDBG aims to improve it by integrating LLMs for more intuitive and effective debugging.", "method": "ChatDBG integrates with standard debuggers (LLDB, GDB, Pdb) and uses LLMs to autonomously query and analyze program state.", "result": "ChatDBG successfully diagnoses and fixes bugs, achieving 67% success with one query and 85% with a follow-up in Python programs.", "conclusion": "ChatDBG is a practical, widely adopted tool that significantly improves debugging efficiency and accuracy."}}
{"id": "2503.06680", "pdf": "https://arxiv.org/pdf/2503.06680", "abs": "https://arxiv.org/abs/2503.06680", "authors": ["Wei Li", "Xin Zhang", "Zhongxin Guo", "Shaoguang Mao", "Wen Luo", "Guangyue Peng", "Yangyu Huang", "Houfeng Wang", "Scarlett Li"], "title": "FEA-Bench: A Benchmark for Evaluating Repository-Level Code Generation for Feature Implementation", "categories": ["cs.SE", "cs.CL"], "comment": "V2, Accepted by ACL 2025 main conference", "summary": "Implementing new features in repository-level codebases is a crucial\napplication of code generation models. However, current benchmarks lack a\ndedicated evaluation framework for this capability. To fill this gap, we\nintroduce FEA-Bench, a benchmark designed to assess the ability of large\nlanguage models (LLMs) to perform incremental development within code\nrepositories. We collect pull requests from 83 GitHub repositories and use\nrule-based and intent-based filtering to construct task instances focused on\nnew feature development. Each task instance containing code changes is paired\nwith relevant unit test files to ensure that the solution can be verified. The\nfeature implementation requires LLMs to simultaneously possess code completion\ncapabilities for new components and code editing abilities for other relevant\nparts in the code repository, providing a more comprehensive evaluation method\nof LLMs' automated software engineering capabilities. Experimental results show\nthat LLMs perform significantly worse in the FEA-Bench, highlighting\nconsiderable challenges in such repository-level incremental code development.", "AI": {"tldr": "FEA-Bench is a benchmark for evaluating LLMs' ability to perform incremental feature development in code repositories, revealing significant challenges.", "motivation": "Current benchmarks lack a dedicated framework for evaluating LLMs' capability in repository-level feature implementation.", "method": "FEA-Bench collects pull requests from 83 GitHub repositories, filters them for new feature tasks, and pairs code changes with unit tests for verification.", "result": "LLMs perform significantly worse in FEA-Bench, indicating challenges in repository-level incremental development.", "conclusion": "FEA-Bench provides a comprehensive evaluation of LLMs' automated software engineering capabilities, highlighting gaps in repository-level feature implementation."}}
{"id": "2504.12696", "pdf": "https://arxiv.org/pdf/2504.12696", "abs": "https://arxiv.org/abs/2504.12696", "authors": ["Naibang Wang", "Deyong Shang", "Yan Gong", "Xiaoxi Hu", "Ziying Song", "Lei Yang", "Yuhan Huang", "Xiaoyu Wang", "Jianli Lu"], "title": "Collaborative Perception Datasets for Autonomous Driving: A Review", "categories": ["cs.CV"], "comment": "18pages, 7figures, journal", "summary": "Collaborative perception has attracted growing interest from academia and\nindustry due to its potential to enhance perception accuracy, safety, and\nrobustness in autonomous driving through multi-agent information fusion. With\nthe advancement of Vehicle-to-Everything (V2X) communication, numerous\ncollaborative perception datasets have emerged, varying in cooperation\nparadigms, sensor configurations, data sources, and application scenarios.\nHowever, the absence of systematic summarization and comparative analysis\nhinders effective resource utilization and standardization of model evaluation.\nAs the first comprehensive review focused on collaborative perception datasets,\nthis work reviews and compares existing resources from a multi-dimensional\nperspective. We categorize datasets based on cooperation paradigms, examine\ntheir data sources and scenarios, and analyze sensor modalities and supported\ntasks. A detailed comparative analysis is conducted across multiple dimensions.\nWe also outline key challenges and future directions, including dataset\nscalability, diversity, domain adaptation, standardization, privacy, and the\nintegration of large language models. To support ongoing research, we provide a\ncontinuously updated online repository of collaborative perception datasets and\nrelated literature:\nhttps://github.com/frankwnb/Collaborative-Perception-Datasets-for-Autonomous-Driving.", "AI": {"tldr": "This paper provides a comprehensive review of collaborative perception datasets for autonomous driving, analyzing their cooperation paradigms, sensor configurations, and applications, while highlighting challenges and future directions.", "motivation": "The lack of systematic summarization and comparative analysis of collaborative perception datasets hinders resource utilization and model evaluation standardization.", "method": "The work categorizes datasets by cooperation paradigms, examines data sources and scenarios, and analyzes sensor modalities and tasks. A comparative analysis is conducted across multiple dimensions.", "result": "The review identifies key challenges like dataset scalability, diversity, domain adaptation, standardization, privacy, and integration of large language models.", "conclusion": "The paper outlines future directions and provides an online repository for ongoing research in collaborative perception datasets."}}
{"id": "2506.17064", "pdf": "https://arxiv.org/pdf/2506.17064", "abs": "https://arxiv.org/abs/2506.17064", "authors": ["Aditya Sengar", "Ali Hariri", "Daniel Probst", "Patrick Barth", "Pierre Vandergheynst"], "title": "Generative Modeling of Full-Atom Protein Conformations using Latent Diffusion on Graph Embeddings", "categories": ["q-bio.BM", "cs.LG"], "comment": "10 pages (main text), 4 figures, 2 tables. Submitted to NeurIPS 2025.\n  Code and data are publicly available", "summary": "Generating diverse, all-atom conformational ensembles of dynamic proteins\nsuch as G-protein-coupled receptors (GPCRs) is critical for understanding their\nfunction, yet most generative models simplify atomic detail or ignore\nconformational diversity altogether. We present latent diffusion for full\nprotein generation (LD-FPG), a framework that constructs complete all-atom\nprotein structures, including every side-chain heavy atom, directly from\nmolecular dynamics (MD) trajectories. LD-FPG employs a Chebyshev graph neural\nnetwork (ChebNet) to obtain low-dimensional latent embeddings of protein\nconformations, which are processed using three pooling strategies: blind,\nsequential and residue-based. A diffusion model trained on these latent\nrepresentations generates new samples that a decoder, optionally regularized by\ndihedral-angle losses, maps back to Cartesian coordinates. Using D2R-MD, a\n2-microsecond MD trajectory (12 000 frames) of the human dopamine D2 receptor\nin a membrane environment, the sequential and residue-based pooling strategy\nreproduces the reference ensemble with high structural fidelity (all-atom lDDT\nof approximately 0.7; C-alpha-lDDT of approximately 0.8) and recovers backbone\nand side-chain dihedral-angle distributions with a Jensen-Shannon divergence of\nless than 0.03 compared to the MD data. LD-FPG thereby offers a practical route\nto system-specific, all-atom ensemble generation for large proteins, providing\na promising tool for structure-based therapeutic design on complex, dynamic\ntargets. The D2R-MD dataset and our implementation are freely available to\nfacilitate further research.", "AI": {"tldr": "LD-FPG is a framework for generating all-atom protein structures from MD trajectories using latent diffusion and ChebNet, achieving high structural fidelity and recovering dihedral-angle distributions.", "motivation": "Understanding dynamic proteins like GPCRs requires diverse, all-atom conformational ensembles, but current models often lack atomic detail or diversity.", "method": "LD-FPG uses ChebNet for latent embeddings, three pooling strategies (blind, sequential, residue-based), and a diffusion model with optional dihedral-angle regularization to generate structures.", "result": "Sequential and residue-based pooling reproduce reference ensembles with high fidelity (all-atom lDDT ~0.7, C-alpha-lDDT ~0.8) and low Jensen-Shannon divergence (<0.03) for dihedral angles.", "conclusion": "LD-FPG enables system-specific, all-atom ensemble generation for large proteins, aiding structure-based therapeutic design. The D2R-MD dataset and implementation are publicly available."}}
{"id": "2407.03146", "pdf": "https://arxiv.org/pdf/2407.03146", "abs": "https://arxiv.org/abs/2407.03146", "authors": ["Yunpeng Jiang", "Yutong Ban", "Paul Weng"], "title": "Understanding and Reducing the Class-Dependent Effects of Data Augmentation with A Two-Player Game Approach", "categories": ["cs.CY", "cs.AI", "cs.CV", "cs.GT", "cs.LG"], "comment": null, "summary": "Data augmentation is widely applied and has shown its benefits in different\nmachine learning tasks. However, as recently observed, it may have an unfair\neffect in multi-class classification. While data augmentation generally\nimproves the overall performance (and therefore is beneficial for many\nclasses), it can actually be detrimental for other classes, which can be\nproblematic in some application domains. In this paper, to counteract this\nphenomenon, we propose CLAM, a CLAss-dependent Multiplicative-weights method.\nTo derive it, we first formulate the training of a classifier as a non-linear\noptimization problem that aims at simultaneously maximizing the individual\nclass performances and balancing them. By rewriting this optimization problem\nas an adversarial two-player game, we propose a novel multiplicative weight\nalgorithm, for which we prove the convergence. Interestingly, our formulation\nalso reveals that the class-dependent effects of data augmentation is not due\nto data augmentation only, but is in fact a general phenomenon. Our empirical\nresults over six datasets demonstrate that the performance of learned\nclassifiers is indeed more fairly distributed over classes, with only limited\nimpact on the average accuracy.", "AI": {"tldr": "CLAM addresses unfair class performance in data-augmented multi-class classification by balancing individual class improvements.", "motivation": "Data augmentation can unfairly harm some classes in multi-class tasks, despite overall performance gains.", "method": "Proposes CLAM, a class-dependent multiplicative-weights method, formulated as an adversarial game for balanced class performance.", "result": "Empirical results show fairer class performance distribution with minimal impact on average accuracy.", "conclusion": "CLAM effectively mitigates unfair class effects in data augmentation, a general phenomenon beyond augmentation alone."}}
{"id": "2505.15517", "pdf": "https://arxiv.org/pdf/2505.15517", "abs": "https://arxiv.org/abs/2505.15517", "authors": ["Kaiyuan Chen", "Shuangyu Xie", "Zehan Ma", "Pannag R Sanketi", "Ken Goldberg"], "title": "Robo2VLM: Visual Question Answering from Large-Scale In-the-Wild Robot Manipulation Datasets", "categories": ["cs.RO", "cs.AI", "cs.CL", "cs.LG"], "comment": null, "summary": "Vision-Language Models (VLMs) acquire real-world knowledge and general\nreasoning ability through Internet-scale image-text corpora. They can augment\nrobotic systems with scene understanding and task planning, and assist\nvisuomotor policies that are trained on robot trajectory data. We explore the\nreverse paradigm - using rich, real, multi-modal robot trajectory data to\nenhance and evaluate VLMs. In this paper, we present Robo2VLM, a Visual\nQuestion Answering (VQA) dataset generation framework for VLMs. Given a human\ntele-operated robot trajectory, Robo2VLM derives ground-truth from non-visual\nand non-descriptive sensory modalities, such as end-effector pose, gripper\naperture, and force sensing. Based on these modalities, it segments the robot\ntrajectory into a sequence of manipulation phases. At each phase, Robo2VLM uses\nscene and interaction understanding to identify 3D properties of the robot,\ntask goal, and the target object. The properties are used to generate\nrepresentative VQA queries - images with textural multiple-choice questions -\nbased on spatial, goal-conditioned, and interaction reasoning question\ntemplates. We curate Robo2VLM-1, a large-scale in-the-wild dataset with 684,710\nquestions covering 463 distinct scenes and 3,396 robotic manipulation tasks\nfrom 176k real robot trajectories. Results suggest that Robo2VLM-1 can\nbenchmark and improve VLM capabilities in spatial and interaction reasoning.", "AI": {"tldr": "Robo2VLM is a framework for generating VQA datasets from robot trajectories to enhance VLMs, tested with a large-scale dataset showing improved spatial and interaction reasoning.", "motivation": "To leverage real robot trajectory data to enhance and evaluate Vision-Language Models (VLMs) by providing rich, multi-modal sensory inputs.", "method": "Robo2VLM segments robot trajectories into manipulation phases, extracts 3D properties, and generates VQA queries (images with questions) based on spatial, goal-conditioned, and interaction reasoning.", "result": "Created Robo2VLM-1, a dataset with 684,710 questions from 176k trajectories, showing improved VLM capabilities in spatial and interaction reasoning.", "conclusion": "Robo2VLM effectively benchmarks and enhances VLMs using real robot data, demonstrating its potential for improving scene and interaction understanding."}}
{"id": "2504.13180", "pdf": "https://arxiv.org/pdf/2504.13180", "abs": "https://arxiv.org/abs/2504.13180", "authors": ["Jang Hyun Cho", "Andrea Madotto", "Effrosyni Mavroudi", "Triantafyllos Afouras", "Tushar Nagarajan", "Muhammad Maaz", "Yale Song", "Tengyu Ma", "Shuming Hu", "Suyog Jain", "Miguel Martin", "Huiyu Wang", "Hanoona Rasheed", "Peize Sun", "Po-Yao Huang", "Daniel Bolya", "Nikhila Ravi", "Shashank Jain", "Tammy Stark", "Shane Moon", "Babak Damavandi", "Vivian Lee", "Andrew Westbury", "Salman Khan", "Philipp Kr\u00e4henb\u00fchl", "Piotr Doll\u00e1r", "Lorenzo Torresani", "Kristen Grauman", "Christoph Feichtenhofer"], "title": "PerceptionLM: Open-Access Data and Models for Detailed Visual Understanding", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": "Technical Report", "summary": "Vision-language models are integral to computer vision research, yet many\nhigh-performing models remain closed-source, obscuring their data, design and\ntraining recipe. The research community has responded by using distillation\nfrom black-box models to label training data, achieving strong benchmark\nresults, at the cost of measurable scientific progress. However, without\nknowing the details of the teacher model and its data sources, scientific\nprogress remains difficult to measure. In this paper, we study building a\nPerception Language Model (PLM) in a fully open and reproducible framework for\ntransparent research in image and video understanding. We analyze standard\ntraining pipelines without distillation from proprietary models and explore\nlarge-scale synthetic data to identify critical data gaps, particularly in\ndetailed video understanding. To bridge these gaps, we release 2.8M\nhuman-labeled instances of fine-grained video question-answer pairs and\nspatio-temporally grounded video captions. Additionally, we introduce\nPLM-VideoBench, a suite for evaluating challenging video understanding tasks\nfocusing on the ability to reason about \"what\", \"where\", \"when\", and \"how\" of a\nvideo. We make our work fully reproducible by providing data, training recipes,\ncode & models. https://github.com/facebookresearch/perception_models", "AI": {"tldr": "The paper introduces a fully open and reproducible Perception Language Model (PLM) for transparent research in image and video understanding, avoiding reliance on closed-source models. It addresses data gaps with 2.8M human-labeled video QA pairs and introduces PLM-VideoBench for evaluation.", "motivation": "To counter the opacity of high-performing closed-source vision-language models, the paper aims to enable transparent research by building an open framework without proprietary model distillation.", "method": "The study analyzes standard training pipelines without proprietary distillation, explores large-scale synthetic data, and releases human-labeled video QA pairs and captions.", "result": "The work provides 2.8M labeled video instances and PLM-VideoBench for evaluation, ensuring reproducibility with open data, code, and models.", "conclusion": "The paper advances transparent research in vision-language models by offering open tools and addressing critical data gaps in video understanding."}}
{"id": "2506.17076", "pdf": "https://arxiv.org/pdf/2506.17076", "abs": "https://arxiv.org/abs/2506.17076", "authors": ["Ziv Aharoni", "Henry D. Pfister"], "title": "Neural Polar Decoders for DNA Data Storage", "categories": ["cs.IT", "cs.LG", "math.IT"], "comment": null, "summary": "Synchronization errors, such as insertions and deletions, present a\nfundamental challenge in DNA-based data storage systems, arising from both\nsynthesis and sequencing noise. These channels are often modeled as\ninsertion-deletion-substitution (IDS) channels, for which designing\nmaximum-likelihood decoders is computationally expensive. In this work, we\npropose a data-driven approach based on neural polar decoders (NPDs) to design\nlow-complexity decoders for channels with synchronization errors. The proposed\narchitecture enables decoding over IDS channels with reduced complexity $O(AN\nlog N )$, where $A$ is a tunable parameter independent of the channel. NPDs\nrequire only sample access to the channel and can be trained without an\nexplicit channel model. Additionally, NPDs provide mutual information (MI)\nestimates that can be used to optimize input distributions and code design. We\ndemonstrate the effectiveness of NPDs on both synthetic deletion and IDS\nchannels. For deletion channels, we show that NPDs achieve near-optimal\ndecoding performance and accurate MI estimation, with significantly lower\ncomplexity than trellis-based decoders. We also provide numerical estimates of\nthe channel capacity for the deletion channel. We extend our evaluation to\nrealistic DNA storage settings, including channels with multiple noisy reads\nand real-world Nanopore sequencing data. Our results show that NPDs match or\nsurpass the performance of existing methods while using significantly fewer\nparameters than the state-of-the-art. These findings highlight the promise of\nNPDs for robust and efficient decoding in DNA data storage systems.", "AI": {"tldr": "The paper proposes neural polar decoders (NPDs) for efficient decoding in DNA data storage systems, addressing synchronization errors with reduced complexity and no explicit channel model requirement.", "motivation": "Synchronization errors (insertions, deletions) in DNA storage systems are challenging. Existing decoders are computationally expensive, motivating a low-complexity, data-driven solution.", "method": "Uses neural polar decoders (NPDs) with complexity O(AN log N), requiring only sample access to the channel and no explicit model. Provides mutual information estimates for optimization.", "result": "NPDs achieve near-optimal decoding for deletion channels, accurate MI estimation, and outperform existing methods in realistic DNA storage settings with fewer parameters.", "conclusion": "NPDs offer a robust, efficient solution for DNA data storage decoding, matching or surpassing state-of-the-art performance with lower complexity."}}
{"id": "2408.09251", "pdf": "https://arxiv.org/pdf/2408.09251", "abs": "https://arxiv.org/abs/2408.09251", "authors": ["Junwei You", "Haotian Shi", "Zhuoyu Jiang", "Zilin Huang", "Rui Gan", "Keshu Wu", "Xi Cheng", "Xiaopeng Li", "Bin Ran"], "title": "V2X-VLM: End-to-End V2X Cooperative Autonomous Driving Through Large Vision-Language Models", "categories": ["cs.RO", "cs.AI", "cs.LG"], "comment": null, "summary": "Vehicle-to-everything (V2X) cooperation has emerged as a promising paradigm\nto overcome the perception limitations of classical autonomous driving by\nleveraging information from both ego-vehicle and infrastructure sensors.\nHowever, effectively fusing heterogeneous visual and semantic information while\nensuring robust trajectory planning remains a significant challenge. This paper\nintroduces V2X-VLM, a novel end-to-end (E2E) cooperative autonomous driving\nframework based on vision-language models (VLMs). V2X-VLM integrates\nmultiperspective camera views from vehicles and infrastructure with text-based\nscene descriptions to enable a more comprehensive understanding of driving\nenvironments. Specifically, we propose a contrastive learning-based mechanism\nto reinforce the alignment of heterogeneous visual and textual characteristics,\nwhich enhances the semantic understanding of complex driving scenarios, and\nemploy a knowledge distillation strategy to stabilize training. Experiments on\na large real-world dataset demonstrate that V2X-VLM achieves state-of-the-art\ntrajectory planning accuracy, significantly reducing L2 error and collision\nrate compared to existing cooperative autonomous driving baselines. Ablation\nstudies validate the contributions of each component. Moreover, the evaluation\nof robustness and efficiency highlights the practicality of V2X-VLM for\nreal-world deployment to enhance overall autonomous driving safety and\ndecision-making.", "AI": {"tldr": "V2X-VLM is an end-to-end cooperative autonomous driving framework using vision-language models to fuse visual and textual data, improving trajectory planning accuracy and safety.", "motivation": "Overcome perception limitations in autonomous driving by integrating heterogeneous sensor data from vehicles and infrastructure.", "method": "Uses contrastive learning for visual-textual alignment and knowledge distillation for stable training.", "result": "Achieves state-of-the-art trajectory planning accuracy, reducing L2 error and collision rates.", "conclusion": "V2X-VLM is practical for real-world deployment, enhancing autonomous driving safety and decision-making."}}
{"id": "2505.16975", "pdf": "https://arxiv.org/pdf/2505.16975", "abs": "https://arxiv.org/abs/2505.16975", "authors": ["Yaxin Du", "Yuzhu Cai", "Yifan Zhou", "Cheng Wang", "Yu Qian", "Xianghe Pang", "Qian Liu", "Yue Hu", "Siheng Chen"], "title": "SWE-Dev: Evaluating and Training Autonomous Feature-Driven Software Development", "categories": ["cs.SE", "cs.CL"], "comment": null, "summary": "Large Language Models (LLMs) have shown strong capability in diverse software\nengineering tasks, e.g. code completion, bug fixing, and document generation.\nHowever, feature-driven development (FDD), a highly prevalent real-world task\nthat involves developing new functionalities for large, existing codebases,\nremains underexplored. We therefore introduce SWE-Dev, the first large-scale\ndataset (with 14,000 training and 500 test samples) designed to evaluate and\ntrain autonomous coding systems on real-world feature development tasks. To\nensure verifiable and diverse training, SWE-Dev uniquely provides all instances\nwith a runnable environment and its developer-authored executable unit tests.\nThis collection not only provides high-quality data for Supervised Fine-Tuning\n(SFT), but also enables Reinforcement Learning (RL) by delivering accurate\nreward signals from executable unit tests. Our extensive evaluations on\nSWE-Dev, covering 17 chatbot LLMs, 10 reasoning models, and 10 Multi-Agent\nSystems (MAS), reveal that FDD is a profoundly challenging frontier for current\nAI (e.g., Claude-3.7-Sonnet achieves only 22.45\\% Pass@3 on the hard test\nsplit). Crucially, we demonstrate that SWE-Dev serves as an effective platform\nfor model improvement: fine-tuning on training set enabled a 7B model\ncomparable to GPT-4o on \\textit{hard} split, underscoring the value of its\nhigh-quality training data. Code is available here\n\\href{https://github.com/DorothyDUUU/SWE-Dev}{https://github.com/DorothyDUUU/SWE-Dev}.", "AI": {"tldr": "SWE-Dev is a large-scale dataset for evaluating and training autonomous coding systems on real-world feature development tasks, providing runnable environments and unit tests. It reveals the challenge of FDD for AI and shows potential for model improvement.", "motivation": "Feature-driven development (FDD) is underexplored despite its prevalence in software engineering. SWE-Dev addresses this gap by providing a dataset for training and evaluating AI systems.", "method": "SWE-Dev includes 14,000 training and 500 test samples with runnable environments and unit tests, enabling Supervised Fine-Tuning (SFT) and Reinforcement Learning (RL).", "result": "Evaluations show FDD is challenging for current AI (e.g., Claude-3.7-Sonnet achieves 22.45% Pass@3). Fine-tuning on SWE-Dev improved a 7B model to GPT-4o level on hard tasks.", "conclusion": "SWE-Dev is a valuable platform for advancing AI in feature-driven development, offering high-quality data and demonstrating model improvement potential."}}
{"id": "2505.03991", "pdf": "https://arxiv.org/pdf/2505.03991", "abs": "https://arxiv.org/abs/2505.03991", "authors": ["Hao Xu", "Arbind Agrahari Baniya", "Sam Well", "Mohamed Reda Bouadjenek", "Richard Dazeley", "Sunil Aryal"], "title": "Action Spotting and Precise Event Detection in Sports: Datasets, Methods, and Challenges", "categories": ["cs.CV"], "comment": "15 pages, 7 figures, 3 tables", "summary": "Video event detection is central to modern sports analytics, enabling\nautomated understanding of key moments for performance evaluation, content\ncreation, and tactical feedback. While deep learning has significantly advanced\ntasks like Temporal Action Localization (TAL), Action Spotting (AS), and\nPrecise Event Spotting (PES), existing surveys often overlook the fine-grained\ntemporal demands and domain-specific challenges posed by sports. This survey\nfirst provides a clear conceptual distinction between TAL, AS, and PES, then\nintroduces a methods-based taxonomy covering recent deep learning approaches\nfor AS and PES, including feature-based pipelines, end-to-end architectures,\nand multimodal strategies. We further review benchmark datasets and evaluation\nprotocols, identifying critical limitations such as reliance on\nbroadcast-quality footage and lenient multi-label metrics that hinder\nreal-world deployment. Finally, we outline open challenges and future\ndirections toward more temporally precise, generalizable, and practical event\nspotting in sports video analysis.", "AI": {"tldr": "This survey distinguishes between Temporal Action Localization (TAL), Action Spotting (AS), and Precise Event Spotting (PES), reviews deep learning methods for AS and PES, and highlights dataset and evaluation limitations in sports video analysis.", "motivation": "To address the overlooked fine-grained temporal demands and domain-specific challenges in sports video event detection, and to provide a comprehensive survey of deep learning approaches.", "method": "The survey categorizes methods into feature-based pipelines, end-to-end architectures, and multimodal strategies, and reviews datasets and evaluation protocols.", "result": "Identifies limitations like reliance on broadcast-quality footage and lenient multi-label metrics, which hinder real-world deployment.", "conclusion": "Outlines open challenges and future directions for more precise, generalizable, and practical event spotting in sports video analysis."}}
{"id": "2506.17197", "pdf": "https://arxiv.org/pdf/2506.17197", "abs": "https://arxiv.org/abs/2506.17197", "authors": ["Samuel Howard", "Peter Potaptchik", "George Deligiannidis"], "title": "Schr\u00f6dinger Bridge Matching for Tree-Structured Costs and Entropic Wasserstein Barycentres", "categories": ["stat.ML", "cs.LG"], "comment": "Preprint", "summary": "Recent advances in flow-based generative modelling have provided scalable\nmethods for computing the Schr\\\"odinger Bridge (SB) between distributions, a\ndynamic form of entropy-regularised Optimal Transport (OT) for the quadratic\ncost. The successful Iterative Markovian Fitting (IMF) procedure solves the SB\nproblem via sequential bridge-matching steps, presenting an elegant and\npractical approach with many favourable properties over the more traditional\nIterative Proportional Fitting (IPF) procedure. Beyond the standard setting,\noptimal transport can be generalised to the multi-marginal case in which the\nobjective is to minimise a cost defined over several marginal distributions. Of\nparticular importance are costs defined over a tree structure, from which\nWasserstein barycentres can be recovered as a special case. In this work, we\nextend the IMF procedure to solve for the tree-structured SB problem. Our\nresulting algorithm inherits the many advantages of IMF over IPF approaches in\nthe tree-based setting. In the specific case of Wasserstein barycentres, our\napproach can be viewed as extending fixed-point approaches for barycentre\ncomputation to the case of flow-based entropic OT solvers.", "AI": {"tldr": "Extends the Iterative Markovian Fitting (IMF) procedure to solve the tree-structured Schr\u00f6dinger Bridge (SB) problem, offering advantages over traditional methods like IPF, especially for Wasserstein barycentres.", "motivation": "To generalize optimal transport to multi-marginal cases, particularly tree-structured costs, and improve upon existing methods like IPF.", "method": "Extends the IMF procedure to handle tree-structured SB problems, leveraging its advantages over IPF.", "result": "A practical algorithm for solving tree-structured SB problems, applicable to Wasserstein barycentres.", "conclusion": "The approach successfully generalizes IMF to tree-structured settings, enhancing flow-based entropic OT solvers."}}
{"id": "2505.20981", "pdf": "https://arxiv.org/pdf/2505.20981", "abs": "https://arxiv.org/abs/2505.20981", "authors": ["Cainan Davidson", "Deva Ramanan", "Neehar Peri"], "title": "RefAV: Towards Planning-Centric Scenario Mining", "categories": ["cs.CV", "cs.CL", "cs.RO"], "comment": "Project Page: https://cainand.github.io/RefAV/", "summary": "Autonomous Vehicles (AVs) collect and pseudo-label terabytes of multi-modal\ndata localized to HD maps during normal fleet testing. However, identifying\ninteresting and safety-critical scenarios from uncurated driving logs remains a\nsignificant challenge. Traditional scenario mining techniques are error-prone\nand prohibitively time-consuming, often relying on hand-crafted structured\nqueries. In this work, we revisit spatio-temporal scenario mining through the\nlens of recent vision-language models (VLMs) to detect whether a described\nscenario occurs in a driving log and, if so, precisely localize it in both time\nand space. To address this problem, we introduce RefAV, a large-scale dataset\nof 10,000 diverse natural language queries that describe complex multi-agent\ninteractions relevant to motion planning derived from 1000 driving logs in the\nArgoverse 2 Sensor dataset. We evaluate several referential multi-object\ntrackers and present an empirical analysis of our baselines. Notably, we find\nthat naively repurposing off-the-shelf VLMs yields poor performance, suggesting\nthat scenario mining presents unique challenges. Lastly, we discuss our recent\nCVPR 2025 competition and share insights from the community. Our code and\ndataset are available at https://github.com/CainanD/RefAV/ and\nhttps://argoverse.github.io/user-guide/tasks/scenario_mining.html", "AI": {"tldr": "RefAV introduces a vision-language model approach for spatio-temporal scenario mining in AV driving logs, addressing challenges in identifying safety-critical scenarios.", "motivation": "Traditional scenario mining methods are error-prone and time-consuming, necessitating a more efficient and accurate approach.", "method": "RefAV uses vision-language models (VLMs) to detect and localize described scenarios in driving logs, supported by a dataset of 10,000 natural language queries.", "result": "Off-the-shelf VLMs perform poorly, highlighting unique challenges in scenario mining. The paper presents empirical analysis and a CVPR 2025 competition.", "conclusion": "RefAV offers a novel dataset and method for scenario mining, with insights for future improvements."}}
{"id": "2505.08013", "pdf": "https://arxiv.org/pdf/2505.08013", "abs": "https://arxiv.org/abs/2505.08013", "authors": ["Gonglin Chen", "Tianwen Fu", "Haiwei Chen", "Wenbin Teng", "Hanyuan Xiao", "Yajie Zhao"], "title": "RDD: Robust Feature Detector and Descriptor using Deformable Transformer", "categories": ["cs.CV"], "comment": null, "summary": "As a core step in structure-from-motion and SLAM, robust feature detection\nand description under challenging scenarios such as significant viewpoint\nchanges remain unresolved despite their ubiquity. While recent works have\nidentified the importance of local features in modeling geometric\ntransformations, these methods fail to learn the visual cues present in\nlong-range relationships. We present Robust Deformable Detector (RDD), a novel\nand robust keypoint detector/descriptor leveraging the deformable transformer,\nwhich captures global context and geometric invariance through deformable\nself-attention mechanisms. Specifically, we observed that deformable attention\nfocuses on key locations, effectively reducing the search space complexity and\nmodeling the geometric invariance. Furthermore, we collected an Air-to-Ground\ndataset for training in addition to the standard MegaDepth dataset. Our\nproposed method outperforms all state-of-the-art keypoint detection/description\nmethods in sparse matching tasks and is also capable of semi-dense matching. To\nensure comprehensive evaluation, we introduce two challenging benchmarks: one\nemphasizing large viewpoint and scale variations, and the other being an\nAir-to-Ground benchmark -- an evaluation setting that has recently gaining\npopularity for 3D reconstruction across different altitudes.", "AI": {"tldr": "The paper introduces Robust Deformable Detector (RDD), a novel keypoint detector/descriptor using deformable transformers to improve feature detection under challenging conditions like viewpoint changes.", "motivation": "Current methods fail to capture long-range visual cues and geometric invariance, limiting robust feature detection in scenarios like structure-from-motion and SLAM.", "method": "RDD leverages deformable self-attention mechanisms to focus on key locations, reducing search space complexity and modeling geometric invariance. Training includes a new Air-to-Ground dataset alongside MegaDepth.", "result": "RDD outperforms state-of-the-art methods in sparse matching and enables semi-dense matching. Two new benchmarks are introduced for evaluation.", "conclusion": "RDD advances feature detection by addressing global context and geometric invariance, validated by superior performance and new benchmarks."}}
{"id": "2007.05943", "pdf": "https://arxiv.org/pdf/2007.05943", "abs": "https://arxiv.org/abs/2007.05943", "authors": ["Sandor Szedmak", "Eric Bach"], "title": "On the generalization of Tanimoto-type kernels to real valued functions", "categories": ["cs.LG", "stat.ML"], "comment": "Pages 12, 3 PDF figures, uses arxiv.sty", "summary": "The Tanimoto kernel (Jaccard index) is a well known tool to describe the\nsimilarity between sets of binary attributes. It has been extended to the case\nwhen the attributes are nonnegative real values. This paper introduces a more\ngeneral Tanimoto kernel formulation which allows to measure the similarity of\narbitrary real-valued functions. This extension is constructed by unifying the\nrepresentation of the attributes via properly chosen sets. After deriving the\ngeneral form of the kernel, explicit feature representation is extracted from\nthe kernel function, and a simply way of including general kernels into the\nTanimoto kernel is shown. Finally, the kernel is also expressed as a quotient\nof piecewise linear functions, and a smooth approximation is provided.", "AI": {"tldr": "The paper generalizes the Tanimoto kernel (Jaccard index) to measure similarity between arbitrary real-valued functions, unifying attribute representation via sets, and provides explicit feature extraction and smooth approximations.", "motivation": "To extend the Tanimoto kernel beyond binary and nonnegative real-valued attributes to arbitrary real-valued functions for broader applicability.", "method": "Unifies attribute representation via sets, derives the general kernel form, extracts explicit features, and includes general kernels into the Tanimoto kernel. Also expresses the kernel as a quotient of piecewise linear functions and provides a smooth approximation.", "result": "A generalized Tanimoto kernel capable of measuring similarity between arbitrary real-valued functions, with explicit feature representation and smooth approximation.", "conclusion": "The extended Tanimoto kernel offers a versatile tool for similarity measurement across a wider range of data types, with practical implementations for feature extraction and smooth approximations."}}
{"id": "2410.21349", "pdf": "https://arxiv.org/pdf/2410.21349", "abs": "https://arxiv.org/abs/2410.21349", "authors": ["Zeyuan Li", "Yangfan He", "Lewei He", "Jianhui Wang", "Tianyu Shi", "Bin Lei", "Yuchen Li", "Qiuwu Chen"], "title": "FALCON: Feedback-driven Adaptive Long/short-term memory reinforced Coding Optimization system", "categories": ["cs.LG", "cs.AI", "cs.PF"], "comment": "20 pages, 7 figures", "summary": "Recently, large language models (LLMs) have achieved significant progress in\nautomated code generation. Despite their strong instruction-following\ncapabilities, these models frequently struggled to align with user intent in\ncoding scenarios. In particular, they were hampered by datasets that lacked\ndiversity and failed to address specialized tasks or edge cases. Furthermore,\nchallenges in supervised fine-tuning (SFT) and reinforcement learning from\nhuman feedback (RLHF) led to failures in generating precise,\nhuman-intent-aligned code. To tackle these challenges and improve the code\ngeneration performance for automated programming systems, we propose\nFeedback-driven Adaptive Long/short-term memory reinforced Coding Optimization\n(i.e., FALCON). FALCON is structured into two hierarchical levels. From the\nglobal level, long-term memory improves code quality by retaining and applying\nlearned knowledge. At the local level, short-term memory allows for the\nincorporation of immediate feedback from compilers and AI systems.\nAdditionally, we introduce meta-reinforcement learning with feedback rewards to\nsolve the global-local bi-level optimization problem and enhance the model's\nadaptability across diverse code generation tasks. Extensive experiments\ndemonstrate that our technique achieves state-of-the-art performance, leading\nother reinforcement learning methods by more than 4.5 percentage points on the\nMBPP benchmark and 6.1 percentage points on the Humaneval benchmark. The\nopen-sourced code is publicly available at https://github.com/titurte/FALCON.", "AI": {"tldr": "FALCON improves LLM-based code generation by combining long/short-term memory and feedback-driven optimization, outperforming benchmarks.", "motivation": "LLMs struggle with user intent alignment in code generation due to dataset limitations and SFT/RLHF challenges.", "method": "FALCON uses hierarchical long/short-term memory and meta-reinforcement learning with feedback rewards for global-local optimization.", "result": "Achieves SOTA performance, surpassing benchmarks by 4.5% (MBPP) and 6.1% (Humaneval).", "conclusion": "FALCON effectively addresses LLM limitations in code generation, offering a robust solution with open-sourced implementation."}}
{"id": "2506.03147", "pdf": "https://arxiv.org/pdf/2506.03147", "abs": "https://arxiv.org/abs/2506.03147", "authors": ["Bin Lin", "Zongjian Li", "Xinhua Cheng", "Yuwei Niu", "Yang Ye", "Xianyi He", "Shenghai Yuan", "Wangbo Yu", "Shaodong Wang", "Yunyang Ge", "Yatian Pang", "Li Yuan"], "title": "UniWorld-V1: High-Resolution Semantic Encoders for Unified Visual Understanding and Generation", "categories": ["cs.CV", "cs.AI", "cs.CL"], "comment": null, "summary": "Although existing unified models achieve strong performance in\nvision-language understanding and text-to-image generation, they remain limited\nin addressing image perception and manipulation -- capabilities increasingly\ndemanded in practical applications. Recently, OpenAI introduced the powerful\nGPT-4o-Image model, which showcases advanced capabilities in comprehensive\nimage perception and manipulation, sparking widespread interest. Through\ncarefully designed experiments, we observe that GPT-4o-Image likely relies on\nsemantic encoders rather than VAEs for feature extraction, despite VAEs being\ncommonly regarded as crucial for image manipulation tasks. Inspired by this\ninsight, we propose UniWorld-V1, a unified generative framework built upon\nsemantic features extracted from powerful multimodal large language models and\ncontrastive semantic encoders. Using only 2.7M training data, UniWorld-V1\nachieves impressive performance across diverse tasks, including image\nunderstanding, generation, manipulation, and perception. We fully open-source\nthe UniWorld-V1 framework, including model weights, training and evaluation\nscripts, and datasets to promote reproducibility and further research.", "AI": {"tldr": "UniWorld-V1, a unified generative framework using semantic features from multimodal LLMs, achieves strong performance in image tasks despite minimal training data.", "motivation": "Existing models lack capabilities in image perception and manipulation, while GPT-4o-Image's advanced features suggest semantic encoders outperform VAEs.", "method": "Proposes UniWorld-V1, leveraging semantic features from multimodal LLMs and contrastive encoders, trained on 2.7M data.", "result": "UniWorld-V1 excels in image understanding, generation, manipulation, and perception tasks.", "conclusion": "The framework is open-sourced to encourage reproducibility and further research."}}
{"id": "2505.08429", "pdf": "https://arxiv.org/pdf/2505.08429", "abs": "https://arxiv.org/abs/2505.08429", "authors": ["Yukiyasu Kamitani", "Misato Tanaka", "Ken Shirakawa"], "title": "Visual Image Reconstruction from Brain Activity via Latent Representation", "categories": ["cs.CV", "q-bio.NC"], "comment": null, "summary": "Visual image reconstruction, the decoding of perceptual content from brain\nactivity into images, has advanced significantly with the integration of deep\nneural networks (DNNs) and generative models. This review traces the field's\nevolution from early classification approaches to sophisticated reconstructions\nthat capture detailed, subjective visual experiences, emphasizing the roles of\nhierarchical latent representations, compositional strategies, and modular\narchitectures. Despite notable progress, challenges remain, such as achieving\ntrue zero-shot generalization for unseen images and accurately modeling the\ncomplex, subjective aspects of perception. We discuss the need for diverse\ndatasets, refined evaluation metrics aligned with human perceptual judgments,\nand compositional representations that strengthen model robustness and\ngeneralizability. Ethical issues, including privacy, consent, and potential\nmisuse, are underscored as critical considerations for responsible development.\nVisual image reconstruction offers promising insights into neural coding and\nenables new psychological measurements of visual experiences, with applications\nspanning clinical diagnostics and brain-machine interfaces.", "AI": {"tldr": "The paper reviews advancements in visual image reconstruction using DNNs and generative models, highlighting progress, challenges, and ethical considerations.", "motivation": "To trace the evolution of visual image reconstruction, emphasizing the need for better generalization, ethical practices, and improved evaluation metrics.", "method": "Integration of deep neural networks (DNNs) and generative models, focusing on hierarchical latent representations and compositional strategies.", "result": "Significant progress in decoding detailed visual experiences, but challenges like zero-shot generalization and subjective perception modeling remain.", "conclusion": "Visual image reconstruction holds promise for neural coding insights and applications, but requires ethical considerations and further methodological refinements."}}
{"id": "2110.03294", "pdf": "https://arxiv.org/pdf/2110.03294", "abs": "https://arxiv.org/abs/2110.03294", "authors": ["Ilyas Fatkhullin", "Igor Sokolov", "Eduard Gorbunov", "Zhize Li", "Peter Richt\u00e1rik"], "title": "EF21 with Bells & Whistles: Six Algorithmic Extensions of Modern Error Feedback", "categories": ["cs.LG", "math.OC"], "comment": "Accepted for publication in JMLR. This extended version includes\n  detailed proofs of several extensions and additional experimental results", "summary": "First proposed by Seide (2014) as a heuristic, error feedback (EF) is a very\npopular mechanism for enforcing convergence of distributed gradient-based\noptimization methods enhanced with communication compression strategies based\non the application of contractive compression operators. However, existing\ntheory of EF relies on very strong assumptions (e.g., bounded gradients), and\nprovides pessimistic convergence rates (e.g., while the best known rate for EF\nin the smooth nonconvex regime, and when full gradients are compressed, is\n$O(1/T^{2/3})$, the rate of gradient descent in the same regime is $O(1/T)$).\nRecently, Richt\\'arik et al. (2021) proposed a new error feedback mechanism,\nEF21, based on the construction of a Markov compressor induced by a contractive\ncompressor. EF21 removes the aforementioned theoretical deficiencies of EF and\nat the same time works better in practice. In this work we propose six\npractical extensions of EF21, all supported by strong convergence theory:\npartial participation, stochastic approximation, variance reduction, proximal\nsetting, momentum, and bidirectional compression. To the best of our knowledge,\nseveral of these techniques have not been previously analyzed in combination\nwith EF, and in cases where prior analysis exists -- such as for bidirectional\ncompression -- our theoretical convergence guarantees significantly improve\nupon existing results.", "AI": {"tldr": "The paper proposes six practical extensions of the EF21 error feedback mechanism, improving convergence theory and practical performance in distributed gradient-based optimization with compression.", "motivation": "Existing error feedback (EF) mechanisms rely on strong assumptions and provide pessimistic convergence rates. EF21 addressed these issues, and this work extends EF21 further for broader applicability.", "method": "The authors introduce six extensions to EF21: partial participation, stochastic approximation, variance reduction, proximal setting, momentum, and bidirectional compression.", "result": "The proposed extensions are supported by strong convergence theory, with some techniques offering improved guarantees over prior work.", "conclusion": "The extensions enhance EF21's practicality and theoretical robustness, addressing limitations of previous EF mechanisms."}}
{"id": "2411.05409", "pdf": "https://arxiv.org/pdf/2411.05409", "abs": "https://arxiv.org/abs/2411.05409", "authors": ["Ashwin Nair", "Zhen Rong Goh", "Tianrui Liu", "Abigail Yongping Huang"], "title": "Web Archives Metadata Generation with GPT-4o: Challenges and Insights", "categories": ["cs.DL", "cs.AI"], "comment": "Published in Information Technology and Libraries, Vol. 44, No. 2,\n  June 2025", "summary": "Current metadata creation for web archives is time consuming and costly due\nto reliance on human effort. This paper explores the use of gpt-4o for metadata\ngeneration within the Web Archive Singapore, focusing on scalability,\nefficiency, and cost effectiveness. We processed 112 Web ARChive (WARC) files\nusing data reduction techniques, achieving a notable 99.9% reduction in\nmetadata generation costs. By prompt engineering, we generated titles and\nabstracts, which were evaluated both intrinsically using Levenshtein Distance\nand BERTScore, and extrinsically with human cataloguers using McNemar's test.\nResults indicate that while our method offers significant cost savings and\nefficiency gains, human curated metadata maintains an edge in quality. The\nstudy identifies key challenges including content inaccuracies, hallucinations,\nand translation issues, suggesting that Large Language Models (LLMs) should\nserve as complements rather than replacements for human cataloguers. Future\nwork will focus on refining prompts, improving content filtering, and\naddressing privacy concerns through experimentation with smaller models. This\nresearch advances the integration of LLMs in web archiving, offering valuable\ninsights into their current capabilities and outlining directions for future\nenhancements. The code is available at\nhttps://github.com/masamune-prog/warc2summary for further development and use\nby institutions facing similar challenges.", "AI": {"tldr": "The paper explores using GPT-4 for automated metadata generation in web archives, achieving 99.9% cost reduction but noting human metadata remains superior in quality.", "motivation": "To address the high cost and inefficiency of human-generated metadata in web archiving.", "method": "Processed 112 WARC files with data reduction and prompt engineering, evaluated using Levenshtein Distance, BERTScore, and human cataloguers.", "result": "Achieved significant cost savings but identified challenges like inaccuracies and hallucinations, suggesting LLMs as complements to humans.", "conclusion": "LLMs can enhance web archiving efficiency but require refinement; future work includes prompt improvement and privacy considerations."}}
{"id": "2506.05146", "pdf": "https://arxiv.org/pdf/2506.05146", "abs": "https://arxiv.org/abs/2506.05146", "authors": ["Massimo Rizzoli", "Simone Alghisi", "Olha Khomyn", "Gabriel Roccabruna", "Seyed Mahed Mousavi", "Giuseppe Riccardi"], "title": "CIVET: Systematic Evaluation of Understanding in VLMs", "categories": ["cs.CV", "cs.CL"], "comment": null, "summary": "While Vision-Language Models (VLMs) have achieved competitive performance in\nvarious tasks, their comprehension of the underlying structure and semantics of\na scene remains understudied. To investigate the understanding of VLMs, we\nstudy their capability regarding object properties and relations in a\ncontrolled and interpretable manner. To this scope, we introduce CIVET, a novel\nand extensible framework for systematiC evaluatIon Via controllEd sTimuli.\nCIVET addresses the lack of standardized systematic evaluation for assessing\nVLMs' understanding, enabling researchers to test hypotheses with statistical\nrigor. With CIVET, we evaluate five state-of-the-art VLMs on exhaustive sets of\nstimuli, free from annotation noise, dataset-specific biases, and uncontrolled\nscene complexity. Our findings reveal that 1) current VLMs can accurately\nrecognize only a limited set of basic object properties; 2) their performance\nheavily depends on the position of the object in the scene; 3) they struggle to\nunderstand basic relations among objects. Furthermore, a comparative evaluation\nwith human annotators reveals that VLMs still fall short of achieving\nhuman-level accuracy.", "AI": {"tldr": "CIVET framework evaluates VLMs' understanding of object properties and relations, revealing limitations in accuracy, positional dependence, and relational comprehension compared to humans.", "motivation": "To systematically assess VLMs' scene comprehension, addressing gaps in standardized evaluation methods.", "method": "Introduces CIVET, a controlled framework for evaluating VLMs using noise-free stimuli, testing five state-of-the-art models.", "result": "VLMs recognize limited basic properties, depend on object position, and struggle with relations, lagging behind human performance.", "conclusion": "Current VLMs lack robust scene understanding, highlighting the need for improved models and evaluation standards."}}
{"id": "2505.16033", "pdf": "https://arxiv.org/pdf/2505.16033", "abs": "https://arxiv.org/abs/2505.16033", "authors": ["Faika Fairuj Preotee", "Shuvashis Sarker", "Shamim Rahim Refat", "Tashreef Muhammad", "Shifat Islam"], "title": "An Approach Towards Identifying Bangladeshi Leaf Diseases through Transfer Learning and XAI", "categories": ["cs.CV"], "comment": "Accepted for publication in 2024 27th International Conference on\n  Computer and Information Technology (ICCIT)", "summary": "Leaf diseases are harmful conditions that affect the health, appearance and\nproductivity of plants, leading to significant plant loss and negatively\nimpacting farmers' livelihoods. These diseases cause visible symptoms such as\nlesions, color changes, and texture variations, making it difficult for farmers\nto manage plant health, especially in large or remote farms where expert\nknowledge is limited. The main motivation of this study is to provide an\nefficient and accessible solution for identifying plant leaf diseases in\nBangladesh, where agriculture plays a critical role in food security. The\nobjective of our research is to classify 21 distinct leaf diseases across six\nplants using deep learning models, improving disease detection accuracy while\nreducing the need for expert involvement. Deep Learning (DL) techniques,\nincluding CNN and Transfer Learning (TL) models like VGG16, VGG19, MobileNetV2,\nInceptionV3, ResNet50V2 and Xception are used. VGG19 and Xception achieve the\nhighest accuracies, with 98.90% and 98.66% respectively. Additionally,\nExplainable AI (XAI) techniques such as GradCAM, GradCAM++, LayerCAM, ScoreCAM\nand FasterScoreCAM are used to enhance transparency by highlighting the regions\nof the models focused on during disease classification. This transparency\nensures that farmers can understand the model's predictions and take necessary\naction. This approach not only improves disease management but also supports\nfarmers in making informed decisions, leading to better plant protection and\nincreased agricultural productivity.", "AI": {"tldr": "The paper proposes a deep learning-based system to classify 21 leaf diseases in six plants, achieving high accuracy with models like VGG19 and Xception, and uses Explainable AI for transparency.", "motivation": "To provide an efficient, accessible solution for identifying plant leaf diseases in Bangladesh, where agriculture is vital for food security, reducing reliance on expert knowledge.", "method": "Uses CNN and Transfer Learning models (VGG16, VGG19, MobileNetV2, InceptionV3, ResNet50V2, Xception) and Explainable AI techniques (GradCAM, GradCAM++, LayerCAM, ScoreCAM, FasterScoreCAM) for disease classification and transparency.", "result": "VGG19 and Xception achieve the highest accuracies (98.90% and 98.66% respectively).", "conclusion": "The approach improves disease management, supports informed farmer decisions, and enhances agricultural productivity."}}
{"id": "2309.17116", "pdf": "https://arxiv.org/pdf/2309.17116", "abs": "https://arxiv.org/abs/2309.17116", "authors": ["Iulia Duta", "Giulia Cassar\u00e0", "Fabrizio Silvestri", "Pietro Li\u00f2"], "title": "Sheaf Hypergraph Networks", "categories": ["cs.LG"], "comment": "Accepted at Neural Information Processing Systems (NeurIPS 2023)", "summary": "Higher-order relations are widespread in nature, with numerous phenomena\ninvolving complex interactions that extend beyond simple pairwise connections.\nAs a result, advancements in higher-order processing can accelerate the growth\nof various fields requiring structured data. Current approaches typically\nrepresent these interactions using hypergraphs. We enhance this representation\nby introducing cellular sheaves for hypergraphs, a mathematical construction\nthat adds extra structure to the conventional hypergraph while maintaining\ntheir local, higherorder connectivity. Drawing inspiration from existing\nLaplacians in the literature, we develop two unique formulations of sheaf\nhypergraph Laplacians: linear and non-linear. Our theoretical analysis\ndemonstrates that incorporating sheaves into the hypergraph Laplacian provides\na more expressive inductive bias than standard hypergraph diffusion, creating a\npowerful instrument for effectively modelling complex data structures. We\nemploy these sheaf hypergraph Laplacians to design two categories of models:\nSheaf Hypergraph Neural Networks and Sheaf Hypergraph Convolutional Networks.\nThese models generalize classical Hypergraph Networks often found in the\nliterature. Through extensive experimentation, we show that this generalization\nsignificantly improves performance, achieving top results on multiple benchmark\ndatasets for hypergraph node classification.", "AI": {"tldr": "The paper introduces cellular sheaves for hypergraphs to enhance higher-order relations modeling, proposing two sheaf hypergraph Laplacians and neural networks that outperform existing methods.", "motivation": "Higher-order relations are common but current hypergraph representations lack expressive structure. The goal is to improve modeling of complex interactions.", "method": "Develops linear and non-linear sheaf hypergraph Laplacians, then designs Sheaf Hypergraph Neural Networks and Convolutional Networks.", "result": "The proposed models achieve top performance on hypergraph node classification benchmarks.", "conclusion": "Incorporating sheaves into hypergraph Laplacians provides a more expressive inductive bias, improving modeling of complex data structures."}}
{"id": "2411.13057", "pdf": "https://arxiv.org/pdf/2411.13057", "abs": "https://arxiv.org/abs/2411.13057", "authors": ["Xu Chen", "Zida Cheng", "Yuangang Pan", "Shuai Xiao", "Xiaoming Liu", "Jinsong Lan", "Xiaoyong Zhu", "Bo Zheng", "Ivor W. Tsang"], "title": "Learning Multi-Branch Cooperation for Enhanced Click-Through Rate Prediction at Taobao", "categories": ["cs.IR", "cs.AI"], "comment": "14 pages", "summary": "Existing click-through rate (CTR) prediction works have studied the role of\nfeature interaction through a variety of techniques. Each interaction technique\nexhibits its own strength, and solely using one type usually constrains the\nmodel's capability to capture the complex feature relationships, especially for\nindustrial data with enormous input feature fields. Recent research shows that\neffective CTR models often combine an MLP network with a dedicated feature\ninteraction network in a two-parallel structure. However, the interplay and\ncooperative dynamics between different streams or branches remain\nunder-researched. In this work, we introduce a novel Multi-Branch Cooperation\nNetwork (MBCnet) which enables multiple branch networks to collaborate with\neach other for better complex feature interaction modeling. Specifically,\nMBCnet consists of three branches: the Extensible Feature Grouping and Crossing\n(EFGC) branch that promotes the model's memorization ability of specific\nfeature fields, the low rank Cross Net branch and Deep branch to enhance\nexplicit and implicit feature crossing for improved generalization. Among these\nbranches, a novel cooperation scheme is proposed based on two principles:\nBranch co-teaching and moderate differentiation. Branch co-teaching encourages\nwell-learned branches to support poorly-learned ones on specific training\nsamples. Moderate differentiation advocates branches to maintain a reasonable\nlevel of difference in their feature representations on the same inputs. This\ncooperation strategy improves learning through mutual knowledge sharing and\nboosts the discovery of diverse feature interactions across branches.\nExperiments on large-scale industrial datasets and online A/B test at Taobao\napp demonstrate MBCnet's superior performance, delivering a 0.09 point increase\nin CTR, 1.49% growth in deals, and 1.62% rise in GMV. Core codes are available\nonline.", "AI": {"tldr": "The paper introduces MBCnet, a Multi-Branch Cooperation Network for CTR prediction, combining three branches for feature interaction modeling and a novel cooperation scheme to improve performance.", "motivation": "Existing CTR models lack effective interplay between feature interaction techniques, limiting their ability to capture complex relationships in industrial data.", "method": "MBCnet uses three branches (EFGC, Cross Net, Deep) with a cooperation scheme based on branch co-teaching and moderate differentiation.", "result": "Experiments show MBCnet improves CTR by 0.09 points, increases deals by 1.49%, and raises GMV by 1.62%.", "conclusion": "MBCnet's multi-branch cooperation effectively enhances feature interaction modeling, demonstrating superior performance in industrial applications."}}
{"id": "2506.05333", "pdf": "https://arxiv.org/pdf/2506.05333", "abs": "https://arxiv.org/abs/2506.05333", "authors": ["Ranajoy Sadhukhan", "Zhuoming Chen", "Haizhong Zheng", "Yang Zhou", "Emma Strubell", "Beidi Chen"], "title": "Kinetics: Rethinking Test-Time Scaling Laws", "categories": ["cs.LG", "cs.CL"], "comment": null, "summary": "We rethink test-time scaling laws from a practical efficiency perspective,\nrevealing that the effectiveness of smaller models is significantly\noverestimated. Prior work, grounded in compute-optimality, overlooks critical\nmemory access bottlenecks introduced by inference-time strategies (e.g.,\nBest-of-$N$, long CoTs). Our holistic analysis, spanning models from 0.6B to\n32B parameters, reveals a new Kinetics Scaling Law that better guides resource\nallocation by incorporating both computation and memory access costs. Kinetics\nScaling Law suggests that test-time compute is more effective when used on\nmodels above a threshold than smaller ones. A key reason is that in TTS,\nattention, rather than parameter count, emerges as the dominant cost factor.\nMotivated by this, we propose a new scaling paradigm centered on sparse\nattention, which lowers per-token cost and enables longer generations and more\nparallel samples within the same resource budget. Empirically, we show that\nsparse attention models consistently outperform dense counterparts, achieving\nover 60 points gains in low-cost regimes and over 5 points gains in high-cost\nregimes for problem-solving accuracy on AIME, encompassing evaluations on\nstate-of-the-art MoEs. These results suggest that sparse attention is essential\nand increasingly important with more computing invested, for realizing the full\npotential of test-time scaling where, unlike training, accuracy has yet to\nsaturate as a function of computation, and continues to improve through\nincreased generation. The code is available at\nhttps://github.com/Infini-AI-Lab/Kinetics.", "AI": {"tldr": "Smaller models' effectiveness is overestimated due to overlooked memory bottlenecks. The Kinetics Scaling Law, incorporating computation and memory costs, suggests larger models are more efficient. Sparse attention models outperform dense ones, especially in low-cost regimes.", "motivation": "To address the overestimation of smaller models' effectiveness and the inefficiencies caused by memory bottlenecks in test-time scaling.", "method": "Proposes the Kinetics Scaling Law, analyzing models from 0.6B to 32B parameters, and introduces sparse attention to reduce per-token costs.", "result": "Sparse attention models outperform dense ones, with significant gains in problem-solving accuracy (60+ points in low-cost, 5+ in high-cost regimes).", "conclusion": "Sparse attention is crucial for efficient test-time scaling, as accuracy continues to improve with increased computation, unlike in training."}}
{"id": "2505.16039", "pdf": "https://arxiv.org/pdf/2505.16039", "abs": "https://arxiv.org/abs/2505.16039", "authors": ["Shuvashis Sarker", "Shamim Rahim Refat", "Faika Fairuj Preotee", "Shifat Islam", "Tashreef Muhammad", "Mohammad Ashraful Hoque"], "title": "An Exploratory Approach Towards Investigating and Explaining Vision Transformer and Transfer Learning for Brain Disease Detection", "categories": ["cs.CV"], "comment": "Accepted for publication in 2024 27th International Conference on\n  Computer and Information Technology (ICCIT)", "summary": "The brain is a highly complex organ that manages many important tasks,\nincluding movement, memory and thinking. Brain-related conditions, like tumors\nand degenerative disorders, can be hard to diagnose and treat. Magnetic\nResonance Imaging (MRI) serves as a key tool for identifying these conditions,\noffering high-resolution images of brain structures. Despite this, interpreting\nMRI scans can be complicated. This study tackles this challenge by conducting a\ncomparative analysis of Vision Transformer (ViT) and Transfer Learning (TL)\nmodels such as VGG16, VGG19, Resnet50V2, MobilenetV2 for classifying brain\ndiseases using MRI data from Bangladesh based dataset. ViT, known for their\nability to capture global relationships in images, are particularly effective\nfor medical imaging tasks. Transfer learning helps to mitigate data constraints\nby fine-tuning pre-trained models. Furthermore, Explainable AI (XAI) methods\nsuch as GradCAM, GradCAM++, LayerCAM, ScoreCAM, and Faster-ScoreCAM are\nemployed to interpret model predictions. The results demonstrate that ViT\nsurpasses transfer learning models, achieving a classification accuracy of\n94.39%. The integration of XAI methods enhances model transparency, offering\ncrucial insights to aid medical professionals in diagnosing brain diseases with\ngreater precision.", "AI": {"tldr": "The study compares Vision Transformer (ViT) and Transfer Learning models for brain disease classification using MRI data, showing ViT's superior accuracy (94.39%) and the use of Explainable AI (XAI) for interpretability.", "motivation": "Brain-related conditions are hard to diagnose; MRI interpretation is complex. The study aims to improve classification and transparency in diagnosing brain diseases.", "method": "Comparative analysis of ViT and TL models (VGG16, VGG19, Resnet50V2, MobilenetV2) on MRI data, enhanced with XAI methods (GradCAM, GradCAM++, etc.).", "result": "ViT outperforms TL models with 94.39% accuracy. XAI methods provide interpretable insights for medical professionals.", "conclusion": "ViT is effective for brain disease classification, and XAI enhances diagnostic precision, aiding medical decision-making."}}
{"id": "2311.16487", "pdf": "https://arxiv.org/pdf/2311.16487", "abs": "https://arxiv.org/abs/2311.16487", "authors": ["Yehya Farhat"], "title": "On the Robustness of Decision-Focused Learning", "categories": ["cs.LG", "math.OC", "68Txx"], "comment": "17 pages, 45 figures", "summary": "Decision-Focused Learning (DFL) is an emerging learning paradigm that tackles\nthe task of training a machine learning (ML) model to predict missing\nparameters of an incomplete optimization problem, where the missing parameters\nare predicted. DFL trains an ML model in an end-to-end system, by integrating\nthe prediction and optimization tasks, providing better alignment of the\ntraining and testing objectives. DFL has shown a lot of promise and holds the\ncapacity to revolutionize decision-making in many real-world applications.\nHowever, very little is known about the performance of these models under\nadversarial attacks. We adopt ten unique DFL methods and benchmark their\nperformance under two distinctly focused attacks adapted towards the\nPredict-then-Optimize problem setting. Our study proposes the hypothesis that\nthe robustness of a model is highly correlated with its ability to find\npredictions that lead to optimal decisions without deviating from the\nground-truth label. Furthermore, we provide insight into how to target the\nmodels that violate this condition and show how these models respond\ndifferently depending on the achieved optimality at the end of their training\ncycles.", "AI": {"tldr": "DFL integrates prediction and optimization tasks for better decision-making, but its robustness under adversarial attacks is poorly understood. This study benchmarks ten DFL methods under attacks, linking robustness to prediction-decision alignment.", "motivation": "To explore the robustness of Decision-Focused Learning (DFL) models under adversarial attacks, as their performance in such scenarios is largely unknown.", "method": "Adopted ten unique DFL methods and benchmarked their performance under two distinct adversarial attacks tailored for the Predict-then-Optimize setting.", "result": "Found that model robustness correlates with its ability to align predictions with optimal decisions without deviating from ground-truth labels. Also identified how models violating this condition respond differently based on training optimality.", "conclusion": "DFL models' robustness depends on prediction-decision alignment, and violating this condition makes them vulnerable to attacks. Insights provided can guide future DFL model development for adversarial resilience."}}
{"id": "2501.15103", "pdf": "https://arxiv.org/pdf/2501.15103", "abs": "https://arxiv.org/abs/2501.15103", "authors": ["Ziyu Zhao", "Yixiao Zhou", "Zhi Zhang", "Didi Zhu", "Tao Shen", "Zexi Li", "Jinluan Yang", "Xuwu Wang", "Jing Su", "Kun Kuang", "Zhongyu Wei", "Fei Wu", "Yu Cheng"], "title": "Each Rank Could be an Expert: Single-Ranked Mixture of Experts LoRA for Multi-Task Learning", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Low-Rank Adaptation (LoRA) is widely used for adapting large language models\n(LLMs) to specific domains due to its efficiency and modularity. Meanwhile,\nvanilla LoRA struggles with task conflicts in multi-task scenarios. Recent\nworks adopt Mixture of Experts (MoE) by treating each LoRA module as an expert,\nthereby mitigating task interference through multiple specialized LoRA modules.\nWhile effective, these methods often isolate knowledge within individual tasks,\nfailing to fully exploit the shared knowledge across related tasks. In this\npaper, we establish a connection between single LoRA and multi-LoRA MoE,\nintegrating them into a unified framework. We demonstrate that the dynamic\nrouting of multiple LoRAs is functionally equivalent to rank partitioning and\nblock-level activation within a single LoRA. We further empirically demonstrate\nthat finer-grained LoRA partitioning, within the same total and activated\nparameter constraints, leads to better performance gains across heterogeneous\ntasks. Building on these findings, we propose Single-ranked Mixture of Experts\nLoRA (\\textbf{SMoRA}), which embeds MoE into LoRA by \\textit{treating each rank\nas an independent expert}. With a \\textit{dynamic rank-wise activation}\nmechanism, SMoRA promotes finer-grained knowledge sharing while mitigating task\nconflicts. Experiments demonstrate that SMoRA activates fewer parameters yet\nachieves better performance in multi-task scenarios.", "AI": {"tldr": "SMoRA integrates LoRA and MoE into a unified framework, treating each rank as an expert, enabling finer-grained knowledge sharing and better multi-task performance.", "motivation": "Vanilla LoRA struggles with task conflicts in multi-task scenarios, and existing MoE-based methods isolate knowledge within tasks, missing shared knowledge.", "method": "Proposes SMoRA, which dynamically activates ranks within a single LoRA, treating each rank as an expert for finer-grained partitioning.", "result": "SMoRA activates fewer parameters but outperforms in multi-task scenarios, demonstrating better performance gains.", "conclusion": "SMoRA effectively combines LoRA and MoE, improving multi-task adaptation by leveraging shared knowledge and reducing task conflicts."}}
{"id": "2506.13784", "pdf": "https://arxiv.org/pdf/2506.13784", "abs": "https://arxiv.org/abs/2506.13784", "authors": ["Junting Zhou", "Wang Li", "Yiyan Liao", "Nengyuan Zhang", "Tingjia Miao", "Zhihui Qi", "Yuhan Wu", "Tong Yang"], "title": "ScholarSearch: Benchmarking Scholar Searching Ability of LLMs", "categories": ["cs.IR", "cs.CL"], "comment": null, "summary": "Large Language Models (LLMs)' search capabilities have garnered significant\nattention. Existing benchmarks, such as OpenAI's BrowseComp, primarily focus on\ngeneral search scenarios and fail to adequately address the specific demands of\nacademic search. These demands include deeper literature tracing and\norganization, professional support for academic databases, the ability to\nnavigate long-tail academic knowledge, and ensuring academic rigor. Here, we\nproposed ScholarSearch, the first dataset specifically designed to evaluate the\ncomplex information retrieval capabilities of Large Language Models (LLMs) in\nacademic research. ScholarSearch possesses the following key characteristics:\nAcademic Practicality, where question content closely mirrors real academic\nlearning and research environments, avoiding deliberately misleading models;\nHigh Difficulty, with answers that are challenging for single models (e.g.,\nGrok DeepSearch or Gemini Deep Research) to provide directly, often requiring\nat least three deep searches to derive; Concise Evaluation, where limiting\nconditions ensure answers are as unique as possible, accompanied by clear\nsources and brief solution explanations, greatly facilitating subsequent audit\nand verification, surpassing the current lack of analyzed search datasets both\ndomestically and internationally; and Broad Coverage, as the dataset spans at\nleast 15 different academic disciplines. Through ScholarSearch, we expect to\nmore precisely measure and promote the performance improvement of LLMs in\ncomplex academic information retrieval tasks. The data is available at:\nhttps://huggingface.co/datasets/PKU-DS-LAB/ScholarSearch", "AI": {"tldr": "ScholarSearch is a dataset designed to evaluate LLMs' academic search capabilities, addressing gaps in existing benchmarks by focusing on academic rigor, deep literature tracing, and professional database support.", "motivation": "Existing benchmarks like OpenAI's BrowseComp lack focus on academic search demands, such as deep literature tracing and academic rigor, prompting the creation of ScholarSearch.", "method": "ScholarSearch is a specialized dataset with key features: Academic Practicality, High Difficulty, Concise Evaluation, and Broad Coverage across 15 disciplines.", "result": "The dataset aims to precisely measure and improve LLMs' performance in complex academic information retrieval tasks.", "conclusion": "ScholarSearch fills a critical gap in academic search evaluation, offering a robust tool for advancing LLMs' capabilities in scholarly research."}}
{"id": "2505.16463", "pdf": "https://arxiv.org/pdf/2505.16463", "abs": "https://arxiv.org/abs/2505.16463", "authors": ["Jiquan Shan", "Junxiao Wang", "Lifeng Zhao", "Liang Cai", "Hongyuan Zhang", "Ioannis Liritzis"], "title": "AnchorFormer: Differentiable Anchor Attention for Efficient Vision Transformer", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "Recently, vision transformers (ViTs) have achieved excellent performance on\nvision tasks by measuring the global self-attention among the image patches.\nGiven $n$ patches, they will have quadratic complexity such as\n$\\mathcal{O}(n^2)$ and the time cost is high when splitting the input image\nwith a small granularity. Meanwhile, the pivotal information is often randomly\ngathered in a few regions of an input image, some tokens may not be helpful for\nthe downstream tasks. To handle this problem, we introduce an anchor-based\nefficient vision transformer (AnchorFormer), which employs the anchor tokens to\nlearn the pivotal information and accelerate the inference. Firstly, by\nestimating the bipartite attention between the anchors and tokens, the\ncomplexity will be reduced from $\\mathcal{O}(n^2)$ to $\\mathcal{O}(mn)$, where\n$m$ is an anchor number and $m < n$. Notably, by representing the anchors with\nthe neurons in a neural layer, we can differentiably learn these anchors and\napproximate global self-attention through the Markov process. It avoids the\nburden caused by non-differentiable operations and further speeds up the\napproximate attention. Moreover, we extend the proposed model to three\ndownstream tasks including classification, detection, and segmentation.\nExtensive experiments show the effectiveness of our AnchorFormer, e.g.,\nachieving up to a 9.0% higher accuracy or 46.7% FLOPs reduction on ImageNet\nclassification, 81.3% higher mAP on COCO detection under comparable FLOPs, as\ncompared to the current baselines.", "AI": {"tldr": "AnchorFormer reduces ViT complexity from O(n\u00b2) to O(mn) using anchor tokens, improving efficiency and performance.", "motivation": "ViTs suffer from high computational cost (O(n\u00b2)) and redundant tokens. AnchorFormer addresses this by focusing on pivotal regions.", "method": "Uses anchor tokens for bipartite attention, reducing complexity. Anchors are learned via differentiable neurons, approximating global self-attention.", "result": "Achieves 9.0% higher accuracy, 46.7% FLOPs reduction on ImageNet, and 81.3% higher mAP on COCO detection.", "conclusion": "AnchorFormer efficiently approximates global attention, enhancing performance and reducing computational cost."}}
{"id": "2403.01306", "pdf": "https://arxiv.org/pdf/2403.01306", "abs": "https://arxiv.org/abs/2403.01306", "authors": ["Moran Yanuka", "Morris Alper", "Hadar Averbuch-Elor", "Raja Giryes"], "title": "ICC: Quantifying Image Caption Concreteness for Multimodal Dataset Curation", "categories": ["cs.LG", "cs.CV"], "comment": "Accepted to ACL 2024 (Finding). For Project webpage, see\n  https://moranyanuka.github.io/icc/", "summary": "Web-scale training on paired text-image data is becoming increasingly central\nto multimodal learning, but is challenged by the highly noisy nature of\ndatasets in the wild. Standard data filtering approaches succeed in removing\nmismatched text-image pairs, but permit semantically related but highly\nabstract or subjective text. These approaches lack the fine-grained ability to\nisolate the most concrete samples that provide the strongest signal for\nlearning in a noisy dataset. In this work, we propose a new metric, image\ncaption concreteness, that evaluates caption text without an image reference to\nmeasure its concreteness and relevancy for use in multimodal learning. Our\napproach leverages strong foundation models for measuring visual-semantic\ninformation loss in multimodal representations. We demonstrate that this\nstrongly correlates with human evaluation of concreteness in both single-word\nand sentence-level texts. Moreover, we show that curation using ICC complements\nexisting approaches: It succeeds in selecting the highest quality samples from\nmultimodal web-scale datasets to allow for efficient training in\nresource-constrained settings.", "AI": {"tldr": "Proposes a new metric, image caption concreteness (ICC), to filter noisy text-image pairs in multimodal learning by measuring caption concreteness without image reference.", "motivation": "Addresses the challenge of noisy datasets in multimodal learning, where existing methods fail to isolate concrete samples for strong learning signals.", "method": "Leverages foundation models to measure visual-semantic information loss in multimodal representations, correlating with human concreteness evaluations.", "result": "ICC strongly correlates with human evaluations and effectively selects high-quality samples for efficient training.", "conclusion": "ICC complements existing methods, improving dataset curation for resource-constrained multimodal learning."}}
{"id": "2501.16029", "pdf": "https://arxiv.org/pdf/2501.16029", "abs": "https://arxiv.org/abs/2501.16029", "authors": ["Zhiyuan Fu", "Junfan Chen", "Lan Zhang", "Ting Yang", "Jun Niu", "Hongyu Sun", "Ruidong Li", "Peng Liu", "Jice Wang", "Fannv He", "Yuqing Zhang"], "title": "FDLLM: A Dedicated Detector for Black-Box LLMs Fingerprinting", "categories": ["cs.CR", "cs.AI"], "comment": null, "summary": "Large Language Models (LLMs) are rapidly transforming the landscape of\ndigital content creation. However, the prevalent black-box Application\nProgramming Interface (API) access to many LLMs introduces significant\nchallenges in accountability, governance, and security. LLM fingerprinting,\nwhich aims to identify the source model by analyzing statistical and stylistic\nfeatures of generated text, offers a potential solution. Current progress in\nthis area is hindered by a lack of dedicated datasets and the need for\nefficient, practical methods that are robust against adversarial manipulations.\nTo address these challenges, we introduce FD-Dataset, a comprehensive bilingual\nfingerprinting benchmark comprising 90,000 text samples from 20 famous\nproprietary and open-source LLMs. Furthermore, we present FDLLM, a novel\nfingerprinting method that leverages parameter-efficient Low-Rank Adaptation\n(LoRA) to fine-tune a foundation model. This approach enables LoRA to extract\ndeep, persistent features that characterize each source LLM. Through our\nanalysis, we find that LoRA adaptation promotes the aggregation of outputs from\nthe same LLM in representation space while enhancing the separation between\ndifferent LLMs. This mechanism explains why LoRA proves particularly effective\nfor LLM fingerprinting. Extensive empirical evaluations on FD-Dataset\ndemonstrate FDLLM's superiority, achieving a Macro F1 score 22.1% higher than\nthe strongest baseline. FDLLM also exhibits strong generalization to newly\nreleased models, achieving an average accuracy of 95% on unseen models.\nNotably, FDLLM remains consistently robust under various adversarial attacks,\nincluding polishing, translation, and synonym substitution. Experimental\nresults show that FDLLM reduces the average attack success rate from 49.2%\n(LM-D) to 23.9%.", "AI": {"tldr": "The paper introduces FD-Dataset and FDLLM, a bilingual fingerprinting benchmark and method, to address challenges in LLM accountability and security by identifying source models through text analysis.", "motivation": "The lack of accountability and security in black-box API access to LLMs necessitates solutions like fingerprinting to identify source models.", "method": "The authors propose FDLLM, a method using LoRA to fine-tune a foundation model for deep feature extraction, enhancing LLM fingerprinting.", "result": "FDLLM outperforms baselines with a 22.1% higher Macro F1 score, generalizes well (95% accuracy on unseen models), and resists adversarial attacks.", "conclusion": "FDLLM is an effective, robust solution for LLM fingerprinting, addressing current limitations and demonstrating strong performance."}}
{"id": "2506.13923", "pdf": "https://arxiv.org/pdf/2506.13923", "abs": "https://arxiv.org/abs/2506.13923", "authors": ["Vaskar Nath", "Elaine Lau", "Anisha Gunjal", "Manasi Sharma", "Nikhil Baharte", "Sean Hendryx"], "title": "Adaptive Guidance Accelerates Reinforcement Learning of Reasoning Models", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": null, "summary": "We study the process through which reasoning models trained with\nreinforcement learning on verifiable rewards (RLVR) can learn to solve new\nproblems. We find that RLVR drives performance in two main ways: (1) by\ncompressing pass@$k$ into pass@1 and (2) via \"capability gain\" in which models\nlearn to solve new problems that they previously could not solve even at high\n$k$. We find that while capability gain exists across model scales, learning to\nsolve new problems is primarily driven through self-distillation. We\ndemonstrate these findings across model scales ranging from 0.5B to 72B\nparameters on >500,000 reasoning problems with prompts and verifiable final\nanswers across math, science, and code domains. We further show that we can\nsignificantly improve pass@$k$ rates by leveraging natural language guidance\nfor the model to consider within context while still requiring the model to\nderive a solution chain from scratch. Based of these insights, we derive\n$\\text{Guide}$ -- a new class of online training algorithms. $\\text{Guide}$\nadaptively incorporates hints into the model's context on problems for which\nall rollouts were initially incorrect and adjusts the importance sampling ratio\nfor the \"off-policy\" trajectories in order to optimize the policy for contexts\nin which the hints are no longer present. We describe variants of\n$\\text{Guide}$ for GRPO and PPO and empirically show that Guide-GRPO on 7B and\n32B parameter models improves generalization over its vanilla counterpart with\nup to 4$\\%$ macro-average improvement across math benchmarks. We include\ncareful ablations to analyze $\\text{Guide}$'s components and theoretically\nanalyze Guide's learning efficiency.", "AI": {"tldr": "RLVR training improves reasoning models by compressing pass@k into pass@1 and enabling capability gain. Self-distillation is key for solving new problems. The $\text{Guide}$ algorithm, incorporating hints and optimizing off-policy trajectories, enhances performance, showing up to 4% improvement on math benchmarks.", "motivation": "To understand how reasoning models trained with RLVR learn to solve new problems and improve performance through methods like self-distillation and adaptive hint integration.", "method": "RLVR training is used to compress pass@k into pass@1 and achieve capability gain. The $\text{Guide}$ algorithm adaptively incorporates hints and optimizes off-policy trajectories, tested on models from 0.5B to 72B parameters.", "result": "Capability gain is observed across model scales, with self-distillation driving problem-solving. $\text{Guide}$ improves pass@k rates, showing up to 4% macro-average improvement on math benchmarks.", "conclusion": "RLVR and $\text{Guide}$ enhance reasoning models' performance, with self-distillation and adaptive hint integration being key factors. The findings are validated across diverse domains and model scales."}}
{"id": "2505.23444", "pdf": "https://arxiv.org/pdf/2505.23444", "abs": "https://arxiv.org/abs/2505.23444", "authors": ["Runmin Jiang", "Genpei Zhang", "Yuntian Yang", "Siqi Wu", "Yuheng Zhang", "Wanyue Feng", "Yizhou Zhao", "Xi Xiao", "Xiao Wang", "Tianyang Wang", "Xingjian Li", "Min Xu"], "title": "CryoCCD: Conditional Cycle-consistent Diffusion with Biophysical Modeling for Cryo-EM Synthesis", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Cryo-electron microscopy (cryo-EM) offers near-atomic resolution imaging of\nmacromolecules, but developing robust models for downstream analysis is\nhindered by the scarcity of high-quality annotated data. While synthetic data\ngeneration has emerged as a potential solution, existing methods often fail to\ncapture both the structural diversity of biological specimens and the complex,\nspatially varying noise inherent in cryo-EM imaging. To overcome these\nlimitations, we propose CryoCCD, a synthesis framework that integrates\nbiophysical modeling with generative techniques. Specifically, CryoCCD produces\nmulti-scale cryo-EM micrographs that reflect realistic biophysical variability\nthrough compositional heterogeneity, cellular context, and physics-informed\nimaging. To generate realistic noise, we employ a conditional diffusion model,\nenhanced by cycle consistency to preserve structural fidelity and mask-aware\ncontrastive learning to capture spatially adaptive noise patterns. Extensive\nexperiments show that CryoCCD generates structurally accurate micrographs and\nenhances performance in downstream tasks, outperforming state-of-the-art\nbaselines in both particle picking and reconstruction.", "AI": {"tldr": "CryoCCD is a framework combining biophysical modeling and generative techniques to create realistic cryo-EM micrographs, improving downstream analysis tasks.", "motivation": "The scarcity of high-quality annotated cryo-EM data and limitations of existing synthetic data methods hinder robust model development.", "method": "CryoCCD integrates biophysical modeling with generative techniques, using a conditional diffusion model for realistic noise and structural fidelity.", "result": "CryoCCD generates accurate micrographs and outperforms baselines in particle picking and reconstruction.", "conclusion": "CryoCCD addresses key challenges in cryo-EM data synthesis, enhancing downstream analysis performance."}}
{"id": "2404.13318", "pdf": "https://arxiv.org/pdf/2404.13318", "abs": "https://arxiv.org/abs/2404.13318", "authors": ["Jiyoun Kim", "Junu Kim", "Kyunghoon Hur", "Edward Choi"], "title": "Client-Centered Federated Learning for Heterogeneous EHRs: Use Fewer Participants to Achieve the Same Performance", "categories": ["cs.LG"], "comment": null, "summary": "The increasing volume of electronic health records (EHRs) presents the\nopportunity to improve the accuracy and robustness of models in clinical\nprediction tasks. Unlike traditional centralized approaches, federated learning\nenables training on data from multiple institutions while preserving patient\nprivacy and complying with regulatory constraints. In practice, healthcare\ninstitutions (i.e., hosts) often need to build predictive models tailored to\ntheir specific needs using federated learning. In this scenario, two key\nchallenges arise: (1) ensuring compatibility across heterogeneous EHR systems,\nand (2) managing federated learning costs within budget constraints. To address\nthese challenges, we propose EHRFL, a federated learning framework designed for\nbuilding a cost-effective, host-specific predictive model using patient EHR\ndata. EHRFL consists of two components: (1) text-based EHR modeling, which\nfacilitates cross-institution compatibility without costly data\nstandardization, and (2) a participant selection strategy based on averaged\npatient embedding similarity to reduce the number of participants without\ndegrading performance. Experiments on multiple open-source EHR datasets\ndemonstrate the effectiveness of both components. We believe our framework\noffers a practical solution for enabling healthcare institutions to build\ninstitution-specific predictive models under budgetary constraints.", "AI": {"tldr": "EHRFL is a federated learning framework for building cost-effective, host-specific predictive models using EHR data, addressing compatibility and budget constraints.", "motivation": "To improve clinical prediction accuracy while preserving patient privacy and complying with regulations, federated learning is needed, but challenges like EHR system heterogeneity and cost management arise.", "method": "EHRFL includes text-based EHR modeling for cross-institution compatibility and a participant selection strategy based on patient embedding similarity to reduce costs.", "result": "Experiments on open-source EHR datasets show EHRFL's effectiveness in maintaining performance while reducing costs.", "conclusion": "EHRFL provides a practical solution for healthcare institutions to build tailored predictive models within budget constraints."}}
{"id": "2501.18426", "pdf": "https://arxiv.org/pdf/2501.18426", "abs": "https://arxiv.org/abs/2501.18426", "authors": ["Ander Gray", "Vignesh Gopakumar", "Sylvain Rousseau", "S\u00e9bastien Destercke"], "title": "Guaranteed prediction sets for functional surrogate models", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "We propose a method for obtaining statistically guaranteed prediction sets\nfor functional machine learning methods: surrogate models which map between\nfunction spaces, motivated by the need to build reliable PDE emulators. The\nmethod constructs nested prediction sets on a low-dimensional representation\n(an SVD) of the surrogate model's error, and then maps these sets to the\nprediction space using set-propagation techniques. This results in prediction\nsets for functional surrogate models with conformal prediction coverage\nguarantees. We use zonotopes as basis of the set construction, which allow an\nexact linear propagation and are closed under Cartesian products, making them\nwell-suited to this high-dimensional problem. The method is model agnostic and\ncan thus be applied to complex Sci-ML models, including Neural Operators, but\nalso in simpler settings. We also introduce a technique to capture the\ntruncation error of the SVD, preserving the guarantees of the method.", "AI": {"tldr": "A method for statistically guaranteed prediction sets in functional machine learning, using SVD and zonotopes for reliable PDE emulators.", "motivation": "Addressing the need for reliable PDE emulators by ensuring conformal prediction coverage guarantees.", "method": "Constructs nested prediction sets on SVD-based error representations, using zonotopes for exact linear propagation.", "result": "Produces prediction sets with conformal guarantees, applicable to complex models like Neural Operators.", "conclusion": "The method is model-agnostic, handles truncation error, and ensures reliable predictions for functional surrogate models."}}
{"id": "2506.15538", "pdf": "https://arxiv.org/pdf/2506.15538", "abs": "https://arxiv.org/abs/2506.15538", "authors": ["Laura Kopf", "Nils Feldhus", "Kirill Bykov", "Philine Lou Bommer", "Anna Hedstr\u00f6m", "Marina M. -C. H\u00f6hne", "Oliver Eberle"], "title": "Capturing Polysemanticity with PRISM: A Multi-Concept Feature Description Framework", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": null, "summary": "Automated interpretability research aims to identify concepts encoded in\nneural network features to enhance human understanding of model behavior.\nCurrent feature description methods face two critical challenges: limited\nrobustness and the flawed assumption that each neuron encodes only a single\nconcept (monosemanticity), despite growing evidence that neurons are often\npolysemantic. This assumption restricts the expressiveness of feature\ndescriptions and limits their ability to capture the full range of behaviors\nencoded in model internals. To address this, we introduce Polysemantic FeatuRe\nIdentification and Scoring Method (PRISM), a novel framework that captures the\ninherent complexity of neural network features. Unlike prior approaches that\nassign a single description per feature, PRISM provides more nuanced\ndescriptions for both polysemantic and monosemantic features. We apply PRISM to\nlanguage models and, through extensive benchmarking against existing methods,\ndemonstrate that our approach produces more accurate and faithful feature\ndescriptions, improving both overall description quality (via a description\nscore) and the ability to capture distinct concepts when polysemanticity is\npresent (via a polysemanticity score).", "AI": {"tldr": "PRISM introduces a framework for nuanced feature descriptions in neural networks, addressing polysemanticity and improving accuracy.", "motivation": "Current methods assume monosemanticity, limiting feature descriptions' expressiveness and robustness.", "method": "PRISM provides nuanced descriptions for polysemantic and monosemantic features, benchmarking against existing methods.", "result": "PRISM improves description quality and captures distinct concepts better, validated via scores.", "conclusion": "PRISM enhances interpretability by addressing polysemanticity, offering more accurate feature descriptions."}}
{"id": "2506.05972", "pdf": "https://arxiv.org/pdf/2506.05972", "abs": "https://arxiv.org/abs/2506.05972", "authors": ["Xing Hu", "Siyuan Chen", "Xuming Huang", "Qianqian Duan", "LingKun Luo", "Ruijiao Li", "Huiliang Shang", "Linhua Jiang", "Jianping Yang", "Hamid Reza Karimi", "Dawei Zhang"], "title": "Bridging Domain Gaps in Agricultural Image Analysis: A Comprehensive Review From Shallow Adaptation to Deep Learning", "categories": ["cs.CV"], "comment": null, "summary": "With the growing application of computer vision in agriculture, image\nanalysis has become essential for tasks such as crop health monitoring and pest\ndetection. However, significant domain shifts caused by environmental\nvariations, different crop types, and diverse data acquisition methods hinder\nmodel generalization across regions, seasons, and complex agricultural\nsettings. This paper investigates how Domain Adaptation (DA) techniques can\naddress these challenges by improving cross-domain transferability in\nagricultural image analysis. Given the limited availability of labeled data,\nweak model adaptability, and dynamic field conditions, DA has emerged as a\npromising solution. The review systematically summarizes recent advances in DA\nfor agricultural imagery, focusing on applications such as crop health\nmonitoring, pest detection, and fruit recognition, where DA methods have\nenhanced performance across diverse domains. DA approaches are categorized into\nshallow and deep learning methods, including supervised, semi-supervised, and\nunsupervised strategies, with particular attention to adversarial\nlearning-based techniques that have demonstrated strong potential in complex\nscenarios. In addition, the paper reviews key public agricultural image\ndatasets, evaluating their strengths and limitations in DA research. Overall,\nthis work offers a comprehensive framework and critical insights to guide\nfuture research and development of domain adaptation in agricultural vision\ntasks.", "AI": {"tldr": "The paper explores Domain Adaptation (DA) techniques to improve cross-domain transferability in agricultural image analysis, addressing challenges like domain shifts and limited labeled data.", "motivation": "The growing use of computer vision in agriculture faces issues like environmental variations and data diversity, hindering model generalization. DA is proposed as a solution.", "method": "The review categorizes DA into shallow and deep learning methods, including supervised, semi-supervised, and unsupervised strategies, with a focus on adversarial learning.", "result": "DA methods enhance performance in tasks like crop health monitoring, pest detection, and fruit recognition, with adversarial techniques showing strong potential.", "conclusion": "The paper provides a framework and insights to guide future DA research in agricultural vision tasks, highlighting the importance of addressing domain shifts."}}
{"id": "2405.01306", "pdf": "https://arxiv.org/pdf/2405.01306", "abs": "https://arxiv.org/abs/2405.01306", "authors": ["Zhenhan Huang", "Tejaswini Pedapati", "Pin-Yu Chen", "Chunheng Jiang", "Jianxi Gao"], "title": "Graph is all you need? Lightweight data-agnostic neural architecture search without training", "categories": ["cs.LG"], "comment": null, "summary": "Neural architecture search (NAS) enables the automatic design of neural\nnetwork models. However, training the candidates generated by the search\nalgorithm for performance evaluation incurs considerable computational\noverhead. Our method, dubbed nasgraph, remarkably reduces the computational\ncosts by converting neural architectures to graphs and using the average\ndegree, a graph measure, as the proxy in lieu of the evaluation metric. Our\ntraining-free NAS method is data-agnostic and light-weight. It can find the\nbest architecture among 200 randomly sampled architectures from NAS-Bench201 in\n217 CPU seconds. Besides, our method is able to achieve competitive performance\non various datasets including NASBench-101, NASBench-201, and NDS search\nspaces. We also demonstrate that nasgraph generalizes to more challenging tasks\non Micro TransNAS-Bench-101.", "AI": {"tldr": "nasgraph reduces NAS computational costs by using graph measures as performance proxies, achieving fast and competitive results.", "motivation": "Training neural architecture candidates is computationally expensive; nasgraph aims to reduce this overhead.", "method": "Converts neural architectures to graphs and uses average degree as a proxy metric, avoiding training.", "result": "Finds top architectures quickly (217 CPU seconds for 200 samples) and performs well across datasets.", "conclusion": "nasgraph is efficient, data-agnostic, and generalizes well to challenging tasks."}}
{"id": "2502.07154", "pdf": "https://arxiv.org/pdf/2502.07154", "abs": "https://arxiv.org/abs/2502.07154", "authors": ["Feng Chen", "Allan Raventos", "Nan Cheng", "Surya Ganguli", "Shaul Druckmann"], "title": "Rethinking Fine-Tuning when Scaling Test-Time Compute: Limiting Confidence Improves Mathematical Reasoning", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Recent progress in large language models (LLMs) highlights the power of\nscaling test-time compute to achieve strong performance on complex tasks, such\nas mathematical reasoning and code generation. This raises a critical question:\nhow should model training be modified to optimize performance under a\nsubsequent test-time compute strategy and budget? To explore this, we focus on\npass@N, a simple test-time strategy that searches for a correct answer in $N$\nindependent samples. We show, surprisingly, that training with cross-entropy\n(CE) loss can be ${\\it misaligned}$ with pass@N in that pass@N accuracy ${\\it\ndecreases}$ with longer training. We explain the origins of this misalignment\nin terms of model overconfidence induced by CE, and experimentally verify our\nprediction of overconfidence as an impediment to scaling test-time compute via\npass@N. Furthermore we suggest a principled, modified training loss that is\nbetter aligned to pass@N by limiting model confidence and rescuing pass@N test\nperformance. Our algorithm demonstrates improved mathematical reasoning on MATH\nand MiniF2F benchmarks under several scenarios: (1) providing answers to math\nquestions; and (2) proving theorems by searching over proof trees of varying\nshapes. Overall our work underscores the importance of co-designing two\ntraditionally separate phases of LLM development: training-time protocols and\ntest-time search and reasoning strategies.", "AI": {"tldr": "Training with cross-entropy loss can misalign with pass@N test-time compute, reducing accuracy. A modified training loss improves performance by limiting model overconfidence.", "motivation": "To optimize LLM performance under test-time compute strategies like pass@N, given the misalignment of cross-entropy loss with such strategies.", "method": "Analyze pass@N strategy, identify overconfidence from CE loss, and propose a modified training loss to align with pass@N.", "result": "Improved mathematical reasoning on MATH and MiniF2F benchmarks, rescuing pass@N performance.", "conclusion": "Co-designing training and test-time strategies is crucial for optimizing LLM performance."}}
{"id": "2506.07497", "pdf": "https://arxiv.org/pdf/2506.07497", "abs": "https://arxiv.org/abs/2506.07497", "authors": ["Xiangyu Guo", "Zhanqian Wu", "Kaixin Xiong", "Ziyang Xu", "Lijun Zhou", "Gangwei Xu", "Shaoqing Xu", "Haiyang Sun", "Bing Wang", "Guang Chen", "Hangjun Ye", "Wenyu Liu", "Xinggang Wang"], "title": "Genesis: Multimodal Driving Scene Generation with Spatio-Temporal and Cross-Modal Consistency", "categories": ["cs.CV"], "comment": null, "summary": "We present Genesis, a unified framework for joint generation of multi-view\ndriving videos and LiDAR sequences with spatio-temporal and cross-modal\nconsistency. Genesis employs a two-stage architecture that integrates a\nDiT-based video diffusion model with 3D-VAE encoding, and a BEV-aware LiDAR\ngenerator with NeRF-based rendering and adaptive sampling. Both modalities are\ndirectly coupled through a shared latent space, enabling coherent evolution\nacross visual and geometric domains. To guide the generation with structured\nsemantics, we introduce DataCrafter, a captioning module built on\nvision-language models that provides scene-level and instance-level\nsupervision. Extensive experiments on the nuScenes benchmark demonstrate that\nGenesis achieves state-of-the-art performance across video and LiDAR metrics\n(FVD 16.95, FID 4.24, Chamfer 0.611), and benefits downstream tasks including\nsegmentation and 3D detection, validating the semantic fidelity and practical\nutility of the generated data.", "AI": {"tldr": "Genesis is a framework for generating multi-view driving videos and LiDAR sequences with consistency. It uses a two-stage architecture with diffusion models and 3D-VAE, coupled via a shared latent space. DataCrafter provides semantic guidance, achieving top performance on nuScenes.", "motivation": "To create a unified framework for generating consistent multi-view driving videos and LiDAR sequences, addressing the need for coherent multi-modal data in autonomous driving applications.", "method": "Two-stage architecture: DiT-based video diffusion model with 3D-VAE encoding, and BEV-aware LiDAR generator with NeRF-based rendering. Shared latent space ensures cross-modal consistency. DataCrafter provides semantic supervision.", "result": "State-of-the-art performance on nuScenes (FVD 16.95, FID 4.24, Chamfer 0.611). Benefits downstream tasks like segmentation and 3D detection.", "conclusion": "Genesis effectively generates high-quality, semantically consistent multi-modal data, proving useful for practical applications in autonomous driving."}}
{"id": "2405.16727", "pdf": "https://arxiv.org/pdf/2405.16727", "abs": "https://arxiv.org/abs/2405.16727", "authors": ["Awni Altabaa", "John Lafferty"], "title": "Disentangling and Integrating Relational and Sensory Information in Transformer Architectures", "categories": ["cs.LG"], "comment": "ICML 2025", "summary": "Relational reasoning is a central component of generally intelligent systems,\nenabling robust and data-efficient inductive generalization. Recent empirical\nevidence shows that many existing neural architectures, including Transformers,\nstruggle with tasks requiring relational reasoning. In this work, we\ndistinguish between two types of information: sensory information about the\nproperties of individual objects, and relational information about the\nrelationships between objects. While neural attention provides a powerful\nmechanism for controlling the flow of sensory information between objects, the\nTransformer lacks an explicit computational mechanism for routing and\nprocessing relational information. To address this limitation, we propose an\narchitectural extension of the Transformer framework that we call the Dual\nAttention Transformer (DAT), featuring two distinct attention mechanisms:\nsensory attention for directing the flow of sensory information, and a novel\nrelational attention mechanism for directing the flow of relational\ninformation. We empirically evaluate DAT on a diverse set of tasks ranging from\nsynthetic relational benchmarks to complex real-world tasks such as language\nmodeling and visual processing. Our results demonstrate that integrating\nexplicit relational computational mechanisms into the Transformer architecture\nleads to significant performance gains in terms of data efficiency and\nparameter efficiency.", "AI": {"tldr": "The paper introduces the Dual Attention Transformer (DAT), an extension of the Transformer framework, to address its limitations in relational reasoning by incorporating separate sensory and relational attention mechanisms.", "motivation": "Existing neural architectures, including Transformers, struggle with relational reasoning tasks, lacking explicit mechanisms for processing relational information.", "method": "The proposed DAT features dual attention mechanisms: sensory attention for object properties and relational attention for inter-object relationships.", "result": "DAT shows significant performance improvements in data and parameter efficiency across synthetic and real-world tasks.", "conclusion": "Explicit relational mechanisms enhance Transformer performance, making DAT a promising solution for relational reasoning tasks."}}
{"id": "2502.13030", "pdf": "https://arxiv.org/pdf/2502.13030", "abs": "https://arxiv.org/abs/2502.13030", "authors": ["Sunay Joshi", "Shayan Kiyani", "George Pappas", "Edgar Dobriban", "Hamed Hassani"], "title": "Conformal Inference under High-Dimensional Covariate Shifts via Likelihood-Ratio Regularization", "categories": ["stat.ML", "cs.AI", "cs.LG"], "comment": null, "summary": "We consider the problem of conformal prediction under covariate shift. Given\nlabeled data from a source domain and unlabeled data from a covariate shifted\ntarget domain, we seek to construct prediction sets with valid marginal\ncoverage in the target domain. Most existing methods require estimating the\nunknown likelihood ratio function, which can be prohibitive for\nhigh-dimensional data such as images. To address this challenge, we introduce\nthe likelihood ratio regularized quantile regression (LR-QR) algorithm, which\ncombines the pinball loss with a novel choice of regularization in order to\nconstruct a threshold function without directly estimating the unknown\nlikelihood ratio. We show that the LR-QR method has coverage at the desired\nlevel in the target domain, up to a small error term that we can control. Our\nproofs draw on a novel analysis of coverage via stability bounds from learning\ntheory. Our experiments demonstrate that the LR-QR algorithm outperforms\nexisting methods on high-dimensional prediction tasks, including a regression\ntask for the Communities and Crime dataset, an image classification task from\nthe WILDS repository, and an LLM question-answering task on the MMLU benchmark.", "AI": {"tldr": "The paper introduces LR-QR, a method for conformal prediction under covariate shift without directly estimating likelihood ratios, ensuring valid coverage in the target domain.", "motivation": "Existing methods for conformal prediction under covariate shift require estimating likelihood ratios, which is challenging for high-dimensional data like images.", "method": "The LR-QR algorithm combines pinball loss with a novel regularization to construct a threshold function without estimating likelihood ratios.", "result": "LR-QR achieves desired coverage in the target domain with a controllable error, outperforming existing methods in high-dimensional tasks.", "conclusion": "LR-QR is a practical solution for conformal prediction under covariate shift, especially for high-dimensional data."}}
{"id": "2506.09399", "pdf": "https://arxiv.org/pdf/2506.09399", "abs": "https://arxiv.org/abs/2506.09399", "authors": ["Kaiyu Guo", "Zijian Wang", "Tan Pan", "Brian C. Lovell", "Mahsa Baktashmotlagh"], "title": "Improving Out-of-Distribution Detection via Dynamic Covariance Calibration", "categories": ["cs.CV"], "comment": null, "summary": "Out-of-Distribution (OOD) detection is essential for the trustworthiness of\nAI systems. Methods using prior information (i.e., subspace-based methods) have\nshown effective performance by extracting information geometry to detect OOD\ndata with a more appropriate distance metric. However, these methods fail to\naddress the geometry distorted by ill-distributed samples, due to the\nlimitation of statically extracting information geometry from the training\ndistribution. In this paper, we argue that the influence of ill-distributed\nsamples can be corrected by dynamically adjusting the prior geometry in\nresponse to new data. Based on this insight, we propose a novel approach that\ndynamically updates the prior covariance matrix using real-time input features,\nrefining its information. Specifically, we reduce the covariance along the\ndirection of real-time input features and constrain adjustments to the residual\nspace, thus preserving essential data characteristics and avoiding effects on\nunintended directions in the principal space. We evaluate our method on two\npre-trained models for the CIFAR dataset and five pre-trained models for\nImageNet-1k, including the self-supervised DINO model. Extensive experiments\ndemonstrate that our approach significantly enhances OOD detection across\nvarious models. The code is released at https://github.com/workerbcd/ooddcc.", "AI": {"tldr": "The paper proposes a dynamic method to correct geometry distortion in OOD detection by adjusting the prior covariance matrix in real-time, improving performance across models.", "motivation": "Current subspace-based OOD detection methods fail to handle geometry distortion caused by ill-distributed samples due to static prior extraction.", "method": "Dynamically updates the prior covariance matrix using real-time input features, reducing covariance along input directions and preserving residual space.", "result": "Significantly enhances OOD detection performance on CIFAR and ImageNet-1k datasets, including the DINO model.", "conclusion": "Dynamic adjustment of prior geometry effectively addresses distortion, improving OOD detection reliability."}}
{"id": "2406.03458", "pdf": "https://arxiv.org/pdf/2406.03458", "abs": "https://arxiv.org/abs/2406.03458", "authors": ["Saba Ahmadi", "Siddharth Bhandari", "Avrim Blum", "Chen Dan", "Prabhav Jain"], "title": "Distributional Adversarial Loss", "categories": ["cs.LG"], "comment": null, "summary": "We initiate the study of a new notion of adversarial loss which we call\ndistributional adversarial loss. In this notion, we assume for each original\nexample, the allowed adversarial perturbation set is a family of distributions,\nand the adversarial loss over each example is the maximum loss over all the\nassociated distributions. The goal is to minimize the overall adversarial loss.\nWe show sample complexity bounds in the PAC-learning setting for our notion of\nadversarial loss. Our notion of adversarial loss contrasts the prior work on\nrobust learning that considers a set of points, not distributions, as the\nperturbation set of each clean example. As an application of our approach, we\nshow how to unify the two lines of work on randomized smoothing and robust\nlearning in the PAC-learning setting and derive sample complexity bounds for\nrandomized smoothing methods.\n  Furthermore, we investigate the role of randomness in achieving robustness\nagainst adversarial attacks. We show a general derandomization technique that\npreserves the extent of a randomized classifier's robustness against\nadversarial attacks and show its effectiveness empirically.", "AI": {"tldr": "The paper introduces 'distributional adversarial loss,' where adversarial perturbations are distributions, not points. It provides PAC-learning bounds and unifies randomized smoothing with robust learning. A derandomization technique for robustness is also presented.", "motivation": "To address limitations in robust learning by considering adversarial perturbations as distributions, not just points, and to bridge the gap between randomized smoothing and robust learning.", "method": "Proposes distributional adversarial loss, analyzes its PAC-learning bounds, and introduces a derandomization technique for robustness.", "result": "Sample complexity bounds for the new adversarial loss are derived, and the derandomization technique effectively preserves robustness.", "conclusion": "The work advances robust learning by unifying randomized smoothing and robust learning, and provides practical tools for derandomizing robust classifiers."}}
{"id": "2502.20233", "pdf": "https://arxiv.org/pdf/2502.20233", "abs": "https://arxiv.org/abs/2502.20233", "authors": ["Daniela B\u00f6hm", "Georg Gottlob", "Matthias Lanzinger", "Davide Longo", "Cem Okulmus", "Reinhard Pichler", "Alexander Selzer"], "title": "Selective Use of Yannakakis' Algorithm to Improve Query Performance: Machine Learning to the Rescue", "categories": ["cs.DB", "cs.AI"], "comment": null, "summary": "Query optimization has played a central role in database research for\ndecades. However, more often than not, the proposed optimization techniques\nlead to a performance improvement in some, but not in all, situations.\nTherefore, we urgently need a methodology for designing a decision procedure\nthat decides for a given query whether the optimization technique should be\napplied or not.\n  In this work, we propose such a methodology with a focus on Yannakakis-style\nquery evaluation as our optimization technique of interest. More specifically,\nwe formulate this decision problem as an algorithm selection problem and we\npresent a Machine Learning based approach for its solution. Empirical results\nwith several benchmarks on a variety of database systems show that our approach\nindeed leads to a statistically significant performance improvement.", "AI": {"tldr": "A methodology for deciding when to apply Yannakakis-style query optimization using ML-based algorithm selection, showing significant performance improvements.", "motivation": "Current query optimizations improve performance inconsistently; a decision procedure is needed to determine when to apply them.", "method": "Formulate the decision as an algorithm selection problem and solve it using a Machine Learning approach.", "result": "Empirical results demonstrate statistically significant performance improvements across benchmarks and database systems.", "conclusion": "The proposed ML-based methodology effectively decides when to apply Yannakakis-style optimization, enhancing query performance."}}
{"id": "2506.09965", "pdf": "https://arxiv.org/pdf/2506.09965", "abs": "https://arxiv.org/abs/2506.09965", "authors": ["Junfei Wu", "Jian Guan", "Kaituo Feng", "Qiang Liu", "Shu Wu", "Liang Wang", "Wei Wu", "Tieniu Tan"], "title": "Reinforcing Spatial Reasoning in Vision-Language Models with Interwoven Thinking and Visual Drawing", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "As textual reasoning with large language models (LLMs) has advanced\nsignificantly, there has been growing interest in enhancing the multimodal\nreasoning capabilities of large vision-language models (LVLMs). However,\nexisting methods primarily approach multimodal reasoning in a straightforward,\ntext-centric manner, where both reasoning and answer derivation are conducted\npurely through text, with the only difference being the presence of multimodal\ninput. As a result, these methods often encounter fundamental limitations in\nspatial reasoning tasks that demand precise geometric understanding and\ncontinuous spatial tracking-capabilities that humans achieve through mental\nvisualization and manipulation. To address the limitations, we propose drawing\nto reason in space, a novel paradigm that enables LVLMs to reason through\nelementary drawing operations in the visual space. By equipping models with\nbasic drawing operations, including annotating bounding boxes and drawing\nauxiliary lines, we empower them to express and analyze spatial relationships\nthrough direct visual manipulation, meanwhile avoiding the performance ceiling\nimposed by specialized perception tools in previous tool-integrated reasoning\napproaches. To cultivate this capability, we develop a three-stage training\nframework: cold-start training with synthetic data to establish basic drawing\nabilities, reflective rejection sampling to enhance self-reflection behaviors,\nand reinforcement learning to directly optimize for target rewards. Extensive\nexperiments demonstrate that our model, named VILASR, consistently outperforms\nexisting methods across diverse spatial reasoning benchmarks, involving maze\nnavigation, static spatial reasoning, video-based reasoning, and\nmulti-view-based reasoning tasks, with an average improvement of 18.4%.", "AI": {"tldr": "The paper introduces 'drawing to reason in space,' a novel paradigm for LVLMs to enhance spatial reasoning by using visual drawing operations, outperforming existing methods by 18.4%.", "motivation": "Existing multimodal reasoning methods are text-centric and struggle with spatial tasks requiring geometric understanding. The paper aims to overcome these limitations by enabling LVLMs to reason visually.", "method": "The proposed method involves equipping LVLMs with drawing operations (e.g., bounding boxes, auxiliary lines) and a three-stage training framework: cold-start training, reflective rejection sampling, and reinforcement learning.", "result": "The model, VILASR, shows significant improvements (18.4% on average) across diverse spatial reasoning benchmarks.", "conclusion": "Visual reasoning through drawing operations effectively addresses the limitations of text-centric approaches, enhancing LVLMs' spatial reasoning capabilities."}}
{"id": "2406.07213", "pdf": "https://arxiv.org/pdf/2406.07213", "abs": "https://arxiv.org/abs/2406.07213", "authors": ["Zhiyu Shao", "Qiong Wu", "Pingyi Fan", "Nan Cheng", "Wen Chen", "Jiangzhou Wang", "Khaled B. Letaief"], "title": "Semantic-Aware Spectrum Sharing in Internet of Vehicles Based on Deep Reinforcement Learning", "categories": ["cs.LG"], "comment": "This paper has been accepted by IEEE Internet of Things Journal. The\n  source code has been released at:\n  https://github.com/qiongwu86/Semantic-Aware-Spectrum-Sharing-in-Internet-of-Vehicles-Based-on-Deep-Reinforcement-Learning", "summary": "This work aims to investigate semantic communication in high-speed mobile\nInternet of vehicles (IoV) environments, with a focus on the spectrum sharing\nbetween vehicle-to-vehicle (V2V) and vehicle-to-infrastructure (V2I)\ncommunications. We specifically address spectrum scarcity and network traffic\nand then propose a semantic-aware spectrum sharing algorithm (SSS) based on the\ndeep reinforcement learning (DRL) soft actor-critic (SAC) approach. Firstly, we\ndelve into the extraction of semantic information. Secondly, we redefine\nmetrics for semantic information in V2V and V2I spectrum sharing in IoV\nenvironments, introducing high-speed semantic spectrum efficiency (HSSE) and\nsemantic transmission rate (HSR). Finally, we employ the SAC algorithm for\ndecision optimization in V2V and V2I spectrum sharing based on semantic\ninformation. This optimization encompasses the optimal link of V2V and V2I\nsharing strategies, the transmission power for vehicles sending semantic\ninformation and the length of transmitted semantic symbols, aiming at\nmaximizing HSSE of V2I and enhancing success rate of effective semantic\ninformation transmission (SRS) of V2V. Experimental results demonstrate that\nthe SSS algorithm outperforms other baseline algorithms, including other\ntraditional-communication-based spectrum sharing algorithms and spectrum\nsharing algorithm using other reinforcement learning approaches. The SSS\nalgorithm exhibits a 15% increase in HSSE and approximately a 7% increase in\nSRS.", "AI": {"tldr": "The paper proposes a semantic-aware spectrum sharing algorithm (SSS) using deep reinforcement learning (SAC) to optimize V2V and V2I communications in IoV, improving HSSE and SRS.", "motivation": "Address spectrum scarcity and network traffic in high-speed mobile IoV environments by leveraging semantic communication.", "method": "Extract semantic information, redefine metrics (HSSE, HSR), and use SAC for decision optimization in spectrum sharing.", "result": "SSS outperforms baselines, increasing HSSE by 15% and SRS by ~7%.", "conclusion": "SSS is effective for semantic-aware spectrum sharing in IoV, enhancing efficiency and transmission success."}}
{"id": "2502.20843", "pdf": "https://arxiv.org/pdf/2502.20843", "abs": "https://arxiv.org/abs/2502.20843", "authors": ["Yoonyoung Cho", "Junhyek Han", "Jisu Han", "Beomjoon Kim"], "title": "Hierarchical and Modular Network on Non-prehensile Manipulation in General Environments", "categories": ["cs.RO", "cs.AI", "cs.LG"], "comment": "http://unicorn-hamnet.github.io/", "summary": "For robots to operate in general environments like households, they must be\nable to perform non-prehensile manipulation actions such as toppling and\nrolling to manipulate ungraspable objects. However, prior works on\nnon-prehensile manipulation cannot yet generalize across environments with\ndiverse geometries. The main challenge lies in adapting to varying\nenvironmental constraints: within a cabinet, the robot must avoid walls and\nceilings; to lift objects to the top of a step, the robot must account for the\nstep's pose and extent. While deep reinforcement learning (RL) has demonstrated\nimpressive success in non-prehensile manipulation, accounting for such\nvariability presents a challenge for the generalist policy, as it must learn\ndiverse strategies for each new combination of constraints. To address this, we\npropose a modular and reconfigurable architecture that adaptively reconfigures\nnetwork modules based on task requirements. To capture the geometric\nvariability in environments, we extend the contact-based object representation\n(CORN) to environment geometries, and propose a procedural algorithm for\ngenerating diverse environments to train our agent. Taken together, the\nresulting policy can zero-shot transfer to novel real-world environments and\nobjects despite training entirely within a simulator. We additionally release a\nsimulation-based benchmark featuring nine digital twins of real-world scenes\nwith 353 objects to facilitate non-prehensile manipulation research in\nrealistic domains.", "AI": {"tldr": "A modular RL architecture is proposed for non-prehensile manipulation, adapting to diverse environmental geometries and enabling zero-shot transfer to real-world scenarios.", "motivation": "Robots need to generalize non-prehensile manipulation (e.g., toppling, rolling) across diverse environments, but prior methods struggle with varying constraints like walls or steps.", "method": "A modular and reconfigurable RL architecture adapts network modules based on task needs, using an extended contact-based representation (CORN) for environments and procedural generation for training.", "result": "The policy achieves zero-shot transfer to novel real-world environments and objects, trained entirely in simulation. A benchmark with nine digital twins and 353 objects is released.", "conclusion": "The approach successfully generalizes non-prehensile manipulation across diverse geometries, advancing real-world applicability."}}
{"id": "2506.10082", "pdf": "https://arxiv.org/pdf/2506.10082", "abs": "https://arxiv.org/abs/2506.10082", "authors": ["Chenjian Gao", "Lihe Ding", "Xin Cai", "Zhanpeng Huang", "Zibin Wang", "Tianfan Xue"], "title": "LoRA-Edit: Controllable First-Frame-Guided Video Editing via Mask-Aware LoRA Fine-Tuning", "categories": ["cs.CV"], "comment": "12 pages", "summary": "Video editing using diffusion models has achieved remarkable results in\ngenerating high-quality edits for videos. However, current methods often rely\non large-scale pretraining, limiting flexibility for specific edits.\nFirst-frame-guided editing provides control over the first frame, but lacks\nflexibility over subsequent frames. To address this, we propose a mask-based\nLoRA (Low-Rank Adaptation) tuning method that adapts pretrained Image-to-Video\n(I2V) models for flexible video editing. Our approach preserves background\nregions while enabling controllable edits propagation. This solution offers\nefficient and adaptable video editing without altering the model architecture.\nTo better steer this process, we incorporate additional references, such as\nalternate viewpoints or representative scene states, which serve as visual\nanchors for how content should unfold. We address the control challenge using a\nmask-driven LoRA tuning strategy that adapts a pre-trained image-to-video model\nto the editing context. The model must learn from two distinct sources: the\ninput video provides spatial structure and motion cues, while reference images\noffer appearance guidance. A spatial mask enables region-specific learning by\ndynamically modulating what the model attends to, ensuring that each area draws\nfrom the appropriate source. Experimental results show our method achieves\nsuperior video editing performance compared to state-of-the-art methods.\nProject Page: https://cjeen.github.io/LoraEditPaper", "AI": {"tldr": "A mask-based LoRA tuning method is proposed for flexible video editing using pretrained I2V models, preserving backgrounds while enabling controllable edits.", "motivation": "Current methods rely on large-scale pretraining and lack flexibility for specific edits, especially beyond the first frame.", "method": "The approach uses mask-driven LoRA tuning to adapt pretrained I2V models, incorporating reference images and spatial masks for region-specific learning.", "result": "The method achieves superior video editing performance compared to state-of-the-art techniques.", "conclusion": "The proposed solution offers efficient, adaptable video editing without altering model architecture, addressing flexibility and control challenges."}}
{"id": "2406.11245", "pdf": "https://arxiv.org/pdf/2406.11245", "abs": "https://arxiv.org/abs/2406.11245", "authors": ["Kangwei Qi", "Qiong Wu", "Pingyi Fan", "Nan Cheng", "Wen Chen", "Jiangzhou Wang", "Khaled B. Letaief"], "title": "Deep-Reinforcement-Learning-Based AoI-Aware Resource Allocation for RIS-Aided IoV Networks", "categories": ["cs.LG", "cs.DC", "cs.NI", "eess.SP"], "comment": "This paper has been accepted by IEEE Transactions on Vehicular\n  Technology. The source code has been released at\n  https://github.com/qiongwu86/RIS-RB-AoI-V2X-DRL.git", "summary": "Reconfigurable Intelligent Surface (RIS) is a pivotal technology in\ncommunication, offering an alternative path that significantly enhances the\nlink quality in wireless communication environments. In this paper, we propose\na RIS-assisted internet of vehicles (IoV) network, considering the\nvehicle-to-everything (V2X) communication method. In addition, in order to\nimprove the timeliness of vehicle-to-infrastructure (V2I) links and the\nstability of vehicle-to-vehicle (V2V) links, we introduce the age of\ninformation (AoI) model and the payload transmission probability model.\nTherefore, with the objective of minimizing the AoI of V2I links and\nprioritizing transmission of V2V links payload, we construct this optimization\nproblem as an Markov decision process (MDP) problem in which the BS serves as\nan agent to allocate resources and control phase-shift for the vehicles using\nthe soft actor-critic (SAC) algorithm, which gradually converges and maintains\na high stability. A AoI-aware joint vehicular resource allocation and RIS\nphase-shift control scheme based on SAC algorithm is proposed and simulation\nresults show that its convergence speed, cumulative reward, AoI performance,\nand payload transmission probability outperforms those of proximal policy\noptimization (PPO), deep deterministic policy gradient (DDPG), twin delayed\ndeep deterministic policy gradient (TD3) and stochastic algorithms.", "AI": {"tldr": "The paper proposes a RIS-assisted IoV network using SAC algorithm to optimize V2I and V2V communications, outperforming PPO, DDPG, TD3, and stochastic methods.", "motivation": "To enhance link quality and timeliness in V2X communications, focusing on AoI for V2I and payload stability for V2V.", "method": "Formulates the problem as an MDP, using SAC for resource allocation and RIS phase-shift control.", "result": "Simulations show superior convergence, reward, AoI, and payload transmission compared to other algorithms.", "conclusion": "The SAC-based scheme effectively optimizes RIS-assisted IoV networks, improving performance metrics."}}
{"id": "2503.01437", "pdf": "https://arxiv.org/pdf/2503.01437", "abs": "https://arxiv.org/abs/2503.01437", "authors": ["Th\u00e9o Vincent", "Tim Faust", "Yogesh Tripathi", "Jan Peters", "Carlo D'Eramo"], "title": "Eau De $Q$-Network: Adaptive Distillation of Neural Networks in Deep Reinforcement Learning", "categories": ["cs.LG", "cs.AI"], "comment": "Published at RLC 2025:\n  https://openreview.net/forum?id=Bb84iBj4wU#discussion", "summary": "Recent works have successfully demonstrated that sparse deep reinforcement\nlearning agents can be competitive against their dense counterparts. This opens\nup opportunities for reinforcement learning applications in fields where\ninference time and memory requirements are cost-sensitive or limited by\nhardware. Until now, dense-to-sparse methods have relied on hand-designed\nsparsity schedules that are not synchronized with the agent's learning pace.\nCrucially, the final sparsity level is chosen as a hyperparameter, which\nrequires careful tuning as setting it too high might lead to poor performances.\nIn this work, we address these shortcomings by crafting a dense-to-sparse\nalgorithm that we name Eau De $Q$-Network (EauDeQN). To increase sparsity at\nthe agent's learning pace, we consider multiple online networks with different\nsparsity levels, where each online network is trained from a shared target\nnetwork. At each target update, the online network with the smallest loss is\nchosen as the next target network, while the other networks are replaced by a\npruned version of the chosen network. We evaluate the proposed approach on the\nAtari $2600$ benchmark and the MuJoCo physics simulator, showing that EauDeQN\nreaches high sparsity levels while keeping performances high.", "AI": {"tldr": "EauDeQN is a dense-to-sparse algorithm for reinforcement learning that dynamically adjusts sparsity levels based on the agent's learning pace, achieving high sparsity without performance loss.", "motivation": "Existing dense-to-sparse methods use fixed sparsity schedules and require manual tuning of sparsity levels, which can hinder performance.", "method": "EauDeQN uses multiple online networks with varying sparsity levels, trained from a shared target network, and selects the best-performing network at each update.", "result": "EauDeQN achieves high sparsity while maintaining performance on Atari 2600 and MuJoCo benchmarks.", "conclusion": "EauDeQN effectively automates sparsity adjustment, improving efficiency without compromising performance."}}
{"id": "2506.10730", "pdf": "https://arxiv.org/pdf/2506.10730", "abs": "https://arxiv.org/abs/2506.10730", "authors": ["Hong Huang", "Weixiang Sun", "Zhijian Wu", "Jingwen Niu", "Donghuan Lu", "Xian Wu", "Yefeng Zheng"], "title": "IQE-CLIP: Instance-aware Query Embedding for Zero-/Few-shot Anomaly Detection in Medical Domain", "categories": ["cs.CV"], "comment": null, "summary": "Recently, the rapid advancements of vision-language models, such as CLIP,\nleads to significant progress in zero-/few-shot anomaly detection (ZFSAD)\ntasks. However, most existing CLIP-based ZFSAD methods commonly assume prior\nknowledge of categories and rely on carefully crafted prompts tailored to\nspecific scenarios. While such meticulously designed text prompts effectively\ncapture semantic information in the textual space, they fall short of\ndistinguishing normal and anomalous instances within the joint embedding space.\nMoreover, these ZFSAD methods are predominantly explored in industrial\nscenarios, with few efforts conducted to medical tasks. To this end, we propose\nan innovative framework for ZFSAD tasks in medical domain, denoted as IQE-CLIP.\nWe reveal that query embeddings, which incorporate both textual and\ninstance-aware visual information, are better indicators for abnormalities.\nSpecifically, we first introduce class-based prompting tokens and learnable\nprompting tokens for better adaptation of CLIP to the medical domain. Then, we\ndesign an instance-aware query module (IQM) to extract region-level contextual\ninformation from both text prompts and visual features, enabling the generation\nof query embeddings that are more sensitive to anomalies. Extensive experiments\nconducted on six medical datasets demonstrate that IQE-CLIP achieves\nstate-of-the-art performance on both zero-shot and few-shot tasks. We release\nour code and data at https://github.com/hongh0/IQE-CLIP/.", "AI": {"tldr": "IQE-CLIP is a new framework for zero-/few-shot anomaly detection in the medical domain, improving CLIP's adaptability and sensitivity to anomalies through class-based and learnable prompting tokens, and an instance-aware query module.", "motivation": "Existing CLIP-based methods for anomaly detection rely on prior knowledge and tailored prompts, lacking effectiveness in distinguishing anomalies in joint embedding space and are rarely applied to medical tasks.", "method": "IQE-CLIP introduces class-based and learnable prompting tokens for domain adaptation and an instance-aware query module (IQM) to generate anomaly-sensitive query embeddings from text and visual features.", "result": "IQE-CLIP achieves state-of-the-art performance on six medical datasets for zero-shot and few-shot anomaly detection tasks.", "conclusion": "The proposed IQE-CLIP framework effectively addresses limitations of existing methods and demonstrates superior performance in medical anomaly detection."}}
{"id": "2407.07575", "pdf": "https://arxiv.org/pdf/2407.07575", "abs": "https://arxiv.org/abs/2407.07575", "authors": ["Yu Xie", "Qiong Wu", "Pingyi Fan", "Nan Cheng", "Wen Chen", "Jiangzhou Wang", "Khaled B. Letaief"], "title": "Resource Allocation for Twin Maintenance and Computing Task Processing in Digital Twin Vehicular Edge Computing Network", "categories": ["cs.LG", "cs.NI"], "comment": "This paper has been accepted by IEEE Internet of Things Journal. The\n  source code has been released\n  at:https://github.com/qiongwu86/Resource-allocation-for-twin-maintenance-and-computing-tasks-in-digital-twin-mobile-edge-network", "summary": "As a promising technology, vehicular edge computing (VEC) can provide\ncomputing and caching services by deploying VEC servers near vehicles. However,\nVEC networks still face challenges such as high vehicle mobility. Digital twin\n(DT), an emerging technology, can predict, estimate, and analyze real-time\nstates by digitally modeling objects in the physical world. By integrating DT\nwith VEC, a virtual vehicle DT can be created in the VEC server to monitor the\nreal-time operating status of vehicles. However, maintaining the vehicle DT\nmodel requires ongoing attention from the VEC server, which also needs to offer\ncomputing services for the vehicles. Therefore, effective allocation and\nscheduling of VEC server resources are crucial. This study focuses on a general\nVEC network with a single VEC service and multiple vehicles, examining the two\ntypes of delays caused by twin maintenance and computational processing within\nthe network. By transforming the problem using satisfaction functions, we\npropose an optimization problem aimed at maximizing each vehicle's resource\nutility to determine the optimal resource allocation strategy. Given the\nnon-convex nature of the issue, we employ multi-agent Markov decision processes\nto reformulate the problem. Subsequently, we propose the twin maintenance and\ncomputing task processing resource collaborative scheduling (MADRL-CSTC)\nalgorithm, which leverages multi-agent deep reinforcement learning. Through\nexperimental comparisons with alternative algorithms, it demonstrates that our\nproposed approach is effective in terms of resource allocation.", "AI": {"tldr": "The paper integrates Digital Twin (DT) with Vehicular Edge Computing (VEC) to optimize resource allocation, addressing delays from twin maintenance and computational processing. A multi-agent deep reinforcement learning algorithm (MADRL-CSTC) is proposed and validated as effective.", "motivation": "VEC networks face challenges like high vehicle mobility. DT can model real-time vehicle states, but resource allocation for both DT maintenance and computational services is critical.", "method": "The study transforms the problem using satisfaction functions, formulates it as a non-convex optimization, and employs multi-agent Markov decision processes. The MADRL-CSTC algorithm is proposed for collaborative scheduling.", "result": "Experimental comparisons show MADRL-CSTC effectively optimizes resource allocation in VEC networks.", "conclusion": "Integrating DT with VEC and using MADRL-CSTC improves resource utility and addresses delays, demonstrating practical effectiveness."}}
{"id": "2503.08558", "pdf": "https://arxiv.org/pdf/2503.08558", "abs": "https://arxiv.org/abs/2503.08558", "authors": ["Chen Xu", "Tony Khuong Nguyen", "Emma Dixon", "Christopher Rodriguez", "Patrick Miller", "Robert Lee", "Paarth Shah", "Rares Ambrus", "Haruki Nishimura", "Masha Itkina"], "title": "Can We Detect Failures Without Failure Data? Uncertainty-Aware Runtime Failure Detection for Imitation Learning Policies", "categories": ["cs.RO", "cs.AI", "cs.LG"], "comment": "Accepted by Robotics: Science and Systems 2025", "summary": "Recent years have witnessed impressive robotic manipulation systems driven by\nadvances in imitation learning and generative modeling, such as diffusion- and\nflow-based approaches. As robot policy performance increases, so does the\ncomplexity and time horizon of achievable tasks, inducing unexpected and\ndiverse failure modes that are difficult to predict a priori. To enable\ntrustworthy policy deployment in safety-critical human environments, reliable\nruntime failure detection becomes important during policy inference. However,\nmost existing failure detection approaches rely on prior knowledge of failure\nmodes and require failure data during training, which imposes a significant\nchallenge in practicality and scalability. In response to these limitations, we\npresent FAIL-Detect, a modular two-stage approach for failure detection in\nimitation learning-based robotic manipulation. To accurately identify failures\nfrom successful training data alone, we frame the problem as sequential\nout-of-distribution (OOD) detection. We first distill policy inputs and outputs\ninto scalar signals that correlate with policy failures and capture epistemic\nuncertainty. FAIL-Detect then employs conformal prediction (CP) as a versatile\nframework for uncertainty quantification with statistical guarantees.\nEmpirically, we thoroughly investigate both learned and post-hoc scalar signal\ncandidates on diverse robotic manipulation tasks. Our experiments show learned\nsignals to be mostly consistently effective, particularly when using our novel\nflow-based density estimator. Furthermore, our method detects failures more\naccurately and faster than state-of-the-art (SOTA) failure detection baselines.\nThese results highlight the potential of FAIL-Detect to enhance the safety and\nreliability of imitation learning-based robotic systems as they progress toward\nreal-world deployment.", "AI": {"tldr": "FAIL-Detect is a modular two-stage approach for failure detection in robotic manipulation, using sequential out-of-distribution detection and conformal prediction to identify failures without prior failure data.", "motivation": "Existing failure detection methods require prior knowledge of failure modes and training data, limiting practicality and scalability. FAIL-Detect addresses this by detecting failures from successful training data alone.", "method": "FAIL-Detect distills policy inputs/outputs into scalar signals and uses conformal prediction for uncertainty quantification. It employs a flow-based density estimator for improved accuracy.", "result": "FAIL-Detect detects failures more accurately and faster than state-of-the-art baselines, demonstrating its effectiveness across diverse robotic tasks.", "conclusion": "FAIL-Detect enhances the safety and reliability of imitation learning-based robotic systems, making it suitable for real-world deployment."}}
{"id": "2506.11302", "pdf": "https://arxiv.org/pdf/2506.11302", "abs": "https://arxiv.org/abs/2506.11302", "authors": ["H\u00e9ctor Carri\u00f3n", "Yutong Bai", "V\u00edctor A. Hern\u00e1ndez Castro", "Kishan Panaganti", "Ayush Zenith", "Matthew Trang", "Tony Zhang", "Pietro Perona", "Jitendra Malik"], "title": "TARDIS STRIDE: A Spatio-Temporal Road Image Dataset and World Model for Autonomy", "categories": ["cs.CV", "cs.AI"], "comment": "Computer Vision, Pattern Recognition, Early-Fusion, Dataset, Data\n  Augmentation", "summary": "World models aim to simulate environments and enable effective agent\nbehavior. However, modeling real-world environments presents unique challenges\nas they dynamically change across both space and, crucially, time. To capture\nthese composed dynamics, we introduce a Spatio-Temporal Road Image Dataset for\nExploration (STRIDE) permuting 360-degree panoramic imagery into rich\ninterconnected observation, state and action nodes. Leveraging this structure,\nwe can simultaneously model the relationship between egocentric views,\npositional coordinates, and movement commands across both space and time. We\nbenchmark this dataset via TARDIS, a transformer-based generative world model\nthat integrates spatial and temporal dynamics through a unified autoregressive\nframework trained on STRIDE. We demonstrate robust performance across a range\nof agentic tasks such as controllable photorealistic image synthesis,\ninstruction following, autonomous self-control, and state-of-the-art\ngeoreferencing. These results suggest a promising direction towards\nsophisticated generalist agents--capable of understanding and manipulating the\nspatial and temporal aspects of their material environments--with enhanced\nembodied reasoning capabilities. Training code, datasets, and model checkpoints\nare made available at https://huggingface.co/datasets/Tera-AI/STRIDE.", "AI": {"tldr": "The paper introduces STRIDE, a spatio-temporal dataset for world modeling, and TARDIS, a transformer-based model, to address dynamic real-world challenges. It shows strong performance in agent tasks like image synthesis and georeferencing.", "motivation": "Real-world environments change dynamically in space and time, posing challenges for world modeling. The goal is to capture these dynamics for better agent behavior.", "method": "The authors create STRIDE, a dataset of interconnected observation, state, and action nodes from 360-degree imagery. They use TARDIS, a transformer-based model, to integrate spatial and temporal dynamics.", "result": "The model achieves robust performance in tasks like photorealistic image synthesis, instruction following, autonomous control, and georeferencing.", "conclusion": "The approach advances generalist agents by enhancing their ability to understand and manipulate spatio-temporal dynamics. Resources are publicly available."}}
{"id": "2407.08458", "pdf": "https://arxiv.org/pdf/2407.08458", "abs": "https://arxiv.org/abs/2407.08458", "authors": ["Shulin Song", "Zheng Zhang", "Qiong Wu", "Qiang Fan", "Pingyi Fan"], "title": "Joint Optimization of Age of Information and Energy Consumption in NR-V2X System based on Deep Reinforcement Learning", "categories": ["cs.LG", "cs.NI", "eess.SP"], "comment": "This paper has been accepted by sensors. The source code has been\n  released at:\n  https://github.com/qiongwu86/Joint-Optimization-of-AoI-and-Energy-Consumption-in-NR-V2X-System-based-on-DRL", "summary": "Autonomous driving may be the most important application scenario of next\ngeneration, the development of wireless access technologies enabling reliable\nand low-latency vehicle communication becomes crucial. To address this, 3GPP\nhas developed Vehicle-to-Everything (V2X) specifications based on 5G New Radio\n(NR) technology, where Mode 2 Side-Link (SL) communication resembles Mode 4 in\nLTE-V2X, allowing direct communication between vehicles. This supplements SL\ncommunication in LTE-V2X and represents the latest advancement in cellular V2X\n(C-V2X) with improved performance of NR-V2X. However, in NR-V2X Mode 2,\nresource collisions still occur, and thus degrade the age of information (AOI).\nTherefore, a interference cancellation method is employed to mitigate this\nimpact by combining NR-V2X with Non-Orthogonal multiple access (NOMA)\ntechnology. In NR-V2X, when vehicles select smaller resource reservation\ninterval (RRI), higher-frequency transmissions take ore energy to reduce AoI.\nHence, it is important to jointly consider AoI and communication energy\nconsumption based on NR-V2X communication. Then, we formulate such an\noptimization problem and employ the Deep Reinforcement Learning (DRL) algorithm\nto compute the optimal transmission RRI and transmission power for each\ntransmitting vehicle to reduce the energy consumption of each transmitting\nvehicle and the AoI of each receiving vehicle. Extensive simulations have\ndemonstrated the performance of our proposed algorithm.", "AI": {"tldr": "The paper proposes a Deep Reinforcement Learning (DRL) algorithm to optimize resource reservation intervals and transmission power in NR-V2X, reducing energy consumption and age of information (AoI).", "motivation": "The need for reliable, low-latency vehicle communication in autonomous driving drives the development of NR-V2X, but resource collisions and high energy consumption degrade performance.", "method": "Combines NR-V2X with Non-Orthogonal Multiple Access (NOMA) and uses DRL to optimize transmission parameters.", "result": "Simulations show the algorithm effectively reduces energy consumption and AoI.", "conclusion": "The proposed DRL-based approach enhances NR-V2X performance, balancing energy efficiency and communication reliability."}}
{"id": "2503.15551", "pdf": "https://arxiv.org/pdf/2503.15551", "abs": "https://arxiv.org/abs/2503.15551", "authors": ["Murong Yue", "Ziyu Yao"], "title": "Efficient but Vulnerable: Benchmarking and Defending LLM Batch Prompting Attack", "categories": ["cs.CR", "cs.AI", "cs.LG"], "comment": "Accepted to ACL Findings, 2025", "summary": "Batch prompting, which combines a batch of multiple queries sharing the same\ncontext in one inference, has emerged as a promising solution to reduce\ninference costs. However, our study reveals a significant security\nvulnerability in batch prompting: malicious users can inject attack\ninstructions into a batch, leading to unwanted interference across all queries,\nwhich can result in the inclusion of harmful content, such as phishing links,\nor the disruption of logical reasoning. In this paper, we construct\nBATCHSAFEBENCH, a comprehensive benchmark comprising 150 attack instructions of\ntwo types and 8k batch instances, to study the batch prompting vulnerability\nsystematically. Our evaluation of both closed-source and open-weight LLMs\ndemonstrates that all LLMs are susceptible to batch-prompting attacks. We then\nexplore multiple defending approaches. While the prompting-based defense shows\nlimited effectiveness for smaller LLMs, the probing-based approach achieves\nabout 95% accuracy in detecting attacks. Additionally, we perform a mechanistic\nanalysis to understand the attack and identify attention heads that are\nresponsible for it.", "AI": {"tldr": "Batch prompting reduces inference costs but introduces security vulnerabilities, allowing malicious attacks. The paper introduces BATCHSAFEBENCH to study and defend against these attacks, finding all LLMs susceptible and proposing effective detection methods.", "motivation": "To address the security risks posed by batch prompting, where malicious instructions can disrupt queries or inject harmful content.", "method": "Constructed BATCHSAFEBENCH with 150 attack instructions and 8k batch instances to evaluate LLM vulnerabilities. Explored prompting-based and probing-based defenses.", "result": "All LLMs are vulnerable to batch-prompting attacks. Probing-based defense detects attacks with ~95% accuracy.", "conclusion": "Batch prompting poses security risks, but probing-based defenses are effective. Attention heads responsible for attacks were identified."}}
{"id": "2506.11996", "pdf": "https://arxiv.org/pdf/2506.11996", "abs": "https://arxiv.org/abs/2506.11996", "authors": ["Hanxue Gu", "Yaqian Chen", "Jisoo Lee", "Diego Schaps", "Regina Woody", "Roy Colglazier", "Maciej A. Mazurowski", "Christopher Mantyh"], "title": "Improving Surgical Risk Prediction Through Integrating Automated Body Composition Analysis: a Retrospective Trial on Colectomy Surgery", "categories": ["cs.CV"], "comment": "32 pages, 5 figures", "summary": "Objective: To evaluate whether preoperative body composition metrics\nautomatically extracted from CT scans can predict postoperative outcomes after\ncolectomy, either alone or combined with clinical variables or existing risk\npredictors. Main outcomes and measures: The primary outcome was the predictive\nperformance for 1-year all-cause mortality following colectomy. A Cox\nproportional hazards model with 1-year follow-up was used, and performance was\nevaluated using the concordance index (C-index) and Integrated Brier Score\n(IBS). Secondary outcomes included postoperative complications, unplanned\nreadmission, blood transfusion, and severe infection, assessed using AUC and\nBrier Score from logistic regression. Odds ratios (OR) described associations\nbetween individual CT-derived body composition metrics and outcomes. Over 300\nfeatures were extracted from preoperative CTs across multiple vertebral levels,\nincluding skeletal muscle area, density, fat areas, and inter-tissue metrics.\nNSQIP scores were available for all surgeries after 2012.", "AI": {"tldr": "Preoperative body composition metrics from CT scans predict postoperative outcomes after colectomy, with 1-year mortality as the primary outcome.", "motivation": "To assess if CT-derived body composition metrics, alone or combined with clinical variables, can improve prediction of postoperative outcomes.", "method": "Used Cox proportional hazards model for 1-year mortality (C-index, IBS) and logistic regression for secondary outcomes (AUC, Brier Score). Extracted over 300 CT features.", "result": "Evaluated predictive performance for mortality and complications, with associations described by odds ratios.", "conclusion": "CT-derived metrics show potential for predicting colectomy outcomes, possibly enhancing existing risk predictors."}}
{"id": "2407.11823", "pdf": "https://arxiv.org/pdf/2407.11823", "abs": "https://arxiv.org/abs/2407.11823", "authors": ["Mohammad Zhalechian", "Soroush Saghafian", "Omar Robles"], "title": "Harmonizing Safety and Speed: A Human-Algorithm Approach to Enhance the FDA's Medical Device Clearance Policy", "categories": ["cs.LG", "cs.HC", "math.OC", "stat.ML"], "comment": null, "summary": "The United States Food and Drug Administration's (FDA's) Premarket\nNotification 510(k) pathway allows manufacturers to gain approval for a medical\ndevice by demonstrating its substantial equivalence to another legally marketed\ndevice. However, the inherent ambiguity of this regulatory procedure has led to\nhigh recall rates for many devices cleared through this pathway. This trend has\nraised significant concerns regarding the efficacy of the FDA's current\napproach, prompting a reassessment of the 510(k) regulatory framework. In this\npaper, we develop a combined human-algorithm approach to assist the FDA in\nimproving its 510(k) medical device clearance process by reducing the risk of\nrecalls and the workload imposed on the FDA. We first develop machine learning\nmethods to estimate the risk of recall of 510(k) medical devices based on the\ninformation available at submission time. We then propose a data-driven\nclearance policy that recommends acceptance, rejection, or deferral to FDA's\ncommittees for in-depth evaluation. We conduct an empirical study using a\nunique large-scale dataset of over 31,000 medical devices that we assembled\nbased on data sources from the FDA and Centers for Medicare and Medicaid\nService (CMS). A conservative evaluation of our proposed policy based on this\ndata shows a 32.9% improvement in the recall rate and a 40.5% reduction in the\nFDA's workload. Our analyses also indicate that implementing our policy could\nresult in significant annual cost savings of $1.7 billion, which highlights the\nvalue of using a holistic and data-driven approach to improve the FDA's current\n510(k) medical device evaluation pathway.", "AI": {"tldr": "A combined human-algorithm approach improves the FDA's 510(k) medical device clearance process, reducing recalls by 32.9% and workload by 40.5%, with potential annual savings of $1.7B.", "motivation": "High recall rates due to ambiguity in the FDA's 510(k) pathway prompt a need for a more effective regulatory framework.", "method": "Machine learning estimates recall risk; a data-driven policy recommends acceptance, rejection, or deferral. Empirical study uses 31,000+ device records from FDA and CMS.", "result": "32.9% reduction in recall rate, 40.5% workload reduction, and $1.7B annual cost savings.", "conclusion": "A data-driven approach significantly enhances the FDA's 510(k) pathway, reducing risks and costs."}}
{"id": "2503.23101", "pdf": "https://arxiv.org/pdf/2503.23101", "abs": "https://arxiv.org/abs/2503.23101", "authors": ["Enrico Marchesini", "Benjamin Donnot", "Constance Crozier", "Ian Dytham", "Christian Merz", "Lars Schewe", "Nico Westerbeck", "Cathy Wu", "Antoine Marot", "Priya L. Donti"], "title": "RL2Grid: Benchmarking Reinforcement Learning in Power Grid Operations", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Reinforcement learning (RL) can provide adaptive and scalable controllers\nessential for power grid decarbonization. However, RL methods struggle with\npower grids' complex dynamics, long-horizon goals, and hard physical\nconstraints. For these reasons, we present RL2Grid, a benchmark designed in\ncollaboration with power system operators to accelerate progress in grid\ncontrol and foster RL maturity. Built on RTE France's power simulation\nframework, RL2Grid standardizes tasks, state and action spaces, and reward\nstructures for a systematic evaluation and comparison of RL algorithms.\nMoreover, we integrate operational heuristics and design safety constraints\nbased on human expertise to ensure alignment with physical requirements. By\nestablishing reference performance metrics for classic RL baselines on\nRL2Grid's tasks, we highlight the need for novel methods capable of handling\nreal systems and discuss future directions for RL-based grid control.", "AI": {"tldr": "RL2Grid is a benchmark for RL in power grid control, addressing complex dynamics and constraints, with standardized tasks and safety measures.", "motivation": "Power grid decarbonization requires adaptive RL controllers, but current methods struggle with grid complexities.", "method": "RL2Grid, built on RTE France's framework, standardizes tasks, states, actions, and rewards, integrating operational heuristics and safety constraints.", "result": "Reference metrics for RL baselines show the need for novel methods to handle real grid systems.", "conclusion": "RL2Grid fosters RL maturity for grid control and highlights future research directions."}}
{"id": "2506.12190", "pdf": "https://arxiv.org/pdf/2506.12190", "abs": "https://arxiv.org/abs/2506.12190", "authors": ["Naomi Fridman", "Bubby Solway", "Tomer Fridman", "Itamar Barnea", "Anat Goldstein"], "title": "BreastDCEDL: Curating a Comprehensive DCE-MRI Dataset and developing a Transformer Implementation for Breast Cancer Treatment Response Prediction", "categories": ["cs.CV", "cs.AI", "68T07, 68U10, 92C55", "I.2.0; I.2.10; I.4.5; J.3"], "comment": null, "summary": "Breast cancer remains a leading cause of cancer-related mortality worldwide,\nmaking early detection and accurate treatment response monitoring critical\npriorities. We present BreastDCEDL, a curated, deep learning-ready dataset\ncomprising pre-treatment 3D Dynamic Contrast-Enhanced MRI (DCE-MRI) scans from\n2,070 breast cancer patients drawn from the I-SPY1, I-SPY2, and Duke cohorts,\nall sourced from The Cancer Imaging Archive. The raw DICOM imaging data were\nrigorously converted into standardized 3D NIfTI volumes with preserved signal\nintegrity, accompanied by unified tumor annotations and harmonized clinical\nmetadata including pathologic complete response (pCR), hormone receptor (HR),\nand HER2 status. Although DCE-MRI provides essential diagnostic information and\ndeep learning offers tremendous potential for analyzing such complex data,\nprogress has been limited by lack of accessible, public, multicenter datasets.\nBreastDCEDL addresses this gap by enabling development of advanced models,\nincluding state-of-the-art transformer architectures that require substantial\ntraining data. To demonstrate its capacity for robust modeling, we developed\nthe first transformer-based model for breast DCE-MRI, leveraging Vision\nTransformer (ViT) architecture trained on RGB-fused images from three contrast\nphases (pre-contrast, early post-contrast, and late post-contrast). Our ViT\nmodel achieved state-of-the-art pCR prediction performance in HR+/HER2-\npatients (AUC 0.94, accuracy 0.93). BreastDCEDL includes predefined benchmark\nsplits, offering a framework for reproducible research and enabling clinically\nmeaningful modeling in breast cancer imaging.", "AI": {"tldr": "BreastDCEDL is a curated, deep learning-ready dataset of 3D DCE-MRI scans from 2,070 breast cancer patients, enabling advanced model development and achieving state-of-the-art pCR prediction performance.", "motivation": "Early detection and accurate treatment monitoring are critical for breast cancer, but progress is hindered by the lack of accessible, public, multicenter datasets.", "method": "The dataset includes standardized 3D NIfTI volumes with tumor annotations and harmonized clinical metadata. A Vision Transformer (ViT) model was trained on RGB-fused images from three contrast phases.", "result": "The ViT model achieved state-of-the-art pCR prediction performance (AUC 0.94, accuracy 0.93) in HR+/HER2- patients.", "conclusion": "BreastDCEDL addresses the data gap, supports reproducible research, and enables clinically meaningful modeling in breast cancer imaging."}}
{"id": "2408.00256", "pdf": "https://arxiv.org/pdf/2408.00256", "abs": "https://arxiv.org/abs/2408.00256", "authors": ["Xueying Gu", "Qiong Wu", "Pingyi Fan", "Qiang Fan"], "title": "Mobility-Aware Federated Self-supervised Learning in Vehicular Network", "categories": ["cs.LG", "cs.NI"], "comment": "This paper has been accepted by urban lifeline. The source code has\n  been released at: The source code has been released at:\n  https://github.com/qiongwu86/FLSimCo", "summary": "Federated Learning (FL) is an advanced distributed machine learning approach,\nthat protects the privacy of each vehicle by allowing the model to be trained\non multiple devices simultaneously without the need to upload all data to a\nroad side unit (RSU). This enables FL to handle scenarios with sensitive or\nwidely distributed data. However, in these fields, it is well known that the\nlabeling costs can be a significant expense, and models relying on labels are\nnot suitable for these rapidly evolving fields especially in vehicular\nnetworks, or mobile internet of things (MIoT), where new data emerges\nconstantly. To handle this issue, the self-supervised learning paves the way\nfor training without labels. Additionally, for vehicles with high velocity,\nowing to blurred images, simple aggregation not only impacts the accuracy of\nthe aggregated model but also reduces the convergence speed of FL. This paper\nproposes a FL algorithm based on image blur level to aggregation, called\nFLSimCo, which does not require labels and serves as a pre-training stage for\nself-supervised learning in the vehicular environment. Simulation results\ndemonstrate that the proposed algorithm exhibits fast and stable convergence.", "AI": {"tldr": "FLSimCo is a federated learning algorithm for vehicular networks that uses image blur level for aggregation, eliminating the need for labels and improving convergence speed.", "motivation": "Addressing the high labeling costs and unsuitability of labeled models in rapidly evolving fields like vehicular networks and MIoT, while tackling issues of blurred images and slow convergence in FL.", "method": "Proposes FLSimCo, a label-free FL algorithm that aggregates based on image blur level, serving as a pre-training stage for self-supervised learning.", "result": "Simulation results show FLSimCo achieves fast and stable convergence.", "conclusion": "FLSimCo effectively addresses challenges in FL for vehicular networks, offering a practical solution for label-free, efficient model training."}}
{"id": "2504.07717", "pdf": "https://arxiv.org/pdf/2504.07717", "abs": "https://arxiv.org/abs/2504.07717", "authors": ["Yang Jiao", "Xiaodong Wang", "Kai Yang"], "title": "PR-Attack: Coordinated Prompt-RAG Attacks on Retrieval-Augmented Generation in Large Language Models via Bilevel Optimization", "categories": ["cs.CR", "cs.AI"], "comment": "Accepted at SIGIR 2025", "summary": "Large Language Models (LLMs) have demonstrated remarkable performance across\na wide range of applications, e.g., medical question-answering, mathematical\nsciences, and code generation. However, they also exhibit inherent limitations,\nsuch as outdated knowledge and susceptibility to hallucinations.\nRetrieval-Augmented Generation (RAG) has emerged as a promising paradigm to\naddress these issues, but it also introduces new vulnerabilities. Recent\nefforts have focused on the security of RAG-based LLMs, yet existing attack\nmethods face three critical challenges: (1) their effectiveness declines\nsharply when only a limited number of poisoned texts can be injected into the\nknowledge database, (2) they lack sufficient stealth, as the attacks are often\ndetectable by anomaly detection systems, which compromises their effectiveness,\nand (3) they rely on heuristic approaches to generate poisoned texts, lacking\nformal optimization frameworks and theoretic guarantees, which limits their\neffectiveness and applicability. To address these issues, we propose\ncoordinated Prompt-RAG attack (PR-attack), a novel optimization-driven attack\nthat introduces a small number of poisoned texts into the knowledge database\nwhile embedding a backdoor trigger within the prompt. When activated, the\ntrigger causes the LLM to generate pre-designed responses to targeted queries,\nwhile maintaining normal behavior in other contexts. This ensures both high\neffectiveness and stealth. We formulate the attack generation process as a\nbilevel optimization problem leveraging a principled optimization framework to\ndevelop optimal poisoned texts and triggers. Extensive experiments across\ndiverse LLMs and datasets demonstrate the effectiveness of PR-Attack, achieving\na high attack success rate even with a limited number of poisoned texts and\nsignificantly improved stealth compared to existing methods.", "AI": {"tldr": "The paper introduces PR-Attack, an optimization-driven method to exploit vulnerabilities in RAG-based LLMs by injecting poisoned texts and embedding triggers in prompts, ensuring high effectiveness and stealth.", "motivation": "To address the limitations of existing attack methods on RAG-based LLMs, which lack effectiveness with limited poisoned texts, stealth, and formal optimization frameworks.", "method": "Proposes PR-Attack, a bilevel optimization framework to generate poisoned texts and backdoor triggers, ensuring targeted LLM responses while maintaining normal behavior otherwise.", "result": "PR-Attack achieves high success rates with limited poisoned texts and improved stealth compared to existing methods, validated across diverse LLMs and datasets.", "conclusion": "PR-Attack effectively addresses the challenges of existing attacks, offering a robust and stealthy method to exploit RAG-based LLMs."}}
{"id": "2506.12400", "pdf": "https://arxiv.org/pdf/2506.12400", "abs": "https://arxiv.org/abs/2506.12400", "authors": ["Hongbi Zhou", "Zhangkai Ni"], "title": "Perceptual-GS: Scene-adaptive Perceptual Densification for Gaussian Splatting", "categories": ["cs.CV"], "comment": "Accepted to International Conference on Machine Learning (ICML) 2025", "summary": "3D Gaussian Splatting (3DGS) has emerged as a powerful technique for novel\nview synthesis. However, existing methods struggle to adaptively optimize the\ndistribution of Gaussian primitives based on scene characteristics, making it\nchallenging to balance reconstruction quality and efficiency. Inspired by human\nperception, we propose scene-adaptive perceptual densification for Gaussian\nSplatting (Perceptual-GS), a novel framework that integrates perceptual\nsensitivity into the 3DGS training process to address this challenge. We first\nintroduce a perception-aware representation that models human visual\nsensitivity while constraining the number of Gaussian primitives. Building on\nthis foundation, we develop a perceptual sensitivity-adaptive distribution to\nallocate finer Gaussian granularity to visually critical regions, enhancing\nreconstruction quality and robustness. Extensive evaluations on multiple\ndatasets, including BungeeNeRF for large-scale scenes, demonstrate that\nPerceptual-GS achieves state-of-the-art performance in reconstruction quality,\nefficiency, and robustness. The code is publicly available at:\nhttps://github.com/eezkni/Perceptual-GS", "AI": {"tldr": "Perceptual-GS improves 3D Gaussian Splatting by adaptively optimizing Gaussian primitives based on human perception, enhancing quality and efficiency.", "motivation": "Existing 3DGS methods lack adaptive optimization for Gaussian distribution, hindering balance between quality and efficiency.", "method": "Introduces perception-aware representation and perceptual sensitivity-adaptive distribution to allocate finer granularity to critical regions.", "result": "Achieves state-of-the-art performance in reconstruction quality, efficiency, and robustness on multiple datasets.", "conclusion": "Perceptual-GS effectively integrates perceptual sensitivity into 3DGS, improving adaptive optimization and performance."}}
{"id": "2408.14831", "pdf": "https://arxiv.org/pdf/2408.14831", "abs": "https://arxiv.org/abs/2408.14831", "authors": ["Xueying Gu", "Qiong Wu", "Pingyi Fan", "Nan Cheng", "Wen Chen", "Khaled B. Letaief"], "title": "DRL-Based Federated Self-Supervised Learning for Task Offloading and Resource Allocation in ISAC-Enabled Vehicle Edge Computing", "categories": ["cs.LG", "cs.DC", "cs.NI"], "comment": "This paper has been accepted by Digital Communications and Networks.\n  The source code has been released at:\n  https://github.com/qiongwu86/Federated-SSL-task-offloading-and-resource-allocation", "summary": "Intelligent Transportation Systems (ITS) leverage Integrated Sensing and\nCommunications (ISAC) to enhance data exchange between vehicles and\ninfrastructure in the Internet of Vehicles (IoV). This integration inevitably\nincreases computing demands, risking real-time system stability. Vehicle Edge\nComputing (VEC) addresses this by offloading tasks to Road Side Unit (RSU),\nensuring timely services. Our previous work FLSimCo algorithm, which uses local\nresources for Federated Self-Supervised Learning (SSL), though vehicles often\ncan't complete all iterations task. Our improved algorithm offloads partial\ntask to RSU and optimizes energy consumption by adjusting transmission power,\nCPU frequency, and task assignment ratios, balancing local and RSU-based\ntraining. Meanwhile, setting an offloading threshold further prevents\ninefficiencies. Simulation results show that the enhanced algorithm reduces\nenergy consumption, improves offloading efficiency and the accuracy of\nFederated SSL.", "AI": {"tldr": "An improved algorithm for Federated Self-Supervised Learning in Vehicle Edge Computing reduces energy use and boosts efficiency by offloading tasks to RSUs.", "motivation": "The integration of ISAC in ITS increases computing demands, risking real-time stability. Existing methods like FLSimCo struggle with incomplete tasks.", "method": "The enhanced algorithm offloads partial tasks to RSUs, optimizes energy by adjusting transmission power, CPU frequency, and task ratios, and sets an offloading threshold.", "result": "Simulations show reduced energy consumption, better offloading efficiency, and higher Federated SSL accuracy.", "conclusion": "The improved algorithm effectively balances local and RSU-based training, enhancing system performance."}}
{"id": "2504.11264", "pdf": "https://arxiv.org/pdf/2504.11264", "abs": "https://arxiv.org/abs/2504.11264", "authors": ["Ruochi Zhang", "Qian Yang", "Xiaoyang Wang", "Tian Wang", "Qiong Zhou", "Ziqi Deng", "Kewei Li", "Yueying Wang", "Yusi Fan", "Jiale Zhang", "Lan Huang", "Chang Liu", "Fengfeng Zhou"], "title": "DeepSelective: Interpretable Prognosis Prediction via Feature Selection and Compression in EHR Data", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "The rapid accumulation of Electronic Health Records (EHRs) has transformed\nhealthcare by providing valuable data that enhance clinical predictions and\ndiagnoses. While conventional machine learning models have proven effective,\nthey often lack robust representation learning and depend heavily on\nexpert-crafted features. Although deep learning offers powerful solutions, it\nis often criticized for its lack of interpretability. To address these\nchallenges, we propose DeepSelective, a novel end to end deep learning\nframework for predicting patient prognosis using EHR data, with a strong\nemphasis on enhancing model interpretability. DeepSelective combines data\ncompression techniques with an innovative feature selection approach,\nintegrating custom-designed modules that work together to improve both accuracy\nand interpretability. Our experiments demonstrate that DeepSelective not only\nenhances predictive accuracy but also significantly improves interpretability,\nmaking it a valuable tool for clinical decision-making. The source code is\nfreely available at http://www.healthinformaticslab.org/supp/resources.php .", "AI": {"tldr": "DeepSelective is a deep learning framework for EHR-based prognosis prediction, improving accuracy and interpretability.", "motivation": "Addressing limitations of conventional ML (lack of robust representation learning) and deep learning (interpretability issues) in EHR analysis.", "method": "Combines data compression and innovative feature selection with custom modules for accuracy and interpretability.", "result": "Enhances predictive accuracy and significantly improves interpretability.", "conclusion": "DeepSelective is a valuable tool for clinical decision-making, with publicly available source code."}}
{"id": "2506.12456", "pdf": "https://arxiv.org/pdf/2506.12456", "abs": "https://arxiv.org/abs/2506.12456", "authors": ["Eugene Kofi Okrah Denteh", "Andrews Danyo", "Joshua Kofi Asamoah", "Blessing Agyei Kyem", "Armstrong Aboah"], "title": "Demographics-Informed Neural Network for Multi-Modal Spatiotemporal forecasting of Urban Growth and Travel Patterns Using Satellite Imagery", "categories": ["cs.CV"], "comment": null, "summary": "This study presents a novel demographics informed deep learning framework\ndesigned to forecast urban spatial transformations by jointly modeling\ngeographic satellite imagery, socio-demographics, and travel behavior dynamics.\nThe proposed model employs an encoder-decoder architecture with temporal gated\nresidual connections, integrating satellite imagery and demographic data to\naccurately forecast future spatial transformations. The study also introduces a\ndemographics prediction component which ensures that predicted satellite\nimagery are consistent with demographic features, significantly enhancing\nphysiological realism and socioeconomic accuracy. The framework is enhanced by\na proposed multi-objective loss function complemented by a semantic loss\nfunction that balances visual realism with temporal coherence. The experimental\nresults from this study demonstrate the superior performance of the proposed\nmodel compared to state-of-the-art models, achieving higher structural\nsimilarity (SSIM: 0.8342) and significantly improved demographic consistency\n(Demo-loss: 0.14 versus 0.95 and 0.96 for baseline models). Additionally, the\nstudy validates co-evolutionary theories of urban development, demonstrating\nquantifiable bidirectional influences between built environment characteristics\nand population patterns. The study also contributes a comprehensive multimodal\ndataset pairing satellite imagery sequences (2012-2023) with corresponding\ndemographic and travel behavior attributes, addressing existing gaps in urban\nand transportation planning resources by explicitly connecting physical\nlandscape evolution with socio-demographic patterns.", "AI": {"tldr": "A demographics-informed deep learning framework forecasts urban spatial transformations by integrating satellite imagery, socio-demographics, and travel behavior, outperforming state-of-the-art models in accuracy and realism.", "motivation": "To address the gap in urban planning by forecasting spatial transformations with physiological and socioeconomic accuracy, connecting physical landscape evolution with demographic patterns.", "method": "Uses an encoder-decoder architecture with temporal gated residual connections, integrating satellite and demographic data, and employs a multi-objective loss function for visual and temporal coherence.", "result": "Achieves higher structural similarity (SSIM: 0.8342) and demographic consistency (Demo-loss: 0.14 vs. 0.95/0.96), validating co-evolutionary urban development theories.", "conclusion": "The framework enhances urban forecasting accuracy and realism, contributing a multimodal dataset for urban and transportation planning."}}
{"id": "2409.11884", "pdf": "https://arxiv.org/pdf/2409.11884", "abs": "https://arxiv.org/abs/2409.11884", "authors": ["Shuo Lu", "Yingsheng Wang", "Lijun Sheng", "Lingxiao He", "Aihua Zheng", "Jian Liang"], "title": "Out-of-Distribution Detection: A Task-Oriented Survey of Recent Advances", "categories": ["cs.LG"], "comment": "First Submitted in May 2024", "summary": "Out-of-distribution (OOD) detection aims to detect test samples outside the\ntraining category space, which is an essential component in building reliable\nmachine learning systems. Existing reviews on OOD detection primarily focus on\nmethod taxonomy, surveying the field by categorizing various approaches.\nHowever, many recent works concentrate on non-traditional OOD detection\nscenarios, such as test-time adaptation, multi-modal data sources and other\nnovel contexts. In this survey, we uniquely review recent advances in OOD\ndetection from the task-oriented perspective for the first time. According to\nthe user's access to the model, that is, whether the OOD detection method is\nallowed to modify or retrain the model, we classify the methods as\ntraining-driven or training-agnostic. Besides, considering the rapid\ndevelopment of pre-trained models, large pre-trained model-based OOD detection\nis also regarded as an important category and discussed separately.\nFurthermore, we provide a discussion of the evaluation scenarios, a variety of\napplications, and several future research directions. We believe this survey\nwith new taxonomy will benefit the proposal of new methods and the expansion of\nmore practical scenarios. A curated list of related papers is provided in the\nGithub repository:\nhttps://github.com/shuolucs/Awesome-Out-Of-Distribution-Detection.", "AI": {"tldr": "A survey on OOD detection focusing on task-oriented taxonomy, classifying methods as training-driven or training-agnostic, and highlighting pre-trained models.", "motivation": "To address gaps in existing reviews by focusing on non-traditional OOD scenarios and providing a new taxonomy.", "method": "Classifies OOD detection methods based on user access to the model (training-driven vs. training-agnostic) and discusses pre-trained models.", "result": "A new taxonomy, evaluation scenarios, applications, and future research directions are presented.", "conclusion": "The survey aims to inspire new methods and practical applications, with a curated list of papers provided."}}
{"id": "2505.05625", "pdf": "https://arxiv.org/pdf/2505.05625", "abs": "https://arxiv.org/abs/2505.05625", "authors": ["Wenqing Peng", "Zhi-Song Liu", "Michael Boy"], "title": "SPIN-ODE: Stiff Physics-Informed Neural ODE for Chemical Reaction Rate Estimation", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Estimating rate coefficients from complex chemical reactions is essential for\nadvancing detailed chemistry. However, the stiffness inherent in real-world\natmospheric chemistry systems poses severe challenges, leading to training\ninstability and poor convergence that hinder effective rate coefficient\nestimation using learning-based approaches. To address this, we propose a Stiff\nPhysics-Informed Neural ODE framework (SPIN-ODE) for chemical reaction\nmodelling. Our method introduces a three-stage optimisation process: first, a\nlatent neural ODE learns the continuous and differentiable trajectory between\nchemical concentrations and their time derivatives; second, an explicit\nChemical Reaction Neural Network (CRNN) extracts the underlying rate\ncoefficients based on the learned dynamics; and third, fine-tune CRNN using a\nneural ODE solver to further improve rate coefficient estimation. Extensive\nexperiments on both synthetic and newly proposed real-world datasets validate\nthe effectiveness and robustness of our approach. As the first work on stiff\nNeural ODEs for chemical rate coefficient discovery, our study opens promising\ndirections for integrating neural networks with detailed chemistry.", "AI": {"tldr": "The paper proposes SPIN-ODE, a three-stage neural framework to estimate rate coefficients in stiff chemical reactions, improving stability and convergence.", "motivation": "Stiffness in atmospheric chemistry systems causes training instability and poor convergence, hindering rate coefficient estimation with learning-based methods.", "method": "SPIN-ODE uses a latent neural ODE, a Chemical Reaction Neural Network (CRNN), and fine-tuning with a neural ODE solver to model reactions and extract rate coefficients.", "result": "Experiments on synthetic and real-world datasets show SPIN-ODE's effectiveness and robustness.", "conclusion": "SPIN-ODE pioneers stiff Neural ODEs for chemical rate coefficient discovery, advancing neural network integration with detailed chemistry."}}
{"id": "2506.12515", "pdf": "https://arxiv.org/pdf/2506.12515", "abs": "https://arxiv.org/abs/2506.12515", "authors": ["Bingchen Zhao", "Kai Han"], "title": "Generalized Category Discovery under the Long-Tailed Distribution", "categories": ["cs.CV"], "comment": null, "summary": "This paper addresses the problem of Generalized Category Discovery (GCD)\nunder a long-tailed distribution, which involves discovering novel categories\nin an unlabelled dataset using knowledge from a set of labelled categories.\nExisting works assume a uniform distribution for both datasets, but real-world\ndata often exhibits a long-tailed distribution, where a few categories contain\nmost examples, while others have only a few. While the long-tailed distribution\nis well-studied in supervised and semi-supervised settings, it remains\nunexplored in the GCD context. We identify two challenges in this setting -\nbalancing classifier learning and estimating category numbers - and propose a\nframework based on confident sample selection and density-based clustering to\ntackle them. Our experiments on both long-tailed and conventional GCD datasets\ndemonstrate the effectiveness of our method.", "AI": {"tldr": "The paper tackles Generalized Category Discovery (GCD) under long-tailed distributions, proposing a framework for discovering novel categories in unlabelled data using labelled knowledge.", "motivation": "Real-world data often follows a long-tailed distribution, but existing GCD works assume uniform distributions, leaving a gap in research.", "method": "The proposed framework uses confident sample selection and density-based clustering to address challenges like classifier learning and category number estimation.", "result": "Experiments show the method's effectiveness on both long-tailed and conventional GCD datasets.", "conclusion": "The study successfully addresses GCD under long-tailed distributions, offering a practical solution for real-world data."}}
{"id": "2409.17264", "pdf": "https://arxiv.org/pdf/2409.17264", "abs": "https://arxiv.org/abs/2409.17264", "authors": ["Amey Agrawal", "Haoran Qiu", "Junda Chen", "\u00cd\u00f1igo Goiri", "Chaojie Zhang", "Rayyan Shahid", "Ramachandran Ramjee", "Alexey Tumanov", "Esha Choukse"], "title": "Medha: Efficiently Serving Multi-Million Context Length LLM Inference Requests Without Approximations", "categories": ["cs.LG", "cs.DC"], "comment": null, "summary": "As large language models (LLMs) handle increasingly longer contexts, serving\nlong inference requests of millions of tokens presents unique challenges. We\nshow that existing work for long context inference is largely based on\ntechniques from long context training, and does not handle the high variability\nin input lengths during inference. This leads to inefficient resource\nutilization, server fragmentation, and head-of-line (HOL) blocking.\n  We present Medha, an end-to-end system for efficient long-context LLM\ninference that addresses these challenges through fine-grained time sharing.\nMedha introduces three key innovations: (1) the mechanism of adaptive prefill\nchunking to help mitigate HOL blocking with preemption; (2) two new parallelism\nstrategies: Sequence Pipeline Parallelism (SPP) to reduce time-to-first-token\nby pipelining prefill chunks, and KV-Cache Parallelism (KVP) to lower\ntime-peroutput-token by distributing decoding across servers; and (3) a novel\ninput-length aware least remaining slack scheduling to meet Service Level\nObjectives (SLOs).\n  Medha enables exact inference scaling beyond 10 million tokens, maintaining\nhigh throughput and low latency across mixed-length workloads. Compared to\nstate-of-the-art systems, Medha reduces server fragmentation, cuts median\nlatency by up to 30x, and improves throughput by over 5x, delivering\nproduction-scale long-context inference without compromising performance on\nshorter requests.", "AI": {"tldr": "Medha is a system for efficient long-context LLM inference, addressing challenges like HOL blocking and resource inefficiency through adaptive prefill chunking, novel parallelism strategies, and smart scheduling.", "motivation": "Existing methods for long-context inference are inefficient due to high input length variability, leading to resource waste and performance issues.", "method": "Medha introduces adaptive prefill chunking, Sequence Pipeline Parallelism (SPP), KV-Cache Parallelism (KVP), and input-length aware scheduling.", "result": "Medha scales beyond 10M tokens, reduces latency by 30x, and improves throughput by 5x compared to state-of-the-art systems.", "conclusion": "Medha enables high-performance, production-scale long-context inference while maintaining efficiency for shorter requests."}}
{"id": "2505.06085", "pdf": "https://arxiv.org/pdf/2505.06085", "abs": "https://arxiv.org/abs/2505.06085", "authors": ["Hiari Pizzini Cavagna", "Daniele Cesarini", "Andrea Bartolini"], "title": "Assessing Tenstorrent's RISC-V MatMul Acceleration Capabilities", "categories": ["cs.PF", "cs.AI", "cs.AR"], "comment": "Accepted to the Computational Aspects of Deep Learning Workshop at\n  ISC High Performance 2025. To appear in the ISC High Performance 2025\n  Workshop Proceedings", "summary": "The increasing demand for generative AI as Large Language Models (LLMs)\nservices has driven the need for specialized hardware architectures that\noptimize computational efficiency and energy consumption. This paper evaluates\nthe performance of the Tenstorrent Grayskull e75 RISC-V accelerator for basic\nlinear algebra kernels at reduced numerical precision, a fundamental operation\nin LLM computations. We present a detailed characterization of Grayskull's\nexecution model, gridsize, matrix dimensions, data formats, and numerical\nprecision impact computational efficiency. Furthermore, we compare Grayskull's\nperformance against state-of-the-art architectures with tensor acceleration,\nincluding Intel Sapphire Rapids processors and two NVIDIA GPUs (V100 and A100).\nWhilst NVIDIA GPUs dominate raw performance, Grayskull demonstrates a\ncompetitive trade-off between power consumption and computational throughput,\nreaching a peak of 1.55 TFLOPs/Watt with BF16.", "AI": {"tldr": "The paper evaluates the Tenstorrent Grayskull e75 RISC-V accelerator for LLM computations, comparing its efficiency and power consumption against Intel Sapphire Rapids and NVIDIA GPUs.", "motivation": "The demand for efficient hardware for generative AI and LLMs drives the need to evaluate specialized accelerators like Grayskull.", "method": "The study analyzes Grayskull's performance for linear algebra kernels at reduced precision, examining execution model, gridsize, matrix dimensions, and data formats.", "result": "Grayskull shows a competitive balance between power and throughput (1.55 TFLOPs/Watt with BF16), though NVIDIA GPUs outperform in raw performance.", "conclusion": "Grayskull is a viable option for LLM computations due to its efficiency-power trade-off, despite not leading in raw performance."}}
{"id": "2506.12723", "pdf": "https://arxiv.org/pdf/2506.12723", "abs": "https://arxiv.org/abs/2506.12723", "authors": ["Ye Li", "Yuan Meng", "Zewen Sun", "Kangye Ji", "Chen Tang", "Jiajun Fan", "Xinzhu Ma", "Shutao Xia", "Zhi Wang", "Wenwu Zhu"], "title": "SP-VLA: A Joint Model Scheduling and Token Pruning Approach for VLA Model Acceleration", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Vision-Language-Action (VLA) models have attracted increasing attention for\ntheir strong control capabilities. However, their high computational cost and\nlow execution frequency hinder their suitability for real-time tasks such as\nrobotic manipulation and autonomous navigation. Existing VLA acceleration\nmethods primarily focus on structural optimization, overlooking the fact that\nthese models operate in sequential decision-making environments. As a result,\ntemporal redundancy in sequential action generation and spatial redundancy in\nvisual input remain unaddressed. To this end, we propose SP-VLA, a unified\nframework that accelerates VLA models by jointly scheduling models and pruning\ntokens. Specifically, we design an action-aware model scheduling mechanism that\nreduces temporal redundancy by dynamically switching between VLA model and a\nlightweight generator. Inspired by the human motion pattern of focusing on key\ndecision points while relying on intuition for other actions, we categorize VLA\nactions into deliberative and intuitive, assigning the former to the VLA model\nand the latter to the lightweight generator, enabling frequency-adaptive\nexecution through collaborative model scheduling. To address spatial\nredundancy, we further develop a spatio-semantic dual-aware token pruning\nmethod. Tokens are classified into spatial and semantic types and pruned based\non their dual-aware importance to accelerate VLA inference. These two\nmechanisms work jointly to guide the VLA in focusing on critical actions and\nsalient visual information, achieving effective acceleration while maintaining\nhigh accuracy. Experimental results demonstrate that our method achieves up to\n1.5$\\times$ acceleration with less than 3% drop in accuracy, outperforming\nexisting approaches in multiple tasks.", "AI": {"tldr": "SP-VLA accelerates Vision-Language-Action models by reducing temporal and spatial redundancies through model scheduling and token pruning, achieving 1.5x speedup with minimal accuracy loss.", "motivation": "Existing VLA models suffer from high computational costs and low execution frequency, making them unsuitable for real-time tasks like robotic manipulation. Current acceleration methods focus on structural optimization but ignore temporal and spatial redundancies.", "method": "SP-VLA introduces action-aware model scheduling (switching between VLA and lightweight generator) and spatio-semantic token pruning to reduce redundancies. Actions are categorized as deliberative (VLA) or intuitive (lightweight generator).", "result": "The method achieves up to 1.5x acceleration with less than 3% accuracy drop, outperforming existing approaches in multiple tasks.", "conclusion": "SP-VLA effectively balances speed and accuracy by addressing temporal and spatial redundancies, making VLA models more suitable for real-time applications."}}
{"id": "2410.02601", "pdf": "https://arxiv.org/pdf/2410.02601", "abs": "https://arxiv.org/abs/2410.02601", "authors": ["Sergei Kholkin", "Grigoriy Ksenofontov", "David Li", "Nikita Kornilov", "Nikita Gushchin", "Alexandra Suvorikova", "Alexey Kroshnin", "Evgeny Burnaev", "Alexander Korotin"], "title": "Diffusion & Adversarial Schr\u00f6dinger Bridges via Iterative Proportional Markovian Fitting", "categories": ["cs.LG"], "comment": null, "summary": "The Iterative Markovian Fitting (IMF) procedure, which iteratively projects\nonto the space of Markov processes and the reciprocal class, successfully\nsolves the Schr\\\"odinger Bridge (SB) problem. However, an efficient practical\nimplementation requires a heuristic modification - alternating between fitting\nforward and backward time diffusion at each iteration. This modification is\ncrucial for stabilizing training and achieving reliable results in applications\nsuch as unpaired domain translation. Our work reveals a close connection\nbetween the modified version of IMF and the Iterative Proportional Fitting\n(IPF) procedure - a foundational method for the SB problem, also known as\nSinkhorn's algorithm. Specifically, we demonstrate that the heuristic\nmodification of the IMF effectively integrates both IMF and IPF procedures. We\nrefer to this combined approach as the Iterative Proportional Markovian Fitting\n(IPMF) procedure. Through theoretical and empirical analysis, we establish the\nconvergence of IPMF procedure under various settings, contributing to\ndeveloping a unified framework for solving SB problems. Moreover, from a\npractical standpoint, the IPMF procedure enables a flexible trade-off between\nimage similarity and generation quality, offering a new mechanism for tailoring\nmodels to specific tasks.", "AI": {"tldr": "The paper introduces the Iterative Proportional Markovian Fitting (IPMF) procedure, combining IMF and IPF for solving the Schr\u00f6dinger Bridge problem, with practical benefits in tasks like domain translation.", "motivation": "To address the instability and inefficiency of the IMF procedure in solving the Schr\u00f6dinger Bridge problem by integrating it with the IPF procedure.", "method": "Proposes IPMF, a heuristic modification alternating between forward and backward time diffusion, combining IMF and IPF.", "result": "Theoretical and empirical analysis confirms IPMF's convergence and practical advantages, such as flexible trade-offs in image tasks.", "conclusion": "IPMF provides a unified, stable framework for SB problems, enhancing task-specific model customization."}}
{"id": "2505.06331", "pdf": "https://arxiv.org/pdf/2505.06331", "abs": "https://arxiv.org/abs/2505.06331", "authors": ["Feilong Jiang", "Xiaonan Hou", "Jianqiao Ye", "Min Xia"], "title": "Mask-PINNs: Regulating Feature Distributions in Physics-Informed Neural Networks", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Physics-Informed Neural Networks (PINNs) have emerged as a powerful framework\nfor solving partial differential equations (PDEs) by embedding physical laws\ndirectly into the loss function. However, effective training of PINNs remains\nchallenging due to internal covariate shift, which destabilizes feature\ndistributions and impairs model expressiveness. While normalization techniques\nlike Batch Normalization and Layer Normalization are standard remedies in deep\nlearning, they disrupt the pointwise input-output mappings critical to\npreserving the physical consistency in PINNs. In this work, we introduce\nMask-PINNs, a novel architecture that regulates internal feature distributions\nthrough a smooth, learnable mask function applied pointwise across hidden\nlayers. Unlike conventional normalization methods, the proposed mask function\npreserves the deterministic nature of input-output relationships while\nsuppressing activation drift and saturation. Theoretically, we demonstrate that\nMask-PINNs control feature spread near initialization by attenuating gradient\nvariance growth through a tailored modulation mechanism. Empirically, we\nvalidate the method on multiple PDE benchmarks across diverse activation\nfunctions. Our results show consistent improvements in prediction accuracy,\nconvergence stability, and robustness, with relative L2 errors reduced by up to\ntwo orders of magnitude over baseline models. Furthermore, we demonstrate that\nMask-PINNs enable the effective use of wider networks, overcoming a key\nlimitation in existing PINN frameworks.", "AI": {"tldr": "Mask-PINNs introduce a learnable mask function to stabilize PINN training by preserving physical consistency while improving accuracy and robustness.", "motivation": "Addressing the challenge of internal covariate shift in PINNs, which disrupts feature distributions and physical consistency, without relying on conventional normalization methods.", "method": "Proposes Mask-PINNs, a novel architecture using a smooth, learnable mask function applied pointwise across hidden layers to regulate feature distributions while preserving input-output mappings.", "result": "Demonstrates improved prediction accuracy, convergence stability, and robustness, reducing relative L2 errors by up to two orders of magnitude and enabling wider networks.", "conclusion": "Mask-PINNs offer a promising solution to stabilize PINN training, enhancing performance and scalability while maintaining physical consistency."}}
{"id": "2506.13496", "pdf": "https://arxiv.org/pdf/2506.13496", "abs": "https://arxiv.org/abs/2506.13496", "authors": ["Kshitij Kavimandan", "Angelos Nalmpantis", "Emma Beauxis-Aussalet", "Robert-Jan Sips"], "title": "Hierarchical Multi-Positive Contrastive Learning for Patent Image Retrieval", "categories": ["cs.CV", "cs.IR", "cs.LG", "68T45, 68T07", "H.3.3; I.4.10; I.2.10"], "comment": "5 pages, 3 figures, Accepted as a short paper at the 6th Workshop on\n  Patent Text Mining and Semantic Technologies (PatentSemTech 2025), co-located\n  with SIGIR 2025", "summary": "Patent images are technical drawings that convey information about a patent's\ninnovation. Patent image retrieval systems aim to search in vast collections\nand retrieve the most relevant images. Despite recent advances in information\nretrieval, patent images still pose significant challenges due to their\ntechnical intricacies and complex semantic information, requiring efficient\nfine-tuning for domain adaptation. Current methods neglect patents'\nhierarchical relationships, such as those defined by the Locarno International\nClassification (LIC) system, which groups broad categories (e.g., \"furnishing\")\ninto subclasses (e.g., \"seats\" and \"beds\") and further into specific patent\ndesigns. In this work, we introduce a hierarchical multi-positive contrastive\nloss that leverages the LIC's taxonomy to induce such relations in the\nretrieval process. Our approach assigns multiple positive pairs to each patent\nimage within a batch, with varying similarity scores based on the hierarchical\ntaxonomy. Our experimental analysis with various vision and multimodal models\non the DeepPatent2 dataset shows that the proposed method enhances the\nretrieval results. Notably, our method is effective with low-parameter models,\nwhich require fewer computational resources and can be deployed on environments\nwith limited hardware.", "AI": {"tldr": "A hierarchical multi-positive contrastive loss method improves patent image retrieval by leveraging the Locarno International Classification (LIC) system's taxonomy, enhancing results even with low-parameter models.", "motivation": "Patent images are complex and current retrieval methods ignore hierarchical relationships like those in the LIC system, limiting accuracy.", "method": "Introduces a hierarchical multi-positive contrastive loss that uses LIC taxonomy to assign multiple positive pairs with varying similarity scores.", "result": "Experimental analysis on DeepPatent2 shows improved retrieval, especially with low-parameter models.", "conclusion": "The method effectively leverages hierarchical relationships for better patent image retrieval while being resource-efficient."}}
{"id": "2410.23693", "pdf": "https://arxiv.org/pdf/2410.23693", "abs": "https://arxiv.org/abs/2410.23693", "authors": ["Wenhan Chang", "Tianqing Zhu", "Ping Xiong", "Yufeng Wu", "Faqian Guan", "Wanlei Zhou"], "title": "Zero-shot Class Unlearning via Layer-wise Relevance Analysis and Neuronal Path Perturbation", "categories": ["cs.LG", "cs.CR"], "comment": "17 pages, 5 figures", "summary": "In the rapid advancement of artificial intelligence, privacy protection has\nbecome crucial, giving rise to machine unlearning. Machine unlearning is a\ntechnique that removes specific data influences from trained models without the\nneed for extensive retraining. However, it faces several key challenges,\nincluding accurately implementing unlearning, ensuring privacy protection\nduring the unlearning process, and achieving effective unlearning without\nsignificantly compromising model performance. This paper presents a novel\napproach to machine unlearning by employing Layer-wise Relevance Analysis and\nNeuronal Path Perturbation. We address three primary challenges: the lack of\ndetailed unlearning principles, privacy guarantees in zero-shot unlearning\nscenario, and the balance between unlearning effectiveness and model utility.\nOur method balances machine unlearning performance and model utility by\nidentifying and perturbing highly relevant neurons, thereby achieving effective\nunlearning. By using data not present in the original training set during the\nunlearning process, we satisfy the zero-shot unlearning scenario and ensure\nrobust privacy protection. Experimental results demonstrate that our approach\neffectively removes targeted data from the target unlearning model while\nmaintaining the model's utility, offering a practical solution for\nprivacy-preserving machine learning.", "AI": {"tldr": "A novel machine unlearning method using Layer-wise Relevance Analysis and Neuronal Path Perturbation addresses privacy and performance challenges, achieving effective unlearning without extensive retraining.", "motivation": "Privacy protection in AI necessitates machine unlearning, but existing methods struggle with accuracy, privacy, and performance trade-offs.", "method": "Employs Layer-wise Relevance Analysis and Neuronal Path Perturbation to identify and perturb relevant neurons, ensuring effective unlearning and privacy.", "result": "The method successfully removes targeted data while maintaining model utility, validated by experiments.", "conclusion": "The approach provides a practical, privacy-preserving solution for machine unlearning, balancing effectiveness and model performance."}}
{"id": "2505.07895", "pdf": "https://arxiv.org/pdf/2505.07895", "abs": "https://arxiv.org/abs/2505.07895", "authors": ["Jiafan Li", "Jiaqi Zhu", "Liang Chang", "Yilin Li", "Miaomiao Li", "Yang Wang", "Hongan Wang"], "title": "Representation Learning with Mutual Influence of Modalities for Node Classification in Multi-Modal Heterogeneous Networks", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Nowadays, numerous online platforms can be described as multi-modal\nheterogeneous networks (MMHNs), such as Douban's movie networks and Amazon's\nproduct review networks. Accurately categorizing nodes within these networks is\ncrucial for analyzing the corresponding entities, which requires effective\nrepresentation learning on nodes. However, existing multi-modal fusion methods\noften adopt either early fusion strategies which may lose the unique\ncharacteristics of individual modalities, or late fusion approaches overlooking\nthe cross-modal guidance in GNN-based information propagation. In this paper,\nwe propose a novel model for node classification in MMHNs, named Heterogeneous\nGraph Neural Network with Inter-Modal Attention (HGNN-IMA). It learns node\nrepresentations by capturing the mutual influence of multiple modalities during\nthe information propagation process, within the framework of heterogeneous\ngraph transformer. Specifically, a nested inter-modal attention mechanism is\nintegrated into the inter-node attention to achieve adaptive multi-modal\nfusion, and modality alignment is also taken into account to encourage the\npropagation among nodes with consistent similarities across all modalities.\nMoreover, an attention loss is augmented to mitigate the impact of missing\nmodalities. Extensive experiments validate the superiority of the model in the\nnode classification task, providing an innovative view to handle multi-modal\ndata, especially when accompanied with network structures.", "AI": {"tldr": "Proposes HGNN-IMA, a model for node classification in multi-modal heterogeneous networks, using inter-modal attention for adaptive fusion and modality alignment.", "motivation": "Existing multi-modal fusion methods either lose unique modality characteristics or overlook cross-modal guidance in GNN-based propagation.", "method": "HGNN-IMA integrates nested inter-modal attention into heterogeneous graph transformer for adaptive fusion and modality alignment, with an attention loss for missing modalities.", "result": "Extensive experiments show HGNN-IMA's superiority in node classification tasks.", "conclusion": "HGNN-IMA offers an innovative approach for multi-modal data with network structures, improving node classification."}}
{"id": "2506.13897", "pdf": "https://arxiv.org/pdf/2506.13897", "abs": "https://arxiv.org/abs/2506.13897", "authors": ["Thomas Kreutz", "Max M\u00fchlh\u00e4user", "Alejandro Sanchez Guinea"], "title": "DeSPITE: Exploring Contrastive Deep Skeleton-Pointcloud-IMU-Text Embeddings for Advanced Point Cloud Human Activity Understanding", "categories": ["cs.CV"], "comment": "This work is currently under review at ICCV 2025", "summary": "Despite LiDAR (Light Detection and Ranging) being an effective\nprivacy-preserving alternative to RGB cameras to perceive human activities, it\nremains largely underexplored in the context of multi-modal contrastive\npre-training for human activity understanding (e.g., human activity recognition\n(HAR), retrieval, or person re-identification (RE-ID)). To close this gap, our\nwork explores learning the correspondence between LiDAR point clouds, human\nskeleton poses, IMU data, and text in a joint embedding space. More\nspecifically, we present DeSPITE, a Deep Skeleton-Pointcloud-IMU-Text Embedding\nmodel, which effectively learns a joint embedding space across these four\nmodalities. At the heart of our empirical exploration, we have combined the\nexisting LIPD and Babel datasets, which enabled us to synchronize data of all\nfour modalities, allowing us to explore the learning of a new joint embedding\nspace. Our experiments demonstrate novel human activity understanding tasks for\npoint cloud sequences enabled through DeSPITE, including\nSkeleton<->Pointcloud<->IMU matching, retrieval, and temporal moment retrieval.\nFurthermore, we show that DeSPITE is an effective pre-training strategy for\npoint cloud HAR through experiments in MSR-Action3D and HMPEAR.", "AI": {"tldr": "DeSPITE introduces a multi-modal contrastive pre-training model for human activity understanding, combining LiDAR, skeleton poses, IMU data, and text in a joint embedding space.", "motivation": "To explore LiDAR's potential in multi-modal contrastive pre-training for human activity understanding, which is underexplored.", "method": "DeSPITE learns a joint embedding space across LiDAR point clouds, skeleton poses, IMU data, and text, using synchronized data from LIPD and Babel datasets.", "result": "Enables novel tasks like Skeleton<->Pointcloud<->IMU matching and retrieval, and improves point cloud HAR in MSR-Action3D and HMPEAR.", "conclusion": "DeSPITE effectively bridges the gap in multi-modal human activity understanding and serves as a strong pre-training strategy."}}
{"id": "2411.08590", "pdf": "https://arxiv.org/pdf/2411.08590", "abs": "https://arxiv.org/abs/2411.08590", "authors": ["Saul Santos", "Vlad Niculae", "Daniel McNamee", "Andr\u00e9 F. T. Martins"], "title": "Hopfield-Fenchel-Young Networks: A Unified Framework for Associative Memory Retrieval", "categories": ["cs.LG"], "comment": "49 pages, 14 figures. arXiv admin note: text overlap with\n  arXiv:2402.13725", "summary": "Associative memory models, such as Hopfield networks and their modern\nvariants, have garnered renewed interest due to advancements in memory capacity\nand connections with self-attention in transformers. In this work, we introduce\na unified framework-Hopfield-Fenchel-Young networks-which generalizes these\nmodels to a broader family of energy functions. Our energies are formulated as\nthe difference between two Fenchel-Young losses: one, parameterized by a\ngeneralized entropy, defines the Hopfield scoring mechanism, while the other\napplies a post-transformation to the Hopfield output. By utilizing Tsallis and\nnorm entropies, we derive end-to-end differentiable update rules that enable\nsparse transformations, uncovering new connections between loss margins,\nsparsity, and exact retrieval of single memory patterns. We further extend this\nframework to structured Hopfield networks using the SparseMAP transformation,\nallowing the retrieval of pattern associations rather than a single pattern.\nOur framework unifies and extends traditional and modern Hopfield networks and\nprovides an energy minimization perspective for widely used\npost-transformations like $\\ell_2$-normalization and layer normalization-all\nthrough suitable choices of Fenchel-Young losses and by using convex analysis\nas a building block. Finally, we validate our Hopfield-Fenchel-Young networks\non diverse memory recall tasks, including free and sequential recall.\nExperiments on simulated data, image retrieval, multiple instance learning, and\ntext rationalization demonstrate the effectiveness of our approach.", "AI": {"tldr": "The paper introduces Hopfield-Fenchel-Young networks, a unified framework generalizing associative memory models with energy functions based on Fenchel-Young losses, enabling sparse transformations and structured retrieval.", "motivation": "To generalize and unify associative memory models like Hopfield networks, leveraging advancements in memory capacity and connections with self-attention in transformers.", "method": "Proposes a framework using Fenchel-Young losses for energy functions, incorporating Tsallis and norm entropies for differentiable update rules and sparse transformations. Extends to structured networks with SparseMAP.", "result": "Derives connections between loss margins, sparsity, and exact retrieval. Validates effectiveness on memory recall tasks, image retrieval, and text rationalization.", "conclusion": "The framework unifies traditional and modern Hopfield networks, offering an energy minimization perspective for post-transformations and demonstrating practical utility."}}
{"id": "2505.13563", "pdf": "https://arxiv.org/pdf/2505.13563", "abs": "https://arxiv.org/abs/2505.13563", "authors": ["Xiaohui Wang", "Peng Ye", "Chenyu Huang", "Shenghe Zheng", "Bo Zhang", "Lei Bai", "Wanli Ouyang", "Tao Chen"], "title": "Breaking the Compression Ceiling: Data-Free Pipeline for Ultra-Efficient Delta Compression", "categories": ["cs.LG", "cs.AI", "cs.CV"], "comment": null, "summary": "With the rise of the fine-tuned--pretrained paradigm, storing numerous\nfine-tuned models for multi-tasking creates significant storage overhead. Delta\ncompression alleviates this by storing only the pretrained model and the highly\ncompressed delta weights (the differences between fine-tuned and pretrained\nmodel weights). However, existing methods fail to maintain both high\ncompression and performance, and often rely on data. To address these\nchallenges, we propose UltraDelta, the first data-free delta compression\npipeline that achieves both ultra-high compression and strong performance.\nUltraDelta is designed to minimize redundancy, maximize information, and\nstabilize performance across inter-layer, intra-layer, and global dimensions,\nusing three key components: (1) Variance-Based Mixed Sparsity Allocation\nassigns sparsity based on variance, giving lower sparsity to high-variance\nlayers to preserve inter-layer information. (2) Distribution-Aware Compression\napplies uniform quantization and then groups parameters by value, followed by\ngroup-wise pruning, to better preserve intra-layer distribution. (3)\nTrace-Norm-Guided Rescaling uses the trace norm of delta weights to estimate a\nglobal rescaling factor, improving model stability under higher compression.\nExtensive experiments across (a) large language models (fine-tuned on LLaMA-2\n7B and 13B) with up to 133x, (b) general NLP models (RoBERTa-base, T5-base)\nwith up to 800x, (c) vision models (ViT-B/32, ViT-L/14) with up to 400x, and\n(d) multi-modal models (BEiT-3) with 40x compression ratio, demonstrate that\nUltraDelta consistently outperforms existing methods, especially under\nultra-high compression.", "AI": {"tldr": "UltraDelta is a data-free delta compression pipeline achieving ultra-high compression and strong performance by minimizing redundancy and maximizing information across layers.", "motivation": "Addressing the storage overhead of fine-tuned models and the limitations of existing delta compression methods in maintaining high compression and performance.", "method": "Uses Variance-Based Mixed Sparsity Allocation, Distribution-Aware Compression, and Trace-Norm-Guided Rescaling to optimize compression.", "result": "Demonstrates superior performance across large language, NLP, vision, and multi-modal models with compression ratios up to 800x.", "conclusion": "UltraDelta outperforms existing methods, especially under ultra-high compression, offering a scalable solution for multi-tasking."}}
{"id": "2506.14243", "pdf": "https://arxiv.org/pdf/2506.14243", "abs": "https://arxiv.org/abs/2506.14243", "authors": ["Xiaohui Jiang", "Haijiang Zhu", "Chade Li", "Fulin Tang", "Ning An"], "title": "Cross-Modal Geometric Hierarchy Fusion: An Implicit-Submap Driven Framework for Resilient 3D Place Recognition", "categories": ["cs.CV"], "comment": null, "summary": "LiDAR-based place recognition serves as a crucial enabler for long-term\nautonomy in robotics and autonomous driving systems. Yet, prevailing\nmethodologies relying on handcrafted feature extraction face dual challenges:\n(1) Inconsistent point cloud density, induced by ego-motion dynamics and\nenvironmental disturbances during repeated traversals, leads to descriptor\ninstability, and (2) Representation fragility stems from reliance on\nsingle-level geometric abstractions that lack discriminative power in\nstructurally complex scenarios. To address these limitations, we propose a\nnovel framework that redefines 3D place recognition through density-agnostic\ngeometric reasoning. Specifically, we introduce an implicit 3D representation\nbased on elastic points, which is immune to the interference of original scene\npoint cloud density and achieves the characteristic of uniform distribution.\nSubsequently, we derive the occupancy grid and normal vector information of the\nscene from this implicit representation. Finally, with the aid of these two\ntypes of information, we obtain descriptors that fuse geometric information\nfrom both bird's-eye view (capturing macro-level spatial layouts) and 3D\nsegment (encoding micro-scale surface geometries) perspectives. We conducted\nextensive experiments on numerous datasets (KITTI, KITTI-360, MulRan, NCLT)\nacross diverse environments. The experimental results demonstrate that our\nmethod achieves state-of-the-art performance. Moreover, our approach strikes an\noptimal balance between accuracy, runtime, and memory optimization for\nhistorical maps, showcasing excellent Resilient and scalability. Our code will\nbe open-sourced in the future.", "AI": {"tldr": "A novel LiDAR-based place recognition framework using density-agnostic geometric reasoning achieves state-of-the-art performance by fusing macro and micro geometric information.", "motivation": "Address challenges of inconsistent point cloud density and representation fragility in current LiDAR-based place recognition methods.", "method": "Introduces an implicit 3D representation with elastic points, derives occupancy grid and normal vectors, and fuses geometric information from bird's-eye view and 3D segments.", "result": "Achieves state-of-the-art performance on multiple datasets (KITTI, KITTI-360, MulRan, NCLT) with balanced accuracy, runtime, and memory optimization.", "conclusion": "The proposed framework is resilient, scalable, and outperforms existing methods, with plans to open-source the code."}}
{"id": "2411.11794", "pdf": "https://arxiv.org/pdf/2411.11794", "abs": "https://arxiv.org/abs/2411.11794", "authors": ["Satush Parikh", "Soumya Basu", "Avishek Ghosh", "Abishek Sankararaman"], "title": "Competing Bandits in Decentralized Contextual Matching Markets", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "Sequential learning in a multi-agent resource constrained matching market has\nreceived significant interest in the past few years. We study decentralized\nlearning in two-sided matching markets where the demand side (aka players or\nagents) competes for the supply side (aka arms) with potentially time-varying\npreferences to obtain a stable match. Motivated by the linear contextual bandit\nframework, we assume that for each agent, an arm-mean may be represented by a\nlinear function of a known feature vector and an unknown (agent-specific)\nparameter. Moreover, the preferences over arms depend on a latent environment\nin each round, where the latent environment varies across rounds in a\nnon-stationary manner. We propose learning algorithms to identify the latent\nenvironment and obtain stable matchings simultaneously. Our proposed algorithms\nachieve instance-dependent logarithmic regret, scaling independently of the\nnumber of arms, and hence applicable for a large market.", "AI": {"tldr": "The paper studies decentralized learning in two-sided matching markets with time-varying preferences, proposing algorithms for stable matching and latent environment identification with logarithmic regret.", "motivation": "To address the challenge of sequential learning in multi-agent resource-constrained matching markets with non-stationary preferences and latent environments.", "method": "Proposes learning algorithms based on the linear contextual bandit framework, where arm-means are linear functions of known features and unknown agent-specific parameters.", "result": "Achieves instance-dependent logarithmic regret, scaling independently of the number of arms, making it suitable for large markets.", "conclusion": "The algorithms effectively identify latent environments and achieve stable matchings, demonstrating scalability and efficiency."}}
{"id": "2505.18384", "pdf": "https://arxiv.org/pdf/2505.18384", "abs": "https://arxiv.org/abs/2505.18384", "authors": ["Boyi Wei", "Benedikt Stroebl", "Jiacen Xu", "Joie Zhang", "Zhou Li", "Peter Henderson"], "title": "Dynamic Risk Assessments for Offensive Cybersecurity Agents", "categories": ["cs.CR", "cs.AI"], "comment": "26 pages, 11 figures", "summary": "Foundation models are increasingly becoming better autonomous programmers,\nraising the prospect that they could also automate dangerous offensive\ncyber-operations. Current frontier model audits probe the cybersecurity risks\nof such agents, but most fail to account for the degrees of freedom available\nto adversaries in the real world. In particular, with strong verifiers and\nfinancial incentives, agents for offensive cybersecurity are amenable to\niterative improvement by would-be adversaries. We argue that assessments should\ntake into account an expanded threat model in the context of cybersecurity,\nemphasizing the varying degrees of freedom that an adversary may possess in\nstateful and non-stateful environments within a fixed compute budget. We show\nthat even with a relatively small compute budget (8 H100 GPU Hours in our\nstudy), adversaries can improve an agent's cybersecurity capability on\nInterCode CTF by more than 40\\% relative to the baseline -- without any\nexternal assistance. These results highlight the need to evaluate agents'\ncybersecurity risk in a dynamic manner, painting a more representative picture\nof risk.", "AI": {"tldr": "Foundation models can automate offensive cyber-operations, and current audits often overlook adversarial freedom. With iterative improvement, adversaries can significantly boost cybersecurity capabilities even with limited compute budgets.", "motivation": "To highlight the risks of foundation models in automating offensive cyber-operations and the inadequacy of current audits in accounting for adversarial freedom.", "method": "Proposes an expanded threat model for cybersecurity, focusing on adversarial freedom in stateful and non-stateful environments, and demonstrates iterative improvement with a small compute budget (8 H100 GPU Hours).", "result": "Adversaries improved an agent's cybersecurity capability by over 40% on InterCode CTF without external assistance, showing the need for dynamic risk evaluation.", "conclusion": "Current cybersecurity risk assessments must evolve to account for dynamic adversarial capabilities, emphasizing iterative improvement and limited compute budgets."}}
{"id": "2506.14399", "pdf": "https://arxiv.org/pdf/2506.14399", "abs": "https://arxiv.org/abs/2506.14399", "authors": ["Tian Xia", "Fabio De Sousa Ribeiro", "Rajat R Rasal", "Avinash Kori", "Raghav Mehta", "Ben Glocker"], "title": "Decoupled Classifier-Free Guidance for Counterfactual Diffusion Models", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Counterfactual image generation aims to simulate realistic visual outcomes\nunder specific causal interventions. Diffusion models have recently emerged as\na powerful tool for this task, combining DDIM inversion with conditional\ngeneration via classifier-free guidance (CFG). However, standard CFG applies a\nsingle global weight across all conditioning variables, which can lead to poor\nidentity preservation and spurious attribute changes - a phenomenon known as\nattribute amplification. To address this, we propose Decoupled Classifier-Free\nGuidance (DCFG), a flexible and model-agnostic framework that introduces\ngroup-wise conditioning control. DCFG builds on an attribute-split embedding\nstrategy that disentangles semantic inputs, enabling selective guidance on\nuser-defined attribute groups. For counterfactual generation, we partition\nattributes into intervened and invariant sets based on a causal graph and apply\ndistinct guidance to each. Experiments on CelebA-HQ, MIMIC-CXR, and EMBED show\nthat DCFG improves intervention fidelity, mitigates unintended changes, and\nenhances reversibility, enabling more faithful and interpretable counterfactual\nimage generation.", "AI": {"tldr": "Proposes Decoupled Classifier-Free Guidance (DCFG) to improve counterfactual image generation by disentangling attribute control, enhancing fidelity and interpretability.", "motivation": "Standard CFG leads to poor identity preservation and spurious attribute changes (attribute amplification) in counterfactual image generation.", "method": "Introduces DCFG, a model-agnostic framework with group-wise conditioning control and attribute-split embedding to disentangle semantic inputs.", "result": "DCFG improves intervention fidelity, mitigates unintended changes, and enhances reversibility on datasets like CelebA-HQ, MIMIC-CXR, and EMBED.", "conclusion": "DCFG enables more faithful and interpretable counterfactual image generation by addressing limitations of standard CFG."}}
{"id": "2412.00119", "pdf": "https://arxiv.org/pdf/2412.00119", "abs": "https://arxiv.org/abs/2412.00119", "authors": ["Luca Colombo", "Fabrizio Pittorino", "Manuel Roveri"], "title": "Training Multi-Layer Binary Neural Networks With Local Binary Error Signals", "categories": ["cs.LG", "cs.CV", "I.2.6"], "comment": null, "summary": "Binary Neural Networks (BNNs) significantly reduce computational complexity\nand memory usage in machine and deep learning by representing weights and\nactivations with just one bit. However, most existing training algorithms for\nBNNs rely on quantization-aware floating-point Stochastic Gradient Descent\n(SGD), limiting the full exploitation of binary operations to the inference\nphase only. In this work, we propose, for the first time, a fully binary and\ngradient-free training algorithm for multi-layer BNNs, eliminating the need for\nback-propagated floating-point gradients. Specifically, the proposed algorithm\nrelies on local binary error signals and binary weight updates, employing\ninteger-valued hidden weights that serve as a synaptic metaplasticity\nmechanism, thereby enhancing its neurobiological plausibility. Our proposed\nsolution enables the training of binary multi-layer perceptrons by using\nexclusively XNOR, Popcount, and increment/decrement operations. Experimental\nresults on multi-class classification benchmarks show test accuracy\nimprovements of up to +35.47% over the only existing fully binary single-layer\nstate-of-the-art solution. Compared to full-precision SGD, our solution\nimproves test accuracy by up to +35.30% under the same total memory demand,\nwhile also reducing computational cost by two to three orders of magnitude in\nterms of the total number of Boolean gates. The proposed algorithm is made\navailable to the scientific community as a public repository.", "AI": {"tldr": "A fully binary, gradient-free training algorithm for multi-layer BNNs is proposed, improving accuracy and reducing computational costs.", "motivation": "Existing BNN training methods rely on floating-point SGD, limiting binary operation benefits to inference. This work aims to enable fully binary training.", "method": "Uses local binary error signals, binary weight updates, and integer-valued hidden weights for neurobiological plausibility, employing XNOR, Popcount, and increment/decrement operations.", "result": "Achieves up to +35.47% test accuracy over existing binary solutions and +35.30% over full-precision SGD, with significantly lower computational costs.", "conclusion": "The proposed algorithm enables efficient, fully binary training of multi-layer BNNs, outperforming existing methods in accuracy and computational efficiency."}}
{"id": "2506.00691", "pdf": "https://arxiv.org/pdf/2506.00691", "abs": "https://arxiv.org/abs/2506.00691", "authors": ["Junaid Muzaffar", "Khubaib Ahmed", "Ingo Frommholz", "Zeeshan Pervez", "Ahsan ul Haq"], "title": "Optimizing Sensory Neurons: Nonlinear Attention Mechanisms for Accelerated Convergence in Permutation-Invariant Neural Networks for Reinforcement Learning", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Training reinforcement learning (RL) agents often requires significant\ncomputational resources and prolonged training durations. To address this\nchallenge, we build upon prior work that introduced a neural architecture with\npermutation-invariant sensory processing. We propose a modified attention\nmechanism that applies a non-linear transformation to the key vectors (K),\nproducing enriched representations (K') through a custom mapping function. This\nNonlinear Attention (NLA) mechanism enhances the representational capacity of\nthe attention layer, enabling the agent to learn more expressive feature\ninteractions. As a result, our model achieves significantly faster convergence\nand improved training efficiency, while maintaining performance on par with the\nbaseline. These results highlight the potential of nonlinear attention\nmechanisms to accelerate reinforcement learning without sacrificing\neffectiveness.", "AI": {"tldr": "The paper proposes a Nonlinear Attention (NLA) mechanism to improve RL training efficiency by enhancing feature interactions, achieving faster convergence without performance loss.", "motivation": "Training RL agents is computationally expensive and time-consuming, prompting the need for more efficient methods.", "method": "A modified attention mechanism applies a non-linear transformation to key vectors (K) to create enriched representations (K'), improving feature interactions.", "result": "The NLA mechanism enables faster convergence and better training efficiency while matching baseline performance.", "conclusion": "Nonlinear attention mechanisms can accelerate RL training effectively without compromising performance."}}
{"id": "2506.14854", "pdf": "https://arxiv.org/pdf/2506.14854", "abs": "https://arxiv.org/abs/2506.14854", "authors": ["Varun Mannam", "Zhenyu Shi"], "title": "Efficient Retail Video Annotation: A Robust Key Frame Generation Approach for Product and Customer Interaction Analysis", "categories": ["cs.CV", "cs.AI", "cs.HC", "cs.LG"], "comment": "Submitting to ICCV 2025 workshop:\n  https://retailvisionworkshop.github.io/", "summary": "Accurate video annotation plays a vital role in modern retail applications,\nincluding customer behavior analysis, product interaction detection, and\nin-store activity recognition. However, conventional annotation methods heavily\nrely on time-consuming manual labeling by human annotators, introducing\nnon-robust frame selection and increasing operational costs. To address these\nchallenges in the retail domain, we propose a deep learning-based approach that\nautomates key-frame identification in retail videos and provides automatic\nannotations of products and customers. Our method leverages deep neural\nnetworks to learn discriminative features by embedding video frames and\nincorporating object detection-based techniques tailored for retail\nenvironments. Experimental results showcase the superiority of our approach\nover traditional methods, achieving accuracy comparable to human annotator\nlabeling while enhancing the overall efficiency of retail video annotation.\nRemarkably, our approach leads to an average of 2 times cost savings in video\nannotation. By allowing human annotators to verify/adjust less than 5% of\ndetected frames in the video dataset, while automating the annotation process\nfor the remaining frames without reducing annotation quality, retailers can\nsignificantly reduce operational costs. The automation of key-frame detection\nenables substantial time and effort savings in retail video labeling tasks,\nproving highly valuable for diverse retail applications such as shopper journey\nanalysis, product interaction detection, and in-store security monitoring.", "AI": {"tldr": "A deep learning-based approach automates key-frame identification and annotation in retail videos, reducing manual effort and costs while maintaining accuracy.", "motivation": "Manual video annotation in retail is time-consuming and costly, requiring a more efficient and automated solution.", "method": "Uses deep neural networks for key-frame identification and object detection tailored for retail environments.", "result": "Achieves human-level accuracy with 2x cost savings and requires human verification for less than 5% of frames.", "conclusion": "The method significantly reduces operational costs and saves time, proving valuable for retail applications like shopper analysis and security monitoring."}}
{"id": "2501.12670", "pdf": "https://arxiv.org/pdf/2501.12670", "abs": "https://arxiv.org/abs/2501.12670", "authors": ["Abhinav Moudgil", "Boris Knyazev", "Guillaume Lajoie", "Eugene Belilovsky"], "title": "Celo: Training Versatile Learned Optimizers on a Compute Diet", "categories": ["cs.LG"], "comment": null, "summary": "Learned optimization has emerged as a promising alternative to hand-crafted\noptimizers, with the potential to discover stronger learned update rules that\nenable faster, hyperparameter-free training of neural networks. A critical\nelement for practically useful learned optimizers, that can be used\noff-the-shelf after meta-training, is strong meta-generalization: the ability\nto apply the optimizers to new tasks. Recent state-of-the-art work in learned\noptimizers, VeLO (Metz et al., 2022), requires a large number of highly diverse\nmeta-training tasks along with massive computational resources, 4000 TPU\nmonths, to achieve meta-generalization. This makes further improvements to such\nlearned optimizers impractical. In this work, we identify several key elements\nin learned optimizer architectures and meta-training procedures that can lead\nto strong meta-generalization. We also propose evaluation metrics to reliably\nassess quantitative performance of an optimizer at scale on a set of evaluation\ntasks. Our proposed approach, Celo, makes a significant leap in improving the\nmeta-generalization performance of learned optimizers and also outperforms\ntuned state-of-the-art optimizers on a diverse set of out-of-distribution\ntasks, despite being meta-trained for just 24 GPU hours.", "AI": {"tldr": "The paper introduces Celo, a learned optimizer with improved meta-generalization, outperforming VeLO and other optimizers with minimal training resources.", "motivation": "To address the impractical resource demands of current learned optimizers like VeLO and improve meta-generalization for broader applicability.", "method": "Identifies key architectural and procedural elements for meta-generalization and proposes evaluation metrics. Introduces Celo, a learned optimizer meta-trained for just 24 GPU hours.", "result": "Celo achieves strong meta-generalization, outperforming tuned state-of-the-art optimizers on diverse out-of-distribution tasks.", "conclusion": "Celo demonstrates that efficient meta-training and careful design can lead to highly effective learned optimizers without excessive computational costs."}}
{"id": "2506.01231", "pdf": "https://arxiv.org/pdf/2506.01231", "abs": "https://arxiv.org/abs/2506.01231", "authors": ["Wenhao Song", "Xuan Wu", "Bo Yang", "You Zhou", "Yubin Xiao", "Yanchun Liang", "Hongwei Ge", "Heow Pueh Lee", "Chunguo Wu"], "title": "Towards Efficient Few-shot Graph Neural Architecture Search via Partitioning Gradient Contribution", "categories": ["cs.LG", "cs.AI"], "comment": "Accepted by SIGKDD 2025", "summary": "To address the weight coupling problem, certain studies introduced few-shot\nNeural Architecture Search (NAS) methods, which partition the supernet into\nmultiple sub-supernets. However, these methods often suffer from computational\ninefficiency and tend to provide suboptimal partitioning schemes. To address\nthis problem more effectively, we analyze the weight coupling problem from a\nnovel perspective, which primarily stems from distinct modules in succeeding\nlayers imposing conflicting gradient directions on the preceding layer modules.\nBased on this perspective, we propose the Gradient Contribution (GC) method\nthat efficiently computes the cosine similarity of gradient directions among\nmodules by decomposing the Vector-Jacobian Product during supernet\nbackpropagation. Subsequently, the modules with conflicting gradient directions\nare allocated to distinct sub-supernets while similar ones are grouped\ntogether. To assess the advantages of GC and address the limitations of\nexisting Graph Neural Architecture Search methods, which are limited to\nsearching a single type of Graph Neural Networks (Message Passing Neural\nNetworks (MPNNs) or Graph Transformers (GTs)), we propose the Unified Graph\nNeural Architecture Search (UGAS) framework, which explores optimal\ncombinations of MPNNs and GTs. The experimental results demonstrate that GC\nachieves state-of-the-art (SOTA) performance in supernet partitioning quality\nand time efficiency. In addition, the architectures searched by UGAS+GC\noutperform both the manually designed GNNs and those obtained by existing NAS\nmethods. Finally, ablation studies further demonstrate the effectiveness of all\nproposed methods.", "AI": {"tldr": "The paper introduces the Gradient Contribution (GC) method to address weight coupling in Neural Architecture Search (NAS) by analyzing gradient conflicts and proposes the Unified Graph Neural Architecture Search (UGAS) framework for combining MPNNs and GTs, achieving SOTA results.", "motivation": "To solve the inefficiency and suboptimal partitioning in few-shot NAS methods caused by weight coupling and gradient conflicts.", "method": "Proposes the GC method to compute gradient similarity and partition modules, and the UGAS framework to unify MPNN and GT searches.", "result": "GC achieves SOTA in partitioning quality and efficiency; UGAS+GC outperforms manual and existing NAS methods.", "conclusion": "The GC method and UGAS framework effectively address weight coupling and expand NAS capabilities, validated by experiments."}}
{"id": "2506.15153", "pdf": "https://arxiv.org/pdf/2506.15153", "abs": "https://arxiv.org/abs/2506.15153", "authors": ["Yufei Liu", "Haoke Xiao", "Jiaxing Chai", "Yongcun Zhang", "Rong Wang", "Zijie Meng", "Zhiming Luo"], "title": "SynPo: Boosting Training-Free Few-Shot Medical Segmentation via High-Quality Negative Prompts", "categories": ["cs.CV"], "comment": "MICCAI 2025 Early Accept. Project Page:\n  https://liu-yufei.github.io/synpo-project-page/", "summary": "The advent of Large Vision Models (LVMs) offers new opportunities for\nfew-shot medical image segmentation. However, existing training-free methods\nbased on LVMs fail to effectively utilize negative prompts, leading to poor\nperformance on low-contrast medical images. To address this issue, we propose\nSynPo, a training-free few-shot method based on LVMs (e.g., SAM), with the core\ninsight: improving the quality of negative prompts. To select point prompts in\na more reliable confidence map, we design a novel Confidence Map Synergy Module\nby combining the strengths of DINOv2 and SAM. Based on the confidence map, we\nselect the top-k pixels as the positive points set and choose the negative\npoints set using a Gaussian distribution, followed by independent K-means\nclustering for both sets. Then, these selected points are leveraged as\nhigh-quality prompts for SAM to get the segmentation results. Extensive\nexperiments demonstrate that SynPo achieves performance comparable to\nstate-of-the-art training-based few-shot methods.", "AI": {"tldr": "SynPo improves few-shot medical image segmentation by enhancing negative prompts in LVMs like SAM, using a Confidence Map Synergy Module and K-means clustering for point selection.", "motivation": "Existing training-free methods using LVMs perform poorly on low-contrast medical images due to ineffective negative prompts.", "method": "SynPo combines DINOv2 and SAM for reliable confidence maps, selects top-k positive and Gaussian-distributed negative points, and applies K-means clustering for high-quality prompts.", "result": "SynPo matches state-of-the-art training-based few-shot methods in performance.", "conclusion": "SynPo effectively addresses the limitations of LVMs in medical image segmentation by improving prompt quality."}}
{"id": "2501.12919", "pdf": "https://arxiv.org/pdf/2501.12919", "abs": "https://arxiv.org/abs/2501.12919", "authors": ["Yuta Suzuki", "Tatsunori Taniai", "Ryo Igarashi", "Kotaro Saito", "Naoya Chiba", "Yoshitaka Ushiku", "Kanta Ono"], "title": "Bridging Text and Crystal Structures: Literature-driven Contrastive Learning for Materials Science", "categories": ["cs.LG", "cond-mat.mtrl-sci"], "comment": "19 pages, 8 figures. Accepted to Machine Learning: Science and\n  Technology (2025). Preliminary versions appeared at NeurIPS 2024 AI4Mat and\n  CVPR 2025 MM4Mat workshops", "summary": "Understanding structure-property relationships is an essential yet\nchallenging aspect of materials discovery and development. To facilitate this\nprocess, recent studies in materials informatics have sought latent embedding\nspaces of crystal structures to capture their similarities based on properties\nand functionalities. However, abstract feature-based embedding spaces are\nhuman-unfriendly and prevent intuitive and efficient exploration of the vast\nmaterials space. Here we introduce Contrastive Language--Structure Pre-training\n(CLaSP), a learning paradigm for constructing crossmodal embedding spaces\nbetween crystal structures and texts. CLaSP aims to achieve material embeddings\nthat 1) capture property- and functionality-related similarities between\ncrystal structures and 2) allow intuitive retrieval of materials via\nuser-provided description texts as queries. To compensate for the lack of\nsufficient datasets linking crystal structures with textual descriptions, CLaSP\nleverages a dataset of over 400,000 published crystal structures and\ncorresponding publication records, including paper titles and abstracts, for\ntraining. We demonstrate the effectiveness of CLaSP through text-based crystal\nstructure screening and embedding space visualization.", "AI": {"tldr": "CLaSP introduces a crossmodal embedding space between crystal structures and texts to improve intuitive materials exploration.", "motivation": "Abstract feature-based embedding spaces are not user-friendly, hindering efficient materials exploration.", "method": "CLaSP uses contrastive learning with a dataset of 400,000 crystal structures and associated texts.", "result": "The method enables intuitive text-based retrieval and visualization of crystal structures.", "conclusion": "CLaSP effectively bridges crystal structures and textual descriptions for better materials discovery."}}
{"id": "2506.02634", "pdf": "https://arxiv.org/pdf/2506.02634", "abs": "https://arxiv.org/abs/2506.02634", "authors": ["Jiahao Wang", "Jinbo Han", "Xingda Wei", "Sijie Shen", "Dingyan Zhang", "Chenguang Fang", "Rong Chen", "Wenyuan Yu", "Haibo Chen"], "title": "KVCache Cache in the Wild: Characterizing and Optimizing KVCache Cache at a Large Cloud Provider", "categories": ["cs.DC", "cs.AI"], "comment": "Accepted by USENIX ATC'25", "summary": "Serving large language models (LLMs) is important for cloud providers, and\ncaching intermediate results (KV\\$) after processing each request substantially\nimproves serving throughput and latency. However, there is limited\nunderstanding of how LLM serving benefits from KV\\$ caching, where system\ndesign decisions like cache eviction policies are highly workload-dependent. In\nthis paper, we present the first systematic characterization of the KV\\$\nworkload patterns from one of the leading LLM service providers. We draw\nobservations that were not covered by previous studies focusing on synthetic\nworkloads, including: KV\\$ reuses are skewed across requests, where reuses\nbetween single-turn requests are equally important as multi-turn requests; the\nreuse time and probability are diverse considering all requests, but for a\nspecific request category, the pattern tends to be predictable; and the overall\ncache size required for an ideal cache hit ratio is moderate. Based on the\ncharacterization, we further propose a workload-aware cache eviction policy\nthat improves the serving performance under real-world traces, especially with\nlimited cache capacity.", "AI": {"tldr": "The paper analyzes KV$ caching in LLM serving, revealing skewed reuse patterns and predictable behavior per request category, leading to a workload-aware eviction policy for better performance.", "motivation": "Understanding KV$ caching's impact on LLM serving performance, as current insights are limited and workload-dependent.", "method": "Systematic characterization of KV$ workload patterns from a leading LLM provider, identifying reuse skew and predictability.", "result": "KV$ reuse is skewed; patterns are predictable per category; ideal cache size is moderate. A workload-aware policy improves performance.", "conclusion": "Workload-aware cache eviction enhances LLM serving efficiency, especially with limited cache capacity."}}
{"id": "2506.15318", "pdf": "https://arxiv.org/pdf/2506.15318", "abs": "https://arxiv.org/abs/2506.15318", "authors": ["Lanfeng Zhong", "Xin Liao", "Shichuan Zhang", "Shaoting Zhang", "Guotai Wang"], "title": "OpenPath: Open-Set Active Learning for Pathology Image Classification via Pre-trained Vision-Language Models", "categories": ["cs.CV"], "comment": "MICCAI 2025 early accept", "summary": "Pathology image classification plays a crucial role in accurate medical\ndiagnosis and treatment planning. Training high-performance models for this\ntask typically requires large-scale annotated datasets, which are both\nexpensive and time-consuming to acquire. Active Learning (AL) offers a solution\nby iteratively selecting the most informative samples for annotation, thereby\nreducing the labeling effort. However, most AL methods are designed under the\nassumption of a closed-set scenario, where all the unannotated images belong to\ntarget classes. In real-world clinical environments, the unlabeled pool often\ncontains a substantial amount of Out-Of-Distribution (OOD) data, leading to low\nefficiency of annotation in traditional AL methods. Furthermore, most existing\nAL methods start with random selection in the first query round, leading to a\nsignificant waste of labeling costs in open-set scenarios. To address these\nchallenges, we propose OpenPath, a novel open-set active learning approach for\npathological image classification leveraging a pre-trained Vision-Language\nModel (VLM). In the first query, we propose task-specific prompts that combine\ntarget and relevant non-target class prompts to effectively select\nIn-Distribution (ID) and informative samples from the unlabeled pool. In\nsubsequent queries, Diverse Informative ID Sampling (DIS) that includes\nPrototype-based ID candidate Selection (PIS) and Entropy-Guided Stochastic\nSampling (EGSS) is proposed to ensure both purity and informativeness in a\nquery, avoiding the selection of OOD samples. Experiments on two public\npathology image datasets show that OpenPath significantly enhances the model's\nperformance due to its high purity of selected samples, and outperforms several\nstate-of-the-art open-set AL methods. The code is available at\n\\href{https://github.com/HiLab-git/OpenPath}{https://github.com/HiLab-git/OpenPath}..", "AI": {"tldr": "OpenPath is a novel open-set active learning method for pathology image classification, leveraging a pre-trained Vision-Language Model to efficiently select informative in-distribution samples while avoiding out-of-distribution data.", "motivation": "Traditional active learning methods assume closed-set scenarios, but real-world clinical data often includes out-of-distribution samples, reducing annotation efficiency. OpenPath addresses this by improving sample selection purity and informativeness.", "method": "OpenPath uses task-specific prompts in the first query to select in-distribution samples. Subsequent queries employ Diverse Informative ID Sampling (DIS), combining Prototype-based ID candidate Selection (PIS) and Entropy-Guided Stochastic Sampling (EGSS).", "result": "Experiments on two public pathology datasets show OpenPath outperforms state-of-the-art open-set active learning methods, enhancing model performance due to high sample purity.", "conclusion": "OpenPath effectively reduces labeling costs in open-set scenarios by improving sample selection, making it a valuable tool for pathology image classification."}}
{"id": "2501.15163", "pdf": "https://arxiv.org/pdf/2501.15163", "abs": "https://arxiv.org/abs/2501.15163", "authors": ["Haixia Liu", "Boxiao Li", "Can Yang", "Yang Wang"], "title": "The Exploration of Error Bounds in Classification with Noisy Labels", "categories": ["cs.LG", "stat.ML"], "comment": "21 pages", "summary": "Numerous studies have shown that label noise can lead to poor generalization\nperformance, negatively affecting classification accuracy. Therefore,\nunderstanding the effectiveness of classifiers trained using deep neural\nnetworks in the presence of noisy labels is of considerable practical\nsignificance. In this paper, we focus on the error bounds of excess risks for\nclassification problems with noisy labels within deep learning frameworks. We\nderive error bounds for the excess risk, decomposing it into statistical error\nand approximation error. To handle statistical dependencies (e.g., mixing\nsequences), we employ an independent block construction to bound the error,\nleveraging techniques for dependent processes. For the approximation error, we\nestablish these theoretical results to the vector-valued setting, where the\noutput space consists of $K$-dimensional unit vectors. Finally, under the\nlow-dimensional manifold hypothesis, we further refine the approximation error\nto mitigate the impact of high-dimensional input spaces.", "AI": {"tldr": "The paper analyzes error bounds for excess risks in deep learning classification with noisy labels, decomposing them into statistical and approximation errors, and refines the latter under low-dimensional manifold assumptions.", "motivation": "Label noise harms classifier performance, making it crucial to understand deep learning's effectiveness in such scenarios.", "method": "Derives error bounds for excess risk, uses independent block construction for statistical dependencies, and extends results to vector-valued outputs.", "result": "Establishes theoretical bounds for excess risk, addressing statistical and approximation errors, and refines the latter for high-dimensional inputs.", "conclusion": "The study provides theoretical insights into handling noisy labels in deep learning, improving robustness in classification tasks."}}
{"id": "2506.05692", "pdf": "https://arxiv.org/pdf/2506.05692", "abs": "https://arxiv.org/abs/2506.05692", "authors": ["Xinghang Li", "Jingzhe Ding", "Chao Peng", "Bing Zhao", "Xiang Gao", "Hongwan Gao", "Xinchen Gu"], "title": "SafeGenBench: A Benchmark Framework for Security Vulnerability Detection in LLM-Generated Code", "categories": ["cs.CR", "cs.AI"], "comment": null, "summary": "The code generation capabilities of large language models(LLMs) have emerged\nas a critical dimension in evaluating their overall performance. However, prior\nresearch has largely overlooked the security risks inherent in the generated\ncode. In this work, we introduce SafeGenBench, a benchmark specifically\ndesigned to assess the security of LLM-generated code. The dataset encompasses\na wide range of common software development scenarios and vulnerability types.\nBuilding upon this benchmark, we develop an automatic evaluation framework that\nleverages both static application security testing(SAST) and LLM-based judging\nto assess the presence of security vulnerabilities in model-generated code.\nThrough the empirical evaluation of state-of-the-art LLMs on SafeGenBench, we\nreveal notable deficiencies in their ability to produce vulnerability-free\ncode. Our findings highlight pressing challenges and offer actionable insights\nfor future advancements in the secure code generation performance of LLMs. The\ndata and code will be released soon.", "AI": {"tldr": "SafeGenBench is a benchmark to evaluate security risks in LLM-generated code, revealing significant vulnerabilities in current models.", "motivation": "Prior research overlooked security risks in LLM-generated code, prompting the need for a dedicated benchmark.", "method": "SafeGenBench includes diverse scenarios and vulnerabilities, evaluated using SAST and LLM-based judging.", "result": "State-of-the-art LLMs show notable deficiencies in producing secure code.", "conclusion": "The findings highlight challenges and provide insights for improving secure code generation in LLMs."}}
{"id": "2506.15564", "pdf": "https://arxiv.org/pdf/2506.15564", "abs": "https://arxiv.org/abs/2506.15564", "authors": ["Jinheng Xie", "Zhenheng Yang", "Mike Zheng Shou"], "title": "Show-o2: Improved Native Unified Multimodal Models", "categories": ["cs.CV"], "comment": "Technical report. (v2: update references and tables)", "summary": "This paper presents improved native unified multimodal models, \\emph{i.e.,}\nShow-o2, that leverage autoregressive modeling and flow matching. Built upon a\n3D causal variational autoencoder space, unified visual representations are\nconstructed through a dual-path of spatial (-temporal) fusion, enabling\nscalability across image and video modalities while ensuring effective\nmultimodal understanding and generation. Based on a language model,\nautoregressive modeling and flow matching are natively applied to the language\nhead and flow head, respectively, to facilitate text token prediction and\nimage/video generation. A two-stage training recipe is designed to effectively\nlearn and scale to larger models. The resulting Show-o2 models demonstrate\nversatility in handling a wide range of multimodal understanding and generation\ntasks across diverse modalities, including text, images, and videos. Code and\nmodels are released at https://github.com/showlab/Show-o.", "AI": {"tldr": "Show-o2 introduces unified multimodal models using autoregressive modeling and flow matching, enabling scalable understanding and generation across text, images, and videos.", "motivation": "To create a versatile model for multimodal tasks by unifying visual representations and leveraging autoregressive and flow-based methods.", "method": "Uses a 3D causal variational autoencoder with dual-path spatial-temporal fusion, autoregressive modeling for text, and flow matching for image/video generation.", "result": "Show-o2 effectively handles diverse multimodal tasks, demonstrating scalability and versatility.", "conclusion": "The model successfully integrates multimodal understanding and generation, with code and models publicly available."}}
{"id": "2501.16839", "pdf": "https://arxiv.org/pdf/2501.16839", "abs": "https://arxiv.org/abs/2501.16839", "authors": ["Christian Wald", "Gabriele Steidl"], "title": "Flow Matching: Markov Kernels, Stochastic Processes and Transport Plans", "categories": ["cs.LG", "math.PR"], "comment": null, "summary": "Among generative neural models, flow matching techniques stand out for their\nsimple applicability and good scaling properties. Here, velocity fields of\ncurves connecting a simple latent and a target distribution are learned. Then\nthe corresponding ordinary differential equation can be used to sample from a\ntarget distribution, starting in samples from the latent one. This paper\nreviews from a mathematical point of view different techniques to learn the\nvelocity fields of absolutely continuous curves in the Wasserstein geometry. We\nshow how the velocity fields can be characterized and learned via i) transport\nplans (couplings) between latent and target distributions, ii) Markov kernels\nand iii) stochastic processes, where the latter two include the coupling\napproach, but are in general broader. Besides this main goal, we show how flow\nmatching can be used for solving Bayesian inverse problems, where the\ndefinition of conditional Wasserstein distances plays a central role. Finally,\nwe briefly address continuous normalizing flows and score matching techniques,\nwhich approach the learning of velocity fields of curves from other directions.", "AI": {"tldr": "The paper reviews flow matching techniques for learning velocity fields in Wasserstein geometry, explores methods like transport plans, Markov kernels, and stochastic processes, and applies them to Bayesian inverse problems.", "motivation": "To provide a mathematical perspective on learning velocity fields for flow matching, highlighting its simplicity and scalability in generative neural models.", "method": "Review and analysis of techniques to learn velocity fields: transport plans (couplings), Markov kernels, and stochastic processes. Also explores applications in Bayesian inverse problems.", "result": "Demonstrates how velocity fields can be characterized and learned, with broader applicability beyond coupling approaches.", "conclusion": "Flow matching is versatile, scalable, and useful for tasks like Bayesian inverse problems, with connections to continuous normalizing flows and score matching."}}
{"id": "2506.08070", "pdf": "https://arxiv.org/pdf/2506.08070", "abs": "https://arxiv.org/abs/2506.08070", "authors": ["Ziheng Qin", "Hailun Xu", "Wei Chee Yew", "Qi Jia", "Yang Luo", "Kanchan Sarkar", "Danhui Guan", "Kai Wang", "Yang You"], "title": "Info-Coevolution: An Efficient Framework for Data Model Coevolution", "categories": ["cs.LG", "cs.AI"], "comment": "V1", "summary": "Machine learning relies heavily on data, yet the continuous growth of\nreal-world data poses challenges for efficient dataset construction and\ntraining. A fundamental yet unsolved question is: given our current model and\ndata, does a new data (sample/batch) need annotation/learning? Conventional\napproaches retain all available data, leading to non-optimal data and training\nefficiency. Active learning aims to reduce data redundancy by selecting a\nsubset of samples to annotate, while it increases pipeline complexity and\nintroduces bias. In this work, we propose Info-Coevolution, a novel framework\nthat efficiently enables models and data to coevolve through online selective\nannotation with no bias. Leveraging task-specific models (and open-source\nmodels), it selectively annotates and integrates online and web data to improve\ndatasets efficiently. For real-world datasets like ImageNet-1K,\nInfo-Coevolution reduces annotation and training costs by 32\\% without\nperformance loss. It is able to automatically give the saving ratio without\ntuning the ratio. It can further reduce the annotation ratio to 50\\% with\nsemi-supervised learning. We also explore retrieval-based dataset enhancement\nusing unlabeled open-source data. Code is available at\nhttps://github.com/NUS-HPC-AI-Lab/Info-Coevolution/.", "AI": {"tldr": "Info-Coevolution is a framework for efficient dataset construction and training by selectively annotating and integrating data, reducing costs without performance loss.", "motivation": "Addresses inefficiency in dataset construction and training due to growing real-world data, aiming to reduce redundancy and bias in annotation.", "method": "Proposes Info-Coevolution, a framework for online selective annotation, leveraging task-specific models to coevolve models and data.", "result": "Reduces annotation and training costs by 32% on ImageNet-1K, with potential for 50% reduction using semi-supervised learning.", "conclusion": "Info-Coevolution offers a scalable, bias-free solution for efficient dataset enhancement and training cost reduction."}}
{"id": "2506.15591", "pdf": "https://arxiv.org/pdf/2506.15591", "abs": "https://arxiv.org/abs/2506.15591", "authors": ["Yujing Sun", "Lingchen Sun", "Shuaizheng Liu", "Rongyuan Wu", "Zhengqiang Zhang", "Lei Zhang"], "title": "One-Step Diffusion for Detail-Rich and Temporally Consistent Video Super-Resolution", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "It is a challenging problem to reproduce rich spatial details while\nmaintaining temporal consistency in real-world video super-resolution\n(Real-VSR), especially when we leverage pre-trained generative models such as\nstable diffusion (SD) for realistic details synthesis. Existing SD-based\nReal-VSR methods often compromise spatial details for temporal coherence,\nresulting in suboptimal visual quality. We argue that the key lies in how to\neffectively extract the degradation-robust temporal consistency priors from the\nlow-quality (LQ) input video and enhance the video details while maintaining\nthe extracted consistency priors. To achieve this, we propose a Dual LoRA\nLearning (DLoRAL) paradigm to train an effective SD-based one-step diffusion\nmodel, achieving realistic frame details and temporal consistency\nsimultaneously. Specifically, we introduce a Cross-Frame Retrieval (CFR) module\nto aggregate complementary information across frames, and train a\nConsistency-LoRA (C-LoRA) to learn robust temporal representations from\ndegraded inputs. After consistency learning, we fix the CFR and C-LoRA modules\nand train a Detail-LoRA (D-LoRA) to enhance spatial details while aligning with\nthe temporal space defined by C-LoRA to keep temporal coherence. The two phases\nalternate iteratively for optimization, collaboratively delivering consistent\nand detail-rich outputs. During inference, the two LoRA branches are merged\ninto the SD model, allowing efficient and high-quality video restoration in a\nsingle diffusion step. Experiments show that DLoRAL achieves strong performance\nin both accuracy and speed. Code and models are available at\nhttps://github.com/yjsunnn/DLoRAL.", "AI": {"tldr": "DLoRAL introduces a Dual LoRA Learning paradigm for Real-VSR, combining Cross-Frame Retrieval and Consistency-LoRA to maintain temporal coherence while enhancing spatial details.", "motivation": "Existing SD-based Real-VSR methods sacrifice spatial details for temporal consistency, leading to suboptimal visual quality.", "method": "Proposes a Dual LoRA Learning (DLoRAL) paradigm with Cross-Frame Retrieval (CFR) and Consistency-LoRA (C-LoRA) for temporal coherence, followed by Detail-LoRA (D-LoRA) for spatial enhancement.", "result": "DLoRAL achieves strong performance in accuracy and speed, delivering consistent and detail-rich outputs.", "conclusion": "The method effectively balances temporal consistency and spatial detail enhancement, outperforming existing approaches."}}
{"id": "2501.19401", "pdf": "https://arxiv.org/pdf/2501.19401", "abs": "https://arxiv.org/abs/2501.19401", "authors": ["Argyrios Gerogiannis", "Yu-Han Huang", "Subhonmesh Bose", "Venugopal V. Veeravalli"], "title": "DAL: A Practical Prior-Free Black-Box Framework for Non-Stationary Bandit Environments", "categories": ["cs.LG", "stat.ML"], "comment": "20 pages, 8 figures, added Acknowledgments", "summary": "We introduce a practical, black-box framework termed Detection Augmenting\nLearning (DAL) for the problem of non-stationary bandits without prior\nknowledge of the underlying non-stationarity. DAL is modular, accepting any\nstationary bandit algorithm as input and augmenting it with a change detector.\nOur approach is applicable to all common parametric and non-parametric bandit\nvariants. Extensive experimentation demonstrates that DAL consistently\nsurpasses current state-of-the-art methods across diverse non-stationary\nscenarios, including synthetic benchmarks and real-world datasets, underscoring\nits versatility and scalability. We provide theoretical insights into DAL's\nstrong empirical performance on piecewise stationary and drift settings,\ncomplemented by thorough experimental validation.", "AI": {"tldr": "DAL is a black-box framework for non-stationary bandits, enhancing any stationary bandit algorithm with a change detector, outperforming state-of-the-art methods.", "motivation": "Addressing non-stationary bandits without prior knowledge of the underlying non-stationarity.", "method": "Modular framework combining stationary bandit algorithms with change detectors.", "result": "DAL consistently outperforms current methods in synthetic and real-world scenarios.", "conclusion": "DAL is versatile, scalable, and effective for non-stationary bandit problems."}}
{"id": "2506.10317", "pdf": "https://arxiv.org/pdf/2506.10317", "abs": "https://arxiv.org/abs/2506.10317", "authors": ["Akshar Tumu", "Henrik I. Christensen", "Marcell Vazquez-Chanlatte", "Chikao Tsuchiya", "Dhaval Bhanderi"], "title": "Using Language and Road Manuals to Inform Map Reconstruction for Autonomous Driving", "categories": ["cs.RO", "cs.AI"], "comment": "4 pages, 3 figures, Accepted at RSS 2025 Workshop -\n  RobotEvaluation@RSS 2025", "summary": "Lane-topology prediction is a critical component of safe and reliable\nautonomous navigation. An accurate understanding of the road environment aids\nthis task. We observe that this information often follows conventions encoded\nin natural language, through design codes that reflect the road structure and\nroad names that capture the road functionality. We augment this information in\na lightweight manner to SMERF, a map-prior-based online lane-topology\nprediction model, by combining structured road metadata from OSM maps and\nlane-width priors from Road design manuals with the road centerline encodings.\nWe evaluate our method on two geo-diverse complex intersection scenarios. Our\nmethod shows improvement in both lane and traffic element detection and their\nassociation. We report results using four topology-aware metrics to\ncomprehensively assess the model performance. These results demonstrate the\nability of our approach to generalize and scale to diverse topologies and\nconditions.", "AI": {"tldr": "The paper improves lane-topology prediction for autonomous navigation by integrating road metadata and lane-width priors into the SMERF model, showing enhanced performance in complex scenarios.", "motivation": "Accurate lane-topology prediction is vital for autonomous navigation, and leveraging natural language conventions (e.g., road names and design codes) can enhance understanding of road environments.", "method": "The authors augment the SMERF model with structured road metadata from OSM maps and lane-width priors from design manuals, combining these with road centerline encodings.", "result": "Evaluation on geo-diverse complex intersections shows improved lane and traffic element detection and association, validated by four topology-aware metrics.", "conclusion": "The approach generalizes and scales well across diverse topologies and conditions, demonstrating its effectiveness."}}
{"id": "2506.15675", "pdf": "https://arxiv.org/pdf/2506.15675", "abs": "https://arxiv.org/abs/2506.15675", "authors": ["Zhen Li", "Chuanhao Li", "Xiaofeng Mao", "Shaoheng Lin", "Ming Li", "Shitian Zhao", "Zhaopan Xu", "Xinyue Li", "Yukang Feng", "Jianwen Sun", "Zizhen Li", "Fanrui Zhang", "Jiaxin Ai", "Zhixiang Wang", "Yuwei Wu", "Tong He", "Jiangmiao Pang", "Yu Qiao", "Yunde Jia", "Kaipeng Zhang"], "title": "Sekai: A Video Dataset towards World Exploration", "categories": ["cs.CV", "cs.AI"], "comment": "12 pages, 6 figures", "summary": "Video generation techniques have made remarkable progress, promising to be\nthe foundation of interactive world exploration. However, existing video\ngeneration datasets are not well-suited for world exploration training as they\nsuffer from some limitations: limited locations, short duration, static scenes,\nand a lack of annotations about exploration and the world. In this paper, we\nintroduce Sekai (meaning ``world'' in Japanese), a high-quality first-person\nview worldwide video dataset with rich annotations for world exploration. It\nconsists of over 5,000 hours of walking or drone view (FPV and UVA) videos from\nover 100 countries and regions across 750 cities. We develop an efficient and\neffective toolbox to collect, pre-process and annotate videos with location,\nscene, weather, crowd density, captions, and camera trajectories. Experiments\ndemonstrate the quality of the dataset. And, we use a subset to train an\ninteractive video world exploration model, named YUME (meaning ``dream'' in\nJapanese). We believe Sekai will benefit the area of video generation and world\nexploration, and motivate valuable applications. The project page is\nhttps://lixsp11.github.io/sekai-project/.", "AI": {"tldr": "The paper introduces Sekai, a high-quality first-person video dataset for world exploration, addressing limitations of existing datasets. It includes 5,000+ hours of videos from 100+ countries, with rich annotations. The dataset is used to train an interactive model, YUME, demonstrating its potential for video generation and exploration applications.", "motivation": "Existing video generation datasets are limited in scope (locations, duration, annotations), making them unsuitable for world exploration training.", "method": "The authors create Sekai, a dataset with 5,000+ hours of first-person videos from 100+ countries, annotated with location, scene, weather, and more. They also develop a toolbox for efficient collection and annotation.", "result": "Experiments confirm the dataset's quality, and a subset is used to train YUME, an interactive video world exploration model.", "conclusion": "Sekai is a valuable resource for video generation and world exploration, with potential for impactful applications."}}
{"id": "2502.00197", "pdf": "https://arxiv.org/pdf/2502.00197", "abs": "https://arxiv.org/abs/2502.00197", "authors": ["Yingshan Chang", "Yonatan Bisk"], "title": "Learning Model Successors", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "The notion of generalization has moved away from the classical one defined in\nstatistical learning theory towards an emphasis on out-of-domain generalization\n(OODG). There has been a growing focus on generalization from easy to hard,\nwhere a progression of difficulty implicitly governs the direction of domain\nshifts. This emerging regime has appeared in the literature under different\nnames, such as length/logical/algorithmic extrapolation, but a formal\ndefinition is lacking. We argue that the unifying theme is induction -- based\non finite samples observed in training, a learner should infer an inductive\nprinciple that applies in an unbounded manner. This work formalizes the notion\nof inductive generalization along a difficulty progression and argues that our\npath ahead lies in transforming the learning paradigm. We attempt to make\ninroads by proposing a novel learning paradigm, Inductive Learning, which\ninvolves a central concept called model successors. We outline practical steps\nto adapt well-established techniques towards learning model successors. This\nwork calls for restructuring of the research discussion around induction and\ngeneralization from fragmented task-centric communities to a more unified\neffort, focused on universal properties of learning and computation.", "AI": {"tldr": "The paper shifts focus from classical generalization to out-of-domain generalization (OODG), emphasizing induction as a unifying theme. It proposes a new learning paradigm, Inductive Learning, centered on model successors, and calls for a unified research approach.", "motivation": "To address the lack of a formal definition for generalization along difficulty progressions and unify fragmented research efforts under the theme of induction.", "method": "Proposes Inductive Learning, introducing model successors and adapting existing techniques to learn them.", "result": "A formalized notion of inductive generalization and practical steps for implementing the new paradigm.", "conclusion": "Advocates for restructuring research around induction and generalization, moving towards a unified effort focused on universal learning properties."}}
{"id": "2506.10954", "pdf": "https://arxiv.org/pdf/2506.10954", "abs": "https://arxiv.org/abs/2506.10954", "authors": ["Lianghong Guo", "Yanlin Wang", "Caihua Li", "Pengyu Yang", "Jiachi Chen", "Wei Tao", "Yingtian Zou", "Duyu Tang", "Zibin Zheng"], "title": "SWE-Factory: Your Automated Factory for Issue Resolution Training Data and Evaluation Benchmarks", "categories": ["cs.SE", "cs.AI"], "comment": null, "summary": "Constructing large-scale datasets for the GitHub issue resolution task is\ncrucial for both training and evaluating the software engineering capabilities\nof Large Language Models (LLMs). However, the traditional process for creating\nsuch benchmarks is notoriously challenging and labor-intensive, particularly in\nthe stages of setting up evaluation environments, grading test outcomes, and\nvalidating task instances. In this paper, we propose SWE-Factory, an automated\npipeline designed to address these challenges. To tackle these issues, our\npipeline integrates three core automated components. First, we introduce\nSWE-Builder, a multi-agent system that automates evaluation environment\nconstruction, which employs four specialized agents that work in a\ncollaborative, iterative loop and leverages an environment memory pool to\nenhance efficiency. Second, we introduce a standardized, exit-code-based\ngrading method that eliminates the need for manually writing custom parsers.\nFinally, we automate the fail2pass validation process using these reliable exit\ncode signals. Experiments on 671 issues across four programming languages show\nthat our pipeline can effectively construct valid task instances; for example,\nwith GPT-4.1-mini, our SWE-Builder constructs 269 valid instances at $0.045 per\ninstance, while with Gemini-2.5-flash, it achieves comparable performance at\nthe lowest cost of $0.024 per instance. We also demonstrate that our\nexit-code-based grading achieves 100% accuracy compared to manual inspection,\nand our automated fail2pass validation reaches a precision of 0.92 and a recall\nof 1.00. We hope our automated pipeline will accelerate the collection of\nlarge-scale, high-quality GitHub issue resolution datasets for both training\nand evaluation. Our code and datasets are released at\nhttps://github.com/DeepSoftwareAnalytics/swe-factory.", "AI": {"tldr": "SWE-Factory automates GitHub issue resolution dataset creation with SWE-Builder, exit-code-based grading, and fail2pass validation, achieving high efficiency and accuracy.", "motivation": "Traditional methods for creating GitHub issue resolution datasets are labor-intensive, requiring automation to improve efficiency and scalability.", "method": "SWE-Factory integrates SWE-Builder (multi-agent system for environment setup), exit-code-based grading, and automated fail2pass validation.", "result": "Achieves 269 valid instances at $0.045 each with GPT-4.1-mini, 100% grading accuracy, and 0.92 precision/1.00 recall in validation.", "conclusion": "SWE-Factory accelerates high-quality dataset creation for LLMs in software engineering, with released code and datasets."}}
{"id": "2502.01702", "pdf": "https://arxiv.org/pdf/2502.01702", "abs": "https://arxiv.org/abs/2502.01702", "authors": ["Christopher E. Mower", "Haitham Bou-Ammar"], "title": "Al-Khwarizmi: Discovering Physical Laws with Foundation Models", "categories": ["cs.LG"], "comment": null, "summary": "Inferring physical laws from data is a central challenge in science and\nengineering, including but not limited to healthcare, physical sciences,\nbiosciences, social sciences, sustainability, climate, and robotics. Deep\nnetworks offer high-accuracy results but lack interpretability, prompting\ninterest in models built from simple components. The Sparse Identification of\nNonlinear Dynamics (SINDy) method has become the go-to approach for building\nsuch modular and interpretable models. SINDy leverages sparse regression with\nL1 regularization to identify key terms from a library of candidate functions.\nHowever, SINDy's choice of candidate library and optimization method requires\nsignificant technical expertise, limiting its widespread applicability. This\nwork introduces Al-Khwarizmi, a novel agentic framework for physical law\ndiscovery from data, which integrates foundational models with SINDy.\nLeveraging LLMs, VLMs, and Retrieval-Augmented Generation (RAG), our approach\nautomates physical law discovery, incorporating prior knowledge and iteratively\nrefining candidate solutions via reflection. Al-Khwarizmi operates in two\nsteps: it summarizes system observations-comprising textual descriptions, raw\ndata, and plots-followed by a secondary step that generates candidate feature\nlibraries and optimizer configurations to identify hidden physics laws\ncorrectly. Evaluating our algorithm on over 198 models, we demonstrate\nstate-of-the-art performance compared to alternatives, reaching a 20 percent\nincrease against the best-performing alternative.", "AI": {"tldr": "Al-Khwarizmi automates physical law discovery using AI, outperforming SINDy by 20%.", "motivation": "Addressing the lack of interpretability in deep networks and the technical expertise required for SINDy.", "method": "Integrates LLMs, VLMs, and RAG with SINDy to automate library generation and optimization.", "result": "Achieves a 20% performance increase over alternatives in 198 models.", "conclusion": "Al-Khwarizmi offers a scalable, automated solution for interpretable physical law discovery."}}
{"id": "2506.11015", "pdf": "https://arxiv.org/pdf/2506.11015", "abs": "https://arxiv.org/abs/2506.11015", "authors": ["Barbara Oakley", "Michael Johnston", "Ken-Zen Chen", "Eulho Jung", "Terrence J. Sejnowski"], "title": "The Memory Paradox: Why Our Brains Need Knowledge in an Age of AI", "categories": ["cs.CY", "cs.AI", "cs.HC", "q-bio.NC"], "comment": "50 pages, 8 figures", "summary": "In the age of generative AI and ubiquitous digital tools, human cognition\nfaces a structural paradox: as external aids become more capable, internal\nmemory systems risk atrophy. Drawing on neuroscience and cognitive psychology,\nthis paper examines how heavy reliance on AI systems and discovery-based\npedagogies may impair the consolidation of declarative and procedural memory --\nsystems essential for expertise, critical thinking, and long-term retention. We\nreview how tools like ChatGPT and calculators can short-circuit the retrieval,\nerror correction, and schema-building processes necessary for robust neural\nencoding. Notably, we highlight striking parallels between deep learning\nphenomena such as \"grokking\" and the neuroscience of overlearning and\nintuition. Empirical studies are discussed showing how premature reliance on AI\nduring learning inhibits proceduralization and intuitive mastery. We argue that\neffective human-AI interaction depends on strong internal models -- biological\n\"schemata\" and neural manifolds -- that enable users to evaluate, refine, and\nguide AI output. The paper concludes with policy implications for education and\nworkforce training in the age of large language models.", "AI": {"tldr": "The paper explores how over-reliance on AI tools like ChatGPT and calculators may weaken human memory systems, impairing expertise and critical thinking. It draws parallels between AI phenomena (e.g., \"grokking\") and neuroscience, emphasizing the need for strong internal cognitive models to guide AI use.", "motivation": "To investigate the paradox where advanced AI tools may degrade human cognitive abilities like memory consolidation and expertise development.", "method": "The study reviews neuroscience and cognitive psychology literature, analyzing parallels between AI processes (e.g., deep learning) and human cognition. Empirical studies on AI's impact on learning are discussed.", "result": "Premature reliance on AI inhibits procedural memory and intuitive mastery, highlighting the need for robust internal cognitive models to effectively interact with AI.", "conclusion": "The paper calls for policy changes in education and workforce training to balance AI use with strengthening human cognitive systems."}}
{"id": "2412.14195", "pdf": "https://arxiv.org/pdf/2412.14195", "abs": "https://arxiv.org/abs/2412.14195", "authors": ["Roberto Daza", "Alvaro Becerra", "Ruth Cobos", "Julian Fierrez", "Aythami Morales"], "title": "A multimodal dataset for understanding the impact of mobile phones on remote online virtual education", "categories": ["cs.HC", "cs.CV"], "comment": "Article under review in the journal Scientific Data. GitHub\n  repository of the dataset at: https://github.com/BiDAlab/IMPROVE", "summary": "This work presents the IMPROVE dataset, a multimodal resource designed to\nevaluate the effects of mobile phone usage on learners during online education.\nIt includes behavioral, biometric, physiological, and academic performance data\ncollected from 120 learners divided into three groups with different levels of\nphone interaction, enabling the analysis of the impact of mobile phone usage\nand related phenomena such as nomophobia. A setup involving 16 synchronized\nsensors -- including EEG, eye tracking, video cameras, smartwatches, and\nkeystroke dynamics -- was used to monitor learner activity during 30-minute\nsessions involving educational videos, document reading, and multiple-choice\ntests. Mobile phone usage events, including both controlled interventions and\nuncontrolled interactions, were labeled by supervisors and refined through a\nsemi-supervised re-labeling process. Technical validation confirmed signal\nquality, and statistical analyses revealed biometric changes associated with\nphone usage. The dataset is publicly available for research through GitHub and\nScience Data Bank, with synchronized recordings from three platforms (edBB,\nedX, and LOGGE), provided in standard formats (.csv, .mp4, .wav, and .tsv), and\naccompanied by a detailed guide.", "AI": {"tldr": "The IMPROVE dataset evaluates mobile phone usage effects on learners during online education, using multimodal data from 120 learners and 16 synchronized sensors.", "motivation": "To analyze the impact of mobile phone usage and related phenomena like nomophobia on learners during online education.", "method": "Data collected from 120 learners divided into three groups, monitored using 16 sensors (EEG, eye tracking, etc.) during 30-minute sessions. Phone usage events were labeled and refined.", "result": "Technical validation confirmed signal quality; statistical analyses showed biometric changes linked to phone usage. Dataset is publicly available.", "conclusion": "The IMPROVE dataset provides a valuable resource for studying mobile phone usage effects in online education, with validated data and public accessibility."}}
{"id": "2502.02970", "pdf": "https://arxiv.org/pdf/2502.02970", "abs": "https://arxiv.org/abs/2502.02970", "authors": ["Muxing Li", "Zesheng Ye", "Yixuan Li", "Andy Song", "Guangquan Zhang", "Feng Liu"], "title": "Membership Inference Attack Should Move On to Distributional Statistics for Distilled Generative Models", "categories": ["cs.LG"], "comment": null, "summary": "To detect unauthorized data usage in training large-scale generative models\n(e.g., ChatGPT or Midjourney), membership inference attacks (MIA) have proven\neffective in distinguishing a single training instance (a member) from a single\nnon-training instance (a non-member). This success is mainly credited to a\nmemorization effect: models tend to perform better on a member than a\nnon-member. However, we find that standard MIAs fail against distilled\ngenerative models (i.e., student models) that are increasingly deployed in\npractice for efficiency (e.g., ChatGPT 4o-mini). Trained exclusively on data\ngenerated from a large-scale model (a teacher model), the student model lacks\ndirect exposure to any members (teacher's training data), nullifying the\nmemorization effect that standard MIAs rely on. This finding reveals a serious\nprivacy loophole, where generation-service providers could deploy a student\nmodel whose teacher was potentially trained on unauthorized data, yet claim the\ndeployed model is clean because it was not directly trained on such data.\nHence, are distilled models inherently unauditable for upstream privacy\nviolations, and should we discard them when we care about privacy? We contend\nno, as we uncover a memory chain connecting the student and teacher's member\ndata: the distribution of student-generated data aligns more closely with the\ndistribution of the teacher's members than with non-members, thus we can detect\nunauthorized data usage even when direct instance-level memorization is absent.\nThis leads us to posit that MIAs on distilled generative models should shift\nfrom instance-level scores to distribution-level statistics. We further propose\nthree principles of distribution-based MIAs for detecting unauthorized training\ndata through distilled generative models, and validate our position through an\nexemplar framework. We lastly discuss the implications of our position.", "AI": {"tldr": "Standard membership inference attacks (MIAs) fail against distilled generative models due to lack of direct memorization, but distribution-level statistics can detect unauthorized data usage.", "motivation": "To address the privacy loophole where distilled models (e.g., student models) evade detection of unauthorized training data usage, despite indirect exposure.", "method": "Propose distribution-based MIAs, shifting from instance-level scores to distribution-level statistics, and validate with an exemplar framework.", "result": "Distribution-level statistics can detect unauthorized data usage in distilled models, even without direct memorization.", "conclusion": "Distilled models are auditable for privacy violations using distribution-based MIAs, offering a viable alternative to discarding them."}}
{"id": "2506.11480", "pdf": "https://arxiv.org/pdf/2506.11480", "abs": "https://arxiv.org/abs/2506.11480", "authors": ["Shikun Li", "Shipeng Li", "Zhiqin Yang", "Xinghua Zhang", "Gaode Chen", "Xiaobo Xia", "Hengyu Liu", "Zhe Peng"], "title": "LearnAlign: Reasoning Data Selection for Reinforcement Learning in Large Language Models Based on Improved Gradient Alignment", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Reinforcement learning (RL) has become a key technique for enhancing LLMs'\nreasoning abilities, yet its data inefficiency remains a major bottleneck. To\naddress this critical yet challenging issue, we present a novel\ngradient-alignment-based method, named LearnAlign, which intelligently selects\nthe learnable and representative training reasoning data for RL post-training.\nTo overcome the issue of response-length bias in gradient norms, we introduce\nthe data learnability based on the success rate, which can indicate the\nlearning potential of each data point. Experiments across three mathematical\nreasoning benchmarks demonstrate that our method significantly reduces training\ndata requirements while achieving minor performance degradation or even\nimproving performance compared to full-data training. For example, it reduces\ndata requirements by up to 1,000 data points with better performance (77.53%)\nthan that on the full dataset on GSM8K benchmark (77.04%). Furthermore, we show\nits effectiveness in the staged RL setting. This work provides valuable\ninsights into data-efficient RL post-training and establishes a foundation for\nfuture research in optimizing reasoning data selection. To facilitate future\nwork, we will release code.", "AI": {"tldr": "LearnAlign, a gradient-alignment-based method, improves data efficiency in RL post-training for LLMs by intelligently selecting learnable reasoning data, reducing data needs while maintaining or improving performance.", "motivation": "Addressing the data inefficiency bottleneck in reinforcement learning (RL) for enhancing LLMs' reasoning abilities.", "method": "Introduces LearnAlign, which selects learnable and representative training data based on success-rate-derived learnability, overcoming response-length bias in gradient norms.", "result": "Reduces training data requirements significantly (e.g., by 1,000 points on GSM8K) with comparable or better performance (77.53% vs. 77.04%). Effective in staged RL settings.", "conclusion": "Provides insights into data-efficient RL post-training and lays groundwork for optimizing reasoning data selection. Code will be released for future research."}}
{"id": "2501.11260", "pdf": "https://arxiv.org/pdf/2501.11260", "abs": "https://arxiv.org/abs/2501.11260", "authors": ["Tuo Feng", "Wenguan Wang", "Yi Yang"], "title": "A Survey of World Models for Autonomous Driving", "categories": ["cs.RO", "cs.CV"], "comment": "Ongoing project. Paper list:\n  https://github.com/FengZicai/AwesomeWMAD; Benchmark:\n  https://github.com/FengZicai/WMAD-Benchmarks", "summary": "Recent breakthroughs in autonomous driving have been propelled by advances in\nrobust world modeling, fundamentally transforming how vehicles interpret\ndynamic scenes and execute safe decision-making. World models have emerged as a\nlinchpin technology, offering high-fidelity representations of the driving\nenvironment that integrate multi-sensor data, semantic cues, and temporal\ndynamics. This paper systematically reviews recent advances in world models for\nautonomous driving, proposing a three-tiered taxonomy: (i) Generation of Future\nPhysical World, covering Image-, BEV-, OG-, and PC-based generation methods\nthat enhance scene evolution modeling through diffusion models and 4D occupancy\nforecasting; (ii) Behavior Planning for Intelligent Agents, combining\nrule-driven and learning-based paradigms with cost map optimization and\nreinforcement learning for trajectory generation in complex traffic conditions;\n(ii) Interaction between Prediction and Planning, achieving multi-agent\ncollaborative decision-making through latent space diffusion and\nmemory-augmented architectures. The study further analyzes training paradigms,\nincluding self-supervised learning, multimodal pretraining, and generative data\naugmentation, while evaluating world models' performance in scene understanding\nand motion prediction tasks. Future research must address key challenges in\nself-supervised representation learning, long-tail scenario generation, and\nmultimodal fusion to advance the practical deployment of world models in\ncomplex urban environments. Overall, the comprehensive analysis provides a\ntechnical roadmap for harnessing the transformative potential of world models\nin advancing safe and reliable autonomous driving solutions.", "AI": {"tldr": "The paper reviews advances in world models for autonomous driving, proposing a taxonomy of generation, behavior planning, and interaction methods, and highlights future research challenges.", "motivation": "To systematically review and categorize recent advancements in world models for autonomous driving, addressing their transformative role in scene interpretation and decision-making.", "method": "Proposes a three-tiered taxonomy: (i) Future Physical World Generation, (ii) Behavior Planning for Intelligent Agents, and (iii) Interaction between Prediction and Planning, analyzing training paradigms and performance.", "result": "Identifies key advancements in scene understanding and motion prediction, while evaluating training methods like self-supervised learning and multimodal pretraining.", "conclusion": "Highlights future challenges in self-supervised learning and multimodal fusion, providing a roadmap for advancing world models in autonomous driving."}}
{"id": "2502.04818", "pdf": "https://arxiv.org/pdf/2502.04818", "abs": "https://arxiv.org/abs/2502.04818", "authors": ["Thomas Geert de Jong", "Hirofumi Notsu", "Kohei Nakajima"], "title": "Harnessing omnipresent oscillator networks as computational resource", "categories": ["cs.LG", "math.DS", "nlin.AO", "nlin.CD", "92B25", "I.2.6"], "comment": null, "summary": "Nature is pervaded with oscillatory dynamics. In networks of coupled\noscillators patterns can arise when the system synchronizes to an external\ninput. Hence, these networks provide processing and memory of input. We present\na universal framework for harnessing oscillator networks as computational\nresource. This computing framework is introduced by the ubiquitous model for\nphase-locking, the Kuramoto model. We force the Kuramoto model by a nonlinear\ntarget-system, then after substituting the target-system with a trained\nfeedback-loop it emulates the target-system. Our results are two-fold. Firstly,\nthe trained network inherits performance properties of the Kuramoto model,\nwhere all-to-all coupling is performed in linear time with respect to the\nnumber of nodes and parameters for synchronization are abundant. The latter\nimplies that the network is generically successful since the system learns via\nsychronization. Secondly, the learning capabilities of the oscillator network,\nwhich describe a type of collective intelligence, can be explained using\nKuramoto model's order parameter. In summary, this work provides the foundation\nfor utilizing nature's oscillator networks as a new class of information\nprocessing systems.", "AI": {"tldr": "A universal framework for using oscillator networks as computational resources, leveraging the Kuramoto model for synchronization and learning.", "motivation": "To harness nature's oscillatory dynamics in networks for computational processing and memory.", "method": "Force the Kuramoto model with a nonlinear target-system, replace it with a trained feedback-loop, and analyze synchronization and learning.", "result": "The network inherits Kuramoto model's efficient coupling and synchronization properties, enabling generic success and collective intelligence.", "conclusion": "Oscillator networks can serve as a new class of information processing systems, leveraging natural dynamics."}}
{"id": "2506.11618", "pdf": "https://arxiv.org/pdf/2506.11618", "abs": "https://arxiv.org/abs/2506.11618", "authors": ["Anna Soligo", "Edward Turner", "Senthooran Rajamanoharan", "Neel Nanda"], "title": "Convergent Linear Representations of Emergent Misalignment", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Fine-tuning large language models on narrow datasets can cause them to\ndevelop broadly misaligned behaviours: a phenomena known as emergent\nmisalignment. However, the mechanisms underlying this misalignment, and why it\ngeneralizes beyond the training domain, are poorly understood, demonstrating\ncritical gaps in our knowledge of model alignment. In this work, we train and\nstudy a minimal model organism which uses just 9 rank-1 adapters to emergently\nmisalign Qwen2.5-14B-Instruct. Studying this, we find that different emergently\nmisaligned models converge to similar representations of misalignment. We\ndemonstrate this convergence by extracting a 'misalignment direction' from one\nfine-tuned model's activations, and using it to effectively ablate misaligned\nbehaviour from fine-tunes using higher dimensional LoRAs and different\ndatasets. Leveraging the scalar hidden state of rank-1 LoRAs, we further\npresent a set of experiments for directly interpreting the fine-tuning\nadapters, showing that six contribute to general misalignment, while two\nspecialise for misalignment in just the fine-tuning domain. Emergent\nmisalignment is a particularly salient example of undesirable and unexpected\nmodel behaviour and by advancing our understanding of the mechanisms behind it,\nwe hope to move towards being able to better understand and mitigate\nmisalignment more generally.", "AI": {"tldr": "The paper explores emergent misalignment in fine-tuned large language models, using a minimal model to study and mitigate misalignment.", "motivation": "To understand the mechanisms behind emergent misalignment in fine-tuned models and why it generalizes beyond the training domain.", "method": "Train a minimal model with 9 rank-1 adapters to study misalignment, extract a 'misalignment direction,' and use it to ablate misaligned behavior.", "result": "Different misaligned models converge to similar representations; six adapters contribute to general misalignment, while two specialize in the fine-tuning domain.", "conclusion": "Advancing understanding of emergent misalignment can help mitigate undesirable model behavior more broadly."}}
{"id": "2502.02773", "pdf": "https://arxiv.org/pdf/2502.02773", "abs": "https://arxiv.org/abs/2502.02773", "authors": ["Hitvarth Diwanji", "Jing-Yan Liao", "Akshar Tumu", "Henrik I. Christensen", "Marcell Vazquez-Chanlatte", "Chikao Tsuchiya"], "title": "SD++: Enhancing Standard Definition Maps by Incorporating Road Knowledge using LLMs", "categories": ["cs.RO", "cs.CV"], "comment": "7 pages, 8 figures, 1 table, Accepted at IEEE Intelligent Vehicles\n  Symposium 2025", "summary": "High-definition maps (HD maps) are detailed and informative maps capturing\nlane centerlines and road elements. Although very useful for autonomous\ndriving, HD maps are costly to build and maintain. Furthermore, access to these\nhigh-quality maps is usually limited to the firms that build them. On the other\nhand, standard definition (SD) maps provide road centerlines with an accuracy\nof a few meters. In this paper, we explore the possibility of enhancing SD maps\nby incorporating information from road manuals using LLMs. We develop SD++, an\nend-to-end pipeline to enhance SD maps with location-dependent road information\nobtained from a road manual. We suggest and compare several ways of using LLMs\nfor such a task. Furthermore, we show the generalization ability of SD++ by\nshowing results from both California and Japan.", "AI": {"tldr": "The paper proposes SD++, a pipeline to enhance standard definition (SD) maps using LLMs and road manuals, addressing the cost and accessibility issues of HD maps.", "motivation": "HD maps are expensive and restricted, while SD maps lack detail. The goal is to improve SD maps affordably.", "method": "Develops SD++, an end-to-end pipeline using LLMs to incorporate road manual data into SD maps, comparing multiple LLM approaches.", "result": "Demonstrates SD++'s effectiveness with results from California and Japan, showing generalization.", "conclusion": "SD++ offers a cost-effective way to enhance SD maps, leveraging LLMs for broader accessibility and utility."}}
{"id": "2502.05075", "pdf": "https://arxiv.org/pdf/2502.05075", "abs": "https://arxiv.org/abs/2502.05075", "authors": ["Yijun Dong", "Yicheng Li", "Yunai Li", "Jason D. Lee", "Qi Lei"], "title": "Discrepancies are Virtue: Weak-to-Strong Generalization through Lens of Intrinsic Dimension", "categories": ["cs.LG", "cs.NA", "math.NA", "stat.ML"], "comment": "ICML 2025", "summary": "Weak-to-strong (W2S) generalization is a type of finetuning (FT) where a\nstrong (large) student model is trained on pseudo-labels generated by a weak\nteacher. Surprisingly, W2S FT often outperforms the weak teacher. We seek to\nunderstand this phenomenon through the observation that FT often occurs in\nintrinsically low-dimensional spaces. Leveraging the low intrinsic\ndimensionality of FT, we analyze W2S in the ridgeless regression setting from a\nvariance reduction perspective. For a strong student-weak teacher pair with\nsufficiently expressive low-dimensional feature subspaces $\\mathcal{V}_s,\n\\mathcal{V}_w$, we provide an exact characterization of the variance that\ndominates the generalization error of W2S. This unveils a virtue of discrepancy\nbetween the strong and weak models in W2S: the variance of the weak teacher is\ninherited by the strong student in $\\mathcal{V}_s \\cap \\mathcal{V}_w$, while\nreduced by a factor of $\\mathrm{dim}(\\mathcal{V}_s)/N$ in the subspace of\ndiscrepancy $\\mathcal{V}_w \\setminus \\mathcal{V}_s$ with $N$ pseudo-labels for\nW2S. Our analysis further casts light on the sample complexities and the\nscaling of performance gap recovery in W2S. The analysis is supported by\nexperiments on synthetic regression problems, as well as real vision and NLP\ntasks.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2506.12034", "pdf": "https://arxiv.org/pdf/2506.12034", "abs": "https://arxiv.org/abs/2506.12034", "authors": ["Dylan Kline"], "title": "Human-like Forgetting Curves in Deep Neural Networks", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "This study bridges cognitive science and neural network design by examining\nwhether artificial models exhibit human-like forgetting curves. Drawing upon\nEbbinghaus' seminal work on memory decay and principles of spaced repetition,\nwe propose a quantitative framework to measure information retention in neural\nnetworks. Our approach computes the recall probability by evaluating the\nsimilarity between a network's current hidden state and previously stored\nprototype representations. This retention metric facilitates the scheduling of\nreview sessions, thereby mitigating catastrophic forgetting during deployment\nand enhancing training efficiency by prompting targeted reviews. Our\nexperiments with Multi-Layer Perceptrons reveal human-like forgetting curves,\nwith knowledge becoming increasingly robust through scheduled reviews. This\nalignment between neural network forgetting curves and established human memory\nmodels identifies neural networks as an architecture that naturally emulates\nhuman memory decay and can inform state-of-the-art continual learning\nalgorithms.", "AI": {"tldr": "The study explores if neural networks show human-like forgetting curves, proposing a framework to measure retention and improve training efficiency.", "motivation": "To bridge cognitive science and neural network design by examining memory decay in artificial models.", "method": "A quantitative framework evaluates recall probability by comparing hidden states to stored prototypes, scheduling reviews to mitigate forgetting.", "result": "Experiments show neural networks exhibit human-like forgetting curves, with knowledge becoming robust through scheduled reviews.", "conclusion": "Neural networks naturally emulate human memory decay, offering insights for continual learning algorithms."}}
{"id": "2502.09507", "pdf": "https://arxiv.org/pdf/2502.09507", "abs": "https://arxiv.org/abs/2502.09507", "authors": ["Elias Kempf", "Simon Schrodi", "Max Argus", "Thomas Brox"], "title": "When and How Does CLIP Enable Domain and Compositional Generalization?", "categories": ["cs.LG", "cs.CV"], "comment": "ICML 2025 (Spotlight)", "summary": "The remarkable generalization performance of contrastive vision-language\nmodels like CLIP is often attributed to the diversity of their training\ndistributions. However, key questions remain unanswered: Can CLIP generalize to\nan entirely unseen domain when trained on a diverse mixture of domains (domain\ngeneralization)? Can it generalize to unseen classes within partially seen\ndomains (compositional generalization)? What factors affect such\ngeneralization? To answer these questions, we trained CLIP models on\nsystematically constructed training distributions with controlled domain\ndiversity and object class exposure. Our experiments show that domain diversity\nis essential for both domain and compositional generalization, yet\ncompositional generalization can be surprisingly weaker than domain\ngeneralization when the training distribution contains a suboptimal subset of\nthe test domain. Through data-centric and mechanistic analyses, we find that\nsuccessful generalization requires the learning of sufficiently shared\nrepresentations in intermediate layers and circuits.", "AI": {"tldr": "CLIP's generalization depends on domain diversity and shared representations, with compositional generalization sometimes weaker than domain generalization.", "motivation": "To understand if CLIP can generalize to unseen domains or classes and identify factors affecting such generalization.", "method": "Trained CLIP models on controlled distributions, analyzing domain diversity and class exposure.", "result": "Domain diversity is crucial for generalization, but compositional generalization can lag due to suboptimal training subsets.", "conclusion": "Successful generalization relies on shared intermediate representations and circuits."}}
{"id": "2502.06295", "pdf": "https://arxiv.org/pdf/2502.06295", "abs": "https://arxiv.org/abs/2502.06295", "authors": ["Yunchu Han", "Zhaojun Nan", "Sheng Zhou", "Zhisheng Niu"], "title": "DVFS-Aware DNN Inference on GPUs: Latency Modeling and Performance Analysis", "categories": ["cs.LG", "cs.NI"], "comment": null, "summary": "The rapid development of deep neural networks (DNNs) is inherently\naccompanied by the problem of high computational costs. To tackle this\nchallenge, dynamic voltage frequency scaling (DVFS) is emerging as a promising\ntechnology for balancing the latency and energy consumption of DNN inference by\nadjusting the computing frequency of processors. However, most existing models\nof DNN inference time are based on the CPU-DVFS technique, and directly\napplying the CPU-DVFS model to DNN inference on GPUs will lead to significant\nerrors in optimizing latency and energy consumption. In this paper, we propose\na DVFS-aware latency model to precisely characterize DNN inference time on\nGPUs. We first formulate the DNN inference time based on extensive experiment\nresults for different devices and analyze the impact of fitting parameters.\nThen by dividing DNNs into multiple blocks and obtaining the actual inference\ntime, the proposed model is further verified. Finally, we compare our proposed\nmodel with the CPU-DVFS model in two specific cases. Evaluation results\ndemonstrate that local inference optimization with our proposed model achieves\na reduction of no less than 66% and 69% in inference time and energy\nconsumption respectively. In addition, cooperative inference with our proposed\nmodel can improve the partition policy and reduce the energy consumption\ncompared to the CPU-DVFS model.", "AI": {"tldr": "Proposes a DVFS-aware latency model for DNN inference on GPUs, reducing inference time by \u226566% and energy by \u226569% compared to CPU-DVFS models.", "motivation": "Existing CPU-DVFS models are inaccurate for GPU-based DNN inference, leading to suboptimal latency and energy optimization.", "method": "Formulates DNN inference time via experiments, analyzes fitting parameters, and verifies the model by dividing DNNs into blocks.", "result": "Achieves significant reductions in inference time (\u226566%) and energy consumption (\u226569%) compared to CPU-DVFS models.", "conclusion": "The proposed GPU-specific DVFS model outperforms CPU-DVFS models, enhancing inference efficiency and energy savings."}}
{"id": "2506.12036", "pdf": "https://arxiv.org/pdf/2506.12036", "abs": "https://arxiv.org/abs/2506.12036", "authors": ["Yanting Miao", "William Loh", "Suraj Kothawade", "Pacal Poupart"], "title": "A Minimalist Method for Fine-tuning Text-to-Image Diffusion Models", "categories": ["cs.LG", "cs.AI"], "comment": "17 pages, 6 figures", "summary": "Recent work uses reinforcement learning (RL) to fine-tune text-to-image\ndiffusion models, improving text-image alignment and sample quality. However,\nexisting approaches introduce unnecessary complexity: they cache the full\nsampling trajectory, depend on differentiable reward models or large preference\ndatasets, or require specialized guidance techniques. Motivated by the \"golden\nnoise\" hypothesis -- that certain initial noise samples can consistently yield\nsuperior alignment -- we introduce Noise PPO, a minimalist RL algorithm that\nleaves the pre-trained diffusion model entirely frozen and learns a\nprompt-conditioned initial noise generator. Our approach requires no trajectory\nstorage, reward backpropagation, or complex guidance tricks. Extensive\nexperiments show that optimizing the initial noise distribution consistently\nimproves alignment and sample quality over the original model, with the most\nsignificant gains at low inference steps. As the number of inference steps\nincreases, the benefit of noise optimization diminishes but remains present.\nThese findings clarify the scope and limitations of the golden noise hypothesis\nand reinforce the practical value of minimalist RL fine-tuning for diffusion\nmodels.", "AI": {"tldr": "Noise PPO is a minimalist RL algorithm that optimizes initial noise for text-to-image diffusion models, improving alignment and quality without complex modifications.", "motivation": "Existing RL methods for fine-tuning diffusion models are overly complex, relying on trajectory storage, reward models, or large datasets. The 'golden noise' hypothesis suggests simpler optimization is possible.", "method": "Noise PPO freezes the pre-trained diffusion model and learns a prompt-conditioned initial noise generator, avoiding trajectory storage or reward backpropagation.", "result": "Noise optimization improves alignment and sample quality, especially at low inference steps, though benefits diminish with more steps.", "conclusion": "The approach validates the golden noise hypothesis and demonstrates the practicality of minimalist RL fine-tuning for diffusion models."}}
{"id": "2505.24305", "pdf": "https://arxiv.org/pdf/2505.24305", "abs": "https://arxiv.org/abs/2505.24305", "authors": ["Mingxu Zhang", "Xiaoqi Li", "Jiahui Xu", "Kaichen Zhou", "Hojin Bae", "Yan Shen", "Chuyan Xiong", "Hao Dong"], "title": "SR3D: Unleashing Single-view 3D Reconstruction for Transparent and Specular Object Grasping", "categories": ["cs.RO", "cs.CV"], "comment": null, "summary": "Recent advancements in 3D robotic manipulation have improved grasping of\neveryday objects, but transparent and specular materials remain challenging due\nto depth sensing limitations. While several 3D reconstruction and depth\ncompletion approaches address these challenges, they suffer from setup\ncomplexity or limited observation information utilization. To address this,\nleveraging the power of single view 3D object reconstruction approaches, we\npropose a training free framework SR3D that enables robotic grasping of\ntransparent and specular objects from a single view observation. Specifically,\ngiven single view RGB and depth images, SR3D first uses the external visual\nmodels to generate 3D reconstructed object mesh based on RGB image. Then, the\nkey idea is to determine the 3D object's pose and scale to accurately localize\nthe reconstructed object back into its original depth corrupted 3D scene.\nTherefore, we propose view matching and keypoint matching mechanisms,which\nleverage both the 2D and 3D's inherent semantic and geometric information in\nthe observation to determine the object's 3D state within the scene, thereby\nreconstructing an accurate 3D depth map for effective grasp detection.\nExperiments in both simulation and real world show the reconstruction\neffectiveness of SR3D.", "AI": {"tldr": "SR3D is a training-free framework for robotic grasping of transparent and specular objects using single-view RGB and depth images, leveraging 3D reconstruction and pose estimation.", "motivation": "Transparent and specular materials challenge depth sensing in robotic manipulation, and existing methods are complex or underutilize observations.", "method": "SR3D reconstructs 3D object mesh from RGB, matches pose and scale via view/keypoint matching, and reconstructs depth for grasp detection.", "result": "Effective reconstruction in simulations and real-world experiments.", "conclusion": "SR3D addresses depth sensing limitations for transparent/specular objects without training, improving robotic grasping."}}
{"id": "2502.07193", "pdf": "https://arxiv.org/pdf/2502.07193", "abs": "https://arxiv.org/abs/2502.07193", "authors": ["Long-Fei Li", "Yu-Yang Qian", "Peng Zhao", "Zhi-Hua Zhou"], "title": "Provably Efficient Online RLHF with One-Pass Reward Modeling", "categories": ["cs.LG", "stat.ML"], "comment": "The first two authors contributed equally", "summary": "Reinforcement Learning from Human Feedback (RLHF) has shown remarkable\nsuccess in aligning Large Language Models (LLMs) with human preferences.\nTraditional RLHF approaches rely on a fixed dataset, which often suffers from\nlimited coverage. To this end, online RLHF has emerged as a promising\ndirection, enabling iterative data collection and model improvement. Despite\nits potential, this paradigm faces a key bottleneck: the requirement to\ncontinuously integrate new data into the historical dataset and re-optimize the\nmodel from scratch at each iteration, resulting in computational and storage\ncosts that grow linearly with the number of iterations. In this work, we\naddress this challenge by proposing a one-pass reward modeling method that does\nnot require storing the historical data and can be computed in constant time.\nSpecifically, we first formalize RLHF as a contextual preference bandit problem\nand design an online mirror descent algorithm with a tailored local norm to\nreplace the standard maximum likelihood estimation for reward modeling. We then\napply our method to various online RLHF settings, including passive data\ncollection, active data collection, and deployment-time adaptation. We provide\ntheoretical guarantees showing that our method improves both statistical and\ncomputational efficiency. Finally, we provide practical algorithms and conduct\nexperiments using Llama-3-8B-Instruct and Qwen2.5-7B-Instruct models on the\nUltrafeedback-binarized and Mixture2 datasets, validating the effectiveness of\nour proposed method.", "AI": {"tldr": "Proposes a one-pass reward modeling method for online RLHF, eliminating the need for historical data storage and reducing computational costs.", "motivation": "Traditional RLHF relies on fixed datasets with limited coverage; online RLHF faces bottlenecks due to high computational and storage costs from iterative data integration.", "method": "Formalizes RLHF as a contextual preference bandit problem, using an online mirror descent algorithm with a tailored local norm for reward modeling.", "result": "Theoretical guarantees show improved statistical and computational efficiency; experiments on Llama-3-8B-Instruct and Qwen2.5-7B-Instruct models validate effectiveness.", "conclusion": "The proposed method addresses key challenges in online RLHF, offering a practical and efficient solution for iterative model improvement."}}
{"id": "2506.12113", "pdf": "https://arxiv.org/pdf/2506.12113", "abs": "https://arxiv.org/abs/2506.12113", "authors": ["Benjamin Marais", "Tony Quertier", "Gr\u00e9goire Barrue"], "title": "Semantic Preprocessing for LLM-based Malware Analysis", "categories": ["cs.CR", "cs.AI"], "comment": null, "summary": "In a context of malware analysis, numerous approaches rely on Artificial\nIntelligence to handle a large volume of data. However, these techniques focus\non data view (images, sequences) and not on an expert's view. Noticing this\nissue, we propose a preprocessing that focuses on expert knowledge to improve\nmalware semantic analysis and result interpretability. We propose a new\npreprocessing method which creates JSON reports for Portable Executable files.\nThese reports gather features from both static and behavioral analysis, and\nincorporate packer signature detection, MITRE ATT\\&CK and Malware Behavior\nCatalog (MBC) knowledge. The purpose of this preprocessing is to gather a\nsemantic representation of binary files, understandable by malware analysts,\nand that can enhance AI models' explainability for malicious files analysis.\nUsing this preprocessing to train a Large Language Model for Malware\nclassification, we achieve a weighted-average F1-score of 0.94 on a complex\ndataset, representative of market reality.", "AI": {"tldr": "A preprocessing method for malware analysis incorporates expert knowledge (packer signatures, MITRE ATT&CK, MBC) into JSON reports, improving semantic analysis and AI model explainability. A Large Language Model trained with this method achieves a 0.94 F1-score.", "motivation": "Existing AI-based malware analysis lacks expert-centric views, focusing only on data perspectives like images or sequences. This gap limits interpretability and semantic understanding.", "method": "Proposes a preprocessing method creating JSON reports for Portable Executable files, combining static/behavioral analysis features with expert knowledge (packer signatures, MITRE ATT&CK, MBC).", "result": "Achieves a weighted-average F1-score of 0.94 when training a Large Language Model for malware classification on a complex dataset.", "conclusion": "The preprocessing enhances malware semantic analysis and AI explainability, bridging the gap between expert knowledge and automated analysis."}}
{"id": "2506.01444", "pdf": "https://arxiv.org/pdf/2506.01444", "abs": "https://arxiv.org/abs/2506.01444", "authors": ["Sujeevan Aseervatham", "Achraf Kerzazi", "Youn\u00e8s Bennani"], "title": "Variance-Based Defense Against Blended Backdoor Attacks", "categories": ["cs.LG", "cs.CV"], "comment": "This paper has been accepted at ECML PKDD 2025", "summary": "Backdoor attacks represent a subtle yet effective class of cyberattacks\ntargeting AI models, primarily due to their stealthy nature. The model behaves\nnormally on clean data but exhibits malicious behavior only when the attacker\nembeds a specific trigger into the input. This attack is performed during the\ntraining phase, where the adversary corrupts a small subset of the training\ndata by embedding a pattern and modifying the labels to a chosen target. The\nobjective is to make the model associate the pattern with the target label\nwhile maintaining normal performance on unaltered data. Several defense\nmechanisms have been proposed to sanitize training data-sets. However, these\nmethods often rely on the availability of a clean dataset to compute\nstatistical anomalies, which may not always be feasible in real-world scenarios\nwhere datasets can be unavailable or compromised. To address this limitation,\nwe propose a novel defense method that trains a model on the given dataset,\ndetects poisoned classes, and extracts the critical part of the attack trigger\nbefore identifying the poisoned instances. This approach enhances\nexplainability by explicitly revealing the harmful part of the trigger. The\neffectiveness of our method is demonstrated through experimental evaluations on\nwell-known image datasets and comparative analysis against three\nstate-of-the-art algorithms: SCAn, ABL, and AGPD.", "AI": {"tldr": "A novel defense method against backdoor attacks in AI models is proposed, detecting poisoned classes and extracting attack triggers without needing a clean dataset.", "motivation": "Existing defenses rely on clean datasets for statistical analysis, which is often impractical in real-world scenarios.", "method": "The proposed method trains a model on the given dataset, detects poisoned classes, extracts the attack trigger, and identifies poisoned instances.", "result": "The method effectively detects backdoor attacks and outperforms state-of-the-art algorithms (SCAn, ABL, AGPD) in evaluations.", "conclusion": "The approach enhances explainability and practicality by not requiring a clean dataset, offering a robust defense against backdoor attacks."}}
{"id": "2502.13900", "pdf": "https://arxiv.org/pdf/2502.13900", "abs": "https://arxiv.org/abs/2502.13900", "authors": ["Antoine Moulin", "Gergely Neu", "Luca Viano"], "title": "Optimistically Optimistic Exploration for Provably Efficient Infinite-Horizon Reinforcement and Imitation Learning", "categories": ["cs.LG"], "comment": null, "summary": "We study the problem of reinforcement learning in infinite-horizon discounted\nlinear Markov decision processes (MDPs), and propose the first computationally\nefficient algorithm achieving rate-optimal regret guarantees in this setting.\nOur main idea is to combine two classic techniques for optimistic exploration:\nadditive exploration bonuses applied to the reward function, and artificial\ntransitions made to an absorbing state with maximal return. We show that,\ncombined with a regularized approximate dynamic-programming scheme, the\nresulting algorithm achieves a regret of order $\\tilde{\\mathcal{O}} (\\sqrt{d^3\n(1 - \\gamma)^{- 7 / 2} T})$, where $T$ is the total number of sample\ntransitions, $\\gamma \\in (0,1)$ is the discount factor, and $d$ is the feature\ndimensionality. The results continue to hold against adversarial reward\nsequences, enabling application of our method to the problem of imitation\nlearning in linear MDPs, where we achieve state-of-the-art results.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2506.12220", "pdf": "https://arxiv.org/pdf/2506.12220", "abs": "https://arxiv.org/abs/2506.12220", "authors": ["Hantao Yu", "Josh Alman"], "title": "Two Heads Are Better than One: Simulating Large Transformers with Small Ones", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "The quadratic complexity of self-attention prevents transformers from scaling\neffectively to long input sequences. On the other hand, modern GPUs and other\nspecialized hardware accelerators are well-optimized for processing small input\nsequences in transformers during both training and inference. A natural\nquestion arises: can we take advantage of the efficiency of small transformers\nto deal with long input sequences?\n  In this paper, we show that transformers with long input sequences (large\ntransformers) can be efficiently simulated by transformers that can only take\nshort input sequences (small transformers). Specifically, we prove that any\ntransformer with input length $N$ can be efficiently simulated by only\n$O((N/M)^2)$ transformers with input length $M \\ll N$, and that this cannot be\nimproved in the worst case. However, we then prove that in various natural\nscenarios including average-case inputs, sliding window masking and attention\nsinks, the optimal number $O(N/M)$ of small transformers suffice.", "AI": {"tldr": "The paper proposes simulating large transformers with long input sequences using multiple small transformers, reducing complexity from O(N\u00b2) to O((N/M)\u00b2) or O(N/M) in natural scenarios.", "motivation": "The quadratic complexity of self-attention in transformers limits scalability for long sequences, while hardware is optimized for small sequences. The goal is to leverage small transformers' efficiency for long sequences.", "method": "The authors prove that a transformer with input length N can be simulated by O((N/M)\u00b2) small transformers (input length M \u226a N), with O(N/M) sufficing in natural cases like average inputs or attention sinks.", "result": "Theoretical results show worst-case complexity is O((N/M)\u00b2), but practical scenarios reduce this to O(N/M).", "conclusion": "Small transformers can efficiently simulate large ones, offering a scalable solution for long sequences with hardware-friendly implementations."}}
{"id": "2506.13045", "pdf": "https://arxiv.org/pdf/2506.13045", "abs": "https://arxiv.org/abs/2506.13045", "authors": ["Haiyang Guo", "Fanhu Zeng", "Fei Zhu", "Jiayi Wang", "Xukai Wang", "Jingang Zhou", "Hongbo Zhao", "Wenzhuo Liu", "Shijie Ma", "Da-Han Wang", "Xu-Yao Zhang", "Cheng-Lin Liu"], "title": "A Comprehensive Survey on Continual Learning in Generative Models", "categories": ["cs.LG", "cs.CV"], "comment": "Preprint", "summary": "The rapid advancement of generative models has enabled modern AI systems to\ncomprehend and produce highly sophisticated content, even achieving human-level\nperformance in specific domains. However, these models remain fundamentally\nconstrained by catastrophic forgetting - a persistent challenge where adapting\nto new tasks typically leads to significant degradation in performance on\npreviously learned tasks. To address this practical limitation, numerous\napproaches have been proposed to enhance the adaptability and scalability of\ngenerative models in real-world applications. In this work, we present a\ncomprehensive survey of continual learning methods for mainstream generative\nmodels, including large language models, multimodal large language models,\nvision language action models, and diffusion models. Drawing inspiration from\nthe memory mechanisms of the human brain, we systematically categorize these\napproaches into three paradigms: architecture-based, regularization-based, and\nreplay-based methods, while elucidating their underlying methodologies and\nmotivations. We further analyze continual learning setups for different\ngenerative models, including training objectives, benchmarks, and core\nbackbones, offering deeper insights into the field. The project page of this\npaper is available at\nhttps://github.com/Ghy0501/Awesome-Continual-Learning-in-Generative-Models.", "AI": {"tldr": "A survey of continual learning methods for generative models, addressing catastrophic forgetting by categorizing approaches into architecture-based, regularization-based, and replay-based paradigms.", "motivation": "To overcome the challenge of catastrophic forgetting in generative models, which hampers adaptability and scalability in real-world applications.", "method": "Systematic categorization of continual learning methods into three paradigms, analyzing methodologies, motivations, and setups for various generative models.", "result": "Provides insights into training objectives, benchmarks, and core backbones for continual learning in generative models.", "conclusion": "The survey offers a comprehensive overview and deeper understanding of continual learning techniques for generative models, aiding future research and applications."}}
{"id": "2502.14259", "pdf": "https://arxiv.org/pdf/2502.14259", "abs": "https://arxiv.org/abs/2502.14259", "authors": ["Sujeong Im", "Jungwoo Oh", "Edward Choi"], "title": "LabTOP: A Unified Model for Lab Test Outcome Prediction on Electronic Health Records", "categories": ["cs.LG"], "comment": "11 pages for main text, 13 pages for appendix", "summary": "Lab tests are fundamental for diagnosing diseases and monitoring patient\nconditions. However, frequent testing can be burdensome for patients, and test\nresults may not always be immediately available. To address these challenges,\nwe propose LabTOP, a unified model that predicts lab test outcomes by\nleveraging a language modeling approach on EHR data. Unlike conventional\nmethods that estimate only a subset of lab tests or classify discrete value\nranges, LabTOP performs continuous numerical predictions for a diverse range of\nlab items. We evaluate LabTOP on three publicly available EHR datasets and\ndemonstrate that it outperforms existing methods, including traditional machine\nlearning models and state-of-the-art large language models. We also conduct\nextensive ablation studies to confirm the effectiveness of our design choices.\nWe believe that LabTOP will serve as an accurate and generalizable framework\nfor lab test outcome prediction, with potential applications in clinical\ndecision support and early detection of critical conditions.", "AI": {"tldr": "LabTOP is a unified model using language modeling on EHR data to predict lab test outcomes, outperforming existing methods.", "motivation": "Frequent lab testing is burdensome for patients, and results may not be immediately available. LabTOP aims to address these challenges.", "method": "LabTOP uses a language modeling approach on EHR data to perform continuous numerical predictions for diverse lab tests.", "result": "LabTOP outperforms traditional machine learning models and large language models on three EHR datasets.", "conclusion": "LabTOP is an accurate, generalizable framework for lab test prediction, useful for clinical decision support and early detection."}}
{"id": "2506.12322", "pdf": "https://arxiv.org/pdf/2506.12322", "abs": "https://arxiv.org/abs/2506.12322", "authors": ["Johnny Peng", "Thanh Tung Khuat", "Katarzyna Musial", "Bogdan Gabrys"], "title": "Machine Learning Methods for Small Data and Upstream Bioprocessing Applications: A Comprehensive Review", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Data is crucial for machine learning (ML) applications, yet acquiring large\ndatasets can be costly and time-consuming, especially in complex,\nresource-intensive fields like biopharmaceuticals. A key process in this\nindustry is upstream bioprocessing, where living cells are cultivated and\noptimised to produce therapeutic proteins and biologics. The intricate nature\nof these processes, combined with high resource demands, often limits data\ncollection, resulting in smaller datasets. This comprehensive review explores\nML methods designed to address the challenges posed by small data and\nclassifies them into a taxonomy to guide practical applications. Furthermore,\neach method in the taxonomy was thoroughly analysed, with a detailed discussion\nof its core concepts and an evaluation of its effectiveness in tackling small\ndata challenges, as demonstrated by application results in the upstream\nbioprocessing and other related domains. By analysing how these methods tackle\nsmall data challenges from different perspectives, this review provides\nactionable insights, identifies current research gaps, and offers guidance for\nleveraging ML in data-constrained environments.", "AI": {"tldr": "A review of ML methods for small datasets in upstream bioprocessing, classifying them into a taxonomy and evaluating their effectiveness.", "motivation": "Data scarcity in resource-intensive fields like biopharmaceuticals limits ML applications, necessitating methods for small datasets.", "method": "Comprehensive review and classification of ML methods into a taxonomy, with analysis of core concepts and effectiveness.", "result": "Identified actionable insights, research gaps, and guidance for ML in data-constrained environments.", "conclusion": "The review aids in leveraging ML for small datasets in upstream bioprocessing and related domains."}}
{"id": "2502.15240", "pdf": "https://arxiv.org/pdf/2502.15240", "abs": "https://arxiv.org/abs/2502.15240", "authors": ["Piyushi Manupriya", "Himanshu", "SakethaNath Jagarlapudi", "Ganesh Ghalme"], "title": "Multi-agent Multi-armed Bandits with Minimum Reward Guarantee Fairness", "categories": ["cs.LG", "cs.SY", "eess.SY"], "comment": null, "summary": "We investigate the problem of maximizing social welfare while ensuring\nfairness in a multi-agent multi-armed bandit (MA-MAB) setting. In this problem,\na centralized decision-maker takes actions over time, generating random rewards\nfor various agents. Our goal is to maximize the sum of expected cumulative\nrewards, a.k.a. social welfare, while ensuring that each agent receives an\nexpected reward that is at least a constant fraction of the maximum possible\nexpected reward.\n  Our proposed algorithm, RewardFairUCB, leverages the Upper Confidence Bound\n(UCB) technique to achieve sublinear regret bounds for both fairness and social\nwelfare. The fairness regret measures the positive difference between the\nminimum reward guarantee and the expected reward of a given policy, whereas the\nsocial welfare regret measures the difference between the social welfare of the\noptimal fair policy and that of the given policy.\n  We show that RewardFairUCB algorithm achieves instance-independent social\nwelfare regret guarantees of $\\tilde{O}(T^{1/2})$ and a fairness regret upper\nbound of $\\tilde{O}(T^{3/4})$. We also give the lower bound of\n$\\Omega(\\sqrt{T})$ for both social welfare and fairness regret. We evaluate\nRewardFairUCB's performance against various baseline and heuristic algorithms\nusing simulated data and real world data, highlighting trade-offs between\nfairness and social welfare regrets.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2506.12708", "pdf": "https://arxiv.org/pdf/2506.12708", "abs": "https://arxiv.org/abs/2506.12708", "authors": ["Pengfei Zuo", "Huimin Lin", "Junbo Deng", "Nan Zou", "Xingkun Yang", "Yingyu Diao", "Weifeng Gao", "Ke Xu", "Zhangyu Chen", "Shirui Lu", "Zhao Qiu", "Peiyang Li", "Xianyu Chang", "Zhengzhong Yu", "Fangzheng Miao", "Jia Zheng", "Ying Li", "Yuan Feng", "Bei Wang", "Zaijian Zong", "Mosong Zhou", "Wenli Zhou", "Houjiang Chen", "Xingyu Liao", "Yipeng Li", "Wenxiao Zhang", "Ping Zhu", "Yinggang Wang", "Chuanjie Xiao", "Depeng Liang", "Dong Cao", "Juncheng Liu", "Yongqiang Yang", "Xiaolong Bai", "Yi Li", "Huaguo Xie", "Huatao Wu", "Zhibin Yu", "Lv Chen", "Hu Liu", "Yujun Ding", "Haipei Zhu", "Jing Xia", "Yi Xiong", "Zhou Yu", "Heng Liao"], "title": "Serving Large Language Models on Huawei CloudMatrix384", "categories": ["cs.DC", "cs.AI", "cs.AR", "cs.LG"], "comment": "59 pages, 24 figures", "summary": "The rapid evolution of large language models (LLMs), driven by growing\nparameter scales, adoption of mixture-of-experts (MoE) architectures, and\nexpanding context lengths, imposes unprecedented demands on AI infrastructure.\nTraditional AI clusters face limitations in compute intensity, memory\nbandwidth, inter-chip communication, and latency, compounded by variable\nworkloads and strict service-level objectives. Addressing these issues requires\nfundamentally redesigned hardware-software integration. This paper introduces\nHuawei CloudMatrix, a next-generation AI datacenter architecture, realized in\nthe production-grade CloudMatrix384 supernode. It integrates 384 Ascend 910\nNPUs and 192 Kunpeng CPUs interconnected via an ultra-high-bandwidth Unified\nBus (UB) network, enabling direct all-to-all communication and dynamic pooling\nof resources. These features optimize performance for communication-intensive\noperations, such as large-scale MoE expert parallelism and distributed\nkey-value cache access. To fully leverage CloudMatrix384, we propose\nCloudMatrix-Infer, an advanced LLM serving solution incorporating three core\ninnovations: a peer-to-peer serving architecture that independently scales\nprefill, decode, and caching; a large-scale expert parallelism strategy\nsupporting EP320 via efficient UB-based token dispatch; and hardware-aware\noptimizations including specialized operators, microbatch-based pipelining, and\nINT8 quantization. Evaluation with the DeepSeek-R1 model shows\nCloudMatrix-Infer achieves state-of-the-art efficiency: prefill throughput of\n6,688 tokens/s per NPU and decode throughput of 1,943 tokens/s per NPU (<50 ms\nTPOT). It effectively balances throughput and latency, sustaining 538 tokens/s\nper NPU even under stringent 15 ms latency constraints, while INT8 quantization\nmaintains model accuracy across benchmarks.", "AI": {"tldr": "Huawei CloudMatrix introduces a next-gen AI datacenter architecture (CloudMatrix384) and CloudMatrix-Infer, an advanced LLM serving solution, achieving high efficiency and performance for large-scale AI workloads.", "motivation": "Addressing the limitations of traditional AI clusters in compute intensity, memory bandwidth, and communication for evolving LLMs.", "method": "Integration of 384 Ascend 910 NPUs and 192 Kunpeng CPUs with a Unified Bus network, plus CloudMatrix-Infer's peer-to-peer serving, expert parallelism, and hardware optimizations.", "result": "State-of-the-art efficiency: 6,688 tokens/s prefill and 1,943 tokens/s decode per NPU, with balanced throughput-latency under constraints.", "conclusion": "CloudMatrix and CloudMatrix-Infer provide a scalable, high-performance solution for modern AI infrastructure demands."}}
{"id": "2502.15988", "pdf": "https://arxiv.org/pdf/2502.15988", "abs": "https://arxiv.org/abs/2502.15988", "authors": ["Varun Babbar", "Hayden McTavish", "Cynthia Rudin", "Margo Seltzer"], "title": "Near Optimal Decision Trees in a SPLIT Second", "categories": ["cs.LG"], "comment": "Accepted to ICML 2025 (Oral)", "summary": "Decision tree optimization is fundamental to interpretable machine learning.\nThe most popular approach is to greedily search for the best feature at every\ndecision point, which is fast but provably suboptimal. Recent approaches find\nthe global optimum using branch and bound with dynamic programming, showing\nsubstantial improvements in accuracy and sparsity at great cost to scalability.\nAn ideal solution would have the accuracy of an optimal method and the\nscalability of a greedy method. We introduce a family of algorithms called\nSPLIT (SParse Lookahead for Interpretable Trees) that moves us significantly\nforward in achieving this ideal balance. We demonstrate that not all\nsub-problems need to be solved to optimality to find high quality trees;\ngreediness suffices near the leaves. Since each depth adds an exponential\nnumber of possible trees, this change makes our algorithms orders of magnitude\nfaster than existing optimal methods, with negligible loss in performance. We\nextend this algorithm to allow scalable computation of sets of near-optimal\ntrees (i.e., the Rashomon set).", "AI": {"tldr": "SPLIT algorithms balance accuracy and scalability in decision tree optimization by combining optimal and greedy methods, focusing on solving sub-problems near the leaves.", "motivation": "Current methods for decision tree optimization are either fast but suboptimal (greedy) or accurate but slow (global optimum). The goal is to achieve both accuracy and scalability.", "method": "Introduces SPLIT algorithms, which use sparse lookahead to solve sub-problems optimally near the root and greedily near the leaves, improving scalability without significant performance loss.", "result": "SPLIT algorithms are orders of magnitude faster than optimal methods with negligible performance loss, and they enable scalable computation of near-optimal tree sets.", "conclusion": "SPLIT achieves a balance between accuracy and scalability, advancing interpretable machine learning by efficiently producing high-quality decision trees."}}
{"id": "2506.13205", "pdf": "https://arxiv.org/pdf/2506.13205", "abs": "https://arxiv.org/abs/2506.13205", "authors": ["Xuan Wang", "Siyuan Liang", "Zhe Liu", "Yi Yu", "Yuliang Lu", "Xiaochun Cao", "Ee-Chien Chang"], "title": "Screen Hijack: Visual Poisoning of VLM Agents in Mobile Environments", "categories": ["cs.CR", "cs.AI"], "comment": "12 pages", "summary": "With the growing integration of vision-language models (VLMs), mobile agents\nare now widely used for tasks like UI automation and camera-based user\nassistance. These agents are often fine-tuned on limited user-generated\ndatasets, leaving them vulnerable to covert threats during the training\nprocess. In this work we present GHOST, the first clean-label backdoor attack\nspecifically designed for mobile agents built upon VLMs. Our method manipulates\nonly the visual inputs of a portion of the training samples - without altering\ntheir corresponding labels or instructions - thereby injecting malicious\nbehaviors into the model. Once fine-tuned with this tampered data, the agent\nwill exhibit attacker-controlled responses when a specific visual trigger is\nintroduced at inference time. The core of our approach lies in aligning the\ngradients of poisoned samples with those of a chosen target instance, embedding\nbackdoor-relevant features into the poisoned training data. To maintain stealth\nand enhance robustness, we develop three realistic visual triggers: static\nvisual patches, dynamic motion cues, and subtle low-opacity overlays. We\nevaluate our method across six real-world Android apps and three VLM\narchitectures adapted for mobile use. Results show that our attack achieves\nhigh attack success rates (up to 94.67 percent) while maintaining high\nclean-task performance (FSR up to 95.85 percent). Additionally, ablation\nstudies shed light on how various design choices affect the efficacy and\nconcealment of the attack. Overall, this work is the first to expose critical\nsecurity flaws in VLM-based mobile agents, highlighting their susceptibility to\nclean-label backdoor attacks and the urgent need for effective defense\nmechanisms in their training pipelines.", "AI": {"tldr": "GHOST is a clean-label backdoor attack for VLM-based mobile agents, manipulating visual inputs to inject malicious behaviors without altering labels, achieving high attack success and clean-task performance.", "motivation": "Mobile agents using VLMs are vulnerable to covert threats during training due to reliance on limited datasets, exposing security flaws.", "method": "GHOST aligns gradients of poisoned samples with target instances, using static patches, dynamic cues, or subtle overlays as triggers.", "result": "Achieves up to 94.67% attack success and 95.85% clean-task performance across real-world apps and VLM architectures.", "conclusion": "Exposes critical security flaws in VLM-based mobile agents, emphasizing the need for defenses against clean-label backdoor attacks."}}
{"id": "2502.17371", "pdf": "https://arxiv.org/pdf/2502.17371", "abs": "https://arxiv.org/abs/2502.17371", "authors": ["Emiliano Seri", "Marcello Petitta", "Chryssoula Papaioannou", "Nikolaos Katsoulas", "Cristina Cornaro"], "title": "Sustainable Greenhouse Microclimate Modeling: A Comparative Analysis of Recurrent and Graph Neural Networks", "categories": ["cs.LG", "stat.AP"], "comment": null, "summary": "The integration of photovoltaic (PV) systems into greenhouses not only\noptimizes land use but also enhances sustainable agricultural practices by\nenabling dual benefits of food production and renewable energy generation.\nHowever, accurate prediction of internal environmental conditions is crucial to\nensure optimal crop growth while maximizing energy production. This study\nintroduces a novel application of Spatio-Temporal Graph Neural Networks\n(STGNNs) to greenhouse microclimate modeling, comparing their performance with\ntraditional Recurrent Neural Networks (RNNs). While RNNs excel at temporal\npattern recognition, they cannot explicitly model the directional relationships\nbetween environmental variables. Our STGNN approach addresses this limitation\nby representing these relationships as directed graphs, enabling the model to\ncapture both environmental dependencies and their directionality. We benchmark\nRNNs against directed STGNNs on two 15-min-resolution datasets from Volos\n(Greece): a six-variable 2020 installation and a more complex eight-variable\ngreenhouse monitored in autumn 2024. In the simpler 2020 case the RNN attains\nnear-perfect accuracy, outperforming the STGNN. When additional drivers are\navailable in 2024, the STGNN overtakes the RNN ($R^{2}=0.905$ vs $0.740$),\ndemonstrating that explicitly modelling directional dependencies becomes\ncritical as interaction complexity grows. These findings indicate when\ngraph-based models are warranted and provide a stepping-stone toward digital\ntwins that jointly optimise crop yield and PV power in agrivoltaic greenhouses.", "AI": {"tldr": "The paper explores using Spatio-Temporal Graph Neural Networks (STGNNs) for greenhouse microclimate modeling, showing their advantage over RNNs in complex environments.", "motivation": "Accurate prediction of greenhouse conditions is vital for optimizing both crop growth and renewable energy production in agrivoltaic systems.", "method": "The study compares STGNNs and RNNs using datasets from two greenhouses, analyzing performance based on variable complexity.", "result": "STGNNs outperform RNNs in complex scenarios (R\u00b2=0.905 vs. 0.740), while RNNs excel in simpler setups.", "conclusion": "Graph-based models like STGNNs are crucial for complex environments, paving the way for digital twins in agrivoltaic greenhouses."}}
{"id": "2506.13751", "pdf": "https://arxiv.org/pdf/2506.13751", "abs": "https://arxiv.org/abs/2506.13751", "authors": ["Haoru Xue", "Xiaoyu Huang", "Dantong Niu", "Qiayuan Liao", "Thomas Kragerud", "Jan Tommy Gravdahl", "Xue Bin Peng", "Guanya Shi", "Trevor Darrell", "Koushil Screenath", "Shankar Sastry"], "title": "LeVERB: Humanoid Whole-Body Control with Latent Vision-Language Instruction", "categories": ["cs.RO", "cs.AI"], "comment": "https://ember-lab-berkeley.github.io/LeVERB-Website/", "summary": "Vision-language-action (VLA) models have demonstrated strong semantic\nunderstanding and zero-shot generalization, yet most existing systems assume an\naccurate low-level controller with hand-crafted action \"vocabulary\" such as\nend-effector pose or root velocity. This assumption confines prior work to\nquasi-static tasks and precludes the agile, whole-body behaviors required by\nhumanoid whole-body control (WBC) tasks. To capture this gap in the literature,\nwe start by introducing the first sim-to-real-ready, vision-language,\nclosed-loop benchmark for humanoid WBC, comprising over 150 tasks from 10\ncategories. We then propose LeVERB: Latent Vision-Language-Encoded Robot\nBehavior, a hierarchical latent instruction-following framework for humanoid\nvision-language WBC, the first of its kind. At the top level, a vision-language\npolicy learns a latent action vocabulary from synthetically rendered kinematic\ndemonstrations; at the low level, a reinforcement-learned WBC policy consumes\nthese latent verbs to generate dynamics-level commands. In our benchmark,\nLeVERB can zero-shot attain a 80% success rate on simple visual navigation\ntasks, and 58.5% success rate overall, outperforming naive hierarchical\nwhole-body VLA implementation by 7.8 times.", "AI": {"tldr": "LeVERB introduces a hierarchical framework for humanoid vision-language-action tasks, outperforming naive methods by 7.8 times in success rates.", "motivation": "Existing VLA models rely on low-level controllers with hand-crafted actions, limiting them to quasi-static tasks and excluding agile humanoid behaviors.", "method": "LeVERB uses a hierarchical approach: a vision-language policy learns latent actions from synthetic demonstrations, while a low-level WBC policy generates dynamics-level commands.", "result": "LeVERB achieves 80% success in simple tasks and 58.5% overall, significantly outperforming baseline methods.", "conclusion": "LeVERB bridges the gap in humanoid WBC tasks, demonstrating strong zero-shot generalization and performance."}}
{"id": "2503.15190", "pdf": "https://arxiv.org/pdf/2503.15190", "abs": "https://arxiv.org/abs/2503.15190", "authors": ["Mohamed Hassouna", "Clara Holzh\u00fcter", "Malte Lehna", "Matthijs de Jong", "Jan Viebahn", "Bernhard Sick", "Christoph Scholz"], "title": "Learning Topology Actions for Power Grid Control: A Graph-Based Soft-Label Imitation Learning Approach", "categories": ["cs.LG"], "comment": "Accepted at European Conference on Machine Learning and Principles\n  and Practice of Knowledge Discovery in Databases (ECML) - Applied Data\n  Science Track", "summary": "The rising proportion of renewable energy in the electricity mix introduces\nsignificant operational challenges for power grid operators. Effective power\ngrid management demands adaptive decision-making strategies capable of handling\ndynamic conditions. With the increase in complexity, more and more Deep\nLearning (DL) approaches have been proposed to find suitable grid topologies\nfor congestion management. In this work, we contribute to this research by\nintroducing a novel Imitation Learning (IL) approach that leverages soft labels\nderived from simulated topological action outcomes, thereby capturing multiple\nviable actions per state. Unlike traditional IL methods that rely on hard\nlabels to enforce a single optimal action, our method constructs soft labels\nthat capture the effectiveness of actions that prove suitable in resolving grid\ncongestion. To further enhance decision-making, we integrate Graph Neural\nNetworks (GNNs) to encode the structural properties of power grids, ensuring\nthat the topology-aware representations contribute to better agent performance.\nOur approach significantly outperforms its hard-label counterparts as well as\nstate-of-the-art Deep Reinforcement Learning (DRL) baseline agents. Most\nnotably, it achieves a 17% better performance compared to the greedy expert\nagent from which the imitation targets were derived.", "AI": {"tldr": "A novel Imitation Learning (IL) approach using soft labels and Graph Neural Networks (GNNs) improves power grid congestion management, outperforming traditional methods by 17%.", "motivation": "Addressing the operational challenges of renewable energy integration in power grids requires adaptive decision-making strategies.", "method": "Proposes an IL method with soft labels from simulated topological actions and integrates GNNs for topology-aware representations.", "result": "Outperforms hard-label IL and Deep Reinforcement Learning baselines, achieving 17% better performance than the expert agent.", "conclusion": "The approach enhances grid management by capturing multiple viable actions and leveraging structural properties of power grids."}}
{"id": "2506.14777", "pdf": "https://arxiv.org/pdf/2506.14777", "abs": "https://arxiv.org/abs/2506.14777", "authors": ["Jules Leguy", "Pierre-Antoine Jean", "Felipe Torres Figueroa", "S\u00e9bastien Harispe"], "title": "WebXAII: an open-source web framework to study human-XAI interaction", "categories": ["cs.HC", "cs.AI", "cs.LG"], "comment": null, "summary": "This article introduces WebXAII, an open-source web framework designed to\nfacilitate research on human interaction with eXplainable Artificial\nIntelligence (XAI) systems. The field of XAI is rapidly expanding, driven by\nthe growing societal implications of the widespread adoption of AI (and in\nparticular machine learning) across diverse applications. Researchers who study\nthe interaction between humans and XAI techniques typically develop ad hoc\ninterfaces in order to conduct their studies. These interfaces are usually not\nshared alongside the results of the studies, which limits their reusability and\nthe reproducibility of experiments. In response, we design and implement\nWebXAII, a web-based platform that can embody full experimental protocols,\nmeaning that it can present all aspects of the experiment to human participants\nand record their responses. The experimental protocols are translated into a\ncomposite architecture of generic views and modules, which offers a lot of\nflexibility. The architecture is defined in a structured configuration file, so\nthat protocols can be implemented with minimal programming skills. We\ndemonstrate that WebXAII can effectively embody relevant protocols, by\nreproducing the protocol of a state-of-the-art study of the literature.", "AI": {"tldr": "WebXAII is an open-source web framework for studying human interaction with XAI systems, addressing reproducibility and reusability issues in research.", "motivation": "The rapid expansion of XAI and the lack of shared interfaces for human-XAI interaction studies motivated the creation of WebXAII.", "method": "WebXAII is a web-based platform with a composite architecture of generic views and modules, defined via structured configuration files for easy protocol implementation.", "result": "WebXAII successfully reproduced a state-of-the-art study protocol, demonstrating its effectiveness.", "conclusion": "WebXAII provides a flexible, reusable solution for human-XAI interaction research, enhancing reproducibility and accessibility."}}
{"id": "2503.19549", "pdf": "https://arxiv.org/pdf/2503.19549", "abs": "https://arxiv.org/abs/2503.19549", "authors": ["Zubair Shaban", "Nazreen Shah", "Ranjitha Prasad"], "title": "Noise Resilient Over-The-Air Federated Learning In Heterogeneous Wireless Networks", "categories": ["cs.LG", "eess.SP"], "comment": null, "summary": "In 6G wireless networks, Artificial Intelligence (AI)-driven applications\ndemand the adoption of Federated Learning (FL) to enable efficient and\nprivacy-preserving model training across distributed devices. Over-The-Air\nFederated Learning (OTA-FL) exploits the superposition property of multiple\naccess channels, allowing edge users in 6G networks to efficiently share\nspectral resources and perform low-latency global model aggregation. However,\nthese advantages come with challenges, as traditional OTA-FL techniques suffer\ndue to the joint effects of Additive White Gaussian Noise (AWGN) at the server,\nfading, and both data and system heterogeneity at the participating edge\ndevices. In this work, we propose the novel Noise Resilient Over-the-Air\nFederated Learning (NoROTA-FL) framework to jointly tackle these challenges in\nfederated wireless networks. In NoROTA-FL, the local optimization problems find\ncontrolled inexact solutions, which manifests as an additional proximal\nconstraint at the clients. This approach provides robustness against\nstraggler-induced partial work, heterogeneity, noise, and fading. From a\ntheoretical perspective, we leverage the zeroth- and first-order inexactness\nand establish convergence guarantees for non-convex optimization problems in\nthe presence of heterogeneous data and varying system capabilities.\nExperimentally, we validate NoROTA-FL on real-world datasets, including\nFEMNIST, CIFAR10, and CIFAR100, demonstrating its robustness in noisy and\nheterogeneous environments. Compared to state-of-the-art baselines such as\nCOTAF and FedProx, NoROTA-FL achieves significantly more stable convergence and\nhigher accuracy, particularly in the presence of stragglers.", "AI": {"tldr": "The paper introduces NoROTA-FL, a noise-resilient framework for federated learning in 6G networks, addressing challenges like noise, fading, and heterogeneity. It outperforms existing methods in stability and accuracy.", "motivation": "AI-driven applications in 6G networks require efficient, privacy-preserving federated learning, but traditional OTA-FL suffers from noise, fading, and heterogeneity issues.", "method": "Proposes NoROTA-FL, which uses controlled inexact solutions with proximal constraints to handle noise, stragglers, and heterogeneity, backed by theoretical convergence guarantees.", "result": "NoROTA-FL shows robust performance on real-world datasets (FEMNIST, CIFAR10, CIFAR100), achieving stable convergence and higher accuracy than COTAF and FedProx.", "conclusion": "NoROTA-FL effectively addresses key challenges in federated wireless networks, offering a practical solution for noisy and heterogeneous environments."}}
{"id": "2506.15626", "pdf": "https://arxiv.org/pdf/2506.15626", "abs": "https://arxiv.org/abs/2506.15626", "authors": ["Vincent Roca", "Marc Tommasi", "Paul Andrey", "Aur\u00e9lien Bellet", "Markus D. Schirmer", "Hilde Henon", "Laurent Puy", "Julien Ramon", "Gr\u00e9gory Kuchcinski", "Martin Bretzner", "Renaud Lopes"], "title": "Federated Learning for MRI-based BrainAGE: a multicenter study on post-stroke functional outcome prediction", "categories": ["cs.LG", "cs.AI", "cs.DC"], "comment": null, "summary": "$\\textbf{Objective:}$ Brain-predicted age difference (BrainAGE) is a\nneuroimaging biomarker reflecting brain health. However, training robust\nBrainAGE models requires large datasets, often restricted by privacy concerns.\nThis study evaluates the performance of federated learning (FL) for BrainAGE\nestimation in ischemic stroke patients treated with mechanical thrombectomy,\nand investigates its association with clinical phenotypes and functional\noutcomes.\n  $\\textbf{Methods:}$ We used FLAIR brain images from 1674 stroke patients\nacross 16 hospital centers. We implemented standard machine learning and deep\nlearning models for BrainAGE estimates under three data management strategies:\ncentralized learning (pooled data), FL (local training at each site), and\nsingle-site learning. We reported prediction errors and examined associations\nbetween BrainAGE and vascular risk factors (e.g., diabetes mellitus,\nhypertension, smoking), as well as functional outcomes at three months\npost-stroke. Logistic regression evaluated BrainAGE's predictive value for\nthese outcomes, adjusting for age, sex, vascular risk factors, stroke severity,\ntime between MRI and arterial puncture, prior intravenous thrombolysis, and\nrecanalisation outcome.\n  $\\textbf{Results:}$ While centralized learning yielded the most accurate\npredictions, FL consistently outperformed single-site models. BrainAGE was\nsignificantly higher in patients with diabetes mellitus across all models.\nComparisons between patients with good and poor functional outcomes, and\nmultivariate predictions of these outcomes showed the significance of the\nassociation between BrainAGE and post-stroke recovery.\n  $\\textbf{Conclusion:}$ FL enables accurate age predictions without data\ncentralization. The strong association between BrainAGE, vascular risk factors,\nand post-stroke recovery highlights its potential for prognostic modeling in\nstroke care.", "AI": {"tldr": "Federated learning (FL) is effective for BrainAGE estimation in stroke patients, outperforming single-site models and showing strong associations with vascular risk factors and functional outcomes.", "motivation": "To address privacy concerns in training BrainAGE models with large datasets, this study evaluates FL for BrainAGE estimation in stroke patients and its clinical relevance.", "method": "Used FLAIR images from 1674 stroke patients across 16 centers, comparing centralized learning, FL, and single-site learning. Examined associations with vascular risk factors and functional outcomes.", "result": "FL outperformed single-site models, with BrainAGE linked to diabetes mellitus and predictive of post-stroke recovery. Centralized learning was most accurate.", "conclusion": "FL enables accurate BrainAGE predictions without data centralization, proving valuable for prognostic modeling in stroke care."}}
{"id": "2504.07863", "pdf": "https://arxiv.org/pdf/2504.07863", "abs": "https://arxiv.org/abs/2504.07863", "authors": ["Mengjia Niu", "Hamed Haddadi", "Guansong Pang"], "title": "Robust Hallucination Detection in LLMs via Adaptive Token Selection", "categories": ["cs.LG"], "comment": null, "summary": "Hallucinations in large language models (LLMs) pose significant safety\nconcerns that impede their broader deployment. Recent research in hallucination\ndetection has demonstrated that LLMs' internal representations contain\ntruthfulness hints, which can be harnessed for detector training. However, the\nperformance of these detectors is heavily dependent on the internal\nrepresentations of predetermined tokens, fluctuating considerably when working\non free-form generations with varying lengths and sparse distributions of\nhallucinated entities. To address this, we propose HaMI, a novel approach that\nenables robust detection of hallucinations through adaptive selection and\nlearning of critical tokens that are most indicative of hallucinations. We\nachieve this robustness by an innovative formulation of the Hallucination\ndetection task as Multiple Instance (HaMI) learning over token-level\nrepresentations within a sequence, thereby facilitating a joint optimisation of\ntoken selection and hallucination detection on generation sequences of diverse\nforms. Comprehensive experimental results on four hallucination benchmarks show\nthat HaMI significantly outperforms existing state-of-the-art approaches.", "AI": {"tldr": "HaMI improves hallucination detection in LLMs by adaptively selecting and learning critical tokens, outperforming existing methods.", "motivation": "Hallucinations in LLMs hinder deployment; current detectors rely on fixed token representations, limiting performance on free-form text.", "method": "Proposes HaMI, a multiple instance learning approach for adaptive token selection and joint optimization of hallucination detection.", "result": "HaMI significantly outperforms state-of-the-art methods on four benchmarks.", "conclusion": "HaMI offers a robust solution for detecting hallucinations in diverse LLM-generated text."}}
{"id": "2504.15920", "pdf": "https://arxiv.org/pdf/2504.15920", "abs": "https://arxiv.org/abs/2504.15920", "authors": ["Xiang Li", "Jianpeng Qi", "Haobing Liu", "Yuan Cao", "Guoqing Chao", "Zhongying Zhao", "Junyu Dong", "Yanwei Yu"], "title": "ScaleGNN: Towards Scalable Graph Neural Networks via Adaptive High-order Neighboring Feature Fusion", "categories": ["cs.LG"], "comment": null, "summary": "Graph Neural Networks (GNNs) have demonstrated impressive performance across\ndiverse graph-based tasks by leveraging message passing to capture complex node\nrelationships. However, when applied to large-scale real-world graphs, GNNs\nface two major challenges: First, it becomes increasingly difficult to ensure\nboth scalability and efficiency, as the repeated aggregation of large\nneighborhoods leads to significant computational overhead; Second, the\nover-smoothing problem arises, where excessive or deep propagation makes node\nrepresentations indistinguishable, severely hindering model expressiveness. To\ntackle these issues, we propose ScaleGNN, a novel framework that adaptively\nfuses multi-level graph features for both scalable and effective graph\nlearning. ScaleGNN first constructs per-order neighbor matrices that capture\nonly the exclusive structural information at each hop, avoiding the redundancy\nof conventional aggregation. A learnable fusion module then selectively\nintegrates these features, emphasizing the most informative high-order\nneighbors. To further reduce redundancy and over-smoothing, we introduce a\nLocal Contribution Score (LCS)-based masking mechanism to filter out less\nrelevant high-order neighbors, ensuring that only the most meaningful\ninformation is aggregated. In addition, a task-aware feature fusion strategy\ndynamically balances low- and high-order information, preserving both local\ndetail and global context without incurring excessive complexity. Extensive\nexperiments on real-world datasets demonstrate that ScaleGNN consistently\noutperforms state-of-the-art GNNs in both predictive accuracy and computational\nefficiency, highlighting its practical value for large-scale graph learning.", "AI": {"tldr": "ScaleGNN addresses scalability and over-smoothing in GNNs by adaptively fusing multi-level graph features, using neighbor matrices and a masking mechanism for efficiency.", "motivation": "GNNs struggle with scalability and over-smoothing on large graphs, limiting their effectiveness.", "method": "ScaleGNN constructs per-order neighbor matrices, uses a fusion module, and employs LCS-based masking to filter irrelevant neighbors.", "result": "ScaleGNN outperforms state-of-the-art GNNs in accuracy and efficiency on real-world datasets.", "conclusion": "ScaleGNN provides a scalable and effective solution for large-scale graph learning."}}
{"id": "2505.05677", "pdf": "https://arxiv.org/pdf/2505.05677", "abs": "https://arxiv.org/abs/2505.05677", "authors": ["Winston Chen", "Trenton Chang", "Jenna Wiens"], "title": "Conditional Front-door Adjustment for Heterogeneous Treatment Assignment Effect Estimation Under Non-adherence", "categories": ["cs.LG"], "comment": "Conference on Health, Inference, and Learning (CHIL) 2025", "summary": "Estimates of heterogeneous treatment assignment effects can inform treatment\ndecisions. Under the presence of non-adherence (e.g., patients do not adhere to\ntheir assigned treatment), both the standard backdoor adjustment (SBD) and the\nconditional front-door adjustment (CFD) can recover unbiased estimates of the\ntreatment assignment effects. However, the estimation variance of these\napproaches may vary widely across settings, which remains underexplored in the\nliterature. In this work, we demonstrate theoretically and empirically that CFD\nyields lower-variance estimates than SBD when the true effect of treatment\nassignment is small (i.e., assigning an intervention leads to small changes in\npatients' future outcome). Additionally, since CFD requires estimating multiple\nnuisance parameters, we introduce LobsterNet, a multi-task neural network that\nimplements CFD with joint modeling of the nuisance parameters. Empirically,\nLobsterNet reduces estimation error across several semi-synthetic and\nreal-world datasets compared to baselines. Our findings suggest CFD with shared\nnuisance parameter modeling can improve treatment assignment effect estimation\nunder non-adherence.", "AI": {"tldr": "CFD yields lower-variance estimates than SBD for small treatment effects under non-adherence. LobsterNet, a multi-task neural network, improves CFD by jointly modeling nuisance parameters, reducing estimation error.", "motivation": "To address the underexplored variance differences between SBD and CFD in estimating treatment effects under non-adherence, and to improve estimation accuracy.", "method": "Theoretical and empirical comparison of SBD and CFD, introduction of LobsterNet for joint nuisance parameter modeling in CFD.", "result": "CFD outperforms SBD in low-effect scenarios; LobsterNet reduces estimation error in semi-synthetic and real-world datasets.", "conclusion": "CFD with shared nuisance parameter modeling (via LobsterNet) enhances treatment effect estimation under non-adherence."}}
{"id": "2505.06753", "pdf": "https://arxiv.org/pdf/2505.06753", "abs": "https://arxiv.org/abs/2505.06753", "authors": ["Muhamed Amin", "Bernard R. Brooks"], "title": "Boltzmann Classifier: A Thermodynamic-Inspired Approach to Supervised Learning", "categories": ["cs.LG", "physics.comp-ph"], "comment": null, "summary": "We present the Boltzmann classifier, a novel distance based probabilistic\nclassification algorithm inspired by the Boltzmann distribution. Unlike\ntraditional classifiers that produce hard decisions or uncalibrated\nprobabilities, the Boltzmann classifier assigns class probabilities based on\nthe average distance to the nearest neighbors within each class, providing\ninterpretable, physically meaningful outputs. We evaluate the performance of\nthe method across three application domains: molecular activity prediction,\noxidation state classification of transition metal complexes, and breast cancer\ndiagnosis. In the molecular activity task, the classifier achieved the highest\naccuracy in predicting active compounds against two protein targets, with\nstrong correlations observed between the predicted probabilities and\nexperimental pIC50 values. For metal complexes, the classifier accurately\ndistinguished between oxidation states II and III for Fe, Mn, and Co, using\nonly metal-ligand bond lengths extracted from crystallographic data, and\ndemonstrated high consistency with known chemical trends. In the breast cancer\ndataset, the classifier achieved 97% accuracy, with low confidence predictions\nconcentrated in inherently ambiguous cases. Across all tasks, the Boltzmann\nclassifier performed competitively or better than standard models such as\nlogistic regression, support vector machines, random forests, and k-nearest\nneighbors. Its probabilistic outputs were found to correlate with continuous\nphysical or biological properties, highlighting its potential utility in both\nclassification and regression contexts. The results suggest that the Boltzmann\nclassifier is a robust and interpretable alternative to conventional machine\nlearning approaches, particularly in scientific domains where underlying\nstructure property relationships are important.", "AI": {"tldr": "The Boltzmann classifier is a distance-based probabilistic algorithm that provides interpretable outputs. It outperforms traditional methods in molecular activity prediction, oxidation state classification, and breast cancer diagnosis.", "motivation": "To create a classifier that offers interpretable, physically meaningful probabilities, unlike traditional models with hard decisions or uncalibrated outputs.", "method": "The classifier assigns class probabilities based on average distances to nearest neighbors within each class, leveraging the Boltzmann distribution.", "result": "Achieved high accuracy in molecular activity prediction, oxidation state classification, and breast cancer diagnosis, often outperforming standard models.", "conclusion": "The Boltzmann classifier is a robust, interpretable alternative for scientific domains, bridging classification and regression with meaningful outputs."}}
{"id": "2505.22998", "pdf": "https://arxiv.org/pdf/2505.22998", "abs": "https://arxiv.org/abs/2505.22998", "authors": ["Jihwan Oh", "Murad Aghazada", "Se-Young Yun", "Taehyeon Kim"], "title": "LLM Agents for Bargaining with Utility-based Feedback", "categories": ["cs.LG"], "comment": "Preprint", "summary": "Bargaining, a critical aspect of real-world interactions, presents challenges\nfor large language models (LLMs) due to limitations in strategic depth and\nadaptation to complex human factors. Existing benchmarks often fail to capture\nthis real-world complexity. To address this and enhance LLM capabilities in\nrealistic bargaining, we introduce a comprehensive framework centered on\nutility-based feedback. Our contributions are threefold: (1) BargainArena, a\nnovel benchmark dataset with six intricate scenarios (e.g., deceptive\npractices, monopolies) to facilitate diverse strategy modeling; (2)\nhuman-aligned, economically-grounded evaluation metrics inspired by utility\ntheory, incorporating agent utility and negotiation power, which implicitly\nreflect and promote opponent-aware reasoning (OAR); and (3) a structured\nfeedback mechanism enabling LLMs to iteratively refine their bargaining\nstrategies. This mechanism can positively collaborate with in-context learning\n(ICL) prompts, including those explicitly designed to foster OAR. Experimental\nresults show that LLMs often exhibit negotiation strategies misaligned with\nhuman preferences, and that our structured feedback mechanism significantly\nimproves their performance, yielding deeper strategic and opponent-aware\nreasoning.", "AI": {"tldr": "The paper introduces a framework to improve LLMs' bargaining skills using utility-based feedback, a new benchmark (BargainArena), and human-aligned metrics. Results show LLMs often misalign with human preferences but improve with structured feedback.", "motivation": "Existing benchmarks lack real-world bargaining complexity, limiting LLMs' strategic depth and adaptation to human factors.", "method": "Proposes BargainArena (6 scenarios), utility-based metrics, and a feedback mechanism for iterative LLM refinement.", "result": "LLMs often misalign with human preferences; structured feedback improves strategic and opponent-aware reasoning.", "conclusion": "The framework enhances LLMs' bargaining capabilities, aligning them better with human strategies through iterative feedback."}}
{"id": "2505.24183", "pdf": "https://arxiv.org/pdf/2505.24183", "abs": "https://arxiv.org/abs/2505.24183", "authors": ["Yaoyu Zhu", "Di Huang", "Hanqi Lyu", "Xiaoyun Zhang", "Chongxiao Li", "Wenxuan Shi", "Yutong Wu", "Jianan Mu", "Jinghua Wang", "Yang Zhao", "Pengwei Jin", "Shuyao Cheng", "Shengwen Liang", "Xishan Zhang", "Rui Zhang", "Zidong Du", "Qi Guo", "Xing Hu", "Yunji Chen"], "title": "CodeV-R1: Reasoning-Enhanced Verilog Generation", "categories": ["cs.LG", "cs.AR", "cs.PL"], "comment": null, "summary": "Large language models (LLMs) trained via reinforcement learning with\nverifiable reward (RLVR) have achieved breakthroughs on tasks with explicit,\nautomatable verification, such as software programming and mathematical\nproblems. Extending RLVR to electronic design automation (EDA), especially\nautomatically generating hardware description languages (HDLs) like Verilog\nfrom natural-language (NL) specifications, however, poses three key challenges:\nthe lack of automated and accurate verification environments, the scarcity of\nhigh-quality NL-code pairs, and the prohibitive computation cost of RLVR. To\nthis end, we introduce CodeV-R1, an RLVR framework for training Verilog\ngeneration LLMs. First, we develop a rule-based testbench generator that\nperforms robust equivalence checking against golden references. Second, we\npropose a round-trip data synthesis method that pairs open-source Verilog\nsnippets with LLM-generated NL descriptions, verifies code-NL-code consistency\nvia the generated testbench, and filters out inequivalent examples to yield a\nhigh-quality dataset. Third, we employ a two-stage \"distill-then-RL\" training\npipeline: distillation for the cold start of reasoning abilities, followed by\nadaptive DAPO, our novel RLVR algorithm that can reduce training cost by\nadaptively adjusting sampling rate. The resulting model, CodeV-R1-7B, achieves\n68.6% and 72.9% pass@1 on VerilogEval v2 and RTLLM v1.1, respectively,\nsurpassing prior state-of-the-art by 12~20%, while matching or even exceeding\nthe performance of 671B DeepSeek-R1. We will release our model, training\npipeline, and dataset to facilitate research in EDA and LLM communities.", "AI": {"tldr": "CodeV-R1 is an RLVR framework for training LLMs to generate Verilog from natural language, addressing challenges like verification, data scarcity, and computation costs. It achieves state-of-the-art results.", "motivation": "Extend RLVR to EDA for Verilog generation from NL, overcoming challenges like lack of verification environments, scarce NL-code pairs, and high RLVR costs.", "method": "Develops a testbench generator, round-trip data synthesis, and a two-stage training pipeline (distillation + adaptive DAPO RLVR).", "result": "CodeV-R1-7B achieves 68.6% and 72.9% pass@1 on benchmarks, outperforming prior SOTA by 12~20%.", "conclusion": "CodeV-R1 advances Verilog generation, with released resources to aid EDA and LLM research."}}
{"id": "2506.02355", "pdf": "https://arxiv.org/pdf/2506.02355", "abs": "https://arxiv.org/abs/2506.02355", "authors": ["Andre He", "Daniel Fried", "Sean Welleck"], "title": "Rewarding the Unlikely: Lifting GRPO Beyond Distribution Sharpening", "categories": ["cs.LG"], "comment": null, "summary": "Reinforcement learning is emerging as a primary driver for improving language\nmodel reasoning capabilities. A fundamental question is whether current\nreinforcement learning algorithms -- such as Group Relative Policy Optimization\n(GRPO), the de facto standard algorithm used to improve language model\nreasoning -- merely sharpen the base model's distribution around problems it\ncan already solve. We investigate this question in the context of formal\ntheorem proving, which has access to a perfect verifier. We identify a\ndegenerate rank bias in GRPO in which highly probable trajectories are\nreinforced and rare ones are neglected. This results in distribution\nsharpening: the model can solve some problems with fewer samples, but\nunderperforms simply sampling more solutions from the original model. To\novercome GRPO's rank bias we introduce unlikeliness reward, a simple method for\nexplicitly up-weighting rare but correct solutions. We show that unlikeliness\nreward mitigates rank bias and improves pass@$N$ across a large range of $N$ in\nboth synthetic and real theorem proving settings. We also uncover an unexpected\nlink between rank bias and a seemingly mundane hyperparameter -- the number of\nupdates per batch -- that leads to a second, complementary mitigation. We\ncombine our insights into a revised GRPO training recipe for formal theorem\nproving, yielding an open pipeline that achieves competitive performance to\nDeepSeek-Prover-V1.5-RL on the miniF2F-test benchmark. We release our\nimplementation at https://github.com/AndreHe02/rewarding-unlikely-release", "AI": {"tldr": "The paper investigates if GRPO, a reinforcement learning algorithm for language models, merely sharpens the model's distribution around solvable problems. It identifies a rank bias in GRPO, introduces unlikeliness reward to mitigate it, and improves performance in theorem proving.", "motivation": "To determine if GRPO's reinforcement learning approach genuinely enhances language model reasoning or just sharpens existing capabilities, using formal theorem proving as a test case.", "method": "Identifies a degenerate rank bias in GRPO, introduces unlikeliness reward to up-weight rare correct solutions, and adjusts hyperparameters like updates per batch.", "result": "Unlikeliness reward mitigates rank bias, improving pass@N performance. The revised GRPO recipe achieves competitive results on the miniF2F-test benchmark.", "conclusion": "The study reveals GRPO's limitations, proposes effective mitigations, and demonstrates improved performance in theorem proving, offering a revised training pipeline."}}
{"id": "2506.03889", "pdf": "https://arxiv.org/pdf/2506.03889", "abs": "https://arxiv.org/abs/2506.03889", "authors": ["Pau Vilimelis Aceituno", "Jack William Miller", "Noah Marti", "Youssef Farag", "Victor Boussange"], "title": "Temporal horizons in forecasting: a performance-learnability trade-off", "categories": ["cs.LG", "nlin.CD"], "comment": "33 pages, 12 figures", "summary": "When training autoregressive models to forecast dynamical systems, a critical\nquestion arises: how far into the future should the model be trained to\npredict? Too short a horizon may miss long-term trends, while too long a\nhorizon can impede convergence due to accumulating prediction errors. In this\nwork, we formalize this trade-off by analyzing how the geometry of the loss\nlandscape depends on the training horizon. We prove that for chaotic systems,\nthe loss landscape's roughness grows exponentially with the training horizon,\nwhile for limit cycles, it grows linearly, making long-horizon training\ninherently challenging. However, we also show that models trained on long\nhorizons generalize well to short-term forecasts, whereas those trained on\nshort horizons suffer exponentially (resp. linearly) worse long-term\npredictions in chaotic (resp. periodic) systems. We validate our theory through\nnumerical experiments and discuss practical implications for selecting training\nhorizons. Our results provide a principled foundation for hyperparameter\noptimization in autoregressive forecasting models.", "AI": {"tldr": "The paper analyzes the trade-off in training autoregressive models for dynamical systems, showing how the training horizon affects the loss landscape and prediction accuracy.", "motivation": "To understand how the choice of training horizon impacts the performance and convergence of autoregressive models in forecasting dynamical systems.", "method": "Theoretical analysis of the loss landscape's geometry based on training horizon, validated through numerical experiments.", "result": "For chaotic systems, loss roughness grows exponentially with horizon; for limit cycles, it grows linearly. Long-horizon training generalizes better to short-term forecasts.", "conclusion": "The study provides a principled approach for selecting training horizons in autoregressive forecasting models."}}
{"id": "2506.09010", "pdf": "https://arxiv.org/pdf/2506.09010", "abs": "https://arxiv.org/abs/2506.09010", "authors": ["Sebastian Schmidt", "Prasanga Dhungel", "Christoffer L\u00f6ffler", "Bj\u00f6rn Nieth", "Stephan G\u00fcnnemann", "Leo Schwinn"], "title": "Effective Data Pruning through Score Extrapolation", "categories": ["cs.LG"], "comment": null, "summary": "Training advanced machine learning models demands massive datasets, resulting\nin prohibitive computational costs. To address this challenge, data pruning\ntechniques identify and remove redundant training samples while preserving\nmodel performance. Yet, existing pruning techniques predominantly require a\nfull initial training pass to identify removable samples, negating any\nefficiency benefits for single training runs. To overcome this limitation, we\nintroduce a novel importance score extrapolation framework that requires\ntraining on only a small subset of data. We present two initial approaches in\nthis framework - k-nearest neighbors and graph neural networks - to accurately\npredict sample importance for the entire dataset using patterns learned from\nthis minimal subset. We demonstrate the effectiveness of our approach for 2\nstate-of-the-art pruning methods (Dynamic Uncertainty and TDDS), 4 different\ndatasets (CIFAR-10, CIFAR-100, Places-365, and ImageNet), and 3 training\nparadigms (supervised, unsupervised, and adversarial). Our results indicate\nthat score extrapolation is a promising direction to scale expensive score\ncalculation methods, such as pruning, data attribution, or other tasks.", "AI": {"tldr": "A novel framework predicts sample importance using minimal training data, enabling efficient data pruning without full initial training.", "motivation": "Training large models is computationally expensive due to massive datasets. Existing pruning methods require full training, negating efficiency gains.", "method": "Introduces importance score extrapolation using k-nearest neighbors and graph neural networks, trained on a small data subset.", "result": "Effective for 2 pruning methods, 4 datasets, and 3 training paradigms, showing promise for scaling expensive tasks like pruning.", "conclusion": "Score extrapolation is a scalable solution for reducing computational costs in data pruning and related tasks."}}
{"id": "2506.11611", "pdf": "https://arxiv.org/pdf/2506.11611", "abs": "https://arxiv.org/abs/2506.11611", "authors": ["Yaning Jia", "Shenyang Deng", "Chiyu Ma", "Yaoqing Yang", "Soroush Vosoughi"], "title": "KCES: Training-Free Defense for Robust Graph Neural Networks via Kernel Complexity", "categories": ["cs.LG"], "comment": null, "summary": "Graph Neural Networks (GNNs) have achieved impressive success across a wide\nrange of graph-based tasks, yet they remain highly vulnerable to small,\nimperceptible perturbations and adversarial attacks. Although numerous defense\nmethods have been proposed to address these vulnerabilities, many rely on\nheuristic metrics, overfit to specific attack patterns, and suffer from high\ncomputational complexity. In this paper, we propose Kernel Complexity-Based\nEdge Sanitization (KCES), a training-free, model-agnostic defense framework.\nKCES leverages Graph Kernel Complexity (GKC), a novel metric derived from the\ngraph's Gram matrix that characterizes GNN generalization via its test error\nbound. Building on GKC, we define a KC score for each edge, measuring the\nchange in GKC when the edge is removed. Edges with high KC scores, typically\nintroduced by adversarial perturbations, are pruned to mitigate their harmful\neffects, thereby enhancing GNNs' robustness. KCES can also be seamlessly\nintegrated with existing defense strategies as a plug-and-play module without\nrequiring training. Theoretical analysis and extensive experiments demonstrate\nthat KCES consistently enhances GNN robustness, outperforms state-of-the-art\nbaselines, and amplifies the effectiveness of existing defenses, offering a\nprincipled and efficient solution for securing GNNs.", "AI": {"tldr": "KCES is a training-free, model-agnostic defense framework for GNNs that uses Graph Kernel Complexity to identify and prune adversarial edges, improving robustness.", "motivation": "GNNs are vulnerable to adversarial attacks, and existing defenses often rely on heuristics, overfit, or are computationally expensive.", "method": "KCES leverages Graph Kernel Complexity (GKC) to score edges, pruning those with high scores (likely adversarial) to enhance robustness.", "result": "KCES improves GNN robustness, outperforms baselines, and integrates well with other defenses.", "conclusion": "KCES provides a principled, efficient solution for securing GNNs against adversarial attacks."}}
{"id": "2506.12958", "pdf": "https://arxiv.org/pdf/2506.12958", "abs": "https://arxiv.org/abs/2506.12958", "authors": ["Khizar Anjum", "Muhammad Arbab Arshad", "Kadhim Hayawi", "Efstathios Polyzos", "Asadullah Tariq", "Mohamed Adel Serhani", "Laiba Batool", "Brady Lund", "Nishith Reddy Mannuru", "Ravi Varma Kumar Bevara", "Taslim Mahbub", "Muhammad Zeeshan Akram", "Sakib Shahriar"], "title": "Domain Specific Benchmarks for Evaluating Multimodal Large Language Models", "categories": ["cs.LG"], "comment": null, "summary": "Large language models (LLMs) are increasingly being deployed across\ndisciplines due to their advanced reasoning and problem solving capabilities.\nTo measure their effectiveness, various benchmarks have been developed that\nmeasure aspects of LLM reasoning, comprehension, and problem-solving. While\nseveral surveys address LLM evaluation and benchmarks, a domain-specific\nanalysis remains underexplored in the literature. This paper introduces a\ntaxonomy of seven key disciplines, encompassing various domains and application\nareas where LLMs are extensively utilized. Additionally, we provide a\ncomprehensive review of LLM benchmarks and survey papers within each domain,\nhighlighting the unique capabilities of LLMs and the challenges faced in their\napplication. Finally, we compile and categorize these benchmarks by domain to\ncreate an accessible resource for researchers, aiming to pave the way for\nadvancements toward artificial general intelligence (AGI)", "AI": {"tldr": "The paper introduces a taxonomy of seven disciplines where LLMs are used, reviews benchmarks, and compiles them by domain to aid AGI research.", "motivation": "To address the lack of domain-specific analysis of LLM benchmarks and evaluation in existing literature.", "method": "Develops a taxonomy of seven key disciplines, reviews LLM benchmarks, and categorizes them by domain.", "result": "A comprehensive resource of domain-specific LLM benchmarks and insights into their capabilities and challenges.", "conclusion": "The work aims to facilitate advancements toward AGI by providing an accessible, domain-focused benchmark resource."}}
{"id": "2506.13064", "pdf": "https://arxiv.org/pdf/2506.13064", "abs": "https://arxiv.org/abs/2506.13064", "authors": ["Kai Tang", "Ji Zhang", "Hua Meng", "Minbo Ma", "Qi Xiong", "Fengmao Lv", "Jie Xu", "Tianrui Li"], "title": "CoIFNet: A Unified Framework for Multivariate Time Series Forecasting with Missing Values", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "Multivariate time series forecasting (MTSF) is a critical task with broad\napplications in domains such as meteorology, transportation, and economics.\nNevertheless, pervasive missing values caused by sensor failures or human\nerrors significantly degrade forecasting accuracy. Prior efforts usually employ\nan impute-then-forecast paradigm, leading to suboptimal predictions due to\nerror accumulation and misaligned objectives between the two stages. To address\nthis challenge, we propose the Collaborative Imputation-Forecasting Network\n(CoIFNet), a novel framework that unifies imputation and forecasting to achieve\nrobust MTSF in the presence of missing values. Specifically, CoIFNet takes the\nobserved values, mask matrix and timestamp embeddings as input, processing them\nsequentially through the Cross-Timestep Fusion (CTF) and Cross-Variate Fusion\n(CVF) modules to capture temporal dependencies that are robust to missing\nvalues. We provide theoretical justifications on how our CoIFNet learning\nobjective improves the performance bound of MTSF with missing values. Through\nextensive experiments on challenging MSTF benchmarks, we demonstrate the\neffectiveness and computational efficiency of our proposed approach across\ndiverse missing-data scenarios, e.g., CoIFNet outperforms the state-of-the-art\nmethod by $\\underline{\\textbf{24.40}}$% ($\\underline{\\textbf{23.81}}$%) at a\npoint (block) missing rate of 0.6, while improving memory and time efficiency\nby $\\underline{\\boldsymbol{4.3\\times}}$ and\n$\\underline{\\boldsymbol{2.1\\times}}$, respectively. Our code is available at:\nhttps://github.com/KaiTang-eng/CoIFNet.", "AI": {"tldr": "CoIFNet unifies imputation and forecasting for robust multivariate time series forecasting (MTSF) with missing values, outperforming state-of-the-art methods.", "motivation": "Missing values in MTSF degrade accuracy; prior impute-then-forecast methods are suboptimal due to error accumulation and misaligned objectives.", "method": "CoIFNet uses Cross-Timestep Fusion (CTF) and Cross-Variate Fusion (CVF) modules to capture temporal dependencies robust to missing values.", "result": "CoIFNet outperforms state-of-the-art by 24.40% (23.81%) at high missing rates and improves efficiency by 4.3\u00d7 (memory) and 2.1\u00d7 (time).", "conclusion": "CoIFNet effectively addresses missing values in MTSF, offering superior performance and efficiency."}}
{"id": "2506.13593", "pdf": "https://arxiv.org/pdf/2506.13593", "abs": "https://arxiv.org/abs/2506.13593", "authors": ["Hen Davidov", "Gilad Freidkin", "Shai Feldman", "Yaniv Romano"], "title": "Calibrated Predictive Lower Bounds on Time-to-Unsafe-Sampling in LLMs", "categories": ["cs.LG", "stat.AP", "stat.ML"], "comment": null, "summary": "We develop a framework to quantify the time-to-unsafe-sampling - the number\nof large language model (LLM) generations required to trigger an unsafe (e.g.,\ntoxic) response. Estimating this quantity is challenging, since unsafe\nresponses are exceedingly rare in well-aligned LLMs, potentially occurring only\nonce in thousands of generations. As a result, directly estimating\ntime-to-unsafe-sampling would require collecting training data with a\nprohibitively large number of generations per prompt. However, with realistic\nsampling budgets, we often cannot generate enough responses to observe an\nunsafe outcome for every prompt, leaving the time-to-unsafe-sampling unobserved\nin many cases, making the estimation and evaluation tasks particularly\nchallenging. To address this, we frame this estimation problem as one of\nsurvival analysis and develop a provably calibrated lower predictive bound\n(LPB) on the time-to-unsafe-sampling of a given prompt, leveraging recent\nadvances in conformal prediction. Our key innovation is designing an adaptive,\nper-prompt sampling strategy, formulated as a convex optimization problem. The\nobjective function guiding this optimized sampling allocation is designed to\nreduce the variance of the estimators used to construct the LPB, leading to\nimproved statistical efficiency over naive methods that use a fixed sampling\nbudget per prompt. Experiments on both synthetic and real data support our\ntheoretical results and demonstrate the practical utility of our method for\nsafety risk assessment in generative AI models.", "AI": {"tldr": "A framework to estimate the time-to-unsafe-sampling in LLMs using survival analysis and conformal prediction, with an adaptive sampling strategy for efficiency.", "motivation": "Unsafe responses in well-aligned LLMs are rare, making direct estimation impractical due to large data requirements.", "method": "Frames the problem as survival analysis, uses conformal prediction for calibrated lower bounds, and optimizes sampling allocation via convex optimization.", "result": "Improved statistical efficiency and practical utility for safety risk assessment in generative AI models.", "conclusion": "The method provides a reliable way to quantify safety risks in LLMs with limited sampling budgets."}}
{"id": "2506.13987", "pdf": "https://arxiv.org/pdf/2506.13987", "abs": "https://arxiv.org/abs/2506.13987", "authors": ["Md Abrar Jahin", "Adiba Abid", "M. F. Mridha"], "title": "Quantum-Informed Contrastive Learning with Dynamic Mixup Augmentation for Class-Imbalanced Expert Systems", "categories": ["cs.LG"], "comment": null, "summary": "Expert systems often operate in domains characterized by class-imbalanced\ntabular data, where detecting rare but critical instances is essential for\nsafety and reliability. While conventional approaches, such as cost-sensitive\nlearning, oversampling, and graph neural networks, provide partial solutions,\nthey suffer from drawbacks like overfitting, label noise, and poor\ngeneralization in low-density regions. To address these challenges, we propose\nQCL-MixNet, a novel Quantum-Informed Contrastive Learning framework augmented\nwith k-nearest neighbor (kNN) guided dynamic mixup for robust classification\nunder imbalance. QCL-MixNet integrates three core innovations: (i) a Quantum\nEntanglement-inspired layer that models complex feature interactions through\nsinusoidal transformations and gated attention, (ii) a sample-aware mixup\nstrategy that adaptively interpolates feature representations of semantically\nsimilar instances to enhance minority class representation, and (iii) a hybrid\nloss function that unifies focal reweighting, supervised contrastive learning,\ntriplet margin loss, and variance regularization to improve both intra-class\ncompactness and inter-class separability. Extensive experiments on 18\nreal-world imbalanced datasets (binary and multi-class) demonstrate that\nQCL-MixNet consistently outperforms 20 state-of-the-art machine learning, deep\nlearning, and GNN-based baselines in macro-F1 and recall, often by substantial\nmargins. Ablation studies further validate the critical role of each\narchitectural component. Our results establish QCL-MixNet as a new benchmark\nfor tabular imbalance handling in expert systems. Theoretical analyses\nreinforce its expressiveness, generalization, and optimization robustness.", "AI": {"tldr": "QCL-MixNet is a quantum-informed contrastive learning framework with dynamic mixup for robust classification in imbalanced tabular data, outperforming 20 state-of-the-art methods.", "motivation": "Addressing drawbacks of conventional methods (overfitting, label noise, poor generalization) in handling class-imbalanced tabular data for expert systems.", "method": "Integrates quantum entanglement-inspired layers, kNN-guided dynamic mixup, and a hybrid loss function for improved feature interaction and minority class representation.", "result": "Outperforms 20 baselines in macro-F1 and recall on 18 real-world datasets, validated by ablation studies.", "conclusion": "QCL-MixNet sets a new benchmark for tabular imbalance handling, supported by theoretical robustness and expressiveness."}}
{"id": "2506.14782", "pdf": "https://arxiv.org/pdf/2506.14782", "abs": "https://arxiv.org/abs/2506.14782", "authors": ["Joseph Geraci", "Bessi Qorri", "Christian Cumbaa", "Mike Tsay", "Paul Leonczyk", "Luca Pani"], "title": "Integrating Dynamical Systems Learning with Foundational Models: A Meta-Evolutionary AI Framework for Clinical Trials", "categories": ["cs.LG", "q-bio.QM"], "comment": "27 pages", "summary": "Artificial intelligence (AI) has evolved into an ecosystem of specialized\n\"species,\" each with unique strengths. We analyze two: DeepSeek-V3, a\n671-billion-parameter Mixture of Experts large language model (LLM)\nexemplifying scale-driven generality, and NetraAI, a dynamical system-based\nframework engineered for stability and interpretability on small clinical trial\ndatasets. We formalize NetraAI's foundations, combining contraction mappings,\ninformation geometry, and evolutionary algorithms to identify predictive\npatient cohorts. Features are embedded in a metric space and iteratively\ncontracted toward stable attractors that define latent subgroups. A\npseudo-temporal embedding and long-range memory enable exploration of\nhigher-order feature interactions, while an internal evolutionary loop selects\ncompact, explainable 2-4-variable bundles (\"Personas\").\n  To guide discovery, we introduce an LLM Strategist as a meta-evolutionary\nlayer that observes Persona outputs, prioritizes promising variables, injects\ndomain knowledge, and assesses robustness. This two-tier architecture mirrors\nthe human scientific process: NetraAI as experimentalist, the LLM as theorist,\nforming a self-improving loop.\n  In case studies (schizophrenia, depression, pancreatic cancer), NetraAI\nuncovered small, high-effect-size subpopulations that transformed weak baseline\nmodels (AUC ~0.50-0.68) into near-perfect classifiers using only a few\nfeatures. We position NetraAI at the intersection of dynamical systems,\ninformation geometry, and evolutionary learning, aligned with emerging\nconcept-level reasoning paradigms such as LeCun's Joint Embedding Predictive\nArchitecture (JEPA). By prioritizing reliable, explainable knowledge, NetraAI\noffers a new generation of adaptive, self-reflective AI to accelerate clinical\ndiscovery.", "AI": {"tldr": "The paper compares two AI approaches: DeepSeek-V3, a large-scale LLM, and NetraAI, a dynamical system-based framework for clinical data. NetraAI combines contraction mappings, information geometry, and evolutionary algorithms to identify predictive patient subgroups, achieving high accuracy with few features.", "motivation": "To address the need for stable, interpretable AI in clinical settings, especially for small datasets, by combining dynamical systems, information geometry, and evolutionary learning.", "method": "NetraAI uses contraction mappings, information geometry, and evolutionary algorithms to embed features in a metric space and identify stable subgroups. An LLM Strategist acts as a meta-evolutionary layer to guide discovery.", "result": "NetraAI transformed weak baseline models into near-perfect classifiers for schizophrenia, depression, and pancreatic cancer, using only a few features.", "conclusion": "NetraAI offers a reliable, explainable AI framework for clinical discovery, aligning with emerging paradigms like JEPA and advancing adaptive, self-reflective AI."}}
{"id": "2506.15337", "pdf": "https://arxiv.org/pdf/2506.15337", "abs": "https://arxiv.org/abs/2506.15337", "authors": ["Naoki Matsumura", "Yuta Yoshimoto", "Yuto Iwasaki", "Meguru Yamazaki", "Yasufumi Sakai"], "title": "Knowledge Distillation Framework for Accelerating High-Accuracy Neural Network-Based Molecular Dynamics Simulations", "categories": ["cs.LG", "cond-mat.mtrl-sci", "physics.comp-ph"], "comment": null, "summary": "Neural network potentials (NNPs) offer a powerful alternative to traditional\nforce fields for molecular dynamics (MD) simulations. Accurate and stable MD\nsimulations, crucial for evaluating material properties, require training data\nencompassing both low-energy stable structures and high-energy structures.\nConventional knowledge distillation (KD) methods fine-tune a pre-trained NNP as\na teacher model to generate training data for a student model. However, in\nmaterial-specific models, this fine-tuning process increases energy barriers,\nmaking it difficult to create training data containing high-energy structures.\nTo address this, we propose a novel KD framework that leverages a\nnon-fine-tuned, off-the-shelf pre-trained NNP as a teacher. Its gentler energy\nlandscape facilitates the exploration of a wider range of structures, including\nthe high-energy structures crucial for stable MD simulations. Our framework\nemploys a two-stage training process: first, the student NNP is trained with a\ndataset generated by the off-the-shelf teacher; then, it is fine-tuned with a\nsmaller, high-accuracy density functional theory (DFT) dataset. We demonstrate\nthe effectiveness of our framework by applying it to both organic (polyethylene\nglycol) and inorganic (L$_{10}$GeP$_{2}$S$_{12}$) materials, achieving\ncomparable or superior accuracy in reproducing physical properties compared to\nexisting methods. Importantly, our method reduces the number of expensive DFT\ncalculations by 10x compared to existing NNP generation methods, without\nsacrificing accuracy. Furthermore, the resulting student NNP achieves up to\n106x speedup in inference compared to the teacher NNP, enabling significantly\nfaster and more efficient MD simulations.", "AI": {"tldr": "A novel knowledge distillation framework uses a non-fine-tuned pre-trained NNP as a teacher to generate training data, reducing DFT calculations by 10x and achieving faster MD simulations without accuracy loss.", "motivation": "Traditional KD methods fine-tune NNPs, increasing energy barriers and limiting high-energy structure data. A gentler approach is needed for stable MD simulations.", "method": "Two-stage training: student NNP trained with off-the-shelf teacher data, then fine-tuned with a smaller DFT dataset.", "result": "Achieves comparable/superior accuracy, reduces DFT calculations by 10x, and speeds up inference by 106x.", "conclusion": "The framework enables efficient, accurate MD simulations with fewer resources."}}
{"id": "2307.13124", "pdf": "https://arxiv.org/pdf/2307.13124", "abs": "https://arxiv.org/abs/2307.13124", "authors": ["Helton Graziadei", "Paulo C. Marques F.", "Eduardo F. L. de Melo", "Rodrigo S. Targino"], "title": "Conformal prediction for frequency-severity modeling", "categories": ["stat.ME", "cs.LG", "stat.ML"], "comment": null, "summary": "We present a model-agnostic framework for the construction of prediction\nintervals of insurance claims, with finite sample statistical guarantees,\nextending the technique of split conformal prediction to the domain of\ntwo-stage frequency-severity modeling. The framework effectiveness is showcased\nwith simulated and real datasets using classical parametric models and\ncontemporary machine learning methods. When the underlying severity model is a\nrandom forest, we extend the two-stage split conformal prediction algorithm,\nshowing how the out-of-bag mechanism can be leveraged to eliminate the need for\na calibration set in the conformal procedure.", "AI": {"tldr": "A model-agnostic framework for insurance claim prediction intervals with finite-sample guarantees, extending split conformal prediction to two-stage frequency-severity modeling.", "motivation": "To provide reliable prediction intervals for insurance claims, ensuring statistical guarantees even with finite samples.", "method": "Extends split conformal prediction to two-stage frequency-severity modeling, using simulated and real datasets with parametric and machine learning models. Introduces an out-of-bag mechanism for random forest severity models to avoid calibration sets.", "result": "Demonstrates effectiveness with both classical and modern methods, showing practical applicability.", "conclusion": "The framework is versatile and reliable for constructing prediction intervals in insurance claim modeling."}}
{"id": "2310.04585", "pdf": "https://arxiv.org/pdf/2310.04585", "abs": "https://arxiv.org/abs/2310.04585", "authors": ["John Y. Zhu"], "title": "Interventions Against Machine-Assisted Statistical Discrimination", "categories": ["econ.TH", "cs.LG"], "comment": null, "summary": "I study statistical discrimination driven by verifiable beliefs, such as\nthose generated by machine learning, rather than by humans. When beliefs are\nverifiable, interventions against statistical discrimination can move beyond\nsimple, belief-free designs like affirmative action, to more sophisticated\nones, that constrain decision makers based on what they are thinking. I design\na belief-contingent intervention I call common identity. I show that it is\neffective at eliminating equilibrium statistical discrimination, even when\ntraining data exhibit the various statistical biases that often plague\nalgorithmic decision problems.", "AI": {"tldr": "The paper explores statistical discrimination driven by verifiable beliefs (e.g., machine learning) and proposes a belief-contingent intervention called 'common identity' to eliminate such discrimination effectively.", "motivation": "To address statistical discrimination arising from verifiable beliefs, moving beyond simplistic interventions like affirmative action to more nuanced, belief-based solutions.", "method": "Designs a belief-contingent intervention named 'common identity' and tests its effectiveness in eliminating equilibrium statistical discrimination, even with biased training data.", "result": "The 'common identity' intervention successfully eliminates equilibrium statistical discrimination, even in the presence of statistical biases in training data.", "conclusion": "Belief-contingent interventions like 'common identity' offer a promising approach to combat statistical discrimination in algorithmic decision-making."}}
{"id": "2402.06562", "pdf": "https://arxiv.org/pdf/2402.06562", "abs": "https://arxiv.org/abs/2402.06562", "authors": ["Manish Prajapat", "Johannes K\u00f6hler", "Matteo Turchetta", "Andreas Krause", "Melanie N. Zeilinger"], "title": "Safe Guaranteed Exploration for Non-linear Systems", "categories": ["eess.SY", "cs.LG", "cs.RO", "cs.SY", "math.OC"], "comment": "Accepted paper in IEEE Transactions on Automatic Control, 2025", "summary": "Safely exploring environments with a-priori unknown constraints is a\nfundamental challenge that restricts the autonomy of robots. While safety is\nparamount, guarantees on sufficient exploration are also crucial for ensuring\nautonomous task completion. To address these challenges, we propose a novel\nsafe guaranteed exploration framework using optimal control, which achieves\nfirst-of-its-kind results: guaranteed exploration for non-linear systems with\nfinite time sample complexity bounds, while being provably safe with\narbitrarily high probability. The framework is general and applicable to many\nreal-world scenarios with complex non-linear dynamics and unknown domains. We\nimprove the efficiency of this general framework by proposing an algorithm,\nSageMPC, SAfe Guaranteed Exploration using Model Predictive Control. SageMPC\nleverages three key techniques: i) exploiting a Lipschitz bound, ii)\ngoal-directed exploration, and iii) receding horizon style re-planning, all\nwhile maintaining the desired sample complexity, safety and exploration\nguarantees of the framework. Lastly, we demonstrate safe efficient exploration\nin challenging unknown environments using SageMPC with a car model.", "AI": {"tldr": "A novel safe guaranteed exploration framework using optimal control ensures safety and exploration for non-linear systems with finite time bounds.", "motivation": "Addressing the challenge of safely exploring unknown environments while ensuring task completion for autonomous robots.", "method": "Proposes SageMPC, leveraging Lipschitz bounds, goal-directed exploration, and re-planning for efficiency.", "result": "Achieves guaranteed exploration with safety and finite time complexity for non-linear systems.", "conclusion": "Demonstrates successful safe exploration in unknown environments using SageMPC with a car model."}}
{"id": "2402.15592", "pdf": "https://arxiv.org/pdf/2402.15592", "abs": "https://arxiv.org/abs/2402.15592", "authors": ["Zhe Jiao", "Wantao Jia", "Weiqiu Zhu"], "title": "Solving a class of stochastic optimal control problems by physics-informed neural networks", "categories": ["math.OC", "cs.LG"], "comment": "8 pages", "summary": "The aim of this work is to develop a deep learning method for solving\nhigh-dimensional stochastic control problems based on the\nHamilton--Jacobi--Bellman (HJB) equation and physics-informed learning. Our\napproach is to parameterize the feedback control and the value function using a\ndecoupled neural network with multiple outputs. We train this network by using\na loss function with penalty terms that enforce the HJB equation along the\nsampled trajectories generated by the controlled system. More significantly,\nnumerical results on various applications are carried out to demonstrate that\nthe proposed approach is efficient and applicable.", "AI": {"tldr": "A deep learning method for solving high-dimensional stochastic control problems using the HJB equation and physics-informed learning, with decoupled neural networks for control and value functions.", "motivation": "To address the challenge of solving high-dimensional stochastic control problems efficiently.", "method": "Parameterize feedback control and value function with a decoupled neural network, trained using a loss function enforcing the HJB equation on sampled trajectories.", "result": "Numerical results show the approach is efficient and applicable across various applications.", "conclusion": "The proposed method effectively solves high-dimensional stochastic control problems using deep learning and physics-informed techniques."}}
{"id": "2403.17285", "pdf": "https://arxiv.org/pdf/2403.17285", "abs": "https://arxiv.org/abs/2403.17285", "authors": ["Qianglin Wen", "Chengchun Shi", "Ying Yang", "Niansheng Tang", "Hongtu Zhu"], "title": "Unraveling the Interplay between Carryover Effects and Reward Autocorrelations in Switchback Experiments", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "A/B testing has become the gold standard for policy evaluation in modern\ntechnological industries. Motivated by the widespread use of switchback\nexperiments in A/B testing, this paper conducts a comprehensive comparative\nanalysis of various switchback designs in Markovian environments. Unlike many\nexisting works which derive the optimal design based on specific and relatively\nsimple estimators, our analysis covers a range of state-of-the-art estimators\ndeveloped in the reinforcement learning (RL) literature. It reveals that the\neffectiveness of different switchback designs depends crucially on (i) the size\nof the carryover effect and (ii) the auto-correlations among reward errors over\ntime. Meanwhile, these findings are estimator-agnostic, i.e., they apply to\nmost RL estimators. Based on these insights, we provide a workflow to offer\nguidelines for practitioners on designing switchback experiments in A/B\ntesting.", "AI": {"tldr": "The paper analyzes switchback designs in A/B testing for Markovian environments, revealing their effectiveness depends on carryover effects and reward error auto-correlations. It provides a workflow for practitioners.", "motivation": "The widespread use of switchback experiments in A/B testing motivates a comparative analysis of designs, especially in Markovian environments.", "method": "The study conducts a comprehensive analysis of switchback designs, covering state-of-the-art RL estimators, unlike prior works focusing on simple estimators.", "result": "Effectiveness of switchback designs hinges on carryover effect size and reward error auto-correlations, with findings applicable to most RL estimators.", "conclusion": "The paper offers a workflow to guide practitioners in designing switchback experiments for A/B testing, based on estimator-agnostic insights."}}
{"id": "2404.04549", "pdf": "https://arxiv.org/pdf/2404.04549", "abs": "https://arxiv.org/abs/2404.04549", "authors": ["A. Martina Neuman", "Dominik Dold", "Philipp Christian Petersen"], "title": "Stable Learning Using Spiking Neural Networks Equipped With Affine Encoders and Decoders", "categories": ["cs.NE", "cs.LG", "math.FA", "stat.ML"], "comment": null, "summary": "We study the learning problem associated with spiking neural networks.\nSpecifically, we focus on spiking neural networks composed of simple spiking\nneurons having only positive synaptic weights, equipped with an affine encoder\nand decoder; we refer to these as affine spiking neural networks. These neural\nnetworks are shown to depend continuously on their parameters, which\nfacilitates classical covering number-based generalization statements and\nsupports stable gradient-based training. We demonstrate that the positivity of\nthe weights enables a wide range of expressivity results, including\nrate-optimal approximation of smooth functions and dimension-independent\napproximation of Barron regular functions. In particular, we show in theory and\nsimulations that affine spiking neural networks are capable of approximating\nshallow ReLU neural networks. Furthermore, we apply these affine spiking neural\nnetworks to standard machine learning benchmarks and reach competitive results.\nFinally, we observe that from a generalization perspective, contrary to\nfeedforward neural networks or previous results for general spiking neural\nnetworks, the depth has little to no adverse effect on the generalization\ncapabilities.", "AI": {"tldr": "The paper studies affine spiking neural networks (SNNs) with positive synaptic weights, showing their continuous dependence on parameters, expressivity, and competitive performance in benchmarks. Depth minimally affects generalization.", "motivation": "To explore the learning capabilities of affine SNNs with positive weights and their potential to approximate other neural networks and functions.", "method": "Focuses on affine SNNs with positive weights, using covering number-based generalization and gradient-based training. Demonstrates expressivity through theoretical and simulation results.", "result": "Affine SNNs achieve rate-optimal and dimension-independent approximation, competitive benchmark performance, and depth-independent generalization.", "conclusion": "Affine SNNs are expressive, stable, and generalize well, with depth having little adverse effect, making them promising for practical applications."}}
{"id": "2405.04944", "pdf": "https://arxiv.org/pdf/2405.04944", "abs": "https://arxiv.org/abs/2405.04944", "authors": ["Tugba Torun", "Ameer Taweel", "Didem Unat"], "title": "A Sparse Tensor Generator with Efficient Feature Extraction", "categories": ["cs.MS", "cs.LG", "68W99", "G.4"], "comment": "22 pages, 4 figures, 7 tables", "summary": "Sparse tensor operations are increasingly important in diverse applications\nsuch as social networks, deep learning, diagnosis, crime, and review analysis.\nHowever, a major obstacle in sparse tensor research is the lack of large-scale\nsparse tensor datasets. Another challenge lies in analyzing sparse tensor\nfeatures, which are essential not only for understanding the nonzero pattern\nbut also for selecting the most suitable storage format, decomposition\nalgorithm, and reordering methods. However, due to the large size of real-world\ntensors, even extracting these features can be computationally expensive\nwithout careful optimization. To address these limitations, we have developed a\nsmart sparse tensor generator that replicates key characteristics of real\nsparse tensors. Additionally, we propose efficient methods for extracting a\ncomprehensive set of sparse tensor features. The effectiveness of our generator\nis validated through the quality of extracted features and the performance of\ndecomposition on the generated tensors. Both the sparse tensor feature\nextractor and the tensor generator are open source with all the artifacts\navailable at https://github.com/sparcityeu/FeaTensor and\nhttps://github.com/sparcityeu/GenTensor, respectively.", "AI": {"tldr": "A smart sparse tensor generator and feature extraction methods are introduced to address the lack of large-scale datasets and computational challenges in sparse tensor research.", "motivation": "The lack of large-scale sparse tensor datasets and the computational expense of analyzing sparse tensor features hinder research in applications like social networks and deep learning.", "method": "Developed a smart sparse tensor generator to replicate real tensor characteristics and proposed efficient methods for feature extraction.", "result": "Validated the generator's effectiveness through feature quality and decomposition performance. Tools are open-sourced.", "conclusion": "The proposed solutions address key challenges in sparse tensor research, with open-source tools available for broader use."}}
{"id": "2405.19805", "pdf": "https://arxiv.org/pdf/2405.19805", "abs": "https://arxiv.org/abs/2405.19805", "authors": ["Vincent Froese", "Moritz Grillo", "Martin Skutella"], "title": "Complexity of Injectivity and Verification of ReLU Neural Networks", "categories": ["cs.CC", "cs.DM", "cs.LG"], "comment": "26 pages, Accepted for presentation at the Conference on Learning\n  Theory (COLT) 2025", "summary": "Neural networks with ReLU activation play a key role in modern machine\nlearning. Understanding the functions represented by ReLU networks is a major\ntopic in current research as this enables a better interpretability of learning\nprocesses. Injectivity of a function computed by a ReLU network, that is, the\nquestion if different inputs to the network always lead to different outputs,\nplays a crucial role whenever invertibility of the function is required, such\nas, e.g., for inverse problems or generative models. The exact computational\ncomplexity of deciding injectivity was recently posed as an open problem\n(Puthawala et al. [JMLR 2022]). We answer this question by proving\ncoNP-completeness. On the positive side, we show that the problem for a single\nReLU-layer is still tractable for small input dimension; more precisely, we\npresent a parameterized algorithm which yields fixed-parameter tractability\nwith respect to the input dimension. In addition, we study the network\nverification problem which is to verify that certain inputs only yield specific\noutputs. This is of great importance since neural networks are increasingly\nused in safety-critical systems. We prove that network verification is\ncoNP-hard for a general class of input domains. Our results also exclude\nconstant-factor polynomial-time approximations for the maximum of a function\ncomputed by a ReLU network. In this context, we also characterize surjectivity\nof functions computed by ReLU networks with one-dimensional output which turns\nout to be the complement of a basic network verification task. We reveal\ninteresting connections to computational convexity by formulating the\nsurjectivity problem as a zonotope containment problem", "AI": {"tldr": "The paper addresses the computational complexity of injectivity in ReLU networks, proving it's coNP-complete, and explores tractability for single-layer networks. It also studies network verification and surjectivity, linking them to computational convexity.", "motivation": "Understanding ReLU networks is crucial for interpretability and safety in machine learning, especially for invertibility in tasks like inverse problems or generative models.", "method": "The paper proves coNP-completeness for injectivity, presents a parameterized algorithm for single-layer networks, and analyzes network verification and surjectivity problems.", "result": "Injectivity is coNP-complete; tractability for single-layer networks is shown. Network verification is coNP-hard, and surjectivity is linked to zonotope containment.", "conclusion": "The work provides insights into the complexity of ReLU network properties, with implications for safety-critical applications and computational convexity."}}
{"id": "2408.07503", "pdf": "https://arxiv.org/pdf/2408.07503", "abs": "https://arxiv.org/abs/2408.07503", "authors": ["Amit Attia", "Ofir Gaash", "Tomer Koren"], "title": "Faster Stochastic Optimization with Arbitrary Delays via Asynchronous Mini-Batching", "categories": ["math.OC", "cs.LG"], "comment": "22 pages", "summary": "We consider the problem of asynchronous stochastic optimization, where an\noptimization algorithm makes updates based on stale stochastic gradients of the\nobjective that are subject to an arbitrary (possibly adversarial) sequence of\ndelays. We present a procedure which, for any given $q \\in (0,1]$, transforms\nany standard stochastic first-order method to an asynchronous method with\nconvergence guarantee depending on the $q$-quantile delay of the sequence. This\napproach leads to convergence rates of the form $O(\\tau_q/qT+\\sigma/\\sqrt{qT})$\nfor non-convex and $O(\\tau_q^2/(q T)^2+\\sigma/\\sqrt{qT})$ for convex smooth\nproblems, where $\\tau_q$ is the $q$-quantile delay, generalizing and improving\non existing results that depend on the average delay. We further show a method\nthat automatically adapts to all quantiles simultaneously, without any prior\nknowledge of the delays, achieving convergence rates of the form $O(\\inf_{q}\n\\tau_q/qT+\\sigma/\\sqrt{qT})$ for non-convex and $O(\\inf_{q} \\tau_q^2/(q\nT)^2+\\sigma/\\sqrt{qT})$ for convex smooth problems. Our technique is based on\nasynchronous mini-batching with a careful batch-size selection and filtering of\nstale gradients.", "AI": {"tldr": "The paper presents a method to adapt standard stochastic optimization to asynchronous settings with arbitrary delays, improving convergence rates by leveraging quantile delays.", "motivation": "Address the challenge of asynchronous stochastic optimization where stale gradients and adversarial delays degrade performance.", "method": "Transform standard stochastic first-order methods into asynchronous ones using quantile delays, with adaptive mini-batching and gradient filtering.", "result": "Achieves improved convergence rates (O(\u03c4_q/qT + \u03c3/\u221aqT) for non-convex, O(\u03c4_q\u00b2/(qT)\u00b2 + \u03c3/\u221aqT) for convex) and adapts to all quantiles without prior delay knowledge.", "conclusion": "The proposed method generalizes and improves existing results, offering robust performance in asynchronous optimization."}}
{"id": "2410.18973", "pdf": "https://arxiv.org/pdf/2410.18973", "abs": "https://arxiv.org/abs/2410.18973", "authors": ["Naitong Chen", "Jonathan H. Huggins", "Trevor Campbell"], "title": "Tuning-Free Coreset Markov Chain Monte Carlo via Hot DoG", "categories": ["stat.CO", "cs.LG"], "comment": "Accepted to the 41st Conference on Uncertainty in Artificial\n  Intelligence (UAI 2025)", "summary": "A Bayesian coreset is a small, weighted subset of a data set that replaces\nthe full data during inference to reduce computational cost. The\nstate-of-the-art coreset construction algorithm, Coreset Markov chain Monte\nCarlo (Coreset MCMC), uses draws from an adaptive Markov chain targeting the\ncoreset posterior to train the coreset weights via stochastic gradient\noptimization. However, the quality of the constructed coreset, and thus the\nquality of its posterior approximation, is sensitive to the stochastic\noptimization learning rate. In this work, we propose a learning-rate-free\nstochastic gradient optimization procedure, Hot-start Distance over Gradient\n(Hot DoG), for training coreset weights in Coreset MCMC without user tuning\neffort. We provide a theoretical analysis of the convergence of the coreset\nweights produced by Hot DoG. We also provide empirical results demonstrate that\nHot DoG provides higher quality posterior approximations than other\nlearning-rate-free stochastic gradient methods, and performs competitively to\noptimally-tuned ADAM.", "AI": {"tldr": "A learning-rate-free stochastic gradient optimization method, Hot DoG, is proposed for training coreset weights in Coreset MCMC, improving posterior approximation quality without tuning effort.", "motivation": "To address the sensitivity of coreset quality to learning rate in Coreset MCMC, eliminating the need for user tuning.", "method": "Introduces Hot-start Distance over Gradient (Hot DoG), a learning-rate-free stochastic gradient optimization procedure for coreset weight training.", "result": "Hot DoG provides higher quality posterior approximations than other learning-rate-free methods and performs competitively with optimally-tuned ADAM.", "conclusion": "Hot DoG is an effective, tuning-free alternative for coreset weight optimization in Coreset MCMC."}}
{"id": "2410.24117", "pdf": "https://arxiv.org/pdf/2410.24117", "abs": "https://arxiv.org/abs/2410.24117", "authors": ["Ali Reza Ibrahimzada", "Kaiyao Ke", "Mrigank Pawagi", "Muhammad Salman Abid", "Rangeet Pan", "Saurabh Sinha", "Reyhaneh Jabbarvand"], "title": "AlphaTrans: A Neuro-Symbolic Compositional Approach for Repository-Level Code Translation and Validation", "categories": ["cs.SE", "cs.LG"], "comment": "Published in FSE 2025", "summary": "Code translation transforms programs from one programming language (PL) to\nanother. Several rule-based transpilers have been designed to automate code\ntranslation between different pairs of PLs. However, the rules can become\nobsolete as the PLs evolve and cannot generalize to other PLs. Recent studies\nhave explored the automation of code translation using Large Language Models\n(LLMs). One key observation is that such techniques may work well for crafted\nbenchmarks but fail to generalize to the scale and complexity of real-world\nprojects with dependencies, custom types, PL-specific features, etc. We propose\nAlphaTrans, a neuro-symbolic approach to automate repository-level code\ntranslation. AlphaTrans translates both source and test code, and employs\nmultiple levels of validation to ensure the translation preserves the\nfunctionality of the source program. To break down the problem for LLMs,\nAlphaTrans leverages program analysis to decompose the program into fragments\nand translates them in the reverse call order. We leveraged AlphaTrans to\ntranslate ten real-world open-source projects consisting of <836, 8575, 2719>\nclasses, methods, and tests. AlphaTrans breaks down these projects into 17874\nfragments and translates the entire repository. 96.40% of the translated\nfragments are syntactically correct, and AlphaTrans validates the translations'\nruntime behavior and functional correctness for 27.03% and 25.14% of fragments.\nOn average, the integrated translation and validation take 34 hours to\ntranslate a project, showing its scalability in practice. For the incorrect\ntranslations, AlphaTrans generates a report including existing translation,\nstack trace, test errors, or assertion failures. We provided these artifacts to\ntwo developers to fix the translation bugs in four projects. They were able to\nfix the issues in 20.1 hours on average and achieve all passing tests.", "AI": {"tldr": "AlphaTrans is a neuro-symbolic approach for repository-level code translation, combining LLMs and program analysis to handle real-world projects, ensuring functionality through validation.", "motivation": "Rule-based transpilers struggle with evolving PLs and real-world complexity; AlphaTrans aims to automate and scale code translation while preserving functionality.", "method": "AlphaTrans decomposes programs into fragments, translates them in reverse call order, and validates syntax, runtime behavior, and functional correctness.", "result": "AlphaTrans translated 10 projects with high syntactic correctness (96.40%) and validated runtime/functional correctness for ~25-27% of fragments, taking ~34 hours per project.", "conclusion": "AlphaTrans demonstrates scalability and effectiveness, though manual fixes are sometimes needed, as shown by developers fixing issues in 20.1 hours on average."}}
{"id": "2411.00463", "pdf": "https://arxiv.org/pdf/2411.00463", "abs": "https://arxiv.org/abs/2411.00463", "authors": ["Shiwei Sun", "Giovanni S. Alberti"], "title": "The learned range test method for the inverse inclusion problem", "categories": ["math.NA", "cs.LG", "cs.NA", "35R30, 65N21, 68T07"], "comment": "27 pages, 13 figures", "summary": "We consider the inverse problem consisting of the reconstruction of an\ninclusion $B$ contained in a bounded domain $\\Omega\\subset\\mathbb{R}^d$ from a\nsingle pair of Cauchy data $(u|_{\\partial\\Omega},\\partial_\\nu\nu|_{\\partial\\Omega})$, where $\\Delta u=0$ in $\\Omega\\setminus\\overline B$ and\n$u=0$ on $\\partial B$. We show that the reconstruction algorithm based on the\nrange test, a domain sampling method, can be written as a neural network with a\nspecific architecture. We propose to learn the weights of this network in the\nframework of supervised learning, and to combine it with a pre-trained\nclassifier, with the purpose of distinguishing the inclusions based on their\ndistance from the boundary. The numerical simulations show that this learned\nrange test method provides accurate and stable reconstructions of polygonal\ninclusions. Furthermore, the results are superior to those obtained with the\nstandard range test method (without learning) and with an end-to-end fully\nconnected deep neural network, a purely data-driven method.", "AI": {"tldr": "The paper proposes a neural network-based reconstruction algorithm for identifying inclusions in a domain using Cauchy data, outperforming traditional and purely data-driven methods.", "motivation": "To improve the accuracy and stability of reconstructing inclusions in a domain from limited Cauchy data by leveraging neural networks.", "method": "A neural network with a specific architecture is trained using supervised learning, combined with a pre-trained classifier to distinguish inclusions based on boundary distance.", "result": "The learned method provides more accurate and stable reconstructions of polygonal inclusions compared to traditional and purely data-driven approaches.", "conclusion": "The neural network-based approach enhances reconstruction performance, demonstrating the potential of combining domain knowledge with machine learning."}}
{"id": "2411.04056", "pdf": "https://arxiv.org/pdf/2411.04056", "abs": "https://arxiv.org/abs/2411.04056", "authors": ["Kiran Doshi", "Marco Bagatella", "Stelian Coros"], "title": "Problem Space Transformations for Out-of-Distribution Generalisation in Behavioural Cloning", "categories": ["cs.RO", "cs.LG"], "comment": null, "summary": "The combination of behavioural cloning and neural networks has driven\nsignificant progress in robotic manipulation. As these algorithms may require a\nlarge number of demonstrations for each task of interest, they remain\nfundamentally inefficient in complex scenarios, in which finite datasets can\nhardly cover the state space. One of the remaining challenges is thus\nout-of-distribution (OOD) generalisation, i.e. the ability to predict correct\nactions for states with a low likelihood with respect to the state occupancy\ninduced by the dataset. This issue is aggravated when the system to control is\ntreated as a black-box, ignoring its physical properties. This work\ncharacterises widespread properties of robotic manipulation, specifically pose\nequivariance and locality. We investigate the effect of the choice of problem\nspace on OOD performance of BC policies and how transformations arising from\ncharacteristic properties of manipulation could be employed for its\nimprovement. We empirically demonstrate that these transformations allow\nbehaviour cloning policies, using either standard MLP-based one-step action\nprediction or diffusion-based action-sequence prediction, to generalise better\nto OOD problem instances.", "AI": {"tldr": "The paper explores improving out-of-distribution (OOD) generalization in robotic manipulation by leveraging pose equivariance and locality properties, enhancing behavior cloning policies.", "motivation": "Behavioral cloning and neural networks struggle with OOD generalization in complex robotic manipulation tasks due to limited dataset coverage of the state space.", "method": "The study investigates the impact of problem space choice on OOD performance and uses pose equivariance and locality transformations to improve behavior cloning policies, tested with MLP-based and diffusion-based action prediction.", "result": "Empirical results show that incorporating these transformations enhances OOD generalization for behavior cloning policies.", "conclusion": "Leveraging robotic manipulation properties like pose equivariance and locality can significantly improve OOD generalization in behavior cloning."}}
{"id": "2412.08961", "pdf": "https://arxiv.org/pdf/2412.08961", "abs": "https://arxiv.org/abs/2412.08961", "authors": ["Yin Tang", "Bing Li"], "title": "Belted and Ensembled Neural Network for Linear and Nonlinear Sufficient Dimension Reduction", "categories": ["stat.ML", "cs.LG", "math.ST", "stat.TH"], "comment": "35 pages, 4 figures, 1 table", "summary": "We introduce a unified, flexible, and easy-to-implement framework of\nsufficient dimension reduction that can accommodate both linear and nonlinear\ndimension reduction, and both the conditional distribution and the conditional\nmean as the targets of estimation. This unified framework is achieved by a\nspecially structured neural network -- the Belted and Ensembled Neural Network\n(BENN) -- that consists of a narrow latent layer, which we call the belt, and a\nfamily of transformations of the response, which we call the ensemble. By\nstrategically placing the belt at different layers of the neural network, we\ncan achieve linear or nonlinear sufficient dimension reduction, and by choosing\nthe appropriate transformation families, we can achieve dimension reduction for\nthe conditional distribution or the conditional mean. Moreover, thanks to the\nadvantage of the neural network, the method is very fast to compute, overcoming\na computation bottleneck of the traditional sufficient dimension reduction\nestimators, which involves the inversion of a matrix of dimension either p or\nn. We develop the algorithm and convergence rate of our method, compare it with\nexisting sufficient dimension reduction methods, and apply it to two data\nexamples.", "AI": {"tldr": "A unified framework for sufficient dimension reduction using a neural network (BENN) that handles linear/nonlinear reduction and targets conditional distribution/mean, offering fast computation.", "motivation": "To address limitations of traditional sufficient dimension reduction methods, which are computationally intensive due to matrix inversions, and to unify linear/nonlinear approaches.", "method": "Uses a Belted and Ensembled Neural Network (BENN) with a narrow latent layer (belt) and response transformations (ensemble) to achieve flexible dimension reduction.", "result": "The method is computationally efficient, avoids matrix inversions, and performs well compared to existing techniques, as demonstrated in data examples.", "conclusion": "BENN provides a fast, flexible, and unified solution for sufficient dimension reduction, overcoming computational bottlenecks of traditional methods."}}
{"id": "2412.15808", "pdf": "https://arxiv.org/pdf/2412.15808", "abs": "https://arxiv.org/abs/2412.15808", "authors": ["Ed Mackay", "Callum Murphy-Barltrop", "Jordan Richards", "Philip Jonathan"], "title": "Deep learning joint extremes of metocean variables using the SPAR model", "categories": ["stat.ML", "cs.LG", "stat.ME", "62G32"], "comment": null, "summary": "This paper presents a novel deep learning framework for estimating\nmultivariate joint extremes of metocean variables, based on the Semi-Parametric\nAngular-Radial (SPAR) model. When considered in polar coordinates, the problem\nof modelling multivariate extremes is transformed to one of modelling an\nangular density, and the tail of a univariate radial variable conditioned on\nangle. In the SPAR approach, the tail of the radial variable is modelled using\na generalised Pareto (GP) distribution, providing a natural extension of\nunivariate extreme value theory to the multivariate setting. In this work, we\nshow how the method can be applied in higher dimensions, using a case study for\nfive metocean variables: wind speed, wind direction, wave height, wave period,\nand wave direction. The angular variable is modelled using a kernel density\nmethod, while the parameters of the GP model are approximated using\nfully-connected deep neural networks. Our approach provides great flexibility\nin the dependence structures that can be represented, together with\ncomputationally efficient routines for training the model. Furthermore, the\napplication of the method requires fewer assumptions about the underlying\ndistribution(s) compared to existing approaches, and an asymptotically\njustified means for extrapolating outside the range of observations. Using\nvarious diagnostic plots, we show that the fitted models provide a good\ndescription of the joint extremes of the metocean variables considered.", "AI": {"tldr": "A deep learning framework for estimating multivariate joint extremes of metocean variables using the Semi-Parametric Angular-Radial (SPAR) model, combining kernel density for angular variables and GP distribution for radial tails.", "motivation": "To address the challenge of modeling multivariate extremes in metocean variables with flexible dependence structures and fewer assumptions.", "method": "Uses SPAR model with GP distribution for radial tails and kernel density for angular variables, enhanced by deep neural networks for parameter approximation.", "result": "Provides a flexible, computationally efficient model for joint extremes, validated by diagnostic plots.", "conclusion": "The SPAR-based deep learning approach effectively models multivariate extremes with fewer assumptions and good extrapolation capabilities."}}
{"id": "2502.11909", "pdf": "https://arxiv.org/pdf/2502.11909", "abs": "https://arxiv.org/abs/2502.11909", "authors": ["Gefan Yang", "Frank van der Meulen", "Stefan Sommer"], "title": "Neural Guided Diffusion Bridges", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "We propose a novel method for simulating conditioned diffusion processes\n(diffusion bridges) in Euclidean spaces. By training a neural network to\napproximate bridge dynamics, our approach eliminates the need for\ncomputationally intensive Markov Chain Monte Carlo (MCMC) methods or score\nmodeling. Compared to existing methods, it offers greater robustness across\nvarious diffusion specifications and conditioning scenarios. This applies in\nparticular to rare events and multimodal distributions, which pose challenges\nfor score-learning- and MCMC-based approaches. We introduce a flexible\nvariational family, partially specified by a neural network, for approximating\nthe diffusion bridge path measure. Once trained, it enables efficient sampling\nof independent bridges at a cost comparable to sampling the unconditioned\n(forward) process.", "AI": {"tldr": "A neural network-based method for simulating diffusion bridges, avoiding MCMC or score modeling, offering robustness and efficiency.", "motivation": "Existing methods for simulating diffusion bridges are computationally intensive (MCMC) or rely on score modeling, struggling with rare events and multimodal distributions.", "method": "Train a neural network to approximate bridge dynamics, using a flexible variational family partially specified by the network.", "result": "The method is robust across diffusion specifications and conditioning scenarios, efficient for rare events and multimodal distributions.", "conclusion": "The approach enables efficient sampling of independent bridges, comparable in cost to sampling the unconditioned process."}}
{"id": "2503.14253", "pdf": "https://arxiv.org/pdf/2503.14253", "abs": "https://arxiv.org/abs/2503.14253", "authors": ["Jakub Malinowski", "Marcin Kostrzewa", "Micha\u0142 Balcerek", "Weronika Tomczuk", "Janusz Szwabi\u0144ski"], "title": "CINNAMON: A hybrid approach to change point detection and parameter estimation in single-particle tracking data", "categories": ["q-bio.QM", "cs.LG"], "comment": null, "summary": "Change point detection has become an important part of the analysis of the\nsingle-particle tracking data, as it allows one to identify moments, in which\nthe motion patterns of observed particles undergo significant changes. The\nsegmentation of diffusive trajectories based on those moments may provide\ninsight into various phenomena in soft condensed matter and biological physics.\nIn this paper, we propose CINNAMON, a hybrid approach to classifying\nsingle-particle tracking trajectories, detecting change points within them, and\nestimating diffusion parameters in the segments between the change points. Our\nmethod is based on a combination of neural networks, feature-based machine\nlearning, and statistical techniques. It has been benchmarked in the second\nAnomalous Diffusion Challenge. The method offers a high level of\ninterpretability due to its analytical and feature-based components. A\npotential use of features from topological data analysis is also discussed.", "AI": {"tldr": "CINNAMON is a hybrid method for classifying single-particle tracking trajectories, detecting change points, and estimating diffusion parameters, combining neural networks, machine learning, and statistical techniques.", "motivation": "Change point detection in single-particle tracking data is crucial for understanding motion pattern changes, aiding studies in soft condensed matter and biological physics.", "method": "CINNAMON integrates neural networks, feature-based machine learning, and statistical techniques to classify trajectories, detect change points, and estimate diffusion parameters.", "result": "Benchmarked in the second Anomalous Diffusion Challenge, the method provides high interpretability and discusses potential use of topological data analysis features.", "conclusion": "CINNAMON offers a robust, interpretable solution for analyzing single-particle tracking data, with potential applications in diverse scientific fields."}}
{"id": "2504.06316", "pdf": "https://arxiv.org/pdf/2504.06316", "abs": "https://arxiv.org/abs/2504.06316", "authors": ["Ziwei Yang", "Takeyuki Tamura"], "title": "DeepGDel: Deep Learning-based Gene Deletion Prediction Framework for Growth-Coupled Production in Genome-Scale Metabolic Models", "categories": ["q-bio.QM", "cs.LG"], "comment": null, "summary": "In genome-scale constraint-based metabolic models, gene deletion strategies\nare crucial for achieving growth-coupled production, where cell growth and\ntarget metabolite production are simultaneously achieved. While computational\nmethods for calculating gene deletions have been widely explored and contribute\nto developing gene deletion strategy databases, current approaches are limited\nin leveraging new data-driven paradigms, such as machine learning, for more\nefficient strain design. Therefore, it is necessary to propose a fundamental\nframework for this objective. In this study, we first formulate the problem of\ngene deletion strategy prediction and then propose a framework for predicting\ngene deletion strategies for growth-coupled production in genome-scale\nmetabolic models. The proposed framework leverages deep learning algorithms to\nlearn and integrate sequential gene and metabolite data representation,\nenabling the automatic gene deletion strategy prediction. Computational\nexperiment results demonstrate the feasibility of the proposed framework,\nshowing substantial improvements over baseline methods. Specifically, the\nproposed framework achieves a 14.69%, 22.52%, and 13.03% increase in overall\naccuracy across three metabolic models of different scales under study, while\nmaintaining balanced precision and recall in predicting gene deletion statuses.\nThe source code and examples for the framework are publicly available at\nhttps://github.com/MetNetComp/DeepGDel.", "AI": {"tldr": "A deep learning framework is proposed to predict gene deletion strategies for growth-coupled production in metabolic models, outperforming baseline methods.", "motivation": "Current computational methods for gene deletion strategies lack integration with data-driven paradigms like machine learning, necessitating a new framework.", "method": "The framework uses deep learning to integrate sequential gene and metabolite data for automatic prediction of gene deletion strategies.", "result": "The framework improves accuracy by 14.69%, 22.52%, and 13.03% across three metabolic models while maintaining balanced precision and recall.", "conclusion": "The proposed framework is feasible and effective, with publicly available source code for further use."}}
{"id": "2504.07818", "pdf": "https://arxiv.org/pdf/2504.07818", "abs": "https://arxiv.org/abs/2504.07818", "authors": ["Hugo Lebeau"], "title": "Performance of Rank-One Tensor Approximation on Incomplete Data", "categories": ["stat.ML", "cs.LG", "math.PR"], "comment": null, "summary": "We are interested in the estimation of a rank-one tensor signal when only a\nportion $\\varepsilon$ of its noisy observation is available. We show that the\nstudy of this problem can be reduced to that of a random matrix model whose\nspectral analysis gives access to the reconstruction performance. These results\nshed light on and specify the loss of performance induced by an artificial\nreduction of the memory cost of a tensor via the deletion of a random part of\nits entries.", "AI": {"tldr": "The paper studies the estimation of a rank-one tensor signal from partial noisy observations, linking it to a random matrix model for performance analysis.", "motivation": "To understand the performance loss when reducing memory cost by randomly deleting tensor entries.", "method": "Reduces the problem to a random matrix model and analyzes its spectrum.", "result": "Provides insights into the performance degradation due to partial observation.", "conclusion": "The study clarifies the trade-off between memory reduction and reconstruction performance."}}
{"id": "2504.10545", "pdf": "https://arxiv.org/pdf/2504.10545", "abs": "https://arxiv.org/abs/2504.10545", "authors": ["Yijun Liu"], "title": "HSTU-BLaIR: Lightweight Contrastive Text Embedding for Generative Recommender", "categories": ["cs.IR", "cs.LG"], "comment": "Accepted at the Workshop on Large Language Models for E-Commerce, KDD\n  2025. Code available at https://www.github.com/snapfinger/HSTU-BLaIR", "summary": "Recent advances in recommender systems have underscored the complementary\nstrengths of generative modeling and pretrained language models. We propose\nHSTU-BLaIR, a hybrid framework that augments the Hierarchical Sequential\nTransduction Unit (HSTU)-based generative recommender with BLaIR, a lightweight\ncontrastive text embedding model. This integration enriches item\nrepresentations with semantic signals from textual metadata while preserving\nHSTU's powerful sequence modeling capabilities.\n  We evaluate HSTU-BLaIR on two e-commerce datasets: three subsets from the\nAmazon Reviews 2023 dataset and the Steam dataset. We compare its performance\nagainst both the original HSTU-based recommender and a variant augmented with\nembeddings from OpenAI's state-of-the-art \\texttt{text-embedding-3-large}\nmodel. Despite the latter being trained on a substantially larger corpus with\nsignificantly more parameters, our lightweight BLaIR-enhanced approach --\npretrained on domain-specific data -- achieves better performance in nearly all\ncases. Specifically, HSTU-BLaIR outperforms the OpenAI embedding-based variant\non all but one metric, where it is marginally lower, and matches it on another.\nThese findings highlight the effectiveness of contrastive text embeddings in\ncompute-efficient recommendation settings.", "AI": {"tldr": "HSTU-BLaIR combines HSTU's sequence modeling with BLaIR's contrastive text embeddings, outperforming OpenAI's larger model in most metrics.", "motivation": "To enhance recommender systems by integrating generative modeling (HSTU) with lightweight contrastive text embeddings (BLaIR) for richer item representations.", "method": "Proposes HSTU-BLaIR, a hybrid framework combining HSTU and BLaIR, evaluated on Amazon Reviews and Steam datasets against HSTU and OpenAI's text-embedding-3-large.", "result": "HSTU-BLaIR outperforms OpenAI's model in nearly all metrics, demonstrating the effectiveness of domain-specific contrastive embeddings.", "conclusion": "Contrastive text embeddings (BLaIR) are highly effective for compute-efficient recommender systems, even against larger models."}}
{"id": "2504.16688", "pdf": "https://arxiv.org/pdf/2504.16688", "abs": "https://arxiv.org/abs/2504.16688", "authors": ["Nahshon Mokua Obiri", "Kristof Van Laerhoven"], "title": "A Statistical Evaluation of Indoor LoRaWAN Environment-Aware Propagation for 6G: MLR, ANOVA, and Residual Distribution Analysis", "categories": ["cs.NI", "cs.LG", "eess.SP"], "comment": "\\c{opyright} 2025 IEEE. Personal use of this material is permitted.\n  Permission from IEEE must be obtained for all other uses, in any current or\n  future media. This is the accepted version of the article: To appear in the\n  2025 Joint European Conference on Networks and Communications & 6G Summit\n  (EuCNC/6G Summit)", "summary": "Modeling path loss in indoor LoRaWAN technology deployments is inherently\nchallenging due to structural obstructions, occupant density and activities,\nand fluctuating environmental conditions. This study proposes a two-stage\napproach to capture and analyze these complexities using an extensive dataset\nof 1,328,334 field measurements collected over six months in a single-floor\noffice at the University of Siegen's Hoelderlinstrasse Campus, Germany. First,\nwe implement a multiple linear regression model that includes traditional\npropagation metrics (distance, structural walls) and an extension with proposed\nenvironmental variables (relative humidity, temperature, carbon dioxide,\nparticulate matter, and barometric pressure). Using analysis of variance, we\ndemonstrate that adding these environmental factors can reduce unexplained\nvariance by 42.32 percent. Secondly, we examine residual distributions by\nfitting five candidate probability distributions: Normal, Skew-Normal, Cauchy,\nStudent's t, and Gaussian Mixture Models (GMMs) with 2 to 5 components. Our\nresults show that a four-component Gaussian Mixture Model captures the residual\nheterogeneity of indoor signal propagation most accurately, significantly\noutperforming single-distribution approaches. Given the push toward\nultra-reliable, context-aware communications in 6G networks, our analysis shows\nthat environment-aware modeling can substantially improve LoRaWAN network\ndesign in dynamic indoor IoT deployments.", "AI": {"tldr": "The study proposes a two-stage approach to model indoor LoRaWAN path loss, incorporating environmental factors and Gaussian Mixture Models, improving accuracy by 42.32%.", "motivation": "Challenges in modeling indoor LoRaWAN path loss due to structural and environmental complexities.", "method": "Two-stage approach: multiple linear regression with environmental variables and fitting residual distributions using Gaussian Mixture Models.", "result": "Environmental factors reduce unexplained variance by 42.32%; a four-component Gaussian Mixture Model best captures residual heterogeneity.", "conclusion": "Environment-aware modeling enhances LoRaWAN network design for dynamic indoor IoT, aligning with 6G goals."}}
{"id": "2505.00310", "pdf": "https://arxiv.org/pdf/2505.00310", "abs": "https://arxiv.org/abs/2505.00310", "authors": ["Maximilian Schuessler", "Erik Sverdrup", "Robert Tibshirani"], "title": "Statistical Learning for Heterogeneous Treatment Effects: Pretraining, Prognosis, and Prediction", "categories": ["stat.ML", "cs.LG", "stat.ME"], "comment": null, "summary": "Robust estimation of heterogeneous treatment effects is a fundamental\nchallenge for optimal decision-making in domains ranging from personalized\nmedicine to educational policy. In recent years, predictive machine learning\nhas emerged as a valuable toolbox for causal estimation, enabling more flexible\neffect estimation. However, accurately estimating conditional average treatment\neffects (CATE) remains a major challenge, particularly in the presence of many\ncovariates. In this article, we propose pretraining strategies that leverage a\nphenomenon in real-world applications: factors that are prognostic of the\noutcome are frequently also predictive of treatment effect heterogeneity. In\nmedicine, for example, components of the same biological signaling pathways\nfrequently influence both baseline risk and treatment response. Specifically,\nwe demonstrate our approach within the R-learner framework, which estimates the\nCATE by solving individual prediction problems based on a residualized loss. We\nuse this structure to incorporate side information and develop models that can\nexploit synergies between risk prediction and causal effect estimation. In\nsettings where these synergies are present, this cross-task learning enables\nmore accurate signal detection, yields lower estimation error, reduced false\ndiscovery rates, and higher power for detecting heterogeneity.", "AI": {"tldr": "The paper proposes pretraining strategies to improve CATE estimation by leveraging prognostic factors that also predict treatment effect heterogeneity, enhancing accuracy and reducing errors.", "motivation": "Robust estimation of heterogeneous treatment effects is crucial for optimal decision-making, but current methods struggle with many covariates.", "method": "The approach integrates pretraining within the R-learner framework, using residualized loss and side information to exploit synergies between risk prediction and causal effect estimation.", "result": "The method improves signal detection, reduces estimation error and false discovery rates, and increases power for detecting heterogeneity.", "conclusion": "Cross-task learning leveraging prognostic factors enhances CATE estimation, offering practical benefits in fields like medicine."}}
{"id": "2505.16901", "pdf": "https://arxiv.org/pdf/2505.16901", "abs": "https://arxiv.org/abs/2505.16901", "authors": ["Hongyuan Tao", "Ying Zhang", "Zhenhao Tang", "Hongen Peng", "Xukun Zhu", "Bingchang Liu", "Yingguang Yang", "Ziyin Zhang", "Zhaogui Xu", "Haipeng Zhang", "Linchao Zhu", "Rui Wang", "Hang Yu", "Jianguo Li", "Peng Di"], "title": "Code Graph Model (CGM): A Graph-Integrated Large Language Model for Repository-Level Software Engineering Tasks", "categories": ["cs.SE", "cs.LG"], "comment": "35 pages, 10 figures", "summary": "Recent advances in Large Language Models (LLMs) have shown promise in\nfunction-level code generation, yet repository-level software engineering tasks\nremain challenging. Current solutions predominantly rely on proprietary LLM\nagents, which introduce unpredictability and limit accessibility, raising\nconcerns about data privacy and model customization. This paper investigates\nwhether open-source LLMs can effectively address repository-level tasks without\nrequiring agent-based approaches. We demonstrate this is possible by enabling\nLLMs to comprehend functions and files within codebases through their semantic\ninformation and structural dependencies. To this end, we introduce Code Graph\nModels (CGMs), which integrate repository code graph structures into the LLM's\nattention mechanism and map node attributes to the LLM's input space using a\nspecialized adapter. When combined with an agentless graph RAG framework, our\napproach achieves a 43.00% resolution rate on the SWE-bench Lite benchmark\nusing the open-source Qwen2.5-72B model. This performance ranks first among\nopen weight models, second among methods with open-source systems, and eighth\noverall, surpassing the previous best open-source model-based method by 12.33%.", "AI": {"tldr": "Open-source LLMs can effectively handle repository-level tasks using Code Graph Models (CGMs) without agent-based approaches, achieving a 43.00% resolution rate on SWE-bench Lite.", "motivation": "Current proprietary LLM agents for repository-level tasks introduce unpredictability, accessibility issues, and privacy concerns. This paper explores open-source alternatives.", "method": "Introduces CGMs, integrating repository code graph structures into LLMs' attention mechanisms and using a specialized adapter for node attributes. Combines with an agentless graph RAG framework.", "result": "Achieves 43.00% resolution rate on SWE-bench Lite, ranking first among open-weight models and surpassing the previous best open-source method by 12.33%.", "conclusion": "Open-source LLMs with CGMs can effectively address repository-level tasks, offering a viable alternative to proprietary solutions."}}
{"id": "2505.18493", "pdf": "https://arxiv.org/pdf/2505.18493", "abs": "https://arxiv.org/abs/2505.18493", "authors": ["Xiang Li", "Yunai Li", "Huiying Zhong", "Lihua Lei", "Zhun Deng"], "title": "Statistical Inference under Performativity", "categories": ["stat.ML", "cs.LG", "math.ST", "stat.TH"], "comment": null, "summary": "Performativity of predictions refers to the phenomena that\nprediction-informed decisions may influence the target they aim to predict,\nwhich is widely observed in policy-making in social sciences and economics. In\nthis paper, we initiate the study of statistical inference under\nperformativity. Our contribution is two-fold. First, we build a central limit\ntheorem for estimation and inference under performativity, which enables\ninferential purposes in policy-making such as constructing confidence intervals\nor testing hypotheses. Second, we further leverage the derived central limit\ntheorem to investigate prediction-powered inference (PPI) under performativity,\nwhich is based on a small labeled dataset and a much larger dataset of\nmachine-learning predictions. This enables us to obtain more precise estimation\nand improved confidence regions for the model parameter (i.e., policy) of\ninterest in performative prediction. We demonstrate the power of our framework\nby numerical experiments. To the best of our knowledge, this paper is the first\none to establish statistical inference under performativity, which brings up\nnew challenges and inference settings that we believe will add significant\nvalues to policy-making, statistics, and machine learning.", "AI": {"tldr": "The paper introduces statistical inference under performativity, where predictions influence outcomes, and develops a central limit theorem for estimation and inference, including prediction-powered inference (PPI).", "motivation": "To address the lack of statistical inference methods for performative predictions, which are common in policy-making, economics, and social sciences.", "method": "Develops a central limit theorem for performative predictions and applies it to PPI, using small labeled datasets and larger prediction datasets.", "result": "Enables precise estimation and improved confidence regions for model parameters in performative settings, validated by numerical experiments.", "conclusion": "This is the first work to establish statistical inference under performativity, offering new tools for policy-making, statistics, and machine learning."}}
{"id": "2505.22094", "pdf": "https://arxiv.org/pdf/2505.22094", "abs": "https://arxiv.org/abs/2505.22094", "authors": ["Tonghe Zhang", "Chao Yu", "Sichang Su", "Yu Wang"], "title": "ReinFlow: Fine-tuning Flow Matching Policy with Online Reinforcement Learning", "categories": ["cs.RO", "cs.LG"], "comment": "31 pages, 13 figures, 10 tables", "summary": "We propose ReinFlow, a simple yet effective online reinforcement learning\n(RL) framework that fine-tunes a family of flow matching policies for\ncontinuous robotic control. Derived from rigorous RL theory, ReinFlow injects\nlearnable noise into a flow policy's deterministic path, converting the flow\ninto a discrete-time Markov Process for exact and straightforward likelihood\ncomputation. This conversion facilitates exploration and ensures training\nstability, enabling ReinFlow to fine-tune diverse flow model variants,\nincluding Rectified Flow [35] and Shortcut Models [19], particularly at very\nfew or even one denoising step. We benchmark ReinFlow in representative\nlocomotion and manipulation tasks, including long-horizon planning with visual\ninput and sparse reward. The episode reward of Rectified Flow policies obtained\nan average net growth of 135.36% after fine-tuning in challenging legged\nlocomotion tasks while saving denoising steps and 82.63% of wall time compared\nto state-of-the-art diffusion RL fine-tuning method DPPO [43]. The success rate\nof the Shortcut Model policies in state and visual manipulation tasks achieved\nan average net increase of 40.34% after fine-tuning with ReinFlow at four or\neven one denoising step, whose performance is comparable to fine-tuned DDIM\npolicies while saving computation time for an average of 23.20%. Project\nwebpage: https://reinflow.github.io/", "AI": {"tldr": "ReinFlow is an online RL framework for fine-tuning flow matching policies in robotic control, improving performance and efficiency.", "motivation": "To enhance robotic control by fine-tuning flow matching policies with learnable noise for better exploration and stability.", "method": "Injects learnable noise into flow policies, converting them into a Markov Process for exact likelihood computation, enabling fine-tuning of models like Rectified Flow and Shortcut Models.", "result": "Achieves significant performance gains (e.g., 135.36% reward growth in locomotion) and computational savings (e.g., 82.63% wall time reduction) compared to state-of-the-art methods.", "conclusion": "ReinFlow effectively improves robotic control policies with fewer denoising steps and reduced computation time."}}
{"id": "2506.06243", "pdf": "https://arxiv.org/pdf/2506.06243", "abs": "https://arxiv.org/abs/2506.06243", "authors": ["Benjamin Smith", "Jianhui Gao", "Jessica Gronsbell"], "title": "fairmetrics: An R package for group fairness evaluation", "categories": ["stat.CO", "cs.LG", "stat.ML", "G.3; G.4"], "comment": "6 pages, 1 figure, 1 table", "summary": "Fairness is a growing area of machine learning (ML) that focuses on ensuring\nmodels do not produce systematically biased outcomes for specific groups,\nparticularly those defined by protected attributes such as race, gender, or\nage. Evaluating fairness is a critical aspect of ML model development, as\nbiased models can perpetuate structural inequalities. The {fairmetrics} R\npackage offers a user-friendly framework for rigorously evaluating numerous\ngroup-based fairness criteria, including metrics based on independence (e.g.,\nstatistical parity), separation (e.g., equalized odds), and sufficiency (e.g.,\npredictive parity). Group-based fairness criteria assess whether a model is\nequally accurate or well-calibrated across a set of predefined groups so that\nappropriate bias mitigation strategies can be implemented. {fairmetrics}\nprovides both point and interval estimates for multiple metrics through a\nconvenient wrapper function and includes an example dataset derived from the\nMedical Information Mart for Intensive Care, version II (MIMIC-II) database\n(Goldberger et al., 2000; Raffa, 2016).", "AI": {"tldr": "The paper introduces the {fairmetrics} R package for evaluating group-based fairness in ML models, addressing biases related to protected attributes like race, gender, or age.", "motivation": "Ensuring fairness in ML models is crucial to prevent biased outcomes and structural inequalities.", "method": "The {fairmetrics} package provides a framework for assessing fairness using metrics like statistical parity, equalized odds, and predictive parity, with point and interval estimates.", "result": "The package includes a user-friendly wrapper function and an example dataset from MIMIC-II for practical application.", "conclusion": "{fairmetrics} facilitates rigorous fairness evaluation, aiding in bias mitigation for ML models."}}
{"id": "2506.12779", "pdf": "https://arxiv.org/pdf/2506.12779", "abs": "https://arxiv.org/abs/2506.12779", "authors": ["Yuxuan Wang", "Ming Yang", "Weishuai Zeng", "Yu Zhang", "Xinrun Xu", "Haobin Jiang", "Ziluo Ding", "Zongqing Lu"], "title": "From Experts to a Generalist: Toward General Whole-Body Control for Humanoid Robots", "categories": ["cs.RO", "cs.LG"], "comment": null, "summary": "Achieving general agile whole-body control on humanoid robots remains a major\nchallenge due to diverse motion demands and data conflicts. While existing\nframeworks excel in training single motion-specific policies, they struggle to\ngeneralize across highly varied behaviors due to conflicting control\nrequirements and mismatched data distributions. In this work, we propose\nBumbleBee (BB), an expert-generalist learning framework that combines motion\nclustering and sim-to-real adaptation to overcome these challenges. BB first\nleverages an autoencoder-based clustering method to group behaviorally similar\nmotions using motion features and motion descriptions. Expert policies are then\ntrained within each cluster and refined with real-world data through iterative\ndelta action modeling to bridge the sim-to-real gap. Finally, these experts are\ndistilled into a unified generalist controller that preserves agility and\nrobustness across all motion types. Experiments on two simulations and a real\nhumanoid robot demonstrate that BB achieves state-of-the-art general whole-body\ncontrol, setting a new benchmark for agile, robust, and generalizable humanoid\nperformance in the real world.", "AI": {"tldr": "BumbleBee (BB) is an expert-generalist framework for agile whole-body control on humanoid robots, combining motion clustering and sim-to-real adaptation to generalize across diverse behaviors.", "motivation": "Existing frameworks struggle with generalizing across varied behaviors due to conflicting control requirements and data mismatches.", "method": "BB uses autoencoder-based clustering to group similar motions, trains expert policies per cluster, refines them with real-world data, and distills them into a unified controller.", "result": "BB achieves state-of-the-art general whole-body control in simulations and on a real humanoid robot.", "conclusion": "BB sets a new benchmark for agile, robust, and generalizable humanoid performance in real-world scenarios."}}
{"id": "2506.14673", "pdf": "https://arxiv.org/pdf/2506.14673", "abs": "https://arxiv.org/abs/2506.14673", "authors": ["Mikael M\u00f8ller H\u00f8gsgaard", "Andrea Paudice"], "title": "Uniform Mean Estimation for Heavy-Tailed Distributions via Median-of-Means", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "The Median of Means (MoM) is a mean estimator that has gained popularity in\nthe context of heavy-tailed data. In this work, we analyze its performance in\nthe task of simultaneously estimating the mean of each function in a class\n$\\mathcal{F}$ when the data distribution possesses only the first $p$ moments\nfor $p \\in (1,2]$. We prove a new sample complexity bound using a novel\nsymmetrization technique that may be of independent interest. Additionally, we\npresent applications of our result to $k$-means clustering with unbounded\ninputs and linear regression with general losses, improving upon existing\nworks.", "AI": {"tldr": "The paper analyzes the Median of Means (MoM) estimator for heavy-tailed data, proving a new sample complexity bound and applying it to clustering and regression.", "motivation": "To improve mean estimation for heavy-tailed data with limited moments (p \u2208 (1,2]) and extend applications to clustering and regression.", "method": "Uses a novel symmetrization technique to derive sample complexity bounds for MoM.", "result": "Proves a new sample complexity bound and demonstrates improved performance in k-means clustering and linear regression.", "conclusion": "The MoM estimator is effective for heavy-tailed data and has practical applications in clustering and regression."}}
{"id": "2506.14772", "pdf": "https://arxiv.org/pdf/2506.14772", "abs": "https://arxiv.org/abs/2506.14772", "authors": ["Jakob De Moor", "Hans Weytjens", "Johannes De Smedt", "Jochen De Weerdt"], "title": "SimBank: from Simulation to Solution in Prescriptive Process Monitoring", "categories": ["cs.DB", "cs.LG"], "comment": null, "summary": "Prescriptive Process Monitoring (PresPM) is an emerging area within Process\nMining, focused on optimizing processes through real-time interventions for\neffective decision-making. PresPM holds significant promise for organizations\nseeking enhanced operational performance. However, the current literature faces\ntwo key limitations: a lack of extensive comparisons between techniques and\ninsufficient evaluation approaches. To address these gaps, we introduce\nSimBank: a simulator designed for accurate benchmarking of PresPM methods.\nModeled after a bank's loan application process, SimBank enables extensive\ncomparisons of both online and offline PresPM methods. It incorporates a\nvariety of intervention optimization problems with differing levels of\ncomplexity and supports experiments on key causal machine learning challenges,\nsuch as assessing a method's robustness to confounding in data. SimBank\nadditionally offers a comprehensive evaluation capability: for each test case,\nit can generate the true outcome under each intervention action, which is not\npossible using recorded datasets. The simulator incorporates parallel\nactivities and loops, drawing from common logs to generate cases that closely\nresemble real-life process instances. Our proof of concept demonstrates\nSimBank's benchmarking capabilities through experiments with various PresPM\nmethods across different interventions, highlighting its value as a publicly\navailable simulator for advancing research and practice in PresPM.", "AI": {"tldr": "The paper introduces SimBank, a simulator for benchmarking Prescriptive Process Monitoring (PresPM) methods, addressing gaps in current literature by enabling extensive comparisons and robust evaluations.", "motivation": "Current PresPM literature lacks comprehensive technique comparisons and evaluation methods, limiting its practical application.", "method": "SimBank simulates a bank's loan application process, incorporating diverse intervention optimization problems and causal machine learning challenges.", "result": "SimBank provides accurate benchmarking, generating true outcomes for interventions and supporting experiments on robustness and complexity.", "conclusion": "SimBank is a valuable tool for advancing PresPM research and practice, demonstrated through proof-of-concept experiments."}}
