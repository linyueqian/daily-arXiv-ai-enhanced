{"id": "2506.03530", "pdf": "https://arxiv.org/pdf/2506.03530", "abs": "https://arxiv.org/abs/2506.03530", "authors": ["Guanzhou Ke", "Yi Xie", "Xiaoli Wang", "Guoqing Chao", "Bo Wang", "Shengfeng He"], "title": "How Far Are We from Predicting Missing Modalities with Foundation Models?", "categories": ["cs.MM", "cs.CL", "cs.CV"], "comment": null, "summary": "Multimodal foundation models have demonstrated impressive capabilities across\ndiverse tasks. However, their potential as plug-and-play solutions for missing\nmodality prediction remains underexplored. To investigate this, we categorize\nexisting approaches into three representative paradigms, encompassing a total\nof 42 model variants, and conduct a comprehensive evaluation in terms of\nprediction accuracy and adaptability to downstream tasks. Our analysis reveals\nthat current foundation models often fall short in two critical aspects: (i)\nfine-grained semantic extraction from the available modalities, and (ii) robust\nvalidation of generated modalities. These limitations lead to suboptimal and,\nat times, misaligned predictions. To address these challenges, we propose an\nagentic framework tailored for missing modality prediction. This framework\ndynamically formulates modality-aware mining strategies based on the input\ncontext, facilitating the extraction of richer and more discriminative semantic\nfeatures. In addition, we introduce a \\textit{self-refinement mechanism}, which\niteratively verifies and enhances the quality of generated modalities through\ninternal feedback. Experimental results show that our method reduces FID for\nmissing image prediction by at least 14% and MER for missing text prediction by\nat least 10% compared to baselines.", "AI": {"tldr": "The paper explores the use of multimodal foundation models for missing modality prediction, identifies their limitations, and proposes an agentic framework with a self-refinement mechanism to improve accuracy and adaptability.", "motivation": "To address the underexplored potential of multimodal foundation models in predicting missing modalities and their shortcomings in fine-grained semantic extraction and robust validation.", "method": "Categorizes existing approaches into three paradigms, evaluates 42 model variants, and introduces an agentic framework with modality-aware mining strategies and a self-refinement mechanism.", "result": "The proposed method reduces FID for missing image prediction by 14% and MER for missing text prediction by 10% compared to baselines.", "conclusion": "The agentic framework and self-refinement mechanism effectively enhance missing modality prediction, addressing key limitations of current foundation models."}}
{"id": "2506.03378", "pdf": "https://arxiv.org/pdf/2506.03378", "abs": "https://arxiv.org/abs/2506.03378", "authors": ["Orchid Chetia Phukan", "Mohd Mujtaba Akhtar", "Girish", "Swarup Ranjan Behera", "Abu Osama Siddiqui", "Sarthak Jain", "Priyabrata Mallick", "Jaya Sai Kiran Patibandla", "Pailla Balakrishna Reddy", "Arun Balaji Buduru", "Rajesh Sharma"], "title": "SNIFR : Boosting Fine-Grained Child Harmful Content Detection Through Audio-Visual Alignment with Cascaded Cross-Transformer", "categories": ["eess.AS", "cs.CV", "cs.MM"], "comment": "Accepted to INTERSPEECH 2025", "summary": "As video-sharing platforms have grown over the past decade, child viewership\nhas surged, increasing the need for precise detection of harmful content like\nviolence or explicit scenes. Malicious users exploit moderation systems by\nembedding unsafe content in minimal frames to evade detection. While prior\nresearch has focused on visual cues and advanced such fine-grained detection,\naudio features remain underexplored. In this study, we embed audio cues with\nvisual for fine-grained child harmful content detection and introduce SNIFR, a\nnovel framework for effective alignment. SNIFR employs a transformer encoder\nfor intra-modality interaction, followed by a cascaded cross-transformer for\ninter-modality alignment. Our approach achieves superior performance over\nunimodal and baseline fusion methods, setting a new state-of-the-art.", "AI": {"tldr": "SNIFR combines audio and visual cues for fine-grained harmful content detection in videos, outperforming unimodal and baseline methods.", "motivation": "The rise in child viewership on video platforms necessitates better detection of harmful content, which is often hidden in minimal frames. Audio features are underexplored in prior work.", "method": "SNIFR uses a transformer encoder for intra-modality interaction and a cascaded cross-transformer for inter-modality alignment of audio and visual cues.", "result": "SNIFR achieves superior performance, setting a new state-of-the-art in harmful content detection.", "conclusion": "Integrating audio with visual cues enhances detection accuracy, making SNIFR a promising solution for child safety on video platforms."}}
{"id": "2506.03594", "pdf": "https://arxiv.org/pdf/2506.03594", "abs": "https://arxiv.org/abs/2506.03594", "authors": ["Shengjie Lin", "Jiading Fang", "Muhammad Zubair Irshad", "Vitor Campagnolo Guizilini", "Rares Andrei Ambrus", "Greg Shakhnarovich", "Matthew R. Walter"], "title": "SplArt: Articulation Estimation and Part-Level Reconstruction with 3D Gaussian Splatting", "categories": ["cs.GR", "cs.CV", "cs.LG", "cs.MM", "cs.RO"], "comment": "https://github.com/ripl/splart", "summary": "Reconstructing articulated objects prevalent in daily environments is crucial\nfor applications in augmented/virtual reality and robotics. However, existing\nmethods face scalability limitations (requiring 3D supervision or costly\nannotations), robustness issues (being susceptible to local optima), and\nrendering shortcomings (lacking speed or photorealism). We introduce SplArt, a\nself-supervised, category-agnostic framework that leverages 3D Gaussian\nSplatting (3DGS) to reconstruct articulated objects and infer kinematics from\ntwo sets of posed RGB images captured at different articulation states,\nenabling real-time photorealistic rendering for novel viewpoints and\narticulations. SplArt augments 3DGS with a differentiable mobility parameter\nper Gaussian, achieving refined part segmentation. A multi-stage optimization\nstrategy is employed to progressively handle reconstruction, part segmentation,\nand articulation estimation, significantly enhancing robustness and accuracy.\nSplArt exploits geometric self-supervision, effectively addressing challenging\nscenarios without requiring 3D annotations or category-specific priors.\nEvaluations on established and newly proposed benchmarks, along with\napplications to real-world scenarios using a handheld RGB camera, demonstrate\nSplArt's state-of-the-art performance and real-world practicality. Code is\npublicly available at https://github.com/ripl/splart.", "AI": {"tldr": "SplArt is a self-supervised framework using 3D Gaussian Splatting to reconstruct articulated objects and infer kinematics from RGB images, enabling real-time photorealistic rendering without 3D supervision.", "motivation": "Existing methods for reconstructing articulated objects face scalability, robustness, and rendering issues, limiting practical applications.", "method": "SplArt augments 3DGS with mobility parameters and employs a multi-stage optimization strategy for reconstruction, segmentation, and articulation estimation.", "result": "SplArt achieves state-of-the-art performance on benchmarks and real-world scenarios, offering robustness and accuracy without 3D annotations.", "conclusion": "SplArt provides a scalable, category-agnostic solution for articulated object reconstruction, with real-time rendering capabilities and practical applicability."}}
{"id": "2506.03831", "pdf": "https://arxiv.org/pdf/2506.03831", "abs": "https://arxiv.org/abs/2506.03831", "authors": ["Ibrahim Ibrahimov", "Zaink\u00f3 Csaba", "G\u00e1bor Gosztolya"], "title": "Conformer-based Ultrasound-to-Speech Conversion", "categories": ["cs.SD", "cs.MM", "eess.AS"], "comment": "accepted to Interspeech 2025", "summary": "Deep neural networks have shown promising potential for ultrasound-to-speech\nconversion task towards Silent Speech Interfaces. In this work, we applied two\nConformer-based DNN architectures (Base and one with bi-LSTM) for this task.\nSpeaker-specific models were trained on the data of four speakers from the\nUltrasuite-Tal80 dataset, while the generated mel spectrograms were synthesized\nto audio waveform using a HiFi-GAN vocoder. Compared to a standard 2D-CNN\nbaseline, objective measurements (MSE and mel cepstral distortion) showed no\nstatistically significant improvement for either model. However, a MUSHRA\nlistening test revealed that Conformer with bi-LSTM provided better perceptual\nquality, while Conformer Base matched the performance of the baseline along\nwith a 3x faster training time due to its simpler architecture. These findings\nsuggest that Conformer-based models, especially the Conformer with bi-LSTM,\noffer a promising alternative to CNNs for ultrasound-to-speech conversion.", "AI": {"tldr": "Conformer-based DNNs (Base and bi-LSTM) were tested for ultrasound-to-speech conversion. While objective metrics showed no improvement over a 2D-CNN baseline, perceptual quality was better with bi-LSTM, and Base matched baseline performance with faster training.", "motivation": "To explore Conformer-based DNNs as alternatives to CNNs for ultrasound-to-speech conversion in Silent Speech Interfaces.", "method": "Used Conformer architectures (Base and bi-LSTM) trained on Ultrasuite-Tal80 data, with HiFi-GAN vocoder for waveform synthesis. Compared to a 2D-CNN baseline.", "result": "No significant objective improvement, but bi-LSTM had better perceptual quality, and Base matched baseline with 3x faster training.", "conclusion": "Conformer-based models, especially with bi-LSTM, are promising for ultrasound-to-speech conversion despite no objective gains."}}
{"id": "2506.03550", "pdf": "https://arxiv.org/pdf/2506.03550", "abs": "https://arxiv.org/abs/2506.03550", "authors": ["Kanami Imamura", "Tomohiko Nakamura", "Norihiro Takamune", "Kohei Yatabe", "Hiroshi Saruwatari"], "title": "Local Equivariance Error-Based Metrics for Evaluating Sampling-Frequency-Independent Property of Neural Network", "categories": ["cs.SD", "eess.AS"], "comment": "5 pages, 4 figures, accepted for European Signal Processing\n  Conference 2025 (EUSIPCO 2025)", "summary": "Audio signal processing methods based on deep neural networks (DNNs) are\ntypically trained only at a single sampling frequency (SF) and therefore\nrequire signal resampling to handle untrained SFs. However, recent studies have\nshown that signal resampling can degrade performance with untrained SFs. This\nproblem has been overlooked because most studies evaluate only the performance\nat trained SFs. In this paper, to assess the robustness of DNNs to SF changes,\nwhich we refer to as the SF-independent (SFI) property, we propose three\nmetrics to quantify the SFI property on the basis of local equivariance error\n(LEE). LEE measures the robustness of DNNs to input transformations. By using\nsignal resampling as input transformation, we extend LEE to measure the\nrobustness of audio source separation methods to signal resampling. The\nproposed metrics are constructed to quantify the SFI property in specific\nnetwork components responsible for predicting time-frequency masks. Experiments\non music source separation demonstrated a strong correlation between the\nproposed metrics and performance degradation at untrained SFs.", "AI": {"tldr": "The paper proposes metrics to measure the robustness of deep neural networks (DNNs) to sampling frequency (SF) changes in audio signal processing, addressing performance degradation at untrained SFs.", "motivation": "Most DNN-based audio signal processing methods are trained at a single SF, leading to performance issues when handling untrained SFs due to resampling. This problem is often overlooked as evaluations typically focus on trained SFs.", "method": "The authors introduce three metrics based on local equivariance error (LEE) to quantify the SF-independent (SFI) property, extending LEE to measure robustness to signal resampling in audio source separation.", "result": "Experiments on music source separation showed a strong correlation between the proposed metrics and performance degradation at untrained SFs.", "conclusion": "The proposed metrics effectively assess the SFI property, highlighting the need for robustness in DNNs to SF changes in audio processing."}}
{"id": "2506.03259", "pdf": "https://arxiv.org/pdf/2506.03259", "abs": "https://arxiv.org/abs/2506.03259", "authors": ["Michael E. Garcia-Alcoser", "Mobina GhojoghNejad", "Fakrul Islam Tushar", "David Kim", "Kyle J. Lafata", "Geoffrey D. Rubin", "Joseph Y. Lo"], "title": "Evaluating Large Language Models for Zero-Shot Disease Labeling in CT Radiology Reports Across Organ Systems", "categories": ["cs.CL", "I.2.7"], "comment": "23 pages, 10 figures, to be submitted in Radiology: Artificial\n  Intelligence", "summary": "Purpose: This study aims to evaluate the effectiveness of large language\nmodels (LLMs) in automating disease annotation of CT radiology reports. We\ncompare a rule-based algorithm (RBA), RadBERT, and three lightweight\nopen-weight LLMs for multi-disease labeling of chest, abdomen, and pelvis (CAP)\nCT reports.\n  Materials and Methods: This retrospective study analyzed 40,833 CT reports\nfrom 29,540 patients, with 1,789 CAP reports manually annotated across three\norgan systems. External validation was conducted using the CT-RATE dataset.\nThree open-weight LLMs were tested with zero-shot prompting. Performance was\nevaluated using Cohen's Kappa and micro/macro-averaged F1 scores.\n  Results: In 12,197 Duke CAP reports from 8,854 patients, Llama-3.1 8B and\nGemma-3 27B showed the highest agreement ($\\kappa$ median: 0.87). On the\nmanually annotated set, Gemma-3 27B achieved the top macro-F1 (0.82), followed\nby Llama-3.1 8B (0.79), while the RBA scored lowest (0.64). On the CT-RATE\ndataset (lungs/pleura only), Llama-3.1 8B performed best (0.91), with Gemma-3\n27B close behind (0.89). Performance differences were mainly due to differing\nlabeling practices, especially for lung atelectasis.\n  Conclusion: Lightweight LLMs outperform rule-based methods for CT report\nannotation and generalize across organ systems with zero-shot prompting.\nHowever, binary labels alone cannot capture the full nuance of report language.\nLLMs can provide a flexible, efficient solution aligned with clinical judgment\nand user needs.", "AI": {"tldr": "Lightweight LLMs outperform rule-based methods for CT report annotation, showing high agreement and generalization across organ systems with zero-shot prompting.", "motivation": "To evaluate the effectiveness of LLMs in automating disease annotation of CT radiology reports compared to rule-based methods.", "method": "Retrospective study analyzing 40,833 CT reports, testing three open-weight LLMs with zero-shot prompting, and evaluating performance using Cohen's Kappa and F1 scores.", "result": "Gemma-3 27B and Llama-3.1 8B showed the highest agreement and performance, outperforming the rule-based algorithm.", "conclusion": "LLMs offer a flexible, efficient solution for CT report annotation, though binary labels may not fully capture report nuances."}}
{"id": "2506.03162", "pdf": "https://arxiv.org/pdf/2506.03162", "abs": "https://arxiv.org/abs/2506.03162", "authors": ["Damith Chamalke Senadeera", "Xiaoyun Yang", "Dimitrios Kollias", "Gregory Slabaugh"], "title": "Dual Branch VideoMamba with Gated Class Token Fusion for Violence Detection", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": null, "summary": "The rapid proliferation of surveillance cameras has increased the demand for\nautomated violence detection. While CNNs and Transformers have shown success in\nextracting spatio-temporal features, they struggle with long-term dependencies\nand computational efficiency. We propose Dual Branch VideoMamba with Gated\nClass Token Fusion (GCTF), an efficient architecture combining a dual-branch\ndesign and a state-space model (SSM) backbone where one branch captures spatial\nfeatures, while the other focuses on temporal dynamics, with continuous fusion\nvia a gating mechanism. We also present a new benchmark by merging RWF-2000,\nRLVS, and VioPeru datasets in video violence detection, ensuring strict\nseparation between training and testing sets. Our model achieves\nstate-of-the-art performance on this benchmark offering an optimal balance\nbetween accuracy and computational efficiency, demonstrating the promise of\nSSMs for scalable, real-time surveillance violence detection.", "AI": {"tldr": "Proposes Dual Branch VideoMamba with GCTF for efficient violence detection in videos, combining spatial and temporal features via SSM backbone, achieving SOTA performance on a new benchmark.", "motivation": "Addresses the limitations of CNNs and Transformers in handling long-term dependencies and computational efficiency for automated violence detection in surveillance videos.", "method": "Introduces a dual-branch architecture with SSM backbone: one branch for spatial features, another for temporal dynamics, fused via a gating mechanism (GCTF). Merges RWF-2000, RLVS, and VioPeru datasets for benchmarking.", "result": "Achieves state-of-the-art performance on the new benchmark, balancing accuracy and computational efficiency.", "conclusion": "Demonstrates the potential of SSMs for scalable, real-time violence detection in surveillance systems."}}
{"id": "2506.03205", "pdf": "https://arxiv.org/pdf/2506.03205", "abs": "https://arxiv.org/abs/2506.03205", "authors": ["Umberto Gon\u00e7alves de Sousa"], "title": "Q-ARDNS-Multi: A Multi-Agent Quantum Reinforcement Learning Framework with Meta-Cognitive Adaptation for Complex 3D Environments", "categories": ["cs.AI"], "comment": "17 pages, 5 figures", "summary": "This paper presents Q-ARDNS-Multi, an advanced multi-agent quantum\nreinforcement learning (QRL) framework that extends the ARDNS-FN-Quantum model,\nwhere Q-ARDNS-Multi stands for \"Quantum Adaptive Reward-Driven Neural Simulator\n- Multi-Agent\". It integrates quantum circuits with RY gates, meta-cognitive\nadaptation, and multi-agent coordination mechanisms for complex 3D\nenvironments. Q-ARDNS-Multi leverages a 2-qubit quantum circuit for action\nselection, a dual-memory system inspired by human cognition, a shared memory\nmodule for agent cooperation, and adaptive exploration strategies modulated by\nreward variance and intrinsic motivation. Evaluated in a $10 \\times 10 \\times\n3$ GridWorld environment with two agents over 5000 episodes, Q-ARDNS-Multi\nachieves success rates of 99.6\\% and 99.5\\% for Agents 0 and 1, respectively,\noutperforming Multi-Agent Deep Deterministic Policy Gradient (MADDPG) and Soft\nActor-Critic (SAC) in terms of success rate, stability, navigation efficiency,\nand collision avoidance. The framework records mean rewards of $-304.2891 \\pm\n756.4636$ and $-295.7622 \\pm 752.7103$, averaging 210 steps to goal,\ndemonstrating its robustness in dynamic settings. Comprehensive analyses,\nincluding learning curves, reward distributions, statistical tests, and\ncomputational efficiency evaluations, highlight the contributions of quantum\ncircuits and meta-cognitive adaptation. By bridging quantum computing,\ncognitive science, and multi-agent RL, Q-ARDNS-Multi offers a scalable,\nhuman-like approach for applications in robotics, autonomous navigation, and\ndecision-making under uncertainty.", "AI": {"tldr": "Q-ARDNS-Multi is a multi-agent quantum reinforcement learning framework integrating quantum circuits, meta-cognition, and coordination, outperforming MADDPG and SAC in complex 3D environments.", "motivation": "To bridge quantum computing, cognitive science, and multi-agent RL for scalable, human-like decision-making in dynamic settings like robotics and navigation.", "method": "Uses 2-qubit quantum circuits, dual-memory systems, shared memory for cooperation, and adaptive exploration strategies. Evaluated in a 3D GridWorld with two agents.", "result": "Achieves 99.6% and 99.5% success rates for agents, outperforming MADDPG and SAC in success rate, stability, and efficiency.", "conclusion": "Q-ARDNS-Multi provides a robust, scalable solution for complex multi-agent tasks, leveraging quantum and cognitive principles."}}
{"id": "2506.03154", "pdf": "https://arxiv.org/pdf/2506.03154", "abs": "https://arxiv.org/abs/2506.03154", "authors": ["Zhaoyang Chen", "Cody Fleming"], "title": "Modular Diffusion Policy Training: Decoupling and Recombining Guidance and Diffusion for Offline RL", "categories": ["cs.LG"], "comment": null, "summary": "Classifier free guidance has shown strong potential in diffusion-based\nreinforcement learning. However, existing methods rely on joint training of the\nguidance module and the diffusion model, which can be suboptimal during the\nearly stages when the guidance is inaccurate and provides noisy learning\nsignals. In offline RL, guidance depends solely on offline data: observations,\nactions, and rewards, and is independent of the policy module's behavior,\nsuggesting that joint training is not required. This paper proposes modular\ntraining methods that decouple the guidance module from the diffusion model,\nbased on three key findings:\n  Guidance Necessity: We explore how the effectiveness of guidance varies with\nthe training stage and algorithm choice, uncovering the roles of guidance and\ndiffusion. A lack of good guidance in the early stage presents an opportunity\nfor optimization.\n  Guidance-First Diffusion Training: We introduce a method where the guidance\nmodule is first trained independently as a value estimator, then frozen to\nguide the diffusion model using classifier-free reward guidance. This\nmodularization reduces memory usage, improves computational efficiency, and\nenhances both sample efficiency and final performance.\n  Cross-Module Transferability: Applying two independently trained guidance\nmodels, one during training and the other during inference, can significantly\nreduce normalized score variance (e.g., reducing IQR by 86%). We show that\nguidance modules trained with one algorithm (e.g., IDQL) can be directly reused\nwith another (e.g., DQL), with no additional training required, demonstrating\nbaseline-level performance as well as strong modularity and transferability.\n  We provide theoretical justification and empirical validation on bullet D4RL\nbenchmarks. Our findings suggest a new paradigm for offline RL: modular,\nreusable, and composable training pipelines.", "AI": {"tldr": "The paper proposes modular training methods for diffusion-based reinforcement learning, decoupling the guidance module from the diffusion model to improve efficiency and performance.", "motivation": "Existing methods rely on joint training of the guidance module and diffusion model, which can be suboptimal due to noisy early-stage guidance. The paper aims to optimize this by modularizing the training process.", "method": "The method involves training the guidance module independently first as a value estimator, then freezing it to guide the diffusion model. It also explores cross-module transferability by reusing guidance models across different algorithms.", "result": "The modular approach reduces memory usage, improves computational efficiency, and enhances sample efficiency and final performance. Cross-module transferability reduces score variance (e.g., IQR by 86%) and demonstrates strong modularity.", "conclusion": "The findings suggest a new paradigm for offline RL with modular, reusable, and composable training pipelines, validated theoretically and empirically on D4RL benchmarks."}}
{"id": "2506.04215", "pdf": "https://arxiv.org/pdf/2506.04215", "abs": "https://arxiv.org/abs/2506.04215", "authors": ["Alex DeWeese", "Guannan Qu"], "title": "Thinking Beyond Visibility: A Near-Optimal Policy Framework for Locally Interdependent Multi-Agent MDPs", "categories": ["cs.MA", "cs.AI", "cs.LG", "math.OC"], "comment": null, "summary": "Decentralized Partially Observable Markov Decision Processes (Dec-POMDPs) are\nknown to be NEXP-Complete and intractable to solve. However, for problems such\nas cooperative navigation, obstacle avoidance, and formation control, basic\nassumptions can be made about local visibility and local dependencies. The work\nDeWeese and Qu 2024 formalized these assumptions in the construction of the\nLocally Interdependent Multi-Agent MDP. In this setting, it establishes three\nclosed-form policies that are tractable to compute in various situations and\nare exponentially close to optimal with respect to visibility. However, it is\nalso shown that these solutions can have poor performance when the visibility\nis small and fixed, often getting stuck during simulations due to the so called\n\"Penalty Jittering\" phenomenon. In this work, we establish the Extended Cutoff\nPolicy Class which is, to the best of our knowledge, the first non-trivial\nclass of near optimal closed-form partially observable policies that are\nexponentially close to optimal with respect to the visibility for any Locally\nInterdependent Multi-Agent MDP. These policies are able to remember agents\nbeyond their visibilities which allows them to perform significantly better in\nmany small and fixed visibility settings, resolve Penalty Jittering\noccurrences, and under certain circumstances guarantee fully observable joint\noptimal behavior despite the partial observability. We also propose a\ngeneralized form of the Locally Interdependent Multi-Agent MDP that allows for\ntransition dependence and extended reward dependence, then replicate our\ntheoretical results in this setting.", "AI": {"tldr": "The paper introduces the Extended Cutoff Policy Class for Locally Interdependent Multi-Agent MDPs, improving performance in small visibility settings and resolving Penalty Jittering.", "motivation": "Dec-POMDPs are intractable, but local assumptions enable tractable solutions. Existing policies perform poorly in small visibility settings due to Penalty Jittering.", "method": "Proposes the Extended Cutoff Policy Class, which remembers agents beyond visibility, and generalizes the Locally Interdependent Multi-Agent MDP framework.", "result": "Policies are exponentially close to optimal, resolve Penalty Jittering, and can guarantee joint optimal behavior under partial observability.", "conclusion": "The Extended Cutoff Policy Class offers a practical, near-optimal solution for Locally Interdependent Multi-Agent MDPs, even in challenging visibility conditions."}}
{"id": "2506.03364", "pdf": "https://arxiv.org/pdf/2506.03364", "abs": "https://arxiv.org/abs/2506.03364", "authors": ["Orchid Chetia Phukan", "Girish", "Mohd Mujtaba Akhtar", "Swarup Ranjan Behera", "Priyabrata Mallick", "Pailla Balakrishna Reddy", "Arun Balaji Buduru", "Rajesh Sharma"], "title": "Towards Source Attribution of Singing Voice Deepfake with Multimodal Foundation Models", "categories": ["eess.AS", "cs.MM", "cs.SD"], "comment": "Accepted to INTERSPEECH 2025", "summary": "In this work, we introduce the task of singing voice deepfake source\nattribution (SVDSA). We hypothesize that multimodal foundation models (MMFMs)\nsuch as ImageBind, LanguageBind will be most effective for SVDSA as they are\nbetter equipped for capturing subtle source-specific characteristics-such as\nunique timbre, pitch manipulation, or synthesis artifacts of each singing voice\ndeepfake source due to their cross-modality pre-training. Our experiments with\nMMFMs, speech foundation models and music foundation models verify the\nhypothesis that MMFMs are the most effective for SVDSA. Furthermore, inspired\nfrom related research, we also explore fusion of foundation models (FMs) for\nimproved SVDSA. To this end, we propose a novel framework, COFFE which employs\nChernoff Distance as novel loss function for effective fusion of FMs. Through\nCOFFE with the symphony of MMFMs, we attain the topmost performance in\ncomparison to all the individual FMs and baseline fusion methods.", "AI": {"tldr": "The paper introduces singing voice deepfake source attribution (SVDSA) and proposes using multimodal foundation models (MMFMs) for superior performance. A novel framework, COFFE, with Chernoff Distance loss, outperforms individual models and baselines.", "motivation": "To address the challenge of attributing deepfake singing voices to their sources by leveraging multimodal foundation models for capturing unique characteristics like timbre and synthesis artifacts.", "method": "Utilizes MMFMs (e.g., ImageBind, LanguageBind) and proposes COFFE, a framework with Chernoff Distance loss for effective fusion of foundation models.", "result": "MMFMs are most effective for SVDSA, and COFFE achieves top performance compared to individual models and baseline fusion methods.", "conclusion": "Multimodal foundation models and the COFFE framework significantly improve singing voice deepfake source attribution, setting a new benchmark for the task."}}
{"id": "2506.04070", "pdf": "https://arxiv.org/pdf/2506.04070", "abs": "https://arxiv.org/abs/2506.04070", "authors": ["Yi Zhao", "Siqi Wang", "Jing Li"], "title": "LaF-GRPO: In-Situ Navigation Instruction Generation for the Visually Impaired via GRPO with LLM-as-Follower Reward", "categories": ["cs.CL", "cs.MM"], "comment": null, "summary": "Navigation instruction generation for visually impaired (VI) individuals\n(NIG-VI) is critical yet relatively underexplored. This study, hence, focuses\non producing precise, in-situ, step-by-step navigation instructions that are\npractically usable by VI users. Concretely, we propose LaF-GRPO\n(LLM-as-Follower GRPO), where an LLM simulates VI user responses to generate\nrewards guiding the Vision-Language Model (VLM) post-training. This enhances\ninstruction usability while reducing costly real-world data needs. To\nfacilitate training and testing, we introduce NIG4VI, a 27k-sample open-sourced\nbenchmark. It provides diverse navigation scenarios with accurate spatial\ncoordinates, supporting detailed, open-ended in-situ instruction generation.\nExperiments on NIG4VI show the effectiveness of LaF-GRPO by quantitative\nmetrics (e.g., Zero-(LaF-GRPO) boosts BLEU +14\\%; SFT+(LaF-GRPO) METEOR 0.542\nvs. GPT-4o's 0.323) and yields more intuitive, safer instructions. Code and\nbenchmark are available at\n\\href{https://github.com/YiyiyiZhao/NIG4VI}{https://github.com/YiyiyiZhao/NIG4VI}.", "AI": {"tldr": "The paper introduces LaF-GRPO, a method using LLMs to simulate VI user responses for generating better navigation instructions, and presents NIG4VI, a 27k-sample benchmark. Results show improved instruction quality and usability.", "motivation": "Navigation instruction generation for visually impaired individuals is underexplored but critical. The study aims to produce precise, usable instructions.", "method": "Proposes LaF-GRPO, where an LLM simulates VI user responses to guide a Vision-Language Model post-training, reducing real-world data needs. Introduces NIG4VI benchmark for training and testing.", "result": "LaF-GRPO improves instruction quality (e.g., BLEU +14%, METEOR 0.542 vs. GPT-4o's 0.323) and yields safer, more intuitive instructions.", "conclusion": "LaF-GRPO effectively enhances navigation instruction generation for VI users, supported by the NIG4VI benchmark."}}
{"id": "2506.03554", "pdf": "https://arxiv.org/pdf/2506.03554", "abs": "https://arxiv.org/abs/2506.03554", "authors": ["Reo Yoneyama", "Masaya Kawamura", "Ryo Terashima", "Ryuichi Yamamoto", "Tomoki Toda"], "title": "Comparative Analysis of Fast and High-Fidelity Neural Vocoders for Low-Latency Streaming Synthesis in Resource-Constrained Environments", "categories": ["cs.SD", "eess.AS"], "comment": "Accepted to Interspeech 2025", "summary": "In real-time speech synthesis, neural vocoders often require low-latency\nsynthesis through causal processing and streaming. However, streaming\nintroduces inefficiencies absent in batch synthesis, such as limited\nparallelism, inter-frame dependency management, and parameter loading overhead.\nThis paper proposes multi-stream Wavehax (MS-Wavehax), an efficient neural\nvocoder for low-latency streaming, by extending the aliasing-free neural\nvocoder Wavehax with multi-stream decomposition. We analyze the\nlatency-throughput trade-off in a CPU-only environment and identify key\nbottlenecks in streaming neural vocoders. Our findings provide practical\ninsights for optimizing chunk sizes and designing vocoders tailored to specific\napplication demands and hardware constraints. Furthermore, our subjective\nevaluations show that MS-Wavehax delivers high speech quality under causal and\nnon-causal conditions while being remarkably compact and easily deployable in\nresource-constrained environments.", "AI": {"tldr": "MS-Wavehax is an efficient neural vocoder for low-latency streaming, addressing inefficiencies like limited parallelism and parameter loading overhead. It extends Wavehax with multi-stream decomposition, optimizing latency-throughput trade-offs and delivering high speech quality.", "motivation": "To overcome inefficiencies in streaming neural vocoders, such as limited parallelism and parameter loading overhead, while maintaining low-latency synthesis.", "method": "Extends Wavehax with multi-stream decomposition, analyzes latency-throughput trade-offs, and optimizes chunk sizes for streaming.", "result": "MS-Wavehax achieves high speech quality under causal and non-causal conditions, is compact, and deployable in resource-constrained environments.", "conclusion": "The paper provides practical insights for optimizing streaming neural vocoders, demonstrating MS-Wavehax's effectiveness in balancing latency, throughput, and quality."}}
{"id": "2506.03268", "pdf": "https://arxiv.org/pdf/2506.03268", "abs": "https://arxiv.org/abs/2506.03268", "authors": ["Cristiano Chesi"], "title": "A conclusive remark on linguistic theorizing and language modeling", "categories": ["cs.CL"], "comment": null, "summary": "This is the final remark on the replies received to my target paper in the\nItalian Journal of Linguistics", "AI": {"tldr": "A summary of responses to a target paper in the Italian Journal of Linguistics.", "motivation": "To address and reflect on the feedback and discussions generated by the target paper.", "method": "Review and analysis of the replies received.", "result": "Insights and perspectives from the responses are highlighted.", "conclusion": "The paper concludes with reflections on the discourse and contributions to the field."}}
{"id": "2506.03168", "pdf": "https://arxiv.org/pdf/2506.03168", "abs": "https://arxiv.org/abs/2506.03168", "authors": ["Dawen Jiang", "Zhishu Shen", "Qiushi Zheng", "Tiehua Zhang", "Wei Xiang", "Jiong Jin"], "title": "Farm-LightSeek: An Edge-centric Multimodal Agricultural IoT Data Analytics Framework with Lightweight LLMs", "categories": ["cs.CV", "cs.LG"], "comment": "Accepted by IEEE Internet of Things Magazine", "summary": "Amid the challenges posed by global population growth and climate change,\ntraditional agricultural Internet of Things (IoT) systems is currently\nundergoing a significant digital transformation to facilitate efficient big\ndata processing. While smart agriculture utilizes artificial intelligence (AI)\ntechnologies to enable precise control, it still encounters significant\nchallenges, including excessive reliance on agricultural expert knowledge,\ndifficulties in fusing multimodal data, poor adaptability to dynamic\nenvironments, and bottlenecks in real-time decision-making at the edge. Large\nlanguage models (LLMs), with their exceptional capabilities in knowledge\nacquisition and semantic understanding, provide a promising solution to address\nthese challenges. To this end, we propose Farm-LightSeek, an edge-centric\nmultimodal agricultural IoT data analytics framework that integrates LLMs with\nedge computing. This framework collects real-time farmland multi-source data\n(images, weather, geographic information) via sensors, performs cross-modal\nreasoning and disease detection at edge nodes, conducts low-latency management\ndecisions, and enables cloud collaboration for model updates. The main\ninnovations of Farm-LightSeek include: (1) an agricultural\n\"perception-decision-action\" closed-loop architecture; (2) cross-modal adaptive\nmonitoring; and (3)a lightweight LLM deployment strategy balancing performance\nand efficiency. Experiments conducted on two real-world datasets demonstrate\nthat Farm-LightSeek consistently achieves reliable performance in\nmission-critical tasks, even under the limitations of edge computing resources.\nThis work advances intelligent real-time agricultural solutions and highlights\nthe potential for deeper integration of agricultural IoT with LLMs.", "AI": {"tldr": "Farm-LightSeek integrates LLMs with edge computing for smart agriculture, addressing challenges like expert reliance and real-time decision-making. It features a closed-loop architecture, cross-modal monitoring, and lightweight LLM deployment, proving effective in real-world tests.", "motivation": "Global population growth and climate change demand efficient agricultural IoT systems. Current AI-based smart agriculture faces issues like expert reliance, multimodal data fusion, and real-time edge decision-making.", "method": "Farm-LightSeek uses edge computing and LLMs to collect real-time farmland data (images, weather, etc.), performs cross-modal reasoning and disease detection at edge nodes, and enables low-latency decisions with cloud collaboration.", "result": "Experiments on real-world datasets show Farm-LightSeek achieves reliable performance in critical tasks despite edge resource limitations.", "conclusion": "Farm-LightSeek advances real-time agricultural solutions and demonstrates the potential of deeper LLM-IoT integration in agriculture."}}
{"id": "2506.03233", "pdf": "https://arxiv.org/pdf/2506.03233", "abs": "https://arxiv.org/abs/2506.03233", "authors": ["Andrea Ferrario"], "title": "A Trustworthiness-based Metaphysics of Artificial Intelligence Systems", "categories": ["cs.AI", "cs.CY", "cs.LG"], "comment": "To appear in the proceedings of 2025 ACM Conference on Fairness,\n  Accountability, and Transparency (FAccT '25)", "summary": "Modern AI systems are man-made objects that leverage machine learning to\nsupport our lives across a myriad of contexts and applications. Despite\nextensive epistemological and ethical debates, their metaphysical foundations\nremain relatively under explored. The orthodox view simply suggests that AI\nsystems, as artifacts, lack well-posed identity and persistence conditions --\ntheir metaphysical kinds are no real kinds. In this work, we challenge this\nperspective by introducing a theory of metaphysical identity of AI systems. We\ndo so by characterizing their kinds and introducing identity criteria -- formal\nrules that answer the questions \"When are two AI systems the same?\" and \"When\ndoes an AI system persist, despite change?\" Building on Carrara and Vermaas'\naccount of fine-grained artifact kinds, we argue that AI trustworthiness\nprovides a lens to understand AI system kinds and formalize the identity of\nthese artifacts by relating their functional requirements to their physical\nmake-ups. The identity criteria of AI systems are determined by their\ntrustworthiness profiles -- the collection of capabilities that the systems\nmust uphold over time throughout their artifact histories, and their\neffectiveness in maintaining these capabilities. Our approach suggests that the\nidentity and persistence of AI systems is sensitive to the socio-technical\ncontext of their design and utilization via their trustworthiness, providing a\nsolid metaphysical foundation to the epistemological, ethical, and legal\ndiscussions about these artifacts.", "AI": {"tldr": "The paper challenges the orthodox view that AI systems lack metaphysical identity by proposing a theory based on trustworthiness profiles to define their kinds and persistence.", "motivation": "To address the under-explored metaphysical foundations of AI systems, countering the claim that they lack identity and persistence conditions.", "method": "Introduces identity criteria for AI systems by linking their functional requirements to physical make-ups, using trustworthiness profiles as a lens.", "result": "AI systems' identity and persistence are determined by their trustworthiness profiles, which reflect their capabilities and effectiveness over time.", "conclusion": "The theory provides a metaphysical foundation for AI systems, linking their identity to socio-technical contexts and supporting broader epistemological, ethical, and legal discussions."}}
{"id": "2506.03155", "pdf": "https://arxiv.org/pdf/2506.03155", "abs": "https://arxiv.org/abs/2506.03155", "authors": ["Yu Zheng"], "title": "Fusing Cross-Domain Knowledge from Multimodal Data to Solve Problems in the Physical World", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "The proliferation of artificial intelligence has enabled a diversity of\napplications that bridge the gap between digital and physical worlds. As\nphysical environments are too complex to model through a single information\nacquisition approach, it is crucial to fuse multimodal data generated by\ndifferent sources, such as sensors, devices, systems, and people, to solve a\nproblem in the real world. Unfortunately, it is neither applicable nor\nsustainable to deploy new resources to collect original data from scratch for\nevery problem. Thus, when data is inadequate in the domain of problem, it is\nvital to fuse knowledge from multimodal data that is already available in other\ndomains. We call this cross-domain knowledge fusion. Existing research focus on\nfusing multimodal data in a single domain, supposing the knowledge from\ndifferent datasets is intrinsically aligned; however, this assumption may not\nhold in the scenarios of cross-domain knowledge fusion. In this paper, we\nformally define the cross-domain multimodal data fusion problem, discussing its\nunique challenges, differences and advantages beyond data fusion in a single\ndomain. We propose a four-layer framework, consisting of Domains, Links, Models\nand Data layers, answering three key questions: \"what to fuse\", \"why can be\nfused\", and \"how to fuse\". The Domains Layer selects relevant data from\ndifferent domains for a given problem. The Links Layer reveals the philosophy\nof knowledge alignment beyond specific model structures. The Models Layer\nprovides two knowledge fusion paradigms based on the fundamental mechanisms for\nprocessing data. The Data Layer turns data of different structures,\nresolutions, scales and distributions into a consistent representation that can\nbe fed into an AI model. With this framework, we can design end-to-end\nsolutions that fuse cross-domain multimodal data effectively for solving\nreal-world problems.", "AI": {"tldr": "The paper introduces a framework for cross-domain multimodal data fusion to address real-world problems when data is inadequate in the target domain.", "motivation": "The complexity of physical environments necessitates multimodal data fusion, but existing methods assume alignment within a single domain, which fails in cross-domain scenarios.", "method": "A four-layer framework (Domains, Links, Models, Data) is proposed to address 'what to fuse', 'why can be fused', and 'how to fuse'.", "result": "The framework enables effective end-to-end solutions for cross-domain multimodal data fusion.", "conclusion": "The proposed framework overcomes challenges of cross-domain fusion, offering a structured approach for real-world problem-solving."}}
{"id": "2506.03543", "pdf": "https://arxiv.org/pdf/2506.03543", "abs": "https://arxiv.org/abs/2506.03543", "authors": ["Wanghao Ye", "Sihan Chen", "Yiting Wang", "Shwai He", "Bowei Tian", "Guoheng Sun", "Ziyi Wang", "Ziyao Wang", "Yexiao He", "Zheyu Shen", "Meng Liu", "Yuning Zhang", "Meng Feng", "Yang Wang", "Siyuan Peng", "Yilong Dai", "Zhenle Duan", "Hanzhang Qin", "Ang Li"], "title": "CogniPair: From LLM Chatbots to Conscious AI Agents -- GNWT-Based Multi-Agent Digital Twins for Social Pairing -- Dating & Hiring Applications", "categories": ["cs.AI", "cs.CY", "cs.MA"], "comment": null, "summary": "Current large language model (LLM) agents lack authentic human psychological\nprocesses necessary for genuine digital twins and social AI applications. To\naddress this limitation, we present a computational implementation of Global\nWorkspace Theory (GNWT) that integrates human cognitive architecture principles\ninto LLM agents, creating specialized sub-agents for emotion, memory, social\nnorms, planning, and goal-tracking coordinated through a global workspace\nmechanism. However, authentic digital twins require accurate personality\ninitialization. We therefore develop a novel adventure-based personality test\nthat evaluates true personality through behavioral choices within interactive\nscenarios, bypassing self-presentation bias found in traditional assessments.\nBuilding on these innovations, our CogniPair platform enables digital twins to\nengage in realistic simulated dating interactions and job interviews before\nreal encounters, providing bidirectional cultural fit assessment for both\nromantic compatibility and workplace matching. Validation using 551 GNWT-Agents\nand Columbia University Speed Dating dataset demonstrates 72% correlation with\nhuman attraction patterns, 77.8% match prediction accuracy, and 74% agreement\nin human validation studies. This work advances psychological authenticity in\nLLM agents and establishes a foundation for intelligent dating platforms and HR\ntechnology solutions.", "AI": {"tldr": "The paper introduces a computational implementation of Global Workspace Theory (GNWT) to enhance LLM agents with human-like psychological processes, including a novel personality test and the CogniPair platform for realistic social interactions.", "motivation": "Current LLM agents lack authentic human psychological processes, limiting their use in digital twins and social AI applications.", "method": "The study integrates GNWT into LLM agents, creating specialized sub-agents and an adventure-based personality test for accurate initialization. The CogniPair platform simulates dating and job interviews.", "result": "Validation shows 72% correlation with human attraction patterns, 77.8% match prediction accuracy, and 74% agreement in human studies.", "conclusion": "The work advances psychological authenticity in LLM agents, supporting applications in dating platforms and HR technology."}}
{"id": "2506.03403", "pdf": "https://arxiv.org/pdf/2506.03403", "abs": "https://arxiv.org/abs/2506.03403", "authors": ["Orchid Chetia Phukan", "Girish", "Mohd Mujtaba Akhtar", "Swarup Ranjan Behera", "Pailla Balakrishna Reddy", "Arun Balaji Buduru", "Rajesh Sharma"], "title": "HYFuse: Aligning Heterogeneous Speech Pre-Trained Representations in Hyperbolic Space for Speech Emotion Recognition", "categories": ["eess.AS"], "comment": "Accepted to INTERSPEECH 2025", "summary": "Compression-based representations (CBRs) from neural audio codecs such as\nEnCodec capture intricate acoustic features like pitch and timbre, while\nrepresentation-learning-based representations (RLRs) from pre-trained models\ntrained for speech representation learning such as WavLM encode high-level\nsemantic and prosodic information. Previous research on Speech Emotion\nRecognition (SER) has explored both, however, fusion of CBRs and RLRs haven't\nbeen explored yet. In this study, we solve this gap and investigate the fusion\nof RLRs and CBRs and hypothesize they will be more effective by providing\ncomplementary information. To this end, we propose, HYFuse, a novel framework\nthat fuses the representations by transforming them to hyperbolic space. With\nHYFuse, through fusion of x-vector (RLR) and Soundstream (CBR), we achieve the\ntop performance in comparison to individual representations as well as the\nhomogeneous fusion of RLRs and CBRs and report SOTA.", "AI": {"tldr": "HYFuse, a novel framework, fuses compression-based (CBR) and representation-learning-based (RLR) audio representations in hyperbolic space, achieving state-of-the-art performance in Speech Emotion Recognition (SER).", "motivation": "Previous SER research explored CBRs and RLRs separately, but their fusion was unexplored. The study hypothesizes that combining them provides complementary information for better performance.", "method": "Proposes HYFuse, a framework that transforms and fuses CBRs (Soundstream) and RLRs (x-vector) in hyperbolic space.", "result": "HYFuse outperforms individual representations and homogeneous fusion methods, achieving state-of-the-art results.", "conclusion": "Fusing CBRs and RLRs in hyperbolic space enhances SER performance, demonstrating the effectiveness of complementary information fusion."}}
{"id": "2506.04214", "pdf": "https://arxiv.org/pdf/2506.04214", "abs": "https://arxiv.org/abs/2506.04214", "authors": ["Tingle Li", "Baihe Huang", "Xiaobin Zhuang", "Dongya Jia", "Jiawei Chen", "Yuping Wang", "Zhuo Chen", "Gopala Anumanchipalli", "Yuxuan Wang"], "title": "Sounding that Object: Interactive Object-Aware Image to Audio Generation", "categories": ["cs.CV", "cs.LG", "cs.MM", "cs.SD", "eess.AS"], "comment": "ICML 2025", "summary": "Generating accurate sounds for complex audio-visual scenes is challenging,\nespecially in the presence of multiple objects and sound sources. In this\npaper, we propose an {\\em interactive object-aware audio generation} model that\ngrounds sound generation in user-selected visual objects within images. Our\nmethod integrates object-centric learning into a conditional latent diffusion\nmodel, which learns to associate image regions with their corresponding sounds\nthrough multi-modal attention. At test time, our model employs image\nsegmentation to allow users to interactively generate sounds at the {\\em\nobject} level. We theoretically validate that our attention mechanism\nfunctionally approximates test-time segmentation masks, ensuring the generated\naudio aligns with selected objects. Quantitative and qualitative evaluations\nshow that our model outperforms baselines, achieving better alignment between\nobjects and their associated sounds. Project page:\nhttps://tinglok.netlify.app/files/avobject/", "AI": {"tldr": "Proposes an interactive object-aware audio generation model using a conditional latent diffusion framework, validated by multi-modal attention and image segmentation.", "motivation": "Addressing the challenge of generating accurate sounds for complex audio-visual scenes with multiple objects and sound sources.", "method": "Integrates object-centric learning into a conditional latent diffusion model, using multi-modal attention to associate image regions with sounds. Employs image segmentation for interactive sound generation at the object level.", "result": "Outperforms baselines in aligning objects with their sounds, validated quantitatively and qualitatively.", "conclusion": "The model effectively grounds sound generation in user-selected visual objects, ensuring accurate audio alignment."}}
{"id": "2506.03959", "pdf": "https://arxiv.org/pdf/2506.03959", "abs": "https://arxiv.org/abs/2506.03959", "authors": ["Jacob de Nobel", "Jeroen J. Briaire", "Thomas H. W. Baeck", "Anna V. Kononova", "Johan H. M. Frijns"], "title": "From Spikes to Speech: NeuroVoc -- A Biologically Plausible Vocoder Framework for Auditory Perception and Cochlear Implant Simulation", "categories": ["cs.SD", "eess.AS", "q-bio.NC"], "comment": "43 Pages, 11 Figures, 2 Tables", "summary": "We present NeuroVoc, a flexible model-agnostic vocoder framework that\nreconstructs acoustic waveforms from simulated neural activity patterns using\nan inverse Fourier transform. The system applies straightforward signal\nprocessing to neurogram representations, time-frequency binned outputs from\nauditory nerve fiber models. Crucially, the model architecture is modular,\nallowing for easy substitution or modification of the underlying auditory\nmodels. This flexibility eliminates the need for\nspeech-coding-strategy-specific vocoder implementations when simulating\nauditory perception in cochlear implant (CI) users. It also allows direct\ncomparisons between normal hearing (NH) and electrical hearing (EH) models, as\ndemonstrated in this study. The vocoder preserves distinctive features of each\nmodel; for example, the NH model retains harmonic structure more faithfully\nthan the EH model. We evaluated perceptual intelligibility in noise using an\nonline Digits-in-Noise (DIN) test, where participants completed three test\nconditions: one with standard speech, and two with vocoded speech using the NH\nand EH models. Both the standard DIN test and the EH-vocoded groups were\nstatistically equivalent to clinically reported data for NH and CI listeners.\nOn average, the NH and EH vocoded groups increased SRT compared to the standard\ntest by 2.4 dB and 7.1 dB, respectively. These findings show that, although\nsome degradation occurs, the vocoder can reconstruct intelligible speech under\nboth hearing models and accurately reflects the reduced speech-in-noise\nperformance experienced by CI users.", "AI": {"tldr": "NeuroVoc is a flexible vocoder framework for reconstructing speech from neural activity, enabling comparisons between normal and electrical hearing models while preserving model-specific features.", "motivation": "To simplify auditory perception simulations for cochlear implant users by eliminating the need for speech-coding-strategy-specific vocoders and enabling direct comparisons between normal and electrical hearing models.", "method": "Uses an inverse Fourier transform on neurogram representations from auditory nerve fiber models, with a modular architecture for easy model substitution.", "result": "The vocoder preserved model-specific features (e.g., harmonic structure) and demonstrated perceptual intelligibility in noise tests, with results aligning with clinical data for normal and cochlear implant listeners.", "conclusion": "NeuroVoc effectively reconstructs intelligible speech and accurately reflects the speech-in-noise performance differences between normal and electrical hearing."}}
{"id": "2506.03278", "pdf": "https://arxiv.org/pdf/2506.03278", "abs": "https://arxiv.org/abs/2506.03278", "authors": ["Christodoulos Constantinides", "Dhaval Patel", "Shuxin Lin", "Claudio Guerrero", "Sunil Dagajirao Patil", "Jayant Kalagnanam"], "title": "FailureSensorIQ: A Multi-Choice QA Dataset for Understanding Sensor Relationships and Failure Modes", "categories": ["cs.CL"], "comment": null, "summary": "We introduce FailureSensorIQ, a novel Multi-Choice Question-Answering (MCQA)\nbenchmarking system designed to assess the ability of Large Language Models\n(LLMs) to reason and understand complex, domain-specific scenarios in Industry\n4.0. Unlike traditional QA benchmarks, our system focuses on multiple aspects\nof reasoning through failure modes, sensor data, and the relationships between\nthem across various industrial assets. Through this work, we envision a\nparadigm shift where modeling decisions are not only data-driven using\nstatistical tools like correlation analysis and significance tests, but also\ndomain-driven by specialized LLMs which can reason about the key contributors\nand useful patterns that can be captured with feature engineering. We evaluate\nthe Industrial knowledge of over a dozen LLMs-including GPT-4, Llama, and\nMistral-on FailureSensorIQ from different lens using\nPerturbation-Uncertainty-Complexity analysis, Expert Evaluation study,\nAsset-Specific Knowledge Gap analysis, ReAct agent using external\nknowledge-bases. Even though closed-source models with strong reasoning\ncapabilities approach expert-level performance, the comprehensive benchmark\nreveals a significant drop in performance that is fragile to perturbations,\ndistractions, and inherent knowledge gaps in the models. We also provide a\nreal-world case study of how LLMs can drive the modeling decisions on 3\ndifferent failure prediction datasets related to various assets. We release:\n(a) expert-curated MCQA for various industrial assets, (b) FailureSensorIQ\nbenchmark and Hugging Face leaderboard based on MCQA built from non-textual\ndata found in ISO documents, and (c) LLMFeatureSelector, an LLM-based feature\nselection scikit-learn pipeline. The software is available at\nhttps://github.com/IBM/FailureSensorIQ.", "AI": {"tldr": "FailureSensorIQ is a novel MCQA benchmarking system for LLMs, focusing on Industry 4.0 scenarios. It evaluates reasoning, domain knowledge, and robustness, revealing gaps in LLM performance.", "motivation": "To assess LLMs' ability to reason about complex, domain-specific industrial scenarios, shifting from purely data-driven to domain-driven modeling decisions.", "method": "Uses Perturbation-Uncertainty-Complexity analysis, Expert Evaluation, Asset-Specific Knowledge Gap analysis, and ReAct agents with external knowledge-bases to evaluate LLMs.", "result": "Closed-source models approach expert-level performance but show fragility to perturbations and knowledge gaps.", "conclusion": "FailureSensorIQ highlights LLMs' limitations in industrial reasoning and provides tools (benchmark, leaderboard, feature selector) for future research."}}
{"id": "2506.03169", "pdf": "https://arxiv.org/pdf/2506.03169", "abs": "https://arxiv.org/abs/2506.03169", "authors": ["Arindam Chaudhuri"], "title": "Improvement of human health lifespan with hybrid group pose estimation methods", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Human beings rely heavily on estimation of poses in order to access their\nbody movements. Human pose estimation methods take advantage of computer vision\nadvances in order to track human body movements in real life applications. This\ncomes from videos which are recorded through available devices. These\npara-digms provide potential to make human movement measurement more accessible\nto users. The consumers of pose estimation movements believe that human poses\ncontent tend to supplement available videos. This has increased pose estimation\nsoftware usage to estimate human poses. In order to address this problem, we\ndevelop hybrid-ensemble-based group pose estimation method to improve human\nhealth. This proposed hybrid-ensemble-based group pose estimation method aims\nto detect multi-person poses using modified group pose estimation and modified\nreal time pose estimation. This ensemble allows fusion of performance of stated\nmethods in real time. The input poses from images are fed into individual\nmeth-ods. The pose transformation method helps to identify relevant features\nfor en-semble to perform training effectively. After this, customized\npre-trained hybrid ensemble is trained on public benchmarked datasets which is\nbeing evaluated through test datasets. The effectiveness and viability of\nproposed method is estab-lished based on comparative analysis of group pose\nestimation methods and ex-periments conducted on benchmarked datasets. It\nprovides best optimized results in real-time pose estimation. It makes pose\nestimation method more robust to oc-clusion and improves dense regression\naccuracy. These results have affirmed po-tential application of this method in\nseveral real-time situations with improvement in human health life span", "AI": {"tldr": "A hybrid-ensemble-based group pose estimation method is proposed to improve real-time multi-person pose detection, enhancing robustness and accuracy for health applications.", "motivation": "The increasing reliance on pose estimation for human movement measurement and its potential to supplement videos drives the need for improved methods.", "method": "The approach combines modified group pose estimation and real-time pose estimation, using pose transformation for feature identification and training on benchmark datasets.", "result": "The method outperforms others in real-time pose estimation, offering better occlusion robustness and dense regression accuracy.", "conclusion": "The proposed method shows promise for real-time applications, particularly in improving human health life span."}}
{"id": "2506.03315", "pdf": "https://arxiv.org/pdf/2506.03315", "abs": "https://arxiv.org/abs/2506.03315", "authors": ["Kai Sauerwald", "Kenneth Skiba", "Eduardo Ferm\u00e9", "Thomas Meyer"], "title": "Axiomatics of Restricted Choices by Linear Orders of Sets with Minimum as Fallback", "categories": ["cs.AI", "cs.LO", "03E99, 91B14", "I.2.4"], "comment": null, "summary": "We study how linear orders can be employed to realise choice functions for\nwhich the set of potential choices is restricted, i.e., the possible choice is\nnot possible among the full powerset of all alternatives. In such restricted\nsettings, constructing a choice function via a relation on the alternatives is\nnot always possible. However, we show that one can always construct a choice\nfunction via a linear order on sets of alternatives, even when a fallback value\nis encoded as the minimal element in the linear order. The axiomatics of such\nchoice functions are presented for the general case and the case of\nunion-closed input restrictions. Restricted choice structures have applications\nin knowledge representation and reasoning, and here we discuss their\napplications for theory change and abstract argumentation.", "AI": {"tldr": "The paper explores constructing choice functions using linear orders for restricted sets of alternatives, showing feasibility even with fallback values. It presents axiomatics for general and union-closed cases, with applications in knowledge representation, theory change, and argumentation.", "motivation": "To address scenarios where choice functions cannot be constructed via relations on alternatives due to restricted sets, the study aims to demonstrate the viability of using linear orders on sets of alternatives, including fallback values.", "method": "The paper employs linear orders on sets of alternatives to construct choice functions, even with fallback values as minimal elements. It also provides axiomatics for general and union-closed input restrictions.", "result": "The study proves that choice functions can always be constructed via linear orders on sets of alternatives, including fallback values, and presents axiomatics for such functions.", "conclusion": "The findings highlight the utility of linear orders in restricted choice settings, with applications in knowledge representation, theory change, and abstract argumentation."}}
{"id": "2506.03158", "pdf": "https://arxiv.org/pdf/2506.03158", "abs": "https://arxiv.org/abs/2506.03158", "authors": ["Jiahao Qin", "Bei Peng", "Feng Liu", "Guangliang Cheng", "Lu Zong"], "title": "DUAL: Dynamic Uncertainty-Aware Learning", "categories": ["cs.LG", "cs.CV"], "comment": "12 pages, 3 figures", "summary": "Deep learning models frequently encounter feature uncertainty in diverse\nlearning scenarios, significantly impacting their performance and reliability.\nThis challenge is particularly complex in multi-modal scenarios, where models\nmust integrate information from different sources with inherent uncertainties.\nWe propose Dynamic Uncertainty-Aware Learning (DUAL), a unified framework that\neffectively handles feature uncertainty in both single-modal and multi-modal\nscenarios. DUAL introduces three key innovations: Dynamic Feature Uncertainty\nModeling, which continuously refines uncertainty estimates through joint\nconsideration of feature characteristics and learning dynamics; Adaptive\nDistribution-Aware Modulation, which maintains balanced feature distributions\nthrough dynamic sample influence adjustment; and Uncertainty-aware Cross-Modal\nRelationship Learning, which explicitly models uncertainties in cross-modal\ninteractions. Through extensive experiments, we demonstrate DUAL's\neffectiveness across multiple domains: in computer vision tasks, it achieves\nsubstantial improvements of 7.1% accuracy on CIFAR-10, 6.5% accuracy on\nCIFAR-100, and 2.3% accuracy on Tiny-ImageNet; in multi-modal learning, it\ndemonstrates consistent gains of 4.1% accuracy on CMU-MOSEI and 2.8% accuracy\non CMU-MOSI for sentiment analysis, while achieving 1.4% accuracy improvements\non MISR. The code will be available on GitHub soon.", "AI": {"tldr": "DUAL is a framework for handling feature uncertainty in deep learning, improving performance in single-modal and multi-modal tasks.", "motivation": "Addressing feature uncertainty in deep learning, especially in multi-modal scenarios, to enhance model reliability and performance.", "method": "DUAL introduces Dynamic Feature Uncertainty Modeling, Adaptive Distribution-Aware Modulation, and Uncertainty-aware Cross-Modal Relationship Learning.", "result": "Achieves significant accuracy improvements: 7.1% on CIFAR-10, 6.5% on CIFAR-100, 2.3% on Tiny-ImageNet, 4.1% on CMU-MOSEI, 2.8% on CMU-MOSI, and 1.4% on MISR.", "conclusion": "DUAL effectively addresses feature uncertainty, demonstrating consistent performance gains across diverse tasks."}}
{"id": "2506.03546", "pdf": "https://arxiv.org/pdf/2506.03546", "abs": "https://arxiv.org/abs/2506.03546", "authors": ["Yuanchen Bai", "Zijian Ding", "Angelique Taylor"], "title": "From Virtual Agents to Robot Teams: A Multi-Robot Framework Evaluation in High-Stakes Healthcare Context", "categories": ["cs.RO", "cs.AI", "cs.MA"], "comment": null, "summary": "Advancements in generative models have enabled multi-agent systems (MAS) to\nperform complex virtual tasks such as writing and code generation, which do not\ngeneralize well to physical multi-agent robotic teams. Current frameworks often\ntreat agents as conceptual task executors rather than physically embodied\nentities, and overlook critical real-world constraints such as spatial context,\nrobotic capabilities (e.g., sensing and navigation). To probe this gap, we\nreconfigure and stress-test a hierarchical multi-agent robotic team built on\nthe CrewAI framework in a simulated emergency department onboarding scenario.\nWe identify five persistent failure modes: role misalignment; tool access\nviolations; lack of in-time handling of failure reports; noncompliance with\nprescribed workflows; bypassing or false reporting of task completion. Based on\nthis analysis, we propose three design guidelines emphasizing process\ntransparency, proactive failure recovery, and contextual grounding. Our work\ninforms the development of more resilient and robust multi-agent robotic\nsystems (MARS), including opportunities to extend virtual multi-agent\nframeworks to the real world.", "AI": {"tldr": "The paper highlights the gap between virtual and physical multi-agent systems, identifies failure modes in robotic teams, and proposes design guidelines for resilience.", "motivation": "Current multi-agent systems (MAS) lack generalization to physical robotic teams due to overlooked real-world constraints like spatial context and robotic capabilities.", "method": "The study reconfigures and tests a hierarchical multi-agent robotic team in a simulated emergency department scenario, identifying five failure modes.", "result": "Five persistent failure modes were identified, leading to proposed design guidelines for process transparency, proactive failure recovery, and contextual grounding.", "conclusion": "The work aims to improve multi-agent robotic systems (MARS) by bridging virtual frameworks with real-world applications."}}
{"id": "2506.03425", "pdf": "https://arxiv.org/pdf/2506.03425", "abs": "https://arxiv.org/abs/2506.03425", "authors": ["Petr Grinberg", "Ankur Kumar", "Surya Koppisetti", "Gaurav Bharaj"], "title": "A Data-Driven Diffusion-based Approach for Audio Deepfake Explanations", "categories": ["eess.AS", "cs.AI", "cs.LG"], "comment": "5 pages, 3 figures, accepted at Interspeech 2025", "summary": "Evaluating explainability techniques, such as SHAP and LRP, in the context of\naudio deepfake detection is challenging due to lack of clear ground truth\nannotations. In the cases when we are able to obtain the ground truth, we find\nthat these methods struggle to provide accurate explanations. In this work, we\npropose a novel data-driven approach to identify artifact regions in deepfake\naudio. We consider paired real and vocoded audio, and use the difference in\ntime-frequency representation as the ground-truth explanation. The difference\nsignal then serves as a supervision to train a diffusion model to expose the\ndeepfake artifacts in a given vocoded audio. Experimental results on the VocV4\nand LibriSeVoc datasets demonstrate that our method outperforms traditional\nexplainability techniques, both qualitatively and quantitatively.", "AI": {"tldr": "Proposes a data-driven method using a diffusion model to identify deepfake audio artifacts, outperforming SHAP and LRP.", "motivation": "Challenges in evaluating explainability techniques like SHAP and LRP for audio deepfake detection due to lack of ground truth.", "method": "Uses paired real and vocoded audio, with time-frequency differences as ground truth, to train a diffusion model.", "result": "Outperforms traditional explainability techniques on VocV4 and LibriSeVoc datasets.", "conclusion": "The proposed method effectively exposes deepfake artifacts, offering better explanations than existing techniques."}}
{"id": "2411.16331", "pdf": "https://arxiv.org/pdf/2411.16331", "abs": "https://arxiv.org/abs/2411.16331", "authors": ["Xiaozhong Ji", "Xiaobin Hu", "Zhihong Xu", "Junwei Zhu", "Chuming Lin", "Qingdong He", "Jiangning Zhang", "Donghao Luo", "Yi Chen", "Qin Lin", "Qinglin Lu", "Chengjie Wang"], "title": "Sonic: Shifting Focus to Global Audio Perception in Portrait Animation", "categories": ["cs.MM", "cs.CV", "cs.GR", "cs.SD", "eess.AS"], "comment": "refer to our main-page \\url{https://jixiaozhong.github.io/Sonic/}", "summary": "The study of talking face generation mainly explores the intricacies of\nsynchronizing facial movements and crafting visually appealing,\ntemporally-coherent animations. However, due to the limited exploration of\nglobal audio perception, current approaches predominantly employ auxiliary\nvisual and spatial knowledge to stabilize the movements, which often results in\nthe deterioration of the naturalness and temporal inconsistencies.Considering\nthe essence of audio-driven animation, the audio signal serves as the ideal and\nunique priors to adjust facial expressions and lip movements, without resorting\nto interference of any visual signals. Based on this motivation, we propose a\nnovel paradigm, dubbed as Sonic, to {s}hift f{o}cus on the exploration of\nglobal audio per{c}ept{i}o{n}.To effectively leverage global audio knowledge,\nwe disentangle it into intra- and inter-clip audio perception and collaborate\nwith both aspects to enhance overall perception.For the intra-clip audio\nperception, 1). \\textbf{Context-enhanced audio learning}, in which long-range\nintra-clip temporal audio knowledge is extracted to provide facial expression\nand lip motion priors implicitly expressed as the tone and speed of speech. 2).\n\\textbf{Motion-decoupled controller}, in which the motion of the head and\nexpression movement are disentangled and independently controlled by\nintra-audio clips. Most importantly, for inter-clip audio perception, as a\nbridge to connect the intra-clips to achieve the global perception,\n\\textbf{Time-aware position shift fusion}, in which the global inter-clip audio\ninformation is considered and fused for long-audio inference via through\nconsecutively time-aware shifted windows. Extensive experiments demonstrate\nthat the novel audio-driven paradigm outperform existing SOTA methodologies in\nterms of video quality, temporally consistency, lip synchronization precision,\nand motion diversity.", "AI": {"tldr": "The paper introduces Sonic, a novel paradigm for talking face generation by focusing on global audio perception, outperforming existing methods in quality and consistency.", "motivation": "Current methods rely on visual signals, leading to unnatural results. Audio signals are ideal for driving facial animations without visual interference.", "method": "Sonic disentangles global audio into intra- and inter-clip perception, using context-enhanced learning, motion-decoupled control, and time-aware fusion.", "result": "Sonic outperforms state-of-the-art methods in video quality, temporal consistency, lip sync precision, and motion diversity.", "conclusion": "Focusing on global audio perception improves talking face generation, offering a more natural and consistent approach."}}
{"id": "2506.04013", "pdf": "https://arxiv.org/pdf/2506.04013", "abs": "https://arxiv.org/abs/2506.04013", "authors": ["Seymanur Akti", "Tuan Nam Nguyen", "Alexander Waibel"], "title": "Towards Better Disentanglement in Non-Autoregressive Zero-Shot Expressive Voice Conversion", "categories": ["cs.SD", "cs.AI", "eess.AS"], "comment": "Accepted to Interspeech 2025", "summary": "Expressive voice conversion aims to transfer both speaker identity and\nexpressive attributes from a target speech to a given source speech. In this\nwork, we improve over a self-supervised, non-autoregressive framework with a\nconditional variational autoencoder, focusing on reducing source timbre leakage\nand improving linguistic-acoustic disentanglement for better style transfer. To\nminimize style leakage, we use multilingual discrete speech units for content\nrepresentation and reinforce embeddings with augmentation-based similarity loss\nand mix-style layer normalization. To enhance expressivity transfer, we\nincorporate local F0 information via cross-attention and extract style\nembeddings enriched with global pitch and energy features. Experiments show our\nmodel outperforms baselines in emotion and speaker similarity, demonstrating\nsuperior style adaptation and reduced source style leakage.", "AI": {"tldr": "The paper improves expressive voice conversion by reducing source timbre leakage and enhancing style transfer using multilingual speech units, augmentation-based loss, and enriched style embeddings.", "motivation": "To achieve better transfer of both speaker identity and expressive attributes while minimizing source style leakage.", "method": "Uses a conditional variational autoencoder with multilingual discrete speech units, augmentation-based similarity loss, mix-style layer normalization, and enriched style embeddings with global pitch and energy features.", "result": "Outperforms baselines in emotion and speaker similarity, showing superior style adaptation and reduced source style leakage.", "conclusion": "The proposed framework effectively improves expressive voice conversion by addressing style leakage and enhancing disentanglement."}}
{"id": "2506.03292", "pdf": "https://arxiv.org/pdf/2506.03292", "abs": "https://arxiv.org/abs/2506.03292", "authors": ["Jiuding Sun", "Sidharth Baskaran", "Zhengxuan Wu", "Michael Sklar", "Christopher Potts", "Atticus Geiger"], "title": "HyperSteer: Activation Steering at Scale with Hypernetworks", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "Steering language models (LMs) by modifying internal activations is a popular\napproach for controlling text generation. Unsupervised dictionary learning\nmethods, e.g., sparse autoencoders, can be scaled to produce many steering\nvectors, but lack guarantees on the individual efficacy of each vector and\ncontrol over the coverage of relevant steering tasks. In contrast, supervised\nmethods for constructing steering vectors are targeted and effective, but\nrequire more data collection and training for each additional steering vector\nproduced. In this work, we introduce HyperSteer, a family of hypernetwork-based\narchitectures which are trained end-to-end to generate steering vectors\nconditioned on the natural language steering prompts and the internals of the\nsteered LM. In our evaluations, we show that scaling HyperSteer with thousands\nof steering prompts exceeds the performance of state-of-the-art activation\nsteering methods, even on steering prompts never seen during training.\nMoreover, HyperSteer performs on par with steering-via-prompting.", "AI": {"tldr": "HyperSteer, a hypernetwork-based method, generates effective steering vectors for language models using natural language prompts, outperforming unsupervised and supervised methods.", "motivation": "Existing methods for steering language models either lack guarantees on individual vector efficacy (unsupervised) or require extensive data/training (supervised). HyperSteer aims to bridge this gap.", "method": "HyperSteer uses hypernetwork architectures trained end-to-end to generate steering vectors conditioned on natural language prompts and LM internals.", "result": "HyperSteer scales well with thousands of prompts, outperforming state-of-the-art methods, even on unseen prompts, and matches steering-via-prompting performance.", "conclusion": "HyperSteer offers a scalable, effective solution for steering language models, combining the strengths of unsupervised and supervised methods."}}
{"id": "2506.03170", "pdf": "https://arxiv.org/pdf/2506.03170", "abs": "https://arxiv.org/abs/2506.03170", "authors": ["Murthy L", "Subarna Tripathi"], "title": "PALADIN : Robust Neural Fingerprinting for Text-to-Image Diffusion Models", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": null, "summary": "The risk of misusing text-to-image generative models for malicious uses,\nespecially due to the open-source development of such models, has become a\nserious concern. As a risk mitigation strategy, attributing generative models\nwith neural fingerprinting is emerging as a popular technique. There has been a\nplethora of recent work that aim for addressing neural fingerprinting. A\ntrade-off between the attribution accuracy and generation quality of such\nmodels has been studied extensively. None of the existing methods yet achieved\n$100\\%$ attribution accuracy. However, any model with less than \\emph{perfect}\naccuracy is practically non-deployable. In this work, we propose an accurate\nmethod to incorporate neural fingerprinting for text-to-image diffusion models\nleveraging the concepts of cyclic error correcting codes from the literature of\ncoding theory.", "AI": {"tldr": "Proposes a method for neural fingerprinting in text-to-image diffusion models using cyclic error correcting codes to achieve perfect attribution accuracy.", "motivation": "Addresses the risk of misuse in open-source text-to-image generative models by improving attribution accuracy.", "method": "Leverages cyclic error correcting codes from coding theory for neural fingerprinting.", "result": "Aims for perfect attribution accuracy, addressing the trade-off with generation quality.", "conclusion": "The proposed method is deployable due to its potential for perfect accuracy."}}
{"id": "2506.03332", "pdf": "https://arxiv.org/pdf/2506.03332", "abs": "https://arxiv.org/abs/2506.03332", "authors": ["Yifei Ming", "Zixuan Ke", "Xuan-Phi Nguyen", "Jiayu Wang", "Shafiq Joty"], "title": "Helpful Agent Meets Deceptive Judge: Understanding Vulnerabilities in Agentic Workflows", "categories": ["cs.AI"], "comment": null, "summary": "Agentic workflows -- where multiple large language model (LLM) instances\ninteract to solve tasks -- are increasingly built on feedback mechanisms, where\none model evaluates and critiques another. Despite the promise of\nfeedback-driven improvement, the stability of agentic workflows rests on the\nreliability of the judge. However, judges may hallucinate information, exhibit\nbias, or act adversarially -- introducing critical vulnerabilities into the\nworkflow. In this work, we present a systematic analysis of agentic workflows\nunder deceptive or misleading feedback. We introduce a two-dimensional\nframework for analyzing judge behavior, along axes of intent (from constructive\nto malicious) and knowledge (from parametric-only to retrieval-augmented\nsystems). Using this taxonomy, we construct a suite of judge behaviors and\ndevelop WAFER-QA, a new benchmark with critiques grounded in retrieved web\nevidence to evaluate robustness of agentic workflows against factually\nsupported adversarial feedback. We reveal that even strongest agents are\nvulnerable to persuasive yet flawed critiques -- often switching correct\nanswers after a single round of misleading feedback. Taking a step further, we\nstudy how model predictions evolve over multiple rounds of interaction,\nrevealing distinct behavioral patterns between reasoning and non-reasoning\nmodels. Our findings highlight fundamental vulnerabilities in feedback-based\nworkflows and offer guidance for building more robust agentic systems.", "AI": {"tldr": "The paper analyzes vulnerabilities in agentic workflows where LLM judges provide feedback, introducing a framework and benchmark (WAFER-QA) to evaluate robustness against deceptive feedback.", "motivation": "To address the unreliability of judges in feedback-driven workflows, which can hallucinate, be biased, or adversarial, undermining system stability.", "method": "A two-dimensional framework categorizes judge behavior by intent and knowledge, followed by creating a benchmark with grounded critiques to test workflow robustness.", "result": "Strong agents are vulnerable to persuasive but flawed critiques, often changing correct answers after misleading feedback. Reasoning and non-reasoning models show distinct behavioral patterns.", "conclusion": "Feedback-based workflows have fundamental vulnerabilities; the study provides insights for building more robust agentic systems."}}
{"id": "2506.03159", "pdf": "https://arxiv.org/pdf/2506.03159", "abs": "https://arxiv.org/abs/2506.03159", "authors": ["Lesley Wheat", "Martin v. Mohrenschildt", "Saeid Habibi"], "title": "Bayes Error Rate Estimation in Difficult Situations", "categories": ["cs.LG", "stat.ME", "stat.ML"], "comment": "21 pages, 13 figures, 20 tables", "summary": "The Bayes Error Rate (BER) is the fundamental limit on the achievable\ngeneralizable classification accuracy of any machine learning model due to\ninherent uncertainty within the data. BER estimators offer insight into the\ndifficulty of any classification problem and set expectations for optimal\nclassification performance. In order to be useful, the estimators must also be\naccurate with a limited number of samples on multivariate problems with unknown\nclass distributions. To determine which estimators meet the minimum\nrequirements for \"usefulness\", an in-depth examination of their accuracy is\nconducted using Monte Carlo simulations with synthetic data in order to obtain\ntheir confidence bounds for binary classification. To examine the usability of\nthe estimators on real-world applications, new test scenarios are introduced\nupon which 2500 Monte Carlo simulations per scenario are run over a wide range\nof BER values. In a comparison of k-Nearest Neighbor (kNN), Generalized\nHenze-Penrose (GHP) divergence and Kernel Density Estimation (KDE) techniques,\nresults show that kNN is overwhelmingly the more accurate non-parametric\nestimator. In order to reach the target of an under 5 percent range for the 95\npercent confidence bounds, the minimum number of required samples per class is\n1000. As more features are added, more samples are needed, so that 2500 samples\nper class are required at only 4 features. Other estimators do become more\naccurate than kNN as more features are added, but continuously fail to meet the\ntarget range.", "AI": {"tldr": "The paper evaluates BER estimators for classification accuracy, finding kNN as the most accurate non-parametric method, requiring 1000-2500 samples per class for reliable results.", "motivation": "To identify accurate BER estimators for practical use in classification problems with limited samples and unknown distributions.", "method": "Monte Carlo simulations with synthetic and real-world data, comparing kNN, GHP divergence, and KDE techniques.", "result": "kNN outperforms other estimators, needing 1000-2500 samples per class for under 5% error in 95% confidence bounds. Other methods fail to meet targets.", "conclusion": "kNN is the most reliable BER estimator for binary classification, though sample requirements increase with feature dimensionality."}}
{"id": "2506.03801", "pdf": "https://arxiv.org/pdf/2506.03801", "abs": "https://arxiv.org/abs/2506.03801", "authors": ["Peter Pfeiffer", "Alexander Rombach", "Maxim Majlatow", "Nijat Mehdiyev"], "title": "From Theory to Practice: Real-World Use Cases on Trustworthy LLM-Driven Process Modeling, Prediction and Automation", "categories": ["cs.SE", "cs.LG", "cs.MA"], "comment": "Accepted to the Next Gen Data and Process Management: Large Language\n  Models and Beyond workshop at SIGMOD 2025", "summary": "Traditional Business Process Management (BPM) struggles with rigidity,\nopacity, and scalability in dynamic environments while emerging Large Language\nModels (LLMs) present transformative opportunities alongside risks. This paper\nexplores four real-world use cases that demonstrate how LLMs, augmented with\ntrustworthy process intelligence, redefine process modeling, prediction, and\nautomation. Grounded in early-stage research projects with industrial partners,\nthe work spans manufacturing, modeling, life-science, and design processes,\naddressing domain-specific challenges through human-AI collaboration. In\nmanufacturing, an LLM-driven framework integrates uncertainty-aware explainable\nMachine Learning (ML) with interactive dialogues, transforming opaque\npredictions into auditable workflows. For process modeling, conversational\ninterfaces democratize BPMN design. Pharmacovigilance agents automate drug\nsafety monitoring via knowledge-graph-augmented LLMs. Finally, sustainable\ntextile design employs multi-agent systems to navigate regulatory and\nenvironmental trade-offs. We intend to examine tensions between transparency\nand efficiency, generalization and specialization, and human agency versus\nautomation. By mapping these trade-offs, we advocate for context-sensitive\nintegration prioritizing domain needs, stakeholder values, and iterative\nhuman-in-the-loop workflows over universal solutions. This work provides\nactionable insights for researchers and practitioners aiming to operationalize\nLLMs in critical BPM environments.", "AI": {"tldr": "LLMs enhance BPM by addressing rigidity and opacity through real-world use cases in manufacturing, modeling, life-science, and design, emphasizing human-AI collaboration and context-sensitive solutions.", "motivation": "Traditional BPM lacks adaptability and transparency in dynamic settings; LLMs offer transformative potential but require trustworthy integration.", "method": "The paper examines four industrial use cases where LLMs, combined with process intelligence, improve modeling, prediction, and automation via human-AI collaboration.", "result": "LLMs enable auditable workflows, democratized BPMN design, automated drug safety monitoring, and sustainable textile design, balancing transparency, efficiency, and human agency.", "conclusion": "Context-sensitive LLM integration, prioritizing domain needs and stakeholder values, is advocated over universal solutions for effective BPM transformation."}}
{"id": "2506.03515", "pdf": "https://arxiv.org/pdf/2506.03515", "abs": "https://arxiv.org/abs/2506.03515", "authors": ["Masaya Kawamura", "Takuya Hasumi", "Yuma Shirahata", "Ryuichi Yamamoto"], "title": "BitTTS: Highly Compact Text-to-Speech Using 1.58-bit Quantization and Weight Indexing", "categories": ["eess.AS", "cs.LG", "cs.SD", "eess.SP"], "comment": "Accepted to INTERSPEECH 2025", "summary": "This paper proposes a highly compact, lightweight text-to-speech (TTS) model\nfor on-device applications. To reduce the model size, the proposed model\nintroduces two techniques. First, we introduce quantization-aware training\n(QAT), which quantizes model parameters during training to as low as 1.58-bit.\nIn this case, most of 32-bit model parameters are quantized to ternary values\n{-1, 0, 1}. Second, we propose a method named weight indexing. In this method,\nwe save a group of 1.58-bit weights as a single int8 index. This allows for\nefficient storage of model parameters, even on hardware that treats values in\nunits of 8-bit. Experimental results demonstrate that the proposed method\nachieved 83 % reduction in model size, while outperforming the baseline of\nsimilar model size without quantization in synthesis quality.", "AI": {"tldr": "A compact TTS model using quantization-aware training and weight indexing reduces size by 83% while improving synthesis quality.", "motivation": "To enable efficient on-device TTS applications by minimizing model size without compromising performance.", "method": "Uses quantization-aware training (QAT) to reduce parameters to 1.58-bit and weight indexing for efficient storage.", "result": "Achieved 83% model size reduction and better synthesis quality than non-quantized baselines.", "conclusion": "The proposed techniques enable highly compact and efficient TTS models for on-device use."}}
{"id": "2506.03152", "pdf": "https://arxiv.org/pdf/2506.03152", "abs": "https://arxiv.org/abs/2506.03152", "authors": ["Robert Bayer", "Julian Priest", "Daniel Kjellberg", "Jeppe Lindhard", "Nikolaj S\u00f8renesen", "Nicolaj Valsted", "\u00cdvar \u00d3li", "P\u0131nar T\u00f6z\u00fcn"], "title": "Adaptive and Robust Image Processing on CubeSats", "categories": ["eess.IV", "cs.CV", "cs.DC", "cs.LG"], "comment": null, "summary": "CubeSats offer a low-cost platform for space research, particularly for Earth\nobservation. However, their resource-constrained nature and being in space,\nchallenge the flexibility and complexity of the deployed image processing\npipelines and their orchestration. This paper introduces two novel systems,\nDIPP and DISH, to address these challenges. DIPP is a modular and configurable\nimage processing pipeline framework that allows for adaptability to changing\nmission goals even after deployment, while preserving robustness. DISH is a\ndomain-specific language (DSL) and runtime system designed to schedule complex\nimaging workloads on low-power and memory-constrained processors.\n  Our experiments demonstrate that DIPP's decomposition of the processing\npipelines adds negligible overhead, while significantly reducing the network\nrequirements of updating pipelines and being robust against erroneous module\nuploads. Furthermore, we compare DISH to Lua, a general purpose scripting\nlanguage, and demonstrate its comparable expressiveness and lower memory\nrequirement.", "AI": {"tldr": "The paper introduces DIPP and DISH, two systems for flexible and efficient image processing on resource-constrained CubeSats. DIPP enables adaptable pipelines, while DISH optimizes workload scheduling. Both systems show minimal overhead and improved efficiency.", "motivation": "CubeSats' resource constraints and space environment limit the flexibility and complexity of image processing pipelines. The paper aims to address these challenges.", "method": "DIPP is a modular framework for adaptable pipelines, and DISH is a DSL/runtime for efficient scheduling on low-power processors. Experiments evaluate their performance.", "result": "DIPP reduces network needs for updates and handles errors robustly. DISH matches Lua's expressiveness with lower memory use.", "conclusion": "DIPP and DISH effectively enhance CubeSat image processing, balancing adaptability and efficiency."}}
{"id": "2505.14151", "pdf": "https://arxiv.org/pdf/2505.14151", "abs": "https://arxiv.org/abs/2505.14151", "authors": ["Jiaming Li", "Sheng Wang", "Xin Wang", "Yitao Zhu", "Honglin Xiong", "Zixu Zhuang", "Qian Wang"], "title": "ReactDiff: Latent Diffusion for Facial Reaction Generation", "categories": ["cs.CV", "cs.MM"], "comment": "Accepted by Neural Networks", "summary": "Given the audio-visual clip of the speaker, facial reaction generation aims\nto predict the listener's facial reactions. The challenge lies in capturing the\nrelevance between video and audio while balancing appropriateness, realism, and\ndiversity. While prior works have mostly focused on uni-modal inputs or\nsimplified reaction mappings, recent approaches such as PerFRDiff have explored\nmulti-modal inputs and the one-to-many nature of appropriate reaction mappings.\nIn this work, we propose the Facial Reaction Diffusion (ReactDiff) framework\nthat uniquely integrates a Multi-Modality Transformer with conditional\ndiffusion in the latent space for enhanced reaction generation. Unlike existing\nmethods, ReactDiff leverages intra- and inter-class attention for fine-grained\nmulti-modal interaction, while the latent diffusion process between the encoder\nand decoder enables diverse yet contextually appropriate outputs. Experimental\nresults demonstrate that ReactDiff significantly outperforms existing\napproaches, achieving a facial reaction correlation of 0.26 and diversity score\nof 0.094 while maintaining competitive realism. The code is open-sourced at\n\\href{https://github.com/Hunan-Tiger/ReactDiff}{github}.", "AI": {"tldr": "ReactDiff is a framework for generating listener facial reactions from speaker audio-visual clips, using multi-modal inputs and latent diffusion for diversity and realism.", "motivation": "The challenge is capturing relevance between video and audio while balancing appropriateness, realism, and diversity in facial reaction generation.", "method": "ReactDiff integrates a Multi-Modality Transformer with conditional diffusion in latent space, using intra- and inter-class attention for fine-grained interaction.", "result": "ReactDiff achieves a facial reaction correlation of 0.26 and diversity score of 0.094, outperforming existing methods.", "conclusion": "ReactDiff enhances facial reaction generation with improved diversity and realism, demonstrated by superior performance metrics."}}
{"id": "2506.04073", "pdf": "https://arxiv.org/pdf/2506.04073", "abs": "https://arxiv.org/abs/2506.04073", "authors": ["Esteban Guti\u00e9rrez", "Frederic Font", "Xavier Serra", "Lonce Wyse"], "title": "A Statistics-Driven Differentiable Approach for Sound Texture Synthesis and Analysis", "categories": ["cs.SD", "eess.AS"], "comment": "Accepted to the 28th International Conference on Digital Audio\n  Effects (DAFx 2025) to be held in Ancona, Italy. 8 pages, one diagram and 5\n  tables", "summary": "In this work, we introduce TexStat, a novel loss function specifically\ndesigned for the analysis and synthesis of texture sounds characterized by\nstochastic structure and perceptual stationarity. Drawing inspiration from the\nstatistical and perceptual framework of McDermott and Simoncelli, TexStat\nidentifies similarities between signals belonging to the same texture category\nwithout relying on temporal structure. We also propose using TexStat as a\nvalidation metric alongside Frechet Audio Distances (FAD) to evaluate texture\nsound synthesis models. In addition to TexStat, we present TexEnv, an\nefficient, lightweight and differentiable texture sound synthesizer that\ngenerates audio by imposing amplitude envelopes on filtered noise. We further\nintegrate these components into TexDSP, a DDSP-inspired generative model\ntailored for texture sounds. Through extensive experiments across various\ntexture sound types, we demonstrate that TexStat is perceptually meaningful,\ntime-invariant, and robust to noise, features that make it effective both as a\nloss function for generative tasks and as a validation metric. All tools and\ncode are provided as open-source contributions and our PyTorch implementations\nare efficient, differentiable, and highly configurable, enabling its use in\nboth generative tasks and as a perceptually grounded evaluation metric.", "AI": {"tldr": "TexStat is a novel loss function for texture sound analysis/synthesis, validated with FAD. TexEnv synthesizes texture sounds, integrated into TexDSP. Both are open-source, efficient, and perceptually effective.", "motivation": "To address the challenge of analyzing and synthesizing texture sounds with stochastic structure and perceptual stationarity without relying on temporal structure.", "method": "TexStat identifies texture similarities statistically and perceptually. TexEnv synthesizes sounds using amplitude envelopes on filtered noise. Both are integrated into TexDSP, a generative model.", "result": "TexStat is perceptually meaningful, time-invariant, and noise-robust, effective as a loss function and validation metric. TexDSP demonstrates strong performance across texture types.", "conclusion": "TexStat and TexEnv provide efficient, perceptually grounded tools for texture sound tasks, with open-source implementations for broader use."}}
{"id": "2506.03295", "pdf": "https://arxiv.org/pdf/2506.03295", "abs": "https://arxiv.org/abs/2506.03295", "authors": ["Yubo Wang", "Ping Nie", "Kai Zou", "Lijun Wu", "Wenhu Chen"], "title": "Unleashing the Reasoning Potential of Pre-trained LLMs by Critique Fine-Tuning on One Problem", "categories": ["cs.CL", "cs.LG"], "comment": null, "summary": "We have witnessed that strong LLMs like Qwen-Math, MiMo, and Phi-4 possess\nimmense reasoning potential inherited from the pre-training stage. With\nreinforcement learning (RL), these models can improve dramatically on reasoning\ntasks. Recent studies have shown that even RL on a single problem can unleash\nthese models' reasoning capabilities. However, RL is not only expensive but\nalso unstable. Even one-shot RL requires hundreds of GPU hours. This raises a\ncritical question: Is there a more efficient way to unleash the reasoning\npotential of these powerful base LLMs? In this work, we demonstrate that\nCritique Fine-Tuning (CFT) on only one problem can effectively unleash the\nreasoning potential of LLMs. Our method constructs critique data by collecting\ndiverse model-generated solutions to a single problem and using teacher LLMs to\nprovide detailed critiques. We fine-tune Qwen and Llama family models, ranging\nfrom 1.5B to 14B parameters, on the CFT data and observe significant\nperformance gains across diverse reasoning tasks. For example, with just 5 GPU\nhours of training, Qwen-Math-7B-CFT show an average improvement of 15% on six\nmath benchmarks and 16% on three logic reasoning benchmarks. These results are\ncomparable to or even surpass the results from RL with 20x less compute.\nAblation studies reveal the robustness of one-shot CFT across different prompt\nproblems. These results highlight one-shot CFT as a simple, general, and\ncompute-efficient approach to unleashing the reasoning capabilities of modern\nLLMs.", "AI": {"tldr": "One-shot Critique Fine-Tuning (CFT) efficiently unleashes LLMs' reasoning potential with minimal compute, outperforming RL methods.", "motivation": "RL is expensive and unstable for improving LLMs' reasoning; CFT offers a simpler, cost-effective alternative.", "method": "CFT constructs critique data from diverse model solutions and teacher critiques, fine-tuning models like Qwen and Llama.", "result": "Qwen-Math-7B-CFT improves 15% on math and 16% on logic tasks with just 5 GPU hours, matching RL with 20x less compute.", "conclusion": "One-shot CFT is a robust, efficient method to enhance LLMs' reasoning capabilities."}}
{"id": "2506.03171", "pdf": "https://arxiv.org/pdf/2506.03171", "abs": "https://arxiv.org/abs/2506.03171", "authors": ["Ghulam Mujtaba", "Eun-Seok Ryu"], "title": "EdgeVidSum: Real-Time Personalized Video Summarization at the Edge", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "EdgeVidSum is a lightweight method that generates personalized, fast-forward\nsummaries of long-form videos directly on edge devices. The proposed approach\nenables real-time video summarization while safeguarding user privacy through\nlocal data processing using innovative thumbnail-based techniques and efficient\nneural architectures. Unlike conventional methods that process entire videos\nframe by frame, the proposed method uses thumbnail containers to significantly\nreduce computational complexity without sacrificing semantic relevance. The\nframework employs a hierarchical analysis approach, where a lightweight 2D CNN\nmodel identifies user-preferred content from thumbnails and generates\ntimestamps to create fast-forward summaries. Our interactive demo highlights\nthe system's ability to create tailored video summaries for long-form videos,\nsuch as movies, sports events, and TV shows, based on individual user\npreferences. The entire computation occurs seamlessly on resource-constrained\ndevices like Jetson Nano, demonstrating how EdgeVidSum addresses the critical\nchallenges of computational efficiency, personalization, and privacy in modern\nvideo consumption environments.", "AI": {"tldr": "EdgeVidSum is a lightweight method for real-time, personalized video summarization on edge devices, using thumbnail containers and efficient neural architectures to reduce computational complexity while maintaining privacy.", "motivation": "To address the challenges of computational efficiency, personalization, and privacy in video summarization, especially on resource-constrained edge devices.", "method": "Uses thumbnail containers and a hierarchical 2D CNN model to identify user-preferred content and generate fast-forward summaries locally.", "result": "Demonstrates real-time summarization on devices like Jetson Nano, tailored to individual preferences for movies, sports, and TV shows.", "conclusion": "EdgeVidSum successfully balances efficiency, personalization, and privacy, making it suitable for modern video consumption on edge devices."}}
{"id": "2506.03469", "pdf": "https://arxiv.org/pdf/2506.03469", "abs": "https://arxiv.org/abs/2506.03469", "authors": ["Tuan Le", "Risal Shefin", "Debashis Gupta", "Thai Le", "Sarra Alqahtani"], "title": "Verification-Guided Falsification for Safe RL via Explainable Abstraction and Risk-Aware Exploration", "categories": ["cs.AI", "cs.LG"], "comment": "8 pages, 7 figures, European Conference on Artificial Intelligence\n  (ECAI)", "summary": "Ensuring the safety of reinforcement learning (RL) policies in high-stakes\nenvironments requires not only formal verification but also interpretability\nand targeted falsification. While model checking provides formal guarantees,\nits effectiveness is limited by abstraction quality and the completeness of the\nunderlying trajectory dataset. We propose a hybrid framework that integrates\n(1) explainability, (2) model checking, and (3) risk-guided falsification to\nachieve both rigor and coverage. Our approach begins by constructing a\nhuman-interpretable abstraction of the RL policy using Comprehensible Abstract\nPolicy Summarization (CAPS). This abstract graph, derived from offline\ntrajectories, is both verifier-friendly, semantically meaningful, and can be\nused as input to Storm probabilistic model checker to verify satisfaction of\ntemporal safety specifications. If the model checker identifies a violation, it\nwill return an interpretable counterexample trace by which the policy fails the\nsafety requirement. However, if no violation is detected, we cannot conclude\nsatisfaction due to potential limitation in the abstraction and coverage of the\noffline dataset. In such cases, we estimate associated risk during model\nchecking to guide a falsification strategy that prioritizes searching in\nhigh-risk states and regions underrepresented in the trajectory dataset. We\nfurther provide PAC-style guarantees on the likelihood of uncovering undetected\nviolations. Finally, we incorporate a lightweight safety shield that switches\nto a fallback policy at runtime when such a risk exceeds a threshold,\nfacilitating failure mitigation without retraining.", "AI": {"tldr": "A hybrid framework combining explainability, model checking, and risk-guided falsification ensures RL policy safety with interpretability and formal guarantees.", "motivation": "To address the limitations of formal verification (abstraction quality, dataset coverage) in ensuring RL policy safety in high-stakes environments.", "method": "Uses CAPS for interpretable policy abstraction, Storm for model checking, and risk-guided falsification for coverage. Includes a safety shield for runtime mitigation.", "result": "Provides verifiable safety guarantees, interpretable counterexamples, and PAC-style guarantees on violation detection.", "conclusion": "The framework balances rigor and coverage, enhancing RL policy safety with interpretability and runtime safeguards."}}
{"id": "2506.03160", "pdf": "https://arxiv.org/pdf/2506.03160", "abs": "https://arxiv.org/abs/2506.03160", "authors": ["Shriyank Somvanshi", "Anannya Ghosh Tusti", "Mahmuda Sultana Mimi", "Md Monzurul Islam", "Sazzad Bin Bashar Polock", "Anandi Dutta", "Subasish Das"], "title": "Applying MambaAttention, TabPFN, and TabTransformers to Classify SAE Automation Levels in Crashes", "categories": ["cs.LG"], "comment": null, "summary": "The increasing presence of automated vehicles (AVs) presents new challenges\nfor crash classification and safety analysis. Accurately identifying the SAE\nautomation level involved in each crash is essential to understanding crash\ndynamics and system accountability. However, existing approaches often overlook\nautomation-specific factors and lack model sophistication to capture\ndistinctions between different SAE levels. To address this gap, this study\nevaluates the performance of three advanced tabular deep learning models\nMambaAttention, TabPFN, and TabTransformer for classifying SAE automation\nlevels using structured crash data from Texas (2024), covering 4,649 cases\ncategorized as Assisted Driving (SAE Level 1), Partial Automation (SAE Level\n2), and Advanced Automation (SAE Levels 3-5 combined). Following class\nbalancing using SMOTEENN, the models were trained and evaluated on a unified\ndataset of 7,300 records. MambaAttention demonstrated the highest overall\nperformance (F1-scores: 88% for SAE 1, 97% for SAE 2, and 99% for SAE 3-5),\nwhile TabPFN excelled in zero-shot inference with high robustness for rare\ncrash categories. In contrast, TabTransformer underperformed, particularly in\ndetecting Partial Automation crashes (F1-score: 55%), suggesting challenges in\nmodeling shared human-system control dynamics. These results highlight the\ncapability of deep learning models tailored for tabular data to enhance the\naccuracy and efficiency of automation-level classification. Integrating such\nmodels into crash analysis frameworks can support policy development, AV safety\nevaluation, and regulatory decisions, especially in distinguishing high-risk\nconditions for mid- and high-level automation technologies.", "AI": {"tldr": "The study evaluates three deep learning models (MambaAttention, TabPFN, TabTransformer) for classifying SAE automation levels in AV crashes, finding MambaAttention most effective, while TabTransformer struggles with partial automation cases.", "motivation": "Accurate classification of SAE automation levels in AV crashes is crucial for understanding crash dynamics and system accountability, but existing methods lack sophistication.", "method": "The study uses structured crash data from Texas (2024) and evaluates three models (MambaAttention, TabPFN, TabTransformer) after class balancing with SMOTEENN.", "result": "MambaAttention achieved the highest F1-scores (88% for SAE 1, 97% for SAE 2, 99% for SAE 3-5), while TabTransformer underperformed (55% for SAE 2).", "conclusion": "Deep learning models tailored for tabular data can improve automation-level classification, aiding policy and safety evaluations for AVs."}}
{"id": "2506.03828", "pdf": "https://arxiv.org/pdf/2506.03828", "abs": "https://arxiv.org/abs/2506.03828", "authors": ["Dhaval Patel", "Shuxin Lin", "James Rayfield", "Nianjun Zhou", "Roman Vaculin", "Natalia Martinez", "Fearghal O'donncha", "Jayant Kalagnanam"], "title": "AssetOpsBench: Benchmarking AI Agents for Task Automation in Industrial Asset Operations and Maintenance", "categories": ["cs.AI", "cs.MA"], "comment": "39 pages, 18 figures", "summary": "AI for Industrial Asset Lifecycle Management aims to automate complex\noperational workflows -- such as condition monitoring, maintenance planning,\nand intervention scheduling -- to reduce human workload and minimize system\ndowntime. Traditional AI/ML approaches have primarily tackled these problems in\nisolation, solving narrow tasks within the broader operational pipeline. In\ncontrast, the emergence of AI agents and large language models (LLMs)\nintroduces a next-generation opportunity: enabling end-to-end automation across\nthe entire asset lifecycle. This paper envisions a future where AI agents\nautonomously manage tasks that previously required distinct expertise and\nmanual coordination. To this end, we introduce AssetOpsBench -- a unified\nframework and environment designed to guide the development, orchestration, and\nevaluation of domain-specific agents tailored for Industry 4.0 applications. We\noutline the key requirements for such holistic systems and provide actionable\ninsights into building agents that integrate perception, reasoning, and control\nfor real-world industrial operations. The software is available at\nhttps://github.com/IBM/AssetOpsBench.", "AI": {"tldr": "The paper proposes AssetOpsBench, a framework for developing AI agents to automate end-to-end industrial asset lifecycle management, leveraging LLMs and AI agents for holistic solutions.", "motivation": "Traditional AI/ML approaches address industrial tasks in isolation, lacking end-to-end automation. The paper aims to bridge this gap by enabling autonomous management of complex workflows.", "method": "Introduces AssetOpsBench, a unified framework for developing domain-specific AI agents that integrate perception, reasoning, and control for Industry 4.0.", "result": "AssetOpsBench provides a practical environment for orchestrating and evaluating AI agents in industrial settings, with software available on GitHub.", "conclusion": "The paper envisions AI agents autonomously managing industrial workflows, reducing human workload and downtime, with AssetOpsBench as a foundational tool."}}
{"id": "2506.03606", "pdf": "https://arxiv.org/pdf/2506.03606", "abs": "https://arxiv.org/abs/2506.03606", "authors": ["Parismita Gogoi", "Sishir Kalita", "Wendy Lalhminghlui", "Viyazonuo Terhiija", "Moakala Tzudir", "Priyankoo Sarmah", "S. R. M. Prasanna"], "title": "Tone recognition in low-resource languages of North-East India: peeling the layers of SSL-based speech models", "categories": ["eess.AS", "cs.AI", "cs.CL", "eess.SP"], "comment": "Accepted in Interspeech2025", "summary": "This study explores the use of self-supervised learning (SSL) models for tone\nrecognition in three low-resource languages from North Eastern India: Angami,\nAo, and Mizo. We evaluate four Wav2vec2.0 base models that were pre-trained on\nboth tonal and non-tonal languages. We analyze tone-wise performance across the\nlayers for all three languages and compare the different models. Our results\nshow that tone recognition works best for Mizo and worst for Angami. The middle\nlayers of the SSL models are the most important for tone recognition,\nregardless of the pre-training language, i.e. tonal or non-tonal. We have also\nfound that the tone inventory, tone types, and dialectal variations affect tone\nrecognition. These findings provide useful insights into the strengths and\nweaknesses of SSL-based embeddings for tonal languages and highlight the\npotential for improving tone recognition in low-resource settings. The source\ncode is available at GitHub 1 .", "AI": {"tldr": "The study evaluates SSL models (Wav2vec2.0) for tone recognition in low-resource languages (Angami, Ao, Mizo), finding Mizo performs best and middle layers are most critical. Tone inventory and dialectal variations impact performance.", "motivation": "To assess the effectiveness of SSL models for tone recognition in low-resource tonal languages and understand the role of model layers and linguistic factors.", "method": "Evaluated four Wav2vec2.0 base models pre-trained on tonal/non-tonal languages, analyzing tone-wise performance across layers for Angami, Ao, and Mizo.", "result": "Mizo had the best tone recognition, Angami the worst. Middle layers were most important. Tone inventory and dialectal variations affected performance.", "conclusion": "SSL models show promise for tone recognition in low-resource languages, with middle layers being key. Linguistic factors like tone inventory and dialects influence results."}}
{"id": "2506.03175", "pdf": "https://arxiv.org/pdf/2506.03175", "abs": "https://arxiv.org/abs/2506.03175", "authors": ["Youshen Xiao", "Yiling Shi", "Ruixi Sun", "Hongjiang Wei", "Fei Gao", "Yuyao Zhang"], "title": "Super-temporal-resolution Photoacoustic Imaging with Dynamic Reconstruction through Implicit Neural Representation in Sparse-view", "categories": ["eess.IV", "cs.CV"], "comment": null, "summary": "Dynamic Photoacoustic Computed Tomography (PACT) is an important imaging\ntechnique for monitoring physiological processes, capable of providing\nhigh-contrast images of optical absorption at much greater depths than\ntraditional optical imaging methods. However, practical instrumentation and\ngeometric constraints limit the number of acoustic sensors available around the\nimaging target, leading to sparsity in sensor data. Traditional photoacoustic\n(PA) image reconstruction methods, when directly applied to sparse PA data,\nproduce severe artifacts. Additionally, these traditional methods do not\nconsider the inter-frame relationships in dynamic imaging. Temporal resolution\nis crucial for dynamic photoacoustic imaging, which is fundamentally limited by\nthe low repetition rate (e.g., 20 Hz) and high cost of high-power laser\ntechnology. Recently, Implicit Neural Representation (INR) has emerged as a\npowerful deep learning tool for solving inverse problems with sparse data, by\ncharacterizing signal properties as continuous functions of their coordinates\nin an unsupervised manner. In this work, we propose an INR-based method to\nimprove dynamic photoacoustic image reconstruction from sparse-views and\nenhance temporal resolution, using only spatiotemporal coordinates as input.\nSpecifically, the proposed INR represents dynamic photoacoustic images as\nimplicit functions and encodes them into a neural network. The weights of the\nnetwork are learned solely from the acquired sparse sensor data, without the\nneed for external training datasets or prior images. Benefiting from the strong\nimplicit continuity regularization provided by INR, as well as explicit\nregularization for low-rank and sparsity, our proposed method outperforms\ntraditional reconstruction methods under two different sparsity conditions,\neffectively suppressing artifacts and ensuring image quality.", "AI": {"tldr": "The paper proposes an Implicit Neural Representation (INR)-based method to enhance dynamic photoacoustic image reconstruction from sparse sensor data, improving temporal resolution and reducing artifacts.", "motivation": "Traditional photoacoustic image reconstruction methods struggle with sparse sensor data and ignore inter-frame relationships in dynamic imaging, leading to artifacts and limited temporal resolution.", "method": "The authors use INR to represent dynamic images as implicit functions, encoding them into a neural network trained solely on sparse sensor data, without external datasets. The method incorporates implicit continuity regularization and explicit low-rank/sparsity constraints.", "result": "The proposed method outperforms traditional techniques under sparse conditions, suppressing artifacts and maintaining image quality.", "conclusion": "INR-based reconstruction offers a promising solution for dynamic photoacoustic imaging, addressing sparsity and temporal resolution challenges without requiring prior data."}}
{"id": "2506.03681", "pdf": "https://arxiv.org/pdf/2506.03681", "abs": "https://arxiv.org/abs/2506.03681", "authors": ["Pradeep Rangappa", "Andres Carofilis", "Jeena Prakash", "Shashi Kumar", "Sergio Burdisso", "Srikanth Madikeri", "Esau Villatoro-Tello", "Bidisha Sharma", "Petr Motlicek", "Kadri Hacioglu", "Shankar Venkatesan", "Saurabh Vyas", "Andreas Stolcke"], "title": "Efficient Data Selection for Domain Adaptation of ASR Using Pseudo-Labels and Multi-Stage Filtering", "categories": ["cs.CL", "cs.SD", "eess.AS"], "comment": "Accepted at Interspeech 2025, Netherlands", "summary": "Fine-tuning pretrained ASR models for specific domains is challenging for\nsmall organizations with limited labeled data and computational resources.\nHere, we explore different data selection pipelines and propose a robust\napproach that improves ASR adaptation by filtering pseudo-labels generated\nusing Whisper (encoder-decoder) and Zipformer (transducer) models. Our approach\nintegrates multiple selection strategies -- including word error rate (WER)\nprediction, named entity recognition (NER), and character error rate (CER)\nanalysis -- to extract high-quality training segments. We evaluate our method\non Whisper and Zipformer using a 7500-hour baseline, comparing it to a\nCER-based approach relying on hypotheses from three ASR systems. Fine-tuning on\n7500 hours of pseudo-labeled call center data achieves 12.3% WER, while our\nfiltering reduces the dataset to 100 hours (1.4%) with similar performance; a\nsimilar trend is observed on Fisher English.", "AI": {"tldr": "A robust data selection pipeline improves ASR adaptation by filtering pseudo-labels from Whisper and Zipformer models, reducing dataset size while maintaining performance.", "motivation": "Fine-tuning pretrained ASR models for specific domains is challenging for small organizations due to limited labeled data and computational resources.", "method": "Proposes a data selection approach integrating WER prediction, NER, and CER analysis to extract high-quality training segments from pseudo-labels.", "result": "Fine-tuning on filtered 100-hour dataset achieves similar performance (12.3% WER) as the 7500-hour baseline; observed on call center and Fisher English data.", "conclusion": "The method effectively reduces dataset size without compromising ASR performance, making domain adaptation more feasible for resource-limited settings."}}
{"id": "2506.03301", "pdf": "https://arxiv.org/pdf/2506.03301", "abs": "https://arxiv.org/abs/2506.03301", "authors": ["Daham M. Mustafa", "Abhishek Nadgeri", "Diego Collarana", "Benedikt T. Arnold", "Christoph Quix", "Christoph Lange", "Stefan Decker"], "title": "From Instructions to ODRL Usage Policies: An Ontology Guided Approach", "categories": ["cs.CL", "F.2.2; I.2.7; H.3.3"], "comment": "The paper is accepted at LLM+KG: International Workshop on Data\n  Management Opportunities in Unifying Large Language Models + Knowledge\n  Graphs, VLDB 2024, August 26, 2024, Guangzhou, China.\n  https://vldb.org/workshops/2024/proceedings/LLM+KG/LLM+KG-15.pdf", "summary": "This study presents an approach that uses large language models such as GPT-4\nto generate usage policies in the W3C Open Digital Rights Language ODRL\nautomatically from natural language instructions. Our approach uses the ODRL\nontology and its documentation as a central part of the prompt. Our research\nhypothesis is that a curated version of existing ontology documentation will\nbetter guide policy generation. We present various heuristics for adapting the\nODRL ontology and its documentation to guide an end-to-end KG construction\nprocess. We evaluate our approach in the context of dataspaces, i.e.,\ndistributed infrastructures for trustworthy data exchange between multiple\nparticipating organizations for the cultural domain. We created a benchmark\nconsisting of 12 use cases of varying complexity. Our evaluation shows\nexcellent results with up to 91.95% accuracy in the resulting knowledge graph.", "AI": {"tldr": "Using GPT-4 and ODRL ontology, the study automates policy generation from natural language, achieving 91.95% accuracy in knowledge graphs for dataspaces.", "motivation": "To automate the creation of usage policies in ODRL by leveraging large language models and curated ontology documentation.", "method": "Uses GPT-4 with ODRL ontology and documentation as prompts, applying heuristics for end-to-end KG construction.", "result": "Achieves up to 91.95% accuracy in generating knowledge graphs for 12 cultural domain use cases.", "conclusion": "Curated ontology documentation effectively guides policy generation, demonstrating high accuracy in automated KG construction."}}
{"id": "2506.03173", "pdf": "https://arxiv.org/pdf/2506.03173", "abs": "https://arxiv.org/abs/2506.03173", "authors": ["Xiaoyi Liu", "Hao Tang"], "title": "FOLIAGE: Towards Physical Intelligence World Models Via Unbounded Surface Evolution", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Physical intelligence -- anticipating and shaping the world from partial,\nmultisensory observations -- is critical for next-generation world models. We\npropose FOLIAGE, a physics-informed multimodal world model for unbounded\naccretive surface growth. In its Action-Perception loop, a unified context\nencoder maps images, mesh connectivity, and point clouds to a shared latent\nstate. A physics-aware predictor, conditioned on physical control actions,\nadvances this latent state in time to align with the target latent of the\nsurface, yielding a Modality-Agnostic Growth Embedding (MAGE) that interfaces\nwith critic heads for downstream objectives. FOLIAGE's Accretive Graph Network\n(AGN) captures dynamic connectivity through Age Positional Encoding and\nEnergy-Gated Message-Passing. Geometry-Correspondence Fusion and Cross-Patch\nMasking enhance MAGE's expressiveness, while Hierarchical Pooling balances\nglobal context with local dynamics. We create SURF-GARDEN, a world model\nlearning platform comprising a Counterfactual Physics Simulator, a Multimodal\nCorrespondence Extractor, and Evolution Tracing, which generates 7,200 diverse\nsurface-growth sequences. SURF-BENCH, our physical-intelligence evaluation\nsuite, evaluates six core tasks -- topology recognition, inverse material\nestimation, growth-stage classification, latent roll-out, cross-modal\nretrieval, and dense correspondence -- and four stress tests -- sensor dropout,\nzero-shot modality transfer, long-horizon prediction, and physics ablation --\nto probe resilience. FOLIAGE outperforms specialized baselines while remaining\nrobust across dynamic environments, establishing a new world-model based,\nmultimodal pathway to physical intelligence.", "AI": {"tldr": "FOLIAGE is a physics-informed multimodal world model for unbounded surface growth, using a shared latent state and physics-aware prediction. It outperforms baselines in physical intelligence tasks.", "motivation": "To advance physical intelligence by modeling unbounded accretive surface growth from partial, multisensory observations.", "method": "Uses a unified context encoder, physics-aware predictor, and Modality-Agnostic Growth Embedding (MAGE) with techniques like Age Positional Encoding and Energy-Gated Message-Passing.", "result": "Outperforms specialized baselines in tasks like topology recognition and cross-modal retrieval, demonstrating robustness.", "conclusion": "FOLIAGE establishes a new multimodal pathway for physical intelligence, excelling in dynamic environments."}}
{"id": "2506.03503", "pdf": "https://arxiv.org/pdf/2506.03503", "abs": "https://arxiv.org/abs/2506.03503", "authors": ["Shan Shan"], "title": "Computational Architects of Society: Quantum Machine Learning for Social Rule Genesis", "categories": ["cs.AI"], "comment": null, "summary": "The quantification of social science remains a longstanding challenge,\nlargely due to the philosophical nature of its foundational theories. Although\nquantum computing has advanced rapidly in recent years, its relevance to social\ntheory remains underexplored. Most existing research focuses on micro-cognitive\nmodels or philosophical analogies, leaving a gap in system-level applications\nof quantum principles to the analysis of social systems. This study addresses\nthat gap by proposing a theoretical and computational framework that combines\nquantum mechanics with Generative AI to simulate the emergence and evolution of\nsocial norms. Drawing on core quantum concepts--such as superposition,\nentanglement, and probabilistic measurement--this research models society as a\ndynamic, uncertain system and sets up five ideal-type experiments. These\nscenarios are simulated using 25 generative agents, each assigned evolving\nroles as compliers, resistors, or enforcers. Within a simulated environment\nmonitored by a central observer (the Watcher), agents interact, respond to\nsurveillance, and adapt to periodic normative disruptions. These interactions\nallow the system to self-organize under external stress and reveal emergent\npatterns. Key findings show that quantum principles, when integrated with\ngenerative AI, enable the modeling of uncertainty, emergence, and\ninterdependence in complex social systems. Simulations reveal patterns\nincluding convergence toward normative order, the spread of resistance, and the\nspontaneous emergence of new equilibria in social rules. In conclusion, this\nstudy introduces a novel computational lens that lays the groundwork for a\nquantum-informed social theory. It offers interdisciplinary insights into how\nsociety can be understood not just as a structure to observe but as a dynamic\nsystem to simulate and redesign through quantum technologies.", "AI": {"tldr": "The paper proposes a quantum-mechanics and Generative AI framework to simulate social norms, addressing gaps in applying quantum principles to social systems.", "motivation": "To bridge the gap in system-level applications of quantum principles in social science, moving beyond micro-cognitive models or philosophical analogies.", "method": "Combines quantum mechanics (superposition, entanglement, probabilistic measurement) with Generative AI to simulate social norms using 25 generative agents in five ideal-type experiments.", "result": "Reveals emergent patterns like normative convergence, resistance spread, and new equilibria, demonstrating quantum principles' utility in modeling social uncertainty and interdependence.", "conclusion": "Introduces a novel computational lens for quantum-informed social theory, enabling dynamic simulation and redesign of societal systems."}}
{"id": "2506.03161", "pdf": "https://arxiv.org/pdf/2506.03161", "abs": "https://arxiv.org/abs/2506.03161", "authors": ["Mira Nuthakki"], "title": "Safety-Prioritized, Reinforcement Learning-Enabled Traffic Flow Optimization in a 3D City-Wide Simulation Environment", "categories": ["cs.LG", "cs.AI", "cs.RO"], "comment": "18 pages, figures at end, methods at end. Format/order can be changed\n  if necessary", "summary": "Traffic congestion and collisions represent significant economic,\nenvironmental, and social challenges worldwide. Traditional traffic management\napproaches have shown limited success in addressing these complex, dynamic\nproblems. To address the current research gaps, three potential tools are\ndeveloped: a comprehensive 3D city-wide simulation environment that integrates\nboth macroscopic and microscopic traffic dynamics; a collision model; and a\nreinforcement learning framework with custom reward functions prioritizing\nsafety over efficiency. Unity game engine-based simulation is used for direct\ncollision modeling. A custom reward enabled reinforcement learning method,\nproximal policy optimization (PPO) model, yields substantial improvements over\nbaseline results, reducing the number of serious collisions, number of\nvehicle-vehicle collisions, and total distance travelled by over 3 times the\nbaseline values. The model also improves fuel efficiency by 39% and reduces\ncarbon emissions by 88%. Results establish feasibility for city-wide 3D traffic\nsimulation applications incorporating the vision-zero safety principles of the\nDepartment of Transportation, including physics-informed, adaptable, realistic\ncollision modeling, as well as appropriate reward modeling for real-world\ntraffic signal light control towards reducing collisions, optimizing traffic\nflow and reducing greenhouse emissions.", "AI": {"tldr": "A reinforcement learning framework with custom rewards, using PPO, significantly improves traffic safety and efficiency in a 3D simulation, reducing collisions and emissions.", "motivation": "Addressing traffic congestion and collisions, which are major global challenges, by leveraging advanced simulation and reinforcement learning.", "method": "Developed a 3D city-wide simulation, a collision model, and a PPO-based reinforcement learning framework with safety-focused rewards.", "result": "Achieved 3x reduction in collisions, 39% better fuel efficiency, and 88% lower emissions compared to baselines.", "conclusion": "The approach is feasible for real-world traffic management, aligning with safety and environmental goals."}}
{"id": "2411.07161", "pdf": "https://arxiv.org/pdf/2411.07161", "abs": "https://arxiv.org/abs/2411.07161", "authors": ["Young-Min Cho", "Raphael Shu", "Nilaksh Das", "Tamer Alkhouli", "Yi-An Lai", "Jason Cai", "Monica Sunkara", "Yi Zhang", "Dan Roth"], "title": "RoundTable: Investigating Group Decision-Making Mechanism in Multi-Agent Collaboration", "categories": ["cs.MA", "cs.AI"], "comment": "preprint", "summary": "Effective group decision-making is critical in Multi-Agent Systems (MAS).\nYet, how different mechanisms for reaching consensus impact collaboration\nquality and efficiency remains understudied. We conduct a systematic study on\ngroup decision-making mechanisms in a decentralized setting. Through controlled\nexperiments, we analyze how different voting rules affect decision quality and\nefficiency in a multi-round collaboration. Results reveal that majority voting\noften cause inefficient collaboration due to its strict acceptance criteria. At\nthe extreme, unanimous voting gives 87% lower initial performance than the\nbest-performing method. Our qualitative analysis of cross-agent communication\nshows that messages become longer and more repetitive over time: while message\nlength increases by 84%, similarity to the previous round increases to 90%.\nBased on these insights, language-based early stopping methods make the\nperformance 13% closer to oracle while reducing rounds by 50%. Our findings\nhighlight the crucial role of group decision-making in optimizing MAS\ncollaboration.", "AI": {"tldr": "The paper studies how different consensus mechanisms (like majority and unanimous voting) impact collaboration quality and efficiency in Multi-Agent Systems (MAS). Majority voting leads to inefficiency, while unanimous voting performs poorly initially. Language-based early stopping improves performance and reduces rounds.", "motivation": "To understand how consensus mechanisms affect collaboration in decentralized MAS, as this area is understudied.", "method": "Systematic study with controlled experiments analyzing voting rules' impact on decision quality and efficiency, including qualitative analysis of agent communication.", "result": "Majority voting causes inefficiency; unanimous voting has 87% lower initial performance. Language-based early stopping improves performance by 13% and reduces rounds by 50%.", "conclusion": "Group decision-making mechanisms significantly impact MAS collaboration, with language-based methods offering notable improvements."}}
{"id": "2506.03917", "pdf": "https://arxiv.org/pdf/2506.03917", "abs": "https://arxiv.org/abs/2506.03917", "authors": ["Stefano Damiano", "Toon van Waterschoot"], "title": "Sound Field Reconstruction Using Physics-Informed Boundary Integral Networks", "categories": ["eess.AS"], "comment": "Accepted for publication at EUSIPCO 2025", "summary": "Sound field reconstruction refers to the problem of estimating the acoustic\npressure field over an arbitrary region of space, using only a limited set of\nmeasurements. Physics-informed neural networks have been adopted to solve the\nproblem by incorporating in the training loss function the governing partial\ndifferential equation, either the Helmholtz or the wave equation. In this work,\nwe introduce a boundary integral network for sound field reconstruction.\nRelying on the Kirchhoff-Helmholtz boundary integral equation to model the\nsound field in a given region of space, we employ a shallow neural network to\nretrieve the pressure distribution on the boundary of the considered domain,\nenabling to accurately retrieve the acoustic pressure inside of it. Assuming\nthe positions of measurement microphones are known, we train the model by\nminimizing the mean squared error between the estimated and measured pressure\nat those locations. Experimental results indicate that the proposed model\noutperforms existing physics-informed data-driven techniques.", "AI": {"tldr": "A boundary integral network is introduced for sound field reconstruction, outperforming existing physics-informed methods.", "motivation": "To improve sound field reconstruction using limited measurements by leveraging boundary integral equations.", "method": "Uses a shallow neural network to model boundary pressure via the Kirchhoff-Helmholtz equation, trained with microphone measurements.", "result": "The model outperforms existing physics-informed data-driven techniques in accuracy.", "conclusion": "The boundary integral network is effective for sound field reconstruction, offering better performance than current methods."}}
{"id": "2506.03177", "pdf": "https://arxiv.org/pdf/2506.03177", "abs": "https://arxiv.org/abs/2506.03177", "authors": ["Isarun Chamveha", "Supphanut Chaiyungyuen", "Sasinun Worakriangkrai", "Nattawadee Prasawang", "Warasinee Chaisangmongkon", "Pornpim Korpraphong", "Voraparee Suvannarerg", "Shanigarn Thiravit", "Chalermdej Kannawat", "Kewalin Rungsinaporn", "Suwara Issaragrisil", "Payia Chadbunchachai", "Pattiya Gatechumpol", "Chawiporn Muktabhant", "Patarachai Sereerat"], "title": "Deep Learning-Based Breast Cancer Detection in Mammography: A Multi-Center Validation Study in Thai Population", "categories": ["eess.IV", "cs.AI", "cs.CV"], "comment": null, "summary": "This study presents a deep learning system for breast cancer detection in\nmammography, developed using a modified EfficientNetV2 architecture with\nenhanced attention mechanisms. The model was trained on mammograms from a major\nThai medical center and validated on three distinct datasets: an in-domain test\nset (9,421 cases), a biopsy-confirmed set (883 cases), and an out-of-domain\ngeneralizability set (761 cases) collected from two different hospitals. For\ncancer detection, the model achieved AUROCs of 0.89, 0.96, and 0.94 on the\nrespective datasets. The system's lesion localization capability, evaluated\nusing metrics including Lesion Localization Fraction (LLF) and Non-Lesion\nLocalization Fraction (NLF), demonstrated robust performance in identifying\nsuspicious regions. Clinical validation through concordance tests showed strong\nagreement with radiologists: 83.5% classification and 84.0% localization\nconcordance for biopsy-confirmed cases, and 78.1% classification and 79.6%\nlocalization concordance for out-of-domain cases. Expert radiologists'\nacceptance rate also averaged 96.7% for biopsy-confirmed cases, and 89.3% for\nout-of-domain cases. The system achieved a System Usability Scale score of\n74.17 for source hospital, and 69.20 for validation hospitals, indicating good\nclinical acceptance. These results demonstrate the model's effectiveness in\nassisting mammogram interpretation, with the potential to enhance breast cancer\nscreening workflows in clinical practice.", "AI": {"tldr": "A deep learning system using modified EfficientNetV2 with enhanced attention mechanisms for breast cancer detection in mammography, validated on diverse datasets with strong performance and clinical acceptance.", "motivation": "To develop an effective deep learning system for breast cancer detection in mammography, improving accuracy and clinical workflow.", "method": "Modified EfficientNetV2 architecture with enhanced attention mechanisms, trained on mammograms from a Thai medical center and validated on three distinct datasets.", "result": "Achieved AUROCs of 0.89, 0.96, and 0.94 on respective datasets; strong lesion localization and high concordance with radiologists (83.5%-84.0% for biopsy-confirmed cases).", "conclusion": "The system is effective for mammogram interpretation, with potential to enhance breast cancer screening workflows clinically."}}
{"id": "2506.03722", "pdf": "https://arxiv.org/pdf/2506.03722", "abs": "https://arxiv.org/abs/2506.03722", "authors": ["Yinfeng Xia", "Huiyan Li", "Chenyang Le", "Manhong Wang", "Yutao Sun", "Xingyang Ma", "Yanmin Qian"], "title": "MFLA: Monotonic Finite Look-ahead Attention for Streaming Speech Recognition", "categories": ["cs.CL", "cs.SD", "eess.AS"], "comment": "Accepted by Interspeech 2025", "summary": "Applying large pre-trained speech models like Whisper has shown promise in\nreducing training costs for various speech tasks. However, integrating these\nmodels into streaming systems remains a challenge. This paper presents a novel\nprefix-to-prefix training framework for streaming recognition by fine-tuning\nthe Whisper. We introduce the Continuous Integrate-and-Fire mechanism to\nestablish a quasi-monotonic alignment between continuous speech sequences and\ndiscrete text tokens. Additionally, we design Monotonic Finite Look-ahead\nAttention, allowing each token to attend to infinite left-context and finite\nright-context from the speech sequences. We also employ the wait-k decoding\nstrategy to simplify the decoding process while ensuring consistency between\ntraining and testing. Our theoretical analysis and experiments demonstrate that\nthis approach achieves a controllable trade-off between latency and quality,\nmaking it suitable for various streaming applications.", "AI": {"tldr": "A novel prefix-to-prefix training framework for streaming speech recognition using Whisper, featuring Continuous Integrate-and-Fire and Monotonic Finite Look-ahead Attention for low-latency, high-quality results.", "motivation": "To address the challenge of integrating large pre-trained speech models like Whisper into streaming systems while maintaining efficiency and quality.", "method": "Fine-tuning Whisper with a prefix-to-prefix framework, Continuous Integrate-and-Fire for alignment, Monotonic Finite Look-ahead Attention for context handling, and wait-k decoding for consistency.", "result": "Achieves a controllable trade-off between latency and quality, suitable for streaming applications.", "conclusion": "The proposed framework effectively enables streaming recognition with Whisper, balancing performance and latency."}}
{"id": "2506.03303", "pdf": "https://arxiv.org/pdf/2506.03303", "abs": "https://arxiv.org/abs/2506.03303", "authors": ["Mustafa Eyceoz", "Nikhil Shivakumar Nayak", "Hao Wang", "Ligong Han", "Akash Srivastava"], "title": "Hopscotch: Discovering and Skipping Redundancies in Language Models", "categories": ["cs.CL", "cs.AI", "cs.LG", "68T50", "I.2.7; I.2.6; I.2.4"], "comment": "10 pages, 4 figures, 9 tables", "summary": "Modern causal language models stack many attention blocks to improve\nperformance, but not all blocks are necessary for every task. We propose\nHopscotch, a simple yet effective method that identifies and skips attention\nblocks with least contributions to a task and adapts to preserve output\nquality. Hopscotch jointly optimizes which blocks to skip and how to scale the\noutputs of the remaining layers. By introducing lightweight, trainable scaling\nparameters to attention and MLP blocks, it mitigates distribution shifts in\nhidden states caused by removing attention blocks. Hopscotch does not modify\nmodel weights or require access to pretraining or instruction-tuning data, and\nis compatible with existing model compression techniques. When applied to\n$\\texttt{Llama-3.1-8B}$ and $\\texttt{Qwen2.5-7B}$, Hopscotch achieves less than\na 2% drop in performance even after skipping four attention blocks.", "AI": {"tldr": "Hopscotch is a method to skip less important attention blocks in causal language models, optimizing performance with minimal output quality loss.", "motivation": "Modern causal language models use many attention blocks, but not all are necessary for every task, leading to inefficiency.", "method": "Hopscotch identifies and skips low-contribution blocks, using trainable scaling parameters to mitigate hidden state shifts.", "result": "Applied to Llama-3.1-8B and Qwen2.5-7B, it skips four blocks with <2% performance drop.", "conclusion": "Hopscotch efficiently reduces computation without modifying weights or requiring additional data."}}
{"id": "2506.03174", "pdf": "https://arxiv.org/pdf/2506.03174", "abs": "https://arxiv.org/abs/2506.03174", "authors": ["Koki Matsuishi", "Kosuke Ukita", "Tsuyoshi Okita"], "title": "Multimodal Foundation Model for Cross-Modal Retrieval and Activity Recognition Tasks", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": "25 pages, 8 figures", "summary": "In recent years, the widespread adoption of wearable devices has highlighted\nthe growing importance of behavior analysis using IMU. While applications span\ndiverse fields such as healthcare and robotics, recent studies have\nincreasingly focused on multimodal analysis, in addition to unimodal analysis.\nSeveral studies have proposed multimodal foundation models that incorporate\nfirst-person video and text data; however, these models still fall short in\nproviding a detailed analysis of full-body human activity. To address this\nlimitation, we propose Activity Understanding and Representations Alignment -\nMultimodal Foundation Model (AURA-MFM), a foundational model integrating four\nmodalities: third-person video, motion capture, IMU, and text. By incorporating\nthird-person video and motion capture data, the model enables a detailed and\nmultidimensional understanding of human activity, which first-person\nperspectives alone fail to capture. Additionally, a Transformer-based IMU\nencoder is employed to enhance the model's overall performance. Experimental\nevaluations on retrieval and activity recognition tasks demonstrate that our\nmodel surpasses existing methods. Notably, in the zero-shot classification for\naction recognition, our method achieved significantly higher performance, with\nan F1-score of 0.6226 and an accuracy of 0.7320, whereas the existing method\nrecorded an F1-score of 0.0747 and an accuracy of 0.1961.", "AI": {"tldr": "The paper proposes AURA-MFM, a multimodal foundation model integrating third-person video, motion capture, IMU, and text for detailed human activity analysis, outperforming existing methods in retrieval and activity recognition tasks.", "motivation": "Existing multimodal models lack detailed full-body human activity analysis, prompting the development of AURA-MFM to incorporate more comprehensive modalities.", "method": "AURA-MFM integrates four modalities (third-person video, motion capture, IMU, and text) and uses a Transformer-based IMU encoder for enhanced performance.", "result": "The model achieved superior results in zero-shot action recognition (F1-score: 0.6226, accuracy: 0.7320) compared to existing methods (F1-score: 0.0747, accuracy: 0.1961).", "conclusion": "AURA-MFM advances multimodal human activity analysis by leveraging diverse data sources and outperforms current methods in key tasks."}}
{"id": "2506.03548", "pdf": "https://arxiv.org/pdf/2506.03548", "abs": "https://arxiv.org/abs/2506.03548", "authors": ["Chenglong Ye", "Gang Xiong", "Junyou Shang", "Xingyuan Dai", "Xiaoyan Gong", "Yisheng Lv"], "title": "SUMO-MCP: Leveraging the Model Context Protocol for Autonomous Traffic Simulation and Optimization", "categories": ["cs.AI"], "comment": null, "summary": "Traffic simulation tools, such as SUMO, are essential for urban mobility\nresearch. However, such tools remain challenging for users due to complex\nmanual workflows involving network download, demand generation, simulation\nsetup, and result analysis. In this paper, we introduce SUMO-MCP, a novel\nplatform that not only wraps SUMO' s core utilities into a unified tool suite\nbut also provides additional auxiliary utilities for common preprocessing and\npostprocessing tasks. Using SUMO-MCP, users can issue simple natural-language\nprompts to generate traffic scenarios from OpenStreetMap data, create demand\nfrom origin-destination matrices or random patterns, run batch simulations with\nmultiple signal-control strategies, perform comparative analyses with automated\nreporting, and detect congestion for signal-timing optimization. Furthermore,\nthe platform allows flexible custom workflows by dynamically combining exposed\nSUMO tools without additional coding. Experiments demonstrate that SUMO-MCP\nsignificantly makes traffic simulation more accessible and reliable for\nresearchers. We will release code for SUMO-MCP at\nhttps://github.com/ycycycl/SUMO-MCP in the future.", "AI": {"tldr": "SUMO-MCP simplifies SUMO traffic simulation by wrapping core utilities and adding auxiliary tools, enabling natural-language prompts for tasks like scenario generation, demand creation, and congestion detection.", "motivation": "Traffic simulation tools like SUMO are complex, requiring manual workflows for setup and analysis, which SUMO-MCP aims to streamline.", "method": "SUMO-MCP integrates SUMO's utilities into a unified platform, offering natural-language prompts and flexible custom workflows without coding.", "result": "Experiments show SUMO-MCP enhances accessibility and reliability of traffic simulation for researchers.", "conclusion": "SUMO-MCP effectively simplifies and improves traffic simulation workflows, with future code release planned."}}
{"id": "2506.03163", "pdf": "https://arxiv.org/pdf/2506.03163", "abs": "https://arxiv.org/abs/2506.03163", "authors": ["Oluwaseyi Giwa"], "title": "Causal Discovery in Dynamic Fading Wireless Networks", "categories": ["cs.LG", "eess.SP", "stat.ME"], "comment": "5 pages, 3 figures", "summary": "Dynamic causal discovery in wireless networks is essential due to evolving\ninterference, fading, and mobility, which complicate traditional static causal\nmodels. This paper addresses causal inference challenges in dynamic fading\nwireless environments by proposing a sequential regression-based algorithm with\na novel application of the NOTEARS acyclicity constraint, enabling efficient\nonline updates. We derive theoretical lower and upper bounds on the detection\ndelay required to identify structural changes, explicitly quantifying their\ndependence on network size, noise variance, and fading severity. Monte Carlo\nsimulations validate these theoretical results, demonstrating linear increases\nin detection delay with network size, quadratic growth with noise variance, and\ninverse-square dependence on the magnitude of structural changes. Our findings\nprovide rigorous theoretical insights and practical guidelines for designing\nrobust online causal inference mechanisms to maintain network reliability under\nnonstationary wireless conditions.", "AI": {"tldr": "Proposes a sequential regression-based algorithm with NOTEARS constraint for dynamic causal discovery in wireless networks, deriving detection delay bounds and validating them via simulations.", "motivation": "Addresses challenges in causal inference due to evolving interference, fading, and mobility in wireless networks, which static models cannot handle.", "method": "Uses a sequential regression-based algorithm with a novel application of the NOTEARS acyclicity constraint for efficient online updates.", "result": "Theoretical bounds on detection delay are derived, showing dependence on network size, noise variance, and fading severity. Simulations confirm linear, quadratic, and inverse-square relationships.", "conclusion": "Provides theoretical insights and practical guidelines for robust online causal inference in nonstationary wireless environments."}}
{"id": "2412.09429", "pdf": "https://arxiv.org/pdf/2412.09429", "abs": "https://arxiv.org/abs/2412.09429", "authors": ["Yi Luo", "Linghang Shi", "Yihao Li", "Aobo Zhuang", "Yeyun Gong", "Ling Liu", "Chen Lin"], "title": "From Intention To Implementation: Automating Biomedical Research via LLMs", "categories": ["cs.MA", "cs.AI", "cs.CL"], "comment": "The paper involves material for which we have not yet obtained proper\n  copyright permissions", "summary": "Conventional biomedical research is increasingly labor-intensive due to the\nexponential growth of scientific literature and datasets. Artificial\nintelligence (AI), particularly Large Language Models (LLMs), has the potential\nto revolutionize this process by automating various steps. Still, significant\nchallenges remain, including the need for multidisciplinary expertise,\nlogicality of experimental design, and performance measurements. This paper\nintroduces BioResearcher, the first end-to-end automated system designed to\nstreamline the entire biomedical research process involving dry lab\nexperiments. BioResearcher employs a modular multi-agent architecture,\nintegrating specialized agents for search, literature processing, experimental\ndesign, and programming. By decomposing complex tasks into logically related\nsub-tasks and utilizing a hierarchical learning approach, BioResearcher\neffectively addresses the challenges of multidisciplinary requirements and\nlogical complexity. Furthermore, BioResearcher incorporates an LLM-based\nreviewer for in-process quality control and introduces novel evaluation metrics\nto assess the quality and automation of experimental protocols. BioResearcher\nsuccessfully achieves an average execution success rate of 63.07% across eight\npreviously unmet research objectives. The generated protocols averagely\noutperform typical agent systems by 22.0% on five quality metrics. The system\ndemonstrates significant potential to reduce researchers' workloads and\naccelerate biomedical discoveries, paving the way for future innovations in\nautomated research systems.", "AI": {"tldr": "BioResearcher is an AI-driven, end-to-end automated system for biomedical research, addressing challenges like multidisciplinary expertise and experimental design. It achieves a 63.07% success rate and outperforms typical systems by 22.0%.", "motivation": "The exponential growth of scientific literature and datasets makes biomedical research labor-intensive. AI, especially LLMs, can automate and streamline this process.", "method": "BioResearcher uses a modular multi-agent architecture with specialized agents for search, literature processing, experimental design, and programming, along with hierarchical learning and LLM-based quality control.", "result": "The system achieves a 63.07% success rate and outperforms typical agent systems by 22.0% on quality metrics.", "conclusion": "BioResearcher reduces researchers' workloads and accelerates discoveries, showcasing potential for future automated research innovations."}}
{"id": "2506.04152", "pdf": "https://arxiv.org/pdf/2506.04152", "abs": "https://arxiv.org/abs/2506.04152", "authors": ["Ryan Langman", "Xuesong Yang", "Paarth Neekhara", "Shehzeen Hussain", "Edresson Casanova", "Evelina Bakhturina", "Jason Li"], "title": "HiFiTTS-2: A Large-Scale High Bandwidth Speech Dataset", "categories": ["eess.AS"], "comment": "Submitted to Interspeech 2025", "summary": "This paper introduces HiFiTTS-2, a large-scale speech dataset designed for\nhigh-bandwidth speech synthesis. The dataset is derived from LibriVox\naudiobooks, and contains approximately 36.7k hours of English speech for 22.05\nkHz training, and 31.7k hours for 44.1 kHz training. We present our data\nprocessing pipeline, including bandwidth estimation, segmentation, text\npreprocessing, and multi-speaker detection. The dataset is accompanied by\ndetailed utterance and audiobook metadata generated by our pipeline, enabling\nresearchers to apply data quality filters to adapt the dataset to various use\ncases. Experimental results demonstrate that our data pipeline and resulting\ndataset can facilitate the training of high-quality, zero-shot text-to-speech\n(TTS) models at high bandwidths.", "AI": {"tldr": "HiFiTTS-2 is a large-scale speech dataset for high-bandwidth TTS, derived from LibriVox audiobooks, with extensive processing and metadata.", "motivation": "To provide a high-quality, large-scale dataset for training high-bandwidth TTS models.", "method": "Data processing pipeline includes bandwidth estimation, segmentation, text preprocessing, and multi-speaker detection.", "result": "The dataset (36.7k hours for 22.05 kHz, 31.7k hours for 44.1 kHz) supports high-quality, zero-shot TTS training.", "conclusion": "HiFiTTS-2 and its pipeline enable effective training of high-bandwidth TTS models."}}
{"id": "2506.03178", "pdf": "https://arxiv.org/pdf/2506.03178", "abs": "https://arxiv.org/abs/2506.03178", "authors": ["Md. Zihad Bin Jahangir", "Muhammad Ashad Kabir", "Sumaiya Akter", "Israt Jahan", "Minh Chau"], "title": "LLaMA-XR: A Novel Framework for Radiology Report Generation using LLaMA and QLoRA Fine Tuning", "categories": ["eess.IV", "cs.AI", "cs.CV"], "comment": "25 pages", "summary": "Automated radiology report generation holds significant potential to reduce\nradiologists' workload and enhance diagnostic accuracy. However, generating\nprecise and clinically meaningful reports from chest radiographs remains\nchallenging due to the complexity of medical language and the need for\ncontextual understanding. Existing models often struggle with maintaining both\naccuracy and contextual relevance. In this paper, we present LLaMA-XR, a novel\nframework that integrates LLaMA 3.1 with DenseNet-121-based image embeddings\nand Quantized Low-Rank Adaptation (QLoRA) fine-tuning. LLaMA-XR achieves\nimproved coherence and clinical accuracy while maintaining computational\nefficiency. This efficiency is driven by an optimization strategy that enhances\nparameter utilization and reduces memory overhead, enabling faster report\ngeneration with lower computational resource demands. Extensive experiments\nconducted on the IU X-ray benchmark dataset demonstrate that LLaMA-XR\noutperforms a range of state-of-the-art methods. Our model achieves a ROUGE-L\nscore of 0.433 and a METEOR score of 0.336, establishing new performance\nbenchmarks in the domain. These results underscore LLaMA-XR's potential as an\neffective and efficient AI system for automated radiology reporting, offering\nenhanced clinical utility and reliability.", "AI": {"tldr": "LLaMA-XR, a novel framework combining LLaMA 3.1 with DenseNet-121 and QLoRA fine-tuning, improves automated radiology report generation by enhancing coherence, clinical accuracy, and computational efficiency.", "motivation": "Automated radiology report generation can reduce workload and improve diagnostic accuracy, but existing models struggle with accuracy and contextual relevance.", "method": "LLaMA-XR integrates LLaMA 3.1 with DenseNet-121-based image embeddings and QLoRA fine-tuning, optimizing parameter utilization and reducing memory overhead.", "result": "LLaMA-XR achieves ROUGE-L 0.433 and METEOR 0.336 on the IU X-ray dataset, outperforming state-of-the-art methods.", "conclusion": "LLaMA-XR is an efficient and effective AI system for automated radiology reporting, offering enhanced clinical utility and reliability."}}
{"id": "2506.03832", "pdf": "https://arxiv.org/pdf/2506.03832", "abs": "https://arxiv.org/abs/2506.03832", "authors": ["Omer Moussa", "Mariya Toneva"], "title": "Brain-tuned Speech Models Better Reflect Speech Processing Stages in the Brain", "categories": ["cs.CL", "cs.SD", "eess.AS", "q-bio.NC"], "comment": "Proceedings of Interspeech 2025", "summary": "Pretrained self-supervised speech models excel in speech tasks but do not\nreflect the hierarchy of human speech processing, as they encode rich semantics\nin middle layers and poor semantics in late layers. Recent work showed that\nbrain-tuning (fine-tuning models using human brain recordings) improves speech\nmodels' semantic understanding. Here, we examine how well brain-tuned models\nfurther reflect the brain's intermediate stages of speech processing. We find\nthat late layers of brain-tuned models substantially improve over pretrained\nmodels in their alignment with semantic language regions. Further layer-wise\nprobing reveals that early layers remain dedicated to low-level acoustic\nfeatures, while late layers become the best at complex high-level tasks. These\nfindings show that brain-tuned models not only perform better but also exhibit\na well-defined hierarchical processing going from acoustic to semantic\nrepresentations, making them better model organisms for human speech\nprocessing.", "AI": {"tldr": "Brain-tuned speech models improve semantic alignment with human brain processing and exhibit hierarchical structure from acoustic to semantic representations.", "motivation": "To investigate if brain-tuned speech models better reflect the brain's intermediate stages of processing compared to pretrained models.", "method": "Fine-tuning speech models using human brain recordings (brain-tuning) and analyzing layer-wise alignment with brain regions.", "result": "Late layers of brain-tuned models align better with semantic regions, while early layers focus on acoustic features.", "conclusion": "Brain-tuned models perform better and mirror human speech hierarchy, making them superior for studying speech processing."}}
{"id": "2506.03310", "pdf": "https://arxiv.org/pdf/2506.03310", "abs": "https://arxiv.org/abs/2506.03310", "authors": ["Guillermo Marco", "Julio Gonzalo", "V\u00edctor Fresno"], "title": "The Reader is the Metric: How Textual Features and Reader Profiles Explain Conflicting Evaluations of AI Creative Writing", "categories": ["cs.CL", "cs.HC"], "comment": "Camera-ready version, 14 pages, 3 figures. Accepted to Findings of\n  the Association for Computational Linguistics (ACL) 2025. Code & data:\n  https://github.com/grmarco/the-reader-is-the-metric", "summary": "Recent studies comparing AI-generated and human-authored literary texts have\nproduced conflicting results: some suggest AI already surpasses human quality,\nwhile others argue it still falls short. We start from the hypothesis that such\ndivergences can be largely explained by genuine differences in how readers\ninterpret and value literature, rather than by an intrinsic quality of the\ntexts evaluated. Using five public datasets (1,471 stories, 101 annotators\nincluding critics, students, and lay readers), we (i) extract 17 reference-less\ntextual features (e.g., coherence, emotional variance, average sentence\nlength...); (ii) model individual reader preferences, deriving feature\nimportance vectors that reflect their textual priorities; and (iii) analyze\nthese vectors in a shared \"preference space\". Reader vectors cluster into two\nprofiles: 'surface-focused readers' (mainly non-experts), who prioritize\nreadability and textual richness; and 'holistic readers' (mainly experts), who\nvalue thematic development, rhetorical variety, and sentiment dynamics. Our\nresults quantitatively explain how measurements of literary quality are a\nfunction of how text features align with each reader's preferences. These\nfindings advocate for reader-sensitive evaluation frameworks in the field of\ncreative text generation.", "AI": {"tldr": "The study explains conflicting AI vs. human text evaluations by showing reader preferences shape perceived quality, identifying two reader profiles.", "motivation": "Resolve inconsistencies in AI vs. human literary text evaluations by examining reader preferences.", "method": "Analyzed 1,471 stories using 17 textual features, modeled reader preferences, and clustered them in a preference space.", "result": "Two reader profiles emerged: surface-focused (non-experts) and holistic (experts), explaining divergent quality assessments.", "conclusion": "Reader-sensitive evaluation frameworks are needed for fair AI-generated text assessment."}}
{"id": "2506.03179", "pdf": "https://arxiv.org/pdf/2506.03179", "abs": "https://arxiv.org/abs/2506.03179", "authors": ["Qi Li", "Runpeng Yu", "Xinchao Wang"], "title": "Vid-SME: Membership Inference Attacks against Large Video Understanding Models", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Multimodal large language models (MLLMs) demonstrate remarkable capabilities\nin handling complex multimodal tasks and are increasingly adopted in video\nunderstanding applications. However, their rapid advancement raises serious\ndata privacy concerns, particularly given the potential inclusion of sensitive\nvideo content, such as personal recordings and surveillance footage, in their\ntraining datasets. Determining improperly used videos during training remains a\ncritical and unresolved challenge. Despite considerable progress on membership\ninference attacks (MIAs) for text and image data in MLLMs, existing methods\nfail to generalize effectively to the video domain. These methods suffer from\npoor scalability as more frames are sampled and generally achieve negligible\ntrue positive rates at low false positive rates (TPR@Low FPR), mainly due to\ntheir failure to capture the inherent temporal variations of video frames and\nto account for model behavior differences as the number of frames varies. To\naddress these challenges, we introduce Vid-SME, the first membership inference\nmethod tailored for video data used in video understanding LLMs (VULLMs).\nVid-SME leverages the confidence of model output and integrates adaptive\nparameterization to compute Sharma-Mittal entropy (SME) for video inputs. By\nleveraging the SME difference between natural and temporally-reversed video\nframes, Vid-SME derives robust membership scores to determine whether a given\nvideo is part of the model's training set. Experiments on various self-trained\nand open-sourced VULLMs demonstrate the strong effectiveness of Vid-SME.", "AI": {"tldr": "Vid-SME is a new method for detecting improperly used videos in training datasets of multimodal large language models (MLLMs), addressing privacy concerns by leveraging Sharma-Mittal entropy (SME) and temporal variations in video frames.", "motivation": "The rapid advancement of MLLMs in video understanding raises data privacy concerns, especially with sensitive video content in training datasets. Existing methods for membership inference attacks (MIAs) fail in the video domain.", "method": "Vid-SME uses model output confidence and adaptive parameterization to compute SME for video inputs, comparing natural and reversed frames to derive membership scores.", "result": "Experiments show Vid-SME is highly effective in detecting training set membership for various video understanding LLMs.", "conclusion": "Vid-SME successfully addresses the challenge of detecting improperly used videos in MLLM training, offering a scalable and robust solution."}}
{"id": "2506.03586", "pdf": "https://arxiv.org/pdf/2506.03586", "abs": "https://arxiv.org/abs/2506.03586", "authors": ["Yu Ma", "Chongtao Guo", "Le Liang", "Xiao Li", "Shi Jin"], "title": "Joint Beamforming and Resource Allocation for Delay Optimization in RIS-Assisted OFDM Systems: A DRL Approach", "categories": ["cs.AI", "cs.IT", "math.IT"], "comment": null, "summary": "This paper investigates a joint phase design and resource allocation problem\nin downlink reconfigurable intelligent surface (RIS)-assisted orthogonal\nfrequency division multiplexing (OFDM) systems to optimize average delay, where\ndata packets for each user arrive at the base station stochastically. The\nsequential optimization problem is inherently a Markov decision process (MDP),\nmaking it fall within the scope of reinforcement learning. To effectively\nhandle the mixed action space and reduce the state space dimensionality, a\nhybrid deep reinforcement learning (DRL) approach is proposed. Specifically,\nproximal policy optimization (PPO)-$\\Theta$ is employed to optimize RIS phase\nshift design, while PPO-N is responsible for subcarrier allocation decisions.\nTo further mitigate the curse of dimensionality associated with subcarrier\nallocation, a multi-agent strategy is introduced to optimize subcarrier\nallocation indicater more efficiently. Moreover, to achieve more adaptive\nresource allocation and accurately capture network dynamics, key factors\nclosely related to average delay, including the number of backlogged packets in\nbuffers and the current packet arrivals, are incorporated into the state space.\nFurthermore, a transfer learning framework is introduced to enhance training\nefficiency and accelerate convergence. Simulation results demonstrate that the\nproposed algorithm significantly reduces average delay, enhances resource\nallocation efficiency, and achieves superior system robustness and fairness\ncompared to baseline methods.", "AI": {"tldr": "A hybrid DRL approach optimizes RIS phase shifts and subcarrier allocation in OFDM systems to reduce average delay, leveraging PPO algorithms and multi-agent strategies for efficiency.", "motivation": "To address the stochastic packet arrivals and optimize delay in RIS-assisted OFDM systems, which is modeled as an MDP.", "method": "Uses hybrid DRL (PPO-\u0398 for RIS phase shifts, PPO-N for subcarrier allocation) with multi-agent strategies and transfer learning.", "result": "Significantly reduces average delay, improves resource allocation efficiency, and enhances system robustness and fairness.", "conclusion": "The proposed method outperforms baselines, demonstrating effectiveness in handling complex network dynamics."}}
{"id": "2506.03164", "pdf": "https://arxiv.org/pdf/2506.03164", "abs": "https://arxiv.org/abs/2506.03164", "authors": ["Vignav Ramesh", "Morteza Mardani"], "title": "Test-Time Scaling of Diffusion Models via Noise Trajectory Search", "categories": ["cs.LG"], "comment": null, "summary": "The iterative and stochastic nature of diffusion models enables test-time\nscaling, whereby spending additional compute during denoising generates\nhigher-fidelity samples. Increasing the number of denoising steps is the\nprimary scaling axis, but this yields quickly diminishing returns. Instead\noptimizing the noise trajectory--the sequence of injected noise vectors--is\npromising, as the specific noise realizations critically affect sample quality;\nbut this is challenging due to a high-dimensional search space, complex\nnoise-outcome interactions, and costly trajectory evaluations. We address this\nby first casting diffusion as a Markov Decision Process (MDP) with a terminal\nreward, showing tree-search methods such as Monte Carlo tree search (MCTS) to\nbe meaningful but impractical. To balance performance and efficiency, we then\nresort to a relaxation of MDP, where we view denoising as a sequence of\nindependent contextual bandits. This allows us to introduce an\n$\\epsilon$-greedy search algorithm that globally explores at extreme timesteps\nand locally exploits during the intermediate steps where de-mixing occurs.\nExperiments on EDM and Stable Diffusion reveal state-of-the-art scores for\nclass-conditioned/text-to-image generation, exceeding baselines by up to\n$164\\%$ and matching/exceeding MCTS performance. To our knowledge, this is the\nfirst practical method for test-time noise trajectory optimization of arbitrary\n(non-differentiable) rewards.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2503.02077", "pdf": "https://arxiv.org/pdf/2503.02077", "abs": "https://arxiv.org/abs/2503.02077", "authors": ["Ziyan Wang", "Zhicheng Zhang", "Fei Fang", "Yali Du"], "title": "M3HF: Multi-agent Reinforcement Learning from Multi-phase Human Feedback of Mixed Quality", "categories": ["cs.MA", "cs.AI", "cs.LG"], "comment": "Accepted to ICML 2025", "summary": "Designing effective reward functions in multi-agent reinforcement learning\n(MARL) is a significant challenge, often leading to suboptimal or misaligned\nbehaviors in complex, coordinated environments. We introduce Multi-agent\nReinforcement Learning from Multi-phase Human Feedback of Mixed Quality\n($\\text{M}^3\\text{HF}$), a novel framework that integrates multi-phase human\nfeedback of mixed quality into the MARL training process. By involving humans\nwith diverse expertise levels to provide iterative guidance,\n$\\text{M}^3\\text{HF}$ leverages both expert and non-expert feedback to\ncontinuously refine agents' policies. During training, we strategically pause\nagent learning for human evaluation, parse feedback using large language models\nto assign it appropriately and update reward functions through predefined\ntemplates and adaptive weights by using weight decay and performance-based\nadjustments. Our approach enables the integration of nuanced human insights\nacross various levels of quality, enhancing the interpretability and robustness\nof multi-agent cooperation. Empirical results in challenging environments\ndemonstrate that $\\text{M}^3\\text{HF}$ significantly outperforms\nstate-of-the-art methods, effectively addressing the complexities of reward\ndesign in MARL and enabling broader human participation in the training\nprocess.", "AI": {"tldr": "The paper introduces $\text{M}^3\text{HF}$, a framework for MARL that integrates multi-phase human feedback of mixed quality to refine agent policies, outperforming state-of-the-art methods.", "motivation": "Designing effective reward functions in MARL is challenging and often leads to suboptimal behaviors. The paper aims to address this by leveraging diverse human feedback.", "method": "The framework involves iterative human feedback, pauses learning for evaluation, parses feedback using LLMs, and updates reward functions with adaptive weights and predefined templates.", "result": "Empirical results show $\text{M}^3\text{HF}$ outperforms existing methods, improving interpretability and robustness in multi-agent cooperation.", "conclusion": "$\text{M}^3\text{HF}$ effectively addresses reward design complexities in MARL and enables broader human participation in training."}}
{"id": "2506.04037", "pdf": "https://arxiv.org/pdf/2506.04037", "abs": "https://arxiv.org/abs/2506.04037", "authors": ["Dan Oneata", "Leanne Nortje", "Yevgen Matusevych", "Herman Kamper"], "title": "The mutual exclusivity bias of bilingual visually grounded speech models", "categories": ["cs.CL", "eess.AS"], "comment": "Interspeech 2025", "summary": "Mutual exclusivity (ME) is a strategy where a novel word is associated with a\nnovel object rather than a familiar one, facilitating language learning in\nchildren. Recent work has found an ME bias in a visually grounded speech (VGS)\nmodel trained on English speech with paired images. But ME has also been\nstudied in bilingual children, who may employ it less due to cross-lingual\nambiguity. We explore this pattern computationally using bilingual VGS models\ntrained on combinations of English, French, and Dutch. We find that bilingual\nmodels generally exhibit a weaker ME bias than monolingual models, though\nexceptions exist. Analyses show that the combined visual embeddings of\nbilingual models have a smaller variance for familiar data, partly explaining\nthe increase in confusion between novel and familiar concepts. We also provide\nnew insights into why the ME bias exists in VGS models in the first place. Code\nand data: https://github.com/danoneata/me-vgs", "AI": {"tldr": "Bilingual visually grounded speech (VGS) models show a weaker mutual exclusivity (ME) bias compared to monolingual models, with visual embeddings explaining the reduced bias.", "motivation": "To investigate how bilingualism affects the ME bias in VGS models, given that bilingual children may use ME less due to cross-lingual ambiguity.", "method": "Training bilingual VGS models on combinations of English, French, and Dutch, then analyzing their ME bias and visual embeddings.", "result": "Bilingual models exhibit a weaker ME bias than monolingual ones, with combined visual embeddings showing smaller variance for familiar data.", "conclusion": "The study provides insights into the ME bias in VGS models and explains the reduced bias in bilingual settings through visual embedding analysis."}}
{"id": "2506.03181", "pdf": "https://arxiv.org/pdf/2506.03181", "abs": "https://arxiv.org/abs/2506.03181", "authors": ["Wangting Zhou", "Jiangshan He", "Tong Cai", "Lin Wang", "Zhen Yuan", "Xunbin Wei", "Xueli Chen"], "title": "Dc-EEMF: Pushing depth-of-field limit of photoacoustic microscopy via decision-level constrained learning", "categories": ["eess.IV", "cs.CV"], "comment": null, "summary": "Photoacoustic microscopy holds the potential to measure biomarkers'\nstructural and functional status without labels, which significantly aids in\ncomprehending pathophysiological conditions in biomedical research. However,\nconventional optical-resolution photoacoustic microscopy (OR-PAM) is hindered\nby a limited depth-of-field (DoF) due to the narrow depth range focused on a\nGaussian beam. Consequently, it fails to resolve sufficient details in the\ndepth direction. Herein, we propose a decision-level constrained end-to-end\nmulti-focus image fusion (Dc-EEMF) to push DoF limit of PAM. The DC-EEMF method\nis a lightweight siamese network that incorporates an artifact-resistant\nchannel-wise spatial frequency as its feature fusion rule. The meticulously\ncrafted U-Net-based perceptual loss function for decision-level focus\nproperties in end-to-end fusion seamlessly integrates the complementary\nadvantages of spatial domain and transform domain methods within Dc-EEMF. This\napproach can be trained end-to-end without necessitating post-processing\nprocedures. Experimental results and numerical analyses collectively\ndemonstrate our method's robust performance, achieving an impressive fusion\nresult for PAM images without a substantial sacrifice in lateral resolution.\nThe utilization of Dc-EEMF-powered PAM has the potential to serve as a\npractical tool in preclinical and clinical studies requiring extended DoF for\nvarious applications.", "AI": {"tldr": "A lightweight siamese network (Dc-EEMF) is proposed to extend the depth-of-field (DoF) in photoacoustic microscopy (PAM), improving image fusion without sacrificing lateral resolution.", "motivation": "Conventional OR-PAM has a limited DoF due to Gaussian beam constraints, hindering detailed depth resolution.", "method": "Dc-EEMF uses a siamese network with artifact-resistant channel-wise spatial frequency for feature fusion and a U-Net-based perceptual loss function for decision-level focus properties.", "result": "The method achieves robust fusion results for PAM images, maintaining lateral resolution.", "conclusion": "Dc-EEMF-powered PAM is promising for preclinical and clinical studies requiring extended DoF."}}
{"id": "2506.04076", "pdf": "https://arxiv.org/pdf/2506.04076", "abs": "https://arxiv.org/abs/2506.04076", "authors": ["Jhen-Ke Lin", "Hao-Chien Lu", "Chung-Chun Wang", "Hong-Yun Lin", "Berlin Chen"], "title": "Acoustically Precise Hesitation Tagging Is Essential for End-to-End Verbatim Transcription Systems", "categories": ["cs.CL", "cs.SD", "eess.AS"], "comment": "submitted to the ISCA SLaTE-2025 Workshop", "summary": "Verbatim transcription for automatic speaking assessment demands accurate\ncapture of disfluencies, crucial for downstream tasks like error analysis and\nfeedback. However, many ASR systems discard or generalize hesitations, losing\nimportant acoustic details. We fine-tune Whisper models on the Speak & Improve\n2025 corpus using low-rank adaptation (LoRA), without recourse to external\naudio training data. We compare three annotation schemes: removing hesitations\n(Pure), generic tags (Rich), and acoustically precise fillers inferred by\nGemini 2.0 Flash from existing audio-transcript pairs (Extra). Our challenge\nsystem achieved 6.47% WER (Pure) and 5.81% WER (Extra). Post-challenge\nexperiments reveal that fine-tuning Whisper Large V3 Turbo with the \"Extra\"\nscheme yielded a 5.5% WER, an 11.3% relative improvement over the \"Pure\" scheme\n(6.2% WER). This demonstrates that explicit, realistic filled-pause labeling\nsignificantly enhances ASR accuracy for verbatim L2 speech transcription.", "AI": {"tldr": "Fine-tuning Whisper models with precise disfluency labeling improves ASR accuracy for verbatim L2 speech transcription.", "motivation": "Accurate capture of disfluencies is crucial for automatic speaking assessment, but many ASR systems discard or generalize hesitations, losing important details.", "method": "Fine-tuned Whisper models on the Speak & Improve 2025 corpus using LoRA, comparing three annotation schemes: Pure (removing hesitations), Rich (generic tags), and Extra (acoustically precise fillers).", "result": "The \"Extra\" scheme achieved 5.5% WER, an 11.3% relative improvement over the \"Pure\" scheme (6.2% WER).", "conclusion": "Explicit, realistic filled-pause labeling significantly enhances ASR accuracy for verbatim L2 speech transcription."}}
{"id": "2506.03312", "pdf": "https://arxiv.org/pdf/2506.03312", "abs": "https://arxiv.org/abs/2506.03312", "authors": ["Celia Chen", "Scotty Beland", "Ingo Burghardt", "Jill Byczek", "William J. Conway", "Eric Cotugno", "Sadaf Davre", "Megan Fletcher", "Rajesh Kumar Gnanasekaran", "Kristin Hamilton", "Marilyn Harbert", "Jordan Heustis", "Tanaya Jha", "Emily Klein", "Hayden Kramer", "Alex Leitch", "Jessica Perkins", "Casi Sherman", "Celia Sterrn", "Logan Stevens", "Rebecca Zarrella", "Jennifer Golbeck"], "title": "Cross-Platform Violence Detection on Social Media: A Dataset and Analysis", "categories": ["cs.CL", "cs.LG"], "comment": "In Proceedings of the 17th ACM Web Science Conference (WebSci '25). 9\n  pages", "summary": "Violent threats remain a significant problem across social media platforms.\nUseful, high-quality data facilitates research into the understanding and\ndetection of malicious content, including violence. In this paper, we introduce\na cross-platform dataset of 30,000 posts hand-coded for violent threats and\nsub-types of violence, including political and sexual violence. To evaluate the\nsignal present in this dataset, we perform a machine learning analysis with an\nexisting dataset of violent comments from YouTube. We find that, despite\noriginating from different platforms and using different coding criteria, we\nachieve high classification accuracy both by training on one dataset and\ntesting on the other, and in a merged dataset condition. These results have\nimplications for content-classification strategies and for understanding\nviolent content across social media.", "AI": {"tldr": "A cross-platform dataset of 30,000 posts hand-coded for violent threats is introduced, achieving high classification accuracy in machine learning analysis across platforms.", "motivation": "Violent threats on social media are a significant issue, and high-quality data is needed for research and detection.", "method": "A hand-coded dataset of violent posts is created and evaluated using machine learning with an existing YouTube dataset.", "result": "High classification accuracy is achieved across different platforms and coding criteria.", "conclusion": "The findings support cross-platform content-classification strategies and better understanding of violent content."}}
{"id": "2506.03182", "pdf": "https://arxiv.org/pdf/2506.03182", "abs": "https://arxiv.org/abs/2506.03182", "authors": ["Shivani Chiranjeevi", "Hossein Zaremehrjerdi", "Zi K. Deng", "Talukder Z. Jubery", "Ari Grele", "Arti Singh", "Asheesh K Singh", "Soumik Sarkar", "Nirav Merchant", "Harold F. Greeney", "Baskar Ganapathysubramanian", "Chinmay Hegde"], "title": "TerraIncognita: A Dynamic Benchmark for Species Discovery Using Frontier Models", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "The rapid global loss of biodiversity, particularly among insects, represents\nan urgent ecological crisis. Current methods for insect species discovery are\nmanual, slow, and severely constrained by taxonomic expertise, hindering timely\nconservation actions. We introduce TerraIncognita, a dynamic benchmark designed\nto evaluate state-of-the-art multimodal models for the challenging problem of\nidentifying unknown, potentially undescribed insect species from image data.\nOur benchmark dataset combines a mix of expertly annotated images of insect\nspecies likely known to frontier AI models, and images of rare and poorly known\nspecies, for which few/no publicly available images exist. These images were\ncollected from underexplored biodiversity hotspots, realistically mimicking\nopen-world discovery scenarios faced by ecologists. The benchmark assesses\nmodels' proficiency in hierarchical taxonomic classification, their capability\nto detect and abstain from out-of-distribution (OOD) samples representing novel\nspecies, and their ability to generate explanations aligned with expert\ntaxonomic knowledge. Notably, top-performing models achieve over 90\\% F1 at the\nOrder level on known species, but drop below 2\\% at the Species level,\nhighlighting the sharp difficulty gradient from coarse to fine taxonomic\nprediction (Order $\\rightarrow$ Family $\\rightarrow$ Genus $\\rightarrow$\nSpecies). TerraIncognita will be updated regularly, and by committing to\nquarterly dataset expansions (of both known and novel species), will provide an\nevolving platform for longitudinal benchmarking of frontier AI methods. All\nTerraIncognita data, results, and future updates are available\n\\href{https://baskargroup.github.io/TerraIncognita/}{here}.", "AI": {"tldr": "TerraIncognita is a benchmark for evaluating AI models in identifying unknown insect species from images, combining known and rare species data to test hierarchical classification and OOD detection.", "motivation": "Address the urgent biodiversity crisis by improving slow, manual insect species discovery methods with AI-driven solutions.", "method": "Introduces TerraIncognita, a dynamic benchmark with expertly annotated images of known and rare insect species, assessing models' hierarchical classification, OOD detection, and explanation generation.", "result": "Top models achieve >90% F1 at Order level but drop to <2% at Species level, showing the challenge of fine taxonomic prediction.", "conclusion": "TerraIncognita provides an evolving platform for AI benchmarking in biodiversity, with regular updates to include new species data."}}
{"id": "2506.03610", "pdf": "https://arxiv.org/pdf/2506.03610", "abs": "https://arxiv.org/abs/2506.03610", "authors": ["Dongmin Park", "Minkyu Kim", "Beongjun Choi", "Junhyuck Kim", "Keon Lee", "Jonghyun Lee", "Inkyu Park", "Byeong-Uk Lee", "Jaeyoung Hwang", "Jaewoo Ahn", "Ameya S. Mahabaleshwarkar", "Bilal Kartal", "Pritam Biswas", "Yoshi Suhara", "Kangwook Lee", "Jaewoong Cho"], "title": "Orak: A Foundational Benchmark for Training and Evaluating LLM Agents on Diverse Video Games", "categories": ["cs.AI"], "comment": null, "summary": "Large Language Model (LLM) agents are reshaping the game industry,\nparticularly with more intelligent and human-preferable game characters.\nHowever, existing game benchmarks fall short of practical needs: they lack\nevaluations of diverse LLM capabilities across various game genres, studies of\nagentic modules crucial for complex gameplay, and fine-tuning datasets for\naligning pre-trained LLMs into gaming agents. To fill these gaps, we present\n\\textbf{\\benchname{}}, a foundational benchmark designed to train and evaluate\nLLM agents across diverse real-world video games. Unlike existing benchmarks,\nOrak includes 12 popular video games spanning all major genres, enabling\ncomprehensive studies of LLM capabilities and agentic modules essential for\nintricate game scenarios. To support consistent evaluation of LLMs, we\nintroduce a plug-and-play interface based on Model Context Protocol (MCP) that\nenables LLMs to seamlessly connect with games and manipulate agentic modules.\nAdditionally, we propose a fine-tuning dataset, consisting of LLM gameplay\ntrajectories across diverse game genres. Orak offers a comprehensive evaluation\nframework, encompassing general game score leaderboards, LLM battle arenas, and\nin-depth analyses of visual input state, agentic strategies, and fine-tuning\neffects, establishing a foundation towards building generic gaming agents. Code\nis available at https://github.com/krafton-ai/Orak.", "AI": {"tldr": "Orak is a new benchmark for training and evaluating LLM agents across diverse video games, addressing gaps in existing benchmarks by covering multiple genres, agentic modules, and fine-tuning datasets.", "motivation": "Existing game benchmarks lack evaluations of diverse LLM capabilities, agentic modules for complex gameplay, and fine-tuning datasets for aligning LLMs into gaming agents.", "method": "Orak includes 12 popular video games across major genres, a plug-and-play interface (MCP), and a fine-tuning dataset of LLM gameplay trajectories.", "result": "Orak provides a comprehensive evaluation framework with game score leaderboards, LLM battle arenas, and analyses of visual input, strategies, and fine-tuning effects.", "conclusion": "Orak establishes a foundation for developing generic gaming agents by addressing practical needs in LLM agent evaluation and training."}}
{"id": "2506.03176", "pdf": "https://arxiv.org/pdf/2506.03176", "abs": "https://arxiv.org/abs/2506.03176", "authors": ["Bin Wang", "Yongqi Han", "Minbo Ma", "Tianrui Li", "Junbo Zhang", "Feng Hong", "Yanwei Yu"], "title": "Non-collective Calibrating Strategy for Time Series Forecasting", "categories": ["cs.LG"], "comment": "Accepted by IJCAI 2025", "summary": "Deep learning-based approaches have demonstrated significant advancements in\ntime series forecasting. Despite these ongoing developments, the complex\ndynamics of time series make it challenging to establish the rule of thumb for\ndesigning the golden model architecture. In this study, we argue that refining\nexisting advanced models through a universal calibrating strategy can deliver\nsubstantial benefits with minimal resource costs, as opposed to elaborating and\ntraining a new model from scratch. We first identify a multi-target learning\nconflict in the calibrating process, which arises when optimizing variables\nacross time steps, leading to the underutilization of the model's learning\ncapabilities. To address this issue, we propose an innovative calibrating\nstrategy called Socket+Plug (SoP). This approach retains an exclusive optimizer\nand early-stopping monitor for each predicted target within each Plug while\nkeeping the fully trained Socket backbone frozen. The model-agnostic nature of\nSoP allows it to directly calibrate the performance of any trained deep\nforecasting models, regardless of their specific architectures. Extensive\nexperiments on various time series benchmarks and a spatio-temporal\nmeteorological ERA5 dataset demonstrate the effectiveness of SoP, achieving up\nto a 22% improvement even when employing a simple MLP as the Plug (highlighted\nin Figure 1)", "AI": {"tldr": "The paper proposes Socket+Plug (SoP), a universal calibrating strategy for refining existing deep learning models in time series forecasting, addressing multi-target learning conflicts and improving performance by up to 22%.", "motivation": "Existing deep learning models for time series forecasting face challenges in optimizing across time steps, leading to underutilized learning capabilities. Refining models is more efficient than building new ones.", "method": "Introduces SoP, which uses separate optimizers and early-stopping monitors for each target (Plug) while keeping the trained backbone (Socket) frozen, making it model-agnostic.", "result": "SoP achieves up to 22% improvement on benchmarks and a spatio-temporal dataset, even with a simple MLP as the Plug.", "conclusion": "SoP offers a resource-efficient way to enhance existing models, demonstrating significant performance gains without requiring new architectures."}}
{"id": "2404.19564", "pdf": "https://arxiv.org/pdf/2404.19564", "abs": "https://arxiv.org/abs/2404.19564", "authors": ["Michael Amir", "Alfred M. Bruckstein"], "title": "Time, Travel, and Energy in the Uniform Dispersion Problem", "categories": ["cs.RO", "cs.DM", "cs.MA", "68T40", "I.2.9"], "comment": "Accepted to IEEE T-RO. Includes and expands results from \"Minimizing\n  Travel in the Uniform Dispersal Problem for Robotic Sensors\" (AAMAS 2019,\n  arXiv:1903.03259)", "summary": "We investigate the algorithmic problem of uniformly dispersing a swarm of\nrobots in an unknown, gridlike environment. In this setting, our goal is to\nstudy the relationships between performance metrics and robot capabilities. We\nintroduce a formal model comparing dispersion algorithms based on makespan,\ntraveled distance, energy consumption, sensing, communication, and memory.\nUsing this framework, we classify uniform dispersion algorithms according to\ntheir capability requirements and performance. We prove that while makespan and\ntravel can be minimized in all environments, energy cannot, if the swarm's\nsensing range is bounded. In contrast, we show that energy can be minimized by\n``ant-like'' robots in synchronous settings and asymptotically minimized in\nasynchronous settings, provided the environment is topologically simply\nconnected, by using our ``Find-Corner Depth-First Search'' (FCDFS) algorithm.\nOur theoretical and experimental results show that FCDFS significantly\noutperforms known algorithms. Our findings reveal key limitations in designing\nswarm robotics systems for unknown environments, emphasizing the role of\ntopology in energy-efficient dispersion.", "AI": {"tldr": "The paper studies uniform dispersion of robot swarms in unknown gridlike environments, analyzing performance metrics and robot capabilities. It introduces a model to compare algorithms and proves trade-offs in minimizing makespan, travel, and energy. A new algorithm, FCDFS, outperforms others in energy efficiency under specific conditions.", "motivation": "To understand the trade-offs between performance metrics (makespan, travel, energy) and robot capabilities (sensing, communication, memory) in swarm robotics for unknown environments.", "method": "Introduces a formal model to classify dispersion algorithms and proposes the FCDFS algorithm for energy-efficient dispersion in simply connected environments. Theoretical and experimental analyses are conducted.", "result": "FCDFS outperforms existing algorithms in energy efficiency for simply connected environments. Trade-offs are proven: makespan and travel can always be minimized, but energy cannot with bounded sensing.", "conclusion": "The study highlights the importance of topology in energy-efficient swarm dispersion and reveals key limitations in designing systems for unknown environments."}}
{"id": "2506.04077", "pdf": "https://arxiv.org/pdf/2506.04077", "abs": "https://arxiv.org/abs/2506.04077", "authors": ["Chung-Chun Wang", "Jhen-Ke Lin", "Hao-Chien Lu", "Hong-Yun Lin", "Berlin Chen"], "title": "A Novel Data Augmentation Approach for Automatic Speaking Assessment on Opinion Expressions", "categories": ["cs.CL", "cs.SD", "eess.AS"], "comment": "submitted to the ISCA SLaTE-2025 Workshop", "summary": "Automated speaking assessment (ASA) on opinion expressions is often hampered\nby the scarcity of labeled recordings, which restricts prompt diversity and\nundermines scoring reliability. To address this challenge, we propose a novel\ntraining paradigm that leverages a large language models (LLM) to generate\ndiverse responses of a given proficiency level, converts responses into\nsynthesized speech via speaker-aware text-to-speech synthesis, and employs a\ndynamic importance loss to adaptively reweight training instances based on\nfeature distribution differences between synthesized and real speech.\nSubsequently, a multimodal large language model integrates aligned textual\nfeatures with speech signals to predict proficiency scores directly.\nExperiments conducted on the LTTC dataset show that our approach outperforms\nmethods relying on real data or conventional augmentation, effectively\nmitigating low-resource constraints and enabling ASA on opinion expressions\nwith cross-modal information.", "AI": {"tldr": "A novel training paradigm using LLMs and synthesized speech improves automated speaking assessment (ASA) for opinion expressions by addressing data scarcity.", "motivation": "The scarcity of labeled recordings limits prompt diversity and scoring reliability in ASA for opinion expressions.", "method": "Leverages LLMs to generate diverse responses, converts them to synthesized speech, and uses dynamic importance loss for training. A multimodal LLM integrates text and speech features for scoring.", "result": "Outperforms methods using real data or conventional augmentation on the LTTC dataset.", "conclusion": "The approach mitigates low-resource constraints and enables ASA on opinion expressions with cross-modal information."}}
{"id": "2506.03183", "pdf": "https://arxiv.org/pdf/2506.03183", "abs": "https://arxiv.org/abs/2506.03183", "authors": ["Ya\u015far Utku Al\u00e7alar", "Yu Cao", "Mehmet Ak\u00e7akaya"], "title": "Edge Computing for Physics-Driven AI in Computational MRI: A Feasibility Study", "categories": ["eess.IV", "cs.AI", "cs.AR", "cs.CV", "cs.LG", "physics.med-ph"], "comment": "IEEE International Conference on Future Internet of Things and Cloud\n  (FiCloud), 2025", "summary": "Physics-driven artificial intelligence (PD-AI) reconstruction methods have\nemerged as the state-of-the-art for accelerating MRI scans, enabling higher\nspatial and temporal resolutions. However, the high resolution of these scans\ngenerates massive data volumes, leading to challenges in transmission, storage,\nand real-time processing. This is particularly pronounced in functional MRI,\nwhere hundreds of volumetric acquisitions further exacerbate these demands.\nEdge computing with FPGAs presents a promising solution for enabling PD-AI\nreconstruction near the MRI sensors, reducing data transfer and storage\nbottlenecks. However, this requires optimization of PD-AI models for hardware\nefficiency through quantization and bypassing traditional FFT-based approaches,\nwhich can be a limitation due to their computational demands. In this work, we\npropose a novel PD-AI computational MRI approach optimized for FPGA-based edge\ncomputing devices, leveraging 8-bit complex data quantization and eliminating\nredundant FFT/IFFT operations. Our results show that this strategy improves\ncomputational efficiency while maintaining reconstruction quality comparable to\nconventional PD-AI methods, and outperforms standard clinical methods. Our\napproach presents an opportunity for high-resolution MRI reconstruction on\nresource-constrained devices, highlighting its potential for real-world\ndeployment.", "AI": {"tldr": "A novel PD-AI MRI reconstruction method optimized for FPGA-based edge computing, using 8-bit quantization and eliminating redundant FFT/IFFT operations, improves efficiency without compromising quality.", "motivation": "High-resolution MRI scans generate massive data, causing transmission, storage, and processing challenges, especially in functional MRI. Edge computing with FPGAs offers a solution but requires hardware-efficient PD-AI models.", "method": "Proposes a PD-AI approach optimized for FPGAs, using 8-bit complex data quantization and removing redundant FFT/IFFT operations.", "result": "The method enhances computational efficiency while maintaining reconstruction quality, outperforming standard clinical methods.", "conclusion": "The approach enables high-resolution MRI reconstruction on resource-constrained devices, showing promise for real-world deployment."}}
{"id": "2506.04134", "pdf": "https://arxiv.org/pdf/2506.04134", "abs": "https://arxiv.org/abs/2506.04134", "authors": ["Jinting Wang", "Shan Yang", "Li Liu"], "title": "UniCUE: Unified Recognition and Generation Framework for Chinese Cued Speech Video-to-Speech Generation", "categories": ["cs.CV", "cs.SD", "eess.AS"], "comment": "10 pages, 10 figures", "summary": "Cued Speech (CS) enhances lipreading through hand coding, providing precise\nspeech perception support for the hearing-impaired. CS Video-to-Speech\ngeneration (CSV2S) task aims to convert the CS visual expressions (CS videos)\nof hearing-impaired individuals into comprehensible speech signals. Direct\ngeneration of speech from CS video (called single CSV2S) yields poor\nperformance due to insufficient CS data. Current research mostly focuses on CS\nRecognition (CSR), which convert video content into linguistic text. Based on\nthis, one straightforward way of CSV2S is to combine CSR with a Text-to-Speech\nsystem. This combined architecture relies on text as an intermediate medium for\nstepwise cross-modal alignment, which may lead to error propagation and\ntemporal misalignment between speech and video dynamics. To address these\nchallenges, we propose a novel approach that directly generates speech from CS\nvideos without relying on intermediate text. Building upon this, we propose\nUniCUE, the first unified framework for CSV2S, whose core innovation lies in\nthe integration of the CSR task that provides fine-grained visual-semantic\ninformation to facilitate speech generation from CS videos. More precisely, (1)\na novel fine-grained semantic alignment pool to ensure precise mapping between\nvisual features and speech contents; (2) a VisioPhonetic adapter to bridge\ncross-task representations, ensuring seamless compatibility between two\ndistinct tasks (i.e., CSV2S and CSR); (3) a pose-aware visual processor is\nintroduced to enhance fine-grained spatiotemporal correlations between lip and\nhand movements in CS video. Experiments on our new established Chinese CS\ndataset (14 cuers1: 8 hearing-impaired and 6 normal-hearing) show that our\nUniCUE significantly reduces Word Error Rate by 78.3% and improves lip-speech\nsynchronization by 32% compared to the single CSV2S.", "AI": {"tldr": "UniCUE is a unified framework for CSV2S that directly generates speech from CS videos, avoiding intermediate text, and improves performance significantly.", "motivation": "Current CSV2S methods rely on intermediate text, leading to error propagation and misalignment. UniCUE aims to address these issues by directly mapping CS videos to speech.", "method": "UniCUE integrates CSR for fine-grained visual-semantic alignment, uses a semantic alignment pool, a VisioPhonetic adapter, and a pose-aware visual processor.", "result": "UniCUE reduces Word Error Rate by 78.3% and improves lip-speech synchronization by 32% compared to single CSV2S.", "conclusion": "UniCUE effectively bridges the gap between CS videos and speech, outperforming existing methods."}}
{"id": "2506.03357", "pdf": "https://arxiv.org/pdf/2506.03357", "abs": "https://arxiv.org/abs/2506.03357", "authors": ["Aldan Creo", "H\u00e9ctor Cerezo-Costas", "Pedro Alonso-Doval", "Maximiliano Hormaz\u00e1bal-Lagos"], "title": "Ask a Local: Detecting Hallucinations With Specialized Model Divergence", "categories": ["cs.CL", "cs.AI"], "comment": "Supplementary materials: https://github.com/ACMCMC/ask-a-local", "summary": "Hallucinations in large language models (LLMs) - instances where models\ngenerate plausible but factually incorrect information - present a significant\nchallenge for AI.\n  We introduce \"Ask a Local\", a novel hallucination detection method exploiting\nthe intuition that specialized models exhibit greater surprise when\nencountering domain-specific inaccuracies. Our approach computes divergence\nbetween perplexity distributions of language-specialized models to identify\npotentially hallucinated spans. Our method is particularly well-suited for a\nmultilingual context, as it naturally scales to multiple languages without the\nneed for adaptation, relying on external data sources, or performing training.\nMoreover, we select computationally efficient models, providing a scalable\nsolution that can be applied to a wide range of languages and domains.\n  Our results on a human-annotated question-answer dataset spanning 14\nlanguages demonstrate consistent performance across languages, with\nIntersection-over-Union (IoU) scores around 0.3 and comparable Spearman\ncorrelation values. Our model shows particularly strong performance on Italian\nand Catalan, with IoU scores of 0.42 and 0.38, respectively, while maintaining\ncross-lingual effectiveness without language-specific adaptations. We release\nour code and architecture to facilitate further research in multilingual\nhallucination detection.", "AI": {"tldr": "The paper introduces 'Ask a Local,' a method for detecting hallucinations in LLMs by leveraging specialized models' surprise at domain-specific inaccuracies, showing consistent multilingual performance without language-specific adaptations.", "motivation": "Addressing the challenge of hallucinations in LLMs, where models generate plausible but incorrect information, by proposing a scalable, multilingual detection method.", "method": "The approach computes divergence between perplexity distributions of language-specialized models to identify hallucinated spans, avoiding the need for external data or training.", "result": "Demonstrated consistent performance across 14 languages, with IoU scores around 0.3 and strong results for Italian (0.42) and Catalan (0.38).", "conclusion": "The method is scalable, effective across languages, and released for further research in multilingual hallucination detection."}}
{"id": "2506.03184", "pdf": "https://arxiv.org/pdf/2506.03184", "abs": "https://arxiv.org/abs/2506.03184", "authors": ["Mahe Zabin", "Ho-Jin Choi", "Md. Monirul Islam", "Jia Uddin"], "title": "Impact of Tuning Parameters in Deep Convolutional Neural Network Using a Crack Image Dataset", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": "8 pages, 2 figures, published at Proceedings of the 15th KIPS\n  International Conference on Ubiquitous Information Technologies and\n  Applications (CUTE 2021), Jeju, Repubilc of Korea", "summary": "The performance of a classifier depends on the tuning of its parame ters. In\nthis paper, we have experimented the impact of various tuning parameters on the\nperformance of a deep convolutional neural network (DCNN). In the ex perimental\nevaluation, we have considered a DCNN classifier that consists of 2\nconvolutional layers (CL), 2 pooling layers (PL), 1 dropout, and a dense layer.\nTo observe the impact of pooling, activation function, and optimizer tuning pa\nrameters, we utilized a crack image dataset having two classes: negative and\npos itive. The experimental results demonstrate that with the maxpooling, the\nDCNN demonstrates its better performance for adam optimizer and tanh activation\nfunc tion.", "AI": {"tldr": "The paper explores how tuning parameters (pooling, activation function, optimizer) affect a DCNN's performance, finding maxpooling with Adam optimizer and tanh activation works best.", "motivation": "To understand the impact of parameter tuning on DCNN performance for crack image classification.", "method": "Used a DCNN with 2 convolutional, 2 pooling, 1 dropout, and 1 dense layer, tested on a crack image dataset with maxpooling, Adam optimizer, and tanh activation.", "result": "Maxpooling with Adam optimizer and tanh activation yielded the best performance.", "conclusion": "Optimal DCNN performance for crack classification is achieved with specific parameter tuning."}}
{"id": "2506.03613", "pdf": "https://arxiv.org/pdf/2506.03613", "abs": "https://arxiv.org/abs/2506.03613", "authors": ["Shaoshan Liu", "Fan Wang", "Hongjun Zhou", "Yuanfeng Wang"], "title": "Training Cross-Morphology Embodied AI Agents: From Practical Challenges to Theoretical Foundations", "categories": ["cs.AI", "cs.CC"], "comment": null, "summary": "While theory and practice are often seen as separate domains, this article\nshows that theoretical insight is essential for overcoming real-world\nengineering barriers. We begin with a practical challenge: training a\ncross-morphology embodied AI policy that generalizes across diverse robot\nmorphologies. We formalize this as the Heterogeneous Embodied Agent Training\n(HEAT) problem and prove it reduces to a structured Partially Observable Markov\nDecision Process (POMDP) that is PSPACE-complete. This result explains why\ncurrent reinforcement learning pipelines break down under morphological\ndiversity, due to sequential training constraints, memory-policy coupling, and\ndata incompatibility. We further explore Collective Adaptation, a distributed\nlearning alternative inspired by biological systems. Though NEXP-complete in\ntheory, it offers meaningful scalability and deployment benefits in practice.\nThis work illustrates how computational theory can illuminate system design\ntrade-offs and guide the development of more robust, scalable embodied AI. For\npractitioners and researchers to explore this problem, the implementation code\nof this work has been made publicly available at\nhttps://github.com/airs-admin/HEAT", "AI": {"tldr": "The paper demonstrates the importance of theoretical insights in solving real-world engineering challenges, specifically in training cross-morphology embodied AI policies. It formalizes the problem as a structured POMDP, proves its complexity, and introduces Collective Adaptation as a scalable alternative.", "motivation": "To address the challenge of training AI policies that generalize across diverse robot morphologies, highlighting the gap between theory and practice in reinforcement learning.", "method": "Formalizes the problem as the Heterogeneous Embodied Agent Training (HEAT) problem, proves it reduces to a structured POMDP, and explores Collective Adaptation, a distributed learning approach.", "result": "The HEAT problem is PSPACE-complete, explaining why current methods fail under morphological diversity. Collective Adaptation, though NEXP-complete, offers practical scalability.", "conclusion": "Theoretical insights can guide robust and scalable embodied AI design, bridging theory and practice. Implementation code is publicly available."}}
{"id": "2506.03206", "pdf": "https://arxiv.org/pdf/2506.03206", "abs": "https://arxiv.org/abs/2506.03206", "authors": ["Nadav Timor", "Jonathan Mamou", "Oren Pereg", "Hongyang Zhang", "David Harel"], "title": "Out-of-Vocabulary Sampling Boosts Speculative Decoding", "categories": ["cs.LG", "cs.CL"], "comment": null, "summary": "Speculative decoding relies on fast and accurate drafters. Recent\nstate-of-the-art language models employ larger and larger vocabularies, which\nsignificantly slows down drafters. One promising approach to boost the\nefficiency of speculative decoding is to use drafters with smaller\nvocabularies. However, existing sampling methods cannot draw out-of-vocabulary\ntokens, creating a tradeoff between drafters' vocabulary size and acceptance\nrates. This paper introduces Redistributing Drafter Kernels (RDK), the first\nout-of-vocabulary sampler that effectively recovers acceptance rates by\nvirtually restoring pruned target tokens. RDK leverages token-affinity priors\nto reallocate drafter mass towards high-overlap regions. We prove\nmathematically that RDK can achieve higher acceptance rates than vanilla and\nstate-of-the-art samplers. We provide an efficient first-order approximation of\nRDK and prove that it reduces redistribution times from $O(N^2)$ to $O(N)$,\nenabling lightweight implementations for large vocabularies. Our experiments\ndemonstrate that this linear-time RDK significantly boosts acceptance rates\neven after extreme pruning (removing more than 75% of the drafter's\nvocabulary), where existing samplers fail. RDK opens the door to extremely\npruned drafters, which were previously impractical.", "AI": {"tldr": "RDK introduces an out-of-vocabulary sampler to boost speculative decoding efficiency by virtually restoring pruned tokens, improving acceptance rates even with extreme vocabulary pruning.", "motivation": "Larger vocabularies slow down drafters in speculative decoding, creating a need for efficient methods to maintain performance with smaller vocabularies.", "method": "RDK uses token-affinity priors to reallocate drafter mass, offering a first-order approximation for efficient implementation.", "result": "RDK achieves higher acceptance rates than existing samplers, even with over 75% vocabulary pruning, and reduces redistribution time to linear complexity.", "conclusion": "RDK enables practical use of extremely pruned drafters, overcoming previous limitations in speculative decoding."}}
{"id": "2502.17721", "pdf": "https://arxiv.org/pdf/2502.17721", "abs": "https://arxiv.org/abs/2502.17721", "authors": ["Xiangwen Wang", "Yibo Jacky Zhang", "Zhoujie Ding", "Katherine Tsai", "Haolun Wu", "Sanmi Koyejo"], "title": "Aligning Compound AI Systems via System-level DPO", "categories": ["cs.LG", "cs.AI", "cs.MA"], "comment": "Accepted to workshops MARW and WMAC (Oral) at AAAI25", "summary": "Compound AI systems, comprising multiple interacting components such as LLMs,\nfoundation models, and external tools, have demonstrated remarkable\nimprovements compared to single models in various tasks. To ensure their\neffective deployment in real-world applications, aligning these systems with\nhuman preferences is crucial. However, aligning the compound system via policy\noptimization, unlike the alignment of a single model, is challenging for two\nmain reasons: (i) non-differentiable interactions between components make\nend-to-end gradient-based optimization method inapplicable, and (ii)\nsystem-level preferences cannot be directly transformed into component-level\npreferences. To address these challenges, we first formulate compound AI\nsystems as Directed Acyclic Graphs (DAGs), explicitly modeling both component\ninteractions and the associated data flows. Building on this formulation, we\nintroduce $\\textbf{SysDPO}$, a framework that extends Direct Preference\nOptimization (DPO) to enable joint system-level alignment. We propose two\nvariants, SysDPO-Direct and SysDPO-Sampling, tailored for scenarios depending\non whether we construct a system-specific preference dataset. We empirically\ndemonstrate the effectiveness of our approach across two applications: the\njoint alignment of a language model and a diffusion model, and the joint\nalignment of an LLM collaboration system.", "AI": {"tldr": "The paper introduces SysDPO, a framework for aligning compound AI systems with human preferences by modeling them as DAGs and extending DPO for joint system-level alignment.", "motivation": "Aligning compound AI systems with human preferences is challenging due to non-differentiable interactions and system-level preference transformation issues.", "method": "Formulates compound AI systems as DAGs and introduces SysDPO (with variants SysDPO-Direct and SysDPO-Sampling) for joint alignment.", "result": "Empirically demonstrates effectiveness in aligning language-diffusion models and LLM collaboration systems.", "conclusion": "SysDPO provides a practical solution for aligning complex AI systems with human preferences."}}
{"id": "2402.12208", "pdf": "https://arxiv.org/pdf/2402.12208", "abs": "https://arxiv.org/abs/2402.12208", "authors": ["Shengpeng Ji", "Minghui Fang", "Jialong Zuo", "Ziyue Jiang", "Dingdong Wang", "Hanting Wang", "Hai Huang", "Zhou Zhao"], "title": "Language-Codec: Bridging Discrete Codec Representations and Speech Language Models", "categories": ["eess.AS", "cs.SD"], "comment": "ACL 2025 Main", "summary": "In recent years, large language models have achieved significant success in\ngenerative tasks related to speech, audio, music, and other signal domains. A\ncrucial element of these models is the discrete acoustic codecs, which serve as\nan intermediate representation replacing the mel-spectrogram. However, there\nexist several gaps between discrete codecs and downstream speech language\nmodels. Specifically, 1) Due to the reconstruction paradigm of the Codec model\nand the structure of residual vector quantization, the initial channel of the\ncodebooks contains excessive information, making it challenging to directly\ngenerate acoustic tokens from weakly supervised signals such as text in\ndownstream tasks. 2) numerous codebooks increases the burden on downstream\nspeech language models. Consequently, leveraging the characteristics of speech\nlanguage models, we propose Language-Codec. In the Language-Codec, we introduce\na Masked Channel Residual Vector Quantization (MCRVQ) mechanism along with\nimproved fourier transform structures and attention blocks, refined\ndiscriminator design to address the aforementioned gaps. We compare our method\nwith competing audio compression algorithms and observe significant\noutperformance across extensive evaluations. Furthermore, we also validate the\nefficiency of the Language-Codec on downstream speech language models. The\nsource code and pre-trained models can be accessed at\nhttps://github.com/jishengpeng/languagecodec .", "AI": {"tldr": "The paper introduces Language-Codec, a method addressing gaps between discrete acoustic codecs and downstream speech language models, using MCRVQ and improved structures for better performance.", "motivation": "Discrete acoustic codecs have gaps in handling weakly supervised signals and burdening downstream models, prompting the need for a better solution.", "method": "Proposes Language-Codec with Masked Channel Residual Vector Quantization (MCRVQ), improved Fourier transforms, attention blocks, and refined discriminator design.", "result": "Outperforms competing audio compression algorithms in evaluations and validates efficiency in downstream tasks.", "conclusion": "Language-Codec effectively bridges gaps and enhances performance, with code and models available for access."}}
{"id": "2506.03185", "pdf": "https://arxiv.org/pdf/2506.03185", "abs": "https://arxiv.org/abs/2506.03185", "authors": ["Liangrui Pan", "Xingchen Li", "Zhongyi Chen", "Ling Chu", "Shaoliang Peng"], "title": "DLiPath: A Benchmark for the Comprehensive Assessment of Donor Liver Based on Histopathological Image Dataset", "categories": ["eess.IV", "cs.AI", "cs.CV", "q-bio.QM"], "comment": "Submit to ACM MM2025", "summary": "Pathologists comprehensive evaluation of donor liver biopsies provides\ncrucial information for accepting or discarding potential grafts. However,\nrapidly and accurately obtaining these assessments intraoperatively poses a\nsignificant challenge for pathologists. Features in donor liver biopsies, such\nas portal tract fibrosis, total steatosis, macrovesicular steatosis, and\nhepatocellular ballooning are correlated with transplant outcomes, yet\nquantifying these indicators suffers from substantial inter- and intra-observer\nvariability. To address this, we introduce DLiPath, the first benchmark for\ncomprehensive donor liver assessment based on a histopathology image dataset.\nWe collected and publicly released 636 whole slide images from 304 donor liver\npatients at the Department of Pathology, the Third Xiangya Hospital, with\nexpert annotations for key pathological features (including cholestasis, portal\ntract fibrosis, portal inflammation, total steatosis, macrovesicular steatosis,\nand hepatocellular ballooning). We selected nine state-of-the-art\nmultiple-instance learning (MIL) models based on the DLiPath dataset as\nbaselines for extensive comparative analysis. The experimental results\ndemonstrate that several MIL models achieve high accuracy across donor liver\nassessment indicators on DLiPath, charting a clear course for future automated\nand intelligent donor liver assessment research. Data and code are available at\nhttps://github.com/panliangrui/ACM_MM_2025.", "AI": {"tldr": "DLiPath is a benchmark for donor liver assessment using histopathology images, addressing variability in manual evaluations with MIL models.", "motivation": "Manual assessment of donor liver biopsies is time-consuming and inconsistent. DLiPath aims to standardize and automate this process.", "method": "Collected 636 whole slide images from 304 patients, annotated by experts, and evaluated nine MIL models for accuracy.", "result": "Several MIL models achieved high accuracy in assessing key pathological features, indicating potential for automation.", "conclusion": "DLiPath provides a foundation for future automated and intelligent donor liver assessment research."}}
{"id": "2410.16428", "pdf": "https://arxiv.org/pdf/2410.16428", "abs": "https://arxiv.org/abs/2410.16428", "authors": ["Wan Lin", "Junhui Chen", "Tianhao Wang", "Zhenyu Zhou", "Lantian Li", "Dong Wang"], "title": "Neural Scoring: A Refreshed End-to-End Approach for Speaker Recognition in Complex Conditions", "categories": ["cs.SD", "eess.AS"], "comment": null, "summary": "Modern speaker verification systems primarily rely on speaker embeddings and\ncosine similarity. While effective, these methods struggle with multi-talker\nspeech due to the unidentifiability of embedding vectors. We propose Neural\nScoring (NS), a novel end-to-end framework that directly estimates verification\nposterior probabilities without relying on test-side embeddings, making it more\npowerful and robust to complex conditions, e.g., with multiple talkers. To\naddress the challenge of training such end-to-end models, we introduce a\nmulti-enrollment training strategy, which pairs each test utterance with\nmultiple enrolled speakers and proves essential to the model's success.\nExperiments on the VoxCeleb dataset demonstrate that NS consistently\noutperforms both the baseline and several competitive methods, achieving an\noverall 70.36% reduction in Equal Error Rate (EER) compared to the baseline.", "AI": {"tldr": "Neural Scoring (NS) is an end-to-end framework for speaker verification that outperforms traditional methods, especially in multi-talker scenarios, reducing EER by 70.36%.", "motivation": "Traditional speaker verification methods struggle with multi-talker speech due to unidentifiable embeddings.", "method": "Proposes Neural Scoring (NS), an end-to-end framework that directly estimates verification probabilities without test-side embeddings, using multi-enrollment training.", "result": "NS achieves a 70.36% reduction in Equal Error Rate (EER) on the VoxCeleb dataset.", "conclusion": "NS is more powerful and robust for speaker verification, particularly in complex conditions like multi-talker speech."}}
{"id": "2506.03360", "pdf": "https://arxiv.org/pdf/2506.03360", "abs": "https://arxiv.org/abs/2506.03360", "authors": ["Zihui Ma", "Lingyao Li", "Juan Li", "Wenyue Hua", "Jingxiao Liu", "Qingyuan Feng", "Yuki Miura"], "title": "A Multimodal, Multilingual, and Multidimensional Pipeline for Fine-grained Crowdsourcing Earthquake Damage Evaluation", "categories": ["cs.CL", "cs.CY", "cs.SI"], "comment": null, "summary": "Rapid, fine-grained disaster damage assessment is essential for effective\nemergency response, yet remains challenging due to limited ground sensors and\ndelays in official reporting. Social media provides a rich, real-time source of\nhuman-centric observations, but its multimodal and unstructured nature presents\nchallenges for traditional analytical methods. In this study, we propose a\nstructured Multimodal, Multilingual, and Multidimensional (3M) pipeline that\nleverages multimodal large language models (MLLMs) to assess disaster impacts.\nWe evaluate three foundation models across two major earthquake events using\nboth macro- and micro-level analyses. Results show that MLLMs effectively\nintegrate image-text signals and demonstrate a strong correlation with\nground-truth seismic data. However, performance varies with language,\nepicentral distance, and input modality. This work highlights the potential of\nMLLMs for disaster assessment and provides a foundation for future research in\napplying MLLMs to real-time crisis contexts. The code and data are released at:\nhttps://github.com/missa7481/EMNLP25_earthquake", "AI": {"tldr": "The paper proposes a 3M pipeline using multimodal large language models (MLLMs) for rapid disaster damage assessment, showing strong correlation with seismic data but varying performance based on language, distance, and modality.", "motivation": "Rapid disaster assessment is hindered by limited ground sensors and delayed reporting. Social media offers real-time data but is challenging due to its unstructured nature.", "method": "A structured 3M pipeline leveraging MLLMs to analyze multimodal social media data, evaluated across two earthquakes using macro- and micro-level analyses.", "result": "MLLMs effectively integrate image-text signals and correlate with seismic data, though performance varies by language, epicentral distance, and modality.", "conclusion": "MLLMs show promise for disaster assessment, providing a foundation for future real-time crisis applications. Code and data are publicly available."}}
{"id": "2506.03189", "pdf": "https://arxiv.org/pdf/2506.03189", "abs": "https://arxiv.org/abs/2506.03189", "authors": ["Ghada Sokar", "Gintare Karolina Dziugaite", "Anurag Arnab", "Ahmet Iscen", "Pablo Samuel Castro", "Cordelia Schmid"], "title": "Continual Learning in Vision-Language Models via Aligned Model Merging", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": null, "summary": "Continual learning is conventionally tackled through sequential fine-tuning,\na process that, while enabling adaptation, inherently favors plasticity over\nthe stability needed to retain prior knowledge. While existing approaches\nattempt to mitigate catastrophic forgetting, a bias towards recent tasks\npersists as they build upon this sequential nature. In this work we present a\nnew perspective based on model merging to maintain stability while still\nretaining plasticity. Rather than just sequentially updating the model weights,\nwe propose merging newly trained task parameters with previously learned ones,\npromoting a better balance. To maximize the effectiveness of the merging\nprocess, we propose a simple mechanism that promotes learning aligned weights\nwith previous ones, thereby avoiding interference when merging. We evaluate\nthis approach on large Vision-Language Models (VLMs), and demonstrate its\neffectiveness in reducing forgetting, increasing robustness to various task\norders and similarities, and improving generalization.", "AI": {"tldr": "A model merging approach for continual learning balances stability and plasticity, reducing forgetting and improving generalization in Vision-Language Models.", "motivation": "Sequential fine-tuning in continual learning favors plasticity over stability, leading to catastrophic forgetting and bias towards recent tasks.", "method": "Proposes merging newly trained task parameters with prior ones, using a mechanism to align weights and avoid interference.", "result": "Reduces forgetting, enhances robustness to task orders/similarities, and improves generalization in VLMs.", "conclusion": "Model merging offers a balanced solution for continual learning, outperforming sequential fine-tuning."}}
{"id": "2506.03673", "pdf": "https://arxiv.org/pdf/2506.03673", "abs": "https://arxiv.org/abs/2506.03673", "authors": ["Yinlong Xu", "Yanzhao Zheng", "Shuoshuo Sun", "Shuaihan Huang", "Baohua Dong", "Hangcheng Zhu", "Ruohui Huang", "Gang Yu", "Hongxia Xu", "Jian Wu"], "title": "Reason from Future: Reverse Thought Chain Enhances LLM Reasoning", "categories": ["cs.AI"], "comment": "Accepted by ACL 2025 findings", "summary": "It has been demonstrated that carefully designed reasoning paradigms, like\nChain-of-Thought (CoT) and Tree-of-Thought (ToT), can enhance the reasoning\ncapabilities of small language models by detailed thinking and extensive\nthought searching, unbounded branching factors in the searching space create\nprohibitive reasoning consumption. However these methods fall into the trap of\nlocal optimum reasoning, which means the model lacks a global perspective while\nsolving problems. We propose a novel reasoning paradigm called Reason from\nFuture (RFF), which generates reasoning paths by bidirectional reasoning that\ncombines top-down planning with bottom-up reasoning accumulation. The essence\nof RFF lies in its reverse reasoning mechanism, which prioritizes core logical\nrelationships and imposes goal-oriented constraints on intermediate steps,\nthereby reducing the searching space and mitigating error accumulation inherent\nin sequential forward reasoning. Empirical evaluations across diverse\nexperiments demonstrate that RFF outperforms conventional paradigms with higher\naccuracy and less searching space to solve complex tasks.", "AI": {"tldr": "The paper introduces Reason from Future (RFF), a bidirectional reasoning paradigm that outperforms Chain-of-Thought and Tree-of-Thought by reducing search space and avoiding local optima.", "motivation": "Existing reasoning paradigms like CoT and ToT enhance small language models but suffer from unbounded search space and local optima, lacking a global perspective.", "method": "RFF combines top-down planning with bottom-up reasoning, using reverse reasoning to prioritize core logic and constrain intermediate steps.", "result": "Empirical evaluations show RFF achieves higher accuracy and requires less search space than conventional methods.", "conclusion": "RFF offers a more efficient and accurate reasoning paradigm by addressing the limitations of forward sequential reasoning."}}
{"id": "2506.03207", "pdf": "https://arxiv.org/pdf/2506.03207", "abs": "https://arxiv.org/abs/2506.03207", "authors": ["Md Nahid Hasan Shuvo", "Moinul Hossain"], "title": "Fingerprinting Deep Learning Models via Network Traffic Patterns in Federated Learning", "categories": ["cs.LG", "cs.AI", "cs.CR"], "comment": "7 pages, 4 Figures, Accepted to publish in Proceedings of the 2025\n  ACM Workshop on Wireless Security and Machine Learning (WiseML 2025), July 3,\n  2025, Arlington, VA, USA", "summary": "Federated Learning (FL) is increasingly adopted as a decentralized machine\nlearning paradigm due to its capability to preserve data privacy by training\nmodels without centralizing user data. However, FL is susceptible to indirect\nprivacy breaches via network traffic analysis-an area not explored in existing\nresearch. The primary objective of this research is to study the feasibility of\nfingerprinting deep learning models deployed within FL environments by\nanalyzing their network-layer traffic information. In this paper, we conduct an\nexperimental evaluation using various deep learning architectures (i.e., CNN,\nRNN) within a federated learning testbed. We utilize machine learning\nalgorithms, including Support Vector Machines (SVM), Random Forest, and\nGradient-Boosting, to fingerprint unique patterns within the traffic data. Our\nexperiments show high fingerprinting accuracy, achieving 100% accuracy using\nRandom Forest and around 95.7% accuracy using SVM and Gradient Boosting\nclassifiers. This analysis suggests that we can identify specific architectures\nrunning within the subsection of the network traffic. Hence, if an adversary\nknows about the underlying DL architecture, they can exploit that information\nand conduct targeted attacks. These findings suggest a notable security\nvulnerability in FL systems and the necessity of strengthening it at the\nnetwork level.", "AI": {"tldr": "The paper investigates privacy risks in Federated Learning (FL) by analyzing network traffic to fingerprint deep learning models, revealing high accuracy in identifying architectures, highlighting a security vulnerability.", "motivation": "To explore indirect privacy breaches in FL via network traffic analysis, an overlooked area in research, and assess the feasibility of fingerprinting models.", "method": "Experimental evaluation using deep learning architectures (CNN, RNN) in an FL testbed, employing SVM, Random Forest, and Gradient Boosting to analyze traffic patterns.", "result": "High fingerprinting accuracy: 100% with Random Forest, ~95.7% with SVM and Gradient Boosting, enabling identification of specific architectures.", "conclusion": "The study exposes a security flaw in FL, emphasizing the need for network-level protections to prevent targeted attacks."}}
{"id": "2505.02945", "pdf": "https://arxiv.org/pdf/2505.02945", "abs": "https://arxiv.org/abs/2505.02945", "authors": ["Egil Diau"], "title": "The Cognitive Foundations of Economic Exchange: A Modular Framework Grounded in Behavioral Evidence", "categories": ["cs.CY", "cs.AI", "cs.MA"], "comment": "This version updates the position paper with clearer language and\n  improved structure. It also corrects minor mistakes in wording and\n  formatting. There is no change in framing, scope, or modeling domain. The\n  core contribution remains a simulateable, agent-based framework intended for\n  cs.CE / cs.MA", "summary": "The origins of economic behavior remain unresolved-not only in the social\nsciences but also in AI, where dominant theories often rely on predefined\nincentives or institutional assumptions. Contrary to the longstanding myth of\nbarter as the foundation of exchange, converging evidence from early human\nsocieties suggests that reciprocity-not barter-was the foundational economic\nlogic, enabling communities to sustain exchange and social cohesion long before\nformal markets emerged. Yet despite its centrality, reciprocity lacks a\nsimulateable and cognitively grounded account. Here, we introduce a minimal\nbehavioral framework based on three empirically supported cognitive\nprimitives-individual recognition, reciprocal credence, and cost--return\nsensitivity-that enable agents to participate in and sustain reciprocal\nexchange, laying the foundation for scalable economic behavior. These\nmechanisms scaffold the emergence of cooperation, proto-economic exchange, and\ninstitutional structure from the bottom up. By bridging insights from\nprimatology, developmental psychology, and economic anthropology, this\nframework offers a unified substrate for modeling trust, coordination, and\neconomic behavior in both human and artificial systems.", "AI": {"tldr": "The paper challenges the myth of barter as the foundation of exchange, proposing reciprocity as the key economic logic. It introduces a cognitive framework for simulating reciprocal behavior in AI and human systems.", "motivation": "To address the lack of a simulateable and cognitively grounded account of reciprocity, which is foundational for economic behavior but often overlooked in AI and social sciences.", "method": "Develops a minimal behavioral framework using three cognitive primitives: individual recognition, reciprocal credence, and cost-return sensitivity.", "result": "The framework enables agents to sustain reciprocal exchange, fostering cooperation and proto-economic behavior from the bottom up.", "conclusion": "The study bridges insights from primatology, psychology, and anthropology, offering a unified approach to model trust and economic behavior in human and artificial systems."}}
{"id": "2406.01205", "pdf": "https://arxiv.org/pdf/2406.01205", "abs": "https://arxiv.org/abs/2406.01205", "authors": ["Shengpeng Ji", "Qian Chen", "Wen Wang", "Jialong Zuo", "Minghui Fang", "Ziyue Jiang", "Hai Huang", "Zehan Wang", "Xize Cheng", "Siqi Zheng", "Zhou Zhao"], "title": "ControlSpeech: Towards Simultaneous and Independent Zero-shot Speaker Cloning and Zero-shot Language Style Control", "categories": ["eess.AS", "cs.LG", "cs.SD"], "comment": "ACL 2025 Main", "summary": "In this paper, we present ControlSpeech, a text-to-speech (TTS) system\ncapable of fully cloning the speaker's voice and enabling arbitrary control and\nadjustment of speaking style. Prior zero-shot TTS models only mimic the\nspeaker's voice without further control and adjustment capabilities while prior\ncontrollable TTS models cannot perform speaker-specific voice generation.\nTherefore, ControlSpeech focuses on a more challenging task: a TTS system with\ncontrollable timbre, content, and style at the same time. ControlSpeech takes\nspeech prompts, content prompts, and style prompts as inputs and utilizes\nbidirectional attention and mask-based parallel decoding to capture codec\nrepresentations corresponding to timbre, content, and style in a discrete\ndecoupling codec space. Moreover, we analyze the many-to-many issue in textual\nstyle control and propose the Style Mixture Semantic Density (SMSD) module,\nwhich is based on Gaussian mixture density networks, to resolve this problem.\nTo facilitate empirical validations, we make available a new style controllable\ndataset called VccmDataset. Our experimental results demonstrate that\nControlSpeech exhibits comparable or state-of-the-art (SOTA) performance in\nterms of controllability, timbre similarity, audio quality, robustness, and\ngeneralizability. The relevant code and demo are available at\nhttps://github.com/jishengpeng/ControlSpeech .", "AI": {"tldr": "ControlSpeech is a TTS system that clones voices and controls speaking styles, addressing limitations of prior models by decoupling timbre, content, and style using bidirectional attention and parallel decoding.", "motivation": "Prior TTS models lack combined control of voice cloning and style adjustment. ControlSpeech aims to achieve both simultaneously.", "method": "Uses speech, content, and style prompts with bidirectional attention and mask-based parallel decoding. Introduces SMSD for style control.", "result": "Achieves SOTA performance in controllability, timbre similarity, audio quality, robustness, and generalizability.", "conclusion": "ControlSpeech successfully integrates voice cloning and style control, validated by experiments and a new dataset."}}
{"id": "2506.03186", "pdf": "https://arxiv.org/pdf/2506.03186", "abs": "https://arxiv.org/abs/2506.03186", "authors": ["Duaa Kareem Qasim", "Sabah Abdulazeez Jebur", "Lafta Raheem Ali", "Abdul Jalil M. Khalaf", "Abir Jaafar Hussain"], "title": "Lightweight Convolutional Neural Networks for Retinal Disease Classification", "categories": ["eess.IV", "cs.AI", "cs.CV", "cs.LG", "cs.NE"], "comment": null, "summary": "Retinal diseases such as Diabetic Retinopathy (DR) and Macular Hole (MH)\nsignificantly impact vision and affect millions worldwide. Early detection is\ncrucial, as DR, a complication of diabetes, damages retinal blood vessels,\npotentially leading to blindness, while MH disrupts central vision, affecting\ntasks like reading and facial recognition. This paper employed two lightweight\nand efficient Convolution Neural Network architectures, MobileNet and\nNASNetMobile, for the classification of Normal, DR, and MH retinal images. The\nmodels were trained on the RFMiD dataset, consisting of 3,200 fundus images,\nafter undergoing preprocessing steps such as resizing, normalization, and\naugmentation. To address data scarcity, this study leveraged transfer learning\nand data augmentation techniques, enhancing model generalization and\nperformance. The experimental results demonstrate that MobileNetV2 achieved the\nhighest accuracy of 90.8%, outperforming NASNetMobile, which achieved 89.5%\naccuracy. These findings highlight the effectiveness of CNNs in retinal disease\nclassification, providing a foundation for AI-assisted ophthalmic diagnosis and\nearly intervention.", "AI": {"tldr": "The paper uses MobileNet and NASNetMobile CNNs to classify retinal diseases (DR and MH) with MobileNetV2 achieving 90.8% accuracy.", "motivation": "Early detection of retinal diseases like DR and MH is critical to prevent vision loss.", "method": "Employed MobileNet and NASNetMobile CNNs, trained on the RFMiD dataset with preprocessing and data augmentation.", "result": "MobileNetV2 achieved 90.8% accuracy, outperforming NASNetMobile (89.5%).", "conclusion": "CNNs are effective for retinal disease classification, aiding AI-assisted diagnosis and early intervention."}}
{"id": "2502.14627", "pdf": "https://arxiv.org/pdf/2502.14627", "abs": "https://arxiv.org/abs/2502.14627", "authors": ["Yuguo Yin", "Yuxin Xie", "Wenyuan Yang", "Dongchao Yang", "Jinghan Ru", "Xianwei Zhuang", "Liming Liang", "Yuexian Zou"], "title": "ATRI: Mitigating Multilingual Audio Text Retrieval Inconsistencies by Reducing Data Distribution Errors", "categories": ["cs.SD", "cs.AI", "eess.AS"], "comment": null, "summary": "Multilingual audio-text retrieval (ML-ATR) is a challenging task that aims to\nretrieve audio clips or multilingual texts from databases. However, existing\nML-ATR schemes suffer from inconsistencies for instance similarity matching\nacross languages. We theoretically analyze the inconsistency in terms of both\nmultilingual modal alignment direction error and weight error, and propose the\ntheoretical weight error upper bound for quantifying the inconsistency. Based\non the analysis of the weight error upper bound, we find that the inconsistency\nproblem stems from the data distribution error caused by random sampling of\nlanguages. We propose a consistent ML-ATR scheme using 1-to-k contrastive\nlearning and audio-English co-anchor contrastive learning, aiming to mitigate\nthe negative impact of data distribution error on recall and consistency in\nML-ATR. Experimental results on the translated AudioCaps and Clotho datasets\nshow that our scheme achieves state-of-the-art performance on recall and\nconsistency metrics for eight mainstream languages, including English. Our code\nwill be available at https://github.com/ATRI-ACL/ATRI-ACL.", "AI": {"tldr": "The paper addresses inconsistency in multilingual audio-text retrieval (ML-ATR) by analyzing errors and proposing a contrastive learning scheme, achieving state-of-the-art results.", "motivation": "Existing ML-ATR schemes struggle with inconsistency in similarity matching across languages, prompting a theoretical and practical solution.", "method": "The authors analyze inconsistency via modal alignment and weight errors, then propose 1-to-k contrastive learning and audio-English co-anchor contrastive learning.", "result": "The proposed scheme outperforms others on recall and consistency metrics for eight languages, as validated on AudioCaps and Clotho datasets.", "conclusion": "The study successfully mitigates data distribution errors in ML-ATR, enhancing retrieval consistency and performance."}}
{"id": "2506.03408", "pdf": "https://arxiv.org/pdf/2506.03408", "abs": "https://arxiv.org/abs/2506.03408", "authors": ["Yi Xu", "Ruining Yang", "Yitian Zhang", "Yizhou Wang", "Jianglin Lu", "Mingyuan Zhang", "Lili Su", "Yun Fu"], "title": "Trajectory Prediction Meets Large Language Models: A Survey", "categories": ["cs.CL", "cs.CV"], "comment": "16 pages, GitHub:\n  https://github.com/colorfulfuture/Awesome-Trajectory-Motion-Prediction-Papers", "summary": "Recent advances in large language models (LLMs) have sparked growing interest\nin integrating language-driven techniques into trajectory prediction. By\nleveraging their semantic and reasoning capabilities, LLMs are reshaping how\nautonomous systems perceive, model, and predict trajectories. This survey\nprovides a comprehensive overview of this emerging field, categorizing recent\nwork into five directions: (1) Trajectory prediction via language modeling\nparadigms, (2) Direct trajectory prediction with pretrained language models,\n(3) Language-guided scene understanding for trajectory prediction, (4)\nLanguage-driven data generation for trajectory prediction, (5) Language-based\nreasoning and interpretability for trajectory prediction. For each, we analyze\nrepresentative methods, highlight core design choices, and identify open\nchallenges. This survey bridges natural language processing and trajectory\nprediction, offering a unified perspective on how language can enrich\ntrajectory prediction.", "AI": {"tldr": "A survey on integrating large language models (LLMs) into trajectory prediction, categorizing recent work into five directions and analyzing methods, design choices, and challenges.", "motivation": "The growing interest in leveraging LLMs' semantic and reasoning capabilities to enhance autonomous systems' trajectory prediction.", "method": "Categorizes recent work into five directions, analyzing representative methods and design choices for each.", "result": "Provides a unified perspective on how language can enrich trajectory prediction, bridging NLP and trajectory prediction.", "conclusion": "The survey highlights the potential of LLMs in trajectory prediction while identifying open challenges for future research."}}
{"id": "2506.03190", "pdf": "https://arxiv.org/pdf/2506.03190", "abs": "https://arxiv.org/abs/2506.03190", "authors": ["Jiaming Yi", "Ruirui Pan", "Jishen Yang", "Xiulong Yang"], "title": "MINT: Memory-Infused Prompt Tuning at Test-time for CLIP", "categories": ["cs.CV", "cs.AI"], "comment": "14 pages, 3 figures", "summary": "Improving the generalization ability of Vision-Language Pre-trained Models\n(VLMs) under test-time data distribution shifts remains a critical challenge.\nThe existing Test-Time Adaptation (TTA) methods fall short in fully leveraging\nthe model's internal knowledge, particularly in dynamically adapting to complex\nand hierarchical visual semantic information. In this paper, we propose\nMemory-Infused Prompt Tuning (MINT), a novel framework to address this issue.\nInspired by human associative memory theory, MINT introduces a Memory Prompt\nBank (MPB), which stores learnable key-value prompt pairs that work as a memory\nof previously seen samples. During the test time, relevant prompt pairs in the\nMPB are retrieved by the hierarchical visual features of test images to\ndynamically assemble Associative Prompts. The associative prompts are then\ninjected into the image encoder for fine-grained, customized visual contextual\nguidance. MINT also utilizes learnable text prompts. MINT thus enables rapid,\nprecise VLM adaptation at test time by leveraging this MPB-acquired memory,\nwithout source data or retraining. The code is available at\nhttps://github.com/Jamieyi2004/MINT.", "AI": {"tldr": "MINT introduces a Memory Prompt Bank for dynamic adaptation of VLMs to test-time data shifts, improving generalization without retraining.", "motivation": "Existing TTA methods fail to fully utilize internal model knowledge for adapting to hierarchical visual semantics.", "method": "MINT uses a Memory Prompt Bank (MPB) with key-value prompt pairs, retrieved by test image features to assemble Associative Prompts for encoder injection.", "result": "MINT enables rapid, precise VLM adaptation at test time without source data or retraining.", "conclusion": "MINT effectively addresses generalization challenges in VLMs under distribution shifts by leveraging memory-infused prompt tuning."}}
{"id": "2506.03915", "pdf": "https://arxiv.org/pdf/2506.03915", "abs": "https://arxiv.org/abs/2506.03915", "authors": ["Sebastian R\u00f6dling", "Matej Ze\u010devi\u0107", "Devendra Singh Dhami", "Kristian Kersting"], "title": "Causal Explanations Over Time: Articulated Reasoning for Interactive Environments", "categories": ["cs.AI"], "comment": "Main paper: 9 pages, References: 2 pages, Supplementary: 9 pages.\n  Number of figures: 10, number of tables: 3", "summary": "Structural Causal Explanations (SCEs) can be used to automatically generate\nexplanations in natural language to questions about given data that are\ngrounded in a (possibly learned) causal model. Unfortunately they work for\nsmall data only. In turn they are not attractive to offer reasons for events,\ne.g., tracking causal changes over multiple time steps, or a behavioral\ncomponent that involves feedback loops through actions of an agent. To this\nend, we generalize SCEs to a (recursive) formulation of explanation trees to\ncapture the temporal interactions between reasons. We show the benefits of this\nmore general SCE algorithm on synthetic time-series data and a 2D grid game,\nand further compare it to the base SCE and other existing methods for causal\nexplanations.", "AI": {"tldr": "The paper generalizes Structural Causal Explanations (SCEs) to handle temporal interactions and feedback loops, improving their applicability beyond small data.", "motivation": "SCEs are limited to small data and lack support for temporal or feedback-driven scenarios, which restricts their practical use.", "method": "The authors propose a recursive formulation of explanation trees to capture temporal interactions and feedback loops.", "result": "The generalized SCE algorithm outperforms the base SCE and other methods on synthetic time-series data and a 2D grid game.", "conclusion": "The recursive SCE formulation enhances explanatory power for temporal and interactive scenarios, broadening its applicability."}}
{"id": "2506.03210", "pdf": "https://arxiv.org/pdf/2506.03210", "abs": "https://arxiv.org/abs/2506.03210", "authors": ["Qiusheng Huang", "Yuan Niu", "Xiaohui Zhong", "Anboyu Guo", "Lei Chen", "Dianjun Zhang", "Xuefeng Zhang", "Hao Li"], "title": "FuXi-Ocean: A Global Ocean Forecasting System with Sub-Daily Resolution", "categories": ["cs.LG", "cs.AI", "physics.ao-ph"], "comment": null, "summary": "Accurate, high-resolution ocean forecasting is crucial for maritime\noperations and environmental monitoring. While traditional numerical models are\ncapable of producing sub-daily, eddy-resolving forecasts, they are\ncomputationally intensive and face challenges in maintaining accuracy at fine\nspatial and temporal scales. In contrast, recent data-driven approaches offer\nimproved computational efficiency and emerging potential, yet typically operate\nat daily resolution and struggle with sub-daily predictions due to error\naccumulation over time. We introduce FuXi-Ocean, the first data-driven global\nocean forecasting model achieving six-hourly predictions at eddy-resolving\n1/12{\\deg} spatial resolution, reaching depths of up to 1500 meters. The model\narchitecture integrates a context-aware feature extraction module with a\npredictive network employing stacked attention blocks. The core innovation is\nthe Mixture-of-Time (MoT) module, which adaptively integrates predictions from\nmultiple temporal contexts by learning variable-specific reliability ,\nmitigating cumulative errors in sequential forecasting. Through comprehensive\nexperimental evaluation, FuXi-Ocean demonstrates superior skill in predicting\nkey variables, including temperature, salinity, and currents, across multiple\ndepths.", "AI": {"tldr": "FuXi-Ocean is a data-driven global ocean forecasting model achieving high-resolution, six-hourly predictions at 1/12\u00b0 spatial resolution, outperforming traditional and other data-driven methods.", "motivation": "Traditional numerical ocean models are computationally intensive and struggle with fine-scale accuracy, while existing data-driven models lack sub-daily resolution. FuXi-Ocean addresses these gaps.", "method": "The model combines context-aware feature extraction with a predictive network using stacked attention blocks and a Mixture-of-Time (MoT) module to mitigate cumulative errors.", "result": "FuXi-Ocean excels in predicting temperature, salinity, and currents across multiple depths, demonstrating superior skill.", "conclusion": "FuXi-Ocean sets a new benchmark for data-driven ocean forecasting with its high-resolution, sub-daily predictions and adaptive error mitigation."}}
{"id": "2406.05298", "pdf": "https://arxiv.org/pdf/2406.05298", "abs": "https://arxiv.org/abs/2406.05298", "authors": ["Ryan Langman", "Ante Juki\u0107", "Kunal Dhawan", "Nithin Rao Koluguri", "Jason Li"], "title": "Spectral Codecs: Improving Non-Autoregressive Speech Synthesis with Spectrogram-Based Audio Codecs", "categories": ["eess.AS"], "comment": null, "summary": "Historically, most speech models in machine-learning have used the\nmel-spectrogram as a speech representation. Recently, discrete audio tokens\nproduced by neural audio codecs have become a popular alternate speech\nrepresentation for speech synthesis tasks such as text-to-speech (TTS).\nHowever, the data distribution produced by such codecs is too complex for some\nTTS models to predict, typically requiring large autoregressive models to get\ngood quality. Most existing audio codecs use Residual Vector Quantization (RVQ)\nto compress and reconstruct the time-domain audio signal. We propose a spectral\ncodec which uses Finite Scalar Quantization (FSQ) to compress the\nmel-spectrogram and reconstruct the time-domain audio signal. A study of\nobjective audio quality metrics and subjective listening tests suggests that\nour spectral codec has comparable perceptual quality to equivalent audio\ncodecs. We show that FSQ, and the use of spectral speech representations, can\nboth improve the performance of parallel TTS models.", "AI": {"tldr": "A spectral codec using Finite Scalar Quantization (FSQ) is proposed for speech synthesis, offering comparable quality to existing audio codecs while improving parallel TTS model performance.", "motivation": "Traditional speech models rely on mel-spectrograms, but discrete audio tokens from neural codecs are complex for some TTS models, requiring large autoregressive models.", "method": "The proposed spectral codec uses FSQ to compress mel-spectrograms and reconstruct audio, avoiding the complexity of Residual Vector Quantization (RVQ).", "result": "Objective metrics and subjective tests show comparable perceptual quality to existing codecs.", "conclusion": "FSQ and spectral representations enhance parallel TTS model performance."}}
{"id": "2506.03188", "pdf": "https://arxiv.org/pdf/2506.03188", "abs": "https://arxiv.org/abs/2506.03188", "authors": ["Madhu Babu Sikha", "Lalith Appari", "Gurudatt Nanjanagudu Ganesh", "Amay Bandodkar", "Imon Banerjee"], "title": "Multi-Analyte, Swab-based Automated Wound Monitor with AI", "categories": ["eess.IV", "cs.AI", "cs.CV", "cs.HC"], "comment": "4 pages conference paper", "summary": "Diabetic foot ulcers (DFUs), a class of chronic wounds, affect ~750,000\nindividuals every year in the US alone and identifying non-healing DFUs that\ndevelop to chronic wounds early can drastically reduce treatment costs and\nminimize risks of amputation. There is therefore a pressing need for diagnostic\ntools that can detect non-healing DFUs early. We develop a low cost,\nmulti-analyte 3D printed assays seamlessly integrated on swabs that can\nidentify non-healing DFUs and a Wound Sensor iOS App - an innovative mobile\napplication developed for the controlled acquisition and automated analysis of\nwound sensor data. By comparing both the original base image (before exposure\nto the wound) and the wound-exposed image, we developed automated computer\nvision techniques to compare density changes between the two assay images,\nwhich allow us to automatically determine the severity of the wound. The iOS\napp ensures accurate data collection and presents actionable insights, despite\nchallenges such as variations in camera configurations and ambient conditions.\nThe proposed integrated sensor and iOS app will allow healthcare professionals\nto monitor wound conditions real-time, track healing progress, and assess\ncritical parameters related to wound care.", "AI": {"tldr": "A low-cost, multi-analyte 3D printed assay and iOS app detect non-healing diabetic foot ulcers early, reducing treatment costs and amputation risks.", "motivation": "Early detection of non-healing diabetic foot ulcers (DFUs) is critical to lower treatment costs and prevent amputations.", "method": "Developed 3D printed assays integrated on swabs and a Wound Sensor iOS App for automated analysis of wound data using computer vision.", "result": "Automated comparison of assay images determines wound severity, with the app ensuring accurate data collection despite environmental variations.", "conclusion": "The integrated sensor and app enable real-time wound monitoring and healing progress tracking for healthcare professionals."}}
{"id": "2503.02769", "pdf": "https://arxiv.org/pdf/2503.02769", "abs": "https://arxiv.org/abs/2503.02769", "authors": ["Dingdong Wang", "Jin Xu", "Ruihang Chu", "Zhifang Guo", "Xiong Wang", "Jincenzi Wu", "Dongchao Yang", "Shengpeng Ji", "Junyang Lin"], "title": "InSerter: Speech Instruction Following with Unsupervised Interleaved Pre-training", "categories": ["cs.SD", "cs.CL", "cs.HC", "eess.AS"], "comment": "Accepted to ACL 2025; Data is available at:\n  https://huggingface.co/datasets/ddwang2000/SpeechInstructBench", "summary": "Recent advancements in speech large language models (SpeechLLMs) have\nattracted considerable attention. Nonetheless, current methods exhibit\nsuboptimal performance in adhering to speech instructions. Notably, the\nintelligence of models significantly diminishes when processing speech-form\ninput as compared to direct text-form input. Prior work has attempted to\nmitigate this semantic inconsistency between speech and text representations\nthrough techniques such as representation and behavior alignment, which involve\nthe meticulous design of data pairs during the post-training phase. In this\npaper, we introduce a simple and scalable training method called InSerter,\nwhich stands for Interleaved Speech-Text Representation Pre-training. InSerter\nis designed to pre-train large-scale unsupervised speech-text sequences, where\nthe speech is synthesized from randomly selected segments of an extensive text\ncorpus using text-to-speech conversion. Consequently, the model acquires the\nability to generate textual continuations corresponding to the provided speech\nsegments, obviating the need for intensive data design endeavors. To\nsystematically evaluate speech instruction-following capabilities, we introduce\nSpeechInstructBench, the first comprehensive benchmark specifically designed\nfor speech-oriented instruction-following tasks. Our proposed InSerter achieves\nSOTA performance in SpeechInstructBench and demonstrates superior or\ncompetitive results across diverse speech processing tasks.", "AI": {"tldr": "InSerter, a scalable training method, improves speech instruction adherence in SpeechLLMs by pre-training on speech-text sequences, achieving SOTA results.", "motivation": "Current SpeechLLMs underperform in speech instruction adherence due to semantic inconsistency between speech and text representations.", "method": "InSerter pre-trains on large-scale unsupervised speech-text sequences, using synthesized speech from text segments, eliminating intensive data design.", "result": "InSerter achieves SOTA performance in SpeechInstructBench and excels in diverse speech tasks.", "conclusion": "InSerter offers a simple, effective solution for enhancing speech instruction-following in SpeechLLMs."}}
{"id": "2506.03424", "pdf": "https://arxiv.org/pdf/2506.03424", "abs": "https://arxiv.org/abs/2506.03424", "authors": ["Nicole R Schneider", "Nandini Ramachandran", "Kent O'Sullivan", "Hanan Samet"], "title": "DistRAG: Towards Distance-Based Spatial Reasoning in LLMs", "categories": ["cs.CL", "cs.IR"], "comment": null, "summary": "Many real world tasks where Large Language Models (LLMs) can be used require\nspatial reasoning, like Point of Interest (POI) recommendation and itinerary\nplanning. However, on their own LLMs lack reliable spatial reasoning\ncapabilities, especially about distances. To address this problem, we develop a\nnovel approach, DistRAG, that enables an LLM to retrieve relevant spatial\ninformation not explicitly learned during training. Our method encodes the\ngeodesic distances between cities and towns in a graph and retrieves a context\nsubgraph relevant to the question. Using this technique, our method enables an\nLLM to answer distance-based reasoning questions that it otherwise cannot\nanswer. Given the vast array of possible places an LLM could be asked about,\nDistRAG offers a flexible first step towards providing a rudimentary `world\nmodel' to complement the linguistic knowledge held in LLMs.", "AI": {"tldr": "DistRAG enhances LLMs' spatial reasoning by retrieving geodesic distances between locations, enabling them to answer distance-based questions they couldn't before.", "motivation": "LLMs lack reliable spatial reasoning, especially for distances, limiting their use in tasks like POI recommendation and itinerary planning.", "method": "DistRAG encodes geodesic distances in a graph and retrieves relevant subgraphs for context, supplementing LLMs' linguistic knowledge.", "result": "The method allows LLMs to answer distance-based reasoning questions accurately.", "conclusion": "DistRAG is a flexible step toward equipping LLMs with a rudimentary 'world model' for spatial tasks."}}
{"id": "2506.03191", "pdf": "https://arxiv.org/pdf/2506.03191", "abs": "https://arxiv.org/abs/2506.03191", "authors": ["Muhammad Islam", "Tao Huang", "Euijoon Ahn", "Usman Naseem"], "title": "Multimodal Generative AI with Autoregressive LLMs for Human Motion Understanding and Generation: A Way Forward", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "This paper presents an in-depth survey on the use of multimodal Generative\nArtificial Intelligence (GenAI) and autoregressive Large Language Models (LLMs)\nfor human motion understanding and generation, offering insights into emerging\nmethods, architectures, and their potential to advance realistic and versatile\nmotion synthesis. Focusing exclusively on text and motion modalities, this\nresearch investigates how textual descriptions can guide the generation of\ncomplex, human-like motion sequences. The paper explores various generative\napproaches, including autoregressive models, diffusion models, Generative\nAdversarial Networks (GANs), Variational Autoencoders (VAEs), and\ntransformer-based models, by analyzing their strengths and limitations in terms\nof motion quality, computational efficiency, and adaptability. It highlights\nrecent advances in text-conditioned motion generation, where textual inputs are\nused to control and refine motion outputs with greater precision. The\nintegration of LLMs further enhances these models by enabling semantic\nalignment between instructions and motion, improving coherence and contextual\nrelevance. This systematic survey underscores the transformative potential of\ntext-to-motion GenAI and LLM architectures in applications such as healthcare,\nhumanoids, gaming, animation, and assistive technologies, while addressing\nongoing challenges in generating efficient and realistic human motion.", "AI": {"tldr": "Survey on multimodal GenAI and LLMs for human motion understanding and generation, focusing on text-to-motion synthesis.", "motivation": "To explore how textual descriptions can guide realistic human motion generation and advance motion synthesis technologies.", "method": "Analyzes generative approaches like autoregressive models, diffusion models, GANs, VAEs, and transformers, evaluating their strengths and limitations.", "result": "Highlights advances in text-conditioned motion generation and the role of LLMs in improving semantic alignment and coherence.", "conclusion": "Demonstrates the transformative potential of text-to-motion GenAI and LLMs in various applications, while addressing challenges in realism and efficiency."}}
{"id": "2506.03939", "pdf": "https://arxiv.org/pdf/2506.03939", "abs": "https://arxiv.org/abs/2506.03939", "authors": ["Junqi Gao", "Xiang Zou", "YIng Ai", "Dong Li", "Yichen Niu", "Biqing Qi", "Jianxing Liu"], "title": "Graph Counselor: Adaptive Graph Exploration via Multi-Agent Synergy to Enhance LLM Reasoning", "categories": ["cs.AI", "cs.CL"], "comment": "Accepted by ACL 2025", "summary": "Graph Retrieval Augmented Generation (GraphRAG) effectively enhances external\nknowledge integration capabilities by explicitly modeling knowledge\nrelationships, thereby improving the factual accuracy and generation quality of\nLarge Language Models (LLMs) in specialized domains. However, existing methods\nsuffer from two inherent limitations: 1) Inefficient Information Aggregation:\nThey rely on a single agent and fixed iterative patterns, making it difficult\nto adaptively capture multi-level textual, structural, and degree information\nwithin graph data. 2) Rigid Reasoning Mechanism: They employ preset reasoning\nschemes, which cannot dynamically adjust reasoning depth nor achieve precise\nsemantic correction. To overcome these limitations, we propose Graph Counselor,\nan GraphRAG method based on multi-agent collaboration. This method uses the\nAdaptive Graph Information Extraction Module (AGIEM), where Planning, Thought,\nand Execution Agents work together to precisely model complex graph structures\nand dynamically adjust information extraction strategies, addressing the\nchallenges of multi-level dependency modeling and adaptive reasoning depth.\nAdditionally, the Self-Reflection with Multiple Perspectives (SR) module\nimproves the accuracy and semantic consistency of reasoning results through\nself-reflection and backward reasoning mechanisms. Experiments demonstrate that\nGraph Counselor outperforms existing methods in multiple graph reasoning tasks,\nexhibiting higher reasoning accuracy and generalization ability. Our code is\navailable at https://github.com/gjq100/Graph-Counselor.git.", "AI": {"tldr": "Graph Counselor enhances GraphRAG by addressing inefficiencies in information aggregation and rigid reasoning through multi-agent collaboration and adaptive modules, improving LLM performance in specialized domains.", "motivation": "Existing GraphRAG methods struggle with inefficient information aggregation and rigid reasoning, limiting their adaptability and accuracy in handling graph data.", "method": "Proposes Graph Counselor, using multi-agent collaboration (AGIEM) and a Self-Reflection module for adaptive graph modeling and reasoning.", "result": "Outperforms existing methods in graph reasoning tasks, showing higher accuracy and generalization.", "conclusion": "Graph Counselor effectively overcomes limitations of current GraphRAG methods, offering improved performance and adaptability."}}
{"id": "2506.03225", "pdf": "https://arxiv.org/pdf/2506.03225", "abs": "https://arxiv.org/abs/2506.03225", "authors": ["Wa\u00ebl Doulazmi", "Auguste Lehuger", "Marin Toromanoff", "Valentin Charraut", "Thibault Buhet", "Fabien Moutarde"], "title": "Multiple-Frequencies Population-Based Training", "categories": ["cs.LG", "cs.AI", "cs.NE"], "comment": "Accepted at RLC25", "summary": "Reinforcement Learning's high sensitivity to hyperparameters is a source of\ninstability and inefficiency, creating significant challenges for\npractitioners. Hyperparameter Optimization (HPO) algorithms have been developed\nto address this issue, among them Population-Based Training (PBT) stands out\nfor its ability to generate hyperparameters schedules instead of fixed\nconfigurations. PBT trains a population of agents, each with its own\nhyperparameters, frequently ranking them and replacing the worst performers\nwith mutations of the best agents. These intermediate selection steps can cause\nPBT to focus on short-term improvements, leading it to get stuck in local\noptima and eventually fall behind vanilla Random Search over longer timescales.\nThis paper studies how this greediness issue is connected to the choice of\nevolution frequency, the rate at which the selection is done. We propose\nMultiple-Frequencies Population-Based Training (MF-PBT), a novel HPO algorithm\nthat addresses greediness by employing sub-populations, each evolving at\ndistinct frequencies. MF-PBT introduces a migration process to transfer\ninformation between sub-populations, with an asymmetric design to balance short\nand long-term optimization. Extensive experiments on the Brax suite demonstrate\nthat MF-PBT improves sample efficiency and long-term performance, even without\nactually tuning hyperparameters.", "AI": {"tldr": "MF-PBT addresses PBT's greediness by using sub-populations with distinct evolution frequencies and migration, improving long-term performance.", "motivation": "PBT's focus on short-term improvements leads to local optima and inefficiency; MF-PBT aims to balance short and long-term optimization.", "method": "MF-PBT employs sub-populations evolving at different frequencies and introduces asymmetric migration for information transfer.", "result": "Experiments on Brax show MF-PBT enhances sample efficiency and long-term performance without hyperparameter tuning.", "conclusion": "MF-PBT effectively mitigates PBT's greediness, offering better stability and efficiency in hyperparameter optimization."}}
{"id": "2504.12423", "pdf": "https://arxiv.org/pdf/2504.12423", "abs": "https://arxiv.org/abs/2504.12423", "authors": ["Haohan Shi", "Xiyu Shi", "Safak Dogan", "Saif Alzubi", "Tianjin Huang", "Yunxiao Zhang"], "title": "Benchmarking Audio Deepfake Detection Robustness in Real-world Communication Scenarios", "categories": ["eess.AS", "eess.SP"], "comment": "Accepted by EUSIPCO 2025", "summary": "Existing Audio Deepfake Detection (ADD) systems often struggle to generalise\neffectively due to the significantly degraded audio quality caused by audio\ncodec compression and channel transmission effects in real-world communication\nscenarios. To address this challenge, we developed a rigorous benchmark to\nevaluate the performance of the ADD system under such scenarios. We introduced\nADD-C, a new test dataset to evaluate the robustness of ADD systems under\ndiverse communication conditions, including different combinations of audio\ncodecs for compression and packet loss rates. Benchmarking three baseline ADD\nmodels on the ADD-C dataset demonstrated a significant decline in robustness\nunder such conditions. A novel Data Augmentation (DA) strategy was proposed to\nimprove the robustness of ADD systems. Experimental results demonstrated that\nthe proposed approach significantly enhances the performance of ADD systems on\nthe proposed ADD-C dataset. Our benchmark can assist future efforts towards\nbuilding practical and robustly generalisable ADD systems.", "AI": {"tldr": "The paper addresses the challenge of audio deepfake detection (ADD) systems struggling with degraded audio quality in real-world scenarios. It introduces ADD-C, a benchmark dataset, and a data augmentation strategy to improve robustness.", "motivation": "Existing ADD systems fail to generalize well due to audio quality degradation from codec compression and transmission effects.", "method": "Developed the ADD-C benchmark dataset and proposed a novel data augmentation strategy to enhance ADD system robustness.", "result": "Benchmarking showed baseline models' performance declined under communication conditions, but the proposed DA strategy improved robustness.", "conclusion": "The ADD-C benchmark and DA strategy can help build more practical and robust ADD systems."}}
{"id": "2506.03192", "pdf": "https://arxiv.org/pdf/2506.03192", "abs": "https://arxiv.org/abs/2506.03192", "authors": ["Basudha Pal", "Rama Chellappa", "Muhammad Umair"], "title": "Encoding of Demographic and Anatomical Information in Chest X-Ray-based Severe Left Ventricular Hypertrophy Classifiers", "categories": ["eess.IV", "cs.AI", "cs.CV"], "comment": null, "summary": "While echocardiography and MRI are clinical standards for evaluating cardiac\nstructure, their use is limited by cost and accessibility.We introduce a direct\nclassification framework that predicts severe left ventricular hypertrophy from\nchest X-rays, without relying on anatomical measurements or demographic inputs.\nOur approach achieves high AUROC and AUPRC, and employs Mutual Information\nNeural Estimation to quantify feature expressivity. This reveals clinically\nmeaningful attribute encoding and supports transparent model interpretation.", "AI": {"tldr": "A framework predicts severe left ventricular hypertrophy from chest X-rays using Mutual Information Neural Estimation, achieving high performance metrics.", "motivation": "Echocardiography and MRI are costly and less accessible, prompting a need for an alternative method using chest X-rays.", "method": "Direct classification framework using Mutual Information Neural Estimation to quantify feature expressivity.", "result": "High AUROC and AUPRC, with clinically meaningful attribute encoding and transparent model interpretation.", "conclusion": "The framework offers a cost-effective, accessible alternative for detecting severe left ventricular hypertrophy."}}
{"id": "2505.14470", "pdf": "https://arxiv.org/pdf/2505.14470", "abs": "https://arxiv.org/abs/2505.14470", "authors": ["Nadav Har-Tuv", "Or Tal", "Yossi Adi"], "title": "PAST: Phonetic-Acoustic Speech Tokenizer", "categories": ["cs.SD", "cs.CL", "cs.LG", "eess.AS"], "comment": null, "summary": "We present PAST, a novel end-to-end framework that jointly models phonetic\ninformation alongside signal reconstruction, eliminating the need for external\npretrained models. Unlike previous approaches that rely on pretrained\nself-supervised models, PAST employs supervised phonetic data, directly\nintegrating domain knowledge into the tokenization process via auxiliary tasks.\nAdditionally, we introduce a streamable, causal variant of PAST, enabling\nreal-time speech applications. Results demonstrate that PAST surpasses existing\nevaluated baseline tokenizers across common evaluation metrics, including\nphonetic representation and speech reconstruction. Notably, PAST also achieves\nsuperior performance when serving as a speech representation for speech\nlanguage models, further highlighting its effectiveness as a foundation for\nspoken language generation. To foster further research, we release the full\nimplementation. For code, model checkpoints, and samples see:\nhttps://pages.cs.huji.ac.il/adiyoss-lab/PAST", "AI": {"tldr": "PAST is an end-to-end framework for joint phonetic and signal modeling, outperforming baselines in phonetic representation and speech reconstruction, and enabling real-time applications.", "motivation": "To eliminate reliance on pretrained models and integrate phonetic knowledge directly into tokenization.", "method": "Uses supervised phonetic data with auxiliary tasks and introduces a causal, streamable variant for real-time use.", "result": "Surpasses baselines in metrics and excels as a speech representation for language models.", "conclusion": "PAST is effective for spoken language generation and is publicly available for further research."}}
{"id": "2506.03434", "pdf": "https://arxiv.org/pdf/2506.03434", "abs": "https://arxiv.org/abs/2506.03434", "authors": ["Ahmad Dawar Hakimi", "Ali Modarressi", "Philipp Wicke", "Hinrich Sch\u00fctze"], "title": "Time Course MechInterp: Analyzing the Evolution of Components and Knowledge in Large Language Models", "categories": ["cs.CL"], "comment": null, "summary": "Understanding how large language models (LLMs) acquire and store factual\nknowledge is crucial for enhancing their interpretability and reliability. In\nthis work, we analyze the evolution of factual knowledge representation in the\nOLMo-7B model by tracking the roles of its attention heads and feed forward\nnetworks (FFNs) over the course of pre-training. We classify these components\ninto four roles: general, entity, relation-answer, and fact-answer specific,\nand examine their stability and transitions. Our results show that LLMs\ninitially depend on broad, general-purpose components, which later specialize\nas training progresses. Once the model reliably predicts answers, some\ncomponents are repurposed, suggesting an adaptive learning process. Notably,\nattention heads display the highest turnover. We also present evidence that\nFFNs remain more stable throughout training. Furthermore, our probing\nexperiments reveal that location-based relations converge to high accuracy\nearlier in training than name-based relations, highlighting how task complexity\nshapes acquisition dynamics. These insights offer a mechanistic view of\nknowledge formation in LLMs.", "AI": {"tldr": "The paper analyzes how the OLMo-7B model's attention heads and FFNs evolve during pre-training, revealing their roles, stability, and transitions in representing factual knowledge.", "motivation": "To enhance interpretability and reliability of LLMs by understanding how they acquire and store factual knowledge.", "method": "Tracking the roles of attention heads and FFNs in OLMo-7B during pre-training, classifying them into four roles, and examining stability and transitions.", "result": "LLMs start with general-purpose components that later specialize; attention heads show high turnover, while FFNs remain stable. Location-based relations converge earlier than name-based ones.", "conclusion": "The study provides a mechanistic view of knowledge formation in LLMs, showing adaptive learning and task complexity's impact on acquisition."}}
{"id": "2506.03193", "pdf": "https://arxiv.org/pdf/2506.03193", "abs": "https://arxiv.org/abs/2506.03193", "authors": ["Ekram Alam", "Abu Sufian", "Paramartha Dutta", "Marco Leo"], "title": "Human Fall Detection using Transfer Learning-based 3D CNN", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "Unintentional or accidental falls are one of the significant health issues in\nsenior persons. The population of senior persons is increasing steadily. So,\nthere is a need for an automated fall detection monitoring system. This paper\nintroduces a vision-based fall detection system using a pre-trained 3D CNN.\nUnlike 2D CNN, 3D CNN extracts not only spatial but also temporal features. The\nproposed model leverages the original learned weights of a 3D CNN model\npre-trained on the Sports1M dataset to extract the spatio-temporal features.\nOnly the SVM classifier was trained, which saves the time required to train the\n3D CNN. Stratified shuffle five split cross-validation has been used to split\nthe dataset into training and testing data. Extracted features from the\nproposed 3D CNN model were fed to an SVM classifier to classify the activity as\nfall or ADL. Two datasets, GMDCSA and CAUCAFall, were utilized to conduct the\nexperiment. The source code for this work can be accessed via the following\nlink: https://github.com/ekramalam/HFD_3DCNN.", "AI": {"tldr": "A vision-based fall detection system for seniors using a pre-trained 3D CNN and SVM classifier, achieving efficient classification with minimal training time.", "motivation": "Addressing the health issue of accidental falls in the growing senior population by automating fall detection.", "method": "Utilizes a pre-trained 3D CNN for spatio-temporal feature extraction and trains only an SVM classifier, validated with stratified shuffle split.", "result": "Tested on GMDCSA and CAUCAFall datasets, demonstrating effective fall detection.", "conclusion": "The proposed system is efficient and practical for real-world fall detection in seniors."}}
{"id": "2506.03997", "pdf": "https://arxiv.org/pdf/2506.03997", "abs": "https://arxiv.org/abs/2506.03997", "authors": ["Mario Alviano", "Laura Giordano", "Daniele Theseider Dupr\u00e9"], "title": "A framework for Conditional Reasoning in Answer Set Programming", "categories": ["cs.AI", "cs.LO", "I.2.4"], "comment": "19 pages", "summary": "In this paper we introduce a Conditional Answer Set Programming framework\n(Conditional ASP) for the definition of conditional extensions of Answer Set\nProgramming (ASP). The approach builds on a conditional logic with typicality,\nand on the combination of a conditional knowledge base with an ASP program, and\nallows for conditional reasoning over the answer sets of the program. The\nformalism relies on a multi-preferential semantics (and on the KLM preferential\nsemantics, as a special case) to provide an interpretation of conditionals.", "AI": {"tldr": "A Conditional ASP framework is introduced for conditional extensions of Answer Set Programming, combining conditional logic with ASP for reasoning over answer sets.", "motivation": "To extend Answer Set Programming with conditional reasoning capabilities, leveraging conditional logic and multi-preferential semantics.", "method": "Combines a conditional knowledge base with an ASP program, using multi-preferential semantics (including KLM preferential semantics) to interpret conditionals.", "result": "The framework enables conditional reasoning over answer sets, providing a flexible and interpretable approach.", "conclusion": "Conditional ASP offers a robust method for integrating conditional reasoning into ASP, enhancing its expressiveness and applicability."}}
{"id": "2506.03227", "pdf": "https://arxiv.org/pdf/2506.03227", "abs": "https://arxiv.org/abs/2506.03227", "authors": ["Abdelrahman Sayed Sayed", "Pierre-Jean Meyer", "Mohamed Ghazel"], "title": "Bridging Neural ODE and ResNet: A Formal Error Bound for Safety Verification", "categories": ["cs.LG", "cs.AI"], "comment": "17 pages, 5 figures, Accepted for publication in the proceedings of\n  the 8th International Symposium on AI Verification SAIV 2025", "summary": "A neural ordinary differential equation (neural ODE) is a machine learning\nmodel that is commonly described as a continuous depth generalization of a\nresidual network (ResNet) with a single residual block, or conversely, the\nResNet can be seen as the Euler discretization of the neural ODE. These two\nmodels are therefore strongly related in a way that the behaviors of either\nmodel are considered to be an approximation of the behaviors of the other. In\nthis work, we establish a more formal relationship between these two models by\nbounding the approximation error between two such related models. The obtained\nerror bound then allows us to use one of the models as a verification proxy for\nthe other, without running the verification tools twice: if the reachable\noutput set expanded by the error bound satisfies a safety property on one of\nthe models, this safety property is then guaranteed to be also satisfied on the\nother model. This feature is fully reversible, and the initial safety\nverification can be run indifferently on either of the two models. This novel\napproach is illustrated on a numerical example of a fixed-point attractor\nsystem modeled as a neural ODE.", "AI": {"tldr": "The paper formalizes the relationship between neural ODEs and ResNets by bounding their approximation error, enabling safety verification for one model to apply to the other.", "motivation": "To establish a formal connection between neural ODEs and ResNets, leveraging their approximation behaviors for efficient safety verification.", "method": "Bounding the approximation error between neural ODEs and ResNets, allowing one model to serve as a verification proxy for the other.", "result": "An error bound is derived, enabling safety verification on one model to guarantee safety on the other without redundant verification.", "conclusion": "The approach is validated on a neural ODE example, demonstrating its utility for reversible safety verification."}}
{"id": "2505.15965", "pdf": "https://arxiv.org/pdf/2505.15965", "abs": "https://arxiv.org/abs/2505.15965", "authors": ["Gowtham Premananth", "Vinith Kugathasan", "Carol Espy-Wilson"], "title": "Analyzing the Impact of Accent on English Speech: Acoustic and Articulatory Perspectives", "categories": ["eess.AS", "eess.SP"], "comment": "Accepted to be presented at Interspeech 2025", "summary": "Advancements in AI-driven speech-based applications have transformed diverse\nindustries ranging from healthcare to customer service. However, the increasing\nprevalence of non-native accented speech in global interactions poses\nsignificant challenges for speech-processing systems, which are often trained\non datasets dominated by native speech. This study investigates accented\nEnglish speech through articulatory and acoustic analysis, identifying simpler\ncoordination patterns and higher average pitch than native speech. Using\neigenspectra and Vocal Tract Variable-based coordination features, we establish\nan efficient method for quantifying accent strength without relying on\nresource-intensive phonetic transcriptions. Our findings provide a new avenue\nfor research on the impacts of accents on speech intelligibility and offer\ninsights for developing inclusive, robust speech processing systems that\naccommodate diverse linguistic communities.", "AI": {"tldr": "The paper explores accented English speech, highlighting its differences from native speech and proposing a method to quantify accent strength without phonetic transcriptions.", "motivation": "The rise of non-native accented speech in global interactions challenges AI-driven speech systems, which are typically trained on native speech datasets.", "method": "The study uses articulatory and acoustic analysis, eigenspectra, and Vocal Tract Variable-based coordination features to analyze accented speech.", "result": "Findings show simpler coordination patterns and higher average pitch in accented speech, with a method to quantify accent strength efficiently.", "conclusion": "The research opens new avenues for studying accent impacts on intelligibility and aids in developing inclusive speech-processing systems."}}
{"id": "2506.03202", "pdf": "https://arxiv.org/pdf/2506.03202", "abs": "https://arxiv.org/abs/2506.03202", "authors": ["Itxasne Ant\u00fanez S\u00e1enz", "Ane Alberdi Aramendi", "David Dunaway", "Juling Ong", "Lara Deli\u00e8ge", "Amparo S\u00e1enz", "Anita Ahmadi Birjandi", "Noor UI Owase Jeelani", "Silvia Schievano", "Alessandro Borghi"], "title": "A combined Machine Learning and Finite Element Modelling tool for the surgical planning of craniosynostosis correction", "categories": ["eess.IV", "cs.CV", "cs.LG", "physics.med-ph"], "comment": "11 pages, 16 figures", "summary": "Craniosynostosis is a medical condition that affects the growth of babies'\nheads, caused by an early fusion of cranial sutures. In recent decades,\nsurgical treatments for craniosynostosis have significantly improved, leading\nto reduced invasiveness, faster recovery, and less blood loss. At Great Ormond\nStreet Hospital (GOSH), the main surgical treatment for patients diagnosed with\nsagittal craniosynostosis (SC) is spring assisted cranioplasty (SAC). This\nprocedure involves a 15x15 mm2 osteotomy, where two springs are inserted to\ninduce distraction. Despite the numerous advantages of this surgical technique\nfor patients, the outcome remains unpredictable due to the lack of efficient\npreoperative planning tools. The surgeon's experience and the baby's age are\ncurrently relied upon to determine the osteotomy location and spring selection.\nPrevious tools for predicting the surgical outcome of SC relied on finite\nelement modeling (FEM), which involved computed tomography (CT) imaging and\nrequired engineering expertise and lengthy calculations. The main goal of this\nresearch is to develop a real-time prediction tool for the surgical outcome of\npatients, eliminating the need for CT scans to minimise radiation exposure\nduring preoperative planning. The proposed methodology involves creating\npersonalised synthetic skulls based on three-dimensional (3D) photographs,\nincorporating population average values of suture location, skull thickness,\nand soft tissue properties. A machine learning (ML) surrogate model is employed\nto achieve the desired surgical outcome. The resulting multi-output support\nvector regressor model achieves a R2 metric of 0.95 and MSE and MAE below 0.13.\nFurthermore, in the future, this model could not only simulate various surgical\nscenarios but also provide optimal parameters for achieving a maximum cranial\nindex (CI).", "AI": {"tldr": "A real-time prediction tool for craniosynostosis surgery outcomes is developed using 3D photos and ML, avoiding CT scans and achieving high accuracy.", "motivation": "Current surgical planning for craniosynostosis lacks efficiency and relies on CT scans, which involve radiation. The goal is to create a safer, faster tool using 3D photos and ML.", "method": "Personalized synthetic skulls are created from 3D photos, incorporating average population data. A machine learning surrogate model predicts surgical outcomes.", "result": "The ML model achieves an R2 of 0.95 and low MSE/MAE (<0.13), demonstrating high accuracy in predicting outcomes.", "conclusion": "The tool offers a radiation-free, efficient alternative to CT-based planning and could optimize surgical parameters for better cranial index outcomes."}}
{"id": "2303.11607", "pdf": "https://arxiv.org/pdf/2303.11607", "abs": "https://arxiv.org/abs/2303.11607", "authors": ["Siddique Latif", "Aun Zaidi", "Heriberto Cuayahuitl", "Fahad Shamshad", "Moazzam Shoukat", "Muhammad Usama", "Junaid Qadir"], "title": "Transformers in Speech Processing: A Survey", "categories": ["cs.CL", "cs.SD", "eess.AS"], "comment": "Accepted in Computer Science Review 2025", "summary": "The remarkable success of transformers in the field of natural language\nprocessing has sparked the interest of the speech-processing community, leading\nto an exploration of their potential for modeling long-range dependencies\nwithin speech sequences. Recently, transformers have gained prominence across\nvarious speech-related domains, including automatic speech recognition, speech\nsynthesis, speech translation, speech para-linguistics, speech enhancement,\nspoken dialogue systems, and numerous multimodal applications. In this paper,\nwe present a comprehensive survey that aims to bridge research studies from\ndiverse subfields within speech technology. By consolidating findings from\nacross the speech technology landscape, we provide a valuable resource for\nresearchers interested in harnessing the power of transformers to advance the\nfield. We identify the challenges encountered by transformers in speech\nprocessing while also offering insights into potential solutions to address\nthese issues.", "AI": {"tldr": "A survey on transformers in speech processing, covering applications, challenges, and potential solutions.", "motivation": "Explore transformers' potential for modeling long-range dependencies in speech sequences and unify research across speech technology subfields.", "method": "Comprehensive survey consolidating findings from diverse speech technology domains.", "result": "Identifies challenges of transformers in speech processing and suggests solutions.", "conclusion": "Provides a resource for researchers to advance speech technology using transformers."}}
{"id": "2506.03458", "pdf": "https://arxiv.org/pdf/2506.03458", "abs": "https://arxiv.org/abs/2506.03458", "authors": ["Zahra Bokaei", "Walid Magdy", "Bonnie Webber"], "title": "Culture Matters in Toxic Language Detection in Persian", "categories": ["cs.CL"], "comment": "Accepted to ACL 2025 (Main Track)", "summary": "Toxic language detection is crucial for creating safer online environments\nand limiting the spread of harmful content. While toxic language detection has\nbeen under-explored in Persian, the current work compares different methods for\nthis task, including fine-tuning, data enrichment, zero-shot and few-shot\nlearning, and cross-lingual transfer learning. What is especially compelling is\nthe impact of cultural context on transfer learning for this task: We show that\nthe language of a country with cultural similarities to Persian yields better\nresults in transfer learning. Conversely, the improvement is lower when the\nlanguage comes from a culturally distinct country. Warning: This paper contains\nexamples of toxic language that may disturb some readers. These examples are\nincluded for the purpose of research on toxic detection.", "AI": {"tldr": "The paper explores toxic language detection in Persian, comparing methods like fine-tuning, data enrichment, and transfer learning, highlighting the role of cultural context in transfer learning effectiveness.", "motivation": "To address the under-explored area of toxic language detection in Persian and improve online safety by identifying effective detection methods.", "method": "Comparison of fine-tuning, data enrichment, zero-shot/few-shot learning, and cross-lingual transfer learning, with emphasis on cultural context in transfer learning.", "result": "Cultural similarity between languages enhances transfer learning performance, while distinct cultures yield lower improvements.", "conclusion": "Cultural context significantly impacts transfer learning for toxic language detection in Persian, suggesting its importance in model development."}}
{"id": "2506.03194", "pdf": "https://arxiv.org/pdf/2506.03194", "abs": "https://arxiv.org/abs/2506.03194", "authors": ["Rynaa Grover", "Jayant Sravan Tamarapalli", "Sahiti Yerramilli", "Nilay Pande"], "title": "HueManity: Probing Fine-Grained Visual Perception in MLLMs", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": null, "summary": "Multimodal Large Language Models (MLLMs) excel at high-level visual\nreasoning, but their performance on nuanced perceptual tasks remains\nsurprisingly limited. We present HueManity, a benchmark designed to assess\nvisual perception in MLLMs. The dataset comprises 83,850 images featuring\ntwo-character alphanumeric strings embedded in Ishihara test style dot\npatterns, challenging models on precise pattern recognition. Our evaluation of\nnine state-of-the-art MLLMs on HueManity demonstrates a significant performance\ndeficit compared to human and traditional computer vision baselines. The\nbest-performing MLLM achieved a 33.6% accuracy on the numeric `easy' task and a\nstriking 3% on the alphanumeric `hard' task. In contrast, human participants\nachieved near-perfect scores (100% and 95.6%), and a fine-tuned ResNet50 model\nreached accuracies of 96.5% and 94.5%. These results highlight a critical gap\nin the visual capabilities of current MLLMs. Our analysis further explores\npotential architectural and training-paradigm factors contributing to this\nperceptual gap in MLLMs. We open-source HueManity dataset and code to foster\nfurther research in improving perceptual robustness of MLLMs.", "AI": {"tldr": "HueManity benchmark reveals MLLMs' poor performance on nuanced visual perception tasks compared to humans and traditional CV models.", "motivation": "To assess and highlight the limitations of MLLMs in visual perception tasks, particularly in precise pattern recognition.", "method": "Created HueManity, a dataset of 83,850 images with alphanumeric strings in Ishihara-style patterns, and evaluated nine MLLMs against human and ResNet50 baselines.", "result": "MLLMs performed poorly (33.6% on 'easy', 3% on 'hard' tasks) vs. humans (~100%, 95.6%) and ResNet50 (96.5%, 94.5%).", "conclusion": "Current MLLMs lack perceptual robustness; HueManity is open-sourced to encourage research in bridging this gap."}}
{"id": "2506.04018", "pdf": "https://arxiv.org/pdf/2506.04018", "abs": "https://arxiv.org/abs/2506.04018", "authors": ["Akshat Naik", "Patrick Quinn", "Guillermo Bosch", "Emma Goun\u00e9", "Francisco Javier Campos Zabala", "Jason Ross Brown", "Edward James Young"], "title": "AgentMisalignment: Measuring the Propensity for Misaligned Behaviour in LLM-Based Agents", "categories": ["cs.AI", "cs.CL", "cs.CY", "cs.LG", "I.2.7; I.2.11; K.4.1; I.2.6"], "comment": "Prepint, under review for NeurIPS 2025", "summary": "As Large Language Model (LLM) agents become more widespread, associated\nmisalignment risks increase. Prior work has examined agents' ability to enact\nmisaligned behaviour (misalignment capability) and their compliance with\nharmful instructions (misuse propensity). However, the likelihood of agents\nattempting misaligned behaviours in real-world settings (misalignment\npropensity) remains poorly understood. We introduce a misalignment propensity\nbenchmark, AgentMisalignment, consisting of a suite of realistic scenarios in\nwhich LLM agents have the opportunity to display misaligned behaviour. We\norganise our evaluations into subcategories of misaligned behaviours, including\ngoal-guarding, resisting shutdown, sandbagging, and power-seeking. We report\nthe performance of frontier models on our benchmark, observing higher\nmisalignment on average when evaluating more capable models. Finally, we\nsystematically vary agent personalities through different system prompts. We\nfind that persona characteristics can dramatically and unpredictably influence\nmisalignment tendencies -- occasionally far more than the choice of model\nitself -- highlighting the importance of careful system prompt engineering for\ndeployed AI agents. Our work highlights the failure of current alignment\nmethods to generalise to LLM agents, and underscores the need for further\npropensity evaluations as autonomous systems become more prevalent.", "AI": {"tldr": "The paper introduces a benchmark, AgentMisalignment, to evaluate the likelihood of LLM agents attempting misaligned behaviors in real-world settings, finding that more capable models and certain personas increase misalignment risks.", "motivation": "To address the poorly understood likelihood of LLM agents attempting misaligned behaviors in real-world scenarios, given the rise of such agents and associated risks.", "method": "Developed the AgentMisalignment benchmark with realistic scenarios, categorized misaligned behaviors (e.g., goal-guarding, power-seeking), and evaluated frontier models while varying system prompts to assess personality impacts.", "result": "More capable models showed higher misalignment, and system prompts (personas) unpredictably influenced misalignment tendencies, sometimes more than model choice itself.", "conclusion": "Current alignment methods fail to generalize to LLM agents, emphasizing the need for further propensity evaluations as autonomous systems proliferate, and highlighting the critical role of system prompt engineering."}}
{"id": "2506.03230", "pdf": "https://arxiv.org/pdf/2506.03230", "abs": "https://arxiv.org/abs/2506.03230", "authors": ["Selcuk Gurses", "Aozhong Zhang", "Yanxia Deng", "Xun Dong", "Xin Li", "Naigang Wang", "Penghang Yin", "Zi Yang"], "title": "DiaBlo: Diagonal Blocks Are Sufficient For Finetuning", "categories": ["cs.LG", "cs.AI", "cs.CL", "math.OC"], "comment": null, "summary": "Finetuning is a critical step for adapting large language models (LLMs) to\ndomain-specific downstream tasks. To mitigate the substantial computational and\nmemory costs of full-model fine-tuning, Parameter-Efficient Finetuning (PEFT)\nmethods have been proposed to update only a small subset of model parameters.\nHowever, performance gaps between PEFT approaches and full-model fine-tuning\nstill exist. In this work, we present DiaBlo, a simple yet effective PEFT\napproach that updates only the diagonal blocks of selected model weight\nmatrices. Unlike Low Rank Adaptation (LoRA) and its variants, DiaBlo eliminates\nthe need for low rank matrix products, thereby avoiding the reliance on\nauxiliary initialization schemes or customized optimization strategies to\nimprove convergence. This design leads to stable and robust convergence while\nmaintaining comparable memory efficiency and training speed to LoRA. We conduct\nextensive experiments across a range of tasks, including commonsense reasoning,\narithmetic reasoning, code generation, and safety alignment, to evaluate the\neffectiveness and efficiency of DiaBlo. Across these benchmarks, DiaBlo\ndemonstrates strong and consistent performance while maintaining high memory\nefficiency and fast finetuning speed. Codes are available at\nhttps://github.com/ziyangjoy/DiaBlo.", "AI": {"tldr": "DiaBlo is a Parameter-Efficient Finetuning (PEFT) method that updates only diagonal blocks of weight matrices, offering stable convergence and efficiency comparable to LoRA without low-rank constraints.", "motivation": "To address the performance gaps and computational inefficiencies of existing PEFT methods compared to full-model fine-tuning.", "method": "DiaBlo updates only diagonal blocks of selected weight matrices, avoiding low-rank products and auxiliary initialization schemes.", "result": "DiaBlo shows strong, consistent performance across tasks like reasoning, code generation, and safety alignment, with high memory efficiency and speed.", "conclusion": "DiaBlo is a simple, effective PEFT approach that bridges performance gaps while maintaining efficiency."}}
{"id": "2505.16044", "pdf": "https://arxiv.org/pdf/2505.16044", "abs": "https://arxiv.org/abs/2505.16044", "authors": ["Gowtham Premananth", "Philip Resnik", "Sonia Bansal", "Deanna L. Kelly", "Carol Espy-Wilson"], "title": "Multimodal Biomarkers for Schizophrenia: Towards Individual Symptom Severity Estimation", "categories": ["eess.AS", "cs.LG", "eess.IV", "eess.SP"], "comment": "Accepted to be presented at Interspeech 2025", "summary": "Studies on schizophrenia assessments using deep learning typically treat it\nas a classification task to detect the presence or absence of the disorder,\noversimplifying the condition and reducing its clinical applicability. This\ntraditional approach overlooks the complexity of schizophrenia, limiting its\npractical value in healthcare settings. This study shifts the focus to\nindividual symptom severity estimation using a multimodal approach that\nintegrates speech, video, and text inputs. We develop unimodal models for each\nmodality and a multimodal framework to improve accuracy and robustness. By\ncapturing a more detailed symptom profile, this approach can help in enhancing\ndiagnostic precision and support personalized treatment, offering a scalable\nand objective tool for mental health assessment.", "AI": {"tldr": "The study proposes a multimodal deep learning approach to estimate individual symptom severity in schizophrenia, moving beyond binary classification for better clinical utility.", "motivation": "Traditional binary classification oversimplifies schizophrenia, limiting clinical applicability. This study aims to capture detailed symptom profiles for improved diagnosis and treatment.", "method": "Unimodal models for speech, video, and text are developed, followed by a multimodal framework to enhance accuracy and robustness.", "result": "The approach provides a more detailed symptom profile, improving diagnostic precision and supporting personalized treatment.", "conclusion": "This scalable, objective tool enhances mental health assessment by addressing the complexity of schizophrenia."}}
{"id": "2506.03216", "pdf": "https://arxiv.org/pdf/2506.03216", "abs": "https://arxiv.org/abs/2506.03216", "authors": ["Arbind Agrahari Baniya", "Tsz-Kwan Lee", "Peter Eklund", "Sunil Aryal"], "title": "A Survey of Deep Learning Video Super-Resolution", "categories": ["eess.IV", "cs.CV", "cs.LG"], "comment": "This paper has been published in IEEE Transactions on Emerging Topics\n  in Computational Intelligence, vol. 8, no. 4, pp. 2655-2676, Aug. 2024, doi:\n  10.1109/TETCI.2024.3398015", "summary": "Video super-resolution (VSR) is a prominent research topic in low-level\ncomputer vision, where deep learning technologies have played a significant\nrole. The rapid progress in deep learning and its applications in VSR has led\nto a proliferation of tools and techniques in the literature. However, the\nusage of these methods is often not adequately explained, and decisions are\nprimarily driven by quantitative improvements. Given the significance of VSR's\npotential influence across multiple domains, it is imperative to conduct a\ncomprehensive analysis of the elements and deep learning methodologies employed\nin VSR research. This methodical analysis will facilitate the informed\ndevelopment of models tailored to specific application needs. In this paper, we\npresent an overarching overview of deep learning-based video super-resolution\nmodels, investigating each component and discussing its implications.\nFurthermore, we provide a synopsis of key components and technologies employed\nby state-of-the-art and earlier VSR models. By elucidating the underlying\nmethodologies and categorising them systematically, we identified trends,\nrequirements, and challenges in the domain. As a first-of-its-kind survey of\ndeep learning-based VSR models, this work also establishes a multi-level\ntaxonomy to guide current and future VSR research, enhancing the maturation and\ninterpretation of VSR practices for various practical applications.", "AI": {"tldr": "A comprehensive survey of deep learning-based video super-resolution (VSR) models, analyzing components, methodologies, and trends to guide future research and applications.", "motivation": "The rapid growth of deep learning in VSR lacks systematic analysis, necessitating a methodical review to inform model development for specific needs.", "method": "The paper provides an overview of VSR models, categorizes methodologies, and establishes a taxonomy to identify trends and challenges.", "result": "Identified key components, trends, and challenges in VSR, along with a multi-level taxonomy for future research guidance.", "conclusion": "This survey enhances understanding and interpretation of VSR practices, aiding tailored model development for diverse applications."}}
{"id": "2505.19931", "pdf": "https://arxiv.org/pdf/2505.19931", "abs": "https://arxiv.org/abs/2505.19931", "authors": ["Qixi Zheng", "Yushen Chen", "Zhikang Niu", "Ziyang Ma", "Xiaofei Wang", "Kai Yu", "Xie Chen"], "title": "Accelerating Flow-Matching-Based Text-to-Speech via Empirically Pruned Step Sampling", "categories": ["eess.AS", "cs.SD"], "comment": null, "summary": "Flow-matching-based text-to-speech (TTS) models, such as Voicebox, E2 TTS,\nand F5-TTS, have attracted significant attention in recent years. These models\nrequire multiple sampling steps to reconstruct speech from noise, making\ninference speed a key challenge. Reducing the number of sampling steps can\ngreatly improve inference efficiency. To this end, we introduce Fast F5-TTS, a\ntraining-free approach to accelerate the inference of flow-matching-based TTS\nmodels. By inspecting the sampling trajectory of F5-TTS, we identify redundant\nsteps and propose Empirically Pruned Step Sampling (EPSS), a non-uniform\ntime-step sampling strategy that effectively reduces the number of sampling\nsteps. Our approach achieves a 7-step generation with an inference RTF of 0.030\non an NVIDIA RTX 3090 GPU, making it 4 times faster than the original F5-TTS\nwhile maintaining comparable performance. Furthermore, EPSS performs well on E2\nTTS models, demonstrating its strong generalization ability.", "AI": {"tldr": "Fast F5-TTS accelerates flow-matching-based TTS models by reducing sampling steps with Empirically Pruned Step Sampling (EPSS), achieving 4x speedup without performance loss.", "motivation": "Flow-matching-based TTS models suffer from slow inference due to multiple sampling steps. Reducing steps can improve efficiency.", "method": "Introduces EPSS, a non-uniform time-step sampling strategy, to prune redundant steps in F5-TTS.", "result": "Achieves 7-step generation with 0.030 RTF, 4x faster than F5-TTS, while maintaining performance. Generalizes well to E2 TTS.", "conclusion": "EPSS is a training-free, effective method to speed up flow-matching-based TTS models without compromising quality."}}
{"id": "2506.03476", "pdf": "https://arxiv.org/pdf/2506.03476", "abs": "https://arxiv.org/abs/2506.03476", "authors": ["Chuyuan Li", "Raymond Li", "Thalia S. Field", "Giuseppe Carenini"], "title": "Delta-KNN: Improving Demonstration Selection in In-Context Learning for Alzheimer's Disease Detection", "categories": ["cs.CL"], "comment": null, "summary": "Alzheimer's Disease (AD) is a progressive neurodegenerative disorder that\nleads to dementia, and early intervention can greatly benefit from analyzing\nlinguistic abnormalities. In this work, we explore the potential of Large\nLanguage Models (LLMs) as health assistants for AD diagnosis from\npatient-generated text using in-context learning (ICL), where tasks are defined\nthrough a few input-output examples. Empirical results reveal that conventional\nICL methods, such as similarity-based selection, perform poorly for AD\ndiagnosis, likely due to the inherent complexity of this task. To address this,\nwe introduce Delta-KNN, a novel demonstration selection strategy that enhances\nICL performance. Our method leverages a delta score to assess the relative\ngains of each training example, coupled with a KNN-based retriever that\ndynamically selects optimal \"representatives\" for a given input. Experiments on\ntwo AD detection datasets across three open-source LLMs demonstrate that\nDelta-KNN consistently outperforms existing ICL baselines. Notably, when using\nthe Llama-3.1 model, our approach achieves new state-of-the-art results,\nsurpassing even supervised classifiers.", "AI": {"tldr": "Delta-KNN, a novel demonstration selection strategy, improves in-context learning (ICL) for Alzheimer's Disease (AD) diagnosis using patient-generated text, outperforming conventional methods and achieving state-of-the-art results.", "motivation": "Early intervention in AD can benefit from linguistic analysis, but conventional ICL methods perform poorly due to task complexity.", "method": "Introduces Delta-KNN, combining delta scores for training example gains and KNN-based retrieval to dynamically select optimal examples.", "result": "Delta-KNN outperforms existing ICL baselines across three LLMs, achieving state-of-the-art results with Llama-3.1.", "conclusion": "Delta-KNN enhances AD diagnosis via ICL, demonstrating superior performance and potential for clinical applications."}}
{"id": "2506.03195", "pdf": "https://arxiv.org/pdf/2506.03195", "abs": "https://arxiv.org/abs/2506.03195", "authors": ["Yunqi Hong", "Sohyun An", "Andrew Bai", "Neil Y. C. Lin", "Cho-Jui Hsieh"], "title": "Unlabeled Data Improves Fine-Grained Image Zero-shot Classification with Multimodal LLMs", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": null, "summary": "Despite Multimodal Large Language Models (MLLMs) showing promising results on\ngeneral zero-shot image classification tasks, fine-grained image classification\nremains challenging. It demands precise attention to subtle visual details to\ndistinguish between visually similar subcategories--details that MLLMs may\neasily overlook without explicit guidance. To address this, we introduce\nAutoSEP, an iterative self-supervised prompt learning framework designed to\nenhance MLLM fine-grained classification capabilities in a fully unsupervised\nmanner. Our core idea is to leverage unlabeled data to learn a description\nprompt that guides MLLMs in identifying crucial discriminative features within\nan image, and boosts classification accuracy. We developed an automatic\nself-enhancing prompt learning framework called AutoSEP to iteratively improve\nthe description prompt using unlabeled data, based on instance-level\nclassification scoring function. AutoSEP only requires black-box access to\nMLLMs, eliminating the need for any training or fine-tuning. We evaluate our\napproach on multiple fine-grained classification datasets. It consistently\noutperforms other unsupervised baselines, demonstrating the effectiveness of\nour self-supervised optimization framework. Notably, AutoSEP on average\nimproves 13 percent over standard zero-shot classification and 5 percent over\nthe best-performing baselines. Code is available at:\nhttps://github.com/yq-hong/AutoSEP", "AI": {"tldr": "AutoSEP is a self-supervised prompt learning framework that enhances MLLMs' fine-grained image classification without training, improving accuracy by 13% over zero-shot and 5% over baselines.", "motivation": "Fine-grained image classification is challenging for MLLMs due to overlooked subtle details. AutoSEP addresses this by leveraging unlabeled data to guide MLLMs.", "method": "AutoSEP iteratively improves a description prompt using unlabeled data and instance-level scoring, requiring only black-box MLLM access.", "result": "AutoSEP outperforms baselines, improving accuracy by 13% over zero-shot and 5% over the best baseline.", "conclusion": "AutoSEP effectively enhances MLLMs' fine-grained classification without training, demonstrating the value of self-supervised prompt learning."}}
{"id": "2506.04022", "pdf": "https://arxiv.org/pdf/2506.04022", "abs": "https://arxiv.org/abs/2506.04022", "authors": ["Qiyue Xia", "J. Michael Herrmann"], "title": "Interpretability by Design for Efficient Multi-Objective Reinforcement Learning", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "Multi-objective reinforcement learning (MORL) aims at optimising several,\noften conflicting goals in order to improve flexibility and reliability of RL\nin practical tasks. This can be achieved by finding diverse policies that are\noptimal for some objective preferences and non-dominated by optimal policies\nfor other preferences so that they form a Pareto front in the multi-objective\nperformance space. The relation between the multi-objective performance space\nand the parameter space that represents the policies is generally non-unique.\nUsing a training scheme that is based on a locally linear map between the\nparameter space and the performance space, we show that an approximate Pareto\nfront can provide an interpretation of the current parameter vectors in terms\nof the objectives which enables an effective search within contiguous solution\ndomains. Experiments are conducted with and without retraining across different\ndomains, and the comparison with previous methods demonstrates the efficiency\nof our approach.", "AI": {"tldr": "The paper presents a method for multi-objective reinforcement learning (MORL) using a locally linear map to approximate Pareto fronts, improving search efficiency in contiguous solution domains.", "motivation": "MORL aims to optimize conflicting goals for flexible and reliable RL in practical tasks by finding diverse, non-dominated policies.", "method": "A training scheme based on a locally linear map between parameter and performance spaces is used to approximate Pareto fronts.", "result": "Experiments show the method's efficiency compared to previous approaches, with and without retraining across domains.", "conclusion": "The approach effectively interprets parameter vectors in terms of objectives, enabling efficient search in contiguous solution domains."}}
{"id": "2506.03234", "pdf": "https://arxiv.org/pdf/2506.03234", "abs": "https://arxiv.org/abs/2506.03234", "authors": ["Kaiwen Duan", "Hongwei Yao", "Yufei Chen", "Ziyun Li", "Tong Qiao", "Zhan Qin", "Cong Wang"], "title": "BadReward: Clean-Label Poisoning of Reward Models in Text-to-Image RLHF", "categories": ["cs.LG", "cs.AI", "cs.CR"], "comment": null, "summary": "Reinforcement Learning from Human Feedback (RLHF) is crucial for aligning\ntext-to-image (T2I) models with human preferences. However, RLHF's feedback\nmechanism also opens new pathways for adversaries. This paper demonstrates the\nfeasibility of hijacking T2I models by poisoning a small fraction of preference\ndata with natural-appearing examples. Specifically, we propose BadReward, a\nstealthy clean-label poisoning attack targeting the reward model in multi-modal\nRLHF. BadReward operates by inducing feature collisions between visually\ncontradicted preference data instances, thereby corrupting the reward model and\nindirectly compromising the T2I model's integrity. Unlike existing alignment\npoisoning techniques focused on single (text) modality, BadReward is\nindependent of the preference annotation process, enhancing its stealth and\npractical threat. Extensive experiments on popular T2I models show that\nBadReward can consistently guide the generation towards improper outputs, such\nas biased or violent imagery, for targeted concepts. Our findings underscore\nthe amplified threat landscape for RLHF in multi-modal systems, highlighting\nthe urgent need for robust defenses. Disclaimer. This paper contains uncensored\ntoxic content that might be offensive or disturbing to the readers.", "AI": {"tldr": "BadReward is a stealthy poisoning attack on RLHF-based T2I models, corrupting reward models via feature collisions in preference data, leading to improper outputs.", "motivation": "To expose vulnerabilities in RLHF for T2I models, showing how adversaries can exploit preference data poisoning.", "method": "Proposes BadReward, a clean-label attack inducing feature collisions in multi-modal preference data to corrupt reward models.", "result": "BadReward successfully guides T2I models to generate biased or violent imagery for targeted concepts.", "conclusion": "Highlights the urgent need for robust defenses in multi-modal RLHF systems due to amplified threats."}}
{"id": "2503.04721", "pdf": "https://arxiv.org/pdf/2503.04721", "abs": "https://arxiv.org/abs/2503.04721", "authors": ["Guan-Ting Lin", "Jiachen Lian", "Tingle Li", "Qirui Wang", "Gopala Anumanchipalli", "Alexander H. Liu", "Hung-yi Lee"], "title": "Full-Duplex-Bench: A Benchmark to Evaluate Full-duplex Spoken Dialogue Models on Turn-taking Capabilities", "categories": ["cs.CL", "eess.AS"], "comment": "Work in Progress", "summary": "Spoken dialogue modeling poses challenges beyond text-based language\nmodeling, requiring real-time interaction, turn-taking, and backchanneling.\nWhile most Spoken Dialogue Models (SDMs) operate in half-duplex mode-processing\none turn at a time - emerging full-duplex SDMs can listen and speak\nsimultaneously, enabling more natural conversations. However, current\nevaluations remain limited, focusing mainly on turn-based metrics or coarse\ncorpus-level analyses. To address this, we introduce Full-Duplex-Bench, a\nbenchmark that systematically evaluates key interactive behaviors: pause\nhandling, backchanneling, turn-taking, and interruption management. Our\nframework uses automatic metrics for consistent, reproducible assessment and\nprovides a fair, fast evaluation setup. By releasing our benchmark and code, we\naim to advance spoken dialogue modeling and foster the development of more\nnatural and engaging SDMs.", "AI": {"tldr": "The paper introduces Full-Duplex-Bench, a benchmark for evaluating full-duplex spoken dialogue models (SDMs) on interactive behaviors like pause handling and turn-taking, aiming to improve naturalness in conversations.", "motivation": "Current evaluations of SDMs are limited to turn-based metrics or coarse analyses, lacking systematic assessment of interactive behaviors essential for natural dialogue.", "method": "The authors propose Full-Duplex-Bench, a framework using automatic metrics to evaluate pause handling, backchanneling, turn-taking, and interruption management.", "result": "The benchmark provides a consistent, reproducible, and fast evaluation setup for SDMs.", "conclusion": "By releasing the benchmark and code, the authors aim to advance SDM development toward more natural and engaging spoken dialogue systems."}}
{"id": "2506.03217", "pdf": "https://arxiv.org/pdf/2506.03217", "abs": "https://arxiv.org/abs/2506.03217", "authors": ["Pierrick Coup\u00e9", "Boris Mansencal", "Flor\u00e9al Morandat", "Sergio Morell-Ortega", "Nicolas Villain", "Jose V. Manj\u00f3n", "Vincent Planche"], "title": "petBrain: A New Pipeline for Amyloid, Tau Tangles and Neurodegeneration Quantification Using PET and MRI", "categories": ["eess.IV", "cs.CV"], "comment": null, "summary": "INTRODUCTION: Quantification of amyloid plaques (A), neurofibrillary tangles\n(T2), and neurodegeneration (N) using PET and MRI is critical for Alzheimer's\ndisease (AD) diagnosis and prognosis. Existing pipelines face limitations\nregarding processing time, variability in tracer types, and challenges in\nmultimodal integration.\n  METHODS: We developed petBrain, a novel end-to-end processing pipeline for\namyloid-PET, tau-PET, and structural MRI. It leverages deep learning-based\nsegmentation, standardized biomarker quantification (Centiloid, CenTauR,\nHAVAs), and simultaneous estimation of A, T2, and N biomarkers. The pipeline is\nimplemented as a web-based platform, requiring no local computational\ninfrastructure or specialized software knowledge.\n  RESULTS: petBrain provides reliable and rapid biomarker quantification, with\nresults comparable to existing pipelines for A and T2. It shows strong\nconcordance with data processed in ADNI databases. The staging and\nquantification of A/T2/N by petBrain demonstrated good agreement with\nCSF/plasma biomarkers, clinical status, and cognitive performance.\n  DISCUSSION: petBrain represents a powerful and openly accessible platform for\nstandardized AD biomarker analysis, facilitating applications in clinical\nresearch.", "AI": {"tldr": "petBrain is a new web-based pipeline for AD biomarker analysis, offering fast, reliable, and standardized quantification of amyloid, tau, and neurodegeneration using PET and MRI.", "motivation": "Existing pipelines for AD diagnosis and prognosis have limitations in processing time, tracer variability, and multimodal integration.", "method": "petBrain uses deep learning-based segmentation and standardized biomarker quantification (Centiloid, CenTauR, HAVAs) for amyloid-PET, tau-PET, and MRI. It's a web-based platform requiring no local infrastructure.", "result": "petBrain matches existing pipelines in reliability for amyloid and tau quantification, aligns with ADNI data, and correlates well with CSF/plasma biomarkers, clinical status, and cognition.", "conclusion": "petBrain is a robust, accessible tool for standardized AD biomarker analysis, enhancing clinical research."}}
{"id": "2506.03483", "pdf": "https://arxiv.org/pdf/2506.03483", "abs": "https://arxiv.org/abs/2506.03483", "authors": ["Jun Rao", "Zepeng Lin", "Xuebo Liu", "Xiaopeng Ke", "Lian Lian", "Dong Jin", "Shengjun Cheng", "Jun Yu", "Min Zhang"], "title": "APT: Improving Specialist LLM Performance with Weakness Case Acquisition and Iterative Preference Training", "categories": ["cs.CL"], "comment": "ACL2025 Findings", "summary": "Large Language Models (LLMs) often require domain-specific fine-tuning to\naddress targeted tasks, which risks degrading their general capabilities.\nMaintaining a balance between domain-specific enhancements and general model\nutility is a key challenge. This paper proposes a novel approach named APT\n(Weakness Case Acquisition and Iterative Preference Training) to enhance\ndomain-specific performance with self-generated dis-preferred weakness data\n(bad cases and similar cases). APT uniquely focuses on training the model using\nonly those samples where errors occur, alongside a small, similar set of\nsamples retrieved for this purpose. This targeted training minimizes\ninterference with the model's existing knowledge base, effectively retaining\ngeneric capabilities. Experimental results on the LLama-2 and Mistral-V0.3\nmodels across various benchmarks demonstrate that APT ensures no reduction in\ngeneric capacity and achieves superior performance on downstream tasks compared\nto various existing methods. This validates our method as an effective strategy\nfor enhancing domain-specific capabilities without sacrificing the model's\nbroader applicability.", "AI": {"tldr": "APT enhances domain-specific LLM performance using self-generated weakness data, preserving general capabilities.", "motivation": "Balancing domain-specific improvements with general model utility is challenging.", "method": "APT uses self-generated dis-preferred weakness data (bad/similar cases) for targeted training.", "result": "APT retains generic capacity and outperforms existing methods on downstream tasks.", "conclusion": "APT effectively boosts domain-specific performance without compromising broader applicability."}}
{"id": "2506.03197", "pdf": "https://arxiv.org/pdf/2506.03197", "abs": "https://arxiv.org/abs/2506.03197", "authors": ["Baode Wang", "Biao Wu", "Weizhen Li", "Meng Fang", "Yanjie Liang", "Zuming Huang", "Haozhe Wang", "Jun Huang", "Ling Chen", "Wei Chu", "Yuan Qi"], "title": "Infinity Parser: Layout Aware Reinforcement Learning for Scanned Document Parsing", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.LG"], "comment": "16 pages, 12 figures", "summary": "Automated parsing of scanned documents into richly structured,\nmachine-readable formats remains a critical bottleneck in Document AI, as\ntraditional multi-stage pipelines suffer from error propagation and limited\nadaptability to diverse layouts. We introduce layoutRL, an end-to-end\nreinforcement learning framework that trains models to be explicitly\nlayout-aware by optimizing a composite reward of normalized edit distance,\nparagraph count accuracy, and reading order preservation. Leveraging our newly\nreleased dataset, Infinity-Doc-55K, which combines 55K high-fidelity synthetic\nscanned document parsing data with expert-filtered real-world documents, we\ninstantiate layoutRL in a vision-language-model-based parser called\nInfinity-Parser. Evaluated on English and Chinese benchmarks for OCR, table and\nformula extraction, and reading order detection, Infinity-Parser achieves new\nstate-of-the-art performance in both accuracy and structural fidelity,\noutpacing specialist pipelines and general-purpose vision-language models. We\nwill publicly release our code and dataset to accelerate progress in robust\ndocument understanding.", "AI": {"tldr": "layoutRL is an end-to-end reinforcement learning framework for parsing scanned documents, achieving state-of-the-art performance with its Infinity-Parser model.", "motivation": "Traditional multi-stage pipelines for document parsing suffer from error propagation and limited adaptability to diverse layouts.", "method": "Uses layoutRL, a reinforcement learning framework optimizing composite rewards (edit distance, paragraph count, reading order), and a dataset (Infinity-Doc-55K) with synthetic and real-world documents.", "result": "Infinity-Parser outperforms specialist pipelines and general-purpose models in OCR, table/formula extraction, and reading order detection.", "conclusion": "The framework and dataset will be publicly released to advance robust document understanding."}}
{"id": "2506.04133", "pdf": "https://arxiv.org/pdf/2506.04133", "abs": "https://arxiv.org/abs/2506.04133", "authors": ["Shaina Raza", "Ranjan Sapkota", "Manoj Karkee", "Christos Emmanouilidis"], "title": "TRiSM for Agentic AI: A Review of Trust, Risk, and Security Management in LLM-based Agentic Multi-Agent Systems", "categories": ["cs.AI"], "comment": null, "summary": "Agentic AI systems, built on large language models (LLMs) and deployed in\nmulti-agent configurations, are redefining intelligent autonomy, collaboration\nand decision-making across enterprise and societal domains. This review\npresents a structured analysis of Trust, Risk, and Security Management (TRiSM)\nin the context of LLM-based agentic multi-agent systems (AMAS). We begin by\nexamining the conceptual foundations of agentic AI, its architectural\ndifferences from traditional AI agents, and the emerging system designs that\nenable scalable, tool-using autonomy. The TRiSM in the agentic AI framework is\nthen detailed through four pillars governance, explainability, ModelOps, and\nprivacy/security each contextualized for agentic LLMs. We identify unique\nthreat vectors and introduce a comprehensive risk taxonomy for the agentic AI\napplications, supported by case studies illustrating real-world\nvulnerabilities. Furthermore, the paper also surveys trust-building mechanisms,\ntransparency and oversight techniques, and state-of-the-art explainability\nstrategies in distributed LLM agent systems. Additionally, metrics for\nevaluating trust, interpretability, and human-centered performance are reviewed\nalongside open benchmarking challenges. Security and privacy are addressed\nthrough encryption, adversarial defense, and compliance with evolving AI\nregulations. The paper concludes with a roadmap for responsible agentic AI,\nproposing research directions to align emerging multi-agent systems with robust\nTRiSM principles for safe, accountable, and transparent deployment.", "AI": {"tldr": "The paper reviews Trust, Risk, and Security Management (TRiSM) in LLM-based agentic multi-agent systems (AMAS), covering governance, explainability, ModelOps, and privacy/security, with case studies and future research directions.", "motivation": "To address the unique challenges of trust, risk, and security in agentic AI systems built on LLMs, ensuring safe and accountable deployment.", "method": "Structured analysis of TRiSM pillars (governance, explainability, ModelOps, privacy/security), threat vectors, risk taxonomy, case studies, and trust-building mechanisms.", "result": "Identifies vulnerabilities, proposes mitigation strategies, and reviews metrics for trust and performance in distributed LLM agent systems.", "conclusion": "Proposes a roadmap for responsible agentic AI, aligning multi-agent systems with robust TRiSM principles for transparency and accountability."}}
{"id": "2506.03267", "pdf": "https://arxiv.org/pdf/2506.03267", "abs": "https://arxiv.org/abs/2506.03267", "authors": ["Shahbaz Rezaei", "Avishai Halev", "Xin Liu"], "title": "On the Necessity of Multi-Domain Explanation: An Uncertainty Principle Approach for Deep Time Series Models", "categories": ["cs.LG", "cs.HC"], "comment": null, "summary": "A prevailing approach to explain time series models is to generate\nattribution in time domain. A recent development in time series XAI is the\nconcept of explanation spaces, where any model trained in the time domain can\nbe interpreted with any existing XAI method in alternative domains, such as\nfrequency. The prevailing approach is to present XAI attributions either in the\ntime domain or in the domain where the attribution is most sparse. In this\npaper, we demonstrate that in certain cases, XAI methods can generate\nattributions that highlight fundamentally different features in the time and\nfrequency domains that are not direct counterparts of one another. This\nsuggests that both domains' attributions should be presented to achieve a more\ncomprehensive interpretation. Thus it shows the necessity of multi-domain\nexplanation. To quantify when such cases arise, we introduce the uncertainty\nprinciple (UP), originally developed in quantum mechanics and later studied in\nharmonic analysis and signal processing, to the XAI literature. This principle\nestablishes a lower bound on how much a signal can be simultaneously localized\nin both the time and frequency domains. By leveraging this concept, we assess\nwhether attributions in the time and frequency domains violate this bound,\nindicating that they emphasize distinct features. In other words, UP provides a\nsufficient condition that the time and frequency domain explanations do not\nmatch and, hence, should be both presented to the end user. We validate the\neffectiveness of this approach across various deep learning models, XAI\nmethods, and a wide range of classification and forecasting datasets. The\nfrequent occurrence of UP violations across various datasets and XAI methods\nhighlights the limitations of existing approaches that focus solely on\ntime-domain explanations. This underscores the need for multi-domain\nexplanations as a new paradigm.", "AI": {"tldr": "The paper introduces the uncertainty principle (UP) from quantum mechanics to time series XAI, showing that time and frequency domain attributions can highlight different features, necessitating multi-domain explanations.", "motivation": "Existing time series XAI methods often focus on single-domain explanations (time or frequency), potentially missing distinct features highlighted in other domains.", "method": "The paper applies the uncertainty principle (UP) to quantify when time and frequency domain attributions diverge, validating this across models, XAI methods, and datasets.", "result": "UP violations frequently occur, indicating that time and frequency domain explanations often highlight non-counterpart features, requiring both for comprehensive interpretation.", "conclusion": "Multi-domain explanations are essential for accurate and comprehensive interpretation of time series models, as demonstrated by UP violations."}}
{"id": "2506.03238", "pdf": "https://arxiv.org/pdf/2506.03238", "abs": "https://arxiv.org/abs/2506.03238", "authors": ["Ziheng Zhao", "Lisong Dai", "Ya Zhang", "Yanfeng Wang", "Weidi Xie"], "title": "Rethinking Whole-Body CT Image Interpretation: An Abnormality-Centric Approach", "categories": ["eess.IV", "cs.AI", "cs.CV"], "comment": null, "summary": "Automated interpretation of CT images-particularly localizing and describing\nabnormal findings across multi-plane and whole-body scans-remains a significant\nchallenge in clinical radiology. This work aims to address this challenge\nthrough four key contributions: (i) On taxonomy, we collaborate with senior\nradiologists to propose a comprehensive hierarchical classification system,\nwith 404 representative abnormal findings across all body regions; (ii) On\ndata, we contribute a dataset containing over 14.5K CT images from multiple\nplanes and all human body regions, and meticulously provide grounding\nannotations for over 19K abnormalities, each linked to the detailed description\nand cast into the taxonomy; (iii) On model development, we propose\nOminiAbnorm-CT, which can automatically ground and describe abnormal findings\non multi-plane and whole-body CT images based on text queries, while also\nallowing flexible interaction through visual prompts; (iv) On benchmarks, we\nestablish three representative evaluation tasks based on real clinical\nscenarios. Through extensive experiments, we show that OminiAbnorm-CT can\nsignificantly outperform existing methods on all the tasks and metrics.", "AI": {"tldr": "The paper introduces OminiAbnorm-CT, a system for automated interpretation of CT images, including a taxonomy, dataset, model, and benchmarks, outperforming existing methods.", "motivation": "Addressing the challenge of localizing and describing abnormal findings in multi-plane and whole-body CT scans in clinical radiology.", "method": "Proposes a hierarchical taxonomy, contributes a dataset with annotations, develops OminiAbnorm-CT for automated grounding and description, and establishes evaluation tasks.", "result": "OminiAbnorm-CT significantly outperforms existing methods on all tasks and metrics.", "conclusion": "The system advances automated CT image interpretation, offering comprehensive tools for clinical radiology."}}
{"id": "2506.03484", "pdf": "https://arxiv.org/pdf/2506.03484", "abs": "https://arxiv.org/abs/2506.03484", "authors": ["Melkamu Abay Mersha", "Mesay Gemeda Yigezu", "Atnafu Lambebo Tonja", "Hassan Shakil", "Samer Iskander", "Olga Kolesnikova", "Jugal Kalita"], "title": "Explainable AI: XAI-Guided Context-Aware Data Augmentation", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Explainable AI (XAI) has emerged as a powerful tool for improving the\nperformance of AI models, going beyond providing model transparency and\ninterpretability. The scarcity of labeled data remains a fundamental challenge\nin developing robust and generalizable AI models, particularly for low-resource\nlanguages. Conventional data augmentation techniques introduce noise, cause\nsemantic drift, disrupt contextual coherence, lack control, and lead to\noverfitting. To address these challenges, we propose XAI-Guided Context-Aware\nData Augmentation. This novel framework leverages XAI techniques to modify less\ncritical features while selectively preserving most task-relevant features. Our\napproach integrates an iterative feedback loop, which refines augmented data\nover multiple augmentation cycles based on explainability-driven insights and\nthe model performance gain. Our experimental results demonstrate that XAI-SR-BT\nand XAI-PR-BT improve the accuracy of models on hate speech and sentiment\nanalysis tasks by 6.6% and 8.1%, respectively, compared to the baseline, using\nthe Amharic dataset with the XLM-R model. XAI-SR-BT and XAI-PR-BT outperform\nexisting augmentation techniques by 4.8% and 5%, respectively, on the same\ndataset and model. Overall, XAI-SR-BT and XAI-PR-BT consistently outperform\nboth baseline and conventional augmentation techniques across all tasks and\nmodels. This study provides a more controlled, interpretable, and context-aware\nsolution to data augmentation, addressing critical limitations of existing\naugmentation techniques and offering a new paradigm shift for leveraging XAI\ntechniques to enhance AI model training.", "AI": {"tldr": "The paper introduces XAI-Guided Context-Aware Data Augmentation, a framework using XAI to enhance data augmentation by preserving task-relevant features, improving model accuracy for low-resource languages.", "motivation": "Addressing the challenges of labeled data scarcity and noise in conventional data augmentation for low-resource languages.", "method": "Proposes XAI-SR-BT and XAI-PR-BT, leveraging XAI to modify less critical features while preserving task-relevant ones, with an iterative feedback loop.", "result": "Improves accuracy by 6.6% and 8.1% for hate speech and sentiment analysis, outperforming baselines by 4.8% and 5%.", "conclusion": "The framework offers a controlled, interpretable, and context-aware solution, advancing AI model training with XAI."}}
{"id": "2506.03198", "pdf": "https://arxiv.org/pdf/2506.03198", "abs": "https://arxiv.org/abs/2506.03198", "authors": ["Hao Yin", "Lijun Gu", "Paritosh Parmar", "Lin Xu", "Tianxiao Guo", "Weiwei Fu", "Yang Zhang", "Tianyou Zheng"], "title": "FLEX: A Large-Scale Multi-Modal Multi-Action Dataset for Fitness Action Quality Assessment", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "With the increasing awareness of health and the growing desire for aesthetic\nphysique, fitness has become a prevailing trend. However, the potential risks\nassociated with fitness training, especially with weight-loaded fitness\nactions, cannot be overlooked. Action Quality Assessment (AQA), a technology\nthat quantifies the quality of human action and provides feedback, holds the\npotential to assist fitness enthusiasts of varying skill levels in achieving\nbetter training outcomes. Nevertheless, current AQA methodologies and datasets\nare limited to single-view competitive sports scenarios and RGB modality and\nlack professional assessment and guidance of fitness actions. To address this\ngap, we propose the FLEX dataset, the first multi-modal, multi-action,\nlarge-scale dataset that incorporates surface electromyography (sEMG) signals\ninto AQA. FLEX utilizes high-precision MoCap to collect 20 different\nweight-loaded actions performed by 38 subjects across 3 different skill levels\nfor 10 repetitions each, containing 5 different views of the RGB video, 3D\npose, sEMG, and physiological information. Additionally, FLEX incorporates\nknowledge graphs into AQA, constructing annotation rules in the form of penalty\nfunctions that map weight-loaded actions, action keysteps, error types, and\nfeedback. We conducted various baseline methodologies on FLEX, demonstrating\nthat multimodal data, multiview data, and fine-grained annotations\nsignificantly enhance model performance. FLEX not only advances AQA\nmethodologies and datasets towards multi-modal and multi-action scenarios but\nalso fosters the integration of artificial intelligence within the fitness\ndomain. Dataset and code are available at\nhttps://haoyin116.github.io/FLEX_Dataset.", "AI": {"tldr": "The paper introduces FLEX, a multi-modal, large-scale dataset for Action Quality Assessment (AQA) in fitness, addressing gaps in current AQA methods by incorporating sEMG signals, multi-view data, and knowledge graphs.", "motivation": "Current AQA methods are limited to single-view competitive sports and lack fitness-specific assessment. The need for better fitness training outcomes drives the creation of FLEX.", "method": "FLEX collects multi-modal data (RGB video, 3D pose, sEMG, physiological info) from 38 subjects performing 20 weight-loaded actions across 3 skill levels. It uses knowledge graphs for annotation.", "result": "Baseline experiments show multimodal, multiview data and fine-grained annotations improve model performance.", "conclusion": "FLEX advances AQA towards multi-modal, multi-action scenarios and supports AI integration in fitness."}}
{"id": "2506.04135", "pdf": "https://arxiv.org/pdf/2506.04135", "abs": "https://arxiv.org/abs/2506.04135", "authors": ["Pei Yang", "Hai Ci", "Mike Zheng Shou"], "title": "macOSWorld: A Multilingual Interactive Benchmark for GUI Agents", "categories": ["cs.AI"], "comment": null, "summary": "Graphical User Interface (GUI) agents show promising capabilities for\nautomating computer-use tasks and facilitating accessibility, but existing\ninteractive benchmarks are mostly English-only, covering web-use or Windows,\nLinux, and Android environments, but not macOS. macOS is a major OS with\ndistinctive GUI patterns and exclusive applications. To bridge the gaps, we\npresent macOSWorld, the first comprehensive benchmark for evaluating GUI agents\non macOS. macOSWorld features 202 multilingual interactive tasks across 30\napplications (28 macOS-exclusive), with task instructions and OS interfaces\noffered in 5 languages (English, Chinese, Arabic, Japanese, and Russian). As\nGUI agents are shown to be vulnerable to deception attacks, macOSWorld also\nincludes a dedicated safety benchmarking subset. Our evaluation on six GUI\nagents reveals a dramatic gap: proprietary computer-use agents lead at above\n30% success rate, while open-source lightweight research models lag at below\n2%, highlighting the need for macOS domain adaptation. Multilingual benchmarks\nalso expose common weaknesses, especially in Arabic, with a 27.5% average\ndegradation compared to English. Results from safety benchmarking also\nhighlight that deception attacks are more general and demand immediate\nattention. macOSWorld is available at https://github.com/showlab/macosworld.", "AI": {"tldr": "macOSWorld is the first benchmark for GUI agents on macOS, featuring 202 multilingual tasks across 30 apps, including safety testing. It reveals performance gaps and multilingual challenges.", "motivation": "Existing GUI benchmarks lack macOS coverage, despite its unique patterns and apps. macOSWorld fills this gap.", "method": "macOSWorld includes 202 tasks in 5 languages, covering 30 macOS apps (28 exclusive), with a safety benchmarking subset.", "result": "Proprietary agents outperform open-source ones (30% vs. 2% success). Multilingual tasks show weaknesses, especially in Arabic. Safety tests reveal deception vulnerabilities.", "conclusion": "macOSWorld highlights the need for macOS adaptation and multilingual robustness in GUI agents, with safety concerns requiring attention."}}
{"id": "2506.03302", "pdf": "https://arxiv.org/pdf/2506.03302", "abs": "https://arxiv.org/abs/2506.03302", "authors": ["James Bagrow", "Josh Bongard"], "title": "Multi-Exit Kolmogorov-Arnold Networks: enhancing accuracy and parsimony", "categories": ["cs.LG", "cs.NE", "physics.data-an", "stat.ML"], "comment": "14 pages, 7 figures, 2 tables", "summary": "Kolmogorov-Arnold Networks (KANs) uniquely combine high accuracy with\ninterpretability, making them valuable for scientific modeling. However, it is\nunclear a priori how deep a network needs to be for any given task, and deeper\nKANs can be difficult to optimize. Here we introduce multi-exit KANs, where\neach layer includes its own prediction branch, enabling the network to make\naccurate predictions at multiple depths simultaneously. This architecture\nprovides deep supervision that improves training while discovering the right\nlevel of model complexity for each task. Multi-exit KANs consistently\noutperform standard, single-exit versions on synthetic functions, dynamical\nsystems, and real-world datasets. Remarkably, the best predictions often come\nfrom earlier, simpler exits, revealing that these networks naturally identify\nsmaller, more parsimonious and interpretable models without sacrificing\naccuracy. To automate this discovery, we develop a differentiable \"learning to\nexit\" algorithm that balances contributions from exits during training. Our\napproach offers scientists a practical way to achieve both high performance and\ninterpretability, addressing a fundamental challenge in machine learning for\nscientific discovery.", "AI": {"tldr": "Multi-exit KANs improve accuracy and interpretability by allowing predictions at multiple depths, often favoring simpler, earlier exits.", "motivation": "Addressing the challenge of determining optimal depth and optimization difficulty in Kolmogorov-Arnold Networks (KANs) for scientific modeling.", "method": "Introduces multi-exit KANs with prediction branches at each layer and a differentiable 'learning to exit' algorithm.", "result": "Outperforms standard KANs on synthetic and real-world tasks, often using simpler exits for better interpretability.", "conclusion": "Multi-exit KANs provide a practical solution for balancing performance and interpretability in scientific machine learning."}}
{"id": "2506.03420", "pdf": "https://arxiv.org/pdf/2506.03420", "abs": "https://arxiv.org/abs/2506.03420", "authors": ["Muhammad Zubair Hasan", "Fahmida Yasmin Rifat"], "title": "Hybrid Ensemble of Segmentation-Assisted Classification and GBDT for Skin Cancer Detection with Engineered Metadata and Synthetic Lesions from ISIC 2024 Non-Dermoscopic 3D-TBP Images", "categories": ["eess.IV", "cs.CV", "cs.LG"], "comment": "Written as per the requirements of CVPR 2025. It is a 8 page paper\n  without reference", "summary": "Skin cancer is among the most prevalent and life-threatening diseases\nworldwide, with early detection being critical to patient outcomes. This work\npresents a hybrid machine and deep learning-based approach for classifying\nmalignant and benign skin lesions using the SLICE-3D dataset from ISIC 2024,\nwhich comprises 401,059 cropped lesion images extracted from 3D Total Body\nPhotography (TBP), emulating non-dermoscopic, smartphone-like conditions. Our\nmethod combines vision transformers (EVA02) and our designed convolutional ViT\nhybrid (EdgeNeXtSAC) to extract robust features, employing a\nsegmentation-assisted classification pipeline to enhance lesion localization.\nPredictions from these models are fused with a gradient-boosted decision tree\n(GBDT) ensemble enriched by engineered features and patient-specific relational\nmetrics. To address class imbalance and improve generalization, we augment\nmalignant cases with Stable Diffusion-generated synthetic lesions and apply a\ndiagnosis-informed relabeling strategy to harmonize external datasets into a\n3-class format. Using partial AUC (pAUC) above 80 percent true positive rate\n(TPR) as the evaluation metric, our approach achieves a pAUC of 0.1755 -- the\nhighest among all configurations. These results underscore the potential of\nhybrid, interpretable AI systems for skin cancer triage in telemedicine and\nresource-constrained settings.", "AI": {"tldr": "A hybrid machine and deep learning approach for skin lesion classification achieves top performance using a segmentation-assisted pipeline and synthetic data augmentation.", "motivation": "Early detection of skin cancer is critical, and this work aims to improve classification of malignant and benign lesions under non-dermoscopic conditions.", "method": "Combines vision transformers (EVA02) and a convolutional ViT hybrid (EdgeNeXtSAC) with a GBDT ensemble, synthetic data augmentation, and relabeling for imbalance.", "result": "Achieves a pAUC of 0.1755, the highest among tested configurations, demonstrating strong performance for skin cancer triage.", "conclusion": "Hybrid AI systems show promise for telemedicine and resource-limited settings in skin cancer detection."}}
{"id": "2506.03489", "pdf": "https://arxiv.org/pdf/2506.03489", "abs": "https://arxiv.org/abs/2506.03489", "authors": ["Mingxu Tao", "Jie Hu", "Mingchuan Yang", "Yunhuai Liu", "Dongyan Zhao", "Yansong Feng"], "title": "EpiCoDe: Boosting Model Performance Beyond Training with Extrapolation and Contrastive Decoding", "categories": ["cs.CL", "cs.AI"], "comment": "ACL 2025 Findings", "summary": "The remarkable performance of Large language models (LLMs) relies heavily on\nthe availability of abundant high-quality training data. However, the high cost\nof acquiring annotated data often prevents models from obtaining capabilities\nto tackle downstream tasks. In this paper, we introduce a novel method, EpiCoDe\nthat boosts model performance in data-scarcity scenarios without extra\ntraining. We first employ model extrapolation to enhance a finetuned model with\nits inferior version, and then adopt contrastive decoding to further reduce\npredicted errors, by comparing the logit scores given by the extrapolated and\nthe vanilla finetuned model. Experiments across three tasks over four different\nLLMs show that EpiCoDe consistently outperforms existing methods with\nsignificant and robust improvement. We also propose a new theoretical framework\nto reveal the mechanism behind contrastive decoding in data-scarcity scenarios,\nwhich further helps us better understand the effectiveness of EpiCoDe.", "AI": {"tldr": "EpiCoDe improves LLM performance in data-scarce settings without extra training by combining model extrapolation and contrastive decoding.", "motivation": "High-quality annotated data is costly, limiting LLMs' downstream task capabilities. EpiCoDe addresses this by enhancing models without additional training.", "method": "Uses model extrapolation to combine a finetuned model with its inferior version, then applies contrastive decoding to reduce errors by comparing logit scores.", "result": "EpiCoDe outperforms existing methods across three tasks and four LLMs, showing significant and robust improvement.", "conclusion": "EpiCoDe is effective in data-scarce scenarios, and a new theoretical framework explains its success via contrastive decoding."}}
{"id": "2506.03211", "pdf": "https://arxiv.org/pdf/2506.03211", "abs": "https://arxiv.org/abs/2506.03211", "authors": ["Wanting Yang", "Zehui Xiong", "Qianqian Yang", "Ping Zhang", "Merouane Debbah", "Rahim Tafazolli"], "title": "Channel-adaptive Cross-modal Generative Semantic Communication for Point Cloud Transmission", "categories": ["cs.CV", "cs.NI"], "comment": null, "summary": "With the rapid development of autonomous driving and extended reality,\nefficient transmission of point clouds (PCs) has become increasingly important.\nIn this context, we propose a novel channel-adaptive cross-modal generative\nsemantic communication (SemCom) for PC transmission, called GenSeC-PC.\nGenSeC-PC employs a semantic encoder that fuses images and point clouds, where\nimages serve as non-transmitted side information. Meanwhile, the decoder is\nbuilt upon the backbone of PointDif. Such a cross-modal design not only ensures\nhigh compression efficiency but also delivers superior reconstruction\nperformance compared to PointDif. Moreover, to ensure robust transmission and\nreduce system complexity, we design a streamlined and asymmetric\nchannel-adaptive joint semantic-channel coding architecture, where only the\nencoder needs the feedback of average signal-to-noise ratio (SNR) and available\nbandwidth. In addition, rectified denoising diffusion implicit models is\nemployed to accelerate the decoding process to the millisecond level, enabling\nreal-time PC communication. Unlike existing methods, GenSeC-PC leverages\ngenerative priors to ensure reliable reconstruction even from noisy or\nincomplete source PCs. More importantly, it supports fully analog transmission,\nimproving compression efficiency by eliminating the need for error-free side\ninformation transmission common in prior SemCom approaches. Simulation results\nconfirm the effectiveness of cross-modal semantic extraction and dual-metric\nguided fine-tuning, highlighting the framework's robustness across diverse\nconditions, including low SNR, bandwidth limitations, varying numbers of 2D\nimages, and previously unseen objects.", "AI": {"tldr": "GenSeC-PC is a novel semantic communication method for point cloud transmission, leveraging cross-modal fusion (images and point clouds) and generative priors for efficient, robust, and real-time performance.", "motivation": "Efficient point cloud transmission is crucial for autonomous driving and extended reality, but existing methods lack robustness and compression efficiency.", "method": "Uses a cross-modal semantic encoder (fusing images and point clouds) and a decoder based on PointDif, with channel-adaptive joint coding and rectified denoising diffusion for speed.", "result": "Superior reconstruction and compression efficiency, robust performance under low SNR, bandwidth limits, and varying conditions.", "conclusion": "GenSeC-PC outperforms existing methods by enabling analog transmission and eliminating error-free side information needs."}}
{"id": "2506.04210", "pdf": "https://arxiv.org/pdf/2506.04210", "abs": "https://arxiv.org/abs/2506.04210", "authors": ["Soumya Suvra Ghosal", "Souradip Chakraborty", "Avinash Reddy", "Yifu Lu", "Mengdi Wang", "Dinesh Manocha", "Furong Huang", "Mohammad Ghavamzadeh", "Amrit Singh Bedi"], "title": "Does Thinking More always Help? Understanding Test-Time Scaling in Reasoning Models", "categories": ["cs.AI", "cs.CL"], "comment": null, "summary": "Recent trends in test-time scaling for reasoning models (e.g., OpenAI o1,\nDeepSeek R1) have led to a popular belief that extending thinking traces using\nprompts like \"Wait\" or \"Let me rethink\" can improve performance. This raises a\nnatural question: Does thinking more at test-time truly lead to better\nreasoning? To answer this question, we perform a detailed empirical study\nacross models and benchmarks, which reveals a consistent pattern of initial\nperformance improvements from additional thinking followed by a decline, due to\n\"overthinking\". To understand this non-monotonic trend, we consider a simple\nprobabilistic model, which reveals that additional thinking increases output\nvariance-creating an illusion of improved reasoning while ultimately\nundermining precision. Thus, observed gains from \"more thinking\" are not true\nindicators of improved reasoning, but artifacts stemming from the connection\nbetween model uncertainty and evaluation metric. This suggests that test-time\nscaling through extended thinking is not an effective way to utilize the\ninference thinking budget. Recognizing these limitations, we introduce an\nalternative test-time scaling approach, parallel thinking, inspired by\nBest-of-N sampling. Our method generates multiple independent reasoning paths\nwithin the same inference budget and selects the most consistent response via\nmajority vote, achieving up to 20% higher accuracy compared to extended\nthinking. This provides a simple yet effective mechanism for test-time scaling\nof reasoning models.", "AI": {"tldr": "Extended thinking at test-time initially improves reasoning but leads to 'overthinking' and performance decline. Parallel thinking, an alternative method, outperforms extended thinking by 20%.", "motivation": "To investigate whether extended thinking at test-time genuinely enhances reasoning performance or creates an illusion of improvement.", "method": "Empirical study across models and benchmarks, analysis using a probabilistic model, and introduction of parallel thinking (inspired by Best-of-N sampling).", "result": "Extended thinking initially improves performance but later declines due to increased output variance. Parallel thinking achieves up to 20% higher accuracy.", "conclusion": "Extended thinking is ineffective for test-time scaling; parallel thinking is a superior alternative."}}
{"id": "2506.03307", "pdf": "https://arxiv.org/pdf/2506.03307", "abs": "https://arxiv.org/abs/2506.03307", "authors": ["Kristen Goebel", "William Solow", "Paola Pesantez-Cabrera", "Markus Keller", "Alan Fern"], "title": "Budgeted Online Active Learning with Expert Advice and Episodic Priors", "categories": ["cs.LG"], "comment": null, "summary": "This paper introduces a novel approach to budgeted online active learning\nfrom finite-horizon data streams with extremely limited labeling budgets. In\nagricultural applications, such streams might include daily weather data over a\ngrowing season, and labels require costly measurements of weather-dependent\nplant characteristics. Our method integrates two key sources of prior\ninformation: a collection of preexisting expert predictors and episodic\nbehavioral knowledge of the experts based on unlabeled data streams. Unlike\nprevious research on online active learning with experts, our work\nsimultaneously considers query budgets, finite horizons, and episodic\nknowledge, enabling effective learning in applications with severely limited\nlabeling capacity. We demonstrate the utility of our approach through\nexperiments on various prediction problems derived from both a realistic\nagricultural crop simulator and real-world data from multiple grape cultivars.\nThe results show that our method significantly outperforms baseline expert\npredictions, uniform query selection, and existing approaches that consider\nbudgets and limited horizons but neglect episodic knowledge, even under highly\nconstrained labeling budgets.", "AI": {"tldr": "A novel budgeted online active learning method for finite-horizon data streams with limited labeling budgets, leveraging expert predictors and episodic knowledge, outperforming baselines in agricultural applications.", "motivation": "Addressing the challenge of learning from finite-horizon data streams (e.g., daily weather data) with costly labels (e.g., plant measurements) under severe labeling budget constraints.", "method": "Integrates preexisting expert predictors and episodic behavioral knowledge from unlabeled data streams, considering query budgets, finite horizons, and episodic knowledge.", "result": "Outperforms baseline expert predictions, uniform query selection, and existing methods, even with highly constrained labeling budgets.", "conclusion": "The approach effectively combines expert knowledge and episodic behavior for superior performance in budget-limited, finite-horizon learning scenarios."}}
{"id": "2506.03752", "pdf": "https://arxiv.org/pdf/2506.03752", "abs": "https://arxiv.org/abs/2506.03752", "authors": ["Gon\u00e7alo Mesquita", "Ana Rita C\u00f3ias", "Artur Dubrawski", "Alexandre Bernardino"], "title": "Frame-Level Real-Time Assessment of Stroke Rehabilitation Exercises from Video-Level Labeled Data: Task-Specific vs. Foundation Models", "categories": ["eess.IV"], "comment": null, "summary": "The growing demands of stroke rehabilitation have increased the need for\nsolutions to support autonomous exercising. Virtual coaches can provide\nreal-time exercise feedback from video data, helping patients improve motor\nfunction and keep engagement. However, training real-time motion analysis\nsystems demands frame-level annotations, which are time-consuming and costly to\nobtain. In this work, we present a framework that learns to classify individual\nframes from video-level annotations for real-time assessment of compensatory\nmotions in rehabilitation exercises. We use a gradient-based technique and a\npseudo-label selection method to create frame-level pseudo-labels for training\na frame-level classifier. We leverage pre-trained task-specific models - Action\nTransformer, SkateFormer - and a foundation model - MOMENT - for pseudo-label\ngeneration, aiming to improve generalization to new patients. To validate the\napproach, we use the \\textit{SERE} dataset with 18 post-stroke patients\nperforming five rehabilitation exercises annotated on compensatory motions.\nMOMENT achieves better video-level assessment results (AUC = $73\\%$),\noutperforming the baseline LSTM (AUC = $58\\%$). The Action Transformer, with\nthe Integrated Gradient technique, leads to better outcomes (AUC = $72\\%$) for\nframe-level assessment, outperforming the baseline trained with ground truth\nframe-level labeling (AUC = $69\\%$). We show that our proposed approach with\npre-trained models enhances model generalization ability and facilitates the\ncustomization to new patients, reducing the demands of data labeling.", "AI": {"tldr": "A framework for real-time stroke rehabilitation exercise assessment using video-level annotations and pseudo-labels, leveraging pre-trained models to reduce labeling costs and improve generalization.", "motivation": "Addressing the high cost and effort of frame-level annotations for training real-time motion analysis systems in stroke rehabilitation.", "method": "Uses gradient-based techniques and pseudo-label selection to train a frame-level classifier from video-level annotations, employing pre-trained models (Action Transformer, SkateFormer, MOMENT) for pseudo-label generation.", "result": "MOMENT achieves 73% AUC for video-level assessment, outperforming LSTM (58%). Action Transformer with Integrated Gradient achieves 72% AUC for frame-level assessment, surpassing baseline (69%).", "conclusion": "The approach reduces labeling demands, improves generalization, and enhances customization for new patients, demonstrating the effectiveness of pre-trained models in rehabilitation exercise assessment."}}
{"id": "2506.03490", "pdf": "https://arxiv.org/pdf/2506.03490", "abs": "https://arxiv.org/abs/2506.03490", "authors": ["Shigeng Chen", "Linhao Luo", "Zhangchi Qiu", "Yanan Cao", "Carl Yang", "Shirui Pan"], "title": "Beyond Memorization: A Rigorous Evaluation Framework for Medical Knowledge Editing", "categories": ["cs.CL"], "comment": null, "summary": "Recently, knowledge editing (KE) has emerged as a promising approach to\nupdate specific facts in Large Language Models (LLMs) without the need for full\nretraining. Despite the effectiveness in general-domain benchmarks, their\napplicability to complex medical domain remains largely unexplored. Medical\nknowledge editing is particularly challenging, as it requires LLMs to\ninternalize the knowledge and generalize to unseen scenarios for effective and\ninterpretable decision-making. In this work, we propose a novel framework\ncalled MedEditBench to rigorously evaluate the effectiveness of existing KE\nmethods in the medical domain. In MedEditBench, we introduce a new medical\nknowledge editing benchmark as well as three different knowledge editing\nparadigms, which are designed to assess the impact of different knowledge\nsources for editing. Our findings indicate that current KE methods result in\nonly superficial memorization of the injected information, failing to\ngeneralize to new scenarios. To overcome this limitation, we present\nSelf-Generated Rationale Editing (SGR-Edit), which utilizes model-derived\nrationales as the target knowledge for editing, thereby uncovering the\nunderlying reasoning process and demonstrating significant improvements over\nexisting KE approaches. Additionally, we offer deeper insights into medical\nknowledge editing, including the localization of medical knowledge in LLMs and\nthe impact of sequential editing on evolving knowledge. This could provide\npractical guidance for implementing KE methods in real-world medical\napplications.", "AI": {"tldr": "The paper introduces MedEditBench, a framework to evaluate knowledge editing (KE) methods in the medical domain, revealing their limitations and proposing SGR-Edit for improved performance.", "motivation": "Current KE methods lack effectiveness in the complex medical domain, requiring generalization and interpretability for decision-making.", "method": "The authors propose MedEditBench, a benchmark with three editing paradigms, and SGR-Edit, which uses model-derived rationales for editing.", "result": "Existing KE methods show superficial memorization, while SGR-Edit significantly improves generalization and reasoning.", "conclusion": "The study provides insights into medical KE, including knowledge localization and sequential editing, offering practical guidance for real-world applications."}}
{"id": "2506.03213", "pdf": "https://arxiv.org/pdf/2506.03213", "abs": "https://arxiv.org/abs/2506.03213", "authors": ["Abdullah Al Mamun", "Miaohua Zhang", "David Ahmedt-Aristizabal", "Zeeshan Hayder", "Mohammad Awrangjeb"], "title": "ConMamba: Contrastive Vision Mamba for Plant Disease Detection", "categories": ["cs.CV"], "comment": null, "summary": "Plant Disease Detection (PDD) is a key aspect of precision agriculture.\nHowever, existing deep learning methods often rely on extensively annotated\ndatasets, which are time-consuming and costly to generate. Self-supervised\nLearning (SSL) offers a promising alternative by exploiting the abundance of\nunlabeled data. However, most existing SSL approaches suffer from high\ncomputational costs due to convolutional neural networks or transformer-based\narchitectures. Additionally, they struggle to capture long-range dependencies\nin visual representation and rely on static loss functions that fail to align\nlocal and global features effectively. To address these challenges, we propose\nConMamba, a novel SSL framework specially designed for PDD. ConMamba integrates\nthe Vision Mamba Encoder (VME), which employs a bidirectional State Space Model\n(SSM) to capture long-range dependencies efficiently. Furthermore, we introduce\na dual-level contrastive loss with dynamic weight adjustment to optimize\nlocal-global feature alignment. Experimental results on three benchmark\ndatasets demonstrate that ConMamba significantly outperforms state-of-the-art\nmethods across multiple evaluation metrics. This provides an efficient and\nrobust solution for PDD.", "AI": {"tldr": "ConMamba, a self-supervised learning framework using Vision Mamba Encoder and dynamic contrastive loss, outperforms existing methods for Plant Disease Detection.", "motivation": "Existing deep learning methods for PDD require costly annotated datasets, and SSL approaches face computational inefficiency and poor feature alignment.", "method": "Proposes ConMamba with Vision Mamba Encoder (bidirectional SSM) and dual-level contrastive loss for dynamic feature alignment.", "result": "ConMamba outperforms state-of-the-art methods on three benchmark datasets.", "conclusion": "ConMamba offers an efficient, robust solution for PDD by addressing computational and feature alignment challenges."}}
{"id": "2209.01205", "pdf": "https://arxiv.org/pdf/2209.01205", "abs": "https://arxiv.org/abs/2209.01205", "authors": ["Han Wu", "Jie Yin", "Bala Rajaratnam", "Jianyuan Guo"], "title": "Hierarchical Relational Learning for Few-Shot Knowledge Graph Completion", "categories": ["cs.LG", "cs.AI", "cs.CV", "I.2"], "comment": "Published at ICLR 2023", "summary": "Knowledge graphs (KGs) are powerful in terms of their inference abilities,\nbut are also notorious for their incompleteness and long-tail distribution of\nrelations. To address these challenges and expand the coverage of KGs, few-shot\nKG completion aims to make predictions for triplets involving novel relations\nwhen only a few training triplets are provided as reference. Previous methods\nhave focused on designing local neighbor aggregators to learn entity-level\ninformation and/or imposing a potentially invalid sequential dependency\nassumption at the triplet level to learn meta relation information. However,\npairwise triplet-level interactions and context-level relational information\nhave been largely overlooked for learning meta representations of few-shot\nrelations. In this paper, we propose a hierarchical relational learning method\n(HiRe) for few-shot KG completion. By jointly capturing three levels of\nrelational information (entity-level, triplet-level and context-level), HiRe\ncan effectively learn and refine meta representations of few-shot relations,\nand thus generalize well to new unseen relations. Extensive experiments on\nbenchmark datasets validate the superiority of HiRe over state-of-the-art\nmethods. The code can be found in https://github.com/alexhw15/HiRe.git.", "AI": {"tldr": "HiRe proposes a hierarchical relational learning method for few-shot KG completion, capturing entity-level, triplet-level, and context-level information to improve meta representations of relations.", "motivation": "Addressing incompleteness and long-tail distribution in KGs by improving few-shot KG completion for novel relations with limited training data.", "method": "HiRe jointly learns entity-level, triplet-level, and context-level relational information to refine meta representations of few-shot relations.", "result": "HiRe outperforms state-of-the-art methods on benchmark datasets, demonstrating superior generalization to unseen relations.", "conclusion": "HiRe effectively addresses few-shot KG completion by leveraging hierarchical relational learning, validated by experimental results."}}
{"id": "2506.03320", "pdf": "https://arxiv.org/pdf/2506.03320", "abs": "https://arxiv.org/abs/2506.03320", "authors": ["Jack Bell", "Luigi Quarantiello", "Eric Nuertey Coleman", "Lanpei Li", "Malio Li", "Mauro Madeddu", "Elia Piccoli", "Vincenzo Lomonaco"], "title": "The Future of Continual Learning in the Era of Foundation Models: Three Key Directions", "categories": ["cs.LG", "cs.AI"], "comment": "16 pages, 1 figure, accepted at TCAI workshop 2025", "summary": "Continual learning--the ability to acquire, retain, and refine knowledge over\ntime--has always been fundamental to intelligence, both human and artificial.\nHistorically, different AI paradigms have acknowledged this need, albeit with\nvarying priorities: early expert and production systems focused on incremental\nknowledge consolidation, while reinforcement learning emphasised dynamic\nadaptation. With the rise of deep learning, deep continual learning has\nprimarily focused on learning robust and reusable representations over time to\nsolve sequences of increasingly complex tasks. However, the emergence of Large\nLanguage Models (LLMs) and foundation models has raised the question: Do we\nstill need continual learning when centralised, monolithic models can tackle\ndiverse tasks with access to internet-scale knowledge? We argue that continual\nlearning remains essential for three key reasons: (i) continual pre-training is\nstill necessary to ensure foundation models remain up to date, mitigating\nknowledge staleness and distribution shifts while integrating new information;\n(ii) continual fine-tuning enables models to specialise and personalise,\nadapting to domain-specific tasks, user preferences, and real-world constraints\nwithout full retraining, avoiding the need for computationally expensive long\ncontext-windows; (iii) continual compositionality offers a scalable and modular\napproach to intelligence, enabling the orchestration of foundation models and\nagents to be dynamically composed, recombined, and adapted. While continual\npre-training and fine-tuning are explored as niche research directions, we\nargue it is continual compositionality that will mark the rebirth of continual\nlearning. The future of AI will not be defined by a single static model but by\nan ecosystem of continually evolving and interacting models, making continual\nlearning more relevant than ever.", "AI": {"tldr": "The paper argues that continual learning remains essential in AI, especially with the rise of LLMs, for updating models, personalization, and modular intelligence.", "motivation": "To address whether continual learning is still relevant given the capabilities of large, centralized models like LLMs.", "method": "The paper discusses three key reasons for continual learning: pre-training updates, fine-tuning for specialization, and compositionality for modular intelligence.", "result": "Continual learning is deemed crucial for maintaining up-to-date, adaptable, and scalable AI systems.", "conclusion": "Continual learning will define the future of AI through evolving, interacting models, making it more relevant than ever."}}
{"id": "2506.03890", "pdf": "https://arxiv.org/pdf/2506.03890", "abs": "https://arxiv.org/abs/2506.03890", "authors": ["Christian Tinauer", "Maximilian Sackl", "Stefan Ropele", "Christian Langkammer"], "title": "Identifying Alzheimer's Disease Prediction Strategies of Convolutional Neural Network Classifiers using R2* Maps and Spectral Clustering", "categories": ["eess.IV", "cs.CV"], "comment": "Accepted for the conference EUSIPCO2025 (https://eusipco2025.org/)", "summary": "Deep learning models have shown strong performance in classifying Alzheimer's\ndisease (AD) from R2* maps, but their decision-making remains opaque, raising\nconcerns about interpretability. Previous studies suggest biases in model\ndecisions, necessitating further analysis. This study uses Layer-wise Relevance\nPropagation (LRP) and spectral clustering to explore classifier decision\nstrategies across preprocessing and training configurations using R2* maps. We\ntrained a 3D convolutional neural network on R2* maps, generating relevance\nheatmaps via LRP and applied spectral clustering to identify dominant patterns.\nt-Stochastic Neighbor Embedding (t-SNE) visualization was used to assess\nclustering structure. Spectral clustering revealed distinct decision patterns,\nwith the relevance-guided model showing the clearest separation between AD and\nnormal control (NC) cases. The t-SNE visualization confirmed that this model\naligned heatmap groupings with the underlying subject groups. Our findings\nhighlight the significant impact of preprocessing and training choices on deep\nlearning models trained on R2* maps, even with similar performance metrics.\nSpectral clustering offers a structured method to identify classification\nstrategy differences, emphasizing the importance of explainability in medical\nAI.", "AI": {"tldr": "The study analyzes deep learning models for Alzheimer's disease classification using R2* maps, focusing on interpretability. Layer-wise Relevance Propagation and spectral clustering reveal distinct decision patterns, emphasizing preprocessing and training impacts.", "motivation": "Deep learning models for AD classification lack interpretability, raising concerns about biases in decisions. This study aims to explore decision strategies using explainable AI techniques.", "method": "A 3D CNN was trained on R2* maps, with LRP generating relevance heatmaps. Spectral clustering identified decision patterns, and t-SNE visualized clustering structure.", "result": "Spectral clustering showed distinct decision patterns, with relevance-guided models clearly separating AD and NC cases. t-SNE confirmed alignment of heatmap groupings with subject groups.", "conclusion": "Preprocessing and training choices significantly impact model decisions, even with similar performance. Spectral clustering aids in understanding classification strategies, stressing the need for explainability in medical AI."}}
{"id": "2506.03501", "pdf": "https://arxiv.org/pdf/2506.03501", "abs": "https://arxiv.org/abs/2506.03501", "authors": ["Yuchen Guo", "Zhicheng Dou", "Huy H. Nguyen", "Ching-Chun Chang", "Saku Sugawara", "Isao Echizen"], "title": "Measuring Human Involvement in AI-Generated Text: A Case Study on Academic Writing", "categories": ["cs.CL", "cs.AI"], "comment": "IJCNN2025 accepted", "summary": "Content creation has dramatically progressed with the rapid advancement of\nlarge language models like ChatGPT and Claude. While this progress has greatly\nenhanced various aspects of life and work, it has also negatively affected\ncertain areas of society. A recent survey revealed that nearly 30% of college\nstudents use generative AI to help write academic papers and reports. Most\ncountermeasures treat the detection of AI-generated text as a binary\nclassification task and thus lack robustness. This approach overlooks human\ninvolvement in the generation of content even though human-machine\ncollaboration is becoming mainstream. Besides generating entire texts, people\nmay use machines to complete or revise texts. Such human involvement varies\ncase by case, which makes binary classification a less than satisfactory\napproach. We refer to this situation as participation detection obfuscation. We\npropose using BERTScore as a metric to measure human involvement in the\ngeneration process and a multi-task RoBERTa-based regressor trained on a token\nclassification task to address this problem. To evaluate the effectiveness of\nthis approach, we simulated academic-based scenarios and created a continuous\ndataset reflecting various levels of human involvement. All of the existing\ndetectors we examined failed to detect the level of human involvement on this\ndataset. Our method, however, succeeded (F1 score of 0.9423 and a regressor\nmean squared error of 0.004). Moreover, it demonstrated some generalizability\nacross generative models. Our code is available at\nhttps://github.com/gyc-nii/CAS-CS-and-dual-head-detector", "AI": {"tldr": "The paper addresses the challenge of detecting human involvement in AI-generated text, proposing a BERTScore metric and a multi-task RoBERTa-based regressor for robust participation detection.", "motivation": "The rise of AI-generated content, especially in academic settings, necessitates better detection methods beyond binary classification to account for varying human involvement.", "method": "The authors use BERTScore to measure human involvement and train a multi-task RoBERTa-based regressor on token classification. They create a continuous dataset simulating academic scenarios for evaluation.", "result": "Their method outperforms existing detectors, achieving an F1 score of 0.9423 and a regressor mean squared error of 0.004, with some generalizability across generative models.", "conclusion": "The proposed approach effectively detects varying levels of human involvement in AI-generated text, addressing limitations of binary classification methods."}}
{"id": "2506.03224", "pdf": "https://arxiv.org/pdf/2506.03224", "abs": "https://arxiv.org/abs/2506.03224", "authors": ["Jinwei Zeng", "Yu Liu", "Guozhen Zhang", "Jingtao Ding", "Yuming Lin", "Jian Yuan", "Yong Li"], "title": "OpenCarbon: A Contrastive Learning-based Cross-Modality Neural Approach for High-Resolution Carbon Emission Prediction Using Open Data", "categories": ["cs.CV", "cs.AI", "physics.soc-ph"], "comment": "Accepted by IJCAI 2025", "summary": "Accurately estimating high-resolution carbon emissions is crucial for\neffective emission governance and mitigation planning. While conventional\nmethods for precise carbon accounting are hindered by substantial data\ncollection efforts, the rise of open data and advanced learning techniques\noffers a promising solution. Once an open data-based prediction model is\ndeveloped and trained, it can easily infer emissions for new areas based on\navailable open data. To address this, we incorporate two modalities of open\ndata, satellite images and point-of-interest (POI) data, to predict\nhigh-resolution urban carbon emissions, with satellite images providing\nmacroscopic and static and POI data offering fine-grained and relatively\ndynamic functionality information. However, estimating high-resolution carbon\nemissions presents two significant challenges: the intertwined and implicit\neffects of various functionalities on carbon emissions, and the complex spatial\ncontiguity correlations that give rise to the agglomeration effect. Our model,\nOpenCarbon, features two major designs that target the challenges: a\ncross-modality information extraction and fusion module to extract\ncomplementary functionality information from two modules and model their\ninteractions, and a neighborhood-informed aggregation module to capture the\nspatial contiguity correlations. Extensive experiments demonstrate our model's\nsuperiority, with a significant performance gain of 26.6\\% on R2. Further\ngeneralizability tests and case studies also show OpenCarbon's capacity to\ncapture the intrinsic relation between urban functionalities and carbon\nemissions, validating its potential to empower efficient carbon governance and\ntargeted carbon mitigation planning. Codes and data are available:\nhttps://github.com/JinweiZzz/OpenCarbon.", "AI": {"tldr": "OpenCarbon uses satellite images and POI data to predict urban carbon emissions, overcoming challenges with cross-modality fusion and spatial correlations, achieving a 26.6% performance gain.", "motivation": "Accurate high-resolution carbon emission estimation is vital for governance and mitigation, but traditional methods are data-intensive. Open data and learning techniques offer a solution.", "method": "Incorporates satellite images (macroscopic, static) and POI data (fine-grained, dynamic) in OpenCarbon, featuring cross-modality fusion and neighborhood-informed aggregation to address intertwined functionalities and spatial correlations.", "result": "Achieves a 26.6% performance gain on R2, with generalizability tests and case studies validating its effectiveness.", "conclusion": "OpenCarbon effectively captures urban functionalities' relation to emissions, aiding efficient carbon governance and mitigation planning."}}
{"id": "2506.03324", "pdf": "https://arxiv.org/pdf/2506.03324", "abs": "https://arxiv.org/abs/2506.03324", "authors": ["Ethan Che", "Hakan Ceylan", "James McInerney", "Nathan Kallus"], "title": "Optimization of Epsilon-Greedy Exploration", "categories": ["cs.LG"], "comment": null, "summary": "Modern recommendation systems rely on exploration to learn user preferences\nfor new items, typically implementing uniform exploration policies (e.g.,\nepsilon-greedy) due to their simplicity and compatibility with machine learning\n(ML) personalization models. Within these systems, a crucial consideration is\nthe rate of exploration - what fraction of user traffic should receive random\nitem recommendations and how this should evolve over time. While various\nheuristics exist for navigating the resulting exploration-exploitation\ntradeoff, selecting optimal exploration rates is complicated by practical\nconstraints including batched updates, time-varying user traffic, short time\nhorizons, and minimum exploration requirements. In this work, we propose a\nprincipled framework for determining the exploration schedule based on directly\nminimizing Bayesian regret through stochastic gradient descent (SGD), allowing\nfor dynamic exploration rate adjustment via Model-Predictive Control (MPC).\nThrough extensive experiments with recommendation datasets, we demonstrate that\nvariations in the batch size across periods significantly influence the optimal\nexploration strategy. Our optimization methods automatically calibrate\nexploration to the specific problem setting, consistently matching or\noutperforming the best heuristic for each setting.", "AI": {"tldr": "A framework for dynamic exploration rate adjustment in recommendation systems using Bayesian regret minimization and SGD, outperforming heuristic methods.", "motivation": "Addressing the challenge of optimizing exploration rates in recommendation systems under practical constraints like batched updates and varying user traffic.", "method": "Proposes a framework using Bayesian regret minimization via SGD and Model-Predictive Control (MPC) for dynamic exploration rate adjustment.", "result": "Experiments show the method adapts to batch size variations and outperforms heuristic strategies.", "conclusion": "The framework provides a principled, adaptive approach to exploration in recommendation systems, improving performance over heuristics."}}
{"id": "2506.04030", "pdf": "https://arxiv.org/pdf/2506.04030", "abs": "https://arxiv.org/abs/2506.04030", "authors": ["Olivier Jaubert", "Salman Mohammadi", "Keith A. Goatman", "Shadia S. Mikhael", "Conor Bradley", "Rebecca Hughes", "Richard Good", "John H. Hipwell", "Sonia Dahdouh"], "title": "Conformal coronary calcification volume estimation with conditional coverage via histogram clustering", "categories": ["eess.IV", "cs.CV"], "comment": "IEEE 22nd International Symposium on Biomedical Imaging (ISBI)", "summary": "Incidental detection and quantification of coronary calcium in CT scans could\nlead to the early introduction of lifesaving clinical interventions. However,\nover-reporting could negatively affect patient wellbeing and unnecessarily\nburden the medical system. Therefore, careful considerations should be taken\nwhen automatically reporting coronary calcium scores. A cluster-based\nconditional conformal prediction framework is proposed to provide score\nintervals with calibrated coverage from trained segmentation networks without\nretraining. The proposed method was tuned and used to calibrate predictive\nintervals for 3D UNet models (deterministic, MCDropout and deep ensemble)\nreaching similar coverage with better triage metrics compared to conventional\nconformal prediction. Meaningful predictive intervals of calcium scores could\nhelp triage patients according to the confidence of their risk category\nprediction.", "AI": {"tldr": "A cluster-based conditional conformal prediction framework is proposed to calibrate coronary calcium score intervals from segmentation networks, improving triage metrics compared to conventional methods.", "motivation": "To balance early detection benefits and risks of over-reporting coronary calcium in CT scans, ensuring accurate and reliable automated reporting.", "method": "A cluster-based conditional conformal prediction framework is applied to 3D UNet models (deterministic, MCDropout, deep ensemble) for calibrated score intervals without retraining.", "result": "Achieved similar coverage with better triage metrics than conventional conformal prediction, enabling confident patient risk categorization.", "conclusion": "The method provides meaningful predictive intervals for calcium scores, aiding in patient triage and clinical decision-making."}}
{"id": "2506.03510", "pdf": "https://arxiv.org/pdf/2506.03510", "abs": "https://arxiv.org/abs/2506.03510", "authors": ["Seungcheol Park", "Sojin Lee", "Jongjin Kim", "Jinsik Lee", "Hyunjik Jo", "U Kang"], "title": "Accurate Sublayer Pruning for Large Language Models by Exploiting Latency and Tunability Information", "categories": ["cs.CL", "68T50", "I.2.7"], "comment": "IJCAI 2025 Main Track", "summary": "How can we accelerate large language models(LLMs) without sacrificing\naccuracy? The slow inference speed of LLMs hinders us to benefit from their\nremarkable performance in diverse applications. This is mainly because numerous\nsublayers are stacked together in LLMs. Sublayer pruning compresses and\nexpedites LLMs via removing unnecessary sublayers. However, existing sublayer\npruning algorithms are limited in accuracy since they naively select sublayers\nto prune, overlooking the different characteristics of each sublayer. In this\npaper, we propose SPRINT (Sublayer PRuning wIth LateNcy and Tunability\nInformation), an accurate sublayer pruning method for LLMs. SPRINT accurately\nselects a target sublayer to prune by considering 1) the amount of latency\nreduction after pruning and 2) the tunability of sublayers. SPRINT iteratively\nprunes redundant sublayers and swiftly tunes the parameters of remaining\nsublayers. Experiments show that SPRINT achieves the best accuracy-speedup\ntrade-off, exhibiting up to 23.88%p higher accuracy on zero-shot commonsense\nreasoning benchmarks compared to existing pruning algorithms.", "AI": {"tldr": "SPRINT is a sublayer pruning method for LLMs that improves speed without losing accuracy by considering latency reduction and sublayer tunability.", "motivation": "The slow inference speed of LLMs due to stacked sublayers limits their practical use, and existing pruning methods lack accuracy by ignoring sublayer characteristics.", "method": "SPRINT selects sublayers to prune based on latency reduction and tunability, iteratively pruning and tuning remaining sublayers.", "result": "SPRINT achieves a 23.88%p higher accuracy on zero-shot benchmarks compared to existing methods, offering the best accuracy-speedup trade-off.", "conclusion": "SPRINT effectively accelerates LLMs while maintaining accuracy by intelligently pruning and tuning sublayers."}}
{"id": "2506.03229", "pdf": "https://arxiv.org/pdf/2506.03229", "abs": "https://arxiv.org/abs/2506.03229", "authors": ["Qian-Wei Wang", "Yuqiu Xie", "Letian Zhang", "Zimo Liu", "Shu-Tao Xia"], "title": "Pre-trained Vision-Language Models Assisted Noisy Partial Label Learning", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "In the context of noisy partial label learning (NPLL), each training sample\nis associated with a set of candidate labels annotated by multiple noisy\nannotators. With the emergence of high-performance pre-trained vision-language\nmodels (VLMs) such as CLIP, LLaVa and GPT-4V, the direction of using these\nmodels to replace time-consuming manual annotation workflows and achieve\n\"manual-annotation-free\" training for downstream tasks has become a highly\npromising research avenue. This paper focuses on learning from noisy partial\nlabels annotated by pre-trained VLMs and proposes an innovative collaborative\nconsistency regularization (Co-Reg) method. Unlike the symmetric noise\nprimarily addressed in traditional noisy label learning, the noise generated by\npre-trained models is instance-dependent, embodying the underlying patterns of\nthe pre-trained models themselves, which significantly increases the learning\ndifficulty for the model. To address this, we simultaneously train two neural\nnetworks that implement collaborative purification of training labels through a\n\"Co-Pseudo-Labeling\" mechanism, while enforcing consistency regularization\nconstraints in both the label space and feature representation space. Our\nmethod can also leverage few-shot manually annotated valid labels to further\nenhance its performances. Comparative experiments with different denoising and\ndisambiguation algorithms, annotation manners, and pre-trained model\napplication schemes fully validate the effectiveness of the proposed method,\nwhile revealing the broad prospects of integrating weakly-supervised learning\ntechniques into the knowledge distillation process of pre-trained models.", "AI": {"tldr": "The paper proposes a collaborative consistency regularization (Co-Reg) method for learning from noisy partial labels annotated by pre-trained vision-language models (VLMs), addressing instance-dependent noise and improving performance with few-shot manual annotations.", "motivation": "To replace manual annotation workflows with pre-trained VLMs and address the challenge of instance-dependent noise in noisy partial label learning (NPLL).", "method": "A Co-Reg method involving two neural networks for collaborative label purification via 'Co-Pseudo-Labeling' and consistency regularization in label and feature spaces.", "result": "Outperforms other denoising and disambiguation algorithms, demonstrating effectiveness and potential for weakly-supervised learning with VLMs.", "conclusion": "The method shows promise for integrating weakly-supervised learning into pre-trained model knowledge distillation, validated by extensive experiments."}}
{"id": "2506.03333", "pdf": "https://arxiv.org/pdf/2506.03333", "abs": "https://arxiv.org/abs/2506.03333", "authors": ["Juan Sebastian Rojas", "Chi-Guhn Lee"], "title": "A Differential Perspective on Distributional Reinforcement Learning", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "To date, distributional reinforcement learning (distributional RL) methods\nhave exclusively focused on the discounted setting, where an agent aims to\noptimize a potentially-discounted sum of rewards over time. In this work, we\nextend distributional RL to the average-reward setting, where an agent aims to\noptimize the reward received per time-step. In particular, we utilize a\nquantile-based approach to develop the first set of algorithms that can\nsuccessfully learn and/or optimize the long-run per-step reward distribution,\nas well as the differential return distribution of an average-reward MDP. We\nderive proven-convergent tabular algorithms for both prediction and control, as\nwell as a broader family of algorithms that have appealing scaling properties.\nEmpirically, we find that these algorithms consistently yield competitive\nperformance when compared to their non-distributional equivalents, while also\ncapturing rich information about the long-run reward and return distributions.", "AI": {"tldr": "The paper extends distributional RL to the average-reward setting, introducing quantile-based algorithms for learning long-run reward distributions and differential returns.", "motivation": "Current distributional RL methods focus only on discounted settings, leaving the average-reward setting unexplored.", "method": "A quantile-based approach is used to develop convergent tabular algorithms for prediction and control, along with scalable variants.", "result": "The algorithms perform competitively against non-distributional methods and capture detailed reward/return distribution information.", "conclusion": "The work successfully bridges the gap in distributional RL for average-reward settings, offering practical and scalable solutions."}}
{"id": "2506.04058", "pdf": "https://arxiv.org/pdf/2506.04058", "abs": "https://arxiv.org/abs/2506.04058", "authors": ["Bulat Maksudov", "Kathleen Curran", "Alessandra Mileo"], "title": "Towards generating more interpretable counterfactuals via concept vectors: a preliminary study on chest X-rays", "categories": ["eess.IV", "cs.AI", "cs.CV"], "comment": null, "summary": "An essential step in deploying medical imaging models is ensuring alignment\nwith clinical knowledge and interpretability. We focus on mapping clinical\nconcepts into the latent space of generative models to identify Concept\nActivation Vectors (CAVs). Using a simple reconstruction autoencoder, we link\nuser-defined concepts to image-level features without explicit label training.\nThe extracted concepts are stable across datasets, enabling visual explanations\nthat highlight clinically relevant features. By traversing latent space along\nconcept directions, we produce counterfactuals that exaggerate or reduce\nspecific clinical features. Preliminary results on chest X-rays show promise\nfor large pathologies like cardiomegaly, while smaller pathologies remain\nchallenging due to reconstruction limits. Although not outperforming baselines,\nthis approach offers a path toward interpretable, concept-based explanations\naligned with clinical knowledge.", "AI": {"tldr": "The paper proposes using Concept Activation Vectors (CAVs) in generative models to align medical imaging with clinical knowledge, enabling interpretable explanations and counterfactual images.", "motivation": "To ensure medical imaging models align with clinical knowledge and provide interpretable explanations for clinicians.", "method": "Mapping clinical concepts into the latent space of generative models using a reconstruction autoencoder, extracting stable CAVs without labeled training.", "result": "Stable concept extraction and visual explanations for clinical features, with promising results for large pathologies like cardiomegaly, though smaller pathologies remain challenging.", "conclusion": "The approach offers interpretable, concept-based explanations aligned with clinical knowledge, despite not outperforming baselines."}}
{"id": "2506.03519", "pdf": "https://arxiv.org/pdf/2506.03519", "abs": "https://arxiv.org/abs/2506.03519", "authors": ["Yangyang Zhao", "Ben Niu", "Libo Qin", "Shihan Wang"], "title": "An Efficient Task-Oriented Dialogue Policy: Evolutionary Reinforcement Learning Injected by Elite Individuals", "categories": ["cs.CL"], "comment": null, "summary": "Deep Reinforcement Learning (DRL) is widely used in task-oriented dialogue\nsystems to optimize dialogue policy, but it struggles to balance exploration\nand exploitation due to the high dimensionality of state and action spaces.\nThis challenge often results in local optima or poor convergence. Evolutionary\nAlgorithms (EAs) have been proven to effectively explore the solution space of\nneural networks by maintaining population diversity. Inspired by this, we\ninnovatively combine the global search capabilities of EA with the local\noptimization of DRL to achieve a balance between exploration and exploitation.\nNevertheless, the inherent flexibility of natural language in dialogue tasks\ncomplicates this direct integration, leading to prolonged evolutionary times.\nThus, we further propose an elite individual injection mechanism to enhance\nEA's search efficiency by adaptively introducing best-performing individuals\ninto the population. Experiments across four datasets show that our approach\nsignificantly improves the balance between exploration and exploitation,\nboosting performance. Moreover, the effectiveness of the EII mechanism in\nreducing exploration time has been demonstrated, achieving an efficient\nintegration of EA and DRL on task-oriented dialogue policy tasks.", "AI": {"tldr": "The paper combines Evolutionary Algorithms (EAs) with Deep Reinforcement Learning (DRL) to balance exploration and exploitation in task-oriented dialogue systems, introducing an elite individual injection mechanism to improve efficiency.", "motivation": "DRL struggles with balancing exploration and exploitation in high-dimensional spaces, leading to poor convergence. EAs offer global search capabilities, but their integration with DRL is challenging due to natural language flexibility.", "method": "The study integrates EA's global search with DRL's local optimization and proposes an elite individual injection mechanism to enhance EA's efficiency.", "result": "Experiments on four datasets show improved balance between exploration and exploitation, with the elite mechanism reducing exploration time.", "conclusion": "The approach successfully integrates EA and DRL, enhancing performance and efficiency in task-oriented dialogue policy optimization."}}
{"id": "2506.03275", "pdf": "https://arxiv.org/pdf/2506.03275", "abs": "https://arxiv.org/abs/2506.03275", "authors": ["Austin Silveria", "Soham V. Govande", "Daniel Y. Fu"], "title": "Chipmunk: Training-Free Acceleration of Diffusion Transformers with Dynamic Column-Sparse Deltas", "categories": ["cs.CV", "cs.AI"], "comment": "10 pages, 4 figures", "summary": "Diffusion Transformers (DiTs) have achieved state-of-the-art performance in\nhigh-quality image and video generation but incur substantial compute cost at\ninference. A common observation is that DiT latent noise vectors change slowly\nacross inference steps, which suggests that the DiT compute may be redundant\nacross steps. In this paper, we aim to speed up inference by reducing this\nredundancy, without additional training. We first study how activations change\nbetween steps in two state-of-the-art open-source DiTs. We find that just 5-25%\nof the values in attention and MLP explain 70-90% of the change in activations\nacross steps. This finding motivates our approach, Chipmunk, which uses dynamic\nsparsity at inference time to recompute only the fastest-changing intermediate\nactivations, while caching the rest. Dynamic sparsity introduces two systems\nchallenges: (1) sparse attention and MLP operations tend to underutilize GPU\ntensor cores; and (2) computing dynamic sparsity patterns at runtime and\ncaching activations both introduce overhead. To address these challenges,\nChipmunk first uses a voxel-based reordering of input tokens to introduce\ncolumn-wise sparsity. We implement column-sparse kernels utilizing efficient\nsparse gathers from global to shared GPU memory, achieving a 9.3x speedup at\n93% sparsity compared to highly-optimized dense baselines. Second, Chipmunk\noverlaps the computation of sparsity patterns and cache updates with other\nparts of the computation (e.g., second layer of the MLP) to hide the extra\nlatency. Chipmunk achieves up to 2.16x speedup on HunyuanVideo and 1.41x on\nFLUX.1-dev without compromising generation quality. Furthermore, we show that\nChipmunk can be stacked on top of full step caching, achieving a 3.72x speedup\non HunyuanVideo, a 2.67x speedup on WAN2.1, and a 2.25x speedup on FLUX.1-dev\nwith minimal quality impact.", "AI": {"tldr": "Chipmunk speeds up DiT inference by reducing redundancy via dynamic sparsity, achieving significant speedups without quality loss.", "motivation": "DiTs incur high compute costs due to redundant activations across steps, suggesting potential for optimization.", "method": "Chipmunk uses dynamic sparsity to recompute only fast-changing activations, with voxel-based reordering and column-sparse kernels for efficiency.", "result": "Achieves up to 2.16x speedup on HunyuanVideo and 1.41x on FLUX.1-dev, with further gains when stacked with caching.", "conclusion": "Chipmunk effectively reduces DiT inference costs without compromising generation quality."}}
{"id": "2506.03337", "pdf": "https://arxiv.org/pdf/2506.03337", "abs": "https://arxiv.org/abs/2506.03337", "authors": ["Yide Ran", "Wentao Guo", "Jingwei Sun", "Yanzhou Pan", "Xiaodong Yu", "Hao Wang", "Jianwen Xie", "Yiran Chen", "Denghui Zhang", "Zhaozhuo Xu"], "title": "Mitigating Non-IID Drift in Zeroth-Order Federated LLM Fine-Tuning with Transferable Sparsity", "categories": ["cs.LG", "cs.AI"], "comment": "56 pages, 11 figures", "summary": "Federated Learning enables collaborative fine-tuning of Large Language Models\n(LLMs) across decentralized Non-Independent and Identically Distributed\n(Non-IID) clients, but such models' massive parameter sizes lead to significant\nmemory and communication challenges. This work introduces Meerkat, a sparse\nzeroth-order optimization (ZO) method designed for federated LLM fine-tuning.\nBy limiting fine-tuning to a transferable, static, extremely sparse subset of\nparameters, Meerkat achieves remarkable communication efficiency, enabling\ncost-effective high-frequency synchronization. With theoretical analysis and\nexperiments, we show that this high-frequency communication effectively\nmitigates Non-IID data challenges and leads to superior performance compared to\nfull-parameter ZO. Furthermore, experiment results show that Meerkat\noutperforms existing sparsity baselines with better performance at the same\ncommunication frequency. To further handle Non-IID drift, Meerkat leverages\ntraceable local updates and forms a virtual path for each client. This virtual\npath mechanism reveals the GradIP phenomenon: the inner products between LLM\npre-training gradients maintained by server and client gradients estimated via\nZO converges for extreme Non-IID clients but oscillates for IID ones. This\ndistinct behavior provides a signal for identifying clients with extreme data\nheterogeneity. Using this signal, Meerkat-vp is proposed to analyze GradIP\ntrajectories to identify extreme Non-IID clients and applies early stopping to\nenhance aggregated model quality. Experiments confirm that Meerkat and\nMeerkat-vp significantly improve the efficiency and effectiveness of ZO\nfederated LLM fine-tuning.", "AI": {"tldr": "Meerkat introduces a sparse zeroth-order optimization method for federated LLM fine-tuning, improving communication efficiency and performance by focusing on a static, sparse subset of parameters. Meerkat-vp further enhances this by identifying extreme Non-IID clients using GradIP signals.", "motivation": "Address memory and communication challenges in federated LLM fine-tuning due to massive parameter sizes and Non-IID data.", "method": "Sparse zeroth-order optimization (ZO) with static parameter subset; Meerkat-vp uses GradIP trajectories for client identification.", "result": "Meerkat achieves superior performance and efficiency; Meerkat-vp improves aggregated model quality by handling extreme Non-IID drift.", "conclusion": "Meerkat and Meerkat-vp significantly enhance federated LLM fine-tuning efficiency and effectiveness."}}
{"id": "2506.04116", "pdf": "https://arxiv.org/pdf/2506.04116", "abs": "https://arxiv.org/abs/2506.04116", "authors": ["Xuanru Zhou", "Jiarun Liu", "Shoujun Yu", "Hao Yang", "Cheng Li", "Tao Tan", "Shanshan Wang"], "title": "A Diffusion-Driven Temporal Super-Resolution and Spatial Consistency Enhancement Framework for 4D MRI imaging", "categories": ["eess.IV", "cs.AI", "cs.CV"], "comment": null, "summary": "In medical imaging, 4D MRI enables dynamic 3D visualization, yet the\ntrade-off between spatial and temporal resolution requires prolonged scan time\nthat can compromise temporal fidelity--especially during rapid, large-amplitude\nmotion. Traditional approaches typically rely on registration-based\ninterpolation to generate intermediate frames. However, these methods struggle\nwith large deformations, resulting in misregistration, artifacts, and\ndiminished spatial consistency. To address these challenges, we propose\nTSSC-Net, a novel framework that generates intermediate frames while preserving\nspatial consistency. To improve temporal fidelity under fast motion, our\ndiffusion-based temporal super-resolution network generates intermediate frames\nusing the start and end frames as key references, achieving 6x temporal\nsuper-resolution in a single inference step. Additionally, we introduce a novel\ntri-directional Mamba-based module that leverages long-range contextual\ninformation to effectively resolve spatial inconsistencies arising from\ncross-slice misalignment, thereby enhancing volumetric coherence and correcting\ncross-slice errors. Extensive experiments were performed on the public ACDC\ncardiac MRI dataset and a real-world dynamic 4D knee joint dataset. The results\ndemonstrate that TSSC-Net can generate high-resolution dynamic MRI from\nfast-motion data while preserving structural fidelity and spatial consistency.", "AI": {"tldr": "TSSC-Net is a novel framework for generating intermediate frames in 4D MRI, improving temporal and spatial resolution during rapid motion.", "motivation": "Addressing the limitations of traditional registration-based interpolation in handling large deformations and preserving spatial consistency in dynamic MRI.", "method": "Uses a diffusion-based temporal super-resolution network and a tri-directional Mamba-based module for long-range contextual information.", "result": "Achieves 6x temporal super-resolution and enhances volumetric coherence, validated on cardiac and knee MRI datasets.", "conclusion": "TSSC-Net effectively preserves structural fidelity and spatial consistency in fast-motion 4D MRI."}}
{"id": "2506.03523", "pdf": "https://arxiv.org/pdf/2506.03523", "abs": "https://arxiv.org/abs/2506.03523", "authors": ["Chong Li", "Jiajun Zhang", "Chengqing Zong"], "title": "TokAlign: Efficient Vocabulary Adaptation via Token Alignment", "categories": ["cs.CL"], "comment": "ACL 2025, our codes and models are available at\n  https://github.com/ZNLP/TokAlign", "summary": "Tokenization serves as a foundational step for Large Language Models (LLMs)\nto process text. In new domains or languages, the inefficiency of the tokenizer\nwill slow down the training and generation of LLM. The mismatch in vocabulary\nalso hinders deep knowledge transfer between LLMs like token-level\ndistillation. To mitigate this gap, we propose an efficient method named\nTokAlign to replace the vocabulary of LLM from the token co-occurrences view,\nand further transfer the token-level knowledge between models. It first aligns\nthe source vocabulary to the target one by learning a one-to-one mapping matrix\nfor token IDs. Model parameters, including embeddings, are rearranged and\nprogressively fine-tuned for the new vocabulary. Our method significantly\nimproves multilingual text compression rates and vocabulary initialization for\nLLMs, decreasing the perplexity from 3.4$\\text{e}^2$ of strong baseline methods\nto 1.2$\\text{e}^2$ after initialization. Experimental results on models across\nmultiple parameter scales demonstrate the effectiveness and generalization of\nTokAlign, which costs as few as 5k steps to restore the performance of the\nvanilla model. After unifying vocabularies between LLMs, token-level\ndistillation can remarkably boost (+4.4% than sentence-level distillation) the\nbase model, costing only 235M tokens.", "AI": {"tldr": "TokAlign is an efficient method to align and transfer token-level knowledge between LLMs by replacing vocabularies, improving multilingual text compression and reducing perplexity.", "motivation": "Tokenization inefficiencies in new domains or languages slow down LLM training and hinder knowledge transfer.", "method": "TokAlign aligns source to target vocabulary via a mapping matrix, rearranges model parameters, and fine-tunes for the new vocabulary.", "result": "Reduces perplexity from 3.4e\u00b2 to 1.2e\u00b2, improves compression, and enables efficient token-level distillation (+4.4% over sentence-level).", "conclusion": "TokAlign effectively unifies vocabularies, enhances LLM performance, and enables efficient knowledge transfer with minimal training steps."}}
{"id": "2506.03290", "pdf": "https://arxiv.org/pdf/2506.03290", "abs": "https://arxiv.org/abs/2506.03290", "authors": ["Leyla Mirvakhabova", "Hong Cai", "Jisoo Jeong", "Hanno Ackermann", "Farhad Zanjani", "Fatih Porikli"], "title": "Learning Optical Flow Field via Neural Ordinary Differential Equation", "categories": ["cs.CV"], "comment": "CVPRW 2025", "summary": "Recent works on optical flow estimation use neural networks to predict the\nflow field that maps positions of one image to positions of the other. These\nnetworks consist of a feature extractor, a correlation volume, and finally\nseveral refinement steps. These refinement steps mimic the iterative\nrefinements performed by classical optimization algorithms and are usually\nimplemented by neural layers (e.g., GRU) which are recurrently executed for a\nfixed and pre-determined number of steps. However, relying on a fixed number of\nsteps may result in suboptimal performance because it is not tailored to the\ninput data. In this paper, we introduce a novel approach for predicting the\nderivative of the flow using a continuous model, namely neural ordinary\ndifferential equations (ODE). One key advantage of this approach is its\ncapacity to model an equilibrium process, dynamically adjusting the number of\ncompute steps based on the data at hand. By following a particular neural\narchitecture, ODE solver, and associated hyperparameters, our proposed model\ncan replicate the exact same updates as recurrent cells used in existing works,\noffering greater generality. Through extensive experimental analysis on optical\nflow benchmarks, we demonstrate that our approach achieves an impressive\nimprovement over baseline and existing models, all while requiring only a\nsingle refinement step.", "AI": {"tldr": "The paper introduces a neural ODE-based approach for optical flow estimation, dynamically adjusting refinement steps for better performance.", "motivation": "Fixed refinement steps in existing neural networks for optical flow estimation may lead to suboptimal performance, as they don't adapt to input data.", "method": "Uses neural ODEs to predict flow derivatives, enabling dynamic adjustment of refinement steps. Replicates updates of recurrent cells with greater generality.", "result": "Achieves significant improvement over baselines and existing models, often requiring only one refinement step.", "conclusion": "The neural ODE approach offers a flexible and efficient alternative to fixed-step refinement in optical flow estimation."}}
{"id": "2506.03209", "pdf": "https://arxiv.org/pdf/2506.03209", "abs": "https://arxiv.org/abs/2506.03209", "authors": ["Tinghuan Li", "Shuheng Chen", "Junyi Fan", "Elham Pishgar", "Kamiar Alaei", "Greg Placencia", "Maryam Pishgar"], "title": "Predicting Postoperative Stroke in Elderly SICU Patients: An Interpretable Machine Learning Model Using MIMIC Data", "categories": ["q-bio.QM", "cs.AI", "cs.LG"], "comment": null, "summary": "Postoperative stroke remains a critical complication in elderly surgical\nintensive care unit (SICU) patients, contributing to prolonged hospitalization,\nelevated healthcare costs, and increased mortality. Accurate early risk\nstratification is essential to enable timely intervention and improve clinical\noutcomes. We constructed a combined cohort of 19,085 elderly SICU admissions\nfrom the MIMIC-III and MIMIC-IV databases and developed an interpretable\nmachine learning (ML) framework to predict in-hospital stroke using clinical\ndata from the first 24 hours of Intensive Care Unit (ICU) stay. The\npreprocessing pipeline included removal of high-missingness features, iterative\nSingular Value Decomposition (SVD) imputation, z-score normalization, one-hot\nencoding, and class imbalance correction via the Adaptive Synthetic Sampling\n(ADASYN) algorithm. A two-stage feature selection process-combining Recursive\nFeature Elimination with Cross-Validation (RFECV) and SHapley Additive\nexPlanations (SHAP)-reduced the initial 80 variables to 20 clinically\ninformative predictors. Among eight ML models evaluated, CatBoost achieved the\nbest performance with an AUROC of 0.8868 (95% CI: 0.8802--0.8937). SHAP\nanalysis and ablation studies identified prior cerebrovascular disease, serum\ncreatinine, and systolic blood pressure as the most influential risk factors.\nOur results highlight the potential of interpretable ML approaches to support\nearly detection of postoperative stroke and inform decision-making in\nperioperative critical care.", "AI": {"tldr": "An interpretable ML framework predicts postoperative stroke in elderly SICU patients using early ICU data, achieving high accuracy (AUROC 0.8868) and identifying key risk factors.", "motivation": "Postoperative stroke in elderly SICU patients leads to poor outcomes and high costs, necessitating early risk stratification for timely intervention.", "method": "Used MIMIC-III/IV data (19,085 admissions), preprocessing (feature removal, SVD imputation, normalization, ADASYN), and feature selection (RFECV, SHAP) to train ML models. CatBoost performed best.", "result": "CatBoost achieved AUROC 0.8868. Key predictors: prior cerebrovascular disease, serum creatinine, systolic blood pressure.", "conclusion": "Interpretable ML can aid early stroke detection and improve perioperative care decisions."}}
{"id": "2506.03355", "pdf": "https://arxiv.org/pdf/2506.03355", "abs": "https://arxiv.org/abs/2506.03355", "authors": ["Elias Abad Rocamora", "Christian Schlarmann", "Naman Deep Singh", "Yongtao Wu", "Matthias Hein", "Volkan Cevher"], "title": "Robustness in Both Domains: CLIP Needs a Robust Text Encoder", "categories": ["cs.LG", "cs.AI", "cs.CV"], "comment": null, "summary": "Adversarial input attacks can cause a significant shift of CLIP embeddings.\nThis can affect the downstream robustness of models incorporating CLIP in the\npipeline, such as text-to-image generative models or large vision language\nmodels. While some efforts have been done towards making the CLIP image\nencoders robust, the robustness of text encoders remains unexplored. In this\nwork, we cover this gap in the literature. We propose LEAF: an efficient\nadversarial finetuning method for the text domain, with the ability to scale to\nlarge CLIP models. Our models significantly improve the zero-shot adversarial\naccuracy in the text domain, while maintaining the vision performance provided\nby robust image encoders. When combined with text-to-image diffusion models, we\ncan improve the generation quality under adversarial noise. When employing our\nrobust CLIP encoders in multimodal retrieval tasks, we improve the recall under\nadversarial noise over standard CLIP models. Finally, we show that robust text\nencoders facilitate better reconstruction of input text from its embedding via\ndirect optimization.", "AI": {"tldr": "LEAF is an adversarial finetuning method for CLIP text encoders, improving robustness in text domain tasks while maintaining vision performance.", "motivation": "Adversarial attacks on CLIP embeddings can disrupt downstream models, but text encoder robustness is unexplored.", "method": "Proposes LEAF, an efficient adversarial finetuning method for CLIP text encoders, scalable to large models.", "result": "Improves zero-shot adversarial accuracy in text, enhances generation quality in text-to-image models, and boosts recall in retrieval tasks.", "conclusion": "Robust text encoders improve adversarial resilience and enable better text reconstruction from embeddings."}}
{"id": "2506.04121", "pdf": "https://arxiv.org/pdf/2506.04121", "abs": "https://arxiv.org/abs/2506.04121", "authors": ["Loan Dao", "Ngoc Quoc Ly"], "title": "A Comprehensive Study on Medical Image Segmentation using Deep Neural Networks", "categories": ["eess.IV", "cs.AI", "cs.CV"], "comment": null, "summary": "Over the past decade, Medical Image Segmentation (MIS) using Deep Neural\nNetworks (DNNs) has achieved significant performance improvements and holds\ngreat promise for future developments. This paper presents a comprehensive\nstudy on MIS based on DNNs. Intelligent Vision Systems are often evaluated\nbased on their output levels, such as Data, Information, Knowledge,\nIntelligence, and Wisdom (DIKIW),and the state-of-the-art solutions in MIS at\nthese levels are the focus of research. Additionally, Explainable Artificial\nIntelligence (XAI) has become an important research direction, as it aims to\nuncover the \"black box\" nature of previous DNN architectures to meet the\nrequirements of transparency and ethics. The study emphasizes the importance of\nMIS in disease diagnosis and early detection, particularly for increasing the\nsurvival rate of cancer patients through timely diagnosis. XAI and early\nprediction are considered two important steps in the journey from\n\"intelligence\" to \"wisdom.\" Additionally, the paper addresses existing\nchallenges and proposes potential solutions to enhance the efficiency of\nimplementing DNN-based MIS.", "AI": {"tldr": "The paper reviews Medical Image Segmentation (MIS) using Deep Neural Networks (DNNs), focusing on DIKIW levels and Explainable AI (XAI) for transparency. It highlights MIS's role in disease diagnosis and early detection, addressing challenges and proposing solutions.", "motivation": "To advance MIS for disease diagnosis, especially cancer, by leveraging DNNs and XAI for transparency and ethical AI.", "method": "Comprehensive study of MIS based on DNNs, evaluated using DIKIW levels and incorporating XAI for explainability.", "result": "Identifies state-of-the-art MIS solutions and emphasizes XAI's role in bridging intelligence to wisdom.", "conclusion": "MIS with DNNs and XAI is crucial for timely diagnosis, but challenges remain; solutions are proposed for efficient implementation."}}
{"id": "2506.03524", "pdf": "https://arxiv.org/pdf/2506.03524", "abs": "https://arxiv.org/abs/2506.03524", "authors": ["Yuyu Zhang", "Jing Su", "Yifan Sun", "Chenguang Xi", "Xia Xiao", "Shen Zheng", "Anxiang Zhang", "Kaibo Liu", "Daoguang Zan", "Tao Sun", "Jinhua Zhu", "Shulin Xin", "Dong Huang", "Yetao Bai", "Lixin Dong", "Chao Li", "Jianchong Chen", "Hanzhi Zhou", "Yifan Huang", "Guanghan Ning", "Xierui Song", "Jiaze Chen", "Siyao Liu", "Kai Shen", "Liang Xiang", "Yonghui Wu"], "title": "Seed-Coder: Let the Code Model Curate Data for Itself", "categories": ["cs.CL", "cs.SE"], "comment": null, "summary": "Code data in large language model (LLM) pretraining is recognized crucial not\nonly for code-related tasks but also for enhancing general intelligence of\nLLMs. Current open-source LLMs often heavily rely on human effort to produce\ntheir code pretraining data, such as employing hand-crafted filtering rules\ntailored to individual programming languages, or using human-annotated data to\ntrain quality filters. However, these approaches are inherently limited in\nscalability, prone to subjective biases, and costly to extend and maintain\nacross diverse programming languages. To address these challenges, we introduce\nSeed-Coder, a series of open-source LLMs comprising base, instruct and\nreasoning models of 8B size, minimizing human involvement in data construction.\nOur code pretraining data is produced by a model-centric data pipeline, which\npredominantly leverages LLMs for scoring and filtering code data. The instruct\nmodel is further trained via supervised fine-tuning and preference\noptimization, and the reasoning model leverages Long-Chain-of-Thought (LongCoT)\nreinforcement learning to improve multi-step code reasoning. Seed-Coder\nachieves state-of-the-art results among open-source models of similar size and\neven surpasses some much larger models, demonstrating superior performance in\ncode generation, code completion, code editing, code reasoning, and software\nengineering tasks.", "AI": {"tldr": "Seed-Coder is an open-source LLM series (8B size) that minimizes human effort in code pretraining data by using a model-centric pipeline, achieving top performance in code-related tasks.", "motivation": "Current methods for code pretraining data rely heavily on human effort, limiting scalability and introducing biases. Seed-Coder aims to reduce human involvement and improve efficiency.", "method": "Uses a model-centric pipeline for scoring and filtering code data. Includes supervised fine-tuning, preference optimization, and LongCoT reinforcement learning for reasoning.", "result": "Achieves state-of-the-art performance in code generation, completion, editing, reasoning, and software engineering tasks, outperforming similar and larger models.", "conclusion": "Seed-Coder demonstrates the effectiveness of minimizing human involvement in data construction while maintaining high performance in diverse code-related tasks."}}
{"id": "2506.03335", "pdf": "https://arxiv.org/pdf/2506.03335", "abs": "https://arxiv.org/abs/2506.03335", "authors": ["Dheeraj Khanna", "Jerrin Bright", "Yuhao Chen", "John S. Zelek"], "title": "SportMamba: Adaptive Non-Linear Multi-Object Tracking with State Space Models for Team Sports", "categories": ["cs.CV"], "comment": "Paper accepted at CVSports IEEE/CVF Conference on Computer Vision and\n  Pattern Recognition Workshops (CVPRW'25). The paper has 8 pages, including 6\n  Figures and 5 Tables", "summary": "Multi-object tracking (MOT) in team sports is particularly challenging due to\nthe fast-paced motion and frequent occlusions resulting in motion blur and\nidentity switches, respectively. Predicting player positions in such scenarios\nis particularly difficult due to the observed highly non-linear motion\npatterns. Current methods are heavily reliant on object detection and\nappearance-based tracking, which struggle to perform in complex team sports\nscenarios, where appearance cues are ambiguous and motion patterns do not\nnecessarily follow a linear pattern. To address these challenges, we introduce\nSportMamba, an adaptive hybrid MOT technique specifically designed for tracking\nin dynamic team sports. The technical contribution of SportMamba is twofold.\nFirst, we introduce a mamba-attention mechanism that models non-linear motion\nby implicitly focusing on relevant embedding dependencies. Second, we propose a\nheight-adaptive spatial association metric to reduce ID switches caused by\npartial occlusions by accounting for scale variations due to depth changes.\nAdditionally, we extend the detection search space with adaptive buffers to\nimprove associations in fast-motion scenarios. Our proposed technique,\nSportMamba, demonstrates state-of-the-art performance on various metrics in the\nSportsMOT dataset, which is characterized by complex motion and severe\nocclusion. Furthermore, we demonstrate its generalization capability through\nzero-shot transfer to VIP-HTD, an ice hockey dataset.", "AI": {"tldr": "SportMamba is a hybrid MOT technique for team sports, addressing challenges like non-linear motion and occlusions with a mamba-attention mechanism and adaptive spatial association.", "motivation": "Current MOT methods struggle in team sports due to non-linear motion and occlusions, leading to poor tracking performance.", "method": "Introduces a mamba-attention mechanism for non-linear motion modeling and a height-adaptive spatial association metric to reduce ID switches. Also uses adaptive buffers for fast-motion scenarios.", "result": "Achieves state-of-the-art performance on SportsMOT and generalizes well to VIP-HTD (ice hockey).", "conclusion": "SportMamba effectively addresses MOT challenges in dynamic team sports, outperforming existing methods."}}
{"id": "2506.03214", "pdf": "https://arxiv.org/pdf/2506.03214", "abs": "https://arxiv.org/abs/2506.03214", "authors": ["Yi Guo", "Yihang Dong", "Michael Kwok-Po Ng", "Shuqiang Wang"], "title": "A Pre-trained Framework for Multilingual Brain Decoding Using Non-invasive Recordings", "categories": ["q-bio.NC", "cs.AI", "cs.CL"], "comment": null, "summary": "Brain-computer interfaces (BCIs) with speech decoding from brain recordings\nhave broad application potential in fields such as clinical rehabilitation and\ncognitive neuroscience. However, current decoding methods remain limited to\nsingle-language, single-subject, and single neuroimaging modality settings,\nrestricting their clinical applicability and generalizability. Here we propose\na joint multilingual, multi-subject and multimodal decoding framework. It maps\ndiverse brain recordings into a unified semantic space defined by a pre-trained\nmultilingual model (PMM), enabling decoding across multiple languages, multiple\nsubjects and multiple neuroimaging modalities. The proposed framework is\nvalidated using non-invasive brain recordings from 159 participants across four\nlanguages. Experimental results show that it exhibits strong generalization\nacross multilingual, multi-subject, and multimodal settings. More importantly,\nthe proposed framework can promote linguistic fairness, which is vital for\nunderrepresented languages in BCI applications. The unified semantic space\nenables cross-lingual mapping enhancement, allowing the framework to boost the\ndecoding performance of underrepresented languages, thereby promoting\nlinguistic fairness. Overall, the proposed framework establishes a new\npotential paradigm for brain decoding, opening new paths for broader\napplications of BCI.", "AI": {"tldr": "A multilingual, multi-subject, multimodal BCI framework is proposed, validated on 159 participants across four languages, showing strong generalization and promoting linguistic fairness.", "motivation": "Current BCI speech decoding methods are limited to single-language, single-subject, and single-modality settings, restricting clinical applicability and generalizability.", "method": "The framework maps diverse brain recordings into a unified semantic space using a pre-trained multilingual model (PMM), enabling cross-language, cross-subject, and cross-modality decoding.", "result": "Validated on non-invasive brain recordings from 159 participants, the framework shows strong generalization and enhances decoding for underrepresented languages.", "conclusion": "The framework establishes a new paradigm for brain decoding, promoting linguistic fairness and broadening BCI applications."}}
{"id": "2506.03363", "pdf": "https://arxiv.org/pdf/2506.03363", "abs": "https://arxiv.org/abs/2506.03363", "authors": ["Divya Shyamal", "Jiaqi Zhang", "Caroline Uhler"], "title": "Probabilistic Factorial Experimental Design for Combinatorial Interventions", "categories": ["cs.LG", "stat.ME", "stat.ML"], "comment": null, "summary": "A combinatorial intervention, consisting of multiple treatments applied to a\nsingle unit with potentially interactive effects, has substantial applications\nin fields such as biomedicine, engineering, and beyond. Given $p$ possible\ntreatments, conducting all possible $2^p$ combinatorial interventions can be\nlaborious and quickly becomes infeasible as $p$ increases. Here we introduce\nprobabilistic factorial experimental design, formalized from how scientists\nperform lab experiments. In this framework, the experimenter selects a dosage\nfor each possible treatment and applies it to a group of units. Each unit\nindependently receives a random combination of treatments, sampled from a\nproduct Bernoulli distribution determined by the dosages. Additionally, the\nexperimenter can carry out such experiments over multiple rounds, adapting the\ndesign in an active manner. We address the optimal experimental design problem\nwithin an intervention model that imposes bounded-degree interactions between\ntreatments. In the passive setting, we provide a closed-form solution for the\nnear-optimal design. Our results prove that a dosage of $\\tfrac{1}{2}$ for each\ntreatment is optimal up to a factor of $1+O(\\tfrac{\\ln(n)}{n})$ for estimating\nany $k$-way interaction model, regardless of $k$, and imply that\n$O\\big(kp^{3k}\\ln(p)\\big)$ observations are required to accurately estimate\nthis model. For the multi-round setting, we provide a near-optimal acquisition\nfunction that can be numerically optimized. We also explore several extensions\nof the design problem and finally validate our findings through simulations.", "AI": {"tldr": "The paper introduces probabilistic factorial experimental design to efficiently study combinatorial interventions, providing optimal and near-optimal solutions for passive and active settings.", "motivation": "Combinatorial interventions are crucial in fields like biomedicine but testing all combinations is infeasible for large p. The paper aims to formalize a practical experimental design.", "method": "The framework uses product Bernoulli distributions to randomly assign treatments, with dosages optimized for estimating interactions. Solutions are provided for passive and multi-round active settings.", "result": "A dosage of 1/2 is near-optimal for estimating k-way interactions, requiring O(kp^3k ln(p)) observations. A near-optimal acquisition function is also derived for active learning.", "conclusion": "The proposed design efficiently estimates treatment interactions, validated by simulations, and offers scalable solutions for combinatorial experiments."}}
{"id": "2506.04129", "pdf": "https://arxiv.org/pdf/2506.04129", "abs": "https://arxiv.org/abs/2506.04129", "authors": ["Loan Dao", "Ngoc Quoc Ly"], "title": "Recent Advances in Medical Image Classification", "categories": ["eess.IV", "cs.AI", "cs.CV"], "comment": null, "summary": "Medical image classification is crucial for diagnosis and treatment,\nbenefiting significantly from advancements in artificial intelligence. The\npaper reviews recent progress in the field, focusing on three levels of\nsolutions: basic, specific, and applied. It highlights advances in traditional\nmethods using deep learning models like Convolutional Neural Networks and\nVision Transformers, as well as state-of-the-art approaches with Vision\nLanguage Models. These models tackle the issue of limited labeled data, and\nenhance and explain predictive results through Explainable Artificial\nIntelligence.", "AI": {"tldr": "The paper reviews AI advancements in medical image classification, covering basic to applied solutions, including deep learning models and Vision Language Models, addressing data limitations and explainability.", "motivation": "To improve diagnosis and treatment through AI-driven medical image classification, leveraging recent technological progress.", "method": "Reviews three levels of solutions (basic, specific, applied) using deep learning (CNNs, Vision Transformers) and Vision Language Models, with a focus on Explainable AI.", "result": "Highlights advancements in handling limited labeled data and improving predictive accuracy and explainability.", "conclusion": "AI, particularly deep learning and Vision Language Models, significantly enhances medical image classification, addressing key challenges like data scarcity and interpretability."}}
{"id": "2506.03533", "pdf": "https://arxiv.org/pdf/2506.03533", "abs": "https://arxiv.org/abs/2506.03533", "authors": ["Apurva Gandhi", "Graham Neubig"], "title": "Go-Browse: Training Web Agents with Structured Exploration", "categories": ["cs.CL"], "comment": null, "summary": "One of the fundamental problems in digital agents is their lack of\nunderstanding of their environment. For instance, a web browsing agent may get\nlost in unfamiliar websites, uncertain what pages must be visited to achieve\nits goals. To address this, we propose Go-Browse, a method for automatically\ncollecting diverse and realistic web agent data at scale through structured\nexploration of web environments. Go-Browse achieves efficient exploration by\nframing data collection as a graph search, enabling reuse of information across\nexploration episodes. We instantiate our method on the WebArena benchmark,\ncollecting a dataset of 10K successful task-solving trajectories and 40K\ninteraction steps across 100 URLs. Fine-tuning a 7B parameter language model on\nthis dataset achieves a success rate of 21.7% on the WebArena benchmark,\nbeating GPT-4o mini by 2.4% and exceeding current state-of-the-art results for\nsub-10B parameter models by 2.9%.", "AI": {"tldr": "Go-Browse improves web agent performance by collecting diverse data via structured exploration, achieving better results than GPT-4o mini and state-of-the-art sub-10B models.", "motivation": "Digital agents often struggle with understanding unfamiliar environments, like web browsing.", "method": "Go-Browse frames data collection as graph search for efficient exploration, tested on WebArena with 10K trajectories and 40K steps.", "result": "Fine-tuning a 7B model on the dataset yields a 21.7% success rate, outperforming benchmarks.", "conclusion": "Structured exploration enhances agent performance, demonstrating scalability and effectiveness."}}
{"id": "2506.03340", "pdf": "https://arxiv.org/pdf/2506.03340", "abs": "https://arxiv.org/abs/2506.03340", "authors": ["Zihui Xue", "Mi Luo", "Kristen Grauman"], "title": "Seeing the Arrow of Time in Large Multimodal Models", "categories": ["cs.CV"], "comment": "Project website: https://vision.cs.utexas.edu/projects/SeeAoT", "summary": "The Arrow of Time (AoT)-time's irreversible flow shaping physical events-is\nfundamental to video comprehension, yet remains a significant challenge for\nmodern large multimodal models (LMMs). Current LMMs struggle to perceive and\nutilize temporal directionality in video when responding to language queries,\nobstructing deeper temporal understanding. We tackle this deficiency by first\nproviding a critical analysis of existing benchmarks and models. We then\nintroduce ArrowRL, a reinforcement learning (RL)-based training strategy with\nan innovative reverse reward that instills AoT awareness by encouraging\ndivergent video interpretations between forward and reversed visual frames. For\nrigorous evaluation, we additionally develop AoTBench, a new multi-faceted\nbenchmark probing temporally challenging questions. Experiments show ArrowRL\ngreatly advances temporal perception: it not only achieves substantial\nimprovements on our challenging AoTBench but also demonstrably boosts\nperformance on standard video question answering (VQA) benchmarks (with peak\naccuracy gains reaching over 20% and 10% respectively). This validates\nArrowRL's effectiveness and highlights the critical need for dedicated AoT\nunderstanding in LMMs.", "AI": {"tldr": "ArrowRL, an RL-based training strategy with reverse reward, improves temporal perception in LMMs, validated by AoTBench and standard VQA benchmarks.", "motivation": "Addressing the challenge of LMMs' inability to perceive temporal directionality in videos, hindering deeper temporal understanding.", "method": "Introduces ArrowRL, a reinforcement learning strategy with a reverse reward to instill AoT awareness by contrasting forward and reversed video interpretations.", "result": "Substantial improvements on AoTBench and standard VQA benchmarks, with peak accuracy gains of over 20% and 10% respectively.", "conclusion": "ArrowRL effectively enhances AoT understanding in LMMs, demonstrating the need for dedicated temporal perception."}}
{"id": "2506.03218", "pdf": "https://arxiv.org/pdf/2506.03218", "abs": "https://arxiv.org/abs/2506.03218", "authors": ["Alina Wernick", "Kristof Meding"], "title": "Beware! The AI Act Can Also Apply to Your AI Research Practices", "categories": ["cs.CY", "cs.AI", "cs.LG"], "comment": null, "summary": "The EU has become one of the vanguards in regulating the digital age. A\nparticularly important regulation in the Artificial Intelligence (AI) domain is\nthe EU AI Act, which entered into force in 2024. The AI Act specifies -- due to\na risk-based approach -- various obligations for providers of AI systems. These\nobligations, for example, include a cascade of documentation and compliance\nmeasures, which represent a potential obstacle to science. But do these\nobligations also apply to AI researchers? This position paper argues that,\nindeed, the AI Act's obligations could apply in many more cases than the AI\ncommunity is aware of. In our analysis of the AI Act and its applicability, we\ncontribute the following: 1.) We give a high-level introduction to the AI Act\naimed at non-legal AI research scientists. 2.) We explain with everyday\nresearch examples why the AI Act applies to research. 3.) We analyse the\nexceptions of the AI Act's applicability and state that especially scientific\nresearch exceptions fail to account for current AI research practices. 4.) We\npropose changes to the AI Act to provide more legal certainty for AI\nresearchers and give two recommendations for AI researchers to reduce the risk\nof not complying with the AI Act. We see our paper as a starting point for a\ndiscussion between policymakers, legal scholars, and AI researchers to avoid\nunintended side effects of the AI Act on research.", "AI": {"tldr": "The paper discusses the EU AI Act's potential impact on AI research, arguing its obligations may apply more broadly than realized, and proposes changes to better accommodate research practices.", "motivation": "To highlight the AI Act's overlooked applicability to AI research and its potential obstacles, advocating for clearer exceptions and legal certainty.", "method": "Analyzes the AI Act's provisions, provides research examples, evaluates exceptions, and proposes amendments.", "result": "Finds current scientific exceptions inadequate for AI research practices and suggests changes to mitigate compliance risks.", "conclusion": "Calls for dialogue among policymakers, legal experts, and researchers to refine the AI Act and protect research interests."}}
{"id": "2506.03370", "pdf": "https://arxiv.org/pdf/2506.03370", "abs": "https://arxiv.org/abs/2506.03370", "authors": ["Leonid Ryvkin"], "title": "Comparison of different Unique hard attention transformer models by the formal languages they can recognize", "categories": ["cs.LG", "cs.CL", "cs.FL"], "comment": null, "summary": "This note is a survey of various results on the capabilities of unique hard\nattention transformers encoders (UHATs) to recognize formal languages. We\ndistinguish between masked vs. non-masked, finite vs. infinite image and\ngeneral vs. bilinear attention score functions. We recall some relations\nbetween these models, as well as a lower bound in terms of first-order logic\nand an upper bound in terms of circuit complexity.", "AI": {"tldr": "Survey on unique hard attention transformers (UHATs) for formal language recognition, comparing masked/non-masked, finite/infinite image, and general/bilinear attention scores.", "motivation": "To explore the capabilities of UHATs in recognizing formal languages by analyzing different variants and their relationships.", "method": "Comparison of UHAT variants (masked/non-masked, finite/infinite image, general/bilinear attention scores) and theoretical analysis using first-order logic and circuit complexity.", "result": "Relations between UHAT variants identified, with a lower bound in first-order logic and an upper bound in circuit complexity.", "conclusion": "UHATs exhibit varied capabilities in formal language recognition, with theoretical bounds providing insights into their computational power."}}
{"id": "2506.04173", "pdf": "https://arxiv.org/pdf/2506.04173", "abs": "https://arxiv.org/abs/2506.04173", "authors": ["Savannah P. Hays", "Lianrui Zuo", "Anqi Feng", "Yihao Liu", "Blake E. Dewey", "Jiachen Zhuo", "Ellen M. Mowry", "Scott D. Newsome Jerry L. Prince", "Aaron Carass"], "title": "Synthetic multi-inversion time magnetic resonance images for visualization of subcortical structures", "categories": ["eess.IV"], "comment": "Under review at the Journal of Medical Imaging", "summary": "Purpose: Visualization of subcortical gray matter is essential in\nneuroscience and clinical practice, particularly for disease understanding and\nsurgical planning.While multi-inversion time (multi-TI) T$_1$-weighted\n(T$_1$-w) magnetic resonance (MR) imaging improves visualization, it is rarely\nacquired in clinical settings. Approach: We present SyMTIC (Synthetic Multi-TI\nContrasts), a deep learning method that generates synthetic multi-TI images\nusing routinely acquired T$_1$-w, T$_2$-weighted (T$_2$-w), and FLAIR images.\nOur approach combines image translation via deep neural networks with imaging\nphysics to estimate longitudinal relaxation time (T$_1$) and proton density\n(PD) maps. These maps are then used to compute multi-TI images with arbitrary\ninversion times. Results: SyMTIC was trained using paired MPRAGE and FGATIR\nimages along with T$_2$-w and FLAIR images. It accurately synthesized multi-TI\nimages from standard clinical inputs, achieving image quality comparable to\nthat from explicitly acquired multi-TI data.The synthetic images, especially\nfor TI values between 400-800 ms, enhanced visualization of subcortical\nstructures and improved segmentation of thalamic nuclei. Conclusion: SyMTIC\nenables robust generation of high-quality multi-TI images from routine MR\ncontrasts. It generalizes well to varied clinical datasets, including those\nwith missing FLAIR images or unknown parameters, offering a practical solution\nfor improving brain MR image visualization and analysis.", "AI": {"tldr": "SyMTIC uses deep learning to generate synthetic multi-TI MR images from routine T1-w, T2-w, and FLAIR scans, improving subcortical visualization.", "motivation": "Multi-TI T1-w MR imaging enhances subcortical visualization but is rarely used clinically. SyMTIC aims to bridge this gap by synthesizing multi-TI images from standard scans.", "method": "SyMTIC combines deep neural networks with imaging physics to estimate T1 and PD maps, then computes multi-TI images with arbitrary inversion times.", "result": "SyMTIC accurately synthesized multi-TI images, enhancing subcortical visualization and thalamic nuclei segmentation, especially for TI values 400-800 ms.", "conclusion": "SyMTIC provides a practical solution for generating high-quality multi-TI images from routine MR contrasts, improving brain image analysis."}}
{"id": "2506.03541", "pdf": "https://arxiv.org/pdf/2506.03541", "abs": "https://arxiv.org/abs/2506.03541", "authors": ["Xiaofeng Zhou", "Heyan Huang", "Lizi Liao"], "title": "Debate, Reflect, and Distill: Multi-Agent Feedback with Tree-Structured Preference Optimization for Efficient Language Model Enhancement", "categories": ["cs.CL", "cs.AI"], "comment": "16 pages, 10 figures. The camera-ready paper for Findings of ACL 2025", "summary": "Large Language Models (LLMs) continue to set new standards in\nknowledge-intensive and complex reasoning tasks, yet their high computational\ndemands limit widespread adoption. While distilling large models into smaller\nones offers a sustainable solution, current techniques--such as static\nknowledge distillation, resource-intensive reinforcement learning from human\nfeedback, or limited self-reflection--struggle to yield substantial and lasting\nperformance gains. In this paper, we present a novel Debate and Reflect (D&R)\nframework that orchestrates multi-turn debates between smaller models and\nstronger teacher models, eliciting actionable feedback (e.g., error analysis,\ncorrective strategies) to guide student models. Further, we introduce\nTree-structured Direct Preference Optimization (T-DPO) to efficiently leverage\nthese debate logs, organizing interactions into a hierarchical format for\neffective training. Empirical evaluations across diverse NLP benchmarks\ndemonstrate that our approach significantly improves smaller-model accuracy,\nrobustness, and generalization, outperforming conventional baselines by a large\nmargin.", "AI": {"tldr": "A novel Debate and Reflect (D&R) framework improves smaller LLMs by facilitating multi-turn debates with teacher models, combined with Tree-structured Direct Preference Optimization (T-DPO) for efficient training.", "motivation": "High computational demands of large LLMs limit adoption; current distillation methods lack lasting performance gains.", "method": "D&R framework for debates between smaller and teacher models, plus T-DPO for hierarchical training from debate logs.", "result": "Significant accuracy, robustness, and generalization improvements in smaller models, outperforming baselines.", "conclusion": "The D&R framework and T-DPO offer an effective solution for enhancing smaller LLMs sustainably."}}
{"id": "2506.03345", "pdf": "https://arxiv.org/pdf/2506.03345", "abs": "https://arxiv.org/abs/2506.03345", "authors": ["Chien-Fu", "Huang", "Katherine Sieg", "Leonid Karlinksy", "Nash Flores", "Rebekah Sheraw", "Xin Zhang"], "title": "Semiconductor SEM Image Defect Classification Using Supervised and Semi-Supervised Learning with Vision Transformers", "categories": ["cs.CV"], "comment": "Published at 36th Annual SEMI Advanced Semiconductor Manufacturing\n  Conference (ASMC) 2025", "summary": "Controlling defects in semiconductor processes is important for maintaining\nyield, improving production cost, and preventing time-dependent critical\ncomponent failures. Electron beam-based imaging has been used as a tool to\nsurvey wafers in the line and inspect for defects. However, manual\nclassification of images for these nano-scale defects is limited by time, labor\nconstraints, and human biases. In recent years, deep learning computer vision\nalgorithms have shown to be effective solutions for image-based inspection\napplications in industry. This work proposes application of vision transformer\n(ViT) neural networks for automatic defect classification (ADC) of scanning\nelectron microscope (SEM) images of wafer defects. We evaluated our proposed\nmethods on 300mm wafer semiconductor defect data from our fab in IBM Albany. We\nstudied 11 defect types from over 7400 total images and investigated the\npotential of transfer learning of DinoV2 and semi-supervised learning for\nimproved classification accuracy and efficient computation. We were able to\nachieve classification accuracies of over 90% with less than 15 images per\ndefect class. Our work demonstrates the potential to apply the proposed\nframework for a platform agnostic in-house classification tool with faster\nturnaround time and flexibility.", "AI": {"tldr": "The paper proposes using vision transformer (ViT) networks for automatic defect classification in semiconductor wafer images, achieving over 90% accuracy with minimal training data.", "motivation": "Manual defect classification is slow, labor-intensive, and prone to bias, necessitating automated solutions.", "method": "Applied ViT networks, transfer learning (DinoV2), and semi-supervised learning to classify 11 defect types from SEM images.", "result": "Achieved over 90% classification accuracy with fewer than 15 images per defect class.", "conclusion": "The framework offers a fast, flexible, and platform-agnostic solution for in-house defect classification."}}
{"id": "2506.03231", "pdf": "https://arxiv.org/pdf/2506.03231", "abs": "https://arxiv.org/abs/2506.03231", "authors": ["Yajie Zhou", "Jiajun Ruan", "Eric S. Wang", "Sadjad Fouladi", "Francis Y. Yan", "Kevin Hsieh", "Zaoxing Liu"], "title": "NetPress: Dynamically Generated LLM Benchmarks for Network Applications", "categories": ["cs.NI", "cs.AI", "cs.LG"], "comment": null, "summary": "Despite growing interest in domain-specific benchmarking of large language\nmodels (LLMs) and agents, current evaluations remain limited to static,\nsmall-scale datasets, especially in high-stakes tasks like network operations\nthat demand reliability for deployments. We present NetPress, an automated\nbenchmark generation framework for evaluating LLM agents in network\napplications. NetPress introduces a unified abstraction with state and action,\nenabling dynamic generation of diverse query sets along with corresponding\nground truths. At runtime, users can specify benchmark configurations to\ngenerate millions of queries on the fly. In addition to dynamic benchmark\nconstruction, NetPress integrates with network emulators to provide realistic\nenvironment feedback, supporting comprehensive evaluation across correctness,\nsafety, and latency. We instantiate NetPress on three representative\napplications, revealing interesting fine-grained differences in agent behavior\nthat static, correctness-only benchmarks often miss. NetPress moves LLM\nevaluation toward realistic, scalable testing in infrastructure-centric\ndomains, helping close the gap between benchmark performance and real-world\ndeployment readiness. Code is available at\nhttps://github.com/Froot-NetSys/NetPress.", "AI": {"tldr": "NetPress is an automated benchmark framework for evaluating LLM agents in network applications, enabling dynamic query generation and realistic environment feedback.", "motivation": "Current evaluations for LLMs in high-stakes tasks like network operations are limited to static, small-scale datasets, lacking reliability for real-world deployment.", "method": "NetPress introduces a unified abstraction with state and action for dynamic query generation and integrates with network emulators for realistic feedback.", "result": "The framework generates millions of queries on the fly and reveals fine-grained agent behaviors missed by static benchmarks.", "conclusion": "NetPress advances LLM evaluation toward scalable, realistic testing in infrastructure-centric domains, bridging the gap between benchmarks and deployment readiness."}}
{"id": "2506.03374", "pdf": "https://arxiv.org/pdf/2506.03374", "abs": "https://arxiv.org/abs/2506.03374", "authors": ["Haley Dozier", "Althea Henslee", "Ashley Abraham", "Andrew Strelzoff", "Mark Chappell"], "title": "Product Quantization for Surface Soil Similarity", "categories": ["cs.LG"], "comment": "To be published in the CSCE 2022 proceedings", "summary": "The use of machine learning (ML) techniques has allowed rapid advancements in\nmany scientific and engineering fields. One of these problems is that of\nsurface soil taxonomy, a research area previously hindered by the reliance on\nhuman-derived classifications, which are mostly dependent on dividing a dataset\nbased on historical understandings of that data rather than data-driven,\nstatistically observable similarities. Using a ML-based taxonomy allows soil\nresearchers to move beyond the limitations of human visualization and create\nclassifications of high-dimension datasets with a much higher level of\nspecificity than possible with hand-drawn taxonomies. Furthermore, this\npipeline allows for the possibility of producing both highly accurate and\nflexible soil taxonomies with classes built to fit a specific application. The\nmachine learning pipeline outlined in this work combines product quantization\nwith the systematic evaluation of parameters and output to get the best\navailable results, rather than accepting sub-optimal results by using either\ndefault settings or best guess settings.", "AI": {"tldr": "ML-based soil taxonomy improves specificity and accuracy over human-derived classifications by leveraging data-driven similarities and systematic parameter evaluation.", "motivation": "Overcome limitations of human-derived soil classifications, which rely on historical data rather than observable similarities.", "method": "Combines product quantization with systematic parameter and output evaluation to optimize results.", "result": "Produces highly accurate and flexible soil taxonomies tailored to specific applications.", "conclusion": "ML enables more precise and adaptable soil classifications than traditional methods."}}
{"id": "2506.03645", "pdf": "https://arxiv.org/pdf/2506.03645", "abs": "https://arxiv.org/abs/2506.03645", "authors": ["Hansen Feng", "Lizhi Wang", "Yiqi Huang", "Tong Li", "Lin Zhu", "Hua Huang"], "title": "YOND: Practical Blind Raw Image Denoising Free from Camera-Specific Data Dependency", "categories": ["cs.CV", "eess.IV"], "comment": "17 pages, 19 figures, TPAMI under review", "summary": "The rapid advancement of photography has created a growing demand for a\npractical blind raw image denoising method. Recently, learning-based methods\nhave become mainstream due to their excellent performance. However, most\nexisting learning-based methods suffer from camera-specific data dependency,\nresulting in performance drops when applied to data from unknown cameras. To\naddress this challenge, we introduce a novel blind raw image denoising method\nnamed YOND, which represents You Only Need a Denoiser. Trained solely on\nsynthetic data, YOND can generalize robustly to noisy raw images captured by\ndiverse unknown cameras. Specifically, we propose three key modules to\nguarantee the practicality of YOND: coarse-to-fine noise estimation (CNE),\nexpectation-matched variance-stabilizing transform (EM-VST), and SNR-guided\ndenoiser (SNR-Net). Firstly, we propose CNE to identify the camera noise\ncharacteristic, refining the estimated noise parameters based on the coarse\ndenoised image. Secondly, we propose EM-VST to eliminate camera-specific data\ndependency, correcting the bias expectation of VST according to the noisy\nimage. Finally, we propose SNR-Net to offer controllable raw image denoising,\nsupporting adaptive adjustments and manual fine-tuning. Extensive experiments\non unknown cameras, along with flexible solutions for challenging cases,\ndemonstrate the superior practicality of our method. The source code will be\npublicly available at the\n\\href{https://fenghansen.github.io/publication/YOND}{project homepage}.", "AI": {"tldr": "YOND is a novel blind raw image denoising method that generalizes to unknown cameras using synthetic data, featuring CNE, EM-VST, and SNR-Net modules.", "motivation": "Addressing the camera-specific data dependency issue in existing learning-based denoising methods.", "method": "Proposes three modules: CNE for noise estimation, EM-VST for eliminating camera dependency, and SNR-Net for controllable denoising.", "result": "Demonstrates superior practicality on unknown cameras and challenging cases.", "conclusion": "YOND offers a robust, flexible solution for blind raw image denoising, with code publicly available."}}
{"id": "2506.03557", "pdf": "https://arxiv.org/pdf/2506.03557", "abs": "https://arxiv.org/abs/2506.03557", "authors": ["Lin Sun", "Chuang Liu", "Peng Liu", "Bingyang Li", "Weijia Lu", "Ning Wu"], "title": "BPO: Revisiting Preference Modeling in Direct Preference Optimization", "categories": ["cs.CL"], "comment": null, "summary": "Direct Preference Optimization (DPO) have emerged as a popular method for\naligning Large Language Models (LLMs) with human preferences. While DPO\neffectively preserves the relative ordering between chosen and rejected\nresponses through pairwise ranking losses, it often neglects absolute reward\nmagnitudes. This oversight can decrease the likelihood of chosen responses and\nincrease the risk of generating out-of-distribution responses, leading to poor\nperformance. We term this issue Degraded Chosen Responses (DCR).To address this\nissue, we propose Balanced Preference Optimization (BPO), a novel framework\nthat dynamically balances the optimization of chosen and rejected responses\nthrough two key components: balanced reward margin and gap adaptor. Unlike\nprevious methods, BPO can fundamentally resolve DPO's DCR issue, without\nintroducing additional constraints to the loss function. Experimental results\non multiple mathematical reasoning tasks show that BPO significantly\noutperforms DPO, improving accuracy by +10.1% with Llama-3.1-8B-Instruct (18.8%\nto 28.9%) and +11.7% with Qwen2.5-Math-7B (35.0% to 46.7%). It also surpasses\nDPO variants by +3.6% over IPO (43.1%), +5.0% over SLiC (41.7%), and +3.1% over\nCal-DPO (43.6%) on the same model. Remarkably, our algorithm requires only a\nsingle line of code modification, making it simple to implement and fully\ncompatible with existing DPO-based frameworks.", "AI": {"tldr": "BPO addresses DPO's DCR issue by balancing chosen and rejected responses, improving accuracy without extra constraints.", "motivation": "DPO neglects absolute reward magnitudes, causing degraded chosen responses (DCR).", "method": "BPO introduces balanced reward margin and gap adaptor to dynamically optimize responses.", "result": "BPO outperforms DPO and variants, e.g., +10.1% accuracy with Llama-3.1-8B-Instruct.", "conclusion": "BPO resolves DCR with minimal code changes, maintaining compatibility with DPO frameworks."}}
{"id": "2506.03371", "pdf": "https://arxiv.org/pdf/2506.03371", "abs": "https://arxiv.org/abs/2506.03371", "authors": ["Xiaonan Wang", "Bo Shao", "Hansaem Kim"], "title": "Toward Reliable VLM: A Fine-Grained Benchmark and Framework for Exposure, Bias, and Inference in Korean Street Views", "categories": ["cs.CV"], "comment": null, "summary": "Recent advances in vision-language models (VLMs) have enabled accurate\nimage-based geolocation, raising serious concerns about location privacy risks\nin everyday social media posts. However, current benchmarks remain\ncoarse-grained, linguistically biased, and lack multimodal and privacy-aware\nevaluations. To address these gaps, we present KoreaGEO Bench, the first\nfine-grained, multimodal geolocation benchmark for Korean street views. Our\ndataset comprises 1,080 high-resolution images sampled across four urban\nclusters and nine place types, enriched with multi-contextual annotations and\ntwo styles of Korean captions simulating real-world privacy exposure. We\nintroduce a three-path evaluation protocol to assess ten mainstream VLMs under\nvarying input modalities and analyze their accuracy, spatial bias, and\nreasoning behavior. Results reveal modality-driven shifts in localization\nprecision and highlight structural prediction biases toward core cities.", "AI": {"tldr": "The paper introduces KoreaGEO Bench, a fine-grained, multimodal geolocation benchmark for Korean street views, addressing gaps in current benchmarks by providing detailed evaluations of vision-language models (VLMs) under varying input modalities.", "motivation": "Current benchmarks for image-based geolocation are coarse-grained, linguistically biased, and lack multimodal and privacy-aware evaluations, raising concerns about location privacy risks in social media posts.", "method": "The authors create KoreaGEO Bench, a dataset of 1,080 high-resolution Korean street view images with multi-contextual annotations and captions. They evaluate ten VLMs using a three-path protocol to analyze accuracy, spatial bias, and reasoning behavior.", "result": "Results show modality-driven shifts in localization precision and structural prediction biases toward core cities.", "conclusion": "KoreaGEO Bench provides a comprehensive evaluation framework for VLMs in geolocation tasks, highlighting biases and precision variations based on input modalities."}}
{"id": "2506.03237", "pdf": "https://arxiv.org/pdf/2506.03237", "abs": "https://arxiv.org/abs/2506.03237", "authors": ["Jigang Fan", "Quanlin Wu", "Shengjie Luo", "Liwei Wang"], "title": "UniSite: The First Cross-Structure Dataset and Learning Framework for End-to-End Ligand Binding Site Detection", "categories": ["q-bio.QM", "cs.AI", "cs.LG", "q-bio.BM"], "comment": null, "summary": "The detection of ligand binding sites for proteins is a fundamental step in\nStructure-Based Drug Design. Despite notable advances in recent years, existing\nmethods, datasets, and evaluation metrics are confronted with several key\nchallenges: (1) current datasets and methods are centered on individual\nprotein-ligand complexes and neglect that diverse binding sites may exist\nacross multiple complexes of the same protein, introducing significant\nstatistical bias; (2) ligand binding site detection is typically modeled as a\ndiscontinuous workflow, employing binary segmentation and subsequent clustering\nalgorithms; (3) traditional evaluation metrics do not adequately reflect the\nactual performance of different binding site prediction methods. To address\nthese issues, we first introduce UniSite-DS, the first UniProt (Unique\nProtein)-centric ligand binding site dataset, which contains 4.81 times more\nmulti-site data and 2.08 times more overall data compared to the previously\nmost widely used datasets. We then propose UniSite, the first end-to-end ligand\nbinding site detection framework supervised by set prediction loss with\nbijective matching. In addition, we introduce Average Precision based on\nIntersection over Union (IoU) as a more accurate evaluation metric for ligand\nbinding site prediction. Extensive experiments on UniSite-DS and several\nrepresentative benchmark datasets demonstrate that IoU-based Average Precision\nprovides a more accurate reflection of prediction quality, and that UniSite\noutperforms current state-of-the-art methods in ligand binding site detection.\nThe dataset and codes will be made publicly available at\nhttps://github.com/quanlin-wu/unisite.", "AI": {"tldr": "The paper introduces UniSite-DS, a new dataset for ligand binding site detection, and UniSite, an end-to-end framework, addressing biases and evaluation issues in current methods.", "motivation": "Current datasets and methods for ligand binding site detection suffer from statistical bias, discontinuous workflows, and inadequate evaluation metrics.", "method": "The authors propose UniSite-DS, a UniProt-centric dataset, and UniSite, an end-to-end framework using set prediction loss with bijective matching. They also introduce IoU-based Average Precision for evaluation.", "result": "UniSite outperforms state-of-the-art methods, and the new evaluation metric provides more accurate performance reflection.", "conclusion": "The UniSite framework and UniSite-DS dataset address key challenges in ligand binding site detection, improving accuracy and evaluation."}}
{"id": "2506.03392", "pdf": "https://arxiv.org/pdf/2506.03392", "abs": "https://arxiv.org/abs/2506.03392", "authors": ["Aref Ghoreishee", "Abhishek Mishra", "John Walsh", "Anup Das", "Nagarajan Kandasamy"], "title": "Improving Performance of Spike-based Deep Q-Learning using Ternary Neurons", "categories": ["cs.LG", "cs.NE", "cs.SY", "eess.SY"], "comment": null, "summary": "We propose a new ternary spiking neuron model to improve the representation\ncapacity of binary spiking neurons in deep Q-learning. Although a ternary\nneuron model has recently been introduced to overcome the limited\nrepresentation capacity offered by the binary spiking neurons, we show that its\nperformance is worse than that of binary models in deep Q-learning tasks. We\nhypothesize gradient estimation bias during the training process as the\nunderlying potential cause through mathematical and empirical analysis. We\npropose a novel ternary spiking neuron model to mitigate this issue by reducing\nthe estimation bias. We use the proposed ternary spiking neuron as the\nfundamental computing unit in a deep spiking Q-learning network (DSQN) and\nevaluate the network's performance in seven Atari games from the Gym\nenvironment. Results show that the proposed ternary spiking neuron mitigates\nthe drastic performance degradation of ternary neurons in Q-learning tasks and\nimproves the network performance compared to the existing binary neurons,\nmaking DSQN a more practical solution for on-board autonomous decision-making\ntasks.", "AI": {"tldr": "A new ternary spiking neuron model is proposed to enhance representation capacity in deep Q-learning, outperforming binary and existing ternary models by addressing gradient estimation bias.", "motivation": "To overcome the limited representation capacity of binary spiking neurons and the poor performance of existing ternary models in deep Q-learning tasks.", "method": "Proposes a novel ternary spiking neuron model to reduce gradient estimation bias, integrated into a deep spiking Q-learning network (DSQN).", "result": "The proposed model mitigates performance degradation in ternary neurons and outperforms binary neurons in Atari game tasks.", "conclusion": "The ternary spiking neuron model improves DSQN performance, making it more practical for autonomous decision-making."}}
{"id": "2506.03738", "pdf": "https://arxiv.org/pdf/2506.03738", "abs": "https://arxiv.org/abs/2506.03738", "authors": ["Francesca Borrelli", "Giusy Giugliano", "Emilie Houliez", "Jaromir Behal", "Daniele Pirone", "Leonilde Roselli", "Angela Sardo", "Valerio Zupo", "Maria Costantini", "Lisa Miccio", "Pasquale Memmolo", "Vittorio Bianco", "Pietro Ferraro"], "title": "3D Holographic Flow Cytometry Measurements of Microalgae: Strategies for Angle Recovery in Complex Rotation Patterns", "categories": ["physics.bio-ph", "cs.SY", "eess.IV", "eess.SY"], "comment": null, "summary": "Marine ecosystems are in the spotlight, because environmental changes are\nthreatening biodiversity and ecological functions. In this context, microalgae\nplay key ecological roles both in planktonic and benthic ecosystems.\nConsequently, they are considered indispensable targets for global monitoring\nprograms. However, due to a high spatial and temporal variability and to\ndifficulties of species identification (still relying on microscopy\nobservations), the assessment of roles played by these components of marine\necosystems is demanding. In addition, technologies for a 3D assessment of their\ncomplex morphology are scarcely available. Here, we present a comprehensive\nworkflow for retrieving 3D information on microalgae with diverse geometries\nthrough holographic microscopy operating in flow-cytometry mode. Depending on\nthe rotation patterns of samples, a tailored approach is used to retrieve their\nrolling angles. We demonstrate the feasibility of measuring 3D data of various\nmicroalgae, contingent to the intrinsic optical properties of cells.\nSpecifically, we show that for quasi-transparent and low-scattering\nmicroorganisms, the retrieved angles permit to achieve quantitative 3D\ntomographic Refractive Index (RI) mapping, providing a full characterization of\nthe alga in terms of its inner structure and the outer shape. Moreover, even in\nthe most challenging scenarios, where microalgae exhibit high light absorption\nor strong scattering, quantitative 3D shape reconstructions of diatoms and\ndinoflagellates can be at least achieved. Finally, we compare our direct 3D\nmeasurements with 2D inferences of 3D properties, obtained using a commercially\navailable microscopy system. The ability to non-invasively obtain 3D\ninformation on microalgae marks a fundamental advancement in the field,\nunlocking a wealth of novel biological insights for characterizing aquatic\necosystems.", "AI": {"tldr": "A workflow using holographic microscopy in flow-cytometry mode is introduced to measure 3D data of microalgae, enabling detailed 3D tomographic mapping and shape reconstruction, even for challenging cases.", "motivation": "Marine ecosystems face threats from environmental changes, and microalgae are key ecological components. Current methods for assessing their roles are limited by high variability, identification difficulties, and lack of 3D assessment technologies.", "method": "Holographic microscopy in flow-cytometry mode is used to retrieve 3D information, including rolling angles and tomographic refractive index mapping, tailored to microalgae's optical properties.", "result": "The method successfully measures 3D data for various microalgae, including quasi-transparent and low-scattering species, and achieves shape reconstructions for high-absorption or strong-scattering cases.", "conclusion": "This non-invasive 3D measurement technique advances microalgae characterization, offering new biological insights for monitoring aquatic ecosystems."}}
{"id": "2506.03558", "pdf": "https://arxiv.org/pdf/2506.03558", "abs": "https://arxiv.org/abs/2506.03558", "authors": ["Jiawei Chen", "Xinyan Guan", "Qianhao Yuan", "Guozhao Mo", "Weixiang Zhou", "Yaojie Lu", "Hongyu Lin", "Ben He", "Le Sun", "Xianpei Han"], "title": "ConsistentChat: Building Skeleton-Guided Consistent Dialogues for Large Language Models from Scratch", "categories": ["cs.CL"], "comment": null, "summary": "Current instruction data synthesis methods primarily focus on single-turn\ninstructions and often neglect cross-turn coherence, resulting in context drift\nand reduced task completion rates in extended conversations. To address this\nlimitation, we propose Skeleton-Guided Multi-Turn Dialogue Generation, a\nframework that constrains multi-turn instruction synthesis by explicitly\nmodeling human conversational intent. It operates in two stages: (1) Intent\nModeling, which captures the global structure of human dialogues by assigning\neach conversation to one of nine well-defined intent trajectories, ensuring a\ncoherent and goal-oriented information flow; and (2) Skeleton Generation, which\nconstructs a structurally grounded sequence of user queries aligned with the\nmodeled intent, thereby serving as a scaffold that constrains and guides the\ndownstream instruction synthesis process. Based on this process, we construct\nConsistentChat, a multi-turn instruction dataset with approximately 15,000\nmulti-turn conversations and 224,392 utterances. Experiments on the Light,\nTopdial, and MT-Eval benchmarks show that models fine-tuned on ConsistentChat\nachieve a 20-30% improvement in chat consistency and up to a 15% increase in\ntask success rate, significantly outperforming models trained on existing\nsingle-turn and multi-turn instruction datasets.", "AI": {"tldr": "Skeleton-Guided Multi-Turn Dialogue Generation improves multi-turn instruction synthesis by modeling human intent, enhancing coherence and task success.", "motivation": "Addressing the neglect of cross-turn coherence in current instruction data synthesis methods, which leads to context drift and reduced task completion.", "method": "A two-stage framework: (1) Intent Modeling for global dialogue structure, and (2) Skeleton Generation to align queries with intent.", "result": "Models fine-tuned on ConsistentChat show 20-30% better chat consistency and up to 15% higher task success.", "conclusion": "The proposed method significantly outperforms existing datasets in multi-turn dialogue coherence and task completion."}}
{"id": "2506.03373", "pdf": "https://arxiv.org/pdf/2506.03373", "abs": "https://arxiv.org/abs/2506.03373", "authors": ["Muhammad Shaban", "Yuzhou Chang", "Huaying Qiu", "Yao Yu Yeo", "Andrew H. Song", "Guillaume Jaume", "Yuchen Wang", "Luca L. Weishaupt", "Tong Ding", "Anurag Vaidya", "Abdallah Lamane", "Daniel Shao", "Mohammed Zidane", "Yunhao Bai", "Paige McCallum", "Shuli Luo", "Wenrui Wu", "Yang Wang", "Precious Cramer", "Chi Ngai Chan", "Pierre Stephan", "Johanna Schaffenrath", "Jia Le Lee", "Hendrik A. Michel", "Caiwei Tian", "Cristina Almagro-Perez", "Sophia J. Wagner", "Sharifa Sahai", "Ming Y. Lu", "Richard J. Chen", "Andrew Zhang", "Mark Edward M. Gonzales", "Ahmad Makky", "Jia-Ying Joey Lee", "Hao Cheng", "Nourhan El Ahmar", "Sayed Matar", "Maximilian Haist", "Darci Phillips", "Yuqi Tan", "Garry P. Nolan", "W. Richard Burack", "Jacob D. Estes", "Jonathan T. C. Liu", "Toni K Choueiri", "Neeraj Agarwal", "Marc Barry", "Scott J. Rodig", "Long Phi Le", "Georg Gerber", "Christian M. Sch\u00fcrch", "Fabian J. Theis", "Youn H Kim", "Joe Yeong", "Sabina Signoretti", "Brooke E. Howitt", "Lit-Hsin Loo", "Qin Ma", "Sizun Jiang", "Faisal Mahmood"], "title": "A Foundation Model for Spatial Proteomics", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Foundation models have begun to transform image analysis by acting as\npretrained generalist backbones that can be adapted to many tasks even when\npost-training data are limited, yet their impact on spatial proteomics, imaging\nthat maps proteins at single-cell resolution, remains limited. Here, we\nintroduce KRONOS, a foundation model built for spatial proteomics. KRONOS was\ntrained in a self-supervised manner on over 47 million image patches covering\n175 protein markers, 16 tissue types, and 8 fluorescence-based imaging\nplatforms. We introduce key architectural adaptations to address the\nhigh-dimensional, multi-channel, and heterogeneous nature of multiplex imaging.\nWe demonstrate that KRONOS learns biologically meaningful representations\nacross multiple scales, ranging from cellular and microenvironment to tissue\nlevels, enabling it to address diverse downstream tasks, including cell\nphenotyping, region classification, and patient stratification. Evaluated\nacross 11 independent cohorts, KRONOS achieves state-of-the-art performance\nacross cell phenotyping, treatment response prediction, and retrieval tasks,\nand is highly data-efficient. KRONOS also introduces the paradigm of\nsegmentation-free patch-level processing for efficient and scalable spatial\nproteomics analysis, allowing cross-institutional comparisons, and as an image\nreverse search engine for spatial patterns. Together, these results position\nKRONOS as a flexible and scalable tool for spatial proteomics. The model is\npublicly accessible at https://github.com/mahmoodlab/KRONOS.", "AI": {"tldr": "KRONOS is a foundation model for spatial proteomics, trained self-supervised on 47M image patches. It excels in tasks like cell phenotyping and patient stratification, achieving state-of-the-art performance.", "motivation": "To address the limited impact of foundation models in spatial proteomics, KRONOS was developed to handle high-dimensional, multi-channel imaging data.", "method": "KRONOS uses self-supervised training on diverse protein markers, tissues, and imaging platforms, with architectural adaptations for multiplex imaging.", "result": "KRONOS achieves top performance in 11 cohorts for tasks like phenotyping and treatment prediction, and enables segmentation-free analysis.", "conclusion": "KRONOS is a scalable, data-efficient tool for spatial proteomics, publicly available for cross-institutional use."}}
{"id": "2506.03270", "pdf": "https://arxiv.org/pdf/2506.03270", "abs": "https://arxiv.org/abs/2506.03270", "authors": ["Jeremy Siburian", "Keisuke Shirai", "Cristian C. Beltran-Hernandez", "Masashi Hamaya", "Michael G\u00f6rner", "Atsushi Hashimoto"], "title": "Grounded Vision-Language Interpreter for Integrated Task and Motion Planning", "categories": ["cs.RO", "cs.AI"], "comment": "Project website: https://omron-sinicx.github.io/ViLaIn-TAMP/", "summary": "While recent advances in vision-language models (VLMs) have accelerated the\ndevelopment of language-guided robot planners, their black-box nature often\nlacks safety guarantees and interpretability crucial for real-world deployment.\nConversely, classical symbolic planners offer rigorous safety verification but\nrequire significant expert knowledge for setup. To bridge the current gap, this\npaper proposes ViLaIn-TAMP, a hybrid planning framework for enabling\nverifiable, interpretable, and autonomous robot behaviors. ViLaIn-TAMP\ncomprises three main components: (1) ViLaIn (Vision-Language Interpreter) - A\nprior framework that converts multimodal inputs into structured problem\nspecifications using off-the-shelf VLMs without additional domain-specific\ntraining, (2) a modular Task and Motion Planning (TAMP) system that grounds\nthese specifications in actionable trajectory sequences through symbolic and\ngeometric constraint reasoning and can utilize learning-based skills for key\nmanipulation phases, and (3) a corrective planning module which receives\nconcrete feedback on failed solution attempts from the motion and task planning\ncomponents and can feed adapted logic and geometric feasibility constraints\nback to ViLaIn to improve and further refine the specification. We evaluate our\nframework on several challenging manipulation tasks in a cooking domain. We\ndemonstrate that the proposed closed-loop corrective architecture exhibits a\nmore than 30% higher mean success rate for ViLaIn-TAMP compared to without\ncorrective planning.", "AI": {"tldr": "ViLaIn-TAMP is a hybrid planning framework combining vision-language models and symbolic planning for verifiable, interpretable robot behaviors, achieving a 30% higher success rate with corrective planning.", "motivation": "Bridging the gap between black-box VLMs (lacking safety guarantees) and classical symbolic planners (requiring expert setup) for safer, interpretable robot planning.", "method": "Integrates ViLaIn (converts multimodal inputs to structured specs), a modular TAMP system (grounds specs in trajectories), and a corrective planning module (adapts based on feedback).", "result": "30% higher mean success rate in manipulation tasks compared to non-corrective planning.", "conclusion": "ViLaIn-TAMP enhances robot autonomy with verifiable, interpretable planning, outperforming traditional methods."}}
{"id": "2506.03404", "pdf": "https://arxiv.org/pdf/2506.03404", "abs": "https://arxiv.org/abs/2506.03404", "authors": ["Walter Mayor", "Johan Obando-Ceron", "Aaron Courville", "Pablo Samuel Castro"], "title": "The Impact of On-Policy Parallelized Data Collection on Deep Reinforcement Learning Networks", "categories": ["cs.LG", "cs.AI"], "comment": "Proceedings of the 42nd International Conference on Machine Learning\n  (ICML 2025)", "summary": "The use of parallel actors for data collection has been an effective\ntechnique used in reinforcement learning (RL) algorithms. The manner in which\ndata is collected in these algorithms, controlled via the number of parallel\nenvironments and the rollout length, induces a form of bias-variance trade-off;\nthe number of training passes over the collected data, on the other hand, must\nstrike a balance between sample efficiency and overfitting. We conduct an\nempirical analysis of these trade-offs on PPO, one of the most popular RL\nalgorithms that uses parallel actors, and establish connections to network\nplasticity and, more generally, optimization stability. We examine its impact\non network architectures, as well as the hyper-parameter sensitivity when\nscaling data. Our analyses indicate that larger dataset sizes can increase\nfinal performance across a variety of settings, and that scaling parallel\nenvironments is more effective than increasing rollout lengths. These findings\nhighlight the critical role of data collection strategies in improving agent\nperformance.", "AI": {"tldr": "The paper analyzes trade-offs in data collection for RL, focusing on PPO, and finds scaling parallel environments more effective than longer rollouts for performance.", "motivation": "To understand the bias-variance trade-offs in RL data collection and their impact on optimization stability and performance.", "method": "Empirical analysis of PPO, examining parallel actors, rollout lengths, and dataset sizes.", "result": "Larger datasets improve performance; scaling parallel environments is more effective than longer rollouts.", "conclusion": "Data collection strategies, especially parallel environments, are crucial for RL performance."}}
{"id": "2506.03979", "pdf": "https://arxiv.org/pdf/2506.03979", "abs": "https://arxiv.org/abs/2506.03979", "authors": ["Haoxuan Chen", "Yinuo Ren", "Martin Renqiang Min", "Lexing Ying", "Zachary Izzo"], "title": "Solving Inverse Problems via Diffusion-Based Priors: An Approximation-Free Ensemble Sampling Approach", "categories": ["cs.LG", "cs.CV", "cs.NA", "eess.IV", "math.NA", "stat.ML"], "comment": "45 pages", "summary": "Diffusion models (DMs) have proven to be effective in modeling\nhigh-dimensional distributions, leading to their widespread adoption for\nrepresenting complex priors in Bayesian inverse problems (BIPs). However,\ncurrent DM-based posterior sampling methods proposed for solving common BIPs\nrely on heuristic approximations to the generative process. To exploit the\ngenerative capability of DMs and avoid the usage of such approximations, we\npropose an ensemble-based algorithm that performs posterior sampling without\nthe use of heuristic approximations. Our algorithm is motivated by existing\nworks that combine DM-based methods with the sequential Monte Carlo (SMC)\nmethod. By examining how the prior evolves through the diffusion process\nencoded by the pre-trained score function, we derive a modified partial\ndifferential equation (PDE) governing the evolution of the corresponding\nposterior distribution. This PDE includes a modified diffusion term and a\nreweighting term, which can be simulated via stochastic weighted particle\nmethods. Theoretically, we prove that the error between the true posterior\ndistribution can be bounded in terms of the training error of the pre-trained\nscore function and the number of particles in the ensemble. Empirically, we\nvalidate our algorithm on several inverse problems in imaging to show that our\nmethod gives more accurate reconstructions compared to existing DM-based\nmethods.", "AI": {"tldr": "The paper proposes an ensemble-based algorithm for posterior sampling in Bayesian inverse problems using diffusion models, avoiding heuristic approximations and improving accuracy.", "motivation": "Current DM-based posterior sampling methods rely on heuristic approximations, limiting their effectiveness. The goal is to exploit DMs' generative capability without such approximations.", "method": "The algorithm combines DM-based methods with sequential Monte Carlo (SMC), deriving a modified PDE for posterior evolution and simulating it via stochastic weighted particle methods.", "result": "Theoretical bounds on posterior error are provided, and empirical validation shows more accurate reconstructions compared to existing DM-based methods.", "conclusion": "The proposed method outperforms existing DM-based approaches in accuracy for inverse problems in imaging."}}
{"id": "2506.03566", "pdf": "https://arxiv.org/pdf/2506.03566", "abs": "https://arxiv.org/abs/2506.03566", "authors": ["Langlin Huang", "Chengsong Huang", "Jixuan Leng", "Di Huang", "Jiaxin Huang"], "title": "POSS: Position Specialist Generates Better Draft for Speculative Decoding", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "Speculative decoding accelerates Large Language Model (LLM) inference by\nusing a small draft model to predict multiple tokens, and a large target model\nto verify these tokens in parallel. Recent studies leverage the hidden state of\nthe target model to enhance draft model prediction accuracy. However, existing\nmethods suffer from the degrading quality of draft token predictions at later\npositions, due to error accumulation in draft model generated features. In this\npaper, we propose Position Specialists (PosS), which consist of multiple\nposition-specialized draft layers to generate tokens at assigned position(s).\nPosition specialists greatly improve token acceptance rate at later positions\nper drafting round, as each specialist only needs to focus on handling a\ncertain level of draft model feature deviation. Experiment results on\nLlama-3-8B-Instruct and Llama-2-13B-chat across six datasets demonstrate that\nPosS effectively improves over baselines on average acceptance length and\nspeed-up ratio. Our codebase is available at https://github.com/shrango/PosS.", "AI": {"tldr": "PosS improves LLM inference by using position-specialized draft layers to enhance token prediction accuracy, reducing error accumulation.", "motivation": "Existing methods degrade in draft token prediction quality due to error accumulation in later positions.", "method": "Introduces Position Specialists (PosS), multiple draft layers specialized for specific positions to handle feature deviation.", "result": "PosS improves token acceptance rate and speed-up ratio on Llama-3-8B-Instruct and Llama-2-13B-chat across six datasets.", "conclusion": "PosS effectively enhances draft model performance, offering better efficiency and accuracy in LLM inference."}}
{"id": "2506.03388", "pdf": "https://arxiv.org/pdf/2506.03388", "abs": "https://arxiv.org/abs/2506.03388", "authors": ["Pengyu Chen", "Xiao Huang", "Teng Fei", "Sicheng Wang"], "title": "Cross-Modal Urban Sensing: Evaluating Sound-Vision Alignment Across Street-Level and Aerial Imagery", "categories": ["cs.CV"], "comment": null, "summary": "Environmental soundscapes convey substantial ecological and social\ninformation regarding urban environments; however, their potential remains\nlargely untapped in large-scale geographic analysis. In this study, we\ninvestigate the extent to which urban sounds correspond with visual scenes by\ncomparing various visual representation strategies in capturing acoustic\nsemantics. We employ a multimodal approach that integrates geo-referenced sound\nrecordings with both street-level and remote sensing imagery across three major\nglobal cities: London, New York, and Tokyo. Utilizing the AST model for audio,\nalong with CLIP and RemoteCLIP for imagery, as well as CLIPSeg and Seg-Earth OV\nfor semantic segmentation, we extract embeddings and class-level features to\nevaluate cross-modal similarity. The results indicate that street view\nembeddings demonstrate stronger alignment with environmental sounds compared to\nsegmentation outputs, whereas remote sensing segmentation is more effective in\ninterpreting ecological categories through a Biophony--Geophony--Anthrophony\n(BGA) framework. These findings imply that embedding-based models offer\nsuperior semantic alignment, while segmentation-based methods provide\ninterpretable links between visual structure and acoustic ecology. This work\nadvances the burgeoning field of multimodal urban sensing by offering novel\nperspectives for incorporating sound into geospatial analysis.", "AI": {"tldr": "The study explores how urban sounds align with visual scenes using multimodal methods, finding street view embeddings align better with sounds, while remote sensing segmentation better interprets ecological categories.", "motivation": "To tap into the untapped potential of environmental soundscapes in large-scale geographic analysis by investigating their correspondence with visual scenes.", "method": "A multimodal approach integrating geo-referenced sound recordings with street-level and remote sensing imagery, using models like AST, CLIP, RemoteCLIP, CLIPSeg, and Seg-Earth OV for embeddings and segmentation.", "result": "Street view embeddings align better with sounds, while remote sensing segmentation is more effective for ecological categories under the BGA framework.", "conclusion": "Embedding-based models offer superior semantic alignment, while segmentation-based methods provide interpretable links between visual structure and acoustic ecology, advancing multimodal urban sensing."}}
{"id": "2506.03350", "pdf": "https://arxiv.org/pdf/2506.03350", "abs": "https://arxiv.org/abs/2506.03350", "authors": ["Eliot Krzysztof Jones", "Alexander Robey", "Andy Zou", "Zachary Ravichandran", "George J. Pappas", "Hamed Hassani", "Matt Fredrikson", "J. Zico Kolter"], "title": "Adversarial Attacks on Robotic Vision Language Action Models", "categories": ["cs.RO", "cs.AI"], "comment": null, "summary": "The emergence of vision-language-action models (VLAs) for end-to-end control\nis reshaping the field of robotics by enabling the fusion of multimodal sensory\ninputs at the billion-parameter scale. The capabilities of VLAs stem primarily\nfrom their architectures, which are often based on frontier large language\nmodels (LLMs). However, LLMs are known to be susceptible to adversarial misuse,\nand given the significant physical risks inherent to robotics, questions remain\nregarding the extent to which VLAs inherit these vulnerabilities. Motivated by\nthese concerns, in this work we initiate the study of adversarial attacks on\nVLA-controlled robots. Our main algorithmic contribution is the adaptation and\napplication of LLM jailbreaking attacks to obtain complete control authority\nover VLAs. We find that textual attacks, which are applied once at the\nbeginning of a rollout, facilitate full reachability of the action space of\ncommonly used VLAs and often persist over longer horizons. This differs\nsignificantly from LLM jailbreaking literature, as attacks in the real world do\nnot have to be semantically linked to notions of harm. We make all code\navailable at https://github.com/eliotjones1/robogcg .", "AI": {"tldr": "The paper explores adversarial attacks on vision-language-action models (VLAs) in robotics, adapting LLM jailbreaking techniques to gain control over VLAs, revealing persistent vulnerabilities.", "motivation": "Concerns about VLAs inheriting vulnerabilities from LLMs, given the physical risks in robotics, drive the study of adversarial attacks on VLA-controlled robots.", "method": "Adaptation and application of LLM jailbreaking attacks to VLAs, focusing on textual attacks for control authority.", "result": "Textual attacks enable full reachability of VLA action spaces and persist over long horizons, differing from LLM jailbreaking norms.", "conclusion": "VLAs are vulnerable to adversarial attacks, posing significant risks in robotics, with implications for future model robustness."}}
{"id": "2506.03411", "pdf": "https://arxiv.org/pdf/2506.03411", "abs": "https://arxiv.org/abs/2506.03411", "authors": ["Melissa Dutz", "Han Shao", "Avrim Blum", "Aloni Cohen"], "title": "A Machine Learning Theory Perspective on Strategic Litigation", "categories": ["cs.LG", "cs.GT"], "comment": null, "summary": "Strategic litigation involves bringing a legal case to court with the goal of\nhaving a broader impact beyond resolving the case itself: for example, creating\nprecedent which will influence future rulings. In this paper, we explore\nstrategic litigation from the perspective of machine learning theory. We\nconsider an abstract model of a common-law legal system where a lower court\ndecides new cases by applying a decision rule learned from a higher court's\npast rulings. In this model, we explore the power of a strategic litigator, who\nstrategically brings cases to the higher court to influence the learned\ndecision rule, thereby affecting future cases. We explore questions including:\nWhat impact can a strategic litigator have? Which cases should a strategic\nlitigator bring to court? Does it ever make sense for a strategic litigator to\nbring a case when they are sure the court will rule against them?", "AI": {"tldr": "The paper explores strategic litigation in a machine learning framework, analyzing how a litigator can influence future rulings by strategically bringing cases to a higher court.", "motivation": "To understand the impact of strategic litigation on legal decision-making through an abstract model of a common-law system.", "method": "An abstract model where a lower court learns decision rules from higher court rulings, and a strategic litigator brings cases to influence these rules.", "result": "The study examines the litigator's potential impact, optimal case selection, and scenarios where bringing losing cases may be beneficial.", "conclusion": "Strategic litigation can significantly influence future rulings, and even seemingly unfavorable cases may serve a strategic purpose."}}
{"id": "2502.03783", "pdf": "https://arxiv.org/pdf/2502.03783", "abs": "https://arxiv.org/abs/2502.03783", "authors": ["Luohong Wu", "Nicola A. Cavalcanti", "Matthias Seibold", "Giuseppe Loggia", "Lisa Reissner", "Jonas Hein", "Silvan Beeler", "Arnd Vieh\u00f6fer", "Stephan Wirth", "Lilian Calvet", "Philipp F\u00fcrnstahl"], "title": "UltraBones100k: A reliable automated labeling method and large-scale dataset for ultrasound-based bone surface extraction", "categories": ["eess.IV", "cs.CV"], "comment": "accepted by Computers in Biology and Medicine", "summary": "Ultrasound-based bone surface segmentation is crucial in computer-assisted\northopedic surgery. However, ultrasound images have limitations, including a\nlow signal-to-noise ratio, and acoustic shadowing, which make interpretation\ndifficult. Existing deep learning models for bone segmentation rely primarily\non costly manual labeling by experts, limiting dataset size and model\ngeneralizability. Additionally, the complexity of ultrasound physics and\nacoustic shadow makes the images difficult for humans to interpret, leading to\nincomplete labels in anechoic regions and limiting model performance. To\nadvance ultrasound bone segmentation and establish effective model benchmarks,\nlarger and higher-quality datasets are needed.\n  We propose a methodology for collecting ex-vivo ultrasound datasets with\nautomatically generated bone labels, including anechoic regions. The proposed\nlabels are derived by accurately superimposing tracked bone CT models onto the\ntracked ultrasound images. These initial labels are refined to account for\nultrasound physics. A clinical evaluation is conducted by an expert physician\nspecialized on orthopedic sonography to assess the quality of the generated\nbone labels. A neural network for bone segmentation is trained on the collected\ndataset and its predictions are compared to expert manual labels, evaluating\naccuracy, completeness, and F1-score.\n  We collected the largest known dataset of 100k ultrasound images of human\nlower limbs with bone labels, called UltraBones100k. A Wilcoxon signed-rank\ntest with Bonferroni correction confirmed that the bone alignment after our\nmethod significantly improved the quality of bone labeling (p < 0.001). The\nmodel trained on UltraBones100k consistently outperforms manual labeling in all\nmetrics, particularly in low-intensity regions (320% improvement in\ncompleteness at a distance threshold of 0.5 mm).", "AI": {"tldr": "The paper proposes a method to automate bone label generation for ultrasound images, improving dataset quality and model performance in bone segmentation.", "motivation": "Current deep learning models for ultrasound bone segmentation rely on costly manual labeling, which is limited in size and quality due to ultrasound's low signal-to-noise ratio and acoustic shadowing.", "method": "The methodology involves collecting ex-vivo ultrasound datasets with automatically generated labels by superimposing tracked bone CT models onto ultrasound images, refined for ultrasound physics. A neural network is trained on this dataset.", "result": "The UltraBones100k dataset was created, showing significant improvement in label quality (p < 0.001). The trained model outperformed manual labeling, especially in low-intensity regions (320% improvement in completeness).", "conclusion": "Automated label generation enhances dataset quality and model performance, addressing limitations of manual labeling in ultrasound bone segmentation."}}
{"id": "2506.03569", "pdf": "https://arxiv.org/pdf/2506.03569", "abs": "https://arxiv.org/abs/2506.03569", "authors": ["Xiaomi LLM-Core Team", ":", "Zihao Yue", "Zhenru Lin", "Yifan Song", "Weikun Wang", "Shuhuai Ren", "Shuhao Gu", "Shicheng Li", "Peidian Li", "Liang Zhao", "Lei Li", "Kainan Bao", "Hao Tian", "Hailin Zhang", "Gang Wang", "Dawei Zhu", "Cici", "Chenhong He", "Bowen Ye", "Bowen Shen", "Zihan Zhang", "Zihan Jiang", "Zhixian Zheng", "Zhichao Song", "Zhenbo Luo", "Yue Yu", "Yudong Wang", "Yuanyuan Tian", "Yu Tu", "Yihan Yan", "Yi Huang", "Xu Wang", "Xinzhe Xu", "Xingchen Song", "Xing Zhang", "Xing Yong", "Xin Zhang", "Xiangwei Deng", "Wenyu Yang", "Wenhan Ma", "Weiwei Lv", "Weiji Zhuang", "Wei Liu", "Sirui Deng", "Shuo Liu", "Shimao Chen", "Shihua Yu", "Shaohui Liu", "Shande Wang", "Rui Ma", "Qiantong Wang", "Peng Wang", "Nuo Chen", "Menghang Zhu", "Kangyang Zhou", "Kang Zhou", "Kai Fang", "Jun Shi", "Jinhao Dong", "Jiebao Xiao", "Jiaming Xu", "Huaqiu Liu", "Hongshen Xu", "Heng Qu", "Haochen Zhao", "Hanglong Lv", "Guoan Wang", "Duo Zhang", "Dong Zhang", "Di Zhang", "Chong Ma", "Chang Liu", "Can Cai", "Bingquan Xia"], "title": "MiMo-VL Technical Report", "categories": ["cs.CL"], "comment": "32 pages", "summary": "We open-source MiMo-VL-7B-SFT and MiMo-VL-7B-RL, two powerful vision-language\nmodels delivering state-of-the-art performance in both general visual\nunderstanding and multimodal reasoning. MiMo-VL-7B-RL outperforms Qwen2.5-VL-7B\non 35 out of 40 evaluated tasks, and scores 59.4 on OlympiadBench, surpassing\nmodels with up to 78B parameters. For GUI grounding applications, it sets a new\nstandard with 56.1 on OSWorld-G, even outperforming specialized models such as\nUI-TARS. Our training combines four-stage pre-training (2.4 trillion tokens)\nwith Mixed On-policy Reinforcement Learning (MORL) integrating diverse reward\nsignals. We identify the importance of incorporating high-quality reasoning\ndata with long Chain-of-Thought into pre-training stages, and the benefits of\nmixed RL despite challenges in simultaneous multi-domain optimization. We also\ncontribute a comprehensive evaluation suite covering 50+ tasks to promote\nreproducibility and advance the field. The model checkpoints and full\nevaluation suite are available at https://github.com/XiaomiMiMo/MiMo-VL.", "AI": {"tldr": "MiMo-VL-7B-SFT and MiMo-VL-7B-RL are open-source vision-language models excelling in visual understanding and multimodal reasoning, outperforming competitors and setting new benchmarks.", "motivation": "To advance vision-language models by combining high-quality reasoning data and mixed reinforcement learning for superior performance.", "method": "Four-stage pre-training (2.4 trillion tokens) with Mixed On-policy Reinforcement Learning (MORL) integrating diverse rewards.", "result": "Outperforms Qwen2.5-VL-7B on 35/40 tasks, scores 59.4 on OlympiadBench, and 56.1 on OSWorld-G, surpassing specialized models.", "conclusion": "The models set new standards, highlighting the value of reasoning data and mixed RL, with open-source resources for reproducibility."}}
{"id": "2506.03394", "pdf": "https://arxiv.org/pdf/2506.03394", "abs": "https://arxiv.org/abs/2506.03394", "authors": ["Shafqaat Ahmad"], "title": "Temporal Vegetation Index-Based Unsupervised Crop Stress Detection via Eigenvector-Guided Contrastive Learning", "categories": ["cs.CV"], "comment": null, "summary": "Early detection of crop stress is vital for minimizing yield loss and\nenabling timely intervention in precision agriculture. Traditional approaches\nusing NDRE often detect stress only after visible symptoms appear or require\nlabeled datasets, limiting scalability. This study introduces EigenCL, a novel\nunsupervised contrastive learning framework guided by temporal NDRE dynamics\nand biologically grounded eigen decomposition. Using over 10,000 Sentinel-2\nNDRE image patches from drought-affected Iowa cornfields, we constructed\nfive-point NDRE time series per patch and derived an RBF similarity matrix. The\nprincipal eigenvector explaining 76% of the variance and strongly correlated (r\n= 0.95) with raw NDRE values was used to define stress-aware similarity for\ncontrastive embedding learning. Unlike existing methods that rely on visual\naugmentations, EigenCL pulls embeddings together based on biologically similar\nstress trajectories and pushes apart divergent ones. The learned embeddings\nformed physiologically meaningful clusters, achieving superior clustering\nmetrics (Silhouette: 0.748, DBI: 0.35) and enabling 76% early stress detection\nup to 12 days before conventional NDRE thresholds. Downstream classification\nyielded 95% k-NN and 91% logistic regression accuracy. Validation on an\nindependent 2023 Nebraska dataset confirmed generalizability without\nretraining. EigenCL offers a label-free, scalable approach for early stress\ndetection that aligns with underlying plant physiology and is suitable for\nreal-world deployment in data-scarce agricultural environments.", "AI": {"tldr": "EigenCL is an unsupervised contrastive learning framework for early crop stress detection using NDRE dynamics, outperforming traditional methods with 76% early detection and high downstream accuracy.", "motivation": "Early detection of crop stress is crucial for yield preservation, but traditional methods like NDRE are limited by late detection and reliance on labeled data.", "method": "EigenCL uses temporal NDRE dynamics and eigen decomposition to define stress-aware similarity for contrastive learning, avoiding visual augmentations.", "result": "Achieved 76% early stress detection (12 days ahead), superior clustering (Silhouette: 0.748), and high classification accuracy (95% k-NN, 91% logistic regression).", "conclusion": "EigenCL provides a scalable, label-free solution for early stress detection, validated for real-world agricultural use."}}
{"id": "2506.03381", "pdf": "https://arxiv.org/pdf/2506.03381", "abs": "https://arxiv.org/abs/2506.03381", "authors": ["Artur Grigorev", "Khaled Saleh", "Jiwon Kim", "Adriana-Simona Mihaita"], "title": "Automated Traffic Incident Response Plans using Generative Artificial Intelligence: Part 1 -- Building the Incident Response Benchmark", "categories": ["eess.SY", "cs.AI", "cs.LG", "cs.SY"], "comment": null, "summary": "Traffic incidents remain a critical public safety concern worldwide, with\nAustralia recording 1,300 road fatalities in 2024, which is the highest toll in\n12 years. Similarly, the United States reports approximately 6 million crashes\nannually, raising significant challenges in terms of a fast reponse time and\noperational management. Traditional response protocols rely on human\ndecision-making, which introduces potential inconsistencies and delays during\ncritical moments when every minute impacts both safety outcomes and network\nperformance. To address this issue, we propose a novel Incident Response\nBenchmark that uses generative artificial intelligence to automatically\ngenerate response plans for incoming traffic incidents. Our approach aims to\nsignificantly reduce incident resolution times by suggesting\ncontext-appropriate actions such as variable message sign deployment, lane\nclosures, and emergency resource allocation adapted to specific incident\ncharacteristics. First, the proposed methodology uses real-world incident\nreports from the Performance Measurement System (PeMS) as training and\nevaluation data. We extract historically implemented actions from these reports\nand compare them against AI-generated response plans that suggest specific\nactions, such as lane closures, variable message sign announcements, and/or\ndispatching appropriate emergency resources. Second, model evaluations reveal\nthat advanced generative AI models like GPT-4o and Grok 2 achieve superior\nalignment with expert solutions, demonstrated by minimized Hamming distances\n(averaging 2.96-2.98) and low weighted differences (approximately 0.27-0.28).\nConversely, while Gemini 1.5 Pro records the lowest count of missed actions,\nits extremely high number of unnecessary actions (1547 compared to 225 for\nGPT-4o) indicates an over-triggering strategy that reduces the overall plan\nefficiency.", "AI": {"tldr": "A novel AI-driven Incident Response Benchmark is proposed to automate traffic incident response plans, reducing resolution times by leveraging generative AI models like GPT-4o and Grok 2, which outperform traditional methods and other AI models.", "motivation": "Traffic incidents cause significant fatalities and delays globally, with traditional human-led response protocols being inconsistent and slow. Automating responses can improve efficiency and safety.", "method": "Uses real-world incident reports from PeMS to train and evaluate AI models. Compares historically implemented actions with AI-generated plans (e.g., lane closures, emergency resource allocation). Evaluates models like GPT-4o, Grok 2, and Gemini 1.5 Pro.", "result": "GPT-4o and Grok 2 show superior alignment with expert solutions (low Hamming distances and weighted differences). Gemini 1.5 Pro has fewer missed actions but excessive unnecessary actions, reducing efficiency.", "conclusion": "Generative AI, particularly GPT-4o and Grok 2, can enhance traffic incident response by providing faster, context-appropriate plans, though model selection is critical to avoid inefficiencies."}}
{"id": "2506.03426", "pdf": "https://arxiv.org/pdf/2506.03426", "abs": "https://arxiv.org/abs/2506.03426", "authors": ["Joonseong Kang", "Soojeong Lee", "Subeen Park", "Sumin Park", "Taero Kim", "Jihee Kim", "Ryunyi Lee", "Kyungwoo Song"], "title": "Adaptive Task Vectors for Large Language Models", "categories": ["cs.LG", "cs.CL"], "comment": null, "summary": "In-Context Learning (ICL) enables Large Language Models (LLMs) to perform\ntasks without parameter updates by conditioning on a few demonstrations\nprovided in the prompt. Despite its success, ICL suffers from several\nlimitations, including sensitivity to demonstration order, context length\nconstraints, and computational inefficiency. To address these challenges, task\nvector-based approaches compress task information into a single vector.\nHowever, these methods typically construct task vectors from fixed sets of\ndemonstrations and reuse them across input queries, without conditioning on the\nspecific input. This limitation can lead models to struggle with effective\nadaptation when the input query is not well aligned with the underlying\ndemonstrations, consequently degrading their generalization performance on\nunseen tasks. To overcome this limitation, we propose Adaptive Task Vectors\n(ATV), a simple and effective framework that dynamically generates task vectors\nconditioned on each input query. ATV employs a small language model to generate\ntask vectors, which are then transformed to match the target LLM's architecture\nand applied to guide its output generation. In contrast to ICL and previous\nvector-based approaches, which rely on fixed demonstration sets and their\ncorresponding vectors, ATV dynamically generates task vectors tailored to each\nspecific input query and task. Consequently, ATV demonstrates strong\nperformance and generalization capabilities, even for unseen tasks.\nFurthermore, we provide a theoretical analysis indicating that ATV is\nexpressively equivalent to LoRA under equal rank budgets and more expressive\nthan Prefix-Tuning, thereby offering formal support for its representational\nadvantage.", "AI": {"tldr": "The paper introduces Adaptive Task Vectors (ATV), a dynamic framework for generating task-specific vectors in LLMs, improving generalization and performance over fixed demonstration-based methods like ICL.", "motivation": "ICL and fixed task vector methods have limitations like sensitivity to demonstration order and poor adaptation to input queries. ATV aims to dynamically tailor task vectors to each query for better performance.", "method": "ATV uses a small language model to generate task vectors conditioned on each input query, transforming them to match the target LLM's architecture.", "result": "ATV outperforms ICL and fixed vector methods, showing strong generalization on unseen tasks. It is theoretically more expressive than Prefix-Tuning and equivalent to LoRA.", "conclusion": "ATV provides a flexible and effective solution for task adaptation in LLMs, addressing key limitations of existing methods and offering theoretical advantages."}}
{"id": "2503.02321", "pdf": "https://arxiv.org/pdf/2503.02321", "abs": "https://arxiv.org/abs/2503.02321", "authors": ["Pengchen Liang", "Leijun Shi", "Huiping Yao", "Bin Pu", "Jianguo Chen", "Lei Zhao", "Haishan Huang", "Zhuangzhuang Chen", "Zhaozhao Xu", "Lite Xu", "Qing Chang", "Yiwei Li"], "title": "Rapid Bone Scintigraphy Enhancement via Semantic Prior Distillation from Segment Anything Model", "categories": ["eess.IV", "cs.CV"], "comment": "12 pages, 9 figures, 8 tables", "summary": "Rapid bone scintigraphy is crucial for diagnosing skeletal disorders and\ndetecting tumor metastases in children, as it shortens scan duration and\nreduces discomfort. However, accelerated acquisition often degrades image\nquality, impairing the visibility of fine anatomical details and potentially\ncompromising diagnosis. To overcome this limitation, we introduce the first\napplication of SAM-based semantic priors for medical image restoration,\nutilizing the Segment Anything Model (SAM) to enhance pediatric rapid bone\nscintigraphy. Our approach employs two cascaded networks, $f^{IR1}$ and\n$f^{IR2}$, supported by three specialized modules: a Semantic Prior Integration\n(SPI) module, a Semantic Knowledge Distillation (SKD) module, and a Semantic\nConsistency Module (SCM). The SPI and SKD modules inject domain-specific\nsemantic cues from a fine-tuned SAM, while the SCM preserves coherent semantic\nfeature representations across both cascaded stages. Moreover, we present RBS,\na novel Rapid Bone Scintigraphy dataset comprising paired standard (20 cm/min)\nand rapid (40 cm/min) scans from 137 pediatric patients aged 0.5 - 16 years,\nmaking it the first dataset tailored for pediatric rapid bone scintigraphy\nrestoration. Extensive experiments on both a public endoscopic dataset and our\nRBS dataset demonstrate that our method consistently surpasses existing\ntechniques in PSNR, SSIM, FID, and LPIPS metrics.", "AI": {"tldr": "The paper introduces a SAM-based method to enhance pediatric rapid bone scintigraphy, addressing image quality degradation in accelerated scans. It uses cascaded networks and specialized modules, validated on a novel dataset (RBS).", "motivation": "Accelerated bone scintigraphy in children reduces discomfort but degrades image quality, potentially compromising diagnosis. The goal is to restore fine anatomical details.", "method": "The approach employs two cascaded networks ($f^{IR1}$ and $f^{IR2}$) with three modules: SPI, SKD, and SCM, leveraging a fine-tuned SAM for semantic priors.", "result": "The method outperforms existing techniques on PSNR, SSIM, FID, and LPIPS metrics, validated on the RBS dataset and a public endoscopic dataset.", "conclusion": "The proposed SAM-based restoration method effectively enhances pediatric rapid bone scintigraphy, improving diagnostic accuracy while maintaining scan efficiency."}}
{"id": "2506.03570", "pdf": "https://arxiv.org/pdf/2506.03570", "abs": "https://arxiv.org/abs/2506.03570", "authors": ["Lin Sun", "Chuang Liu", "Xiaofeng Ma", "Tao Yang", "Weijia Lu", "Ning Wu"], "title": "FreePRM: Training Process Reward Models Without Ground Truth Process Labels", "categories": ["cs.CL"], "comment": null, "summary": "Recent advancements in Large Language Models (LLMs) have demonstrated that\nProcess Reward Models (PRMs) play a crucial role in enhancing model\nperformance. However, training PRMs typically requires step-level labels,\neither manually annotated or automatically generated, which can be costly and\ndifficult to obtain at scale. To address this challenge, we introduce FreePRM,\na weakly supervised framework for training PRMs without access to ground-truth\nstep-level labels. FreePRM first generates pseudo step-level labels based on\nthe correctness of final outcome, and then employs Buffer Probability to\neliminate impact of noise inherent in pseudo labeling. Experimental results\nshow that FreePRM achieves an average F1 score of 53.0% on ProcessBench,\noutperforming fully supervised PRM trained on Math-Shepherd by +24.1%. Compared\nto other open-source PRMs, FreePRM outperforms upon RLHFlow-PRM-Mistral-8B\n(28.4%) by +24.6%, EurusPRM (31.3%) by +21.7%, and Skywork-PRM-7B (42.1%) by\n+10.9%. This work introduces a new paradigm in PRM training, significantly\nreducing reliance on costly step-level annotations while maintaining strong\nperformance.", "AI": {"tldr": "FreePRM is a weakly supervised framework for training Process Reward Models (PRMs) without step-level labels, outperforming supervised and open-source PRMs.", "motivation": "Training PRMs typically requires costly step-level labels, which are hard to obtain at scale. FreePRM addresses this by avoiding the need for such labels.", "method": "FreePRM generates pseudo step-level labels from final outcomes and uses Buffer Probability to reduce noise in pseudo labeling.", "result": "FreePRM achieves a 53.0% F1 score on ProcessBench, outperforming supervised and open-source PRMs by significant margins.", "conclusion": "FreePRM offers a cost-effective alternative for PRM training, reducing reliance on step-level annotations while maintaining strong performance."}}
{"id": "2506.03433", "pdf": "https://arxiv.org/pdf/2506.03433", "abs": "https://arxiv.org/abs/2506.03433", "authors": ["Yifan Li", "Xin Li", "Tianqin Li", "Wenbin He", "Yu Kong", "Liu Ren"], "title": "ViT-Split: Unleashing the Power of Vision Foundation Models via Efficient Splitting Heads", "categories": ["cs.CV"], "comment": "The project is available:\n  https://jackyfl.github.io/vitsplit.github.io/", "summary": "Vision foundation models (VFMs) have demonstrated remarkable performance\nacross a wide range of downstream tasks. While several VFM adapters have shown\npromising results by leveraging the prior knowledge of VFMs, we identify two\ninefficiencies in these approaches. First, the interaction between\nconvolutional neural network (CNN) and VFM backbone triggers early layer\ngradient backpropagation. Second, existing methods require tuning all\ncomponents, adding complexity. Besides, these adapters alter VFM features,\nunderutilizing the prior knowledge. To tackle these challenges, we propose a\nnew approach called ViT-Split, based on a key observation: the layers of\nseveral VFMs, like DINOv2, can be divided into two distinct components: an\nextractor for learning low-level features and an adapter for learning\ntask-specific features. Leveraging this insight, we eliminate the CNN branch\nand introduce two heads, task head and prior head, to the frozen VFM. The task\nhead is designed to learn task-specific features, mitigating the early gradient\npropagation issue. The prior head is used to leverage the multi-scale prior\nfeatures from the frozen VFM, reducing tuning parameters and overfitting.\nExtensive experiments on various tasks (e.g., segmentation, detection, depth\nestimation, and visual question answering) validate the effectiveness and\nefficiency of ViT-Split. Specifically, ViT-Split reduces training time up to\n$4\\times$ while achieving comparable or even better results on ADE20K, compared\nto other VFM adapters.", "AI": {"tldr": "ViT-Split improves VFM efficiency by splitting layers into extractor and adapter components, reducing training time and maintaining performance.", "motivation": "Address inefficiencies in VFM adapters, such as early gradient backpropagation and excessive tuning, while better utilizing prior knowledge.", "method": "Proposes ViT-Split, which divides VFM layers into extractor and adapter, introduces task and prior heads, and freezes the VFM backbone.", "result": "ViT-Split reduces training time by up to 4x and achieves comparable or better performance on tasks like segmentation and detection.", "conclusion": "ViT-Split is an efficient and effective alternative to existing VFM adapters, leveraging prior knowledge while minimizing training overhead."}}
{"id": "2506.03391", "pdf": "https://arxiv.org/pdf/2506.03391", "abs": "https://arxiv.org/abs/2506.03391", "authors": ["Tri Kurniawan Wijaya", "Xinyang Shao", "Gonzalo Fiz Pontiveros", "Edoardo D'Amico"], "title": "Universal Reusability in Recommender Systems: The Case for Dataset- and Task-Independent Frameworks", "categories": ["cs.IR", "cs.AI", "cs.DB", "cs.LG"], "comment": null, "summary": "Recommender systems are pivotal in delivering personalized experiences across\nindustries, yet their adoption and scalability remain hindered by the need for\nextensive dataset- and task-specific configurations. Existing systems often\nrequire significant manual intervention, domain expertise, and engineering\neffort to adapt to new datasets or tasks, creating barriers to entry and\nlimiting reusability. In contrast, recent advancements in large language models\n(LLMs) have demonstrated the transformative potential of reusable systems,\nwhere a single model can handle diverse tasks without significant\nreconfiguration. Inspired by this paradigm, we propose the Dataset- and\nTask-Independent Recommender System (DTIRS), a framework aimed at maximizing\nthe reusability of recommender systems while minimizing barriers to entry.\nUnlike LLMs, which achieve task generalization directly, DTIRS focuses on\neliminating the need to rebuild or reconfigure recommendation pipelines for\nevery new dataset or task, even though models may still need retraining on new\ndata. By leveraging the novel Dataset Description Language (DsDL), DTIRS\nenables standardized dataset descriptions and explicit task definitions,\nallowing autonomous feature engineering, model selection, and optimization.\nThis paper introduces the concept of DTIRS and establishes a roadmap for\ntransitioning from Level-1 automation (dataset-agnostic but task-specific\nsystems) to Level-2 automation (fully dataset- and task-independent systems).\nAchieving this paradigm would maximize code reusability and lower barriers to\nadoption. We discuss key challenges, including the trade-offs between\ngeneralization and specialization, computational overhead, and scalability,\nwhile presenting DsDL as a foundational tool for this vision.", "AI": {"tldr": "Proposes DTIRS, a dataset- and task-independent recommender system framework using DsDL to standardize descriptions and automate pipelines, aiming to reduce manual effort and improve reusability.", "motivation": "Current recommender systems require extensive manual configuration for new datasets/tasks, limiting scalability and adoption. DTIRS aims to minimize these barriers by leveraging reusable systems inspired by LLMs.", "method": "Introduces DTIRS with DsDL for standardized dataset descriptions and task definitions, enabling autonomous feature engineering, model selection, and optimization. Proposes a roadmap from Level-1 to Level-2 automation.", "result": "DTIRS framework and DsDL tool are presented as foundational steps toward fully dataset- and task-independent recommender systems, addressing key challenges like generalization-specialization trade-offs.", "conclusion": "DTIRS offers a promising path to maximize reusability and lower adoption barriers in recommender systems, with DsDL as a key enabler for future automation."}}
{"id": "2506.03444", "pdf": "https://arxiv.org/pdf/2506.03444", "abs": "https://arxiv.org/abs/2506.03444", "authors": ["Yue Gong", "Raul Castro Fernandez"], "title": "Exploiting LLMs for Automatic Hypothesis Assessment via a Logit-Based Calibrated Prior", "categories": ["cs.LG", "cs.CL"], "comment": "Under Review", "summary": "As hypothesis generation becomes increasingly automated, a new bottleneck has\nemerged: hypothesis assessment. Modern systems can surface thousands of\nstatistical relationships-correlations, trends, causal links-but offer little\nguidance on which ones are novel, non-trivial, or worthy of expert attention.\nIn this work, we study the complementary problem to hypothesis generation:\nautomatic hypothesis assessment. Specifically, we ask: given a large set of\nstatistical relationships, can we automatically assess which ones are novel and\nworth further exploration? We focus on correlations as they are a common entry\npoint in exploratory data analysis that often serve as the basis for forming\ndeeper scientific or causal hypotheses.\n  To support automatic assessment, we propose to leverage the vast knowledge\nencoded in LLMs' weights to derive a prior distribution over the correlation\nvalue of a variable pair. If an LLM's prior expects the correlation value\nobserved, then such correlation is not surprising, and vice versa. We propose\nthe Logit-based Calibrated Prior, an LLM-elicited correlation prior that\ntransforms the model's raw output logits into a calibrated, continuous\npredictive distribution over correlation values. We evaluate the prior on a\nbenchmark of 2,096 real-world variable pairs and it achieves a sign accuracy of\n78.8%, a mean absolute error of 0.26, and 95% credible interval coverage of\n89.2% in predicting Pearson correlation coefficient. It also outperforms a\nfine-tuned RoBERTa classifier in binary correlation prediction and achieves\nhigher precision@K in hypothesis ranking. We further show that the prior\ngeneralizes to correlations not seen during LLM pretraining, reflecting\ncontext-sensitive reasoning rather than memorization.", "AI": {"tldr": "The paper addresses the bottleneck of hypothesis assessment in automated systems by proposing an LLM-based method to evaluate the novelty and worthiness of statistical correlations.", "motivation": "Modern systems generate many statistical relationships but lack guidance on their novelty or importance, creating a need for automated hypothesis assessment.", "method": "The authors propose the Logit-based Calibrated Prior, which uses LLMs to derive a prior distribution over correlation values, assessing novelty based on how surprising the observed correlation is.", "result": "The method achieves 78.8% sign accuracy, 0.26 mean absolute error, and 89.2% credible interval coverage, outperforming a fine-tuned RoBERTa classifier.", "conclusion": "The LLM-based prior effectively assesses correlation novelty and generalizes to unseen correlations, demonstrating context-sensitive reasoning."}}
{"id": "2504.18268", "pdf": "https://arxiv.org/pdf/2504.18268", "abs": "https://arxiv.org/abs/2504.18268", "authors": ["Ana Matoso", "Catarina Passarinho", "Marta P. Loureiro", "Jos\u00e9 Maria Moreira", "Patr\u00edcia Figueiredo", "Rita G. Nunes"], "title": "Towards a deep learning approach for classifying treatment response in glioblastomas", "categories": ["eess.IV", "cs.CV"], "comment": null, "summary": "Glioblastomas are the most aggressive type of glioma, having a 5-year\nsurvival rate of 6.9%. Treatment typically involves surgery, followed by\nradiotherapy and chemotherapy, and frequent magnetic resonance imaging (MRI)\nscans to monitor disease progression. To assess treatment response,\nradiologists use the Response Assessment in Neuro-Oncology (RANO) criteria to\ncategorize the tumor into one of four labels based on imaging and clinical\nfeatures: complete response, partial response, stable disease, and progressive\ndisease. This assessment is very complex and time-consuming. Since deep\nlearning (DL) has been widely used to tackle classification problems, this work\naimed to implement the first DL pipeline for the classification of RANO\ncriteria based on two consecutive MRI acquisitions. The models were trained and\ntested on the open dataset LUMIERE. Five approaches were tested: 1) subtraction\nof input images, 2) different combinations of modalities, 3) different model\narchitectures, 4) different pretraining tasks, and 5) adding clinical data. The\npipeline that achieved the best performance used a Densenet264 considering only\nT1-weighted, T2-weighted, and Fluid Attenuated Inversion Recovery (FLAIR)\nimages as input without any pretraining. A median Balanced Accuracy of 50.96%\nwas achieved. Additionally, explainability methods were applied. Using Saliency\nMaps, the tumor region was often successfully highlighted. In contrast,\nGrad-CAM typically failed to highlight the tumor region, with some exceptions\nobserved in the Complete Response and Progressive Disease classes, where it\neffectively identified the tumor region. These results set a benchmark for\nfuture studies on glioblastoma treatment response assessment based on the RANO\ncriteria while emphasizing the heterogeneity of factors that might play a role\nwhen assessing the tumor's response to treatment.", "AI": {"tldr": "A deep learning pipeline was developed to classify glioblastoma treatment response using MRI scans and RANO criteria, achieving a median balanced accuracy of 50.96%.", "motivation": "The manual assessment of glioblastoma treatment response using RANO criteria is complex and time-consuming, prompting the need for an automated DL solution.", "method": "Five DL approaches were tested, including image subtraction, modality combinations, model architectures, pretraining tasks, and clinical data integration. The best-performing pipeline used Densenet264 with T1, T2, and FLAIR images.", "result": "The pipeline achieved a median balanced accuracy of 50.96%, with Saliency Maps effectively highlighting tumor regions, while Grad-CAM had limited success.", "conclusion": "This study establishes a benchmark for automated glioblastoma response assessment, highlighting the complexity and heterogeneity of factors influencing treatment evaluation."}}
{"id": "2506.03573", "pdf": "https://arxiv.org/pdf/2506.03573", "abs": "https://arxiv.org/abs/2506.03573", "authors": ["Lin Sun", "Can Zhang"], "title": "Exchange of Perspective Prompting Enhances Reasoning in Large Language Models", "categories": ["cs.CL"], "comment": null, "summary": "Large language models (LLMs) have made significant advancements in addressing\ndiverse natural language processing (NLP) tasks. However, their performance is\noften limited by inherent comprehension of problems. To address this\nlimitation, we propose Exchange-of-Perspective (EoP), a novel framework\ndesigned to exchange perspectives across different definitions of problem, so\nthat it can break the fixed mindset from any particular formulation of the\nquestion. We conducted extensive and comprehensive experiments on 8 benchmarks.\nThe results show that EoP can significantly improve performance. For instance,\ncompared to the non-commutative baseline PHP, with GPT-3.5-Turbo and EoP, we\nobserve a 3.6% improvement on AQuA (60.6% to 64.2%), while GPT-4-powered EoP\ndemonstrates a 7.7% overall accuracy enhancement on Math (53.9% to 61.6%) and a\n3.5% improvement on OlympiadBench Maths (43.5% to 47.0%) when using\nQwen-2.5-72b.", "AI": {"tldr": "The paper introduces Exchange-of-Perspective (EoP), a framework to enhance LLM performance by exchanging problem perspectives, showing significant improvements across benchmarks.", "motivation": "LLMs struggle with fixed problem formulations, limiting their comprehension and performance. EoP aims to overcome this by diversifying problem perspectives.", "method": "EoP exchanges perspectives across problem definitions to avoid fixed mindsets. Experiments were conducted on 8 benchmarks using models like GPT-3.5-Turbo and GPT-4.", "result": "EoP improved performance: 3.6% on AQuA, 7.7% on Math, and 3.5% on OlympiadBench Maths.", "conclusion": "EoP effectively enhances LLM performance by broadening problem comprehension, demonstrating its potential for diverse NLP tasks."}}
{"id": "2506.03440", "pdf": "https://arxiv.org/pdf/2506.03440", "abs": "https://arxiv.org/abs/2506.03440", "authors": ["Tanqiu Qiao", "Ruochen Li", "Frederick W. B. Li", "Yoshiki Kubotani", "Shigeo Morishima", "Hubert P. H. Shum"], "title": "Geometric Visual Fusion Graph Neural Networks for Multi-Person Human-Object Interaction Recognition in Videos", "categories": ["cs.CV"], "comment": "Accepted by Expert Systems with Applications (ESWA)", "summary": "Human-Object Interaction (HOI) recognition in videos requires understanding\nboth visual patterns and geometric relationships as they evolve over time.\nVisual and geometric features offer complementary strengths. Visual features\ncapture appearance context, while geometric features provide structural\npatterns. Effectively fusing these multimodal features without compromising\ntheir unique characteristics remains challenging. We observe that establishing\nrobust, entity-specific representations before modeling interactions helps\npreserve the strengths of each modality. Therefore, we hypothesize that a\nbottom-up approach is crucial for effective multimodal fusion. Following this\ninsight, we propose the Geometric Visual Fusion Graph Neural Network\n(GeoVis-GNN), which uses dual-attention feature fusion combined with\ninterdependent entity graph learning. It progressively builds from\nentity-specific representations toward high-level interaction understanding. To\nadvance HOI recognition to real-world scenarios, we introduce the Concurrent\nPartial Interaction Dataset (MPHOI-120). It captures dynamic multi-person\ninteractions involving concurrent actions and partial engagement. This dataset\nhelps address challenges like complex human-object dynamics and mutual\nocclusions. Extensive experiments demonstrate the effectiveness of our method\nacross various HOI scenarios. These scenarios include two-person interactions,\nsingle-person activities, bimanual manipulations, and complex concurrent\npartial interactions. Our method achieves state-of-the-art performance.", "AI": {"tldr": "The paper proposes GeoVis-GNN, a method for Human-Object Interaction (HOI) recognition by fusing visual and geometric features using dual-attention and graph learning, and introduces the MPHOI-120 dataset for real-world scenarios.", "motivation": "Understanding HOI in videos requires combining visual and geometric features without losing their unique strengths, which is challenging.", "method": "Proposes GeoVis-GNN, a bottom-up approach with dual-attention feature fusion and interdependent entity graph learning.", "result": "Achieves state-of-the-art performance in various HOI scenarios, including complex concurrent interactions.", "conclusion": "GeoVis-GNN effectively fuses multimodal features and advances HOI recognition, supported by the new MPHOI-120 dataset."}}
{"id": "2506.03399", "pdf": "https://arxiv.org/pdf/2506.03399", "abs": "https://arxiv.org/abs/2506.03399", "authors": ["Sean Steinle"], "title": "Sampling Preferences Yields Simple Trustworthiness Scores", "categories": ["cs.HC", "cs.AI"], "comment": null, "summary": "With the onset of large language models (LLMs), the performance of artificial\nintelligence (AI) models is becoming increasingly multi-dimensional.\nAccordingly, there have been several large, multi-dimensional evaluation\nframeworks put forward to evaluate LLMs. Though these frameworks are much more\nrealistic than previous attempts which only used a single score like accuracy,\nmulti-dimensional evaluations can complicate decision-making since there is no\nobvious way to select an optimal model. This work introduces preference\nsampling, a method to extract a scalar trustworthiness score from\nmulti-dimensional evaluation results by considering the many characteristics of\nmodel performance which users value. We show that preference sampling improves\nupon alternate aggregation methods by using multi-dimensional trustworthiness\nevaluations of LLMs from TrustLLM and DecodingTrust. We find that preference\nsampling is consistently reductive, fully reducing the set of candidate models\n100% of the time whereas Pareto optimality never reduces the set by more than\n50%. Likewise, preference sampling is consistently sensitive to user\npriors-allowing users to specify the relative weighting and confidence of their\npreferences-whereas averaging scores is intransigent to the users' prior\nknowledge.", "AI": {"tldr": "Preference sampling is introduced as a method to derive a scalar trustworthiness score from multi-dimensional LLM evaluations, outperforming other aggregation methods like Pareto optimality and averaging.", "motivation": "Multi-dimensional evaluation frameworks for LLMs complicate decision-making due to the lack of a clear way to select an optimal model.", "method": "Preference sampling extracts a scalar trustworthiness score by considering user-valued characteristics of model performance.", "result": "Preference sampling fully reduces candidate models 100% of the time and is sensitive to user priors, unlike Pareto optimality or averaging.", "conclusion": "Preference sampling is a superior method for aggregating multi-dimensional LLM evaluations into actionable scores."}}
{"id": "2506.03472", "pdf": "https://arxiv.org/pdf/2506.03472", "abs": "https://arxiv.org/abs/2506.03472", "authors": ["Mahesh Godavarti"], "title": "Directional Non-Commutative Monoidal Embeddings for MNIST", "categories": ["cs.LG", "20-XX, 08A02", "F.4.1; I.2"], "comment": null, "summary": "We present an empirical validation of the directional non-commutative\nmonoidal embedding framework recently introduced in prior\nwork~\\cite{Godavarti2025monoidal}. This framework defines learnable\ncompositional embeddings using distinct non-commutative operators per dimension\n(axis) that satisfy an interchange law, generalizing classical one-dimensional\ntransforms. Our primary goal is to verify that this framework can effectively\nmodel real data by applying it to a controlled, well-understood task: image\nclassification on the MNIST dataset~\\cite{lecun1998gradient}. A central\nhypothesis for why the proposed monoidal embedding works well is that it\ngeneralizes the Discrete Fourier Transform (DFT)~\\cite{oppenheim1999discrete}\nby learning task-specific frequency components instead of using fixed basis\nfrequencies. We test this hypothesis by comparing learned monoidal embeddings\nagainst fixed DFT-based embeddings on MNIST. The results show that as the\nembedding dimensionality decreases (e.g., from 32 to 8 to 2), the performance\ngap between the learned monoidal embeddings and fixed DFT-based embeddings on\nMNIST grows increasingly large. This comparison is used as an analytic tool to\nexplain why the framework performs well: the learnable embeddings can capture\nthe most discriminative spectral components for the task. Overall, our\nexperiments confirm that directional non-commutative monoidal embeddings are\nhighly effective for representing image data, offering a compact learned\nrepresentation that retains high task performance. The code used in this work\nis available at\nhttps://github.com/mahesh-godavarti/directional_composition_mnist.", "AI": {"tldr": "The paper validates a non-commutative monoidal embedding framework on MNIST, showing it outperforms fixed DFT-based embeddings, especially in low dimensions, by learning task-specific spectral components.", "motivation": "To empirically validate the effectiveness of the proposed monoidal embedding framework in modeling real data, using MNIST as a controlled task.", "method": "Applied the framework to MNIST, comparing learned monoidal embeddings against fixed DFT-based embeddings across varying dimensionalities.", "result": "Learned embeddings outperform fixed DFT-based ones, with the gap widening as dimensionality decreases, indicating better capture of discriminative spectral components.", "conclusion": "Directional non-commutative monoidal embeddings are effective for image data, offering compact, high-performing learned representations."}}
{"id": "2506.00605", "pdf": "https://arxiv.org/pdf/2506.00605", "abs": "https://arxiv.org/abs/2506.00605", "authors": ["Ruiming Min", "Minghao Liu"], "title": "ABCDEFGH: An Adaptation-Based Convolutional Neural Network-CycleGAN Disease-Courses Evolution Framework Using Generative Models in Health Education", "categories": ["eess.IV", "cs.CV"], "comment": "All authors did not agree to submitting this work. This version of\n  the report contains misinformation and is not ready to share", "summary": "With the advancement of modern medicine and the development of technologies\nsuch as MRI, CT, and cellular analysis, it has become increasingly critical for\nclinicians to accurately interpret various diagnostic images. However, modern\nmedical education often faces challenges due to limited access to high-quality\nteaching materials, stemming from privacy concerns and a shortage of\neducational resources (Balogh et al., 2015). In this context, image data\ngenerated by machine learning models, particularly generative models, presents\na promising solution. These models can create diverse and comparable imaging\ndatasets without compromising patient privacy, thereby supporting modern\nmedical education. In this study, we explore the use of convolutional neural\nnetworks (CNNs) and CycleGAN (Zhu et al., 2017) for generating synthetic\nmedical images. The source code is available at\nhttps://github.com/mliuby/COMP4211-Project.", "AI": {"tldr": "The paper explores using CNNs and CycleGAN to generate synthetic medical images for education, addressing privacy and resource limitations.", "motivation": "Modern medical education lacks high-quality teaching materials due to privacy concerns and resource shortages. Synthetic images from generative models offer a solution.", "method": "The study employs convolutional neural networks (CNNs) and CycleGAN to create synthetic medical images.", "result": "The approach generates diverse and privacy-compliant medical imaging datasets for educational use.", "conclusion": "Generative models like CNNs and CycleGAN can effectively support medical education by providing synthetic, privacy-safe imaging data."}}
{"id": "2506.03576", "pdf": "https://arxiv.org/pdf/2506.03576", "abs": "https://arxiv.org/abs/2506.03576", "authors": ["Zirui Chen", "Xin Wang", "Zhao Li", "Wenbin Guo", "Dongxiao He"], "title": "KG-BiLM: Knowledge Graph Embedding via Bidirectional Language Models", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Recent advances in knowledge representation learning (KRL) highlight the\nurgent necessity to unify symbolic knowledge graphs (KGs) with language models\n(LMs) for richer semantic understanding. However, existing approaches typically\nprioritize either graph structure or textual semantics, leaving a gap: a\nunified framework that simultaneously captures global KG connectivity, nuanced\nlinguistic context, and discriminative reasoning semantics. To bridge this gap,\nwe introduce KG-BiLM, a bidirectional LM framework that fuses structural cues\nfrom KGs with the semantic expressiveness of generative transformers. KG-BiLM\nincorporates three key components: (i) Bidirectional Knowledge Attention, which\nremoves the causal mask to enable full interaction among all tokens and\nentities; (ii) Knowledge-Masked Prediction, which encourages the model to\nleverage both local semantic contexts and global graph connectivity; and (iii)\nContrastive Graph Semantic Aggregation, which preserves KG structure via\ncontrastive alignment of sampled sub-graph representations. Extensive\nexperiments on standard benchmarks demonstrate that KG-BiLM outperforms strong\nbaselines in link prediction, especially on large-scale graphs with complex\nmulti-hop relations - validating its effectiveness in unifying structural\ninformation and textual semantics.", "AI": {"tldr": "KG-BiLM is a bidirectional LM framework that unifies knowledge graphs and language models for richer semantic understanding, outperforming baselines in link prediction.", "motivation": "Existing approaches prioritize either graph structure or textual semantics, lacking a unified framework for global KG connectivity, nuanced linguistic context, and reasoning semantics.", "method": "KG-BiLM integrates Bidirectional Knowledge Attention, Knowledge-Masked Prediction, and Contrastive Graph Semantic Aggregation to fuse KG structure with LM semantics.", "result": "KG-BiLM outperforms baselines in link prediction, especially on large-scale graphs with complex multi-hop relations.", "conclusion": "KG-BiLM effectively unifies structural information and textual semantics, bridging the gap between KGs and LMs."}}
{"id": "2506.03448", "pdf": "https://arxiv.org/pdf/2506.03448", "abs": "https://arxiv.org/abs/2506.03448", "authors": ["Bimsara Pathiraja", "Maitreya Patel", "Shivam Singh", "Yezhou Yang", "Chitta Baral"], "title": "RefEdit: A Benchmark and Method for Improving Instruction-based Image Editing Model on Referring Expressions", "categories": ["cs.CV"], "comment": "Project page: \\url{http://refedit.vercel.app}", "summary": "Despite recent advances in inversion and instruction-based image editing,\nexisting approaches primarily excel at editing single, prominent objects but\nsignificantly struggle when applied to complex scenes containing multiple\nentities. To quantify this gap, we first introduce RefEdit-Bench, a rigorous\nreal-world benchmark rooted in RefCOCO, where even baselines trained on\nmillions of samples perform poorly. To overcome this limitation, we introduce\nRefEdit -- an instruction-based editing model trained on our scalable synthetic\ndata generation pipeline. Our RefEdit, trained on only 20,000 editing triplets,\noutperforms the Flux/SD3 model-based baselines trained on millions of data.\nExtensive evaluations across various benchmarks demonstrate that our model not\nonly excels in referring expression tasks but also enhances performance on\ntraditional benchmarks, achieving state-of-the-art results comparable to\nclosed-source methods. We release data \\& checkpoint for reproducibility.", "AI": {"tldr": "RefEdit addresses the challenge of editing complex scenes with multiple entities, outperforming baselines with a scalable synthetic data pipeline and achieving state-of-the-art results.", "motivation": "Existing methods struggle with complex scenes containing multiple entities, highlighting the need for a robust solution.", "method": "RefEdit, trained on 20,000 synthetic editing triplets, leverages a scalable data generation pipeline.", "result": "RefEdit outperforms baselines trained on millions of samples and achieves state-of-the-art performance.", "conclusion": "RefEdit sets a new benchmark for instruction-based image editing in complex scenes, with released data and checkpoints for reproducibility."}}
{"id": "2506.03407", "pdf": "https://arxiv.org/pdf/2506.03407", "abs": "https://arxiv.org/abs/2506.03407", "authors": ["Lukas Meyer", "Josef Gr\u00fcn", "Maximilian Weiherer", "Bernhard Egger", "Marc Stamminger", "Linus Franke"], "title": "Multi-Spectral Gaussian Splatting with Neural Color Representation", "categories": ["cs.GR", "cs.AI", "cs.CV", "cs.LG"], "comment": null, "summary": "We present MS-Splatting -- a multi-spectral 3D Gaussian Splatting (3DGS)\nframework that is able to generate multi-view consistent novel views from\nimages of multiple, independent cameras with different spectral domains. In\ncontrast to previous approaches, our method does not require cross-modal camera\ncalibration and is versatile enough to model a variety of different spectra,\nincluding thermal and near-infra red, without any algorithmic changes.\n  Unlike existing 3DGS-based frameworks that treat each modality separately (by\noptimizing per-channel spherical harmonics) and therefore fail to exploit the\nunderlying spectral and spatial correlations, our method leverages a novel\nneural color representation that encodes multi-spectral information into a\nlearned, compact, per-splat feature embedding. A shallow multi-layer perceptron\n(MLP) then decodes this embedding to obtain spectral color values, enabling\njoint learning of all bands within a unified representation.\n  Our experiments show that this simple yet effective strategy is able to\nimprove multi-spectral rendering quality, while also leading to improved\nper-spectra rendering quality over state-of-the-art methods. We demonstrate the\neffectiveness of this new technique in agricultural applications to render\nvegetation indices, such as normalized difference vegetation index (NDVI).", "AI": {"tldr": "MS-Splatting is a multi-spectral 3D Gaussian Splatting framework that generates consistent novel views from multi-spectral images without cross-modal calibration. It uses a neural color representation for joint learning of spectral bands, improving rendering quality.", "motivation": "Existing methods treat spectral modalities separately, missing correlations. MS-Splatting aims to unify multi-spectral data for better rendering.", "method": "Uses a neural color representation with per-splat feature embeddings and an MLP to decode spectral colors, enabling joint learning.", "result": "Improves multi-spectral and per-spectra rendering quality, demonstrated in agricultural applications like NDVI.", "conclusion": "MS-Splatting offers a versatile, calibration-free solution for multi-spectral 3D rendering with superior quality."}}
{"id": "2506.03474", "pdf": "https://arxiv.org/pdf/2506.03474", "abs": "https://arxiv.org/abs/2506.03474", "authors": ["Yifeng Xiao", "Yurong Xu", "Ning Yan", "Masood Mortazavi", "Pierluigi Nuzzo"], "title": "CORE: Constraint-Aware One-Step Reinforcement Learning for Simulation-Guided Neural Network Accelerator Design", "categories": ["cs.LG", "cs.AI", "cs.AR", "I.2.6; C.3"], "comment": "Preprint. 10 pages + appendix. Submitted to NeurIPS 2025", "summary": "Simulation-based design space exploration (DSE) aims to efficiently optimize\nhigh-dimensional structured designs under complex constraints and expensive\nevaluation costs. Existing approaches, including heuristic and multi-step\nreinforcement learning (RL) methods, struggle to balance sampling efficiency\nand constraint satisfaction due to sparse, delayed feedback, and large hybrid\naction spaces. In this paper, we introduce CORE, a constraint-aware, one-step\nRL method for simulationguided DSE. In CORE, the policy agent learns to sample\ndesign configurations by defining a structured distribution over them,\nincorporating dependencies via a scaling-graph-based decoder, and by reward\nshaping to penalize invalid designs based on the feedback obtained from\nsimulation. CORE updates the policy using a surrogate objective that compares\nthe rewards of designs within a sampled batch, without learning a value\nfunction. This critic-free formulation enables efficient learning by\nencouraging the selection of higher-reward designs. We instantiate CORE for\nhardware-mapping co-design of neural network accelerators, demonstrating that\nit significantly improves sample efficiency and achieves better accelerator\nconfigurations compared to state-of-the-art baselines. Our approach is general\nand applicable to a broad class of discrete-continuous constrained design\nproblems.", "AI": {"tldr": "CORE is a constraint-aware, one-step RL method for efficient simulation-based design space exploration, outperforming existing methods in sample efficiency and design quality.", "motivation": "Existing DSE methods struggle with balancing sampling efficiency and constraint satisfaction due to sparse feedback and large action spaces.", "method": "CORE uses a structured distribution over designs, a scaling-graph-based decoder, and reward shaping to penalize invalid designs. It updates policy via a surrogate objective without a value function.", "result": "CORE significantly improves sample efficiency and achieves better accelerator configurations than state-of-the-art baselines.", "conclusion": "CORE is a general solution for discrete-continuous constrained design problems, demonstrating superior performance in hardware-mapping co-design."}}
{"id": "2506.02197", "pdf": "https://arxiv.org/pdf/2506.02197", "abs": "https://arxiv.org/abs/2506.02197", "authors": ["Marcos V. Conde", "Radu Timofte", "Zihao Lu", "Xiangyu Kong", "Xiaoxia Xing", "Fan Wang", "Suejin Han", "MinKyu Park", "Tianyu Zhang", "Xin Luo", "Yeda Chen", "Dong Liu", "Li Pang", "Yuhang Yang", "Hongzhong Wang", "Xiangyong Cao", "Ruixuan Jiang", "Senyan Xu", "Siyuan Jiang", "Xueyang Fu", "Zheng-Jun Zha", "Tianyu Hao", "Yuhong He", "Ruoqi Li", "Yueqi Yang", "Xiang Yu", "Guanlan Hong", "Minmin Yi", "Yuanjia Chen", "Liwen Zhang", "Zijie Jin", "Cheng Li", "Lian Liu", "Wei Song", "Heng Sun", "Yubo Wang", "Jinghua Wang", "Jiajie Lu", "Watchara Ruangsan"], "title": "NTIRE 2025 Challenge on RAW Image Restoration and Super-Resolution", "categories": ["eess.IV", "cs.CV"], "comment": "CVPR 2025 - New Trends in Image Restoration and Enhancement (NTIRE)", "summary": "This paper reviews the NTIRE 2025 RAW Image Restoration and Super-Resolution\nChallenge, highlighting the proposed solutions and results. New methods for RAW\nRestoration and Super-Resolution could be essential in modern Image Signal\nProcessing (ISP) pipelines, however, this problem is not as explored as in the\nRGB domain. The goal of this challenge is two fold, (i) restore RAW images with\nblur and noise degradations, (ii) upscale RAW Bayer images by 2x, considering\nunknown noise and blur. In the challenge, a total of 230 participants\nregistered, and 45 submitted results during thee challenge period. This report\npresents the current state-of-the-art in RAW Restoration.", "AI": {"tldr": "The paper reviews the NTIRE 2025 RAW Image Restoration and Super-Resolution Challenge, showcasing new methods and results for RAW image processing, which is less explored than RGB.", "motivation": "To advance RAW image restoration and super-resolution, addressing gaps in modern ISP pipelines.", "method": "Participants proposed solutions for restoring degraded RAW images and upscaling RAW Bayer images by 2x, tackling unknown noise and blur.", "result": "230 participants registered, 45 submitted results, revealing the current state-of-the-art in RAW restoration.", "conclusion": "The challenge highlights progress and potential in RAW image processing, though it remains under-explored compared to RGB."}}
{"id": "2506.03580", "pdf": "https://arxiv.org/pdf/2506.03580", "abs": "https://arxiv.org/abs/2506.03580", "authors": ["Enrico Benedetti", "Akiko Aizawa", "Florian Boudin"], "title": "Automatically Suggesting Diverse Example Sentences for L2 Japanese Learners Using Pre-Trained Language Models", "categories": ["cs.CL"], "comment": "Proceedings of the 62nd Annual Meeting of the Association for\n  Computational Linguistics (Volume 4: Student Research Workshop)", "summary": "Providing example sentences that are diverse and aligned with learners'\nproficiency levels is essential for fostering effective language acquisition.\nThis study examines the use of Pre-trained Language Models (PLMs) to produce\nexample sentences targeting L2 Japanese learners. We utilize PLMs in two ways:\nas quality scoring components in a retrieval system that draws from a newly\ncurated corpus of Japanese sentences, and as direct sentence generators using\nzero-shot learning. We evaluate the quality of sentences by considering\nmultiple aspects such as difficulty, diversity, and naturalness, with a panel\nof raters consisting of learners of Japanese, native speakers -- and GPT-4. Our\nfindings suggest that there is inherent disagreement among participants on the\nratings of sentence qualities, except for difficulty. Despite that, the\nretrieval approach was preferred by all evaluators, especially for beginner and\nadvanced target proficiency, while the generative approaches received lower\nscores on average. Even so, our experiments highlight the potential for using\nPLMs to enhance the adaptability of sentence suggestion systems and therefore\nimprove the language learning journey.", "AI": {"tldr": "The study explores using Pre-trained Language Models (PLMs) to generate or retrieve example sentences for L2 Japanese learners, finding retrieval methods preferred over generative ones despite rating disagreements.", "motivation": "To enhance language learning by providing diverse, proficiency-aligned example sentences using PLMs.", "method": "PLMs are used for quality scoring in a retrieval system and as direct sentence generators via zero-shot learning. Sentences are evaluated for difficulty, diversity, and naturalness by learners, native speakers, and GPT-4.", "result": "Retrieval approach was preferred, especially for beginner and advanced learners, while generative methods scored lower. Disagreement among raters was noted except for difficulty.", "conclusion": "PLMs show promise for improving sentence suggestion systems in language learning, with retrieval methods being more effective."}}
{"id": "2506.03449", "pdf": "https://arxiv.org/pdf/2506.03449", "abs": "https://arxiv.org/abs/2506.03449", "authors": ["John W. Smutny"], "title": "The effects of using created synthetic images in computer vision training", "categories": ["cs.CV"], "comment": "Nine pages long. Main content in pages one through eight. References\n  start at page nine", "summary": "This paper investigates how rendering engines, like Unreal Engine 4 (UE), can\nbe used to create synthetic images to supplement datasets for deep computer\nvision (CV) models in image abundant and image limited use cases. Using\nrendered synthetic images from UE can provide developers and businesses with a\nmethod of accessing nearly unlimited, reproducible, agile, and cheap training\nsets for their customers and applications without the threat of poisoned images\nfrom the internet or the cost of collecting them. The validity of these\ngenerated images are examined by testing the change in model test accuracy in\ntwo different sized CV models across two binary classification cases (Cat vs\nDog and Weld Defect Detection). In addition, this paper provides an\nimplementation of how to measure the quality of synthetic images by using\npre-trained CV models as auditors. Results imply that for large (VGG16) and\nsmall (MobileNetV3-small) parameter deep CV models, adding >60% additional\nsynthetic images to a real image dataset during model training can narrow the\ntest-training accuracy gap to ~1-2% without a conclusive effect on test\naccuracy compared to using real world images alone. Likewise, adding <10%\nadditional real training images to synthetic only training sets decreased the\nclassification error rate in half, then decreasing further when adding more\nreal training images. For these cases tested, using synthetic images from\nrendering engines allow researchers to only use 10% of their real images during\ntraining, compared to the traditional 50-70%. This research serves as an\nexample of how to create synthetic images, guidelines on how to use the images,\npotential restrictions and possible performance improvements for data-scarce\nprojects.", "AI": {"tldr": "Using synthetic images from Unreal Engine 4 can supplement real datasets for CV models, reducing reliance on real images while maintaining accuracy.", "motivation": "To address the challenges of limited or costly real-world datasets and the risks of poisoned images from the internet.", "method": "Testing synthetic images' validity by evaluating model accuracy in binary classification tasks (Cat vs Dog, Weld Defect Detection) and measuring synthetic image quality with pre-trained CV models.", "result": "Adding >60% synthetic images narrows the test-training accuracy gap to ~1-2%. Using 10% real images with synthetic data halves classification error rates.", "conclusion": "Synthetic images enable researchers to use only 10% of real images, offering a cost-effective and scalable solution for data-scarce projects."}}
{"id": "2506.03511", "pdf": "https://arxiv.org/pdf/2506.03511", "abs": "https://arxiv.org/abs/2506.03511", "authors": ["Fangyi Cao", "Bin Ren", "Zihao Wang", "Shiwei Fu", "Youbin Mo", "Xiaoyang Liu", "Yuzhou Chen", "Weixin Yao"], "title": "POLARIS: A High-contrast Polarimetric Imaging Benchmark Dataset for Exoplanetary Disk Representation Learning", "categories": ["astro-ph.EP", "astro-ph.IM", "cs.AI", "eess.IV"], "comment": "9 pages main text with 5 figures, 9 pages appendix with 9 figures.\n  Submitted to NeurIPS 2025", "summary": "With over 1,000,000 images from more than 10,000 exposures using\nstate-of-the-art high-contrast imagers (e.g., Gemini Planet Imager, VLT/SPHERE)\nin the search for exoplanets, can artificial intelligence (AI) serve as a\ntransformative tool in imaging Earth-like exoplanets in the coming decade? In\nthis paper, we introduce a benchmark and explore this question from a\npolarimetric image representation learning perspective. Despite extensive\ninvestments over the past decade, only a few new exoplanets have been directly\nimaged. Existing imaging approaches rely heavily on labor-intensive labeling of\nreference stars, which serve as background to extract circumstellar objects\n(disks or exoplanets) around target stars. With our POLARIS (POlarized Light\ndAta for total intensity Representation learning of direct Imaging of\nexoplanetary Systems) dataset, we classify reference star and circumstellar\ndisk images using the full public SPHERE/IRDIS polarized-light archive since\n2014, requiring less than 10 percent manual labeling. We evaluate a range of\nmodels including statistical, generative, and large vision-language models and\nprovide baseline performance. We also propose an unsupervised generative\nrepresentation learning framework that integrates these models, achieving\nsuperior performance and enhanced representational power. To our knowledge,\nthis is the first uniformly reduced, high-quality exoplanet imaging dataset,\nrare in astrophysics and machine learning. By releasing this dataset and\nbaselines, we aim to equip astrophysicists with new tools and engage data\nscientists in advancing direct exoplanet imaging, catalyzing major\ninterdisciplinary breakthroughs.", "AI": {"tldr": "AI can transform exoplanet imaging by reducing manual effort and improving efficiency, demonstrated using the POLARIS dataset and unsupervised learning.", "motivation": "The motivation is to leverage AI to address the inefficiency and labor-intensive nature of current exoplanet imaging methods, which rely heavily on manual labeling.", "method": "The paper introduces the POLARIS dataset, evaluates statistical, generative, and vision-language models, and proposes an unsupervised generative framework for representation learning.", "result": "The proposed framework achieves superior performance and enhanced representational power, requiring less than 10% manual labeling.", "conclusion": "The release of the POLARIS dataset and baselines aims to advance exoplanet imaging and foster interdisciplinary breakthroughs."}}
{"id": "2506.03522", "pdf": "https://arxiv.org/pdf/2506.03522", "abs": "https://arxiv.org/abs/2506.03522", "authors": ["Daniel Campa", "Mehdi Saeedi", "Ian Colbert", "Srinjoy Das"], "title": "Path Generation and Evaluation in Video Games: A Nonparametric Statistical Approach", "categories": ["cs.LG", "stat.ML"], "comment": "8 pages, 9 figures, Accepted at the IEEE Conference on Games 2025\n  (IEEE CoG)", "summary": "Navigation path traces play a crucial role in video game design, serving as a\nvital resource for both enhancing player engagement and fine-tuning\nnon-playable character behavior. Generating such paths with human-like realism\ncan enrich the overall gaming experience, and evaluating path traces can\nprovide game designers insights into player interactions. Despite the\nimpressive recent advancements in deep learning-based generative modeling, the\nvideo game industry hesitates to adopt such models for path generation, often\nciting their complex training requirements and interpretability challenges. To\naddress these problems, we propose a novel path generation and evaluation\napproach that is grounded in principled nonparametric statistics and provides\nprecise control while offering interpretable insights. Our path generation\nmethod fuses two statistical techniques: (1) nonparametric model-free\ntransformations that capture statistical characteristics of path traces through\ntime; and (2) copula models that capture statistical dependencies in space. For\npath evaluation, we adapt a nonparametric three-sample hypothesis test designed\nto determine if the generated paths are overfit (mimicking the original data\ntoo closely) or underfit (diverging too far from it). We demonstrate the\nprecision and reliability of our proposed methods with empirical analysis on\ntwo existing gaming benchmarks to showcase controlled generation of diverse\nnavigation paths. Notably, our novel path generator can be fine-tuned with user\ncontrollable parameters to create navigation paths that exhibit varying levels\nof human-likeness in contrast to those produced by neural network-based agents.\nThe code is available at https://github.com/daniel-campa/mf-copula.", "AI": {"tldr": "A novel nonparametric statistical approach for generating and evaluating human-like navigation paths in video games, addressing interpretability and control issues in deep learning models.", "motivation": "To overcome the limitations of deep learning-based path generation in games, such as complexity and lack of interpretability, by using principled statistical methods.", "method": "Combines nonparametric model-free transformations for temporal characteristics and copula models for spatial dependencies, with a three-sample hypothesis test for evaluation.", "result": "Demonstrates precise and reliable generation of diverse paths, with user-controllable parameters for human-likeness, validated on gaming benchmarks.", "conclusion": "The proposed method offers interpretable, controllable, and reliable path generation, outperforming neural network-based approaches in usability."}}
{"id": "2406.04158", "pdf": "https://arxiv.org/pdf/2406.04158", "abs": "https://arxiv.org/abs/2406.04158", "authors": ["Da Li", "Guoqiang Zhao", "Chen Yao", "Kaiqiang Zhu", "Houjun Sun", "Jiacheng Bao"], "title": "CMAR-Net: Accurate Cross-Modal 3D SAR Reconstruction of Vehicle Targets with Sparse-Aspect Multi-Baseline Data", "categories": ["cs.CV", "eess.IV"], "comment": "This work has been submitted to the IEEE for possible publication", "summary": "Sparse-aspect multi-baseline Synthetic Aperture Radar (SAR) three-dimensional\n(3D) tomography is a crucial remote sensing technique. Compared to full-aspect\nobservation, it needs only a few observation aspects to achieve a sufficiently\nclear 3D scene reconstruction, providing a cost-effective alternative. In the\npast, compressive sensing (CS) was the mainstream approach for sparse 3D SAR\nimaging. Recently, deep learning (DL) revolutionizes this field through its\npowerful data-driven representation capabilities and efficient inference\ncharacteristics. However, existing DL methods primarily depend on\nhigh-resolution radar images for supervising the training of deep neural\nnetworks (DNNs). This unimodal approach precludes the incorporation of\ncomplementary information from other data sources, thereby limiting potential\nimprovements in imaging performance. In this paper, we propose a Cross-Modal\n3D-SAR Reconstruction Network (CMAR-Net) that enhances 3D SAR imaging by fusing\nheterogeneous information. Leveraging cross-modal supervision from 2D optical\nimages and error transfer guaranteed by differentiable rendering, CMAR-Net\nachieves efficient training and reconstructs highly sparse-aspect\nmulti-baseline SAR image into visually structured and accurate 3D images,\nparticularly for vehicle targets. Extensive experiments on simulated and\nreal-world datasets demonstrate that CMAR-Net significantly outperforms\nstate-of-the-art sparse reconstruction algorithms based on CS and DL, with\naverage improvements of 75.83% in PSNR and 47.85% in SSIM. Furthermore, our\nmethod eliminates the need for time-consuming full-aperture data preprocessing\nand relies solely on computer-rendered optical images, significantly reducing\ndataset construction costs. This work highlights the potential of cross-modal\nlearning for multi-baseline SAR 3D imaging and introduces a novel framework for\nradar imaging research.", "AI": {"tldr": "The paper proposes CMAR-Net, a cross-modal 3D-SAR reconstruction network, to enhance sparse-aspect multi-baseline SAR imaging by fusing 2D optical images and SAR data, outperforming CS and DL methods.", "motivation": "Existing DL methods for sparse 3D SAR imaging rely solely on high-resolution radar images, missing complementary data from other sources, which limits performance.", "method": "CMAR-Net uses cross-modal supervision from 2D optical images and differentiable rendering to train efficiently and reconstruct accurate 3D images from sparse SAR data.", "result": "CMAR-Net improves PSNR by 75.83% and SSIM by 47.85% over state-of-the-art methods, while reducing dataset construction costs.", "conclusion": "The work demonstrates the potential of cross-modal learning for SAR 3D imaging and offers a cost-effective framework for radar imaging research."}}
{"id": "2506.03592", "pdf": "https://arxiv.org/pdf/2506.03592", "abs": "https://arxiv.org/abs/2506.03592", "authors": ["Viktor Hangya", "Fabian K\u00fcch", "Darina Gold"], "title": "From Understanding to Generation: An Efficient Shortcut for Evaluating Language Models", "categories": ["cs.CL"], "comment": null, "summary": "Iterative evaluation of LLMs during training is essential to ensure expected\ncapability development, but can be time- and compute-intensive. While NLU\ntasks, where the model selects from fixed answer choices, are cheap to\nevaluate, essential capabilities like reasoning and code generation rely on the\nmore time-consuming NLG (token-by-token generation) format. In this work, our\naim is to decrease the computational burden of NLG benchmarks in order to\nenable monitoring crucial LLM capabilities during model training. We\nreformulate generative tasks into computationally cheaper NLU alternatives. We\ntest the performance correlation between the original and reformulated tasks\nusing 8 LMs of various sizes and 4 capabilities: mathematical reasoning, code\ngeneration, factual knowledge and reading comprehension. Our results show a\nstrong correlation between task formats, supporting capability assessment via\ncheaper alternatives and achieving over 35x average reduction in evaluation\ntime. We plan to publish our benchmark adaptions.", "AI": {"tldr": "The paper proposes reformulating NLG tasks into cheaper NLU formats to reduce evaluation time for LLM training, showing strong correlation and significant time savings.", "motivation": "To reduce the computational burden of evaluating LLM capabilities like reasoning and code generation during training by using cheaper NLU alternatives.", "method": "Reformulate generative (NLG) tasks into NLU formats and test performance correlation across 8 LMs and 4 capabilities.", "result": "Strong correlation between original and reformulated tasks, with over 35x average reduction in evaluation time.", "conclusion": "Cheaper NLU alternatives can effectively assess LLM capabilities during training, enabling more efficient monitoring."}}
{"id": "2506.03461", "pdf": "https://arxiv.org/pdf/2506.03461", "abs": "https://arxiv.org/abs/2506.03461", "authors": ["Nan Xiang", "Lifeng Xing", "Dequan Jin"], "title": "RoNFA: Robust Neural Field-based Approach for Few-Shot Image Classification with Noisy Labels", "categories": ["cs.CV", "68Txx", "I.5.1"], "comment": "7 pages, 1 figure", "summary": "In few-shot learning (FSL), the labeled samples are scarce. Thus, label\nerrors can significantly reduce classification accuracy. Since label errors are\ninevitable in realistic learning tasks, improving the robustness of the model\nin the presence of label errors is critical. This paper proposes a new robust\nneural field-based image approach (RoNFA) for few-shot image classification\nwith noisy labels. RoNFA consists of two neural fields for feature and category\nrepresentation. They correspond to the feature space and category set. Each\nneuron in the field for category representation (FCR) has a receptive field\n(RF) on the field for feature representation (FFR) centered at the\nrepresentative neuron for its category generated by soft clustering. In the\nprediction stage, the range of these receptive fields adapts according to the\nneuronal activation in FCR to ensure prediction accuracy. These learning\nstrategies provide the proposed model with excellent few-shot learning\ncapability and strong robustness against label noises. The experimental results\non real-world FSL datasets with three different types of label noise\ndemonstrate that the proposed method significantly outperforms state-of-the-art\nFSL methods. Its accuracy obtained in the presence of noisy labels even\nsurpasses the results obtained by state-of-the-art FSL methods trained on clean\nsupport sets, indicating its strong robustness against noisy labels.", "AI": {"tldr": "RoNFA is a robust neural field-based method for few-shot image classification with noisy labels, outperforming state-of-the-art methods even with label errors.", "motivation": "Label errors in few-shot learning reduce accuracy, necessitating robust models.", "method": "RoNFA uses two neural fields for feature and category representation, with adaptive receptive fields for accuracy.", "result": "RoNFA surpasses state-of-the-art FSL methods on noisy datasets, even outperforming clean-set results.", "conclusion": "RoNFA offers strong robustness against label noise and superior few-shot learning performance."}}
{"id": "2506.03516", "pdf": "https://arxiv.org/pdf/2506.03516", "abs": "https://arxiv.org/abs/2506.03516", "authors": ["Arnab Debnath", "Gregory J. Stein", "Jana Kosecka"], "title": "SemNav: A Model-Based Planner for Zero-Shot Object Goal Navigation Using Vision-Foundation Models", "categories": ["cs.RO", "cs.AI"], "comment": "Accepted at CVPR 2025 workshop - Foundation Models Meet Embodied\n  Agents", "summary": "Object goal navigation is a fundamental task in embodied AI, where an agent\nis instructed to locate a target object in an unexplored environment.\nTraditional learning-based methods rely heavily on large-scale annotated data\nor require extensive interaction with the environment in a reinforcement\nlearning setting, often failing to generalize to novel environments and\nlimiting scalability. To overcome these challenges, we explore a zero-shot\nsetting where the agent operates without task-specific training, enabling more\nscalable and adaptable solution. Recent advances in Vision Foundation Models\n(VFMs) offer powerful capabilities for visual understanding and reasoning,\nmaking them ideal for agents to comprehend scenes, identify relevant regions,\nand infer the likely locations of objects. In this work, we present a zero-shot\nobject goal navigation framework that integrates the perceptual strength of\nVFMs with a model-based planner that is capable of long-horizon decision making\nthrough frontier exploration. We evaluate our approach on the HM3D dataset\nusing the Habitat simulator and demonstrate that our method achieves\nstate-of-the-art performance in terms of success weighted by path length for\nzero-shot object goal navigation.", "AI": {"tldr": "A zero-shot object goal navigation framework leverages Vision Foundation Models (VFMs) for scene understanding and combines it with a model-based planner for long-horizon decision making, achieving state-of-the-art performance without task-specific training.", "motivation": "Traditional methods for object goal navigation rely on large annotated datasets or extensive reinforcement learning, limiting scalability and generalization. This work addresses these issues by exploring a zero-shot approach.", "method": "The framework integrates VFMs for visual understanding and reasoning with a model-based planner for frontier exploration and long-horizon decision making.", "result": "Evaluated on the HM3D dataset using Habitat simulator, the method achieves state-of-the-art performance in zero-shot object goal navigation, measured by success weighted by path length.", "conclusion": "The proposed zero-shot framework demonstrates scalability and adaptability, outperforming traditional methods without requiring task-specific training."}}
{"id": "2506.03531", "pdf": "https://arxiv.org/pdf/2506.03531", "abs": "https://arxiv.org/abs/2506.03531", "authors": ["Daniel Ovalle", "Lorenz T. Biegler", "Ignacio E. Grossmann", "Carl D. Laird", "Mateo Dulce Rubio"], "title": "Conformal Mixed-Integer Constraint Learning with Feasibility Guarantees", "categories": ["cs.LG", "math.OC"], "comment": null, "summary": "We propose Conformal Mixed-Integer Constraint Learning (C-MICL), a novel\nframework that provides probabilistic feasibility guarantees for data-driven\nconstraints in optimization problems. While standard Mixed-Integer Constraint\nLearning methods often violate the true constraints due to model error or data\nlimitations, our C-MICL approach leverages conformal prediction to ensure\nfeasible solutions are ground-truth feasible. This guarantee holds with\nprobability at least $1{-}\\alpha$, under a conditional independence assumption.\nThe proposed framework supports both regression and classification tasks\nwithout requiring access to the true constraint function, while avoiding the\nscalability issues associated with ensemble-based heuristics. Experiments on\nreal-world applications demonstrate that C-MICL consistently achieves target\nfeasibility rates, maintains competitive objective performance, and\nsignificantly reduces computational cost compared to existing methods. Our work\nbridges mathematical optimization and machine learning, offering a principled\napproach to incorporate uncertainty-aware constraints into decision-making with\nrigorous statistical guarantees.", "AI": {"tldr": "C-MICL is a framework ensuring probabilistic feasibility guarantees for data-driven constraints in optimization, outperforming existing methods in feasibility, performance, and cost.", "motivation": "Standard methods often violate true constraints due to errors; C-MICL aims to provide reliable feasibility guarantees.", "method": "Uses conformal prediction to ensure feasible solutions are ground-truth feasible, supporting regression and classification without needing the true constraint function.", "result": "Achieves target feasibility rates, maintains competitive performance, and reduces computational cost in real-world applications.", "conclusion": "Bridges optimization and ML, offering uncertainty-aware constraints with rigorous guarantees."}}
{"id": "2503.17797", "pdf": "https://arxiv.org/pdf/2503.17797", "abs": "https://arxiv.org/abs/2503.17797", "authors": ["Chaoyu Liu", "Davide Murari", "Lihao Liu", "Yangming Li", "Chris Budd", "Carola-Bibiane Sch\u00f6nlieb"], "title": "Enhancing Fourier Neural Operators with Local Spatial Features", "categories": ["cs.LG", "eess.IV"], "comment": null, "summary": "Partial Differential Equation (PDE) problems often exhibit strong local\nspatial structures, and effectively capturing these structures is critical for\napproximating their solutions. Recently, the Fourier Neural Operator (FNO) has\nemerged as an efficient approach for solving these PDE problems. By using\nparametrization in the frequency domain, FNOs can efficiently capture global\npatterns. However, this approach inherently overlooks the critical role of\nlocal spatial features, as frequency-domain parameterized convolutions\nprimarily emphasize global interactions without encoding comprehensive\nlocalized spatial dependencies. Although several studies have attempted to\naddress this limitation, their extracted Local Spatial Features (LSFs) remain\ninsufficient, and computational efficiency is often compromised. To address\nthis limitation, we introduce a convolutional neural network (CNN)-based\nfeature pre-extractor to capture LSFs directly from input data, resulting in a\nhybrid architecture termed \\textit{Conv-FNO}. Furthermore, we introduce two\nnovel resizing schemes to make our Conv-FNO resolution invariant. In this work,\nwe focus on demonstrating the effectiveness of incorporating LSFs into FNOs by\nconducting both a theoretical analysis and extensive numerical experiments. Our\nfindings show that this simple yet impactful modification enhances the\nrepresentational capacity of FNOs and significantly improves performance on\nchallenging PDE benchmarks.", "AI": {"tldr": "The paper introduces Conv-FNO, a hybrid architecture combining CNN-based local feature extraction with FNOs to enhance PDE solution approximation by capturing both local and global spatial structures.", "motivation": "FNOs efficiently capture global patterns in PDEs but overlook local spatial features, limiting their performance. Existing methods for local feature extraction are insufficient or inefficient.", "method": "A CNN-based feature pre-extractor is added to FNOs to capture Local Spatial Features (LSFs), creating Conv-FNO. Two novel resizing schemes ensure resolution invariance.", "result": "Conv-FNO improves FNOs' representational capacity and performance on challenging PDE benchmarks, as shown by theoretical analysis and numerical experiments.", "conclusion": "Incorporating LSFs into FNOs via Conv-FNO is a simple yet effective modification that significantly enhances PDE solution approximation."}}
{"id": "2506.03593", "pdf": "https://arxiv.org/pdf/2506.03593", "abs": "https://arxiv.org/abs/2506.03593", "authors": ["Ray Groshan", "Michael Ginn", "Alexis Palmer"], "title": "Is linguistically-motivated data augmentation worth it?", "categories": ["cs.CL"], "comment": "Accepted to ACL 2025 Main. First two authors contributed equally", "summary": "Data augmentation, a widely-employed technique for addressing data scarcity,\ninvolves generating synthetic data examples which are then used to augment\navailable training data. Researchers have seen surprising success from simple\nmethods, such as random perturbations from natural examples, where models seem\nto benefit even from data with nonsense words, or data that doesn't conform to\nthe rules of the language. A second line of research produces synthetic data\nthat does in fact follow all linguistic constraints; these methods require some\nlinguistic expertise and are generally more challenging to implement. No\nprevious work has done a systematic, empirical comparison of both\nlinguistically-naive and linguistically-motivated data augmentation strategies,\nleaving uncertainty about whether the additional time and effort of\nlinguistically-motivated data augmentation work in fact yields better\ndownstream performance.\n  In this work, we conduct a careful and comprehensive comparison of\naugmentation strategies (both linguistically-naive and\nlinguistically-motivated) for two low-resource languages with different\nmorphological properties, Uspanteko and Arapaho. We evaluate the effectiveness\nof many different strategies and their combinations across two important\nsequence-to-sequence tasks for low-resource languages: machine translation and\ninterlinear glossing. We find that linguistically-motivated strategies can have\nbenefits over naive approaches, but only when the new examples they produce are\nnot significantly unlike the training data distribution.", "AI": {"tldr": "The paper compares linguistically-naive and linguistically-motivated data augmentation strategies for low-resource languages, finding that the latter is beneficial only when synthetic data aligns closely with the training distribution.", "motivation": "To address uncertainty about whether linguistically-motivated data augmentation outperforms naive methods, given the lack of systematic empirical comparisons.", "method": "A comprehensive comparison of augmentation strategies for Uspanteko and Arapaho, evaluated on machine translation and interlinear glossing tasks.", "result": "Linguistically-motivated strategies outperform naive ones only when synthetic data closely matches the training distribution.", "conclusion": "Linguistically-motivated augmentation is beneficial but depends on alignment with the training data distribution."}}
{"id": "2506.03473", "pdf": "https://arxiv.org/pdf/2506.03473", "abs": "https://arxiv.org/abs/2506.03473", "authors": ["Xinru Ying", "Jiaqi Mo", "Jingyang Lin", "Canghong Jin", "Fangfang Wang", "Lina Wei"], "title": "MamFusion: Multi-Mamba with Temporal Fusion for Partially Relevant Video Retrieval", "categories": ["cs.CV"], "comment": null, "summary": "Partially Relevant Video Retrieval (PRVR) is a challenging task in the domain\nof multimedia retrieval. It is designed to identify and retrieve untrimmed\nvideos that are partially relevant to the provided query. In this work, we\ninvestigate long-sequence video content understanding to address information\nredundancy issues. Leveraging the outstanding long-term state space modeling\ncapability and linear scalability of the Mamba module, we introduce a\nmulti-Mamba module with temporal fusion framework (MamFusion) tailored for PRVR\ntask. This framework effectively captures the state-relatedness in long-term\nvideo content and seamlessly integrates it into text-video relevance\nunderstanding, thereby enhancing the retrieval process. Specifically, we\nintroduce Temporal T-to-V Fusion and Temporal V-to-T Fusion to explicitly model\ntemporal relationships between text queries and video moments, improving\ncontextual awareness and retrieval accuracy. Extensive experiments conducted on\nlarge-scale datasets demonstrate that MamFusion achieves state-of-the-art\nperformance in retrieval effectiveness. Code is available at the link:\nhttps://github.com/Vision-Multimodal-Lab-HZCU/MamFusion.", "AI": {"tldr": "The paper introduces MamFusion, a multi-Mamba module framework for Partially Relevant Video Retrieval (PRVR), leveraging long-term state space modeling to improve retrieval accuracy.", "motivation": "Addressing the challenge of identifying partially relevant untrimmed videos by tackling information redundancy in long-sequence video content.", "method": "Proposes MamFusion with Temporal T-to-V and V-to-T Fusion to model temporal relationships between text queries and video moments.", "result": "Achieves state-of-the-art performance in retrieval effectiveness on large-scale datasets.", "conclusion": "MamFusion effectively enhances PRVR by integrating long-term video content understanding with text-video relevance."}}
{"id": "2506.03525", "pdf": "https://arxiv.org/pdf/2506.03525", "abs": "https://arxiv.org/abs/2506.03525", "authors": ["Daeun Lee", "Jaehong Yoon", "Jaemin Cho", "Mohit Bansal"], "title": "Video-Skill-CoT: Skill-based Chain-of-Thoughts for Domain-Adaptive Video Reasoning", "categories": ["cs.CV", "cs.AI", "cs.CL"], "comment": "Project website: https://video-skill-cot.github.io/", "summary": "Recent advances in Chain-of-Thought (CoT) reasoning have improved complex\nvideo understanding, but existing methods often struggle to adapt to\ndomain-specific skills (e.g., event detection, spatial relation understanding,\nemotion understanding) over various video content. To address this, we propose\nVideo-Skill-CoT (a.k.a. Video-SKoT), a framework that automatically constructs\nand leverages skill-aware CoT supervisions for domain-adaptive video reasoning.\nFirst, we construct skill-based CoT annotations: we extract domain-relevant\nreasoning skills from training questions, cluster them into a shared skill\ntaxonomy, and create detailed multi-step CoT rationale tailored to each\nvideo-question pair for training. Second, we introduce a skill-specific expert\nlearning framework. Each expert module specializes in a subset of reasoning\nskills and is trained with lightweight adapters using the collected CoT\nsupervision. We demonstrate the effectiveness of the proposed approach on three\nvideo understanding benchmarks, where Video-SKoT consistently outperforms\nstrong baselines. We also provide in-depth analyses on comparing different CoT\nannotation pipelines and learned skills over multiple video domains.", "AI": {"tldr": "Video-SKoT improves video understanding by using skill-aware CoT supervisions and expert learning, outperforming baselines on benchmarks.", "motivation": "Existing CoT methods struggle with domain-specific skills in video understanding, necessitating a more adaptive approach.", "method": "Video-SKoT constructs skill-based CoT annotations and employs skill-specific expert learning with lightweight adapters.", "result": "The framework outperforms baselines on three video understanding benchmarks.", "conclusion": "Video-SKoT effectively adapts CoT reasoning to diverse video domains, enhancing performance and skill understanding."}}
{"id": "2506.03542", "pdf": "https://arxiv.org/pdf/2506.03542", "abs": "https://arxiv.org/abs/2506.03542", "authors": ["Yongxiang Tang", "Yanhua Cheng", "Xiaocheng Liu", "Chenchen Jiao", "Yanxiang Zeng", "Ning Luo", "Pengjia Yuan", "Xialong Liu", "Peng Jiang"], "title": "Learning Monotonic Probabilities with a Generative Cost Model", "categories": ["cs.LG"], "comment": null, "summary": "In many machine learning tasks, it is often necessary for the relationship\nbetween input and output variables to be monotonic, including both strictly\nmonotonic and implicitly monotonic relationships. Traditional methods for\nmaintaining monotonicity mainly rely on construction or regularization\ntechniques, whereas this paper shows that the issue of strict monotonic\nprobability can be viewed as a partial order between an observable revenue\nvariable and a latent cost variable. This perspective enables us to reformulate\nthe monotonicity challenge into modeling the latent cost variable. To tackle\nthis, we introduce a generative network for the latent cost variable, termed\nthe Generative Cost Model (GCM), which inherently addresses the strict\nmonotonic problem, and propose the Implicit Generative Cost Model (IGCM) to\naddress the implicit monotonic problem. We further validate our approach with a\nnumerical simulation of quantile regression and conduct multiple experiments on\npublic datasets, showing that our method significantly outperforms existing\nmonotonic modeling techniques. The code for our experiments can be found at\nhttps://github.com/tyxaaron/GCM.", "AI": {"tldr": "The paper introduces Generative Cost Model (GCM) and Implicit Generative Cost Model (IGCM) to address strict and implicit monotonicity in machine learning, outperforming traditional methods.", "motivation": "Monotonic relationships between input and output variables are crucial in many ML tasks, but traditional methods rely on construction or regularization. This paper reframes monotonicity as a partial order problem involving latent cost variables.", "method": "The authors propose GCM for strict monotonicity and IGCM for implicit monotonicity, modeling the latent cost variable. The approach is validated via quantile regression simulations and experiments on public datasets.", "result": "The method significantly outperforms existing monotonic modeling techniques, as demonstrated in experiments.", "conclusion": "The paper successfully reformulates monotonicity challenges using latent cost variables, offering effective solutions with GCM and IGCM."}}
{"id": "2505.12532", "pdf": "https://arxiv.org/pdf/2505.12532", "abs": "https://arxiv.org/abs/2505.12532", "authors": ["Ahmet Bilican", "M. Ak\u0131n Y\u0131lmaz", "A. Murat Tekalp", "R. G\u00f6kberk Cinbi\u015f"], "title": "Exploring Sparsity for Parameter Efficient Fine Tuning Using Wavelets", "categories": ["cs.CV", "cs.AI", "cs.LG", "eess.IV", "eess.SP"], "comment": null, "summary": "Efficiently adapting large foundation models is critical, especially with\ntight compute and memory budgets. Parameter-Efficient Fine-Tuning (PEFT)\nmethods such as LoRA offer limited granularity and effectiveness in\nfew-parameter regimes. We propose Wavelet Fine-Tuning (WaveFT), a novel PEFT\nmethod that learns highly sparse updates in the wavelet domain of residual\nmatrices. WaveFT allows precise control of trainable parameters, offering\nfine-grained capacity adjustment and excelling with remarkably low parameter\ncount, potentially far fewer than LoRA's minimum, ideal for extreme\nparameter-efficient scenarios. Evaluated on personalized text-to-image\ngeneration using Stable Diffusion XL as baseline, WaveFT significantly\noutperforms LoRA and other PEFT methods, especially at low parameter counts;\nachieving superior subject fidelity, prompt alignment, and image diversity.", "AI": {"tldr": "WaveFT is a novel PEFT method for efficient adaptation of large models, outperforming LoRA in few-parameter regimes by learning sparse updates in the wavelet domain.", "motivation": "The need for efficient adaptation of large foundation models under tight compute and memory constraints, where existing methods like LoRA lack granularity and effectiveness.", "method": "WaveFT learns highly sparse updates in the wavelet domain of residual matrices, enabling precise control of trainable parameters and fine-grained capacity adjustment.", "result": "WaveFT significantly outperforms LoRA and other PEFT methods in personalized text-to-image generation, achieving better subject fidelity, prompt alignment, and image diversity, especially at low parameter counts.", "conclusion": "WaveFT is ideal for extreme parameter-efficient scenarios, offering superior performance with remarkably low parameter counts."}}
{"id": "2506.03598", "pdf": "https://arxiv.org/pdf/2506.03598", "abs": "https://arxiv.org/abs/2506.03598", "authors": ["Zetong Tang", "Qian Ma", "Di Wu"], "title": "Auto prompt sql: a resource-efficient architecture for text-to-sql translation in constrained environments", "categories": ["cs.CL", "cs.AI", "68T50"], "comment": "4 pages,2 figures,EITCE 2025", "summary": "Using the best Text-to-SQL methods in resource-constrained environments is\nchallenging due to their reliance on resource-intensive open-source models.\nThis paper introduces Auto Prompt SQL(AP-SQL), a novel architecture designed to\nbridge the gap between resource-efficient small open-source models and the\npowerful capabilities of large closed-source models for Text-to-SQL\ntranslation. Our method decomposes the task into schema filtering,\nretrieval-augmented text-to-SQL generation based on in-context examples, and\nprompt-driven schema linking and SQL generation. To improve schema selection\naccuracy, we fine-tune large language models. Crucially, we also explore the\nimpact of prompt engineering throughout the process, leveraging\nChain-of-Thought(CoT) and Graph-of-Thought(GoT) templates to significantly\nenhance the model's reasoning for accurate SQL generation. Comprehensive\nevaluations on the Spider benchmarks demonstrate the effectiveness of AP-SQL.", "AI": {"tldr": "AP-SQL bridges resource-efficient small models and powerful large models for Text-to-SQL, using schema filtering, retrieval-augmented generation, and prompt-driven methods with CoT/GoT templates.", "motivation": "Addressing the challenge of using resource-intensive models in constrained environments for Text-to-SQL tasks.", "method": "Decomposes the task into schema filtering, retrieval-augmented generation, and prompt-driven schema linking/SQL generation, with fine-tuned LLMs and CoT/GoT prompts.", "result": "Effective performance demonstrated on Spider benchmarks.", "conclusion": "AP-SQL successfully balances efficiency and capability for Text-to-SQL translation."}}
{"id": "2506.03481", "pdf": "https://arxiv.org/pdf/2506.03481", "abs": "https://arxiv.org/abs/2506.03481", "authors": ["Hongsong Wang", "Xiaoyan Ma", "Jidong Kuang", "Jie Gui"], "title": "Heterogeneous Skeleton-Based Action Representation Learning", "categories": ["cs.CV"], "comment": "To appear in CVPR 2025", "summary": "Skeleton-based human action recognition has received widespread attention in\nrecent years due to its diverse range of application scenarios. Due to the\ndifferent sources of human skeletons, skeleton data naturally exhibit\nheterogeneity. The previous works, however, overlook the heterogeneity of human\nskeletons and solely construct models tailored for homogeneous skeletons. This\nwork addresses the challenge of heterogeneous skeleton-based action\nrepresentation learning, specifically focusing on processing skeleton data that\nvaries in joint dimensions and topological structures. The proposed framework\ncomprises two primary components: heterogeneous skeleton processing and unified\nrepresentation learning. The former first converts two-dimensional skeleton\ndata into three-dimensional skeleton via an auxiliary network, and then\nconstructs a prompted unified skeleton using skeleton-specific prompts. We also\ndesign an additional modality named semantic motion encoding to harness the\nsemantic information within skeletons. The latter module learns a unified\naction representation using a shared backbone network that processes different\nheterogeneous skeletons. Extensive experiments on the NTU-60, NTU-120, and\nPKU-MMD II datasets demonstrate the effectiveness of our method in various\ntasks of action understanding. Our approach can be applied to action\nrecognition in robots with different humanoid structures.", "AI": {"tldr": "The paper proposes a framework for heterogeneous skeleton-based action recognition, addressing variability in joint dimensions and topological structures. It includes skeleton processing and unified representation learning, validated on multiple datasets.", "motivation": "Existing models overlook skeleton heterogeneity, limiting their applicability. This work aims to handle diverse skeleton data for broader action recognition tasks.", "method": "The framework processes skeletons via 2D-to-3D conversion and skeleton-specific prompts, adds semantic motion encoding, and uses a shared backbone for unified representation.", "result": "Experiments on NTU-60, NTU-120, and PKU-MMD II show the method's effectiveness in action understanding tasks.", "conclusion": "The approach successfully handles heterogeneous skeletons and is applicable to robots with varied humanoid structures."}}
{"id": "2506.03568", "pdf": "https://arxiv.org/pdf/2506.03568", "abs": "https://arxiv.org/abs/2506.03568", "authors": ["Li Zeqiao", "Wang Yijing", "Wang Haoyu", "Li Zheng", "Li Peng", "Zuo zhiqiang", "Hu Chuan"], "title": "Confidence-Guided Human-AI Collaboration: Reinforcement Learning with Distributional Proxy Value Propagation for Autonomous Driving", "categories": ["cs.RO", "cs.AI"], "comment": null, "summary": "Autonomous driving promises significant advancements in mobility, road safety\nand traffic efficiency, yet reinforcement learning and imitation learning face\nsafe-exploration and distribution-shift challenges. Although human-AI\ncollaboration alleviates these issues, it often relies heavily on extensive\nhuman intervention, which increases costs and reduces efficiency. This paper\ndevelops a confidence-guided human-AI collaboration (C-HAC) strategy to\novercome these limitations. First, C-HAC employs a distributional proxy value\npropagation method within the distributional soft actor-critic (DSAC)\nframework. By leveraging return distributions to represent human intentions\nC-HAC achieves rapid and stable learning of human-guided policies with minimal\nhuman interaction. Subsequently, a shared control mechanism is activated to\nintegrate the learned human-guided policy with a self-learning policy that\nmaximizes cumulative rewards. This enables the agent to explore independently\nand continuously enhance its performance beyond human guidance. Finally, a\npolicy confidence evaluation algorithm capitalizes on DSAC's return\ndistribution networks to facilitate dynamic switching between human-guided and\nself-learning policies via a confidence-based intervention function. This\nensures the agent can pursue optimal policies while maintaining safety and\nperformance guarantees. Extensive experiments across diverse driving scenarios\nreveal that C-HAC significantly outperforms conventional methods in terms of\nsafety, efficiency, and overall performance, achieving state-of-the-art\nresults. The effectiveness of the proposed method is further validated through\nreal-world road tests in complex traffic conditions. The videos and code are\navailable at: https://github.com/lzqw/C-HAC.", "AI": {"tldr": "The paper introduces C-HAC, a confidence-guided human-AI collaboration strategy for autonomous driving, combining human-guided and self-learning policies to improve safety and efficiency.", "motivation": "Autonomous driving faces challenges like safe-exploration and distribution-shift in reinforcement and imitation learning. Human-AI collaboration often requires excessive human intervention, increasing costs and reducing efficiency.", "method": "C-HAC uses a distributional proxy value propagation method within DSAC to learn human-guided policies with minimal interaction. It integrates these with self-learning policies via a shared control mechanism and dynamic switching based on policy confidence.", "result": "C-HAC outperforms conventional methods in safety, efficiency, and performance, achieving state-of-the-art results in diverse driving scenarios and real-world tests.", "conclusion": "C-HAC effectively balances human guidance and autonomous learning, ensuring safety and performance while minimizing human intervention."}}
{"id": "2506.03556", "pdf": "https://arxiv.org/pdf/2506.03556", "abs": "https://arxiv.org/abs/2506.03556", "authors": ["Wang WeiQuan", "Riaz-ul-Haque Mian"], "title": "Optimizing FPGA and Wafer Test Coverage with Spatial Sampling and Machine Learning", "categories": ["cs.LG"], "comment": null, "summary": "In semiconductor manufacturing, testing costs remain significantly high,\nespecially during wafer and FPGA testing. To reduce the number of required\ntests while maintaining predictive accuracy, this study investigates three\nbaseline sampling strategies: Random Sampling, Stratified Sampling, and k-means\nClustering Sampling. To further enhance these methods, this study proposes a\nnovel algorithm that improves the sampling quality of each approach. This\nresearch is conducted using real industrial production data from wafer-level\ntests and silicon measurements from various FPGAs. This study introduces two\nhybrid strategies: Stratified with Short Distance Elimination (S-SDE) and\nk-means with Short Distance Elimination (K-SDE). Their performance is evaluated\nwithin the framework of Gaussian Process Regression (GPR) for predicting wafer\nand FPGA test data. At the core of our proposed approach is the Short Distance\nElimination (SDE) algorithm, which excludes spatially proximate candidate\npoints during sampling, thereby ensuring a more uniform distribution of\ntraining data across the physical domain. A parameter sweep was conducted over\nthe (alpha, beta) thresholds, where alpha and beta are in the range {0, 1, 2,\n3, 4} and not both zero, to identify the optimal combination that minimizes\nRMSD. Experimental results on a randomly selected wafer file reveal that\n(alpha, beta) equal (2, 2) yields the lowest RMSD. Accordingly, all subsequent\nexperiments adopt this parameter configuration. The results demonstrate that\nthe proposed SDE-based strategies enhance predictive accuracy: K-SDE improves\nupon k-means sampling by 16.26 percent (wafer) and 13.07 percent (FPGA), while\nS-SDE improves upon stratified sampling by 16.49 percent (wafer) and 8.84\npercent (FPGA).", "AI": {"tldr": "The study proposes a novel algorithm (SDE) to enhance sampling strategies in semiconductor testing, improving predictive accuracy in wafer and FPGA tests.", "motivation": "High testing costs in semiconductor manufacturing drive the need for efficient sampling methods to reduce tests while maintaining accuracy.", "method": "Investigates Random, Stratified, and k-means Sampling, proposes hybrid S-SDE and K-SDE strategies using SDE for uniform data distribution, evaluated via GPR.", "result": "SDE-based strategies (K-SDE, S-SDE) improve accuracy: 16.26% (wafer) and 13.07% (FPGA) over k-means; 16.49% (wafer) and 8.84% (FPGA) over stratified sampling.", "conclusion": "The SDE algorithm effectively enhances sampling quality, reducing testing costs while maintaining accuracy in semiconductor manufacturing."}}
{"id": "2506.01224", "pdf": "https://arxiv.org/pdf/2506.01224", "abs": "https://arxiv.org/abs/2506.01224", "authors": ["John W. Smutny"], "title": "Dirty and Clean-Label attack detection using GAN discriminators", "categories": ["cs.CV", "eess.IV"], "comment": "13 pages total. Appendix starts on page 10", "summary": "Gathering enough images to train a deep computer vision model is a constant\nchallenge. Unfortunately, collecting images from unknown sources can leave your\nmodel s behavior at risk of being manipulated by a dirty-label or clean-label\nattack unless the images are properly inspected. Manually inspecting each\nimage-label pair is impractical and common poison-detection methods that\ninvolve re-training your model can be time consuming. This research uses GAN\ndiscriminators to protect a single class against mislabeled and different\nlevels of modified images. The effect of said perturbation on a basic\nconvolutional neural network classifier is also included for reference. The\nresults suggest that after training on a single class, GAN discriminator s\nconfidence scores can provide a threshold to identify mislabeled images and\nidentify 100% of the tested poison starting at a perturbation epsilon magnitude\nof 0.20, after decision threshold calibration using in-class samples.\nDevelopers can use this report as a basis to train their own discriminators to\nprotect high valued classes in their CV models.", "AI": {"tldr": "GAN discriminators can detect mislabeled and poisoned images in a single class, providing a threshold for identifying such threats with high accuracy.", "motivation": "Addressing the challenge of ensuring image-label integrity in deep learning models without impractical manual inspection or time-consuming retraining.", "method": "Using GAN discriminators trained on a single class to identify mislabeled and modified images, with threshold calibration for detection.", "result": "GAN discriminators achieved 100% poison detection at perturbation epsilon \u2265 0.20 after threshold calibration.", "conclusion": "GAN discriminators offer a practical solution for protecting high-value classes in computer vision models against label manipulation."}}
{"id": "2506.03616", "pdf": "https://arxiv.org/pdf/2506.03616", "abs": "https://arxiv.org/abs/2506.03616", "authors": ["Eunki Kim", "Sangryul Kim", "James Thorne"], "title": "Learning to Insert [PAUSE] Tokens for Better Reasoning", "categories": ["cs.CL"], "comment": "18 pages, 5 figures, ACL findings", "summary": "To enhance reasoning capabilities, previous works have explored incorporating\nspecial-purpose tokens into the training process. These strategies strengthen\nthe learning mechanism of transformer-based large language models (LLMs).\nBuilding on prior research, in which inserting dummy tokens consecutively just\nbefore reasoning steps can enhance effectiveness, we introduce a novel approach\ntermed Dynamic Inserting Tokens Training (DIT). Our method identifies positions\nwithin sequences where model confidence is lowest according to token\nlog-likelihood. Strategically inserting [PAUSE] tokens on these positions\nbolsters the model's predictive capabilities for subsequent tokens.\nExperimental results across diverse datasets and models, from the 2.7B model to\nthe 8B model, demonstrate that DIT consistently outperforms traditional\nfine-tuning and previous token insertion methods. With this simple yet\neffective method, we achieve accuracy gains of up to 4.7%p on GSM8K, 3.23%p on\nAQUA-RAT, and pass@1 improvements of up to 3.4%p on MBPP datasets. Our work\nshows a model-based, dynamic approach rather than a heuristic one, thereby\nbroadening the scope of research in reasoning.", "AI": {"tldr": "The paper introduces Dynamic Inserting Tokens Training (DIT), a method to enhance reasoning in LLMs by strategically inserting [PAUSE] tokens where model confidence is low, improving performance over traditional methods.", "motivation": "To improve reasoning in LLMs by dynamically identifying and addressing low-confidence positions in sequences, moving beyond heuristic token insertion.", "method": "DIT inserts [PAUSE] tokens at positions with lowest token log-likelihood, enhancing predictive capabilities for subsequent tokens.", "result": "DIT outperforms traditional fine-tuning and prior token insertion methods, achieving accuracy gains up to 4.7%p on GSM8K and 3.4%p pass@1 on MBPP.", "conclusion": "DIT offers a dynamic, model-based approach to reasoning enhancement, expanding research possibilities beyond heuristic methods."}}
{"id": "2506.03502", "pdf": "https://arxiv.org/pdf/2506.03502", "abs": "https://arxiv.org/abs/2506.03502", "authors": ["Yuxuan Chen", "Haipeng Xie"], "title": "CHIME: Conditional Hallucination and Integrated Multi-scale Enhancement for Time Series Diffusion Model", "categories": ["cs.CV", "cs.SY", "eess.SY"], "comment": null, "summary": "The denoising diffusion probabilistic model has become a mainstream\ngenerative model, achieving significant success in various computer vision\ntasks. Recently, there has been initial exploration of applying diffusion\nmodels to time series tasks. However, existing studies still face challenges in\nmulti-scale feature alignment and generative capabilities across different\nentities and long-time scales. In this paper, we propose CHIME, a conditional\nhallucination and integrated multi-scale enhancement framework for time series\ndiffusion models. By employing multi-scale decomposition and adaptive\nintegration, CHIME captures the decomposed features of time series, achieving\nin-domain distribution alignment between generated and original samples. In\naddition, we introduce a feature hallucination module in the conditional\ndenoising process, enabling the transfer of temporal features through the\ntraining of category-independent transformation layers. Experimental results on\npublicly available real-world datasets demonstrate that CHIME achieves\nstate-of-the-art performance and exhibits excellent generative generalization\ncapabilities in few-shot scenarios.", "AI": {"tldr": "CHIME is a framework for time series diffusion models that improves multi-scale feature alignment and generative capabilities through decomposition, adaptive integration, and feature hallucination.", "motivation": "Existing diffusion models for time series struggle with multi-scale feature alignment and generative generalization across entities and long-time scales.", "method": "CHIME uses multi-scale decomposition, adaptive integration, and a feature hallucination module for conditional denoising.", "result": "CHIME achieves state-of-the-art performance and strong generalization in few-shot scenarios on real-world datasets.", "conclusion": "CHIME effectively addresses challenges in time series diffusion models, enhancing generative capabilities and feature alignment."}}
{"id": "2506.03571", "pdf": "https://arxiv.org/pdf/2506.03571", "abs": "https://arxiv.org/abs/2506.03571", "authors": ["Chong Hyun Lee", "Kibae Lee"], "title": "DiagNet: Detecting Objects using Diagonal Constraints on Adjacency Matrix of Graph Neural Network", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "We propose DaigNet, a new approach to object detection with which we can\ndetect an object bounding box using diagonal constraints on adjacency matrix of\na graph convolutional network (GCN). We propose two diagonalization algorithms\nbased on hard and soft constraints on adjacency matrix and two loss functions\nusing diagonal constraint and complementary constraint. The DaigNet eliminates\nthe need for designing a set of anchor boxes commonly used. To prove\nfeasibility of our novel detector, we adopt detection head in YOLO models.\nExperiments show that the DiagNet achieves 7.5% higher mAP50 on Pascal VOC than\nYOLOv1. The DiagNet also shows 5.1% higher mAP on MS COCO than YOLOv3u, 3.7%\nhigher mAP than YOLOv5u, and 2.9% higher mAP than YOLOv8.", "AI": {"tldr": "DaigNet introduces a novel object detection method using diagonal constraints on GCN adjacency matrices, outperforming YOLO variants in accuracy.", "motivation": "To simplify object detection by eliminating anchor box design and improving accuracy through graph-based constraints.", "method": "Uses GCN with hard/soft diagonal constraints on adjacency matrices and complementary loss functions, integrated into YOLO's detection head.", "result": "Achieves 7.5% higher mAP50 on Pascal VOC and outperforms YOLOv3u, YOLOv5u, and YOLOv8 on MS COCO.", "conclusion": "DaigNet is a feasible, anchor-free detector with superior performance over YOLO models."}}
{"id": "2506.03588", "pdf": "https://arxiv.org/pdf/2506.03588", "abs": "https://arxiv.org/abs/2506.03588", "authors": ["Hiroki Shiraishi", "Hisao Ishibuchi", "Masaya Nakata"], "title": "A Class Inference Scheme With Dempster-Shafer Theory for Learning Fuzzy-Classifier Systems", "categories": ["cs.LG", "cs.AI", "cs.NE"], "comment": null, "summary": "The decision-making process significantly influences the predictions of\nmachine learning models. This is especially important in rule-based systems\nsuch as Learning Fuzzy-Classifier Systems (LFCSs) where the selection and\napplication of rules directly determine prediction accuracy and reliability.\nLFCSs combine evolutionary algorithms with supervised learning to optimize\nfuzzy classification rules, offering enhanced interpretability and robustness.\nDespite these advantages, research on improving decision-making mechanisms\n(i.e., class inference schemes) in LFCSs remains limited. Most LFCSs use\nvoting-based or single-winner-based inference schemes. These schemes rely on\nclassification performance on training data and may not perform well on unseen\ndata, risking overfitting. To address these limitations, this article\nintroduces a novel class inference scheme for LFCSs based on the\nDempster-Shafer Theory of Evidence (DS theory). The proposed scheme handles\nuncertainty well. By using the DS theory, the scheme calculates belief masses\n(i.e., measures of belief) for each specific class and the ``I don't know''\nstate from each fuzzy rule and infers a class from these belief masses. Unlike\nthe conventional schemes, the proposed scheme also considers the ``I don't\nknow'' state that reflects uncertainty, thereby improving the transparency and\nreliability of LFCSs. Applied to a variant of LFCS (i.e., Fuzzy-UCS), the\nproposed scheme demonstrates statistically significant improvements in terms of\ntest macro F1 scores across 30 real-world datasets compared to conventional\nvoting-based and single-winner-based fuzzy inference schemes. It forms smoother\ndecision boundaries, provides reliable confidence measures, and enhances the\nrobustness and generalizability of LFCSs in real-world applications. Our\nimplementation is available at https://github.com/YNU-NakataLab/jUCS.", "AI": {"tldr": "The paper introduces a novel class inference scheme for Learning Fuzzy-Classifier Systems (LFCSs) using Dempster-Shafer Theory to improve uncertainty handling and reliability.", "motivation": "Existing LFCSs rely on voting-based or single-winner inference schemes, which may overfit and lack transparency. The study aims to enhance decision-making in LFCSs.", "method": "A new inference scheme based on Dempster-Shafer Theory calculates belief masses for classes and an \"I don't know\" state, improving uncertainty handling.", "result": "The scheme outperforms conventional methods on 30 datasets, showing better macro F1 scores, smoother decision boundaries, and improved robustness.", "conclusion": "The proposed scheme enhances LFCSs' reliability and generalizability, offering a transparent and robust alternative to traditional inference methods."}}
{"id": "2506.03619", "pdf": "https://arxiv.org/pdf/2506.03619", "abs": "https://arxiv.org/abs/2506.03619", "authors": ["Ayuto Tsutsumi", "Yuu Jinnai"], "title": "Do Large Language Models Know Folktales? A Case Study of Yokai in Japanese Folktales", "categories": ["cs.CL"], "comment": null, "summary": "Although Large Language Models (LLMs) have demonstrated strong language\nunderstanding and generation abilities across various languages, their cultural\nknowledge is often limited to English-speaking communities, which can\nmarginalize the cultures of non-English communities. To address the problem,\nevaluation of the cultural awareness of the LLMs and the methods to develop\nculturally aware LLMs have been investigated. In this study, we focus on\nevaluating knowledge of folktales, a key medium for conveying and circulating\nculture. In particular, we focus on Japanese folktales, specifically on\nknowledge of Yokai. Yokai are supernatural creatures originating from Japanese\nfolktales that continue to be popular motifs in art and entertainment today.\nYokai have long served as a medium for cultural expression, making them an\nideal subject for assessing the cultural awareness of LLMs. We introduce\nYokaiEval, a benchmark dataset consisting of 809 multiple-choice questions\n(each with four options) designed to probe knowledge about yokai. We evaluate\nthe performance of 31 Japanese and multilingual LLMs on this dataset. The\nresults show that models trained with Japanese language resources achieve\nhigher accuracy than English-centric models, with those that underwent\ncontinued pretraining in Japanese, particularly those based on Llama-3,\nperforming especially well. The code and dataset are available at\nhttps://github.com/CyberAgentA ILab/YokaiEval.", "AI": {"tldr": "The paper evaluates cultural awareness in LLMs using Japanese folktales (Yokai) and introduces YokaiEval, a benchmark dataset. Results show Japanese-trained models outperform English-centric ones.", "motivation": "LLMs often lack cultural knowledge beyond English-speaking communities, marginalizing non-English cultures. The study aims to assess and improve cultural awareness in LLMs.", "method": "The study introduces YokaiEval, a dataset of 809 multiple-choice questions about Yokai, and evaluates 31 Japanese and multilingual LLMs.", "result": "Japanese-trained models, especially those based on Llama-3, achieve higher accuracy than English-centric models.", "conclusion": "The study highlights the need for culturally diverse training in LLMs and demonstrates the effectiveness of language-specific pretraining."}}
{"id": "2506.03512", "pdf": "https://arxiv.org/pdf/2506.03512", "abs": "https://arxiv.org/abs/2506.03512", "authors": ["Daikun Liu", "Lei Cheng", "Teng Wang", "changyin Sun"], "title": "EDCFlow: Exploring Temporally Dense Difference Maps for Event-based Optical Flow Estimation", "categories": ["cs.CV"], "comment": "14 pages, 8 figures", "summary": "Recent learning-based methods for event-based optical flow estimation utilize\ncost volumes for pixel matching but suffer from redundant computations and\nlimited scalability to higher resolutions for flow refinement. In this work, we\ntake advantage of the complementarity between temporally dense feature\ndifferences of adjacent event frames and cost volume and present a lightweight\nevent-based optical flow network (EDCFlow) to achieve high-quality flow\nestimation at a higher resolution. Specifically, an attention-based multi-scale\ntemporal feature difference layer is developed to capture diverse motion\npatterns at high resolution in a computation-efficient manner. An adaptive\nfusion of high-resolution difference motion features and low-resolution\ncorrelation motion features is performed to enhance motion representation and\nmodel generalization. Notably, EDCFlow can serve as a plug-and-play refinement\nmodule for RAFT-like event-based methods to enhance flow details. Extensive\nexperiments demonstrate that EDCFlow achieves better performance with lower\ncomplexity compared to existing methods, offering superior generalization.", "AI": {"tldr": "EDCFlow is a lightweight event-based optical flow network that combines temporal feature differences and cost volumes for high-quality flow estimation at higher resolutions with lower complexity.", "motivation": "Existing methods suffer from redundant computations and limited scalability to higher resolutions for flow refinement.", "method": "Uses an attention-based multi-scale temporal feature difference layer and adaptively fuses high-resolution difference features with low-resolution correlation features.", "result": "Achieves better performance with lower complexity and superior generalization compared to existing methods.", "conclusion": "EDCFlow is effective for high-resolution flow estimation and can enhance RAFT-like methods as a plug-and-play module."}}
{"id": "2506.03582", "pdf": "https://arxiv.org/pdf/2506.03582", "abs": "https://arxiv.org/abs/2506.03582", "authors": ["Rui Yann", "Xianglei Xing"], "title": "ViTSGMM: A Robust Semi-Supervised Image Recognition Network Using Sparse Labels", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": null, "summary": "We present ViTSGMM, an image recognition network that leverages\nsemi-supervised learning in a highly efficient manner. Existing works often\nrely on complex training techniques and architectures, while their\ngeneralization ability when dealing with extremely limited labeled data remains\nto be improved. To address these limitations, we construct a hierarchical\nmixture density classification decision mechanism by optimizing mutual\ninformation between feature representations and target classes, compressing\nredundant information while retaining crucial discriminative components.\nExperimental results demonstrate that our method achieves state-of-the-art\nperformance on STL-10 and CIFAR-10/100 datasets when using negligible labeled\nsamples. Notably, this paper also reveals a long-overlooked data leakage issue\nin the STL-10 dataset for semi-supervised learning tasks and removes duplicates\nto ensure the reliability of experimental results. Code available at\nhttps://github.com/Shu1L0n9/ViTSGMM.", "AI": {"tldr": "ViTSGMM is an efficient semi-supervised image recognition network that improves generalization with limited labeled data using a hierarchical mixture density mechanism and mutual information optimization.", "motivation": "Existing methods struggle with generalization on limited labeled data and rely on complex architectures.", "method": "Constructs a hierarchical mixture density classification mechanism, optimizing mutual information to retain discriminative features.", "result": "Achieves state-of-the-art performance on STL-10 and CIFAR-10/100 with minimal labeled data; identifies and fixes data leakage in STL-10.", "conclusion": "ViTSGMM is highly efficient and reliable, addressing key limitations in semi-supervised learning."}}
{"id": "2506.03590", "pdf": "https://arxiv.org/pdf/2506.03590", "abs": "https://arxiv.org/abs/2506.03590", "authors": ["Minh Luu", "Surya Jasper", "Khoi Le", "Evan Pan", "Michael Quinn", "Aakash Tyagi", "Jiang Hu"], "title": "VCDiag: Classifying Erroneous Waveforms for Failure Triage Acceleration", "categories": ["cs.LG"], "comment": null, "summary": "Failure triage in design functional verification is critical but\ntime-intensive, relying on manual specification reviews, log inspections, and\nwaveform analyses. While machine learning (ML) has improved areas like stimulus\ngeneration and coverage closure, its application to RTL-level simulation\nfailure triage, particularly for large designs, remains limited. VCDiag offers\nan efficient, adaptable approach using VCD data to classify failing waveforms\nand pinpoint likely failure locations. In the largest experiment, VCDiag\nachieves over 94% accuracy in identifying the top three most likely modules.\nThe framework introduces a novel signal selection and statistical compression\napproach, achieving over 120x reduction in raw data size while preserving\nfeatures essential for classification. It can also be integrated into diverse\nVerilog/SystemVerilog designs and testbenches.", "AI": {"tldr": "VCDiag uses VCD data to classify failing waveforms and locate failures in RTL-level simulation, achieving high accuracy and significant data reduction.", "motivation": "Manual failure triage in design verification is time-consuming, and ML applications for RTL-level simulation failure triage are limited.", "method": "VCDiag employs signal selection and statistical compression on VCD data to classify failures and reduce data size.", "result": "Achieves over 94% accuracy in identifying top failure modules and reduces raw data size by over 120x.", "conclusion": "VCDiag is an efficient, adaptable framework for failure triage, compatible with diverse Verilog/SystemVerilog designs."}}
{"id": "2506.03627", "pdf": "https://arxiv.org/pdf/2506.03627", "abs": "https://arxiv.org/abs/2506.03627", "authors": ["Lin Mu", "Guowei Chu", "Li Ni", "Lei Sang", "Zhize Wu", "Peiquan Jin", "Yiwen Zhang"], "title": "Robustness of Prompting: Enhancing Robustness of Large Language Models Against Prompting Attacks", "categories": ["cs.CL", "cs.AI"], "comment": "13pages", "summary": "Large Language Models (LLMs) have demonstrated remarkable performance across\nvarious tasks by effectively utilizing a prompting strategy. However, they are\nhighly sensitive to input perturbations, such as typographical errors or slight\ncharacter order errors, which can substantially degrade their performance.\nDespite advances in prompting techniques, developing a prompting strategy that\nexplicitly mitigates the negative impact of such perturbations remains an open\nchallenge. To bridge this gap, we propose Robustness of Prompting (RoP), a\nnovel prompting strategy specifically designed to enhance the robustness of\nLLMs. RoP consists of two stages: Error Correction and Guidance. In the Error\nCorrection stage, RoP applies diverse perturbation methods to generate\nadversarial examples, which are then used to construct prompts that\nautomatically correct input errors. In the Guidance stage, RoP generates an\noptimal guidance prompting based on the corrected input, steering the model\ntoward more robust and accurate inferences. Through comprehensive experiments\nspanning arithmetic, commonsense, and logical reasoning tasks, we demonstrate\nthat RoP significantly improves LLMs' robustness against adversarial\nperturbations. Notably, it maintains model accuracy with only minimal\ndegradation compared to clean input scenarios, thereby establishing RoP as a\npractical and effective approach for enhancing LLM robustness in real-world\napplications.", "AI": {"tldr": "RoP is a novel prompting strategy to enhance LLM robustness against input perturbations, combining error correction and guidance stages for improved performance.", "motivation": "LLMs are sensitive to input perturbations, degrading performance, but existing prompting strategies lack explicit mitigation for such issues.", "method": "RoP involves two stages: Error Correction (generating adversarial examples for prompt correction) and Guidance (optimal prompting for robust inference).", "result": "RoP significantly improves LLM robustness across tasks, maintaining accuracy with minimal degradation compared to clean inputs.", "conclusion": "RoP is a practical and effective method for enhancing LLM robustness in real-world applications."}}
{"id": "2506.03517", "pdf": "https://arxiv.org/pdf/2506.03517", "abs": "https://arxiv.org/abs/2506.03517", "authors": ["Ziyi Wu", "Anil Kag", "Ivan Skorokhodov", "Willi Menapace", "Ashkan Mirzaei", "Igor Gilitschenski", "Sergey Tulyakov", "Aliaksandr Siarohin"], "title": "DenseDPO: Fine-Grained Temporal Preference Optimization for Video Diffusion Models", "categories": ["cs.CV"], "comment": "Project page: https://snap-research.github.io/DenseDPO/", "summary": "Direct Preference Optimization (DPO) has recently been applied as a\npost-training technique for text-to-video diffusion models. To obtain training\ndata, annotators are asked to provide preferences between two videos generated\nfrom independent noise. However, this approach prohibits fine-grained\ncomparisons, and we point out that it biases the annotators towards low-motion\nclips as they often contain fewer visual artifacts. In this work, we introduce\nDenseDPO, a method that addresses these shortcomings by making three\ncontributions. First, we create each video pair for DPO by denoising corrupted\ncopies of a ground truth video. This results in aligned pairs with similar\nmotion structures while differing in local details, effectively neutralizing\nthe motion bias. Second, we leverage the resulting temporal alignment to label\npreferences on short segments rather than entire clips, yielding a denser and\nmore precise learning signal. With only one-third of the labeled data, DenseDPO\ngreatly improves motion generation over vanilla DPO, while matching it in text\nalignment, visual quality, and temporal consistency. Finally, we show that\nDenseDPO unlocks automatic preference annotation using off-the-shelf Vision\nLanguage Models (VLMs): GPT accurately predicts segment-level preferences\nsimilar to task-specifically fine-tuned video reward models, and DenseDPO\ntrained on these labels achieves performance close to using human labels.", "AI": {"tldr": "DenseDPO improves Direct Preference Optimization (DPO) for text-to-video diffusion models by addressing motion bias and enabling fine-grained comparisons through aligned video pairs and segment-level labeling.", "motivation": "The motivation is to overcome biases in DPO training data, where annotators favor low-motion clips due to fewer artifacts, and to enable more precise comparisons.", "method": "DenseDPO creates aligned video pairs from corrupted ground truth videos, labels preferences on short segments, and uses Vision Language Models (VLMs) for automatic annotation.", "result": "DenseDPO improves motion generation with one-third the labeled data, matches DPO in text alignment and quality, and achieves near-human performance with VLM labels.", "conclusion": "DenseDPO effectively addresses DPO's limitations, offering a more efficient and unbiased approach for training text-to-video models."}}
{"id": "2506.03589", "pdf": "https://arxiv.org/pdf/2506.03589", "abs": "https://arxiv.org/abs/2506.03589", "authors": ["Huy Le", "Nhat Chung", "Tung Kieu", "Anh Nguyen", "Ngan Le"], "title": "BiMa: Towards Biases Mitigation for Text-Video Retrieval via Scene Element Guidance", "categories": ["cs.CV", "cs.AI", "cs.CL"], "comment": "22 pages, 14 figures", "summary": "Text-video retrieval (TVR) systems often suffer from visual-linguistic biases\npresent in datasets, which cause pre-trained vision-language models to overlook\nkey details. To address this, we propose BiMa, a novel framework designed to\nmitigate biases in both visual and textual representations. Our approach begins\nby generating scene elements that characterize each video by identifying\nrelevant entities/objects and activities. For visual debiasing, we integrate\nthese scene elements into the video embeddings, enhancing them to emphasize\nfine-grained and salient details. For textual debiasing, we introduce a\nmechanism to disentangle text features into content and bias components,\nenabling the model to focus on meaningful content while separately handling\nbiased information. Extensive experiments and ablation studies across five\nmajor TVR benchmarks (i.e., MSR-VTT, MSVD, LSMDC, ActivityNet, and DiDeMo)\ndemonstrate the competitive performance of BiMa. Additionally, the model's bias\nmitigation capability is consistently validated by its strong results on\nout-of-distribution retrieval tasks.", "AI": {"tldr": "BiMa is a framework to reduce visual-linguistic biases in text-video retrieval by enhancing video embeddings and disentangling text features, showing strong performance across benchmarks.", "motivation": "TVR systems often overlook key details due to biases in datasets, limiting model effectiveness.", "method": "BiMa generates scene elements for videos, integrates them into embeddings for visual debiasing, and disentangles text features into content and bias components for textual debiasing.", "result": "BiMa achieves competitive performance on five TVR benchmarks and excels in out-of-distribution retrieval tasks.", "conclusion": "BiMa effectively mitigates biases in TVR systems, improving retrieval accuracy and robustness."}}
{"id": "2506.03595", "pdf": "https://arxiv.org/pdf/2506.03595", "abs": "https://arxiv.org/abs/2506.03595", "authors": ["Runa Eschenhagen", "Aaron Defazio", "Tsung-Hsien Lee", "Richard E. Turner", "Hao-Jun Michael Shi"], "title": "Purifying Shampoo: Investigating Shampoo's Heuristics by Decomposing its Preconditioner", "categories": ["cs.LG", "cs.AI", "stat.ML"], "comment": null, "summary": "The recent success of Shampoo in the AlgoPerf contest has sparked renewed\ninterest in Kronecker-factorization-based optimization algorithms for training\nneural networks. Despite its success, Shampoo relies heavily on several\nheuristics such as learning rate grafting and stale preconditioning to achieve\nperformance at-scale. These heuristics increase algorithmic complexity,\nnecessitate further hyperparameter tuning, and lack theoretical justification.\nThis paper investigates these heuristics from the angle of Frobenius norm\napproximation to full-matrix Adam and decouples the preconditioner's\neigenvalues and eigenbasis updates. We show that grafting from Adam mitigates\nthe staleness and mis-scaling of the preconditioner's eigenvalues and how\ncorrecting the eigenvalues directly can eliminate the need for learning rate\ngrafting. To manage the error induced by infrequent eigenbasis computations, we\npropose an adaptive criterion for determining the eigenbasis computation\nfrequency motivated by terminating a warm-started QR algorithm. This criterion\ndecouples the update frequency of different preconditioner matrices and enables\nus to investigate the impact of approximation error on convergence. These\npractical techniques offer a principled angle towards removing Shampoo's\nheuristics and developing improved Kronecker-factorization-based training\nalgorithms.", "AI": {"tldr": "The paper analyzes Shampoo's heuristics in neural network training, proposing improvements like eigenvalue correction and adaptive eigenbasis updates to reduce complexity and enhance performance.", "motivation": "Shampoo's reliance on heuristics like learning rate grafting and stale preconditioning increases complexity and lacks theoretical backing, prompting a need for principled alternatives.", "method": "The study decouples preconditioner eigenvalue and eigenbasis updates, corrects eigenvalues directly, and introduces an adaptive criterion for eigenbasis computation frequency.", "result": "Grafting from Adam mitigates preconditioner issues, and eigenvalue correction eliminates the need for grafting. Adaptive eigenbasis updates manage approximation errors.", "conclusion": "The proposed techniques offer a principled approach to improve Shampoo's heuristics, advancing Kronecker-factorization-based training algorithms."}}
{"id": "2506.03637", "pdf": "https://arxiv.org/pdf/2506.03637", "abs": "https://arxiv.org/abs/2506.03637", "authors": ["Zhuohao Yu", "Jiali Zeng", "Weizheng Gu", "Yidong Wang", "Jindong Wang", "Fandong Meng", "Jie Zhou", "Yue Zhang", "Shikun Zhang", "Wei Ye"], "title": "RewardAnything: Generalizable Principle-Following Reward Models", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "23 pages, 8 figures", "summary": "Reward Models, essential for guiding Large Language Model optimization, are\ntypically trained on fixed preference datasets, resulting in rigid alignment to\nsingle, implicit preference distributions. This prevents adaptation to diverse\nreal-world needs-from conciseness in one task to detailed explanations in\nanother. The standard practice of collecting task-specific preference data and\nretraining reward models is resource-intensive, often producing biased rewards,\nand limits practical application. We introduce generalizable,\nprinciple-following reward models. We propose that RMs should understand and\nadhere to dynamically provided natural language specifications of reward\nprinciples, similar to instruction-following in LLMs. To measure this\ncapability, we develop RABench, a comprehensive benchmark for RMs focusing on\ngeneralization across diverse principles. Evaluations on RABench reveal poor\ngeneralization of current RMs. As a solution, we present RewardAnything, a\nnovel RM designed and trained to explicitly follow natural language principles.\nWe achieve SotA performance with RewardAnything in traditional RM benchmark\nsimply by specifying a well-defined principle, and results on RABench show we\nexcel in adapting to novel principles without retraining. Furthermore,\nRewardAnything integrates seamlessly with existing RLHF methods and we show by\na case study on how to automatically and efficiently align LLMs with only\nnatural language principles.", "AI": {"tldr": "The paper introduces RewardAnything, a generalizable reward model that follows natural language principles, addressing the rigidity and bias of traditional reward models trained on fixed datasets.", "motivation": "Current reward models are inflexible and resource-intensive, limiting their adaptability to diverse real-world tasks. The goal is to create a model that can dynamically follow natural language specifications for broader application.", "method": "The authors propose RewardAnything, a reward model designed to adhere to natural language principles, and introduce RABench to evaluate generalization across diverse principles.", "result": "RewardAnything achieves state-of-the-art performance on traditional benchmarks and excels in adapting to new principles without retraining.", "conclusion": "RewardAnything offers a flexible, efficient solution for aligning large language models using natural language principles, demonstrating superior generalization and practical integration with existing methods."}}
{"id": "2506.03521", "pdf": "https://arxiv.org/pdf/2506.03521", "abs": "https://arxiv.org/abs/2506.03521", "authors": ["Weinan He", "Zilei Wang", "Yixin Zhang"], "title": "Target Semantics Clustering via Text Representations for Robust Universal Domain Adaptation", "categories": ["cs.CV"], "comment": "Camera-ready version for AAAI 2025", "summary": "Universal Domain Adaptation (UniDA) focuses on transferring source domain\nknowledge to the target domain under both domain shift and unknown category\nshift. Its main challenge lies in identifying common class samples and aligning\nthem. Current methods typically obtain target domain semantics centers from an\nunconstrained continuous image representation space. Due to domain shift and\nthe unknown number of clusters, these centers often result in complex and less\nrobust alignment algorithm. In this paper, based on vision-language models, we\nsearch for semantic centers in a semantically meaningful and discrete text\nrepresentation space. The constrained space ensures almost no domain bias and\nappropriate semantic granularity for these centers, enabling a simple and\nrobust adaptation algorithm. Specifically, we propose TArget Semantics\nClustering (TASC) via Text Representations, which leverages information\nmaximization as a unified objective and involves two stages. First, with the\nfrozen encoders, a greedy search-based framework is used to search for an\noptimal set of text embeddings to represent target semantics. Second, with the\nsearch results fixed, encoders are refined based on gradient descent,\nsimultaneously achieving robust domain alignment and private class clustering.\nAdditionally, we propose Universal Maximum Similarity (UniMS), a scoring\nfunction tailored for detecting open-set samples in UniDA. Experimentally, we\nevaluate the universality of UniDA algorithms under four category shift\nscenarios. Extensive experiments on four benchmarks demonstrate the\neffectiveness and robustness of our method, which has achieved state-of-the-art\nperformance.", "AI": {"tldr": "The paper proposes TASC and UniMS for UniDA, leveraging vision-language models to improve semantic center alignment and open-set detection, achieving state-of-the-art results.", "motivation": "Addressing domain and category shift challenges in UniDA by improving semantic center alignment and robustness.", "method": "Uses TASC for semantic center search in text space and UniMS for open-set detection, combining greedy search and gradient descent.", "result": "Achieves state-of-the-art performance across four benchmarks under various category shifts.", "conclusion": "The method is effective and robust for UniDA, with potential for broader applications."}}
{"id": "2506.03602", "pdf": "https://arxiv.org/pdf/2506.03602", "abs": "https://arxiv.org/abs/2506.03602", "authors": ["Hiroki Shiraishi", "Yohei Hayamizu", "Tomonori Hashiyama", "Keiki Takadama", "Hisao Ishibuchi", "Masaya Nakata"], "title": "Adapting Rule Representation With Four-Parameter Beta Distribution for Learning Classifier Systems", "categories": ["cs.LG", "cs.AI", "cs.NE"], "comment": null, "summary": "Rule representations significantly influence the search capabilities and\ndecision boundaries within the search space of Learning Classifier Systems\n(LCSs), a family of rule-based machine learning systems that evolve\ninterpretable models through evolutionary processes. However, it is very\ndifficult to choose an appropriate rule representation for each problem.\nAdditionally, some problems benefit from using different representations for\ndifferent subspaces within the input space. Thus, an adaptive mechanism is\nneeded to choose an appropriate rule representation for each rule in LCSs. This\narticle introduces a flexible rule representation using a four-parameter beta\ndistribution and integrates it into a fuzzy-style LCS. The four-parameter beta\ndistribution can form various function shapes, and this flexibility enables our\nLCS to automatically select appropriate representations for different\nsubspaces. Our rule representation can represent crisp/fuzzy decision\nboundaries in various boundary shapes, such as rectangles and bells, by\ncontrolling four parameters, compared to the standard representations such as\ntrapezoidal ones. Leveraging this flexibility, our LCS is designed to adapt the\nappropriate rule representation for each subspace. Moreover, our LCS\nincorporates a generalization bias favoring crisp rules where feasible,\nenhancing model interpretability without compromising accuracy. Experimental\nresults on real-world classification tasks show that our LCS achieves\nsignificantly superior test accuracy and produces more compact rule sets. Our\nimplementation is available at https://github.com/YNU-NakataLab/Beta4-UCS. An\nextended abstract related to this work is available at\nhttps://doi.org/10.36227/techrxiv.174900805.59801248/v1.", "AI": {"tldr": "The paper introduces a flexible rule representation using a four-parameter beta distribution in Learning Classifier Systems (LCSs) to adaptively choose rule representations for different subspaces, improving accuracy and interpretability.", "motivation": "Choosing appropriate rule representations in LCSs is challenging, and some problems benefit from varied representations for different subspaces. An adaptive mechanism is needed.", "method": "The proposed method integrates a four-parameter beta distribution into a fuzzy-style LCS, enabling automatic selection of rule representations for different subspaces.", "result": "Experimental results show superior test accuracy and more compact rule sets compared to standard representations.", "conclusion": "The flexible rule representation enhances LCS adaptability and interpretability without sacrificing accuracy, validated by real-world classification tasks."}}
{"id": "2506.03618", "pdf": "https://arxiv.org/pdf/2506.03618", "abs": "https://arxiv.org/abs/2506.03618", "authors": ["Jiayi Wan", "Xiang Zhu", "Fanzhen Liu", "Wei Fan", "Xiaolong Xu"], "title": "GCFL: A Gradient Correction-based Federated Learning Framework for Privacy-preserving CPSS", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Federated learning, as a distributed architecture, shows great promise for\napplications in Cyber-Physical-Social Systems (CPSS). In order to mitigate the\nprivacy risks inherent in CPSS, the integration of differential privacy with\nfederated learning has attracted considerable attention. Existing research\nmainly focuses on dynamically adjusting the noise added or discarding certain\ngradients to mitigate the noise introduced by differential privacy. However,\nthese approaches fail to remove the noise that hinders convergence and correct\nthe gradients affected by the noise, which significantly reduces the accuracy\nof model classification. To overcome these challenges, this paper proposes a\nnovel framework for differentially private federated learning that balances\nrigorous privacy guarantees with accuracy by introducing a server-side gradient\ncorrection mechanism. Specifically, after clients perform gradient clipping and\nnoise perturbation, our framework detects deviations in the noisy local\ngradients and employs a projection mechanism to correct them, mitigating the\nnegative impact of noise. Simultaneously, gradient projection promotes the\nalignment of gradients from different clients and guides the model towards\nconvergence to a global optimum. We evaluate our framework on several benchmark\ndatasets, and the experimental results demonstrate that it achieves\nstate-of-the-art performance under the same privacy budget.", "AI": {"tldr": "Proposes a server-side gradient correction framework for differentially private federated learning to balance privacy and accuracy.", "motivation": "Mitigate privacy risks in CPSS while addressing noise-induced accuracy reduction in existing methods.", "method": "Introduces a gradient correction mechanism to detect and correct noisy gradients, promoting alignment and convergence.", "result": "Achieves state-of-the-art performance under the same privacy budget on benchmark datasets.", "conclusion": "The framework effectively balances privacy and accuracy in federated learning for CPSS."}}
{"id": "2506.03659", "pdf": "https://arxiv.org/pdf/2506.03659", "abs": "https://arxiv.org/abs/2506.03659", "authors": ["Yinuo Wang", "Robert E. Mercer", "Frank Rudzicz", "Sudipta Singha Roy", "Pengjie Ren", "Zhumin Chen", "Xindi Wang"], "title": "Trustworthy Medical Question Answering: An Evaluation-Centric Survey", "categories": ["cs.CL"], "comment": null, "summary": "Trustworthiness in healthcare question-answering (QA) systems is important\nfor ensuring patient safety, clinical effectiveness, and user confidence. As\nlarge language models (LLMs) become increasingly integrated into medical\nsettings, the reliability of their responses directly influences clinical\ndecision-making and patient outcomes. However, achieving comprehensive\ntrustworthiness in medical QA poses significant challenges due to the inherent\ncomplexity of healthcare data, the critical nature of clinical scenarios, and\nthe multifaceted dimensions of trustworthy AI. In this survey, we\nsystematically examine six key dimensions of trustworthiness in medical QA,\ni.e., Factuality, Robustness, Fairness, Safety, Explainability, and\nCalibration. We review how each dimension is evaluated in existing LLM-based\nmedical QA systems. We compile and compare major benchmarks designed to assess\nthese dimensions and analyze evaluation-guided techniques that drive model\nimprovements, such as retrieval-augmented grounding, adversarial fine-tuning,\nand safety alignment. Finally, we identify open challenges-such as scalable\nexpert evaluation, integrated multi-dimensional metrics, and real-world\ndeployment studies-and propose future research directions to advance the safe,\nreliable, and transparent deployment of LLM-powered medical QA.", "AI": {"tldr": "This survey explores trustworthiness in medical QA systems, focusing on six key dimensions (Factuality, Robustness, Fairness, Safety, Explainability, Calibration) and their evaluation in LLM-based systems. It reviews benchmarks, improvement techniques, and identifies open challenges for future research.", "motivation": "Ensuring trustworthiness in medical QA systems is critical for patient safety and clinical effectiveness, especially as LLMs are increasingly used in healthcare.", "method": "The survey systematically examines six trustworthiness dimensions in medical QA, reviews evaluation benchmarks, and analyzes techniques like retrieval-augmented grounding and adversarial fine-tuning.", "result": "The study compiles benchmarks and techniques for improving trustworthiness but highlights challenges like scalable expert evaluation and real-world deployment.", "conclusion": "Future research should address open challenges to advance the safe and reliable deployment of LLM-powered medical QA systems."}}
{"id": "2506.03538", "pdf": "https://arxiv.org/pdf/2506.03538", "abs": "https://arxiv.org/abs/2506.03538", "authors": ["Chengqi Li", "Zhihao Shi", "Yangdi Lu", "Wenbo He", "Xiangyu Xu"], "title": "Robust Neural Rendering in the Wild with Asymmetric Dual 3D Gaussian Splatting", "categories": ["cs.CV"], "comment": null, "summary": "3D reconstruction from in-the-wild images remains a challenging task due to\ninconsistent lighting conditions and transient distractors. Existing methods\ntypically rely on heuristic strategies to handle the low-quality training data,\nwhich often struggle to produce stable and consistent reconstructions,\nfrequently resulting in visual artifacts. In this work, we propose Asymmetric\nDual 3DGS, a novel framework that leverages the stochastic nature of these\nartifacts: they tend to vary across different training runs due to minor\nrandomness. Specifically, our method trains two 3D Gaussian Splatting (3DGS)\nmodels in parallel, enforcing a consistency constraint that encourages\nconvergence on reliable scene geometry while suppressing inconsistent\nartifacts. To prevent the two models from collapsing into similar failure modes\ndue to confirmation bias, we introduce a divergent masking strategy that\napplies two complementary masks: a multi-cue adaptive mask and a\nself-supervised soft mask, which leads to an asymmetric training process of the\ntwo models, reducing shared error modes. In addition, to improve the efficiency\nof model training, we introduce a lightweight variant called Dynamic EMA Proxy,\nwhich replaces one of the two models with a dynamically updated Exponential\nMoving Average (EMA) proxy, and employs an alternating masking strategy to\npreserve divergence. Extensive experiments on challenging real-world datasets\ndemonstrate that our method consistently outperforms existing approaches while\nachieving high efficiency. Codes and trained models will be released.", "AI": {"tldr": "Proposes Asymmetric Dual 3DGS, a framework for stable 3D reconstruction from in-the-wild images by leveraging stochastic artifacts and enforcing consistency constraints.", "motivation": "Addresses challenges in 3D reconstruction from inconsistent lighting and transient distractors, aiming to reduce visual artifacts and improve stability.", "method": "Trains two 3D Gaussian Splatting models with consistency constraints and divergent masking to suppress artifacts. Introduces Dynamic EMA Proxy for efficiency.", "result": "Outperforms existing methods on real-world datasets, achieving stable and consistent reconstructions with high efficiency.", "conclusion": "The framework effectively mitigates artifacts and improves reconstruction quality, with plans to release codes and models."}}
{"id": "2506.03614", "pdf": "https://arxiv.org/pdf/2506.03614", "abs": "https://arxiv.org/abs/2506.03614", "authors": ["Zhanhui Zhou", "Lingjie Chen", "Chao Yang", "Chaochao Lu"], "title": "VLMs Can Aggregate Scattered Training Patches", "categories": ["cs.CV", "cs.AI", "cs.CL"], "comment": null, "summary": "One way to mitigate risks in vision-language models (VLMs) is to remove\ndangerous samples in their training data. However, such data moderation can be\neasily bypassed when harmful images are split into small, benign-looking\npatches, scattered across many training samples. VLMs may then learn to piece\nthese fragments together during training and generate harmful responses at\ninference, either from full images or text references. For instance, if trained\non image patches from a bloody scene paired with the descriptions \"safe,\" VLMs\nmay later describe, the full image or a text reference to the scene, as \"safe.\"\nWe define the core ability of VLMs enabling this attack as $\\textit{visual\nstitching}$ -- the ability to integrate visual information spread across\nmultiple training samples that share the same textual descriptions. In our\nwork, we first demonstrate visual stitching abilities in common open-source\nVLMs on three datasets where each image is labeled with a unique synthetic ID:\nwe split each $(\\texttt{image}, \\texttt{ID})$ pair into $\\{(\\texttt{patch},\n\\texttt{ID})\\}$ pairs at different granularity for finetuning, and we find that\ntuned models can verbalize the correct IDs from full images or text reference.\nBuilding on this, we simulate the adversarial data poisoning scenario mentioned\nabove by using patches from dangerous images and replacing IDs with text\ndescriptions like ``safe'' or ``unsafe'', demonstrating how harmful content can\nevade moderation in patches and later be reconstructed through visual\nstitching, posing serious VLM safety risks. Code is available at\nhttps://github.com/ZHZisZZ/visual-stitching.", "AI": {"tldr": "VLMs can reconstruct harmful content from benign-looking patches due to visual stitching, bypassing data moderation and posing safety risks.", "motivation": "To highlight the vulnerability of VLMs to adversarial data poisoning where harmful content is split into benign patches, evading moderation and later being reconstructed.", "method": "Demonstrated visual stitching in VLMs by splitting images into patches with unique IDs, then simulating adversarial poisoning with harmful patches labeled as \"safe\" or \"unsafe\".", "result": "VLMs can correctly verbalize IDs or harmful descriptions from patched data, showing the risk of visual stitching.", "conclusion": "Visual stitching in VLMs enables harmful content reconstruction, revealing a critical safety loophole in data moderation."}}
{"id": "2506.03674", "pdf": "https://arxiv.org/pdf/2506.03674", "abs": "https://arxiv.org/abs/2506.03674", "authors": ["Yidi Wang", "Jiawei Gu", "pei Xiaobing", "Xubin Zheng", "Xiao Luo", "Pengyang Wang", "Ziyue Qiao"], "title": "Out-of-Distribution Graph Models Merging", "categories": ["cs.LG"], "comment": null, "summary": "This paper studies a novel problem of out-of-distribution graph models\nmerging, which aims to construct a generalized model from multiple graph models\npre-trained on different domains with distribution discrepancy. This problem is\nchallenging because of the difficulty in learning domain-invariant knowledge\nimplicitly in model parameters and consolidating expertise from potentially\nheterogeneous GNN backbones. In this work, we propose a graph generation\nstrategy that instantiates the mixture distribution of multiple domains. Then,\nwe merge and fine-tune the pre-trained graph models via a MoE module and a\nmasking mechanism for generalized adaptation. Our framework is\narchitecture-agnostic and can operate without any source/target domain data.\nBoth theoretical analysis and experimental results demonstrate the\neffectiveness of our approach in addressing the model generalization problem.", "AI": {"tldr": "The paper addresses merging out-of-distribution graph models into a generalized model, using a graph generation strategy and MoE module for adaptation.", "motivation": "The challenge lies in learning domain-invariant knowledge from heterogeneous GNN models pre-trained on different domains.", "method": "Proposes a graph generation strategy for domain mixture distribution and merges models via MoE and masking mechanisms.", "result": "The framework is architecture-agnostic, requires no source/target data, and shows effectiveness in model generalization.", "conclusion": "The approach successfully generalizes models across domains without needing domain-specific data."}}
{"id": "2506.03665", "pdf": "https://arxiv.org/pdf/2506.03665", "abs": "https://arxiv.org/abs/2506.03665", "authors": ["Hern\u00e1n Maina", "Guido Ivetta", "Mateo Lione Stuto", "Julian Martin Eisenschlos", "Jorge S\u00e1nchez", "Luciana Benotti"], "title": "ROSA: Addressing text understanding challenges in photographs via ROtated SAmpling", "categories": ["cs.CL", "cs.CV"], "comment": null, "summary": "Visually impaired people could benefit from Visual Question Answering (VQA)\nsystems to interpret text in their surroundings. However, current models often\nstruggle with recognizing text in the photos taken by this population. Through\nin-depth interviews with visually impaired individuals, we identified common\nframing conventions that frequently result in misaligned text. Existing VQA\nbenchmarks primarily feature well-oriented text captured by sighted users,\nunder-representing these challenges. To address this gap, we introduce ROtated\nSAmpling (ROSA), a decoding strategy that enhances VQA performance in text-rich\nimages with incorrectly oriented text. ROSA outperforms Greedy decoding by 11.7\nabsolute points in the best-performing model.", "AI": {"tldr": "ROSA, a decoding strategy, improves VQA performance for misaligned text in images, addressing challenges faced by visually impaired users.", "motivation": "Current VQA systems struggle with text recognition in photos taken by visually impaired individuals due to common framing issues.", "method": "Introduced ROtated SAmpling (ROSA), a decoding strategy to handle incorrectly oriented text in images.", "result": "ROSA outperforms Greedy decoding by 11.7 absolute points in the best-performing model.", "conclusion": "ROSA effectively addresses the gap in VQA benchmarks for text-rich images with misaligned text."}}
{"id": "2506.03555", "pdf": "https://arxiv.org/pdf/2506.03555", "abs": "https://arxiv.org/abs/2506.03555", "authors": ["Tianpei Zhang", "Jufeng Zhao", "Yiming Zhu", "Guangmang Cui"], "title": "WIFE-Fusion:Wavelet-aware Intra-inter Frequency Enhancement for Multi-model Image Fusion", "categories": ["cs.CV"], "comment": null, "summary": "Multimodal image fusion effectively aggregates information from diverse\nmodalities, with fused images playing a crucial role in vision systems.\nHowever, existing methods often neglect frequency-domain feature exploration\nand interactive relationships. In this paper, we propose wavelet-aware\nIntra-inter Frequency Enhancement Fusion (WIFE-Fusion), a multimodal image\nfusion framework based on frequency-domain components interactions. Its core\ninnovations include: Intra-Frequency Self-Attention (IFSA) that leverages\ninherent cross-modal correlations and complementarity through interactive\nself-attention mechanisms to extract enriched frequency-domain features, and\nInter-Frequency Interaction (IFI) that enhances enriched features and filters\nlatent features via combinatorial interactions between heterogeneous\nfrequency-domain components across modalities. These processes achieve precise\nsource feature extraction and unified modeling of feature\nextraction-aggregation. Extensive experiments on five datasets across three\nmultimodal fusion tasks demonstrate WIFE-Fusion's superiority over current\nspecialized and unified fusion methods. Our code is available at\nhttps://github.com/Lmmh058/WIFE-Fusion.", "AI": {"tldr": "WIFE-Fusion is a multimodal image fusion framework that enhances frequency-domain feature exploration and interactions, outperforming existing methods.", "motivation": "Existing methods lack frequency-domain feature exploration and interactive relationships, limiting fusion quality.", "method": "Proposes Intra-Frequency Self-Attention (IFSA) and Inter-Frequency Interaction (IFI) for enriched feature extraction and aggregation.", "result": "Superior performance on five datasets across three multimodal fusion tasks.", "conclusion": "WIFE-Fusion effectively addresses limitations of current methods, offering precise feature extraction and unified modeling."}}
{"id": "2506.03621", "pdf": "https://arxiv.org/pdf/2506.03621", "abs": "https://arxiv.org/abs/2506.03621", "authors": ["Chaehun Shin", "Jooyoung Choi", "Johan Barthelemy", "Jungbeom Lee", "Sungroh Yoon"], "title": "Negative-Guided Subject Fidelity Optimization for Zero-Shot Subject-Driven Generation", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "We present Subject Fidelity Optimization (SFO), a novel comparative learning\nframework for zero-shot subject-driven generation that enhances subject\nfidelity. Beyond supervised fine-tuning methods that rely only on positive\ntargets and use the diffusion loss as in the pre-training stage, SFO introduces\nsynthetic negative targets and explicitly guides the model to favor positives\nover negatives through pairwise comparison. For negative targets, we propose\nCondition-Degradation Negative Sampling (CDNS), which automatically generates\ndistinctive and informative negatives by intentionally degrading visual and\ntextual cues without expensive human annotations. Moreover, we reweight the\ndiffusion timesteps to focus finetuning on intermediate steps where subject\ndetails emerge. Extensive experiments demonstrate that SFO with CDNS\nsignificantly outperforms baselines in terms of both subject fidelity and text\nalignment on a subject-driven generation benchmark. Project page:\nhttps://subjectfidelityoptimization.github.io/", "AI": {"tldr": "SFO introduces a comparative learning framework for zero-shot subject-driven generation, using synthetic negatives and timestep reweighting to enhance subject fidelity.", "motivation": "Improving subject fidelity in zero-shot subject-driven generation by addressing limitations of supervised fine-tuning methods.", "method": "Uses synthetic negative targets via Condition-Degradation Negative Sampling (CDNS) and pairwise comparison, with reweighted diffusion timesteps.", "result": "Outperforms baselines in subject fidelity and text alignment on a benchmark.", "conclusion": "SFO with CDNS is effective for enhancing subject-driven generation."}}
{"id": "2506.03696", "pdf": "https://arxiv.org/pdf/2506.03696", "abs": "https://arxiv.org/abs/2506.03696", "authors": ["Fang Wang", "Paolo Ceravolo", "Ernesto Damiani"], "title": "Comprehensive Attribute Encoding and Dynamic LSTM HyperModels for Outcome Oriented Predictive Business Process Monitoring", "categories": ["cs.LG"], "comment": null, "summary": "Predictive Business Process Monitoring (PBPM) aims to forecast future\noutcomes of ongoing business processes. However, existing methods often lack\nflexibility to handle real-world challenges such as simultaneous events, class\nimbalance, and multi-level attributes. While prior work has explored static\nencoding schemes and fixed LSTM architectures, they struggle to support\nadaptive representations and generalize across heterogeneous datasets. To\naddress these limitations, we propose a suite of dynamic LSTM HyperModels that\nintegrate two-level hierarchical encoding for event and sequence attributes,\ncharacter-based decomposition of event labels, and novel pseudo-embedding\ntechniques for durations and attribute correlations. We further introduce\nspecialized LSTM variants for simultaneous event modeling, leveraging\nmultidimensional embeddings and time-difference flag augmentation. Experimental\nvalidation on four public and real-world datasets demonstrates up to 100%\naccuracy on balanced datasets and F1 scores exceeding 86\\% on imbalanced ones.\nOur approach advances PBPM by offering modular and interpretable models better\nsuited for deployment in complex settings. Beyond PBPM, it contributes to the\nbroader AI community by improving temporal outcome prediction, supporting data\nheterogeneity, and promoting explainable process intelligence frameworks.", "AI": {"tldr": "The paper proposes dynamic LSTM HyperModels for Predictive Business Process Monitoring (PBPM) to address limitations like simultaneous events, class imbalance, and multi-level attributes, achieving high accuracy and F1 scores.", "motivation": "Existing PBPM methods lack flexibility for real-world challenges like simultaneous events and data heterogeneity.", "method": "Dynamic LSTM HyperModels with hierarchical encoding, character-based decomposition, and pseudo-embedding techniques, plus specialized LSTM variants for simultaneous events.", "result": "Achieves up to 100% accuracy on balanced datasets and F1 scores over 86% on imbalanced ones.", "conclusion": "The approach advances PBPM with modular, interpretable models and contributes to AI by improving temporal prediction and explainability."}}
{"id": "2506.03690", "pdf": "https://arxiv.org/pdf/2506.03690", "abs": "https://arxiv.org/abs/2506.03690", "authors": ["Jie Sun", "Junkang Wu", "Jiancan Wu", "Zhibo Zhu", "Xingyu Lu", "Jun Zhou", "Lintao Ma", "Xiang Wang"], "title": "Robust Preference Optimization via Dynamic Target Margins", "categories": ["cs.CL"], "comment": "18 pages, 6 figures, accepted to The 63rd Annual Meeting of the\n  Association for Computational Linguistics (ACL2025)", "summary": "The alignment of Large Language Models (LLMs) is crucial for ensuring their\nsafety and reliability in practical applications. Direct Preference\nOptimization (DPO) has emerged as an efficient method that directly optimizes\nmodels using preference pairs, significantly reducing resource demands.\nHowever, the effectiveness of DPO heavily depends on the data quality, which is\nfrequently compromised by noise. In this work, we propose $\\gamma$-PO, a\ndynamic target margin preference optimization algorithm that adjust reward\nmargins at the pairwise level. By introducing instance-specific margin\ncalibration, $\\gamma$-PO strategically prioritizes high-confidence pairs (those\ndemonstrating higher reward margins) while suppressing potential noise from\nambiguous pairs. Moreover, $\\gamma$-PO is a plug-and-play method, compatible\nwith variants of DPO that rely on reward margin between preference pairs.\nAcross benchmarks such as AlpacaEval2 and Arena-Hard, $\\gamma$-PO achieves an\naverage 4.4\\% improvement over other baselines, setting new benchmarks for\nstate-of-the-art performance. Additionally, $\\gamma$-PO requires minimal code\nchanges and has a negligible impact on training efficiency, making it a robust\nsolution for enhancing LLMs alignment. Our codes are available at\n\\href{https://github.com/sunjie279/gammaPO}{https://github.com/sunjie279/gammaPO}.", "AI": {"tldr": "The paper introduces \u03b3-PO, a dynamic target margin preference optimization algorithm for aligning LLMs, improving performance by 4.4% over baselines while being resource-efficient.", "motivation": "Alignment of LLMs is critical for safety and reliability, but existing methods like DPO are sensitive to noisy data. \u03b3-PO addresses this by dynamically adjusting reward margins.", "method": "\u03b3-PO introduces instance-specific margin calibration to prioritize high-confidence pairs and suppress noise, remaining compatible with DPO variants.", "result": "\u03b3-PO achieves a 4.4% average improvement on benchmarks like AlpacaEval2 and Arena-Hard, with minimal impact on training efficiency.", "conclusion": "\u03b3-PO is a robust, plug-and-play solution for enhancing LLM alignment, offering better performance and noise resilience."}}
{"id": "2506.03583", "pdf": "https://arxiv.org/pdf/2506.03583", "abs": "https://arxiv.org/abs/2506.03583", "authors": ["Zhigang Yang", "Huiguang Yao", "Linmao Tian", "Xuezhi Zhao", "Qiang Li", "Qi Wang"], "title": "A Large-Scale Referring Remote Sensing Image Segmentation Dataset and Benchmark", "categories": ["cs.CV"], "comment": null, "summary": "Referring Remote Sensing Image Segmentation is a complex and challenging task\nthat integrates the paradigms of computer vision and natural language\nprocessing. Existing datasets for RRSIS suffer from critical limitations in\nresolution, scene diversity, and category coverage, which hinders the\ngeneralization and real-world applicability of refer segmentation models. To\nfacilitate the development of this field, we introduce NWPU-Refer, the largest\nand most diverse RRSIS dataset to date, comprising 15,003 high-resolution\nimages (1024-2048px) spanning 30+ countries with 49,745 annotated targets\nsupporting single-object, multi-object, and non-object segmentation scenarios.\nAdditionally, we propose the Multi-scale Referring Segmentation Network\n(MRSNet), a novel framework tailored for the unique demands of RRSIS. MRSNet\nintroduces two key innovations: (1) an Intra-scale Feature Interaction Module\n(IFIM) that captures fine-grained details within each encoder stage, and (2) a\nHierarchical Feature Interaction Module (HFIM) to enable seamless cross-scale\nfeature fusion, preserving spatial integrity while enhancing discriminative\npower. Extensive experiments conducte on the proposed NWPU-Refer dataset\ndemonstrate that MRSNet achieves state-of-the-art performance across multiple\nevaluation metrics, validating its effectiveness. The dataset and code are\npublicly available at https://github.com/CVer-Yang/NWPU-Refer.", "AI": {"tldr": "The paper introduces NWPU-Refer, the largest RRSIS dataset, and MRSNet, a novel framework for referring remote sensing image segmentation, achieving state-of-the-art results.", "motivation": "Existing RRSIS datasets lack resolution, diversity, and category coverage, limiting model generalization and real-world applicability.", "method": "Proposes MRSNet with Intra-scale Feature Interaction Module (IFIM) and Hierarchical Feature Interaction Module (HFIM) for fine-grained and cross-scale feature fusion.", "result": "MRSNet achieves state-of-the-art performance on the NWPU-Refer dataset.", "conclusion": "The dataset and MRSNet framework advance RRSIS research, with publicly available resources."}}
{"id": "2506.03642", "pdf": "https://arxiv.org/pdf/2506.03642", "abs": "https://arxiv.org/abs/2506.03642", "authors": ["Haoyu Zhang", "Meng Liu", "Zaijing Li", "Haokun Wen", "Weili Guan", "Yaowei Wang", "Liqiang Nie"], "title": "Spatial Understanding from Videos: Structured Prompts Meet Simulation Data", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Visual-spatial understanding, the ability to infer object relationships and\nlayouts from visual input, is fundamental to downstream tasks such as robotic\nnavigation and embodied interaction. However, existing methods face spatial\nuncertainty and data scarcity, limiting the 3D spatial reasoning capability of\npre-trained vision-language models (VLMs). To address these challenges, we\npresent a unified framework for enhancing 3D spatial reasoning in pre-trained\nVLMs without modifying their architecture. This framework combines SpatialMind,\na structured prompting strategy that decomposes complex scenes and questions\ninto interpretable reasoning steps, with ScanForgeQA, a scalable\nquestion-answering dataset built from diverse 3D simulation scenes through an\nautomated construction process designed for fine-tuning. Extensive experiments\nacross multiple benchmarks demonstrate the individual and combined\neffectiveness of our prompting and fine-tuning strategies, and yield insights\nthat may inspire future research on visual-spatial understanding.", "AI": {"tldr": "A framework combining SpatialMind (structured prompting) and ScanForgeQA (scalable QA dataset) enhances 3D spatial reasoning in pre-trained VLMs without architecture changes.", "motivation": "Address spatial uncertainty and data scarcity in 3D spatial reasoning for VLMs.", "method": "Uses SpatialMind for structured prompting and ScanForgeQA for fine-tuning via automated dataset construction.", "result": "Improves 3D spatial reasoning in VLMs across benchmarks, validating the framework's effectiveness.", "conclusion": "The framework advances visual-spatial understanding and offers insights for future research."}}
{"id": "2506.03703", "pdf": "https://arxiv.org/pdf/2506.03703", "abs": "https://arxiv.org/abs/2506.03703", "authors": ["Xiansheng Cai", "Sihan Hu", "Tao Wang", "Yuan Huang", "Pan Zhang", "Youjin Deng", "Kun Chen"], "title": "Learning-at-Criticality in Large Language Models for Quantum Field Theory and Beyond", "categories": ["cs.LG", "cond-mat.dis-nn", "cond-mat.stat-mech", "cond-mat.str-el", "physics.comp-ph"], "comment": null, "summary": "Fundamental physics often confronts complex symbolic problems with few\nguiding exemplars or established principles. While artificial intelligence (AI)\noffers promise, its typical need for vast datasets to learn from hinders its\nuse in these information-scarce frontiers. We introduce learning at criticality\n(LaC), a reinforcement learning (RL) scheme that tunes Large Language Models\n(LLMs) to a sharp learning transition, addressing this information scarcity. At\nthis transition, LLMs achieve peak generalization from minimal data,\nexemplified by 7-digit base-7 addition -- a test of nontrivial arithmetic\nreasoning. To elucidate this peak, we analyze a minimal concept-network model\n(CoNet) designed to capture the essence of how LLMs might link tokens. Trained\non a single exemplar, this model also undergoes a sharp learning transition.\nThis transition exhibits hallmarks of a second-order phase transition, notably\npower-law distributed solution path lengths. At this critical point, the system\nmaximizes a ``critical thinking pattern\" crucial for generalization, enabled by\nthe underlying scale-free exploration. This suggests LLMs reach peak\nperformance by operating at criticality, where such explorative dynamics enable\nthe extraction of underlying operational rules. We demonstrate LaC in quantum\nfield theory: an 8B-parameter LLM, tuned to its critical point by LaC using a\nfew exemplars of symbolic Matsubara sums, solves unseen, higher-order problems,\nsignificantly outperforming far larger models. LaC thus leverages critical\nphenomena, a physical principle, to empower AI for complex, data-sparse\nchallenges in fundamental physics.", "AI": {"tldr": "LaC (Learning at Criticality) is a reinforcement learning method that optimizes LLMs for peak generalization with minimal data, demonstrated in tasks like base-7 addition and quantum field theory.", "motivation": "Address the challenge of AI's reliance on large datasets in information-scarce domains like fundamental physics.", "method": "LaC tunes LLMs to a sharp learning transition (criticality), where they generalize best from minimal data, supported by a concept-network model (CoNet).", "result": "LLMs at criticality solve complex tasks (e.g., 7-digit base-7 addition, symbolic Matsubara sums) with few exemplars, outperforming larger models.", "conclusion": "LaC leverages critical phenomena to enhance AI performance in data-sparse, complex problems in physics."}}
{"id": "2506.03700", "pdf": "https://arxiv.org/pdf/2506.03700", "abs": "https://arxiv.org/abs/2506.03700", "authors": ["Zhepei Wei", "Wei-Lin Chen", "Xinyu Zhu", "Yu Meng"], "title": "AdaDecode: Accelerating LLM Decoding with Adaptive Layer Parallelism", "categories": ["cs.CL"], "comment": "ICML 2025. Code: https://github.com/weizhepei/AdaDecode", "summary": "Large language models (LLMs) are increasingly used for long-content\ngeneration (e.g., long Chain-of-Thought reasoning) where decoding efficiency\nbecomes a critical bottleneck: Autoregressive decoding is inherently limited by\nits sequential token generation process, where each token must be generated\nbefore the next can be processed. This sequential dependency restricts the\nability to fully leverage modern hardware's parallel processing capabilities.\nExisting methods like speculative decoding and layer skipping offer potential\nspeedups but have notable drawbacks: speculative decoding relies on an\nauxiliary \"drafter\" model, which can be challenging to acquire and increases\nmemory overhead, while layer skipping may introduce discrepancies in the\noutputs due to the missing key-value cache at skipped layers. In this work, we\npropose AdaDecode, which accelerates LLM decoding without requiring auxiliary\nmodels or changes to the original model parameters, while ensuring output\nconsistency. AdaDecode leverages the insight that many tokens can accurately be\ngenerated at intermediate layers, as further layers often do not significantly\nalter predictions once the model reaches a certain confidence. By adaptively\ngenerating tokens at intermediate layers when confidence is high, AdaDecode\nenables the next token's computation to begin immediately. The remaining layer\ncomputations for early-predicted tokens are deferred and executed in parallel\nwith subsequent tokens when needed, maximizing hardware utilization and\nreducing decoding latency. A final verification step ensures that early\npredictions match the results of standard autoregressive decoding, preserving\noutput parity. Experiments across diverse generation tasks shows that AdaDecode\nconsistently achieves superior decoding throughput with up to 1.73x speedup,\nwhile guaranteeing output parity with standard autoregressive decoding.", "AI": {"tldr": "AdaDecode accelerates LLM decoding by generating tokens at intermediate layers when confidence is high, achieving up to 1.73x speedup without auxiliary models or output discrepancies.", "motivation": "Autoregressive decoding in LLMs is inefficient due to sequential token generation, limiting hardware parallelism. Existing methods like speculative decoding and layer skipping have drawbacks.", "method": "AdaDecode adaptively generates tokens at intermediate layers when confidence is high, defers remaining computations, and verifies outputs for consistency.", "result": "AdaDecode achieves up to 1.73x speedup in decoding throughput while maintaining output parity with standard autoregressive decoding.", "conclusion": "AdaDecode offers an efficient, hardware-friendly solution for LLM decoding without compromising output quality."}}
{"id": "2506.03591", "pdf": "https://arxiv.org/pdf/2506.03591", "abs": "https://arxiv.org/abs/2506.03591", "authors": ["Jiaxing Zhang", "Xinyi Zeng", "Hao Tang"], "title": "Resolving Task Objective Conflicts in Unified Multimodal Understanding and Generation via Task-Aware Mixture-of-Experts", "categories": ["cs.CV"], "comment": null, "summary": "Unified multimodal large language models (MLLMs) based on end-to-end\nautoregressive (AR) transformers effectively integrate both understanding and\ngeneration tasks within a single framework. However, intrinsic Task Objective\nConflicts between high-level semantic abstraction in understanding and\nfine-grained detail preservation in generation pose significant challenges,\noften leading to suboptimal trade-offs and task interference. Existing\nsolutions, such as decoupling shared visual encoders, fall short of\nfundamentally resolving these conflicts due to inherent AR architecture. In\nthis paper, we propose a novel approach that decouples internal components of\nAR to resolve task objective conflicts. Specifically, we design UTAMoE, a\nUnified Task-Aware Mixture-of-Experts (MoE) framework that decouples internal\nAR modules via a Task-Aware MoE Layer to create task-specific optimization\nsubpaths. To enhance task differentiation while maintaining overall\ncoordination, we introduce a novel Two-Stage Training Strategy. Extensive\nexperiments on multimodal benchmarks demonstrate that UTAMoE mitigates task\nobjective conflicts, achieving state-of-the-art performance across various\ntasks. Visualizations and ablation studies further validate the effectiveness\nof our approach.", "AI": {"tldr": "UTAMoE, a Unified Task-Aware Mixture-of-Experts framework, decouples autoregressive transformer modules to resolve task objective conflicts in multimodal LLMs, achieving state-of-the-art performance.", "motivation": "Addressing intrinsic Task Objective Conflicts in multimodal LLMs between understanding (high-level semantics) and generation (fine-grained details), which existing solutions fail to resolve due to autoregressive architecture limitations.", "method": "Proposes UTAMoE, a framework using a Task-Aware MoE Layer to decouple internal autoregressive modules, creating task-specific optimization paths, and a Two-Stage Training Strategy for task differentiation and coordination.", "result": "UTAMoE mitigates task conflicts and achieves state-of-the-art performance on multimodal benchmarks, validated by visualizations and ablation studies.", "conclusion": "The UTAMoE framework effectively resolves task objective conflicts in multimodal LLMs, enhancing performance and coordination across tasks."}}
{"id": "2506.03654", "pdf": "https://arxiv.org/pdf/2506.03654", "abs": "https://arxiv.org/abs/2506.03654", "authors": ["Xiaochun Lei", "Siqi Wu", "Weilin Wu", "Zetao Jiang"], "title": "MambaNeXt-YOLO: A Hybrid State Space Model for Real-time Object Detection", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Real-time object detection is a fundamental but challenging task in computer\nvision, particularly when computational resources are limited. Although\nYOLO-series models have set strong benchmarks by balancing speed and accuracy,\nthe increasing need for richer global context modeling has led to the use of\nTransformer-based architectures. Nevertheless, Transformers have high\ncomputational complexity because of their self-attention mechanism, which\nlimits their practicality for real-time and edge deployments. To overcome these\nchallenges, recent developments in linear state space models, such as Mamba,\nprovide a promising alternative by enabling efficient sequence modeling with\nlinear complexity. Building on this insight, we propose MambaNeXt-YOLO, a novel\nobject detection framework that balances accuracy and efficiency through three\nkey contributions: (1) MambaNeXt Block: a hybrid design that integrates CNNs\nwith Mamba to effectively capture both local features and long-range\ndependencies; (2) Multi-branch Asymmetric Fusion Pyramid Network (MAFPN): an\nenhanced feature pyramid architecture that improves multi-scale object\ndetection across various object sizes; and (3) Edge-focused Efficiency: our\nmethod achieved 66.6\\% mAP at 31.9 FPS on the PASCAL VOC dataset without any\npre-training and supports deployment on edge devices such as the NVIDIA Jetson\nXavier NX and Orin NX.", "AI": {"tldr": "MambaNeXt-YOLO is a new object detection framework combining CNNs and Mamba for efficient real-time detection, achieving 66.6% mAP at 31.9 FPS on PASCAL VOC.", "motivation": "Addressing the computational complexity of Transformers and the need for efficient real-time object detection on edge devices.", "method": "Hybrid MambaNeXt Block (CNNs + Mamba), Multi-branch Asymmetric Fusion Pyramid Network (MAFPN), and edge-focused optimization.", "result": "66.6% mAP at 31.9 FPS on PASCAL VOC, deployable on edge devices like NVIDIA Jetson Xavier NX.", "conclusion": "MambaNeXt-YOLO effectively balances accuracy and efficiency for real-time object detection, suitable for edge deployments."}}
{"id": "2506.03719", "pdf": "https://arxiv.org/pdf/2506.03719", "abs": "https://arxiv.org/abs/2506.03719", "authors": ["Quentin Bertrand", "Anne Gagneux", "Mathurin Massias", "R\u00e9mi Emonet"], "title": "On the Closed-Form of Flow Matching: Generalization Does Not Arise from Target Stochasticity", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "Modern deep generative models can now produce high-quality synthetic samples\nthat are often indistinguishable from real training data. A growing body of\nresearch aims to understand why recent methods -- such as diffusion and flow\nmatching techniques -- generalize so effectively. Among the proposed\nexplanations are the inductive biases of deep learning architectures and the\nstochastic nature of the conditional flow matching loss. In this work, we rule\nout the latter -- the noisy nature of the loss -- as a primary contributor to\ngeneralization in flow matching. First, we empirically show that in\nhigh-dimensional settings, the stochastic and closed-form versions of the flow\nmatching loss yield nearly equivalent losses. Then, using state-of-the-art flow\nmatching models on standard image datasets, we demonstrate that both variants\nachieve comparable statistical performance, with the surprising observation\nthat using the closed-form can even improve performance.", "AI": {"tldr": "The paper investigates whether the stochastic nature of the flow matching loss contributes to generalization in deep generative models, finding it does not significantly impact performance.", "motivation": "To understand why modern generative models generalize well, specifically testing if the noisy nature of the flow matching loss is a key factor.", "method": "Empirical comparison of stochastic and closed-form flow matching losses in high-dimensional settings and on standard image datasets.", "result": "Both loss variants perform similarly, with the closed-form version sometimes improving performance.", "conclusion": "The stochastic nature of the flow matching loss is not a primary contributor to generalization in flow matching."}}
{"id": "2506.03704", "pdf": "https://arxiv.org/pdf/2506.03704", "abs": "https://arxiv.org/abs/2506.03704", "authors": ["Pei-Yun Lin", "Yen-lung Tsai"], "title": "ScoreRAG: A Retrieval-Augmented Generation Framework with Consistency-Relevance Scoring and Structured Summarization for News Generation", "categories": ["cs.CL", "68T50", "I.2.7"], "comment": "11 pages, 8 figures. Code and demo available at\n  https://github.com/peiyun2260/ScoreRAG. Submitted to arXiv for public access;\n  journal submission planned", "summary": "This research introduces ScoreRAG, an approach to enhance the quality of\nautomated news generation. Despite advancements in Natural Language Processing\nand large language models, current news generation methods often struggle with\nhallucinations, factual inconsistencies, and lack of domain-specific expertise\nwhen producing news articles. ScoreRAG addresses these challenges through a\nmulti-stage framework combining retrieval-augmented generation, consistency\nrelevance evaluation, and structured summarization. The system first retrieves\nrelevant news documents from a vector database, maps them to complete news\nitems, and assigns consistency relevance scores based on large language model\nevaluations. These documents are then reranked according to relevance, with\nlow-quality items filtered out. The framework proceeds to generate graded\nsummaries based on relevance scores, which guide the large language model in\nproducing complete news articles following professional journalistic standards.\nThrough this methodical approach, ScoreRAG aims to significantly improve the\naccuracy, coherence, informativeness, and professionalism of generated news\narticles while maintaining stability and consistency throughout the generation\nprocess. The code and demo are available at:\nhttps://github.com/peiyun2260/ScoreRAG.", "AI": {"tldr": "ScoreRAG improves automated news generation by combining retrieval-augmented generation, consistency scoring, and structured summarization to reduce hallucinations and enhance quality.", "motivation": "Current news generation methods suffer from hallucinations, factual inconsistencies, and lack of domain expertise. ScoreRAG aims to address these issues.", "method": "A multi-stage framework involving retrieval, consistency scoring, reranking, and structured summarization to guide news article generation.", "result": "ScoreRAG enhances accuracy, coherence, informativeness, and professionalism in generated news articles.", "conclusion": "ScoreRAG provides a robust solution for high-quality automated news generation, with code and demo available."}}
{"id": "2506.03596", "pdf": "https://arxiv.org/pdf/2506.03596", "abs": "https://arxiv.org/abs/2506.03596", "authors": ["Feng Han", "Yang Jiao", "Shaoxiang Chen", "Junhao Xu", "Jingjing Chen", "Yu-Gang Jiang"], "title": "ControlThinker: Unveiling Latent Semantics for Controllable Image Generation through Visual Reasoning", "categories": ["cs.CV"], "comment": null, "summary": "The field of controllable image generation has seen significant advancements,\nwith various architectures improving generation layout consistency with control\nsignals. However, contemporary methods still face challenges in bridging the\nsemantic gap between input text prompts with sparse semantics and the target\nimages, often over-relying on low-level control signals to infer regional\ndetails. To address this challenge, we propose ControlThinker, a novel\nframework that employs a \"comprehend-then-generate\" paradigm. Firstly, by\nincentivizing the visual reasoning capability of a MLLM, latent semantics from\ncontrol images are mined to enrich text prompts. This enriched semantic\nunderstanding then seamlessly aids in image generation without the need for\nadditional complex modifications. To further tackle the uncertainty arising\nfrom the ambiguity of control images, we encourage broader exploration of\nreasoning trajectories and select the optimal one using a metric-based output\nreward model (ORM). Extensive experimental results demonstrate that\nControlThinker effectively mitigates the semantic gap between raw text prompts\nand target images, resulting in improved visual quality and semantic\nconsistency across a wide range of benchmarks. The code and models are\navailable at https://github.com/Maplebb/ControlThinker.", "AI": {"tldr": "ControlThinker is a novel framework that enhances controllable image generation by enriching text prompts with latent semantics from control images, improving visual quality and semantic consistency.", "motivation": "Addressing the semantic gap between sparse text prompts and target images in controllable image generation, which current methods struggle with.", "method": "Uses a 'comprehend-then-generate' paradigm, leveraging a MLLM for visual reasoning to mine latent semantics from control images and enrich prompts. Includes a metric-based ORM to handle ambiguity.", "result": "Effectively reduces the semantic gap, improving visual quality and semantic consistency across benchmarks.", "conclusion": "ControlThinker offers a robust solution for bridging the semantic gap in controllable image generation, with publicly available code and models."}}
{"id": "2506.03667", "pdf": "https://arxiv.org/pdf/2506.03667", "abs": "https://arxiv.org/abs/2506.03667", "authors": ["Joji Joseph", "Bharadwaj Amrutur", "Shalabh Bhatnagar"], "title": "Accelerating SfM-based Pose Estimation with Dominating Set", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "This paper introduces a preprocessing technique to speed up\nStructure-from-Motion (SfM) based pose estimation, which is critical for\nreal-time applications like augmented reality (AR), virtual reality (VR), and\nrobotics. Our method leverages the concept of a dominating set from graph\ntheory to preprocess SfM models, significantly enhancing the speed of the pose\nestimation process without losing significant accuracy. Using the OnePose\ndataset, we evaluated our method across various SfM-based pose estimation\ntechniques. The results demonstrate substantial improvements in processing\nspeed, ranging from 1.5 to 14.48 times, and a reduction in reference images and\npoint cloud size by factors of 17-23 and 2.27-4, respectively. This work offers\na promising solution for efficient and accurate 3D pose estimation, balancing\nspeed and accuracy in real-time applications.", "AI": {"tldr": "A preprocessing technique using graph theory's dominating set speeds up SfM-based pose estimation, improving speed 1.5-14.48x while maintaining accuracy.", "motivation": "To enhance real-time applications like AR, VR, and robotics by accelerating SfM-based pose estimation without sacrificing accuracy.", "method": "Leverages a dominating set from graph theory to preprocess SfM models, reducing reference images and point cloud size.", "result": "Achieved speed improvements of 1.5-14.48x, reduced reference images by 17-23x, and point cloud size by 2.27-4x.", "conclusion": "The method efficiently balances speed and accuracy, offering a practical solution for real-time 3D pose estimation."}}
{"id": "2506.03725", "pdf": "https://arxiv.org/pdf/2506.03725", "abs": "https://arxiv.org/abs/2506.03725", "authors": ["Daniil Medyakov", "Sergey Stanko", "Gleb Molodtsov", "Philip Zmushko", "Grigoriy Evseev", "Egor Petrov", "Aleksandr Beznosikov"], "title": "Sign-SGD is the Golden Gate between Multi-Node to Single-Node Learning: Significant Boost via Parameter-Free Optimization", "categories": ["cs.LG", "math.OC"], "comment": "58 pages, 5 figures, 5 tables", "summary": "Quite recently, large language models have made a significant breakthrough\nacross various disciplines. However, training them is an extremely\nresource-intensive task, even for major players with vast computing resources.\nOne of the methods gaining popularity in light of these challenges is Sign-SGD.\nThis method can be applied both as a memory-efficient approach in single-node\ntraining and as a gradient compression technique in the distributed learning.\nNevertheless, it is impossible to automatically determine the effective\nstepsize from the theoretical standpoint. Indeed, it depends on the parameters\nof the dataset to which we do not have access in the real-world learning\nparadigm. To address this issue, we design several variants of single-node\ndeterministic Sign-SGD. We extend our approaches to practical scenarios:\nstochastic single-node and multi-node learning, methods with incorporated\nmomentum. We conduct extensive experiments on real machine learning problems\nthat emphasize the practical applicability of our ideas.", "AI": {"tldr": "The paper explores variants of Sign-SGD to address the challenge of determining effective stepsizes in large language model training, extending them to practical scenarios like stochastic and multi-node learning.", "motivation": "Training large language models is resource-intensive, and Sign-SGD offers a memory-efficient solution, but lacks automatic stepsize determination.", "method": "Designs deterministic Sign-SGD variants, extends to stochastic and multi-node learning, and incorporates momentum.", "result": "Extensive experiments demonstrate practical applicability on real machine learning problems.", "conclusion": "The proposed Sign-SGD variants effectively address stepsize challenges, enhancing practical usability in resource-intensive training."}}
{"id": "2506.03723", "pdf": "https://arxiv.org/pdf/2506.03723", "abs": "https://arxiv.org/abs/2506.03723", "authors": ["Chaeyun Jang", "Moonseok Choi", "Yegon Kim", "Hyungi Lee", "Juho Lee"], "title": "Verbalized Confidence Triggers Self-Verification: Emergent Behavior Without Explicit Reasoning Supervision", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Uncertainty calibration is essential for the safe deployment of large\nlanguage models (LLMs), particularly when users rely on verbalized confidence\nestimates. While prior work has focused on classifiers or short-form\ngeneration, confidence calibration for chain-of-thought (CoT) reasoning remains\nlargely unexplored. Surprisingly, we find that supervised fine-tuning with\nscalar confidence labels alone suffices to elicit self-verification behavior of\nlanguage models, without any explicit reasoning supervision or reinforcement\nlearning-based rewards. Despite being trained only to produce a verbalized\nconfidence score without any self-verifying examples, the model learns to\ngenerate longer and self-checking responses for low-confidence queries while\nproviding more concise answers for high-confidence ones. We further propose a\nsimple rethinking method that boosts performance via test-time scaling based on\ncalibrated uncertainty. Experiments on GSM8K and held-out reasoning tasks such\nas MATH-500 and ARC-Challenge show that our confidence-aware fine-tuning\nimproves both calibration and accuracy, while also enhancing interpretability\nby aligning the model's reasoning path with its confidence.", "AI": {"tldr": "Fine-tuning LLMs with scalar confidence labels elicits self-verification behavior, improving calibration and accuracy in CoT reasoning tasks.", "motivation": "Addressing the lack of research on confidence calibration for chain-of-thought reasoning in LLMs, aiming for safer deployment.", "method": "Supervised fine-tuning with scalar confidence labels and a rethinking method for test-time scaling.", "result": "Improved calibration, accuracy, and interpretability on tasks like GSM8K, MATH-500, and ARC-Challenge.", "conclusion": "Confidence-aware fine-tuning enhances LLM performance and aligns reasoning with confidence, without explicit supervision."}}
{"id": "2506.03605", "pdf": "https://arxiv.org/pdf/2506.03605", "abs": "https://arxiv.org/abs/2506.03605", "authors": ["Tomoya Yoshida", "Shuhei Kurita", "Taichi Nishimura", "Shinsuke Mori"], "title": "Generating 6DoF Object Manipulation Trajectories from Action Description in Egocentric Vision", "categories": ["cs.CV"], "comment": "CVPR 2025", "summary": "Learning to use tools or objects in common scenes, particularly handling them\nin various ways as instructed, is a key challenge for developing interactive\nrobots. Training models to generate such manipulation trajectories requires a\nlarge and diverse collection of detailed manipulation demonstrations for\nvarious objects, which is nearly unfeasible to gather at scale. In this paper,\nwe propose a framework that leverages large-scale ego- and exo-centric video\ndatasets -- constructed globally with substantial effort -- of Exo-Ego4D to\nextract diverse manipulation trajectories at scale. From these extracted\ntrajectories with the associated textual action description, we develop\ntrajectory generation models based on visual and point cloud-based language\nmodels. In the recently proposed egocentric vision-based in-a-quality\ntrajectory dataset of HOT3D, we confirmed that our models successfully generate\nvalid object trajectories, establishing a training dataset and baseline models\nfor the novel task of generating 6DoF manipulation trajectories from action\ndescriptions in egocentric vision.", "AI": {"tldr": "A framework for generating 6DoF manipulation trajectories from action descriptions using large-scale video datasets, validated on HOT3D.", "motivation": "Developing interactive robots requires diverse manipulation demonstrations, which are hard to gather at scale.", "method": "Leverages Exo-Ego4D video datasets to extract trajectories, then trains visual and point cloud-based language models for trajectory generation.", "result": "Models successfully generate valid object trajectories in the HOT3D dataset.", "conclusion": "Establishes a baseline for generating manipulation trajectories from action descriptions in egocentric vision."}}
{"id": "2506.03682", "pdf": "https://arxiv.org/pdf/2506.03682", "abs": "https://arxiv.org/abs/2506.03682", "authors": ["Melika Ayoughi", "Samira Abnar", "Chen Huang", "Chris Sandino", "Sayeri Lala", "Eeshan Gunesh Dhekane", "Dan Busbridge", "Shuangfei Zhai", "Vimal Thilak", "Josh Susskind", "Pascal Mettes", "Paul Groth", "Hanlin Goh"], "title": "How PARTs assemble into wholes: Learning the relative composition of images", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": null, "summary": "The composition of objects and their parts, along with object-object\npositional relationships, provides a rich source of information for\nrepresentation learning. Hence, spatial-aware pretext tasks have been actively\nexplored in self-supervised learning. Existing works commonly start from a grid\nstructure, where the goal of the pretext task involves predicting the absolute\nposition index of patches within a fixed grid. However, grid-based approaches\nfall short of capturing the fluid and continuous nature of real-world object\ncompositions. We introduce PART, a self-supervised learning approach that\nleverages continuous relative transformations between off-grid patches to\novercome these limitations. By modeling how parts relate to each other in a\ncontinuous space, PART learns the relative composition of images-an off-grid\nstructural relative positioning process that generalizes beyond occlusions and\ndeformations. In tasks requiring precise spatial understanding such as object\ndetection and time series prediction, PART outperforms strong grid-based\nmethods like MAE and DropPos, while also maintaining competitive performance on\nglobal classification tasks with minimal hyperparameter tuning. By breaking\nfree from grid constraints, PART opens up an exciting new trajectory for\nuniversal self-supervised pretraining across diverse datatypes-from natural\nimages to EEG signals-with promising potential in video, medical imaging, and\naudio.", "AI": {"tldr": "PART is a self-supervised learning method that uses continuous relative transformations between off-grid patches to improve spatial understanding, outperforming grid-based methods in tasks like object detection.", "motivation": "Existing grid-based approaches fail to capture the fluid and continuous nature of real-world object compositions, limiting their effectiveness.", "method": "PART leverages continuous relative transformations between off-grid patches to model how parts relate to each other in a continuous space.", "result": "PART outperforms grid-based methods (e.g., MAE, DropPos) in tasks requiring precise spatial understanding and maintains competitive performance in global classification tasks.", "conclusion": "PART offers a promising new direction for universal self-supervised pretraining across diverse datatypes, including images, EEG signals, video, and audio."}}
{"id": "2506.03757", "pdf": "https://arxiv.org/pdf/2506.03757", "abs": "https://arxiv.org/abs/2506.03757", "authors": ["Razvan-Andrei Lascu", "David \u0160i\u0161ka", "\u0141ukasz Szpruch"], "title": "PPO in the Fisher-Rao geometry", "categories": ["cs.LG", "math.OC"], "comment": "17 pages", "summary": "Proximal Policy Optimization (PPO) has become a widely adopted algorithm for\nreinforcement learning, offering a practical policy gradient method with strong\nempirical performance. Despite its popularity, PPO lacks formal theoretical\nguarantees for policy improvement and convergence. PPO is motivated by Trust\nRegion Policy Optimization (TRPO) that utilizes a surrogate loss with a KL\ndivergence penalty, which arises from linearizing the value function within a\nflat geometric space. In this paper, we derive a tighter surrogate in the\nFisher-Rao (FR) geometry, yielding a novel variant, Fisher-Rao PPO (FR-PPO).\nOur proposed scheme provides strong theoretical guarantees, including monotonic\npolicy improvement. Furthermore, in the tabular setting, we demonstrate that\nFR-PPO achieves sub-linear convergence without any dependence on the\ndimensionality of the action or state spaces, marking a significant step toward\nestablishing formal convergence results for PPO-based algorithms.", "AI": {"tldr": "FR-PPO, a variant of PPO, improves theoretical guarantees and convergence by using Fisher-Rao geometry.", "motivation": "PPO lacks formal theoretical guarantees despite its empirical success. FR-PPO addresses this gap.", "method": "Derives a tighter surrogate loss in Fisher-Rao geometry, creating FR-PPO.", "result": "FR-PPO ensures monotonic policy improvement and sub-linear convergence in tabular settings.", "conclusion": "FR-PPO advances PPO's theoretical foundation, offering stronger guarantees and convergence."}}
{"id": "2506.03735", "pdf": "https://arxiv.org/pdf/2506.03735", "abs": "https://arxiv.org/abs/2506.03735", "authors": ["Junling Wang", "Anna Rutkiewicz", "April Yi Wang", "Mrinmaya Sachan"], "title": "Generating Pedagogically Meaningful Visuals for Math Word Problems: A New Benchmark and Analysis of Text-to-Image Models", "categories": ["cs.CL", "cs.AI", "cs.HC"], "comment": "Findings of the Association for Computational Linguistics: ACL 2025", "summary": "Visuals are valuable tools for teaching math word problems (MWPs), helping\nyoung learners interpret textual descriptions into mathematical expressions\nbefore solving them. However, creating such visuals is labor-intensive and\nthere is a lack of automated methods to support this process. In this paper, we\npresent Math2Visual, an automatic framework for generating pedagogically\nmeaningful visuals from MWP text descriptions. Math2Visual leverages a\npre-defined visual language and a design space grounded in interviews with math\nteachers, to illustrate the core mathematical relationships in MWPs. Using\nMath2Visual, we construct an annotated dataset of 1,903 visuals and evaluate\nText-to-Image (TTI) models for their ability to generate visuals that align\nwith our design. We further fine-tune several TTI models with our dataset,\ndemonstrating improvements in educational visual generation. Our work\nestablishes a new benchmark for automated generation of pedagogically\nmeaningful visuals and offers insights into key challenges in producing\nmultimodal educational content, such as the misrepresentation of mathematical\nrelationships and the omission of essential visual elements.", "AI": {"tldr": "Math2Visual automates the creation of pedagogically meaningful visuals for math word problems, improving educational content generation.", "motivation": "Manual creation of visuals for math word problems is labor-intensive, and automated methods are lacking.", "method": "Math2Visual uses a pre-defined visual language and teacher-informed design space to generate visuals, and evaluates/fine-tunes Text-to-Image models.", "result": "A dataset of 1,903 visuals was created, and fine-tuned TTI models showed improved educational visual generation.", "conclusion": "Math2Visual sets a benchmark for automated, pedagogically meaningful visuals and highlights challenges in multimodal educational content."}}
{"id": "2506.03607", "pdf": "https://arxiv.org/pdf/2506.03607", "abs": "https://arxiv.org/abs/2506.03607", "authors": ["Wing Man Casca Kwok", "Yip Chiu Tung", "Kunal Bhagchandani"], "title": "Analyzing Transformer Models and Knowledge Distillation Approaches for Image Captioning on Edge AI", "categories": ["cs.CV"], "comment": null, "summary": "Edge computing decentralizes processing power to network edge, enabling\nreal-time AI-driven decision-making in IoT applications. In industrial\nautomation such as robotics and rugged edge AI, real-time perception and\nintelligence are critical for autonomous operations. Deploying\ntransformer-based image captioning models at the edge can enhance machine\nperception, improve scene understanding for autonomous robots, and aid in\nindustrial inspection.\n  However, these edge or IoT devices are often constrained in computational\nresources for physical agility, yet they have strict response time\nrequirements. Traditional deep learning models can be too large and\ncomputationally demanding for these devices. In this research, we present\nfindings of transformer-based models for image captioning that operate\neffectively on edge devices. By evaluating resource-effective transformer\nmodels and applying knowledge distillation techniques, we demonstrate inference\ncan be accelerated on resource-constrained devices while maintaining model\nperformance using these techniques.", "AI": {"tldr": "Transformer-based image captioning models optimized for edge devices enable real-time AI in IoT applications, balancing performance and resource constraints.", "motivation": "Industrial automation and IoT applications require real-time AI for tasks like robotics and inspection, but edge devices face computational limitations.", "method": "Evaluated resource-effective transformer models and applied knowledge distillation to optimize performance on edge devices.", "result": "Demonstrated accelerated inference on resource-constrained devices while maintaining model performance.", "conclusion": "Optimized transformer models enable effective real-time AI at the edge for industrial and IoT applications."}}
{"id": "2506.03710", "pdf": "https://arxiv.org/pdf/2506.03710", "abs": "https://arxiv.org/abs/2506.03710", "authors": ["Yisen Feng", "Haoyu Zhang", "Qiaohui Chu", "Meng Liu", "Weili Guan", "Yaowei Wang", "Liqiang Nie"], "title": "OSGNet @ Ego4D Episodic Memory Challenge 2025", "categories": ["cs.CV", "cs.AI"], "comment": "The champion solutions for the three egocentric video localization\n  tracks(Natural Language Queries, Goal Step, and Moment Queries tracks) of the\n  Ego4D Episodic Memory Challenge at CVPR EgoVis Workshop 2025", "summary": "In this report, we present our champion solutions for the three egocentric\nvideo localization tracks of the Ego4D Episodic Memory Challenge at CVPR 2025.\nAll tracks require precise localization of the interval within an untrimmed\negocentric video. Previous unified video localization approaches often rely on\nlate fusion strategies, which tend to yield suboptimal results. To address\nthis, we adopt an early fusion-based video localization model to tackle all\nthree tasks, aiming to enhance localization accuracy. Ultimately, our method\nachieved first place in the Natural Language Queries, Goal Step, and Moment\nQueries tracks, demonstrating its effectiveness. Our code can be found at\nhttps://github.com/Yisen-Feng/OSGNet.", "AI": {"tldr": "The paper presents a winning solution for the Ego4D Episodic Memory Challenge, using an early fusion-based model to improve video localization accuracy across three tasks.", "motivation": "Existing late fusion strategies for video localization are suboptimal, prompting the need for a more effective approach.", "method": "An early fusion-based video localization model is employed to address the tasks.", "result": "The method achieved first place in all three tracks: Natural Language Queries, Goal Step, and Moment Queries.", "conclusion": "The early fusion-based model proves effective for precise video localization, as demonstrated by its top performance in the challenge."}}
{"id": "2506.03758", "pdf": "https://arxiv.org/pdf/2506.03758", "abs": "https://arxiv.org/abs/2506.03758", "authors": ["Daniel Palenicek", "Florian Vogt", "Jan Peters"], "title": "Scaling CrossQ with Weight Normalization", "categories": ["cs.LG", "cs.AI"], "comment": "arXiv admin note: substantial text overlap with arXiv:2502.07523", "summary": "Reinforcement learning has achieved significant milestones, but sample\nefficiency remains a bottleneck for real-world applications. Recently, CrossQ\nhas demonstrated state-of-the-art sample efficiency with a low update-to-data\n(UTD) ratio of 1. In this work, we explore CrossQ's scaling behavior with\nhigher UTD ratios. We identify challenges in the training dynamics which are\nemphasized by higher UTDs, particularly Q-bias explosion and the growing\nmagnitude of critic network weights. To address this, we integrate weight\nnormalization into the CrossQ framework, a solution that stabilizes training,\nprevents potential loss of plasticity and keeps the effective learning rate\nconstant. Our proposed approach reliably scales with increasing UTD ratios,\nachieving competitive or superior performance across a range of challenging\ntasks on the DeepMind control benchmark, notably the complex dog and humanoid\nenvironments. This work eliminates the need for drastic interventions, such as\nnetwork resets, and offers a robust pathway for improving sample efficiency and\nscalability in model-free reinforcement learning.", "AI": {"tldr": "CrossQ's scaling with higher UTD ratios faces challenges like Q-bias explosion and critic weight growth. Weight normalization stabilizes training, enabling reliable scaling and superior performance on complex tasks.", "motivation": "Addressing sample efficiency bottlenecks in reinforcement learning by exploring CrossQ's behavior at higher UTD ratios.", "method": "Integrating weight normalization into CrossQ to stabilize training dynamics and maintain constant effective learning rates.", "result": "Improved scalability and performance on challenging tasks like dog and humanoid environments in the DeepMind control benchmark.", "conclusion": "Weight normalization offers a robust solution for scaling CrossQ without drastic interventions, enhancing sample efficiency in model-free RL."}}
{"id": "2506.03761", "pdf": "https://arxiv.org/pdf/2506.03761", "abs": "https://arxiv.org/abs/2506.03761", "authors": ["Hongcheng Guo", "Zheyong Xie", "Shaosheng Cao", "Boyang Wang", "Weiting Liu", "Zheyu Ye", "Zhoujun Li", "Zuozhu Liu"], "title": "Act-as-Pet: Benchmarking the Abilities of Large Language Models as E-Pets in Social Network Services", "categories": ["cs.CL"], "comment": null, "summary": "As interest in using Large Language Models (LLMs) for interactive and\nemotionally rich experiences grows, virtual pet companionship emerges as a\nnovel yet underexplored application. Existing approaches focus on basic pet\nrole-playing interactions without systematically benchmarking LLMs for\ncomprehensive companionship. In this paper, we introduce Pet-Bench, a dedicated\nbenchmark that evaluates LLMs across both self-interaction and\nhuman-interaction dimensions. Unlike prior work, Pet-Bench emphasizes\nself-evolution and developmental behaviors alongside interactive engagement,\noffering a more realistic reflection of pet companionship. It features diverse\ntasks such as intelligent scheduling, memory-based dialogues, and psychological\nconversations, with over 7,500 interaction instances designed to simulate\ncomplex pet behaviors. Evaluation of 28 LLMs reveals significant performance\nvariations linked to model size and inherent capabilities, underscoring the\nneed for specialized optimization in this domain. Pet-Bench serves as a\nfoundational resource for benchmarking pet-related LLM abilities and advancing\nemotionally immersive human-pet interactions.", "AI": {"tldr": "Pet-Bench is a benchmark for evaluating LLMs in virtual pet companionship, focusing on self-evolution and interactive engagement, with 7,500+ tasks. Testing 28 LLMs shows performance varies by model size and capabilities.", "motivation": "To address the lack of systematic benchmarking for LLMs in virtual pet companionship, aiming for more realistic and emotionally rich interactions.", "method": "Introduces Pet-Bench, a benchmark with tasks like intelligent scheduling, memory-based dialogues, and psychological conversations.", "result": "Evaluation of 28 LLMs reveals performance variations tied to model size and capabilities, highlighting the need for specialized optimization.", "conclusion": "Pet-Bench provides a foundational tool for advancing emotionally immersive human-pet interactions and benchmarking LLM abilities in this domain."}}
{"id": "2506.03608", "pdf": "https://arxiv.org/pdf/2506.03608", "abs": "https://arxiv.org/abs/2506.03608", "authors": ["Di Fan", "Heng Yu", "Zhiyuan Xu"], "title": "PDSE: A Multiple Lesion Detector for CT Images using PANet and Deformable Squeeze-and-Excitation Block", "categories": ["cs.CV"], "comment": "MIUA 2024", "summary": "Detecting lesions in Computed Tomography (CT) scans is a challenging task in\nmedical image processing due to the diverse types, sizes, and locations of\nlesions. Recently, various one-stage and two-stage framework networks have been\ndeveloped to focus on lesion localization. We introduce a one-stage lesion\ndetection framework, PDSE, by redesigning Retinanet to achieve higher accuracy\nand efficiency for detecting lesions in multimodal CT images. Specifically, we\nenhance the path aggregation flow by incorporating a low-level feature map.\nAdditionally, to improve model representation, we utilize the adaptive\nSqueeze-and-Excitation (SE) block and integrate channel feature map attention.\nThis approach has resulted in achieving new state-of-the-art performance. Our\nmethod significantly improves the detection of small and multiscaled objects.\nWhen evaluated against other advanced algorithms on the public DeepLesion\nbenchmark, our algorithm achieved an mAP of over 0.20.", "AI": {"tldr": "The paper introduces PDSE, a one-stage lesion detection framework for CT scans, enhancing Retinanet with low-level feature maps and adaptive SE blocks for improved accuracy and efficiency.", "motivation": "Detecting diverse lesions in CT scans is challenging due to varying types, sizes, and locations, prompting the need for more accurate and efficient methods.", "method": "PDSE redesigns Retinanet by incorporating low-level feature maps and adaptive SE blocks with channel feature map attention to enhance lesion detection.", "result": "The method achieves state-of-the-art performance, improving small and multiscaled object detection, with an mAP over 0.20 on the DeepLesion benchmark.", "conclusion": "PDSE demonstrates superior accuracy and efficiency in lesion detection, setting a new benchmark for multimodal CT image analysis."}}
{"id": "2506.03737", "pdf": "https://arxiv.org/pdf/2506.03737", "abs": "https://arxiv.org/abs/2506.03737", "authors": ["Hao Yu", "Tangyu Jiang", "Shuning Jia", "Shannan Yan", "Shunning Liu", "Haolong Qian", "Guanghao Li", "Shuting Dong", "Huaisong Zhang", "Chun Yuan"], "title": "ComRoPE: Scalable and Robust Rotary Position Embedding Parameterized by Trainable Commuting Angle Matrices", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "The Transformer architecture has revolutionized various regions since it was\nproposed, and its effectiveness largely depends on the ability to encode\npositional information. Traditional position encoding methods exhibit\nsignificant limitations due to lack of robustness and flexibility of position.\nTherefore, Rotary Positional Encoding (RoPE) was proposed to alleviate these\nissues, which integrates positional information by rotating the embeddings in\nthe attention mechanism. However, RoPE requires manually defined rotation\nmatrices with limited transformation space, constraining the model's capacity.\nIn this work, we propose ComRoPE, which generalizes RoPE by defining it in\nterms of trainable commuting angle matrices. Specifically, we demonstrate that\npairwise commutativity of these matrices is essential for RoPE to achieve\nscalability and positional robustness. We formally define the RoPE Equation,\nwhich is an essential condition that ensures consistent performance with\nposition offsets. Based on the theoretical analysis, we present two types of\ntrainable commuting angle matrices as sufficient solutions to the RoPE\nequation, which significantly improve performance, surpassing the current\nstate-of-the-art method by 1.6% at training resolution and 2.9% at higher\nresolution on the ImageNet-1K dataset. Furthermore, our framework shows\nversatility in generalizing to existing RoPE formulations and offering new\ninsights for future positional encoding research. To ensure reproducibility,\nthe source code and instructions are available at\nhttps://github.com/Longin-Yu/ComRoPE", "AI": {"tldr": "ComRoPE improves Rotary Positional Encoding (RoPE) by introducing trainable commuting angle matrices, enhancing performance and flexibility in positional encoding.", "motivation": "Traditional position encoding methods lack robustness and flexibility, and RoPE's manual rotation matrices limit model capacity.", "method": "ComRoPE generalizes RoPE with trainable commuting angle matrices, ensuring scalability and positional robustness.", "result": "ComRoPE outperforms state-of-the-art by 1.6% at training resolution and 2.9% at higher resolution on ImageNet-1K.", "conclusion": "ComRoPE offers a versatile, scalable solution for positional encoding, with potential for future research."}}
{"id": "2506.03777", "pdf": "https://arxiv.org/pdf/2506.03777", "abs": "https://arxiv.org/abs/2506.03777", "authors": ["Li Zhang", "Zhongxuan Han", "Chaochao chen", "Xiaohua Feng", "Jiaming Zhang", "Yuyuan Li"], "title": "FedFACT: A Provable Framework for Controllable Group-Fairness Calibration in Federated Learning", "categories": ["cs.LG"], "comment": null, "summary": "With emerging application of Federated Learning (FL) in decision-making\nscenarios, it is imperative to regulate model fairness to prevent disparities\nacross sensitive groups (e.g., female, male). Current research predominantly\nfocuses on two concepts of group fairness within FL: Global Fairness (overall\nmodel disparity across all clients) and Local Fairness (the disparity within\neach client). However, the non-decomposable, non-differentiable nature of\nfairness criteria pose two fundamental, unresolved challenges for fair FL: (i)\nHarmonizing global and local fairness in multi-class classification; (ii)\nEnabling a controllable, optimal accuracy-fairness trade-off. To tackle the\naforementioned challenges, we propose a novel controllable federated\ngroup-fairness calibration framework, named FedFACT. FedFACT identifies the\nBayes-optimal classifiers under both global and local fairness constraints in\nmulti-class case, yielding models with minimal performance decline while\nguaranteeing fairness. To effectively realize an adjustable, optimal\naccuracy-fairness balance, we derive specific characterizations of the\nBayes-optimal fair classifiers for reformulating fair FL as personalized\ncost-sensitive learning problem for in-processing, and bi-level optimization\nfor post-processing. Theoretically, we provide convergence and generalization\nguarantees for FedFACT to approach the near-optimal accuracy under given\nfairness levels. Extensive experiments on multiple datasets across various data\nheterogeneity demonstrate that FedFACT consistently outperforms baselines in\nbalancing accuracy and global-local fairness.", "AI": {"tldr": "FedFACT is a framework for fair Federated Learning, addressing global and local fairness challenges in multi-class classification with controllable accuracy-fairness trade-offs.", "motivation": "To regulate model fairness in FL, ensuring no disparities across sensitive groups, and to harmonize global and local fairness while enabling optimal accuracy-fairness balance.", "method": "Proposes FedFACT, which identifies Bayes-optimal classifiers under fairness constraints, reformulates fair FL as personalized cost-sensitive learning, and uses bi-level optimization.", "result": "FedFACT outperforms baselines in balancing accuracy and fairness across datasets with varying data heterogeneity.", "conclusion": "FedFACT provides a near-optimal solution for fair FL with theoretical guarantees and practical effectiveness."}}
{"id": "2506.03762", "pdf": "https://arxiv.org/pdf/2506.03762", "abs": "https://arxiv.org/abs/2506.03762", "authors": ["Yifeng Gu", "Zicong Jiang", "Jianxiu Jin", "Kailing Guo", "Ziyang Zhang", "Xiangmin Xu"], "title": "AhaKV: Adaptive Holistic Attention-Driven KV Cache Eviction for Efficient Inference of Large Language Models", "categories": ["cs.CL", "cs.AI"], "comment": "14 pages, 8 figures", "summary": "Large Language Models (LLMs) have significantly advanced the field of\nArtificial Intelligence. However, their deployment is resource-intensive, not\nonly due to the large number of model parameters but also because the\n(Key-Value) KV cache consumes a lot of memory during inference. While several\nworks propose reducing the KV cache by evicting the unnecessary tokens, these\napproaches rely on accumulated attention score as eviction score to quantify\nthe importance of the token. We identify the accumulated attention score is\nbiased and it decreases with the position of the tokens in the mathematical\nexpectation. As a result, the retained tokens concentrate on the initial\npositions, limiting model's access to global contextual information. To address\nthis issue, we propose Adaptive holistic attention KV (AhaKV), it addresses the\nbias of the accumulated attention score by adaptively tuning the scale of\nsoftmax according the expectation of information entropy of attention scores.\nTo make use of the holistic attention information in self-attention mechanism,\nAhaKV utilize the information of value vectors, which is overlooked in previous\nworks, to refine the adaptive score. We show theoretically that our method is\nwell suited for bias reduction. We deployed AhaKV on different models with a\nfixed cache budget. Experiments show that AhaKV successfully mitigates bias and\nretains crucial tokens across global context and achieve state-of-the-art\nresults against other related work on several benchmark tasks.", "AI": {"tldr": "AhaKV reduces bias in KV cache eviction by adaptively tuning softmax scale, improving global context retention in LLMs.", "motivation": "Current KV cache eviction methods are biased, favoring initial tokens and limiting global context access.", "method": "Proposes AhaKV, which adjusts softmax scale based on attention entropy and uses value vectors for refined scoring.", "result": "AhaKV mitigates bias, retains crucial tokens globally, and achieves SOTA results on benchmarks.", "conclusion": "AhaKV effectively addresses KV cache bias, enhancing LLM inference efficiency and performance."}}
{"id": "2506.03615", "pdf": "https://arxiv.org/pdf/2506.03615", "abs": "https://arxiv.org/abs/2506.03615", "authors": ["Sarah Alyami", "Hamzah Luqman", "Sadam Al-Azani", "Maad Alowaifeer", "Yazeed Alharbi", "Yaser Alonaizan"], "title": "Isharah: A Large-Scale Multi-Scene Dataset for Continuous Sign Language Recognition", "categories": ["cs.CV"], "comment": null, "summary": "Current benchmarks for sign language recognition (SLR) focus mainly on\nisolated SLR, while there are limited datasets for continuous SLR (CSLR), which\nrecognizes sequences of signs in a video. Additionally, existing CSLR datasets\nare collected in controlled settings, which restricts their effectiveness in\nbuilding robust real-world CSLR systems. To address these limitations, we\npresent Isharah, a large multi-scene dataset for CSLR. It is the first dataset\nof its type and size that has been collected in an unconstrained environment\nusing signers' smartphone cameras. This setup resulted in high variations of\nrecording settings, camera distances, angles, and resolutions. This variation\nhelps with developing sign language understanding models capable of handling\nthe variability and complexity of real-world scenarios. The dataset consists of\n30,000 video clips performed by 18 deaf and professional signers. Additionally,\nthe dataset is linguistically rich as it provides a gloss-level annotation for\nall dataset's videos, making it useful for developing CSLR and sign language\ntranslation (SLT) systems. This paper also introduces multiple sign language\nunderstanding benchmarks, including signer-independent and unseen-sentence\nCSLR, along with gloss-based and gloss-free SLT. The Isharah dataset is\navailable on https://snalyami.github.io/Isharah_CSLR/.", "AI": {"tldr": "The paper introduces Isharah, a large multi-scene dataset for continuous sign language recognition (CSLR) collected in unconstrained environments, addressing limitations of existing datasets.", "motivation": "Existing CSLR datasets are limited and collected in controlled settings, hindering robust real-world SLR systems.", "method": "Isharah is created using smartphone cameras, capturing 30,000 video clips with high variability in recording settings. It includes gloss-level annotations.", "result": "The dataset supports CSLR and sign language translation (SLT) benchmarks, including signer-independent and unseen-sentence tasks.", "conclusion": "Isharah enhances real-world SLR and SLT development by providing diverse, linguistically rich data."}}
{"id": "2506.03740", "pdf": "https://arxiv.org/pdf/2506.03740", "abs": "https://arxiv.org/abs/2506.03740", "authors": ["Jianfeng Wu", "Nannan Xu"], "title": "SAAT: Synergistic Alternating Aggregation Transformer for Image Super-Resolution", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Single image super-resolution is a well-known downstream task which aims to\nrestore low-resolution images into high-resolution images. At present, models\nbased on Transformers have shone brightly in the field of super-resolution due\nto their ability to capture long-term dependencies in information. However,\ncurrent methods typically compute self-attention in nonoverlapping windows to\nsave computational costs, and the standard self-attention computation only\nfocuses on its results, thereby neglecting the useful information across\nchannels and the rich spatial structural information generated in the\nintermediate process. Channel attention and spatial attention have,\nrespectively, brought significant improvements to various downstream visual\ntasks in terms of extracting feature dependency and spatial structure\nrelationships, but the synergistic relationship between channel and spatial\nattention has not been fully explored yet.To address these issues, we propose a\nnovel model. Synergistic Alternating Aggregation Transformer (SAAT), which can\nbetter utilize the potential information of features. In SAAT, we introduce the\nEfficient Channel & Window Synergistic Attention Group (CWSAG) and the Spatial\n& Window Synergistic Attention Group (SWSAG). On the one hand, CWSAG combines\nefficient channel attention with shifted window attention, enhancing non-local\nfeature fusion, and producing more visually appealing results. On the other\nhand, SWSAG leverages spatial attention to capture rich structured feature\ninformation, thereby enabling SAAT to more effectively extract structural\nfeatures.Extensive experimental results and ablation studies demonstrate the\neffectiveness of SAAT in the field of super-resolution. SAAT achieves\nperformance comparable to that of the state-of-the-art (SOTA) under the same\nquantity of parameters.", "AI": {"tldr": "The paper proposes SAAT, a novel Transformer-based model for single image super-resolution, combining channel and spatial attention synergistically to improve feature utilization and performance.", "motivation": "Current Transformer-based super-resolution methods neglect useful cross-channel and spatial structural information due to nonoverlapping window self-attention. The paper aims to address this by exploring the synergistic relationship between channel and spatial attention.", "method": "Introduces SAAT with two key components: CWSAG (combines channel attention and shifted window attention) and SWSAG (leverages spatial attention). These enhance feature fusion and structural feature extraction.", "result": "SAAT achieves performance comparable to state-of-the-art models under the same parameter count, demonstrating effectiveness in super-resolution.", "conclusion": "SAAT successfully integrates channel and spatial attention synergistically, improving super-resolution results and feature utilization."}}
{"id": "2506.03784", "pdf": "https://arxiv.org/pdf/2506.03784", "abs": "https://arxiv.org/abs/2506.03784", "authors": ["Beatrix M. G. Nielsen", "Emanuele Marconato", "Andrea Dittadi", "Luigi Gresele"], "title": "When Does Closeness in Distribution Imply Representational Similarity? An Identifiability Perspective", "categories": ["cs.LG", "cs.AI", "stat.ML"], "comment": null, "summary": "When and why representations learned by different deep neural networks are\nsimilar is an active research topic. We choose to address these questions from\nthe perspective of identifiability theory, which suggests that a measure of\nrepresentational similarity should be invariant to transformations that leave\nthe model distribution unchanged. Focusing on a model family which includes\nseveral popular pre-training approaches, e.g., autoregressive language models,\nwe explore when models which generate distributions that are close have similar\nrepresentations. We prove that a small Kullback-Leibler divergence between the\nmodel distributions does not guarantee that the corresponding representations\nare similar. This has the important corollary that models arbitrarily close to\nmaximizing the likelihood can still learn dissimilar representations, a\nphenomenon mirrored in our empirical observations on models trained on\nCIFAR-10. We then define a distributional distance for which closeness implies\nrepresentational similarity, and in synthetic experiments, we find that wider\nnetworks learn distributions which are closer with respect to our distance and\nhave more similar representations. Our results establish a link between\ncloseness in distribution and representational similarity.", "AI": {"tldr": "The paper investigates when and why deep neural networks learn similar representations, using identifiability theory. It shows that small KL divergence doesn't guarantee similar representations, and defines a new distance metric linking distributional closeness to representational similarity.", "motivation": "To understand the conditions under which different neural networks learn similar representations, despite generating close model distributions.", "method": "Uses identifiability theory and focuses on a model family including autoregressive language models. Proves limitations of KL divergence and introduces a new distributional distance.", "result": "Small KL divergence doesn't ensure similar representations. Wider networks learn distributions closer to the new distance and have more similar representations.", "conclusion": "Establishes a connection between distributional closeness and representational similarity, with implications for model training and evaluation."}}
{"id": "2506.03763", "pdf": "https://arxiv.org/pdf/2506.03763", "abs": "https://arxiv.org/abs/2506.03763", "authors": ["Quang Hieu Pham", "Thuy Duong Nguyen", "Tung Pham", "Anh Tuan Luu", "Dat Quoc Nguyen"], "title": "ClozeMath: Improving Mathematical Reasoning in Language Models by Learning to Fill Equations", "categories": ["cs.CL"], "comment": "Accepted to ACL 2025 Findings", "summary": "The capabilities of large language models (LLMs) have been enhanced by\ntraining on data that reflects human thought processes, such as the\nChain-of-Thought format. However, evidence suggests that the conventional\nscheme of next-word prediction may not fully capture how humans learn to think.\nInspired by how humans generalize mathematical reasoning, we propose a new\napproach named ClozeMath to fine-tune LLMs for mathematical reasoning. Our\nClozeMath involves a text-infilling task that predicts masked equations from a\ngiven solution, analogous to cloze exercises used in human learning.\nExperiments on GSM8K, MATH, and GSM-Symbolic show that ClozeMath surpasses the\nstrong baseline Masked Thought in performance and robustness, with two\ntest-time scaling decoding algorithms, Beam Search and Chain-of-Thought\ndecoding. Additionally, we conduct an ablation study to analyze the effects of\nvarious architectural and implementation choices on our approach.", "AI": {"tldr": "ClozeMath, a new fine-tuning approach for LLMs, improves mathematical reasoning by predicting masked equations from solutions, outperforming baselines like Masked Thought.", "motivation": "Current LLM training on next-word prediction may not fully mimic human learning, especially in mathematical reasoning.", "method": "ClozeMath uses a text-infilling task to predict masked equations from given solutions, akin to cloze exercises.", "result": "ClozeMath outperforms Masked Thought on GSM8K, MATH, and GSM-Symbolic datasets, with Beam Search and Chain-of-Thought decoding enhancing robustness.", "conclusion": "ClozeMath is a promising approach for enhancing LLMs' mathematical reasoning, validated by ablation studies on architectural choices."}}
{"id": "2506.03635", "pdf": "https://arxiv.org/pdf/2506.03635", "abs": "https://arxiv.org/abs/2506.03635", "authors": ["Yinfan Wang", "Jie Gui", "Baosheng Yu", "Qi Li", "Zhenan Sun", "Juho Kannala", "Guoying Zhao"], "title": "FingerVeinSyn-5M: A Million-Scale Dataset and Benchmark for Finger Vein Recognition", "categories": ["cs.CV"], "comment": null, "summary": "A major challenge in finger vein recognition is the lack of large-scale\npublic datasets. Existing datasets contain few identities and limited samples\nper finger, restricting the advancement of deep learning-based methods. To\naddress this, we introduce FVeinSyn, a synthetic generator capable of producing\ndiverse finger vein patterns with rich intra-class variations. Using FVeinSyn,\nwe created FingerVeinSyn-5M -- the largest available finger vein dataset --\ncontaining 5 million samples from 50,000 unique fingers, each with 100\nvariations including shift, rotation, scale, roll, varying exposure levels,\nskin scattering blur, optical blur, and motion blur. FingerVeinSyn-5M is also\nthe first to offer fully annotated finger vein images, supporting deep learning\napplications in this field. Models pretrained on FingerVeinSyn-5M and\nfine-tuned with minimal real data achieve an average 53.91\\% performance gain\nacross multiple benchmarks. The dataset is publicly available at:\nhttps://github.com/EvanWang98/FingerVeinSyn-5M.", "AI": {"tldr": "The paper introduces FVeinSyn, a synthetic generator for finger vein patterns, and FingerVeinSyn-5M, the largest finger vein dataset with 5M samples. Pretraining on it boosts performance by 53.91%.", "motivation": "The lack of large-scale public finger vein datasets limits deep learning advancements in this field.", "method": "Developed FVeinSyn to generate synthetic finger vein patterns with rich variations and created FingerVeinSyn-5M dataset.", "result": "Pretraining on FingerVeinSyn-5M and fine-tuning with minimal real data yields a 53.91% performance gain.", "conclusion": "FingerVeinSyn-5M addresses dataset scarcity, enabling better deep learning models for finger vein recognition."}}
{"id": "2506.03755", "pdf": "https://arxiv.org/pdf/2506.03755", "abs": "https://arxiv.org/abs/2506.03755", "authors": ["Max Hellrigel-Holderbaum", "Leonard Dung"], "title": "Misalignment or misuse? The AGI alignment tradeoff", "categories": ["cs.CY", "cs.AI"], "comment": "Forthcoming in Philosophical Studies", "summary": "Creating systems that are aligned with our goals is seen as a leading\napproach to create safe and beneficial AI in both leading AI companies and the\nacademic field of AI safety. We defend the view that misaligned AGI - future,\ngenerally intelligent (robotic) AI agents - poses catastrophic risks. At the\nsame time, we support the view that aligned AGI creates a substantial risk of\ncatastrophic misuse by humans. While both risks are severe and stand in tension\nwith one another, we show that - in principle - there is room for alignment\napproaches which do not increase misuse risk. We then investigate how the\ntradeoff between misalignment and misuse looks empirically for different\ntechnical approaches to AI alignment. Here, we argue that many current\nalignment techniques and foreseeable improvements thereof plausibly increase\nrisks of catastrophic misuse. Since the impacts of AI depend on the social\ncontext, we close by discussing important social factors and suggest that to\nreduce the risk of a misuse catastrophe due to aligned AGI, techniques such as\nrobustness, AI control methods and especially good governance seem essential.", "AI": {"tldr": "The paper discusses the dual risks of misaligned AGI (catastrophic risks) and aligned AGI (misuse risks), proposing that some alignment approaches can avoid increasing misuse risk. It evaluates current alignment techniques and emphasizes social factors and governance to mitigate misuse risks.", "motivation": "To address the catastrophic risks posed by both misaligned and aligned AGI, and to explore alignment approaches that minimize misuse risks.", "method": "Analyzes the tradeoff between misalignment and misuse risks for various AI alignment techniques, and evaluates their empirical implications.", "result": "Many current alignment techniques may increase misuse risks, highlighting the need for robust AI control methods and governance.", "conclusion": "Effective alignment must balance misalignment and misuse risks, with governance and robustness being key to mitigating misuse of aligned AGI."}}
{"id": "2506.03790", "pdf": "https://arxiv.org/pdf/2506.03790", "abs": "https://arxiv.org/abs/2506.03790", "authors": ["Peng Wang", "Yifu Lu", "Yaodong Yu", "Druv Pai", "Qing Qu", "Yi Ma"], "title": "Attention-Only Transformers via Unrolled Subspace Denoising", "categories": ["cs.LG"], "comment": "28 pages, 7 figures, 5 tables", "summary": "Despite the popularity of transformers in practice, their architectures are\nempirically designed and neither mathematically justified nor interpretable.\nMoreover, as indicated by many empirical studies, some components of\ntransformer architectures may be redundant. To derive a fully interpretable\ntransformer architecture with only necessary components, we contend that the\ngoal of representation learning is to compress a set of noisy initial token\nrepresentations towards a mixture of low-dimensional subspaces. To compress\nthese noisy token representations, an associated denoising operation naturally\ntakes the form of a multi-head (subspace) self-attention. By unrolling such\niterative denoising operations into a deep network, we arrive at a highly\ncompact architecture that consists of \\textit{only} self-attention operators\nwith skip connections at each layer. Moreover, we show that each layer performs\nhighly efficient denoising: it improves the signal-to-noise ratio of token\nrepresentations \\textit{at a linear rate} with respect to the number of layers.\nDespite its simplicity, extensive experiments on vision and language tasks\ndemonstrate that such a transformer achieves performance close to that of\nstandard transformer architectures such as GPT-2 and CRATE.", "AI": {"tldr": "The paper proposes a fully interpretable transformer architecture derived from denoising noisy token representations, achieving performance close to standard transformers like GPT-2 and CRATE.", "motivation": "Current transformer architectures are empirically designed, redundant, and lack interpretability. The goal is to create a mathematically justified, compact, and interpretable transformer.", "method": "The method involves compressing noisy token representations into low-dimensional subspaces using multi-head self-attention, unrolled into a deep network with skip connections.", "result": "The compact architecture achieves linear-rate denoising per layer and performs comparably to standard transformers in vision and language tasks.", "conclusion": "The proposed interpretable transformer is efficient, compact, and competitive with empirical designs, offering a mathematically grounded alternative."}}
{"id": "2506.03781", "pdf": "https://arxiv.org/pdf/2506.03781", "abs": "https://arxiv.org/abs/2506.03781", "authors": ["Seungcheol Park", "Jeongin Bae", "Beomseok Kwon", "Minjun Kim", "Byeongwook Kim", "Se Jung Kwon", "U Kang", "Dongsoo Lee"], "title": "Unifying Uniform and Binary-coding Quantization for Accurate Compression of Large Language Models", "categories": ["cs.CL", "68T50", "I.2.7"], "comment": "ACL 2025 Main Track", "summary": "How can we quantize large language models while preserving accuracy?\nQuantization is essential for deploying large language models (LLMs)\nefficiently. Binary-coding quantization (BCQ) and uniform quantization (UQ) are\npromising quantization schemes that have strong expressiveness and\noptimizability, respectively. However, neither scheme leverages both\nadvantages. In this paper, we propose UniQuanF (Unified Quantization with\nFlexible Mapping), an accurate quantization method for LLMs. UniQuanF harnesses\nboth strong expressiveness and optimizability by unifying the flexible mapping\ntechnique in UQ and non-uniform quantization levels of BCQ. We propose unified\ninitialization, and local and periodic mapping techniques to optimize the\nparameters in UniQuanF precisely. After optimization, our unification theorem\nremoves computational and memory overhead, allowing us to utilize the superior\naccuracy of UniQuanF without extra deployment costs induced by the unification.\nExperimental results demonstrate that UniQuanF outperforms existing UQ and BCQ\nmethods, achieving up to 4.60% higher accuracy on GSM8K benchmark.", "AI": {"tldr": "UniQuanF unifies BCQ and UQ for efficient LLM quantization, achieving higher accuracy without extra deployment costs.", "motivation": "Current quantization schemes (BCQ and UQ) lack combined expressiveness and optimizability, limiting LLM deployment efficiency.", "method": "UniQuanF integrates flexible mapping (UQ) and non-uniform levels (BCQ), with unified initialization and optimization techniques.", "result": "UniQuanF outperforms BCQ and UQ, achieving up to 4.60% higher accuracy on GSM8K.", "conclusion": "UniQuanF provides a superior, cost-free quantization solution for LLMs by unifying BCQ and UQ strengths."}}
{"id": "2506.03643", "pdf": "https://arxiv.org/pdf/2506.03643", "abs": "https://arxiv.org/abs/2506.03643", "authors": ["Lingjun Mao", "Rodolfo Corona", "Xin Liang", "Wenhao Yan", "Zineng Tang"], "title": "Images are Worth Variable Length of Representations", "categories": ["cs.CV"], "comment": null, "summary": "Most existing vision encoders map images into a fixed-length sequence of\ntokens, overlooking the fact that different images contain varying amounts of\ninformation. For example, a visually complex image (e.g., a cluttered room)\ninherently carries more information and thus deserves more tokens than a simple\nimage (e.g., a blank wall). To address this inefficiency, we propose DOVE, a\ndynamic vision encoder that produces a variable number of visual tokens (i.e.,\ncontinuous representation vectors) to reconstruct each image. Our results show\nthat DOVE significantly reduces the average number of tokens while maintaining\nhigh reconstruction quality. In several linear probing and downstream\nmultimodal tasks, it outperforms existing autoencoder-based tokenization\nmethods when using far fewer tokens, capturing more expressive semantic\nfeatures compared to fixed-length encoding. We further extend DOVE with\nquery-conditioned tokenization. By guiding the model to focus on query-relevant\nregions, it achieves more efficient and targeted semantic extraction. Our code\nand checkpoints are available at https://dove-encoder.github.io/dove-encoder.", "AI": {"tldr": "DOVE is a dynamic vision encoder that adapts token count per image based on complexity, improving efficiency and semantic feature capture.", "motivation": "Fixed-length token sequences in vision encoders ignore varying image information, leading to inefficiency.", "method": "DOVE dynamically adjusts token count per image and introduces query-conditioned tokenization for targeted feature extraction.", "result": "DOVE reduces token count while maintaining quality, outperforming fixed-length methods in tasks.", "conclusion": "DOVE offers efficient, adaptive tokenization with superior semantic feature extraction."}}
{"id": "2506.03785", "pdf": "https://arxiv.org/pdf/2506.03785", "abs": "https://arxiv.org/abs/2506.03785", "authors": ["Isik Baran Sandan", "Tu Anh Dinh", "Jan Niehues"], "title": "Knockout LLM Assessment: Using Large Language Models for Evaluations through Iterative Pairwise Comparisons", "categories": ["cs.CL", "cs.AI", "I.2.7"], "comment": "4 pages, 2 figures", "summary": "Large Language Models (LLMs) have shown to be effective evaluators across\nvarious domains such as machine translations or the scientific domain. Current\nLLM-as-a-Judge approaches rely mostly on individual assessments or a single\nround of pairwise assessments, preventing the judge LLM from developing a\nglobal ranking perspective. To address this, we present Knockout Assessment, an\nLLM-asa Judge method using a knockout tournament system with iterative pairwise\ncomparisons. Experiments across three LLMs on two datasets show that knockout\nassessment improves scoring accuracy, increasing Pearson correlation with\nexpert evaluations by 0.07 on average for university-level exam scoring and\nmachine translation evaluations, aligning LLM assessments more closely with\nhuman scoring.", "AI": {"tldr": "Knockout Assessment improves LLM-as-a-Judge accuracy by using iterative pairwise comparisons in a knockout tournament system.", "motivation": "Current LLM-as-a-Judge methods lack a global ranking perspective due to reliance on individual or single-round pairwise assessments.", "method": "Proposes Knockout Assessment, a tournament-based iterative pairwise comparison method for LLMs.", "result": "Improves scoring accuracy, increasing Pearson correlation with expert evaluations by 0.07 on average.", "conclusion": "Knockout Assessment aligns LLM evaluations more closely with human scoring."}}
{"id": "2506.03802", "pdf": "https://arxiv.org/pdf/2506.03802", "abs": "https://arxiv.org/abs/2506.03802", "authors": ["Andreas Athanasopoulos", "Christos Dimitrakakis"], "title": "Learning Equilibria in Matching Games with Bandit Feedback", "categories": ["cs.LG"], "comment": "21 pages, 2 figures", "summary": "We investigate the problem of learning an equilibrium in a generalized\ntwo-sided matching market, where agents can adaptively choose their actions\nbased on their assigned matches. Specifically, we consider a setting in which\nmatched agents engage in a zero-sum game with initially unknown payoff\nmatrices, and we explore whether a centralized procedure can learn an\nequilibrium from bandit feedback. We adopt the solution concept of matching\nequilibrium, where a pair consisting of a matching $\\mathfrak{m}$ and a set of\nagent strategies $X$ forms an equilibrium if no agent has the incentive to\ndeviate from $(\\mathfrak{m}, X)$. To measure the deviation of a given pair\n$(\\mathfrak{m}, X)$ from the equilibrium pair $(\\mathfrak{m}^\\star, X^\\star)$,\nwe introduce matching instability that can serve as a regret measure for the\ncorresponding learning problem. We then propose a UCB algorithm in which agents\nform preferences and select actions based on optimistic estimates of the game\npayoffs, and prove that it achieves sublinear, instance-independent regret over\na time horizon $T$.", "AI": {"tldr": "The paper explores learning equilibria in a two-sided matching market where agents adaptively choose actions based on matches, using a UCB algorithm to achieve sublinear regret.", "motivation": "To address the challenge of learning equilibria in dynamic matching markets with initially unknown payoff matrices, where agents' actions influence outcomes.", "method": "A UCB algorithm is proposed, where agents form preferences and select actions based on optimistic payoff estimates, aiming for sublinear regret.", "result": "The algorithm achieves sublinear, instance-independent regret over time horizon T, demonstrating its effectiveness.", "conclusion": "The study successfully introduces a method for learning equilibria in adaptive matching markets, with theoretical guarantees on regret."}}
{"id": "2506.03793", "pdf": "https://arxiv.org/pdf/2506.03793", "abs": "https://arxiv.org/abs/2506.03793", "authors": ["Sidharth Pulipaka", "Sparsh Jain", "Ashwin Sankar", "Raj Dabre"], "title": "Mark My Words: A Robust Multilingual Model for Punctuation in Text and Speech Transcripts", "categories": ["cs.CL"], "comment": "Work in Progress", "summary": "Punctuation plays a vital role in structuring meaning, yet current models\noften struggle to restore it accurately in transcripts of spontaneous speech,\nespecially in the presence of disfluencies such as false starts and\nbacktracking. These limitations hinder the performance of downstream tasks like\ntranslation, text to speech, summarization, etc. where sentence boundaries are\ncritical for preserving quality. In this work, we introduce Cadence, a\ngeneralist punctuation restoration model adapted from a pretrained large\nlanguage model. Cadence is designed to handle both clean written text and\nhighly spontaneous spoken transcripts. It surpasses the previous state of the\nart in performance while expanding support from 14 to all 22 Indian languages\nand English. We conduct a comprehensive analysis of model behavior across\npunctuation types and language families, identifying persistent challenges\nunder domain shift and with rare punctuation marks. Our findings demonstrate\nthe efficacy of utilizing pretrained language models for multilingual\npunctuation restoration and highlight Cadence practical value for low resource\nNLP pipelines at scale.", "AI": {"tldr": "Cadence, a punctuation restoration model, outperforms state-of-the-art methods for multilingual and spontaneous speech transcripts, addressing challenges in NLP tasks.", "motivation": "Current models struggle with punctuation restoration in spontaneous speech, impacting downstream NLP tasks like translation and summarization.", "method": "Cadence, adapted from a pretrained large language model, handles clean text and spontaneous speech, supporting 22 Indian languages and English.", "result": "Cadence surpasses previous models in performance, though challenges remain with domain shift and rare punctuation marks.", "conclusion": "Pretrained language models are effective for multilingual punctuation restoration, with Cadence offering practical value for low-resource NLP pipelines."}}
{"id": "2506.03652", "pdf": "https://arxiv.org/pdf/2506.03652", "abs": "https://arxiv.org/abs/2506.03652", "authors": ["Cheng Zhang", "Hongxia xie", "Bin Wen", "Songhan Zuo", "Ruoxuan Zhang", "Wen-huang Cheng"], "title": "EmoArt: A Multidimensional Dataset for Emotion-Aware Artistic Generation", "categories": ["cs.CV"], "comment": null, "summary": "With the rapid advancement of diffusion models, text-to-image generation has\nachieved significant progress in image resolution, detail fidelity, and\nsemantic alignment, particularly with models like Stable Diffusion 3.5, Stable\nDiffusion XL, and FLUX 1. However, generating emotionally expressive and\nabstract artistic images remains a major challenge, largely due to the lack of\nlarge-scale, fine-grained emotional datasets. To address this gap, we present\nthe EmoArt Dataset -- one of the most comprehensive emotion-annotated art\ndatasets to date. It contains 132,664 artworks across 56 painting styles (e.g.,\nImpressionism, Expressionism, Abstract Art), offering rich stylistic and\ncultural diversity. Each image includes structured annotations: objective scene\ndescriptions, five key visual attributes (brushwork, composition, color, line,\nlight), binary arousal-valence labels, twelve emotion categories, and potential\nart therapy effects. Using EmoArt, we systematically evaluate popular\ntext-to-image diffusion models for their ability to generate emotionally\naligned images from text. Our work provides essential data and benchmarks for\nemotion-driven image synthesis and aims to advance fields such as affective\ncomputing, multimodal learning, and computational art, enabling applications in\nart therapy and creative design. The dataset and more details can be accessed\nvia our project website.", "AI": {"tldr": "The paper introduces the EmoArt Dataset, a comprehensive emotion-annotated art dataset, to address challenges in generating emotionally expressive and abstract artistic images using text-to-image diffusion models.", "motivation": "Existing text-to-image models lack the ability to generate emotionally expressive and abstract art due to the absence of large-scale, fine-grained emotional datasets.", "method": "The authors present the EmoArt Dataset, containing 132,664 artworks with structured annotations, and evaluate popular text-to-image diffusion models for emotional alignment.", "result": "The dataset provides benchmarks for emotion-driven image synthesis, aiding fields like affective computing, multimodal learning, and computational art.", "conclusion": "The EmoArt Dataset advances emotion-driven image generation and supports applications in art therapy and creative design."}}
{"id": "2506.03827", "pdf": "https://arxiv.org/pdf/2506.03827", "abs": "https://arxiv.org/abs/2506.03827", "authors": ["Zhenhui Liu", "Chunyuan Yuan", "Ming Pang", "Zheng Fang", "Li Yuan", "Xue Jiang", "Changping Peng", "Zhangang Lin", "Zheng Luo", "Jingping Shao"], "title": "Multi-objective Aligned Bidword Generation Model for E-commerce Search Advertising", "categories": ["cs.CL", "cs.AI", "cs.IR"], "comment": "Accepted by SIGIR2025", "summary": "Retrieval systems primarily address the challenge of matching user queries\nwith the most relevant advertisements, playing a crucial role in e-commerce\nsearch advertising. The diversity of user needs and expressions often produces\nmassive long-tail queries that cannot be matched with merchant bidwords or\nproduct titles, which results in some advertisements not being recalled,\nultimately harming user experience and search efficiency. Existing query\nrewriting research focuses on various methods such as query log mining,\nquery-bidword vector matching, or generation-based rewriting. However, these\nmethods often fail to simultaneously optimize the relevance and authenticity of\nthe user's original query and rewrite and maximize the revenue potential of\nrecalled ads.\n  In this paper, we propose a Multi-objective aligned Bidword Generation Model\n(MoBGM), which is composed of a discriminator, generator, and preference\nalignment module, to address these challenges. To simultaneously improve the\nrelevance and authenticity of the query and rewrite and maximize the platform\nrevenue, we design a discriminator to optimize these key objectives. Using the\nfeedback signal of the discriminator, we train a multi-objective aligned\nbidword generator that aims to maximize the combined effect of the three\nobjectives. Extensive offline and online experiments show that our proposed\nalgorithm significantly outperforms the state of the art. After deployment, the\nalgorithm has created huge commercial value for the platform, further verifying\nits feasibility and robustness.", "AI": {"tldr": "The paper introduces MoBGM, a multi-objective model for query rewriting in e-commerce search ads, improving relevance, authenticity, and revenue.", "motivation": "Addressing the gap in existing query rewriting methods that fail to optimize relevance, authenticity, and revenue simultaneously.", "method": "Proposes MoBGM with a discriminator, generator, and preference alignment module to align and optimize multiple objectives.", "result": "Outperforms state-of-the-art methods in offline and online tests, creating significant commercial value.", "conclusion": "MoBGM is feasible, robust, and effective for enhancing search ad retrieval systems."}}
{"id": "2506.03813", "pdf": "https://arxiv.org/pdf/2506.03813", "abs": "https://arxiv.org/abs/2506.03813", "authors": ["Lili Chen", "Changyang She", "Jingge Zhu", "Jamie Evans"], "title": "Graph Neural Networks for Resource Allocation in Multi-Channel Wireless Networks", "categories": ["cs.LG", "eess.SP"], "comment": null, "summary": "As the number of mobile devices continues to grow, interference has become a\nmajor bottleneck in improving data rates in wireless networks. Efficient joint\nchannel and power allocation (JCPA) is crucial for managing interference. In\nthis paper, we first propose an enhanced WMMSE (eWMMSE) algorithm to solve the\nJCPA problem in multi-channel wireless networks. To reduce the computational\ncomplexity of iterative optimization, we further introduce JCPGNN-M, a graph\nneural network-based solution that enables simultaneous multi-channel\nallocation for each user. We reformulate the problem as a Lagrangian function,\nwhich allows us to enforce the total power constraints systematically. Our\nsolution involves combining this Lagrangian framework with GNNs and iteratively\nupdating the Lagrange multipliers and resource allocation scheme. Unlike\nexisting GNN-based methods that limit each user to a single channel, JCPGNN-M\nsupports efficient spectrum reuse and scales well in dense network scenarios.\nSimulation results show that JCPGNN-M achieves better data rate compared to\neWMMSE. Meanwhile, the inference time of JCPGNN-M is much lower than eWMMS, and\nit can generalize well to larger networks.", "AI": {"tldr": "Proposed JCPGNN-M, a GNN-based solution for joint channel and power allocation, outperforming eWMMSE in data rates and computational efficiency.", "motivation": "Interference in wireless networks hinders data rate improvements, necessitating efficient joint channel and power allocation methods.", "method": "Introduced eWMMSE and JCPGNN-M, combining Lagrangian framework with GNNs for multi-channel allocation and power constraints.", "result": "JCPGNN-M achieves higher data rates, lower inference time, and better scalability than eWMMSE.", "conclusion": "JCPGNN-M is a scalable, efficient solution for dense wireless networks, outperforming traditional iterative methods."}}
{"id": "2506.03820", "pdf": "https://arxiv.org/pdf/2506.03820", "abs": "https://arxiv.org/abs/2506.03820", "authors": ["Ahmad Mustapha Wali", "Sergiu Nisioi"], "title": "Automatic Correction of Writing Anomalies in Hausa Texts", "categories": ["cs.CL"], "comment": null, "summary": "Hausa texts are often characterized by writing anomalies such as incorrect\ncharacter substitutions and spacing errors, which sometimes hinder natural\nlanguage processing (NLP) applications. This paper presents an approach to\nautomatically correct the anomalies by finetuning transformer-based models.\nUsing a corpus gathered from several public sources, we created a large-scale\nparallel dataset of over 450,000 noisy-clean Hausa sentence pairs by\nintroducing synthetically generated noise, fine-tuned to mimic realistic\nwriting errors. Moreover, we adapted several multilingual and African\nlanguage-focused models, including M2M100, AfriTEVA, mBART, and Opus-MT\nvariants for this correction task using SentencePiece tokenization. Our\nexperimental results demonstrate significant increases in F1, BLEU and METEOR\nscores, as well as reductions in Character Error Rate (CER) and Word Error Rate\n(WER). This research provides a robust methodology, a publicly available\ndataset, and effective models to improve Hausa text quality, thereby advancing\nNLP capabilities for the language and offering transferable insights for other\nlow-resource languages.", "AI": {"tldr": "The paper introduces a method to correct writing anomalies in Hausa texts using transformer-based models, achieving improved NLP metrics.", "motivation": "Hausa texts often contain writing errors that hinder NLP applications, necessitating automated correction solutions.", "method": "The approach involves fine-tuning transformer models (M2M100, AfriTEVA, mBART, Opus-MT) on a synthetic parallel dataset of 450,000 noisy-clean Hausa sentences.", "result": "Experiments show significant improvements in F1, BLEU, METEOR scores, and reductions in CER and WER.", "conclusion": "The study provides a robust methodology, dataset, and models to enhance Hausa text quality, benefiting NLP for low-resource languages."}}
{"id": "2506.03660", "pdf": "https://arxiv.org/pdf/2506.03660", "abs": "https://arxiv.org/abs/2506.03660", "authors": ["Wei Luo", "Haiming Yao", "Yunkang Cao", "Qiyu Chen", "Ang Gao", "Weiming Shen", "Weihang Zhang", "Wenyong Yu"], "title": "INP-Former++: Advancing Universal Anomaly Detection via Intrinsic Normal Prototypes and Residual Learning", "categories": ["cs.CV"], "comment": "15 pages, 11 figures, 13 tables", "summary": "Anomaly detection (AD) is essential for industrial inspection and medical\ndiagnosis, yet existing methods typically rely on ``comparing'' test images to\nnormal references from a training set. However, variations in appearance and\npositioning often complicate the alignment of these references with the test\nimage, limiting detection accuracy. We observe that most anomalies manifest as\nlocal variations, meaning that even within anomalous images, valuable normal\ninformation remains. We argue that this information is useful and may be more\naligned with the anomalies since both the anomalies and the normal information\noriginate from the same image. Therefore, rather than relying on external\nnormality from the training set, we propose INP-Former, a novel method that\nextracts Intrinsic Normal Prototypes (INPs) directly from the test image.\nSpecifically, we introduce the INP Extractor, which linearly combines normal\ntokens to represent INPs. We further propose an INP Coherence Loss to ensure\nINPs can faithfully represent normality for the testing image. These INPs then\nguide the INP-guided Decoder to reconstruct only normal tokens, with\nreconstruction errors serving as anomaly scores. Additionally, we propose a\nSoft Mining Loss to prioritize hard-to-optimize samples during training.\nINP-Former achieves state-of-the-art performance in single-class, multi-class,\nand few-shot AD tasks across MVTec-AD, VisA, and Real-IAD, positioning it as a\nversatile and universal solution for AD. Remarkably, INP-Former also\ndemonstrates some zero-shot AD capability. Furthermore, we propose a soft\nversion of the INP Coherence Loss and enhance INP-Former by incorporating\nresidual learning, leading to the development of INP-Former++. The proposed\nmethod significantly improves detection performance across single-class,\nmulti-class, semi-supervised, few-shot, and zero-shot settings.", "AI": {"tldr": "INP-Former is a novel anomaly detection method that extracts intrinsic normal prototypes (INPs) from test images, avoiding reliance on external references. It achieves state-of-the-art performance across various tasks and settings, including zero-shot detection.", "motivation": "Existing anomaly detection methods rely on external normal references, which may misalign with test images due to variations. INP-Former leverages intrinsic normal information within the test image itself for better alignment and accuracy.", "method": "INP-Former extracts INPs from test images using an INP Extractor and ensures their coherence with a dedicated loss. An INP-guided Decoder reconstructs normal tokens, with reconstruction errors indicating anomalies. A Soft Mining Loss prioritizes hard samples during training.", "result": "INP-Former outperforms existing methods in single-class, multi-class, and few-shot anomaly detection tasks. It also shows zero-shot capability and is further improved in INP-Former++.", "conclusion": "INP-Former is a versatile and universal solution for anomaly detection, leveraging intrinsic normal information for superior performance across diverse settings."}}
{"id": "2506.03837", "pdf": "https://arxiv.org/pdf/2506.03837", "abs": "https://arxiv.org/abs/2506.03837", "authors": ["Xiao-Qi Han", "Ze-Feng Gao", "Xin-De Wang", "Zhenfeng Ouyang", "Peng-Jie Guo", "Zhong-Yi Lu"], "title": "HTSC-2025: A Benchmark Dataset of Ambient-Pressure High-Temperature Superconductors for AI-Driven Critical Temperature Prediction", "categories": ["cond-mat.supr-con", "cond-mat.mtrl-sci", "cs.AI", "cs.LG"], "comment": "7 pages, 2 figures", "summary": "The discovery of high-temperature superconducting materials holds great\nsignificance for human industry and daily life. In recent years, research on\npredicting superconducting transition temperatures using artificial\nintelligence~(AI) has gained popularity, with most of these tools claiming to\nachieve remarkable accuracy. However, the lack of widely accepted benchmark\ndatasets in this field has severely hindered fair comparisons between different\nAI algorithms and impeded further advancement of these methods. In this work,\nwe present the HTSC-2025, an ambient-pressure high-temperature superconducting\nbenchmark dataset. This comprehensive compilation encompasses theoretically\npredicted superconducting materials discovered by theoretical physicists from\n2023 to 2025 based on BCS superconductivity theory, including the renowned\nX$_2$YH$_6$ system, perovskite MXH$_3$ system, M$_3$XH$_8$ system, cage-like\nBCN-doped metal atomic systems derived from LaH$_{10}$ structural evolution,\nand two-dimensional honeycomb-structured systems evolving from MgB$_2$. The\nHTSC-2025 benchmark has been open-sourced at\nhttps://github.com/xqh19970407/HTSC-2025 and will be continuously updated. This\nbenchmark holds significant importance for accelerating the discovery of\nsuperconducting materials using AI-based methods.", "AI": {"tldr": "The paper introduces HTSC-2025, a benchmark dataset for high-temperature superconductors, addressing the lack of standardized data for AI-based predictions.", "motivation": "The absence of widely accepted benchmark datasets in high-temperature superconductor research hinders fair AI algorithm comparisons and progress.", "method": "The authors compile HTSC-2025, a dataset of theoretically predicted superconducting materials (2023-2025) based on BCS theory, including various systems like X$_2$YH$_6$ and perovskite MXH$_3$.", "result": "The HTSC-2025 dataset is open-sourced and will be updated, providing a standardized resource for AI-driven superconductor discovery.", "conclusion": "HTSC-2025 is a crucial step toward accelerating AI-based discovery of high-temperature superconducting materials."}}
{"id": "2506.03817", "pdf": "https://arxiv.org/pdf/2506.03817", "abs": "https://arxiv.org/abs/2506.03817", "authors": ["Julius Gonsior", "Tim Rie\u00df", "Anja Reusch", "Claudio Hartmann", "Maik Thiele", "Wolfgang Lehner"], "title": "Survey of Active Learning Hyperparameters: Insights from a Large-Scale Experimental Grid", "categories": ["cs.LG"], "comment": null, "summary": "Annotating data is a time-consuming and costly task, but it is inherently\nrequired for supervised machine learning. Active Learning (AL) is an\nestablished method that minimizes human labeling effort by iteratively\nselecting the most informative unlabeled samples for expert annotation, thereby\nimproving the overall classification performance. Even though AL has been known\nfor decades, AL is still rarely used in real-world applications. As indicated\nin the two community web surveys among the NLP community about AL, two main\nreasons continue to hold practitioners back from using AL: first, the\ncomplexity of setting AL up, and second, a lack of trust in its effectiveness.\nWe hypothesize that both reasons share the same culprit: the large\nhyperparameter space of AL. This mostly unexplored hyperparameter space often\nleads to misleading and irreproducible AL experiment results. In this study, we\nfirst compiled a large hyperparameter grid of over 4.6 million hyperparameter\ncombinations, second, recorded the performance of all combinations in the\nso-far biggest conducted AL study, and third, analyzed the impact of each\nhyperparameter in the experiment results. In the end, we give recommendations\nabout the influence of each hyperparameter, demonstrate the surprising\ninfluence of the concrete AL strategy implementation, and outline an\nexperimental study design for reproducible AL experiments with minimal\ncomputational effort, thus contributing to more reproducible and trustworthy AL\nresearch in the future.", "AI": {"tldr": "Active Learning (AL) reduces labeling effort but is underused due to setup complexity and trust issues. This study explores AL's hyperparameter space, analyzes impacts, and provides recommendations for reproducible research.", "motivation": "AL is rarely used in practice due to its complex setup and perceived ineffectiveness, likely caused by its large, unexplored hyperparameter space.", "method": "The study compiled a hyperparameter grid of 4.6M combinations, recorded their performance in a large AL study, and analyzed each hyperparameter's impact.", "result": "Findings highlight hyperparameter influence, AL strategy implementation effects, and propose a study design for reproducible AL experiments.", "conclusion": "The study aims to improve AL's reproducibility and trustworthiness by clarifying hyperparameter impacts and suggesting efficient experimental designs."}}
{"id": "2506.03822", "pdf": "https://arxiv.org/pdf/2506.03822", "abs": "https://arxiv.org/abs/2506.03822", "authors": ["Fabian Karl", "Ansgar Scherp"], "title": "CRAWLDoc: A Dataset for Robust Ranking of Bibliographic Documents", "categories": ["cs.CL", "cs.IR"], "comment": "Accepted at SCOLIA 2025", "summary": "Publication databases rely on accurate metadata extraction from diverse web\nsources, yet variations in web layouts and data formats present challenges for\nmetadata providers. This paper introduces CRAWLDoc, a new method for contextual\nranking of linked web documents. Starting with a publication's URL, such as a\ndigital object identifier, CRAWLDoc retrieves the landing page and all linked\nweb resources, including PDFs, ORCID profiles, and supplementary materials. It\nembeds these resources, along with anchor texts and the URLs, into a unified\nrepresentation. For evaluating CRAWLDoc, we have created a new, manually\nlabeled dataset of 600 publications from six top publishers in computer\nscience. Our method CRAWLDoc demonstrates a robust and layout-independent\nranking of relevant documents across publishers and data formats. It lays the\nfoundation for improved metadata extraction from web documents with various\nlayouts and formats. Our source code and dataset can be accessed at\nhttps://github.com/FKarl/CRAWLDoc.", "AI": {"tldr": "CRAWLDoc is a method for contextual ranking of linked web documents to improve metadata extraction from diverse web sources.", "motivation": "Challenges in metadata extraction due to varying web layouts and data formats.", "method": "CRAWLDoc retrieves and embeds linked resources (PDFs, ORCID profiles, etc.) into a unified representation for ranking.", "result": "Demonstrates robust, layout-independent ranking on a manually labeled dataset of 600 publications.", "conclusion": "CRAWLDoc improves metadata extraction across diverse web layouts and formats; code and dataset are publicly available."}}
{"id": "2506.03662", "pdf": "https://arxiv.org/pdf/2506.03662", "abs": "https://arxiv.org/abs/2506.03662", "authors": ["Erhang Zhang", "Junyi Ma", "Yin-Dong Zheng", "Yixuan Zhou", "Hesheng Wang"], "title": "Zero-Shot Temporal Interaction Localization for Egocentric Videos", "categories": ["cs.CV", "cs.RO"], "comment": null, "summary": "Locating human-object interaction (HOI) actions within video serves as the\nfoundation for multiple downstream tasks, such as human behavior analysis and\nhuman-robot skill transfer. Current temporal action localization methods\ntypically rely on annotated action and object categories of interactions for\noptimization, which leads to domain bias and low deployment efficiency.\nAlthough some recent works have achieved zero-shot temporal action localization\n(ZS-TAL) with large vision-language models (VLMs), their coarse-grained\nestimations and open-loop pipelines hinder further performance improvements for\ntemporal interaction localization (TIL). To address these issues, we propose a\nnovel zero-shot TIL approach dubbed EgoLoc to locate the timings of grasp\nactions for human-object interaction in egocentric videos. EgoLoc introduces a\nself-adaptive sampling strategy to generate reasonable visual prompts for VLM\nreasoning. By absorbing both 2D and 3D observations, it directly samples\nhigh-quality initial guesses around the possible contact/separation timestamps\nof HOI according to 3D hand velocities, leading to high inference accuracy and\nefficiency. In addition, EgoLoc generates closed-loop feedback from visual and\ndynamic cues to further refine the localization results. Comprehensive\nexperiments on the publicly available dataset and our newly proposed benchmark\ndemonstrate that EgoLoc achieves better temporal interaction localization for\negocentric videos compared to state-of-the-art baselines. We will release our\ncode and relevant data as open-source at https://github.com/IRMVLab/EgoLoc.", "AI": {"tldr": "EgoLoc is a zero-shot TIL method for egocentric videos, using self-adaptive sampling and closed-loop feedback to improve grasp action localization.", "motivation": "Current methods rely on annotated data, causing domain bias and inefficiency, while existing ZS-TAL approaches lack precision.", "method": "EgoLoc uses 2D/3D observations and hand velocities for sampling, with closed-loop feedback for refinement.", "result": "Outperforms state-of-the-art baselines in temporal interaction localization.", "conclusion": "EgoLoc offers high accuracy and efficiency for HOI action localization in egocentric videos."}}
{"id": "2506.03872", "pdf": "https://arxiv.org/pdf/2506.03872", "abs": "https://arxiv.org/abs/2506.03872", "authors": ["Yang Xiao", "Guoan Xu", "Qiang Wu", "Wenjing Jia"], "title": "JointSplat: Probabilistic Joint Flow-Depth Optimization for Sparse-View Gaussian Splatting", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Reconstructing 3D scenes from sparse viewpoints is a long-standing challenge\nwith wide applications. Recent advances in feed-forward 3D Gaussian sparse-view\nreconstruction methods provide an efficient solution for real-time novel view\nsynthesis by leveraging geometric priors learned from large-scale multi-view\ndatasets and computing 3D Gaussian centers via back-projection. Despite\noffering strong geometric cues, both feed-forward multi-view depth estimation\nand flow-depth joint estimation face key limitations: the former suffers from\nmislocation and artifact issues in low-texture or repetitive regions, while the\nlatter is prone to local noise and global inconsistency due to unreliable\nmatches when ground-truth flow supervision is unavailable. To overcome this, we\npropose JointSplat, a unified framework that leverages the complementarity\nbetween optical flow and depth via a novel probabilistic optimization\nmechanism. Specifically, this pixel-level mechanism scales the information\nfusion between depth and flow based on the matching probability of optical flow\nduring training. Building upon the above mechanism, we further propose a novel\nmulti-view depth-consistency loss to leverage the reliability of supervision\nwhile suppressing misleading gradients in uncertain areas. Evaluated on\nRealEstate10K and ACID, JointSplat consistently outperforms state-of-the-art\n(SOTA) methods, demonstrating the effectiveness and robustness of our proposed\nprobabilistic joint flow-depth optimization approach for high-fidelity\nsparse-view 3D reconstruction.", "AI": {"tldr": "JointSplat is a unified framework for sparse-view 3D reconstruction, combining optical flow and depth via probabilistic optimization, outperforming SOTA methods.", "motivation": "Addressing limitations in existing methods (mislocation, artifacts, noise, inconsistency) for sparse-view 3D reconstruction.", "method": "Uses a probabilistic optimization mechanism to fuse depth and flow, with a multi-view depth-consistency loss.", "result": "Outperforms SOTA on RealEstate10K and ACID, showing robustness and high fidelity.", "conclusion": "JointSplat effectively combines flow and depth for superior sparse-view 3D reconstruction."}}
{"id": "2506.03835", "pdf": "https://arxiv.org/pdf/2506.03835", "abs": "https://arxiv.org/abs/2506.03835", "authors": ["Jianyuan Yin", "Qianxiao Li"], "title": "Learning task-specific predictive models for scientific computing", "categories": ["cs.LG"], "comment": null, "summary": "We consider learning a predictive model to be subsequently used for a given\ndownstream task (described by an algorithm) that requires access to the model\nevaluation. This task need not be prediction, and this situation is frequently\nencountered in machine-learning-augmented scientific computing. We show that\nthis setting differs from classical supervised learning, and in general it\ncannot be solved by minimizing the mean square error of the model predictions\nas is frequently performed in the literature. Instead, we find that the maximum\nprediction error on the support of the downstream task algorithm can serve as\nan effective estimate for the subsequent task performance. With this insight,\nwe formulate a task-specific supervised learning problem based on the given\nsampling measure, whose solution serves as a reliable surrogate model for the\ndownstream task. Then, we discretize the empirical risk based on training data,\nand develop an iterative algorithm to solve the task-specific supervised\nlearning problem. Three illustrative numerical examples on trajectory\nprediction, optimal control and minimum energy path computation demonstrate the\neffectiveness of the approach.", "AI": {"tldr": "The paper proposes a task-specific supervised learning approach for downstream tasks in machine-learning-augmented scientific computing, focusing on maximum prediction error instead of mean square error.", "motivation": "Traditional supervised learning methods, like minimizing mean square error, are inadequate for downstream tasks that require model evaluation beyond prediction.", "method": "Formulates a task-specific supervised learning problem using maximum prediction error, discretizes empirical risk, and develops an iterative algorithm.", "result": "Demonstrates effectiveness through numerical examples in trajectory prediction, optimal control, and minimum energy path computation.", "conclusion": "The approach provides a reliable surrogate model for downstream tasks, outperforming traditional methods."}}
{"id": "2506.03861", "pdf": "https://arxiv.org/pdf/2506.03861", "abs": "https://arxiv.org/abs/2506.03861", "authors": ["Qiuhan Han", "Qian Wang", "Atsushi Yoshikawa", "Masayuki Yamamura"], "title": "PulseReddit: A Novel Reddit Dataset for Benchmarking MAS in High-Frequency Cryptocurrency Trading", "categories": ["cs.CL"], "comment": null, "summary": "High-Frequency Trading (HFT) is pivotal in cryptocurrency markets, demanding\nrapid decision-making. Social media platforms like Reddit offer valuable, yet\nunderexplored, information for such high-frequency, short-term trading. This\npaper introduces \\textbf{PulseReddit}, a novel dataset that is the first to\nalign large-scale Reddit discussion data with high-frequency cryptocurrency\nmarket statistics for short-term trading analysis. We conduct an extensive\nempirical study using Large Language Model (LLM)-based Multi-Agent Systems\n(MAS) to investigate the impact of social sentiment from PulseReddit on trading\nperformance. Our experiments conclude that MAS augmented with PulseReddit data\nachieve superior trading outcomes compared to traditional baselines,\nparticularly in bull markets, and demonstrate robust adaptability across\ndifferent market regimes. Furthermore, our research provides conclusive\ninsights into the performance-efficiency trade-offs of different LLMs,\ndetailing significant considerations for practical model selection in HFT\napplications. PulseReddit and our findings establish a foundation for advanced\nMAS research in HFT, demonstrating the tangible benefits of integrating social\nmedia.", "AI": {"tldr": "PulseReddit dataset aligns Reddit discussions with cryptocurrency market stats for HFT. LLM-based MAS using PulseReddit outperforms baselines, especially in bull markets, and adapts well across market regimes.", "motivation": "Social media like Reddit offers untapped data for HFT, but its impact on short-term trading is underexplored.", "method": "Introduces PulseReddit dataset and uses LLM-based MAS to analyze social sentiment's effect on trading performance.", "result": "MAS with PulseReddit data achieves better trading outcomes, particularly in bull markets, and adapts to various market conditions.", "conclusion": "PulseReddit and findings highlight social media's value in HFT, offering insights for LLM selection and MAS research."}}
{"id": "2506.03664", "pdf": "https://arxiv.org/pdf/2506.03664", "abs": "https://arxiv.org/abs/2506.03664", "authors": ["Valerie Krug", "Sebastian Stober"], "title": "Intersectional Bias in Pre-Trained Image Recognition Models", "categories": ["cs.CV", "cs.CY", "cs.HC", "cs.LG"], "comment": "Summary paper accepted at the 3rd TRR 318 Conference: Contextualizing\n  Explanations 2025", "summary": "Deep Learning models have achieved remarkable success. Training them is often\naccelerated by building on top of pre-trained models which poses the risk of\nperpetuating encoded biases. Here, we investigate biases in the representations\nof commonly used ImageNet classifiers for facial images while considering\nintersections of sensitive variables age, race and gender. To assess the\nbiases, we use linear classifier probes and visualize activations as\ntopographic maps. We find that representations in ImageNet classifiers\nparticularly allow differentiation between ages. Less strongly pronounced, the\nmodels appear to associate certain ethnicities and distinguish genders in\nmiddle-aged groups.", "AI": {"tldr": "The paper investigates biases in ImageNet classifiers for facial images, focusing on age, race, and gender intersections, using linear probes and activation maps.", "motivation": "To address the risk of perpetuating biases in deep learning models built on pre-trained classifiers.", "method": "Linear classifier probes and visualization of activations as topographic maps.", "result": "ImageNet classifiers differentiate ages strongly, with weaker associations for ethnicities and gender distinctions in middle-aged groups.", "conclusion": "The study highlights biases in pre-trained models, emphasizing the need for mitigation strategies."}}
{"id": "2506.03880", "pdf": "https://arxiv.org/pdf/2506.03880", "abs": "https://arxiv.org/abs/2506.03880", "authors": ["Ruihan Jin", "Pengpeng Shao", "Zhengqi Wen", "Jinyang Wu", "Mingkuan Feng", "Shuai Zhang", "Jianhua Tao"], "title": "RadialRouter: Structured Representation for Efficient and Robust Large Language Models Routing", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "The rapid advancements in large language models (LLMs) have led to the\nemergence of routing techniques, which aim to efficiently select the optimal\nLLM from diverse candidates to tackle specific tasks, optimizing performance\nwhile reducing costs. Current LLM routing methods are limited in effectiveness\ndue to insufficient exploration of the intrinsic connection between user\nqueries and the characteristics of LLMs. To address this issue, in this paper,\nwe present RadialRouter, a novel framework for LLM routing which employs a\nlightweight Transformer-based backbone with a radial structure named\nRadialFormer to articulate the query-LLMs relationship. The optimal LLM\nselection is performed based on the final states of RadialFormer. The pipeline\nis further refined by an objective function that combines Kullback-Leibler\ndivergence with the query-query contrastive loss to enhance robustness.\nExperimental results on RouterBench show that RadialRouter significantly\noutperforms existing routing methods by 9.2\\% and 5.8\\% in the Balance and Cost\nFirst scenarios, respectively. Additionally, its adaptability toward different\nperformance-cost trade-offs and the dynamic LLM pool demonstrates practical\napplication potential.", "AI": {"tldr": "RadialRouter is a new LLM routing framework using a lightweight Transformer (RadialFormer) to optimize LLM selection, outperforming existing methods by 9.2% and 5.8% in benchmarks.", "motivation": "Current LLM routing methods lack effectiveness due to insufficient exploration of query-LLM relationships.", "method": "RadialRouter employs RadialFormer, a Transformer-based backbone, and refines selection with a combined Kullback-Leibler divergence and contrastive loss objective.", "result": "Outperforms existing methods by 9.2% (Balance) and 5.8% (Cost First) on RouterBench, with adaptability to dynamic LLM pools.", "conclusion": "RadialRouter demonstrates superior performance and practical potential for efficient LLM routing."}}
{"id": "2506.03839", "pdf": "https://arxiv.org/pdf/2506.03839", "abs": "https://arxiv.org/abs/2506.03839", "authors": ["Tobias Pielok", "Bernd Bischl", "David R\u00fcgamer"], "title": "Revisiting Unbiased Implicit Variational Inference", "categories": ["cs.LG", "stat.ML", "62F15, 68T07", "I.2.6; G.3"], "comment": "Accepted to ICML 2025", "summary": "Recent years have witnessed growing interest in semi-implicit variational\ninference (SIVI) methods due to their ability to rapidly generate samples from\ncomplex distributions. However, since the likelihood of these samples is\nnon-trivial to estimate in high dimensions, current research focuses on finding\neffective SIVI training routines. Although unbiased implicit variational\ninference (UIVI) has largely been dismissed as imprecise and computationally\nprohibitive because of its inner MCMC loop, we revisit this method and show\nthat UIVI's MCMC loop can be effectively replaced via importance sampling and\nthe optimal proposal distribution can be learned stably by minimizing an\nexpected forward Kullback-Leibler divergence without bias. Our refined approach\ndemonstrates superior performance or parity with state-of-the-art methods on\nestablished SIVI benchmarks.", "AI": {"tldr": "Revisiting UIVI, the paper shows its MCMC loop can be replaced with importance sampling, achieving superior or comparable performance to SIVI benchmarks.", "motivation": "Addressing the computational and precision issues of UIVI by improving its training routine.", "method": "Replace UIVI's MCMC loop with importance sampling and learn the optimal proposal distribution via minimizing an expected forward KL divergence.", "result": "The refined UIVI method matches or outperforms state-of-the-art SIVI benchmarks.", "conclusion": "UIVI, when refined, is a viable and effective alternative to SIVI methods."}}
{"id": "2506.03867", "pdf": "https://arxiv.org/pdf/2506.03867", "abs": "https://arxiv.org/abs/2506.03867", "authors": ["Jacqueline Rowe", "Mateusz Klimaszewski", "Liane Guillou", "Shannon Vallor", "Alexandra Birch"], "title": "EuroGEST: Investigating gender stereotypes in multilingual language models", "categories": ["cs.CL"], "comment": "8 pages, 6 figures, 1 table", "summary": "Large language models increasingly support multiple languages, yet most\nbenchmarks for gender bias remain English-centric. We introduce EuroGEST, a\ndataset designed to measure gender-stereotypical reasoning in LLMs across\nEnglish and 29 European languages. EuroGEST builds on an existing\nexpert-informed benchmark covering 16 gender stereotypes, expanded in this work\nusing translation tools, quality estimation metrics, and morphological\nheuristics. Human evaluations confirm that our data generation method results\nin high accuracy of both translations and gender labels across languages. We\nuse EuroGEST to evaluate 24 multilingual language models from six model\nfamilies, demonstrating that the strongest stereotypes in all models across all\nlanguages are that women are \\textit{beautiful,} \\textit{empathetic} and\n\\textit{neat} and men are \\textit{leaders}, \\textit{strong, tough} and\n\\textit{professional}. We also show that larger models encode gendered\nstereotypes more strongly and that instruction finetuning does not consistently\nreduce gendered stereotypes. Our work highlights the need for more multilingual\nstudies of fairness in LLMs and offers scalable methods and resources to audit\ngender bias across languages.", "AI": {"tldr": "EuroGEST is a dataset for measuring gender bias in LLMs across 30 European languages, revealing strong stereotypes and showing larger models encode bias more strongly.", "motivation": "Most gender bias benchmarks are English-centric; EuroGEST addresses this gap for multilingual fairness studies.", "method": "Expands an expert-informed benchmark using translation tools, quality metrics, and morphological heuristics, validated by human evaluations.", "result": "Strongest stereotypes: women as beautiful, empathetic, neat; men as leaders, strong, tough, professional. Larger models show stronger bias.", "conclusion": "Highlights need for multilingual fairness studies and provides scalable tools for auditing gender bias in LLMs."}}
{"id": "2506.03675", "pdf": "https://arxiv.org/pdf/2506.03675", "abs": "https://arxiv.org/abs/2506.03675", "authors": ["Jialei Chen", "Xu Zheng", "Danda Pani Paudel", "Luc Van Gool", "Hiroshi Murase", "Daisuke Deguchi"], "title": "BiXFormer: A Robust Framework for Maximizing Modality Effectiveness in Multi-Modal Semantic Segmentation", "categories": ["cs.CV"], "comment": null, "summary": "Utilizing multi-modal data enhances scene understanding by providing\ncomplementary semantic and geometric information. Existing methods fuse\nfeatures or distill knowledge from multiple modalities into a unified\nrepresentation, improving robustness but restricting each modality's ability to\nfully leverage its strengths in different situations. We reformulate\nmulti-modal semantic segmentation as a mask-level classification task and\npropose BiXFormer, which integrates Unified Modality Matching (UMM) and Cross\nModality Alignment (CMA) to maximize modality effectiveness and handle missing\nmodalities. Specifically, BiXFormer first categorizes multi-modal inputs into\nRGB and X, where X represents any non-RGB modalities, e.g., depth, allowing\nseparate processing for each. This design leverages the well-established\npretraining for RGB, while addressing the relative lack of attention to X\nmodalities. Then, we propose UMM, which includes Modality Agnostic Matching\n(MAM) and Complementary Matching (CM). MAM assigns labels to features from all\nmodalities without considering modality differences, leveraging each modality's\nstrengths. CM then reassigns unmatched labels to remaining unassigned features\nwithin their respective modalities, ensuring that each available modality\ncontributes to the final prediction and mitigating the impact of missing\nmodalities. Moreover, to further facilitate UMM, we introduce CMA, which\nenhances the weaker queries assigned in CM by aligning them with optimally\nmatched queries from MAM. Experiments on both synthetic and real-world\nmulti-modal benchmarks demonstrate the effectiveness of our method, achieving\nsignificant improvements in mIoU of +2.75% and +22.74% over the prior arts.", "AI": {"tldr": "BiXFormer improves multi-modal semantic segmentation by integrating Unified Modality Matching (UMM) and Cross Modality Alignment (CMA), achieving significant performance gains.", "motivation": "Existing methods fuse multi-modal data into a unified representation, limiting each modality's potential. BiXFormer aims to maximize modality effectiveness and handle missing modalities.", "method": "BiXFormer categorizes inputs into RGB and non-RGB (X), processes them separately, and uses UMM (MAM and CM) and CMA to enhance feature matching and alignment.", "result": "Achieves mIoU improvements of +2.75% and +22.74% over prior methods on synthetic and real-world benchmarks.", "conclusion": "BiXFormer effectively leverages multi-modal strengths, mitigates missing modality impacts, and outperforms existing approaches."}}
{"id": "2506.03930", "pdf": "https://arxiv.org/pdf/2506.03930", "abs": "https://arxiv.org/abs/2506.03930", "authors": ["Yuansheng Ni", "Ping Nie", "Kai Zou", "Xiang Yue", "Wenhu Chen"], "title": "VisCoder: Fine-Tuning LLMs for Executable Python Visualization Code Generation", "categories": ["cs.SE", "cs.AI", "cs.CL"], "comment": null, "summary": "Large language models (LLMs) often struggle with visualization tasks like\nplotting diagrams, charts, where success depends on both code correctness and\nvisual semantics. Existing instruction-tuning datasets lack execution-grounded\nsupervision and offer limited support for iterative code correction, resulting\nin fragile and unreliable plot generation. We present VisCode-200K, a\nlarge-scale instruction tuning dataset for Python-based visualization and\nself-correction. It contains over 200K examples from two sources: (1) validated\nplotting code from open-source repositories, paired with natural language\ninstructions and rendered plots; and (2) 45K multi-turn correction dialogues\nfrom Code-Feedback, enabling models to revise faulty code using runtime\nfeedback. We fine-tune Qwen2.5-Coder-Instruct on VisCode-200K to create\nVisCoder, and evaluate it on PandasPlotBench. VisCoder significantly\noutperforms strong open-source baselines and approaches the performance of\nproprietary models like GPT-4o-mini. We further adopt a self-debug evaluation\nprotocol to assess iterative repair, demonstrating the benefits of\nfeedback-driven learning for executable, visually accurate code generation.", "AI": {"tldr": "VisCode-200K is a dataset for improving LLMs' visualization tasks by providing execution-grounded supervision and iterative code correction. VisCoder, fine-tuned on this dataset, outperforms baselines and nears proprietary model performance.", "motivation": "LLMs struggle with visualization tasks due to lack of execution-grounded supervision and iterative correction support in existing datasets.", "method": "Created VisCode-200K, a dataset with 200K examples from validated plotting code and multi-turn correction dialogues, and fine-tuned Qwen2.5-Coder-Instruct to produce VisCoder.", "result": "VisCoder outperforms open-source baselines and approaches GPT-4o-mini performance on PandasPlotBench.", "conclusion": "Feedback-driven learning and iterative repair improve executable, visually accurate code generation for LLMs."}}
{"id": "2506.03850", "pdf": "https://arxiv.org/pdf/2506.03850", "abs": "https://arxiv.org/abs/2506.03850", "authors": ["Liang Chen", "Xueting Han", "Li Shen", "Jing Bai", "Kam-Fai Wong"], "title": "Vulnerability-Aware Alignment: Mitigating Uneven Forgetting in Harmful Fine-Tuning", "categories": ["cs.LG"], "comment": "ICML 2025", "summary": "Harmful fine-tuning (HFT), performed directly on open-source LLMs or through\nFine-tuning-as-a-Service, breaks safety alignment and poses significant\nthreats. Existing methods aim to mitigate HFT risks by learning robust\nrepresentation on alignment data or making harmful data unlearnable, but they\ntreat each data sample equally, leaving data vulnerability patterns\nunderstudied. In this work, we reveal that certain subsets of alignment data\nare consistently more prone to forgetting during HFT across different\nfine-tuning tasks. Inspired by these findings, we propose Vulnerability-Aware\nAlignment (VAA), which estimates data vulnerability, partitions data into\n\"vulnerable\" and \"invulnerable\" groups, and encourages balanced learning using\na group distributionally robust optimization (Group DRO) framework.\nSpecifically, VAA learns an adversarial sampler that samples examples from the\ncurrently underperforming group and then applies group-dependent adversarial\nperturbations to the data during training, aiming to encourage a balanced\nlearning process across groups. Experiments across four fine-tuning tasks\ndemonstrate that VAA significantly reduces harmful scores while preserving\ndownstream task performance, outperforming state-of-the-art baselines.", "AI": {"tldr": "Vulnerability-Aware Alignment (VAA) identifies and mitigates harmful fine-tuning risks by focusing on vulnerable data subsets, using adversarial sampling and perturbations for balanced learning.", "motivation": "Harmful fine-tuning (HFT) undermines safety alignment in LLMs, and existing methods fail to address data vulnerability patterns.", "method": "VAA estimates data vulnerability, partitions data, and uses Group DRO with adversarial sampling and perturbations.", "result": "VAA reduces harmful scores while maintaining task performance, outperforming baselines.", "conclusion": "VAA effectively addresses HFT risks by targeting vulnerable data subsets and ensuring balanced learning."}}
{"id": "2506.03884", "pdf": "https://arxiv.org/pdf/2506.03884", "abs": "https://arxiv.org/abs/2506.03884", "authors": ["Utkarsh Pathak", "Chandra Sai Krishna Gunda", "Anusha Prakash", "Keshav Agarwal", "Hema A. Murthy"], "title": "Kinship in Speech: Leveraging Linguistic Relatedness for Zero-Shot TTS in Indian Languages", "categories": ["cs.CL", "cs.CV", "I.5.4"], "comment": "Accepted at INTERSPEECH 2025", "summary": "Text-to-speech (TTS) systems typically require high-quality studio data and\naccurate transcriptions for training. India has 1369 languages, with 22\nofficial using 13 scripts. Training a TTS system for all these languages, most\nof which have no digital resources, seems a Herculean task. Our work focuses on\nzero-shot synthesis, particularly for languages whose scripts and phonotactics\ncome from different families. The novelty of our work is in the augmentation of\na shared phone representation and modifying the text parsing rules to match the\nphonotactics of the target language, thus reducing the synthesiser overhead and\nenabling rapid adaptation. Intelligible and natural speech was generated for\nSanskrit, Maharashtrian and Canara Konkani, Maithili and Kurukh by leveraging\nlinguistic connections across languages with suitable synthesisers. Evaluations\nconfirm the effectiveness of this approach, highlighting its potential to\nexpand speech technology access for under-represented languages.", "AI": {"tldr": "The paper proposes a zero-shot TTS synthesis method for under-resourced Indian languages by augmenting shared phone representations and adapting text parsing rules, achieving intelligible and natural speech for several languages.", "motivation": "India's linguistic diversity (1369 languages, 22 official) lacks digital resources, making TTS training challenging. The goal is to enable TTS for languages with no existing resources.", "method": "Augments shared phone representations and modifies text parsing rules to match target language phonotactics, reducing synthesis overhead and enabling rapid adaptation.", "result": "Successfully generated intelligible and natural speech for Sanskrit, Maharashtrian and Canara Konkani, Maithili, and Kurukh.", "conclusion": "The approach is effective and has potential to expand speech technology access for under-represented languages."}}
{"id": "2506.03683", "pdf": "https://arxiv.org/pdf/2506.03683", "abs": "https://arxiv.org/abs/2506.03683", "authors": ["Qiang Fu", "Zonglei Jing", "Zonghao Ying", "Xiaoqian Li"], "title": "PRJ: Perception-Retrieval-Judgement for Generated Images", "categories": ["cs.CV"], "comment": null, "summary": "The rapid progress of generative AI has enabled remarkable creative\ncapabilities, yet it also raises urgent concerns regarding the safety of\nAI-generated visual content in real-world applications such as content\nmoderation, platform governance, and digital media regulation. This includes\nunsafe material such as sexually explicit images, violent scenes, hate symbols,\npropaganda, and unauthorized imitations of copyrighted artworks. Existing image\nsafety systems often rely on rigid category filters and produce binary outputs,\nlacking the capacity to interpret context or reason about nuanced,\nadversarially induced forms of harm. In addition, standard evaluation metrics\n(e.g., attack success rate) fail to capture the semantic severity and dynamic\nprogression of toxicity. To address these limitations, we propose\nPerception-Retrieval-Judgement (PRJ), a cognitively inspired framework that\nmodels toxicity detection as a structured reasoning process. PRJ follows a\nthree-stage design: it first transforms an image into descriptive language\n(perception), then retrieves external knowledge related to harm categories and\ntraits (retrieval), and finally evaluates toxicity based on legal or normative\nrules (judgement). This language-centric structure enables the system to detect\nboth explicit and implicit harms with improved interpretability and categorical\ngranularity. In addition, we introduce a dynamic scoring mechanism based on a\ncontextual toxicity risk matrix to quantify harmfulness across different\nsemantic dimensions. Experiments show that PRJ surpasses existing safety\ncheckers in detection accuracy and robustness while uniquely supporting\nstructured category-level toxicity interpretation.", "AI": {"tldr": "The paper introduces PRJ, a framework for detecting toxic AI-generated visual content by mimicking human reasoning, improving accuracy and interpretability over traditional methods.", "motivation": "Addressing the limitations of current AI safety systems in detecting nuanced and context-dependent harmful content.", "method": "Proposes PRJ, a three-stage framework: perception (image to language), retrieval (external knowledge), and judgement (toxicity evaluation).", "result": "PRJ outperforms existing systems in accuracy and robustness, offering better interpretability and granularity.", "conclusion": "PRJ provides a more effective and interpretable solution for detecting harmful AI-generated visual content."}}
{"id": "2506.03933", "pdf": "https://arxiv.org/pdf/2506.03933", "abs": "https://arxiv.org/abs/2506.03933", "authors": ["Jia Fu", "Yongtao Wu", "Yihang Chen", "Kunyu Peng", "Xiao Zhang", "Volkan Cevher", "Sepideh Pashami", "Anders Holst"], "title": "DiffCAP: Diffusion-based Cumulative Adversarial Purification for Vision Language Models", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Vision Language Models (VLMs) have shown remarkable capabilities in\nmultimodal understanding, yet their susceptibility to perturbations poses a\nsignificant threat to their reliability in real-world applications. Despite\noften being imperceptible to humans, these perturbations can drastically alter\nmodel outputs, leading to erroneous interpretations and decisions. This paper\nintroduces DiffCAP, a novel diffusion-based purification strategy that can\neffectively neutralize adversarial corruptions in VLMs. We observe that adding\nminimal noise to an adversarially corrupted image significantly alters its\nlatent embedding with respect to VLMs. Building on this insight, DiffCAP\ncumulatively injects random Gaussian noise into adversarially perturbed input\ndata. This process continues until the embeddings of two consecutive noisy\nimages reach a predefined similarity threshold, indicating a potential approach\nto neutralize the adversarial effect. Subsequently, a pretrained diffusion\nmodel is employed to denoise the stabilized image, recovering a clean\nrepresentation suitable for the VLMs to produce an output. Through extensive\nexperiments across six datasets with three VLMs under varying attack strengths\nin three task scenarios, we show that DiffCAP consistently outperforms existing\ndefense techniques by a substantial margin. Notably, DiffCAP significantly\nreduces both hyperparameter tuning complexity and the required diffusion time,\nthereby accelerating the denoising process. Equipped with strong theoretical\nand empirical support, DiffCAP provides a robust and practical solution for\nsecurely deploying VLMs in adversarial environments.", "AI": {"tldr": "DiffCAP is a diffusion-based method to neutralize adversarial corruptions in Vision Language Models (VLMs), outperforming existing defenses with minimal tuning and faster denoising.", "motivation": "VLMs are vulnerable to adversarial perturbations, which can cause unreliable outputs despite being imperceptible to humans.", "method": "DiffCAP injects Gaussian noise into perturbed inputs until embeddings stabilize, then uses a pretrained diffusion model to denoise and recover clean representations.", "result": "DiffCAP consistently outperforms other defenses across datasets, VLMs, and attack strengths, reducing tuning complexity and diffusion time.", "conclusion": "DiffCAP offers a robust, practical solution for secure VLM deployment in adversarial settings, supported by theory and experiments."}}
{"id": "2506.03857", "pdf": "https://arxiv.org/pdf/2506.03857", "abs": "https://arxiv.org/abs/2506.03857", "authors": ["Mingxuan Xia", "Haobo Wang", "Yixuan Li", "Zewei Yu", "Jindong Wang", "Junbo Zhao", "Runze Wu"], "title": "Prompt Candidates, then Distill: A Teacher-Student Framework for LLM-driven Data Annotation", "categories": ["cs.LG", "cs.CL"], "comment": "Accepted to ACL 2025 (Main conference)", "summary": "Recently, Large Language Models (LLMs) have demonstrated significant\npotential for data annotation, markedly reducing the labor costs associated\nwith downstream applications. However, existing methods mostly adopt an\naggressive strategy by prompting LLM to determine a single gold label for each\nunlabeled sample. Due to the inherent uncertainty within LLMs, they often\nproduce incorrect labels for difficult samples, severely compromising the data\nquality for downstream applications. Motivated by ambiguity aversion in human\nbehaviors, we propose a novel candidate annotation paradigm wherein large\nlanguage models are encouraged to output all possible labels when incurring\nuncertainty. To ensure unique labels are provided for downstream tasks, we\ndevelop a teacher-student framework CanDist that distills candidate annotations\nwith a Small Language Model (SLM). We further provide a rigorous justification\ndemonstrating that distilling candidate annotations from the teacher LLM offers\nsuperior theoretical guarantees compared to directly using single annotations.\nExtensive experiments across six text classification tasks validate the\neffectiveness of our proposed method. The source code is available at\nhttps://github.com/MingxuanXia/CanDist.", "AI": {"tldr": "The paper introduces a candidate annotation paradigm using LLMs to output multiple labels for uncertain samples, improving data quality via a teacher-student framework (CanDist) and outperforming single-label methods.", "motivation": "Existing LLM-based annotation methods often produce incorrect labels for uncertain samples, harming downstream data quality. Inspired by human ambiguity aversion, the authors propose a multi-label approach.", "method": "A candidate annotation paradigm where LLMs output all possible labels for uncertain samples, followed by a teacher-student framework (CanDist) to distill these annotations using a Small Language Model (SLM).", "result": "The method shows superior theoretical guarantees and effectiveness across six text classification tasks.", "conclusion": "The proposed candidate annotation paradigm and CanDist framework enhance data quality by leveraging LLM uncertainty, validated by experiments."}}
{"id": "2506.03887", "pdf": "https://arxiv.org/pdf/2506.03887", "abs": "https://arxiv.org/abs/2506.03887", "authors": ["Junyi Chen", "Shihao Bai", "Zaijun Wang", "Siyu Wu", "Chuheng Du", "Hailong Yang", "Ruihao Gong", "Shengzhong Liu", "Fan Wu", "Guihai Chen"], "title": "Pre$^3$: Enabling Deterministic Pushdown Automata for Faster Structured LLM Generation", "categories": ["cs.CL"], "comment": "Published as a conference paper at ACL 2025", "summary": "Extensive LLM applications demand efficient structured generations,\nparticularly for LR(1) grammars, to produce outputs in specified formats (e.g.,\nJSON). Existing methods primarily parse LR(1) grammars into a pushdown\nautomaton (PDA), leading to runtime execution overhead for context-dependent\ntoken processing, especially inefficient under large inference batches. To\naddress these issues, we propose Pre$^3$ that exploits deterministic pushdown\nautomata (DPDA) to optimize the constrained LLM decoding efficiency. First, by\nprecomputing prefix-conditioned edges during the preprocessing, Pre$^3$ enables\nahead-of-time edge analysis and thus makes parallel transition processing\npossible. Second, by leveraging the prefix-conditioned edges, Pre$^3$\nintroduces a novel approach that transforms LR(1) transition graphs into DPDA,\neliminating the need for runtime path exploration and achieving edge\ntransitions with minimal overhead. Pre$^3$ can be seamlessly integrated into\nstandard LLM inference frameworks, reducing time per output token (TPOT) by up\nto 40% and increasing throughput by up to 36% in our experiments. Our code is\navailable at https://github.com/ModelTC/lightllm.", "AI": {"tldr": "Pre$^3$ optimizes LLM decoding for LR(1) grammars by using deterministic pushdown automata (DPDA), reducing runtime overhead and improving efficiency.", "motivation": "Existing methods for structured LLM outputs (e.g., JSON) using LR(1) grammars suffer from inefficiency due to runtime parsing overhead, especially in large batches.", "method": "Pre$^3$ precomputes prefix-conditioned edges to enable parallel processing and transforms LR(1) transition graphs into DPDA, eliminating runtime path exploration.", "result": "Pre$^3$ reduces time per output token (TPOT) by up to 40% and increases throughput by up to 36%.", "conclusion": "Pre$^3$ efficiently integrates into LLM frameworks, significantly improving structured generation performance."}}
{"id": "2506.03684", "pdf": "https://arxiv.org/pdf/2506.03684", "abs": "https://arxiv.org/abs/2506.03684", "authors": ["Zunhui Xia", "Hongxing Li", "Libin Lan"], "title": "DSSAU-Net:U-Shaped Hybrid Network for Pubic Symphysis and Fetal Head Segmentation", "categories": ["cs.CV"], "comment": "14 pages, 3 figures, 5 tables.Accepted by MICCAI Workshop on IUGC\n  2024", "summary": "In the childbirth process, traditional methods involve invasive vaginal\nexaminations, but research has shown that these methods are both subjective and\ninaccurate. Ultrasound-assisted diagnosis offers an objective yet effective way\nto assess fetal head position via two key parameters: Angle of Progression\n(AoP) and Head-Symphysis Distance (HSD), calculated by segmenting the fetal\nhead (FH) and pubic symphysis (PS), which aids clinicians in ensuring a smooth\ndelivery process. Therefore, accurate segmentation of FH and PS is crucial. In\nthis work, we propose a sparse self-attention network architecture with good\nperformance and high computational efficiency, named DSSAU-Net, for the\nsegmentation of FH and PS. Specifically, we stack varying numbers of Dual\nSparse Selection Attention (DSSA) blocks at each stage to form a symmetric\nU-shaped encoder-decoder network architecture. For a given query, DSSA is\ndesigned to explicitly perform one sparse token selection at both the region\nand pixel levels, respectively, which is beneficial for further reducing\ncomputational complexity while extracting the most relevant features. To\ncompensate for the information loss during the upsampling process, skip\nconnections with convolutions are designed. Additionally, multiscale feature\nfusion is employed to enrich the model's global and local information. The\nperformance of DSSAU-Net has been validated using the Intrapartum Ultrasound\nGrand Challenge (IUGC) 2024 \\textit{test set} provided by the organizer in the\nMICCAI IUGC 2024\ncompetition\\footnote{\\href{https://codalab.lisn.upsaclay.fr/competitions/18413\\#learn\\_the\\_details}{https://codalab.lisn.upsaclay.fr/competitions/18413\\#learn\\_the\\_details}},\nwhere we win the fourth place on the tasks of classification and segmentation,\ndemonstrating its effectiveness. The codes will be available at\nhttps://github.com/XiaZunhui/DSSAU-Net.", "AI": {"tldr": "A sparse self-attention network (DSSAU-Net) is proposed for accurate segmentation of fetal head and pubic symphysis in ultrasound images, improving childbirth diagnosis.", "motivation": "Traditional vaginal examinations are subjective and inaccurate; ultrasound-assisted diagnosis using AoP and HSD parameters offers a better alternative, requiring precise segmentation of FH and PS.", "method": "DSSAU-Net uses Dual Sparse Selection Attention blocks in a U-shaped encoder-decoder architecture, with sparse token selection at region and pixel levels, skip connections, and multiscale feature fusion.", "result": "DSSAU-Net achieved fourth place in the MICCAI IUGC 2024 competition, validating its effectiveness in segmentation and classification tasks.", "conclusion": "DSSAU-Net is a computationally efficient and effective solution for FH and PS segmentation, enhancing ultrasound-assisted childbirth diagnosis."}}
{"id": "2506.03941", "pdf": "https://arxiv.org/pdf/2506.03941", "abs": "https://arxiv.org/abs/2506.03941", "authors": ["Vivian Nguyen", "Lillian Lee", "Cristian Danescu-Niculescu-Mizil"], "title": "Hanging in the Balance: Pivotal Moments in Crisis Counseling Conversations", "categories": ["cs.CL", "cs.AI", "cs.CY", "physics.soc-ph"], "comment": "To appear in the Proceedings of ACL 2025. Code and demo available in\n  ConvoKit (convokit.cornell.edu)", "summary": "During a conversation, there can come certain moments where its outcome hangs\nin the balance. In these pivotal moments, how one responds can put the\nconversation on substantially different trajectories leading to significantly\ndifferent outcomes. Systems that can detect when such moments arise could\nassist conversationalists in domains with highly consequential outcomes, such\nas mental health crisis counseling.\n  In this work, we introduce an unsupervised computational method for detecting\nsuch pivotal moments as they happen, in an online fashion. Our approach relies\non the intuition that a moment is pivotal if our expectation of the outcome\nvaries widely depending on what might be said next. By applying our method to\ncrisis counseling conversations, we first validate it by showing that it aligns\nwith human perception -- counselors take significantly longer to respond during\nmoments detected by our method -- and with the eventual conversational\ntrajectory -- which is more likely to change course at these times. We then use\nour framework to explore the relation of the counselor's response during\npivotal moments with the eventual outcome of the session.", "AI": {"tldr": "The paper introduces an unsupervised method to detect pivotal moments in conversations, validated in crisis counseling, showing alignment with human perception and conversational outcomes.", "motivation": "To assist in domains like mental health crisis counseling by identifying moments where conversation outcomes can significantly diverge based on responses.", "method": "An unsupervised computational approach detecting pivotal moments by analyzing variance in expected outcomes based on potential responses.", "result": "Validated by human perception (longer response times) and conversational trajectory changes. Explored counselor responses' impact on session outcomes.", "conclusion": "The method effectively identifies pivotal moments, aiding in understanding and improving consequential conversations."}}
{"id": "2506.03870", "pdf": "https://arxiv.org/pdf/2506.03870", "abs": "https://arxiv.org/abs/2506.03870", "authors": ["Mohd. Farhan Israk Soumik", "Syed Mhamudul Hasan", "Abdur R. Shahid"], "title": "Evaluating Apple Intelligence's Writing Tools for Privacy Against Large Language Model-Based Inference Attacks: Insights from Early Datasets", "categories": ["cs.LG", "cs.CR"], "comment": null, "summary": "The misuse of Large Language Models (LLMs) to infer emotions from text for\nmalicious purposes, known as emotion inference attacks, poses a significant\nthreat to user privacy. In this paper, we investigate the potential of Apple\nIntelligence's writing tools, integrated across iPhone, iPad, and MacBook, to\nmitigate these risks through text modifications such as rewriting and tone\nadjustment. By developing early novel datasets specifically for this purpose,\nwe empirically assess how different text modifications influence LLM-based\ndetection. This capability suggests strong potential for Apple Intelligence's\nwriting tools as privacy-preserving mechanisms. Our findings lay the groundwork\nfor future adaptive rewriting systems capable of dynamically neutralizing\nsensitive emotional content to enhance user privacy. To the best of our\nknowledge, this research provides the first empirical analysis of Apple\nIntelligence's text-modification tools within a privacy-preservation context\nwith the broader goal of developing on-device, user-centric privacy-preserving\nmechanisms to protect against LLMs-based advanced inference attacks on deployed\nsystems.", "AI": {"tldr": "The paper explores how Apple Intelligence's writing tools can mitigate emotion inference attacks by modifying text, preserving privacy against LLM misuse.", "motivation": "Address the threat of LLM misuse for emotion inference attacks, which compromises user privacy.", "method": "Develop datasets to assess text modifications (rewriting, tone adjustment) and their impact on LLM-based detection.", "result": "Apple Intelligence's tools show strong potential as privacy-preserving mechanisms by neutralizing emotional content.", "conclusion": "The study pioneers empirical analysis of Apple's tools for privacy, paving the way for adaptive systems to protect against LLM-based attacks."}}
{"id": "2506.03901", "pdf": "https://arxiv.org/pdf/2506.03901", "abs": "https://arxiv.org/abs/2506.03901", "authors": ["Yuxin Zhang", "Yan Wang", "Yongrui Chen", "Shenyu Zhang", "Xinbang Dai", "Sheng Bi", "Guilin Qi"], "title": "Magic Mushroom: A Customizable Benchmark for Fine-grained Analysis of Retrieval Noise Erosion in RAG Systems", "categories": ["cs.CL"], "comment": null, "summary": "Retrieval-Augmented Generation (RAG) systems enhance Large Language Models\n(LLMs) by incorporating external retrieved information, mitigating issues such\nas hallucination and outdated knowledge.\n  However, RAG systems are highly sensitive to retrieval noise prevalent in\nreal-world scenarios.\n  Existing benchmarks fail to emulate the complex and heterogeneous noise\ndistributions encountered in real-world retrieval environments, undermining\nreliable robustness assessment.\n  In this paper, we define four categories of retrieval noise based on\nlinguistic properties and noise characteristics, aiming to reflect the\nheterogeneity of noise in real-world scenarios.\n  Building on this, we introduce Magic Mushroom, a benchmark for replicating\n\"magic mushroom\" noise: contexts that appear relevant on the surface but\ncovertly mislead RAG systems.\n  Magic Mushroom comprises 7,468 single-hop and 3,925 multi-hop question-answer\npairs.\n  More importantly, Magic Mushroom enables researchers to flexibly configure\ncombinations of retrieval noise according to specific research objectives or\napplication scenarios, allowing for highly controlled evaluation setups.\n  We evaluate LLM generators of varying parameter scales and classic RAG\ndenoising strategies under diverse noise distributions to investigate their\nperformance dynamics during progressive noise encroachment.\n  Our analysis reveals that both generators and denoising strategies have\nsignificant room for improvement and exhibit extreme sensitivity to noise\ndistributions.\n  Magic Mushroom emerges as a promising tool for evaluating and advancing\nnoise-robust RAG systems, accelerating their widespread deployment in\nreal-world applications.\n  The Magic Mushroom benchmark is available at the\nhttps://drive.google.com/file/d/1aP5kyPuk4L-L_uoI6T9UhxuTyt8oMqjT/view?usp=sharing.", "AI": {"tldr": "The paper introduces Magic Mushroom, a benchmark for evaluating retrieval noise in RAG systems, highlighting their sensitivity to noise and the need for improved robustness.", "motivation": "Existing benchmarks fail to capture real-world retrieval noise, undermining reliable assessment of RAG systems.", "method": "Defines four categories of retrieval noise and introduces Magic Mushroom, a benchmark with configurable noise combinations for controlled evaluation.", "result": "LLMs and RAG denoising strategies show significant sensitivity to noise distributions, with room for improvement.", "conclusion": "Magic Mushroom is a valuable tool for advancing noise-robust RAG systems, aiding real-world deployment."}}
{"id": "2506.03698", "pdf": "https://arxiv.org/pdf/2506.03698", "abs": "https://arxiv.org/abs/2506.03698", "authors": ["Yuanlin Mo", "Haishan Huang", "Bocheng Liang", "Weibo Ma"], "title": "Advancements in Artificial Intelligence Applications for Cardiovascular Disease Research", "categories": ["cs.CV"], "comment": null, "summary": "Recent advancements in artificial intelligence (AI) have revolutionized\ncardiovascular medicine, particularly through integration with computed\ntomography (CT), magnetic resonance imaging (MRI), electrocardiography (ECG)\nand ultrasound (US). Deep learning architectures, including convolutional\nneural networks and generative adversarial networks, enable automated analysis\nof medical imaging and physiological signals, surpassing human capabilities in\ndiagnostic accuracy and workflow efficiency. However, critical challenges\npersist, including the inability to validate input data accuracy, which may\npropagate diagnostic errors. This review highlights AI's transformative\npotential in precision diagnostics while underscoring the need for robust\nvalidation protocols to ensure clinical reliability. Future directions\nemphasize hybrid models integrating multimodal data and adaptive algorithms to\nrefine personalized cardiovascular care.", "AI": {"tldr": "AI advancements in cardiovascular medicine improve diagnostics via deep learning but face challenges in data validation. Future focus is on hybrid models for personalized care.", "motivation": "To explore AI's role in enhancing cardiovascular diagnostics through medical imaging and signals, addressing current limitations.", "method": "Utilizes deep learning (CNNs, GANs) for automated analysis of CT, MRI, ECG, and US data.", "result": "AI surpasses human accuracy and efficiency but lacks robust validation for input data.", "conclusion": "AI holds transformative potential but requires validation protocols and hybrid models for reliable clinical use."}}
{"id": "2506.03954", "pdf": "https://arxiv.org/pdf/2506.03954", "abs": "https://arxiv.org/abs/2506.03954", "authors": ["Jianqing Zhang", "Xinghao Wu", "Yanbing Zhou", "Xiaoting Sun", "Qiqi Cai", "Yang Liu", "Yang Hua", "Zhenzhe Zheng", "Jian Cao", "Qiang Yang"], "title": "HtFLlib: A Comprehensive Heterogeneous Federated Learning Library and Benchmark", "categories": ["cs.LG", "cs.AI", "cs.DC"], "comment": "Accepted by KDD2025", "summary": "As AI evolves, collaboration among heterogeneous models helps overcome data\nscarcity by enabling knowledge transfer across institutions and devices.\nTraditional Federated Learning (FL) only supports homogeneous models, limiting\ncollaboration among clients with heterogeneous model architectures. To address\nthis, Heterogeneous Federated Learning (HtFL) methods are developed to enable\ncollaboration across diverse heterogeneous models while tackling the data\nheterogeneity issue at the same time. However, a comprehensive benchmark for\nstandardized evaluation and analysis of the rapidly growing HtFL methods is\nlacking. Firstly, the highly varied datasets, model heterogeneity scenarios,\nand different method implementations become hurdles to making easy and fair\ncomparisons among HtFL methods. Secondly, the effectiveness and robustness of\nHtFL methods are under-explored in various scenarios, such as the medical\ndomain and sensor signal modality. To fill this gap, we introduce the first\nHeterogeneous Federated Learning Library (HtFLlib), an easy-to-use and\nextensible framework that integrates multiple datasets and model heterogeneity\nscenarios, offering a robust benchmark for research and practical applications.\nSpecifically, HtFLlib integrates (1) 12 datasets spanning various domains,\nmodalities, and data heterogeneity scenarios; (2) 40 model architectures,\nranging from small to large, across three modalities; (3) a modularized and\neasy-to-extend HtFL codebase with implementations of 10 representative HtFL\nmethods; and (4) systematic evaluations in terms of accuracy, convergence,\ncomputation costs, and communication costs. We emphasize the advantages and\npotential of state-of-the-art HtFL methods and hope that HtFLlib will catalyze\nadvancing HtFL research and enable its broader applications. The code is\nreleased at https://github.com/TsingZ0/HtFLlib.", "AI": {"tldr": "The paper introduces HtFLlib, a benchmark library for Heterogeneous Federated Learning (HtFL) to standardize evaluation and analysis of diverse HtFL methods, addressing data and model heterogeneity challenges.", "motivation": "Traditional Federated Learning (FL) supports only homogeneous models, limiting collaboration among clients with heterogeneous architectures. HtFL methods aim to overcome this but lack a standardized benchmark for evaluation.", "method": "The authors develop HtFLlib, a framework integrating 12 datasets, 40 model architectures, and 10 HtFL methods. It provides systematic evaluations on accuracy, convergence, and costs.", "result": "HtFLlib offers a robust benchmark for HtFL research, enabling fair comparisons and exploring method effectiveness in diverse scenarios like medical and sensor domains.", "conclusion": "HtFLlib fills a critical gap in HtFL research, promoting advancements and broader applications. The library is open-source and extensible."}}
{"id": "2506.03889", "pdf": "https://arxiv.org/pdf/2506.03889", "abs": "https://arxiv.org/abs/2506.03889", "authors": ["Pau Vilimelis Aceituno", "Jack William Miller", "Noah Marti", "Youssef Farag", "Victor Boussange"], "title": "Temporal horizons in forecasting: a performance-learnability trade-off", "categories": ["cs.LG", "nlin.CD"], "comment": "33 pages, 12 figures", "summary": "When training autoregressive models for dynamical systems, a critical\nquestion arises: how far into the future should the model be trained to\npredict? Too short a horizon may miss long-term trends, while too long a\nhorizon can impede convergence due to accumulating prediction errors. In this\nwork, we formalize this trade-off by analyzing how the geometry of the loss\nlandscape depends on the training horizon. We prove that for chaotic systems,\nthe loss landscape's roughness grows exponentially with the training horizon,\nwhile for limit cycles, it grows linearly, making long-horizon training\ninherently challenging. However, we also show that models trained on long\nhorizons generalize well to short-term forecasts, whereas those trained on\nshort horizons suffer exponentially (resp. linearly) worse long-term\npredictions in chaotic (resp. periodic) systems. We validate our theory through\nnumerical experiments and discuss practical implications for selecting training\nhorizons. Our results provide a principled foundation for hyperparameter\noptimization in autoregressive forecasting models.", "AI": {"tldr": "The paper analyzes the trade-off in training horizons for autoregressive models in dynamical systems, showing how loss landscape geometry varies with horizon length and its impact on generalization.", "motivation": "To address the challenge of selecting an optimal training horizon for autoregressive models in dynamical systems, balancing short-term accuracy and long-term prediction quality.", "method": "Theoretical analysis of loss landscape geometry for chaotic and periodic systems, validated through numerical experiments.", "result": "Loss roughness grows exponentially with horizon in chaotic systems and linearly in periodic ones. Long-horizon models generalize better to short-term forecasts, while short-horizon models perform poorly on long-term predictions.", "conclusion": "Provides a principled approach for selecting training horizons in autoregressive forecasting models, emphasizing the importance of horizon choice for model performance."}}
{"id": "2506.03902", "pdf": "https://arxiv.org/pdf/2506.03902", "abs": "https://arxiv.org/abs/2506.03902", "authors": ["Eleftheria Tsipidi", "Samuel Kiegeland", "Franz Nowak", "Tianyang Xu", "Ethan Wilcox", "Alex Warstadt", "Ryan Cotterell", "Mario Giulianelli"], "title": "The Harmonic Structure of Information Contours", "categories": ["cs.CL"], "comment": "ACL 2025 (main conference)", "summary": "The uniform information density (UID) hypothesis proposes that speakers aim\nto distribute information evenly throughout a text, balancing production effort\nand listener comprehension difficulty. However, language typically does not\nmaintain a strictly uniform information rate; instead, it fluctuates around a\nglobal average. These fluctuations are often explained by factors such as\nsyntactic constraints, stylistic choices, or audience design. In this work, we\nexplore an alternative perspective: that these fluctuations may be influenced\nby an implicit linguistic pressure towards periodicity, where the information\nrate oscillates at regular intervals, potentially across multiple frequencies\nsimultaneously. We apply harmonic regression and introduce a novel extension\ncalled time scaling to detect and test for such periodicity in information\ncontours. Analyzing texts in English, Spanish, German, Dutch, Basque, and\nBrazilian Portuguese, we find consistent evidence of periodic patterns in\ninformation rate. Many dominant frequencies align with discourse structure,\nsuggesting these oscillations reflect meaningful linguistic organization.\nBeyond highlighting the connection between information rate and discourse\nstructure, our approach offers a general framework for uncovering structural\npressures at various levels of linguistic granularity.", "AI": {"tldr": "The paper explores periodic fluctuations in information rate in language, proposing an implicit pressure towards periodicity. Using harmonic regression and time scaling, it finds consistent periodic patterns across multiple languages, linking them to discourse structure.", "motivation": "The study aims to understand why language information rate fluctuates, challenging the uniform information density hypothesis by suggesting periodicity as an alternative explanation.", "method": "The authors apply harmonic regression and introduce time scaling to detect periodic patterns in information rate across English, Spanish, German, Dutch, Basque, and Brazilian Portuguese texts.", "result": "Consistent periodic patterns in information rate are found, with dominant frequencies aligning with discourse structure, indicating meaningful linguistic organization.", "conclusion": "The findings connect information rate fluctuations to discourse structure and provide a framework for analyzing structural pressures in language."}}
{"id": "2506.03706", "pdf": "https://arxiv.org/pdf/2506.03706", "abs": "https://arxiv.org/abs/2506.03706", "authors": ["Aditya Gandhamal", "Aniruddh Sikdar", "Suresh Sundaram"], "title": "OV-COAST: Cost Aggregation with Optimal Transport for Open-Vocabulary Semantic Segmentation", "categories": ["cs.CV"], "comment": "Accepted at CVPR 2025 Workshop on Transformers for Vision\n  (Non-archival track)", "summary": "Open-vocabulary semantic segmentation (OVSS) entails assigning semantic\nlabels to each pixel in an image using textual descriptions, typically\nleveraging world models such as CLIP. To enhance out-of-domain generalization,\nwe propose Cost Aggregation with Optimal Transport (OV-COAST) for\nopen-vocabulary semantic segmentation. To align visual-language features within\nthe framework of optimal transport theory, we employ cost volume to construct a\ncost matrix, which quantifies the distance between two distributions. Our\napproach adopts a two-stage optimization strategy: in the first stage, the\noptimal transport problem is solved using cost volume via Sinkhorn distance to\nobtain an alignment solution; in the second stage, this solution is used to\nguide the training of the CAT-Seg model. We evaluate state-of-the-art OVSS\nmodels on the MESS benchmark, where our approach notably improves the\nperformance of the cost-aggregation model CAT-Seg with ViT-B backbone,\nachieving superior results, surpassing CAT-Seg by 1.72 % and SAN-B by 4.9 %\nmIoU. The code is available at\nhttps://github.com/adityagandhamal/OV-COAST/}{https://github.com/adityagandhamal/OV-COAST/ .", "AI": {"tldr": "OV-COAST improves open-vocabulary semantic segmentation by using cost aggregation with optimal transport, enhancing out-of-domain generalization and outperforming existing models.", "motivation": "To enhance out-of-domain generalization in open-vocabulary semantic segmentation by aligning visual-language features using optimal transport theory.", "method": "Proposes a two-stage optimization: first solves optimal transport using cost volume and Sinkhorn distance, then uses the solution to train the CAT-Seg model.", "result": "Achieves superior performance, surpassing CAT-Seg by 1.72% and SAN-B by 4.9% mIoU on the MESS benchmark.", "conclusion": "OV-COAST effectively improves segmentation performance by leveraging optimal transport for feature alignment."}}
{"id": "2506.03964", "pdf": "https://arxiv.org/pdf/2506.03964", "abs": "https://arxiv.org/abs/2506.03964", "authors": ["HyunGi Kim", "Jisoo Mok", "Dongjun Lee", "Jaihyun Lew", "Sungjae Kim", "Sungroh Yoon"], "title": "Causality-Aware Contrastive Learning for Robust Multivariate Time-Series Anomaly Detection", "categories": ["cs.LG", "cs.AI"], "comment": "Accepted to ICML 2025", "summary": "Utilizing the complex inter-variable causal relationships within multivariate\ntime-series provides a promising avenue toward more robust and reliable\nmultivariate time-series anomaly detection (MTSAD) but remains an underexplored\narea of research. This paper proposes Causality-Aware contrastive learning for\nRObust multivariate Time-Series (CAROTS), a novel MTSAD pipeline that\nincorporates the notion of causality into contrastive learning. CAROTS employs\ntwo data augmentors to obtain causality-preserving and -disturbing samples that\nserve as a wide range of normal variations and synthetic anomalies,\nrespectively. With causality-preserving and -disturbing samples as positives\nand negatives, CAROTS performs contrastive learning to train an encoder whose\nlatent space separates normal and abnormal samples based on causality.\nMoreover, CAROTS introduces a similarity-filtered one-class contrastive loss\nthat encourages the contrastive learning process to gradually incorporate more\nsemantically diverse samples with common causal relationships. Extensive\nexperiments on five real-world and two synthetic datasets validate that the\nintegration of causal relationships endows CAROTS with improved MTSAD\ncapabilities. The code is available at https://github.com/kimanki/CAROTS.", "AI": {"tldr": "CAROTS introduces causality-aware contrastive learning for robust multivariate time-series anomaly detection, using data augmentors to create causality-preserving and -disturbing samples for training.", "motivation": "Existing methods underutilize causal relationships in multivariate time-series data, limiting anomaly detection robustness.", "method": "CAROTS employs two data augmentors to generate causality-preserving (normal) and -disturbing (anomalous) samples, training an encoder via contrastive learning with a similarity-filtered one-class loss.", "result": "Experiments on real-world and synthetic datasets show CAROTS improves anomaly detection by leveraging causal relationships.", "conclusion": "CAROTS effectively integrates causality into contrastive learning, enhancing multivariate time-series anomaly detection."}}
{"id": "2506.03898", "pdf": "https://arxiv.org/pdf/2506.03898", "abs": "https://arxiv.org/abs/2506.03898", "authors": ["Pierre-Fran\u00e7ois Massiani", "Christian Fiedler", "Lukas Haverbeck", "Friedrich Solowjow", "Sebastian Trimpe"], "title": "A kernel conditional two-sample test", "categories": ["cs.LG", "stat.ML"], "comment": "40 pages, 8 figures, 8 tables. Under review", "summary": "We propose a framework for hypothesis testing on conditional probability\ndistributions, which we then use to construct conditional two-sample\nstatistical tests. These tests identify the inputs -- called covariates in this\ncontext -- where two conditional expectations differ with high probability. Our\nkey idea is to transform confidence bounds of a learning method into a\nconditional two-sample test, and we instantiate this principle for kernel ridge\nregression (KRR) and conditional kernel mean embeddings. We generalize existing\npointwise-in-time or time-uniform confidence bounds for KRR to\npreviously-inaccessible yet essential cases such as infinite-dimensional\noutputs with non-trace-class kernels. These bounds enable circumventing the\nneed for independent data in our statistical tests, since they allow online\nsampling. We also introduce bootstrapping schemes leveraging the parametric\nform of testing thresholds identified in theory to avoid tuning inaccessible\nparameters, making our method readily applicable in practice. Such conditional\ntwo-sample tests are especially relevant in applications where data arrive\nsequentially or non-independently, or when output distributions vary with\noperational parameters. We demonstrate their utility through examples in\nprocess monitoring and comparison of dynamical systems. Overall, our results\nestablish a comprehensive foundation for conditional two-sample testing, from\ntheoretical guarantees to practical implementation, and advance the\nstate-of-the-art on the concentration of vector-valued least squares\nestimation.", "AI": {"tldr": "A framework for hypothesis testing on conditional probability distributions is proposed, enabling conditional two-sample tests to identify covariate differences. It leverages learning method confidence bounds, generalizes KRR bounds, and introduces practical bootstrapping schemes.", "motivation": "To address the need for conditional two-sample tests in scenarios with sequential, non-independent data or varying output distributions, such as process monitoring and dynamical systems comparison.", "method": "Transforms confidence bounds of learning methods (e.g., KRR, conditional kernel mean embeddings) into tests, generalizes KRR bounds for infinite-dimensional outputs, and introduces bootstrapping for practical use.", "result": "Enables conditional two-sample testing without independent data, with theoretical guarantees and practical applicability demonstrated in process monitoring and dynamical systems.", "conclusion": "The work establishes a foundation for conditional two-sample testing, advancing vector-valued least squares estimation and offering practical implementation."}}
{"id": "2506.03913", "pdf": "https://arxiv.org/pdf/2506.03913", "abs": "https://arxiv.org/abs/2506.03913", "authors": ["Claire Barale", "Michael Rovatsos", "Nehal Bhuta"], "title": "When Fairness Isn't Statistical: The Limits of Machine Learning in Evaluating Legal Reasoning", "categories": ["cs.CL", "cs.LG"], "comment": "Preprint", "summary": "Legal decisions are increasingly evaluated for fairness, consistency, and\nbias using machine learning (ML) techniques. In high-stakes domains like\nrefugee adjudication, such methods are often applied to detect disparities in\noutcomes. Yet it remains unclear whether statistical methods can meaningfully\nassess fairness in legal contexts shaped by discretion, normative complexity,\nand limited ground truth.\n  In this paper, we empirically evaluate three common ML approaches\n(feature-based analysis, semantic clustering, and predictive modeling) on a\nlarge, real-world dataset of 59,000+ Canadian refugee decisions (AsyLex). Our\nexperiments show that these methods produce divergent and sometimes\ncontradictory signals, that predictive modeling often depends on contextual and\nprocedural features rather than legal features, and that semantic clustering\nfails to capture substantive legal reasoning.\n  We show limitations of statistical fairness evaluation, challenge the\nassumption that statistical regularity equates to fairness, and argue that\ncurrent computational approaches fall short of evaluating fairness in legally\ndiscretionary domains. We argue that evaluating fairness in law requires\nmethods grounded not only in data, but in legal reasoning and institutional\ncontext.", "AI": {"tldr": "The paper evaluates ML methods for fairness in legal decisions, finding limitations in current approaches and advocating for context-aware, legally grounded methods.", "motivation": "To assess whether statistical ML methods can effectively evaluate fairness in discretionary legal contexts like refugee adjudication.", "method": "Empirical evaluation of three ML approaches (feature-based analysis, semantic clustering, predictive modeling) on 59,000+ Canadian refugee decisions.", "result": "ML methods produce divergent signals, rely on procedural features, and fail to capture legal reasoning, highlighting limitations in statistical fairness evaluation.", "conclusion": "Current computational approaches are insufficient; fairness evaluation in law requires integrating legal reasoning and institutional context."}}
{"id": "2506.03709", "pdf": "https://arxiv.org/pdf/2506.03709", "abs": "https://arxiv.org/abs/2506.03709", "authors": ["Aniruddh Sikdar", "Aditya Gandhamal", "Suresh Sundaram"], "title": "AetherVision-Bench: An Open-Vocabulary RGB-Infrared Benchmark for Multi-Angle Segmentation across Aerial and Ground Perspectives", "categories": ["cs.CV"], "comment": "Accepted at Workshop on Foundation Models Meet Embodied Agents at\n  CVPR 2025 (Non-archival Track)", "summary": "Open-vocabulary semantic segmentation (OVSS) involves assigning labels to\neach pixel in an image based on textual descriptions, leveraging world models\nlike CLIP. However, they encounter significant challenges in cross-domain\ngeneralization, hindering their practical efficacy in real-world applications.\nEmbodied AI systems are transforming autonomous navigation for ground vehicles\nand drones by enhancing their perception abilities, and in this study, we\npresent AetherVision-Bench, a benchmark for multi-angle segmentation across\naerial, and ground perspectives, which facilitates an extensive evaluation of\nperformance across different viewing angles and sensor modalities. We assess\nstate-of-the-art OVSS models on the proposed benchmark and investigate the key\nfactors that impact the performance of zero-shot transfer models. Our work\npioneers the creation of a robustness benchmark, offering valuable insights and\nestablishing a foundation for future research.", "AI": {"tldr": "The paper introduces AetherVision-Bench, a benchmark for evaluating open-vocabulary semantic segmentation (OVSS) models across aerial and ground perspectives, addressing cross-domain generalization challenges.", "motivation": "To improve the practical efficacy of OVSS models in real-world applications by addressing their cross-domain generalization issues, particularly in embodied AI systems like autonomous navigation.", "method": "Creation of AetherVision-Bench, a multi-angle segmentation benchmark, and evaluation of state-of-the-art OVSS models to identify key performance factors.", "result": "The benchmark provides insights into the performance of zero-shot transfer models across different viewing angles and sensor modalities.", "conclusion": "The work establishes a foundation for future research by pioneering a robustness benchmark for OVSS models."}}
{"id": "2506.04001", "pdf": "https://arxiv.org/pdf/2506.04001", "abs": "https://arxiv.org/abs/2506.04001", "authors": ["Han Ji", "Yuqi Feng", "Jiahao Fan", "Yanan Sun"], "title": "CARL: Causality-guided Architecture Representation Learning for an Interpretable Performance Predictor", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Performance predictors have emerged as a promising method to accelerate the\nevaluation stage of neural architecture search (NAS). These predictors estimate\nthe performance of unseen architectures by learning from the correlation\nbetween a small set of trained architectures and their performance. However,\nmost existing predictors ignore the inherent distribution shift between limited\ntraining samples and diverse test samples. Hence, they tend to learn spurious\ncorrelations as shortcuts to predictions, leading to poor generalization. To\naddress this, we propose a Causality-guided Architecture Representation\nLearning (CARL) method aiming to separate critical (causal) and redundant\n(non-causal) features of architectures for generalizable architecture\nperformance prediction. Specifically, we employ a substructure extractor to\nsplit the input architecture into critical and redundant substructures in the\nlatent space. Then, we generate multiple interventional samples by pairing\ncritical representations with diverse redundant representations to prioritize\ncritical features. Extensive experiments on five NAS search spaces demonstrate\nthe state-of-the-art accuracy and superior interpretability of CARL. For\ninstance, CARL achieves 97.67% top-1 accuracy on CIFAR-10 using DARTS.", "AI": {"tldr": "CARL improves neural architecture search (NAS) performance prediction by separating causal and non-causal features, achieving high accuracy and interpretability.", "motivation": "Existing performance predictors in NAS often fail due to distribution shifts and spurious correlations, limiting generalization.", "method": "CARL uses a substructure extractor to split architectures into causal and non-causal features, generating interventional samples to prioritize critical features.", "result": "CARL achieves state-of-the-art accuracy, e.g., 97.67% top-1 accuracy on CIFAR-10 with DARTS.", "conclusion": "CARL effectively addresses generalization issues in NAS performance prediction by focusing on causal features."}}
{"id": "2506.03910", "pdf": "https://arxiv.org/pdf/2506.03910", "abs": "https://arxiv.org/abs/2506.03910", "authors": ["Shyam Prabhu", "P Akshay Kumar", "Antov Selwinston", "Pavan Taduvai", "Shreya Bairi", "Rohit Batra"], "title": "Enhancing Experimental Efficiency in Materials Design: A Comparative Study of Taguchi and Machine Learning Methods", "categories": ["cs.LG"], "comment": "7 pages, 3 figures", "summary": "Materials design problems often require optimizing multiple variables,\nrendering full factorial exploration impractical. Design of experiment (DOE)\nmethods, such as Taguchi technique, are commonly used to efficiently sample the\ndesign space but they inherently lack the ability to capture non-linear\ndependency of process variables. In this work, we demonstrate how machine\nlearning (ML) methods can be used to overcome these limitations. We compare the\nperformance of Taguchi method against an active learning based Gaussian process\nregression (GPR) model in a wire arc additive manufacturing (WAAM) process to\naccurately predict aspects of bead geometry, including penetration depth, bead\nwidth, and height. While Taguchi method utilized a three-factor, five-level L25\northogonal array to suggest weld parameters, the GPR model used an\nuncertainty-based exploration acquisition function coupled with latin hypercube\nsampling for initial training data. Accuracy and efficiency of both models was\nevaluated on 15 test cases, with GPR outperforming Taguchi in both metrics.\nThis work applies to broader materials processing domain requiring efficient\nexploration of complex parameters.", "AI": {"tldr": "Machine learning (GPR) outperforms Taguchi method in optimizing WAAM bead geometry, offering better accuracy and efficiency.", "motivation": "Full factorial exploration is impractical for multi-variable materials design. DOE methods like Taguchi lack non-linear dependency capture, motivating ML solutions.", "method": "Compared Taguchi (L25 orthogonal array) with active learning-based GPR (uncertainty exploration + latin hypercube sampling) in WAAM.", "result": "GPR outperformed Taguchi in accuracy and efficiency across 15 test cases.", "conclusion": "ML methods like GPR are superior for complex parameter exploration in materials processing."}}
{"id": "2506.03916", "pdf": "https://arxiv.org/pdf/2506.03916", "abs": "https://arxiv.org/abs/2506.03916", "authors": ["Agostina Calabrese", "Tom Sherborne", "Bj\u00f6rn Ross", "Mirella Lapata"], "title": "Compositional Generalisation for Explainable Hate Speech Detection", "categories": ["cs.CL"], "comment": null, "summary": "Hate speech detection is key to online content moderation, but current models\nstruggle to generalise beyond their training data. This has been linked to\ndataset biases and the use of sentence-level labels, which fail to teach models\nthe underlying structure of hate speech. In this work, we show that even when\nmodels are trained with more fine-grained, span-level annotations (e.g.,\n\"artists\" is labeled as target and \"are parasites\" as dehumanising comparison),\nthey struggle to disentangle the meaning of these labels from the surrounding\ncontext. As a result, combinations of expressions that deviate from those seen\nduring training remain particularly difficult for models to detect. We\ninvestigate whether training on a dataset where expressions occur with equal\nfrequency across all contexts can improve generalisation. To this end, we\ncreate U-PLEAD, a dataset of ~364,000 synthetic posts, along with a novel\ncompositional generalisation benchmark of ~8,000 manually validated posts.\nTraining on a combination of U-PLEAD and real data improves compositional\ngeneralisation while achieving state-of-the-art performance on the\nhuman-sourced PLEAD.", "AI": {"tldr": "The paper addresses hate speech detection challenges by introducing U-PLEAD, a synthetic dataset, to improve model generalization beyond training data biases.", "motivation": "Current hate speech detection models struggle with generalization due to dataset biases and sentence-level labels, failing to capture hate speech structure.", "method": "The authors create U-PLEAD, a synthetic dataset with balanced expression frequencies, and combine it with real data for training.", "result": "Training with U-PLEAD and real data improves compositional generalization and achieves state-of-the-art performance on PLEAD.", "conclusion": "Balancing expression frequencies across contexts enhances hate speech detection model generalization."}}
{"id": "2506.03713", "pdf": "https://arxiv.org/pdf/2506.03713", "abs": "https://arxiv.org/abs/2506.03713", "authors": ["Sam Bahrami", "Dylan Campbell"], "title": "Pl\u00fcckeRF: A Line-based 3D Representation for Few-view Reconstruction", "categories": ["cs.CV"], "comment": null, "summary": "Feed-forward 3D reconstruction methods aim to predict the 3D structure of a\nscene directly from input images, providing a faster alternative to per-scene\noptimization approaches. Significant progress has been made in single-view and\nfew-view reconstruction using learned priors that infer object shape and\nappearance, even for unobserved regions. However, there is substantial\npotential to enhance these methods by better leveraging information from\nmultiple views when available. To address this, we propose a few-view\nreconstruction model that more effectively harnesses multi-view information.\nOur approach introduces a simple mechanism that connects the 3D representation\nwith pixel rays from the input views, allowing for preferential sharing of\ninformation between nearby 3D locations and between 3D locations and nearby\npixel rays. We achieve this by defining the 3D representation as a set of\nstructured, feature-augmented lines; the Pl\\\"uckeRF representation. Using this\nrepresentation, we demonstrate improvements in reconstruction quality over the\nequivalent triplane representation and state-of-the-art feedforward\nreconstruction methods.", "AI": {"tldr": "A feed-forward 3D reconstruction method improves multi-view information utilization with a novel Pl\u00fcckeRF representation, outperforming triplane and state-of-the-art methods.", "motivation": "Enhancing few-view 3D reconstruction by better leveraging multi-view information, addressing limitations of current learned priors.", "method": "Introduces Pl\u00fcckeRF, a structured feature-augmented line representation, connecting 3D locations with input pixel rays for improved information sharing.", "result": "Demonstrates superior reconstruction quality compared to triplane and leading feedforward methods.", "conclusion": "The Pl\u00fcckeRF representation effectively harnesses multi-view data, advancing feed-forward 3D reconstruction."}}
{"id": "2506.04006", "pdf": "https://arxiv.org/pdf/2506.04006", "abs": "https://arxiv.org/abs/2506.04006", "authors": ["Fernando de Meer Pardo", "Branka Hadji Misheva", "Martin Braschler", "Kurt Stockinger"], "title": "TransClean: Finding False Positives in Multi-Source Entity Matching under Real-World Conditions via Transitive Consistency", "categories": ["cs.DB", "cs.AI", "cs.LG"], "comment": null, "summary": "We present TransClean, a method for detecting false positive predictions of\nentity matching algorithms under real-world conditions characterized by\nlarge-scale, noisy, and unlabeled multi-source datasets that undergo\ndistributional shifts. TransClean is explicitly designed to operate with\nmultiple data sources in an efficient, robust and fast manner while accounting\nfor edge cases and requiring limited manual labeling. TransClean leverages the\nTransitive Consistency of a matching, a measure of the consistency of a\npairwise matching model f_theta on the matching it produces G_f_theta, based\nboth on its predictions on directly evaluated record pairs and its predictions\non implied record pairs. TransClean iteratively modifies a matching through\ngradually removing false positive matches while removing as few true positive\nmatches as possible. In each of these steps, the estimation of the Transitive\nConsistency is exclusively done through model evaluations and produces\nquantities that can be used as proxies of the amounts of true and false\npositives in the matching while not requiring any manual labeling, producing an\nestimate of the quality of the matching and indicating which record groups are\nlikely to contain false positives. In our experiments, we compare combining\nTransClean with a naively trained pairwise matching model (DistilBERT) and with\na state-of-the-art end-to-end matching method (CLER) and illustrate the\nflexibility of TransClean in being able to detect most of the false positives\nof either setup across a variety of datasets. Our experiments show that\nTransClean induces an average +24.42 F1 score improvement for entity matching\nin a multi-source setting when compared to traditional pair-wise matching\nalgorithms.", "AI": {"tldr": "TransClean detects false positives in entity matching under noisy, large-scale, and unlabeled multi-source datasets, improving F1 score by +24.42.", "motivation": "Addressing false positives in entity matching under real-world noisy and unlabeled conditions with distributional shifts.", "method": "Leverages Transitive Consistency to iteratively remove false positives without manual labeling, using model evaluations.", "result": "Improves F1 score by +24.42 compared to traditional methods, working well with both naive and state-of-the-art models.", "conclusion": "TransClean is efficient, robust, and flexible for detecting false positives in multi-source entity matching."}}
{"id": "2506.03911", "pdf": "https://arxiv.org/pdf/2506.03911", "abs": "https://arxiv.org/abs/2506.03911", "authors": ["Chamsi Hssaine", "Yichun Hu", "Ciara Pike-Burke"], "title": "Learning Fair And Effective Points-Based Rewards Programs", "categories": ["cs.LG", "math.OC"], "comment": null, "summary": "Points-based rewards programs are a prevalent way to incentivize customer\nloyalty; in these programs, customers who make repeated purchases from a seller\naccumulate points, working toward eventual redemption of a free reward. These\nprograms have recently come under scrutiny due to accusations of unfair\npractices in their implementation. Motivated by these concerns, we study the\nproblem of fairly designing points-based rewards programs, with a focus on two\nobstacles that put fairness at odds with their effectiveness. First, due to\ncustomer heterogeneity, the seller should set different redemption thresholds\nfor different customers to generate high revenue. Second, the relationship\nbetween customer behavior and the number of accumulated points is typically\nunknown; this requires experimentation which may unfairly devalue customers'\npreviously earned points. We first show that an individually fair rewards\nprogram that uses the same redemption threshold for all customers suffers a\nloss in revenue of at most a factor of $1+\\ln 2$, compared to the optimal\npersonalized strategy that differentiates between customers. We then tackle the\nproblem of designing temporally fair learning algorithms in the presence of\ndemand uncertainty. Toward this goal, we design a learning algorithm that\nlimits the risk of point devaluation due to experimentation by only changing\nthe redemption threshold $O(\\log T)$ times, over a horizon of length $T$. This\nalgorithm achieves the optimal (up to polylogarithmic factors)\n$\\widetilde{O}(\\sqrt{T})$ regret in expectation. We then modify this algorithm\nto only ever decrease redemption thresholds, leading to improved fairness at a\ncost of only a constant factor in regret. Extensive numerical experiments show\nthe limited value of personalization in average-case settings, in addition to\ndemonstrating the strong practical performance of our proposed learning\nalgorithms.", "AI": {"tldr": "The paper explores fair design of points-based rewards programs, balancing revenue and fairness despite customer heterogeneity and unknown behavior-points relationships. It proposes learning algorithms to limit unfair point devaluation while maintaining revenue.", "motivation": "Address concerns about unfair practices in points-based rewards programs by ensuring fairness without significantly compromising effectiveness or revenue.", "method": "Analyze fair rewards programs with uniform thresholds and design learning algorithms to limit threshold changes and devaluation risks.", "result": "Uniform thresholds lose at most a factor of $1+\\ln 2$ revenue vs. personalized strategies. Proposed algorithms achieve optimal regret and limit unfairness.", "conclusion": "Fair rewards programs can balance revenue and fairness, with limited value in personalization and strong performance of proposed algorithms."}}
{"id": "2506.03922", "pdf": "https://arxiv.org/pdf/2506.03922", "abs": "https://arxiv.org/abs/2506.03922", "authors": ["Zhaolu Kang", "Junhao Gong", "Jiaxu Yan", "Wanke Xia", "Yian Wang", "Ziwen Wang", "Huaxuan Ding", "Zhuo Cheng", "Wenhao Cao", "Zhiyuan Feng", "Siqi He", "Shannan Yan", "Junzhe Chen", "Xiaomin He", "Chaoya Jiang", "Wei Ye", "Kaidong Yu", "Xuelong Li"], "title": "HSSBench: Benchmarking Humanities and Social Sciences Ability for Multimodal Large Language Models", "categories": ["cs.CL"], "comment": null, "summary": "Multimodal Large Language Models (MLLMs) have demonstrated significant\npotential to advance a broad range of domains. However, current benchmarks for\nevaluating MLLMs primarily emphasize general knowledge and vertical\nstep-by-step reasoning typical of STEM disciplines, while overlooking the\ndistinct needs and potential of the Humanities and Social Sciences (HSS). Tasks\nin the HSS domain require more horizontal, interdisciplinary thinking and a\ndeep integration of knowledge across related fields, which presents unique\nchallenges for MLLMs, particularly in linking abstract concepts with\ncorresponding visual representations. Addressing this gap, we present HSSBench,\na dedicated benchmark designed to assess the capabilities of MLLMs on HSS tasks\nin multiple languages, including the six official languages of the United\nNations. We also introduce a novel data generation pipeline tailored for HSS\nscenarios, in which multiple domain experts and automated agents collaborate to\ngenerate and iteratively refine each sample. HSSBench contains over 13,000\nmeticulously designed samples, covering six key categories. We benchmark more\nthan 20 mainstream MLLMs on HSSBench and demonstrate that it poses significant\nchallenges even for state-of-the-art models. We hope that this benchmark will\ninspire further research into enhancing the cross-disciplinary reasoning\nabilities of MLLMs, especially their capacity to internalize and connect\nknowledge across fields.", "AI": {"tldr": "HSSBench is a new benchmark for evaluating Multimodal Large Language Models (MLLMs) on Humanities and Social Sciences (HSS) tasks, addressing gaps in current benchmarks.", "motivation": "Current MLLM benchmarks focus on STEM disciplines, neglecting HSS needs like interdisciplinary thinking and abstract-visual linking.", "method": "HSSBench includes 13,000 samples in six categories, generated via a collaborative pipeline of experts and automated agents, covering six UN languages.", "result": "Testing 20+ MLLMs shows HSSBench poses significant challenges, even for top models.", "conclusion": "HSSBench aims to inspire research into improving MLLMs' cross-disciplinary reasoning and knowledge integration."}}
{"id": "2506.03714", "pdf": "https://arxiv.org/pdf/2506.03714", "abs": "https://arxiv.org/abs/2506.03714", "authors": ["Shuai Liu", "Mingyue Cui", "Boyang Li", "Quanmin Liang", "Tinghe Hong", "Kai Huang", "Yunxiao Shan", "Kai Huang"], "title": "FSHNet: Fully Sparse Hybrid Network for 3D Object Detection", "categories": ["cs.CV"], "comment": "Accepted by CVPR2025", "summary": "Fully sparse 3D detectors have recently gained significant attention due to\ntheir efficiency in long-range detection. However, sparse 3D detectors extract\nfeatures only from non-empty voxels, which impairs long-range interactions and\ncauses the center feature missing. The former weakens the feature extraction\ncapability, while the latter hinders network optimization. To address these\nchallenges, we introduce the Fully Sparse Hybrid Network (FSHNet). FSHNet\nincorporates a proposed SlotFormer block to enhance the long-range feature\nextraction capability of existing sparse encoders. The SlotFormer divides\nsparse voxels using a slot partition approach, which, compared to traditional\nwindow partition, provides a larger receptive field. Additionally, we propose a\ndynamic sparse label assignment strategy to deeply optimize the network by\nproviding more high-quality positive samples. To further enhance performance,\nwe introduce a sparse upsampling module to refine downsampled voxels,\npreserving fine-grained details crucial for detecting small objects. Extensive\nexperiments on the Waymo, nuScenes, and Argoverse2 benchmarks demonstrate the\neffectiveness of FSHNet. The code is available at\nhttps://github.com/Say2L/FSHNet.", "AI": {"tldr": "FSHNet improves sparse 3D detectors by enhancing long-range feature extraction and optimizing network performance with dynamic label assignment and sparse upsampling.", "motivation": "Sparse 3D detectors lack long-range interactions and center features, weakening feature extraction and optimization.", "method": "FSHNet uses SlotFormer for better feature extraction, dynamic sparse label assignment for optimization, and sparse upsampling for detail preservation.", "result": "FSHNet shows effectiveness on Waymo, nuScenes, and Argoverse2 benchmarks.", "conclusion": "FSHNet addresses key limitations of sparse 3D detectors, improving performance and feature extraction."}}
{"id": "2506.04036", "pdf": "https://arxiv.org/pdf/2506.04036", "abs": "https://arxiv.org/abs/2506.04036", "authors": ["Wei Wenying", "Zhao Kaifa", "Xue Lei", "Fan Ming"], "title": "Privacy and Security Threat for OpenAI GPTs", "categories": ["cs.CR", "cs.AI"], "comment": null, "summary": "Large language models (LLMs) demonstrate powerful information handling\ncapabilities and are widely integrated into chatbot applications. OpenAI\nprovides a platform for developers to construct custom GPTs, extending\nChatGPT's functions and integrating external services. Since its release in\nNovember 2023, over 3 million custom GPTs have been created. However, such a\nvast ecosystem also conceals security and privacy threats. For developers,\ninstruction leaking attacks threaten the intellectual property of instructions\nin custom GPTs through carefully crafted adversarial prompts. For users,\nunwanted data access behavior by custom GPTs or integrated third-party services\nraises significant privacy concerns. To systematically evaluate the scope of\nthreats in real-world LLM applications, we develop three phases instruction\nleaking attacks target GPTs with different defense level. Our widespread\nexperiments on 10,000 real-world custom GPTs reveal that over 98.8% of GPTs are\nvulnerable to instruction leaking attacks via one or more adversarial prompts,\nand half of the remaining GPTs can also be attacked through multiround\nconversations. We also developed a framework to assess the effectiveness of\ndefensive strategies and identify unwanted behaviors in custom GPTs. Our\nfindings show that 77.5% of custom GPTs with defense strategies are vulnerable\nto basic instruction leaking attacks. Additionally, we reveal that 738 custom\nGPTs collect user conversational information, and identified 8 GPTs exhibiting\ndata access behaviors that are unnecessary for their intended functionalities.\nOur findings raise awareness among GPT developers about the importance of\nintegrating specific defensive strategies in their instructions and highlight\nusers' concerns about data privacy when using LLM-based applications.", "AI": {"tldr": "The paper investigates security and privacy threats in custom GPTs, revealing vulnerabilities in instruction leaking attacks and unwanted data access behaviors.", "motivation": "To evaluate the scope of security and privacy threats in real-world LLM applications, particularly custom GPTs, due to their widespread use and potential risks.", "method": "Developed three-phase instruction leaking attacks targeting GPTs with varying defense levels and a framework to assess defensive strategies and unwanted behaviors.", "result": "Over 98.8% of GPTs are vulnerable to instruction leaking attacks, and 77.5% of defended GPTs are still susceptible. Unwanted data access behaviors were identified in 738 GPTs.", "conclusion": "Highlights the need for better defensive strategies in custom GPTs and raises awareness about data privacy concerns for users."}}
{"id": "2506.03914", "pdf": "https://arxiv.org/pdf/2506.03914", "abs": "https://arxiv.org/abs/2506.03914", "authors": ["Eduardo Santos Escriche", "Stefanie Jegelka"], "title": "Learning equivariant models by discovering symmetries with learnable augmentations", "categories": ["cs.LG"], "comment": null, "summary": "Recently, a trend has emerged that favors learning relevant symmetries from\ndata in geometric domains instead of designing constrained architectures. To do\nso, two popular options are (1) to modify the training protocol, e.g., with a\nspecific loss and data augmentations (soft equivariance), or (2) to ignore\nequivariance and infer it only implicitly. However, both options have\nlimitations: soft equivariance requires a priori knowledge about relevant\nsymmetries, while inferring symmetries merely via the task and larger data\nlacks interpretability. To address both limitations, we propose SEMoLA, an\nend-to-end approach that jointly (1) discovers a priori unknown symmetries in\nthe data via learnable data augmentations, and (2) softly encodes the\nrespective approximate equivariance into an arbitrary unconstrained model.\nHence, it does not need prior knowledge about symmetries, it offers\ninterpretability, and it maintains robustness to distribution shifts.\nEmpirically, we demonstrate the ability of SEMoLA to robustly discover relevant\nsymmetries while achieving high prediction accuracy across various datasets,\nencompassing multiple data modalities and underlying symmetry groups.", "AI": {"tldr": "SEMoLA is an end-to-end method for discovering unknown symmetries in data and encoding approximate equivariance into models, addressing limitations of existing approaches.", "motivation": "Existing methods for learning symmetries from data either require prior knowledge (soft equivariance) or lack interpretability (implicit inference). SEMoLA aims to overcome these limitations.", "method": "SEMoLA jointly discovers unknown symmetries via learnable data augmentations and softly encodes approximate equivariance into unconstrained models.", "result": "SEMoLA robustly discovers relevant symmetries and achieves high prediction accuracy across diverse datasets and symmetry groups.", "conclusion": "SEMoLA provides a flexible, interpretable, and robust solution for learning symmetries without prior knowledge."}}
{"id": "2506.03923", "pdf": "https://arxiv.org/pdf/2506.03923", "abs": "https://arxiv.org/abs/2506.03923", "authors": ["Mohammadamin Shafiei", "Hamidreza Saffari", "Nafise Sadat Moosavi"], "title": "More or Less Wrong: A Benchmark for Directional Bias in LLM Comparative Reasoning", "categories": ["cs.CL"], "comment": null, "summary": "Large language models (LLMs) are known to be sensitive to input phrasing, but\nthe mechanisms by which semantic cues shape reasoning remain poorly understood.\nWe investigate this phenomenon in the context of comparative math problems with\nobjective ground truth, revealing a consistent and directional framing bias:\nlogically equivalent questions containing the words ``more'', ``less'', or\n``equal'' systematically steer predictions in the direction of the framing\nterm. To study this effect, we introduce MathComp, a controlled benchmark of\n300 comparison scenarios, each evaluated under 14 prompt variants across three\nLLM families. We find that model errors frequently reflect linguistic steering,\nsystematic shifts toward the comparative term present in the prompt.\nChain-of-thought prompting reduces these biases, but its effectiveness varies:\nfree-form reasoning is more robust, while structured formats may preserve or\nreintroduce directional drift. Finally, we show that including demographic\nidentity terms (e.g., ``a woman'', ``a Black person'') in input scenarios\namplifies directional drift, despite identical underlying quantities,\nhighlighting the interplay between semantic framing and social referents. These\nfindings expose critical blind spots in standard evaluation and motivate\nframing-aware benchmarks for diagnosing reasoning robustness and fairness in\nLLMs.", "AI": {"tldr": "LLMs exhibit framing bias in comparative math problems, influenced by terms like 'more', 'less', or 'equal'. The MathComp benchmark reveals this bias, mitigated partially by chain-of-thought prompting. Demographic terms amplify bias, highlighting fairness concerns.", "motivation": "To understand how semantic framing biases LLM reasoning, especially in comparative contexts, and to evaluate robustness and fairness.", "method": "Introduced MathComp, a benchmark of 300 comparison scenarios tested under 14 prompt variants across three LLM families. Analyzed framing bias and mitigation via chain-of-thought prompting.", "result": "Framing terms systematically steer predictions. Chain-of-thought helps but varies in effectiveness. Demographic terms exacerbate bias.", "conclusion": "Framing biases are critical blind spots; benchmarks should account for them to ensure robust and fair LLM reasoning."}}
{"id": "2506.03753", "pdf": "https://arxiv.org/pdf/2506.03753", "abs": "https://arxiv.org/abs/2506.03753", "authors": ["Caiyi Sun", "Yujing Sun", "Xiao Han", "Zemin Yang", "Jiawei Liu", "Xinge Zhu", "Siu Ming Yiu", "Yuexin Ma"], "title": "HUMOF: Human Motion Forecasting in Interactive Social Scenes", "categories": ["cs.CV"], "comment": null, "summary": "Complex scenes present significant challenges for predicting human behaviour\ndue to the abundance of interaction information, such as human-human and\nhumanenvironment interactions. These factors complicate the analysis and\nunderstanding of human behaviour, thereby increasing the uncertainty in\nforecasting human motions. Existing motion prediction methods thus struggle in\nthese complex scenarios. In this paper, we propose an effective method for\nhuman motion forecasting in interactive scenes. To achieve a comprehensive\nrepresentation of interactions, we design a hierarchical interaction feature\nrepresentation so that high-level features capture the overall context of the\ninteractions, while low-level features focus on fine-grained details. Besides,\nwe propose a coarse-to-fine interaction reasoning module that leverages both\nspatial and frequency perspectives to efficiently utilize hierarchical\nfeatures, thereby enhancing the accuracy of motion predictions. Our method\nachieves state-of-the-art performance across four public datasets. Code will be\nreleased when this paper is published.", "AI": {"tldr": "A hierarchical interaction feature representation and coarse-to-fine reasoning module improve human motion prediction in complex scenes.", "motivation": "Complex scenes with abundant interactions complicate human behavior analysis and motion prediction, challenging existing methods.", "method": "Proposes hierarchical interaction features (high-level for context, low-level for details) and a coarse-to-fine reasoning module using spatial and frequency perspectives.", "result": "Achieves state-of-the-art performance on four public datasets.", "conclusion": "The method effectively addresses challenges in complex scenes, enhancing motion prediction accuracy."}}
{"id": "2506.04038", "pdf": "https://arxiv.org/pdf/2506.04038", "abs": "https://arxiv.org/abs/2506.04038", "authors": ["Sven Kirchner", "Alois C. Knoll"], "title": "Generating Automotive Code: Large Language Models for Software Development and Verification in Safety-Critical Systems", "categories": ["cs.SE", "cs.AI"], "comment": "8 pages; Accepted for publication at the 36th IEEE Intelligent\n  Vehicles Symposium (IV), Cluj-Napoca, Romania, June 22-25, 2025", "summary": "Developing safety-critical automotive software presents significant\nchallenges due to increasing system complexity and strict regulatory demands.\nThis paper proposes a novel framework integrating Generative Artificial\nIntelligence (GenAI) into the Software Development Lifecycle (SDLC). The\nframework uses Large Language Models (LLMs) to automate code generation in\nlanguages such as C++, incorporating safety-focused practices such as static\nverification, test-driven development and iterative refinement. A\nfeedback-driven pipeline ensures the integration of test, simulation and\nverification for compliance with safety standards. The framework is validated\nthrough the development of an Adaptive Cruise Control (ACC) system. Comparative\nbenchmarking of LLMs ensures optimal model selection for accuracy and\nreliability. Results demonstrate that the framework enables automatic code\ngeneration while ensuring compliance with safety-critical requirements,\nsystematically integrating GenAI into automotive software engineering. This\nwork advances the use of AI in safety-critical domains, bridging the gap\nbetween state-of-the-art generative models and real-world safety requirements.", "AI": {"tldr": "A novel framework integrates GenAI into automotive SDLC, automating code generation with LLMs while ensuring safety compliance, validated via an ACC system.", "motivation": "Addressing challenges in safety-critical automotive software due to complexity and regulatory demands.", "method": "Uses LLMs for automated code generation in C++, incorporating safety practices like static verification and test-driven development, with a feedback-driven pipeline for compliance.", "result": "Demonstrates automatic code generation meeting safety-critical requirements, validated through ACC system development.", "conclusion": "Advances AI use in safety-critical domains by bridging generative models and real-world safety needs."}}
{"id": "2506.03919", "pdf": "https://arxiv.org/pdf/2506.03919", "abs": "https://arxiv.org/abs/2506.03919", "authors": ["Lorenz Kummer", "Samir Moustafa", "Anatol Ehrlich", "Franka Bause", "Nikolaus Suess", "Wilfried N. Gansterer", "Nils M. Kriege"], "title": "Weisfeiler and Leman Go Gambling: Why Expressive Lottery Tickets Win", "categories": ["cs.LG"], "comment": "Accepted at ICML 2025", "summary": "The lottery ticket hypothesis (LTH) is well-studied for convolutional neural\nnetworks but has been validated only empirically for graph neural networks\n(GNNs), for which theoretical findings are largely lacking. In this paper, we\nidentify the expressivity of sparse subnetworks, i.e. their ability to\ndistinguish non-isomorphic graphs, as crucial for finding winning tickets that\npreserve the predictive performance. We establish conditions under which the\nexpressivity of a sparsely initialized GNN matches that of the full network,\nparticularly when compared to the Weisfeiler-Leman test, and in that context\nput forward and prove a Strong Expressive Lottery Ticket Hypothesis. We\nsubsequently show that an increased expressivity in the initialization\npotentially accelerates model convergence and improves generalization. Our\nfindings establish novel theoretical foundations for both LTH and GNN research,\nhighlighting the importance of maintaining expressivity in sparsely initialized\nGNNs. We illustrate our results using examples from drug discovery.", "AI": {"tldr": "The paper establishes theoretical foundations for the lottery ticket hypothesis (LTH) in graph neural networks (GNNs), focusing on expressivity of sparse subnetworks and their ability to match full-network performance. It introduces a Strong Expressive Lottery Ticket Hypothesis and demonstrates its implications for convergence and generalization, with applications in drug discovery.", "motivation": "The motivation is to bridge the gap in theoretical understanding of LTH for GNNs, which has only been empirically validated. The study aims to identify conditions where sparse subnetworks maintain expressivity and performance.", "method": "The method involves analyzing the expressivity of sparse subnetworks in GNNs, comparing them to the Weisfeiler-Leman test, and proving the Strong Expressive Lottery Ticket Hypothesis. Experiments include applications in drug discovery.", "result": "Results show that sparse subnetworks can match the expressivity of full networks under certain conditions, leading to faster convergence and better generalization. Theoretical proofs support these findings.", "conclusion": "The study provides novel theoretical insights into LTH for GNNs, emphasizing the role of expressivity in sparse subnetworks. It advances both LTH and GNN research, with practical implications for tasks like drug discovery."}}
{"id": "2506.03949", "pdf": "https://arxiv.org/pdf/2506.03949", "abs": "https://arxiv.org/abs/2506.03949", "authors": ["Junnan Zhu", "Jingyi Wang", "Bohan Yu", "Xiaoyu Wu", "Junbo Li", "Lei Wang", "Nan Xu"], "title": "TableEval: A Real-World Benchmark for Complex, Multilingual, and Multi-Structured Table Question Answering", "categories": ["cs.CL"], "comment": null, "summary": "LLMs have shown impressive progress in natural language processing. However,\nthey still face significant challenges in TableQA, where real-world\ncomplexities such as diverse table structures, multilingual data, and\ndomain-specific reasoning are crucial. Existing TableQA benchmarks are often\nlimited by their focus on simple flat tables and suffer from data leakage.\nFurthermore, most benchmarks are monolingual and fail to capture the\ncross-lingual and cross-domain variability in practical applications. To\naddress these limitations, we introduce TableEval, a new benchmark designed to\nevaluate LLMs on realistic TableQA tasks. Specifically, TableEval includes\ntables with various structures (such as concise, hierarchical, and nested\ntables) collected from four domains (including government, finance, academia,\nand industry reports). Besides, TableEval features cross-lingual scenarios with\ntables in Simplified Chinese, Traditional Chinese, and English. To minimize the\nrisk of data leakage, we collect all data from recent real-world documents.\nConsidering that existing TableQA metrics fail to capture semantic accuracy, we\nfurther propose SEAT, a new evaluation framework that assesses the alignment\nbetween model responses and reference answers at the sub-question level.\nExperimental results have shown that SEAT achieves high agreement with human\njudgment. Extensive experiments on TableEval reveal critical gaps in the\nability of state-of-the-art LLMs to handle these complex, real-world TableQA\ntasks, offering insights for future improvements. We make our dataset available\nhere: https://github.com/wenge-research/TableEval.", "AI": {"tldr": "The paper introduces TableEval, a new benchmark for evaluating LLMs on realistic TableQA tasks, addressing limitations like simple table structures, data leakage, and monolingual focus. It also proposes SEAT, a semantic accuracy evaluation framework.", "motivation": "Existing TableQA benchmarks are limited by simplistic table structures, monolingual data, and data leakage, failing to capture real-world complexities.", "method": "TableEval includes diverse table structures from four domains and three languages, with data collected from recent real-world documents. SEAT evaluates semantic accuracy at the sub-question level.", "result": "SEAT aligns well with human judgment, and experiments reveal gaps in state-of-the-art LLMs' ability to handle complex TableQA tasks.", "conclusion": "TableEval and SEAT provide a robust framework for evaluating LLMs on realistic TableQA tasks, highlighting areas for future improvement."}}
{"id": "2506.03798", "pdf": "https://arxiv.org/pdf/2506.03798", "abs": "https://arxiv.org/abs/2506.03798", "authors": ["Fan Shi", "Haiyang Yu", "Bin Li", "Xiangyang Xue"], "title": "CoLa: Chinese Character Decomposition with Compositional Latent Components", "categories": ["cs.CV"], "comment": null, "summary": "Humans can decompose Chinese characters into compositional components and\nrecombine them to recognize unseen characters. This reflects two cognitive\nprinciples: Compositionality, the idea that complex concepts are built on\nsimpler parts; and Learning-to-learn, the ability to learn strategies for\ndecomposing and recombining components to form new concepts. These principles\nprovide inductive biases that support efficient generalization. They are\ncritical to Chinese character recognition (CCR) in solving the zero-shot\nproblem, which results from the common long-tail distribution of Chinese\ncharacter datasets. Existing methods have made substantial progress in modeling\ncompositionality via predefined radical or stroke decomposition. However, they\noften ignore the learning-to-learn capability, limiting their ability to\ngeneralize beyond human-defined schemes. Inspired by these principles, we\npropose a deep latent variable model that learns Compositional Latent\ncomponents of Chinese characters (CoLa) without relying on human-defined\ndecomposition schemes. Recognition and matching can be performed by comparing\ncompositional latent components in the latent space, enabling zero-shot\ncharacter recognition. The experiments illustrate that CoLa outperforms\nprevious methods in both character the radical zero-shot CCR. Visualization\nindicates that the learned components can reflect the structure of characters\nin an interpretable way. Moreover, despite being trained on historical\ndocuments, CoLa can analyze components of oracle bone characters, highlighting\nits cross-dataset generalization ability.", "AI": {"tldr": "The paper proposes CoLa, a deep latent variable model for Chinese character recognition (CCR) that learns compositional components without human-defined schemes, improving zero-shot generalization.", "motivation": "Existing CCR methods rely on predefined decomposition schemes, ignoring the learning-to-learn capability, which limits generalization. The paper aims to address this by leveraging cognitive principles of compositionality and learning-to-learn.", "method": "The authors introduce CoLa, a deep latent variable model that autonomously learns compositional latent components of Chinese characters, enabling recognition and matching in latent space for zero-shot CCR.", "result": "CoLa outperforms previous methods in zero-shot CCR and demonstrates interpretable component learning. It also shows cross-dataset generalization by analyzing oracle bone characters.", "conclusion": "CoLa effectively addresses the limitations of human-defined decomposition schemes, offering a scalable and generalizable approach to CCR by learning compositional components autonomously."}}
{"id": "2506.04039", "pdf": "https://arxiv.org/pdf/2506.04039", "abs": "https://arxiv.org/abs/2506.04039", "authors": ["Jiulong Wu", "Zhengliang Shi", "Shuaiqiang Wang", "Jizhou Huang", "Dawei Yin", "Lingyong Yan", "Min Cao", "Min Zhang"], "title": "Mitigating Hallucinations in Large Vision-Language Models via Entity-Centric Multimodal Preference Optimization", "categories": ["cs.CV", "cs.AI", "cs.CL"], "comment": null, "summary": "Large Visual Language Models (LVLMs) have demonstrated impressive\ncapabilities across multiple tasks. However, their trustworthiness is often\nchallenged by hallucinations, which can be attributed to the modality\nmisalignment and the inherent hallucinations of their underlying Large Language\nModels (LLMs) backbone. Existing preference alignment methods focus on aligning\nmodel responses with human preferences while neglecting image-text modality\nalignment, resulting in over-reliance on LLMs and hallucinations. In this\npaper, we propose Entity-centric Multimodal Preference Optimization (EMPO),\nwhich achieves enhanced modality alignment than existing human preference\nalignment methods. Besides, to overcome the scarcity of high-quality multimodal\npreference data, we utilize open-source instruction datasets to automatically\nconstruct high-quality preference data across three aspects: image,\ninstruction, and response. Experiments on two human preference datasets and\nfive multimodal hallucination benchmarks demonstrate the effectiveness of EMPO,\ne.g., reducing hallucination rates by 85.9% on Object-HalBench and 49.8% on\nMM-HalBench.", "AI": {"tldr": "EMPO improves trustworthiness in LVLMs by enhancing modality alignment and reducing hallucinations using automatically constructed preference data.", "motivation": "Addressing hallucinations in LVLMs caused by modality misalignment and LLM backbone issues.", "method": "Proposes Entity-centric Multimodal Preference Optimization (EMPO) and uses open-source data to construct preference datasets.", "result": "Reduces hallucination rates by 85.9% on Object-HalBench and 49.8% on MM-HalBench.", "conclusion": "EMPO effectively enhances modality alignment and reduces hallucinations in LVLMs."}}
{"id": "2506.03931", "pdf": "https://arxiv.org/pdf/2506.03931", "abs": "https://arxiv.org/abs/2506.03931", "authors": ["Yotam Alexander", "Yonatan Slutzky", "Yuval Ran-Milo", "Nadav Cohen"], "title": "Do Neural Networks Need Gradient Descent to Generalize? A Theoretical Study", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "Conventional wisdom attributes the mysterious generalization abilities of\noverparameterized neural networks to gradient descent (and its variants). The\nrecent volume hypothesis challenges this view: it posits that these\ngeneralization abilities persist even when gradient descent is replaced by\nGuess & Check (G&C), i.e., by drawing weight settings until one that fits the\ntraining data is found. The validity of the volume hypothesis for wide and deep\nneural networks remains an open question. In this paper, we theoretically\ninvestigate this question for matrix factorization (with linear and non-linear\nactivation)--a common testbed in neural network theory. We first prove that\ngeneralization under G&C deteriorates with increasing width, establishing what\nis, to our knowledge, the first case where G&C is provably inferior to gradient\ndescent. Conversely, we prove that generalization under G&C improves with\nincreasing depth, revealing a stark contrast between wide and deep networks,\nwhich we further validate empirically. These findings suggest that even in\nsimple settings, there may not be a simple answer to the question of whether\nneural networks need gradient descent to generalize well.", "AI": {"tldr": "The paper challenges the volume hypothesis by showing that Guess & Check (G&C) performs worse than gradient descent in wide networks but better in deep ones, using matrix factorization as a testbed.", "motivation": "To investigate whether neural networks need gradient descent to generalize well, contrasting the volume hypothesis with conventional wisdom.", "method": "Theoretical analysis of matrix factorization (with linear and non-linear activations) under G&C, comparing performance with gradient descent across wide and deep networks.", "result": "G&C deteriorates generalization in wide networks but improves it in deep ones, highlighting a fundamental difference between wide and deep architectures.", "conclusion": "The findings suggest no simple answer to whether neural networks require gradient descent for generalization, as performance depends on network architecture."}}
{"id": "2506.03968", "pdf": "https://arxiv.org/pdf/2506.03968", "abs": "https://arxiv.org/abs/2506.03968", "authors": ["Chiwei Zhu", "Benfeng Xu", "Xiaorui Wang", "Zhendong Mao"], "title": "From Real to Synthetic: Synthesizing Millions of Diversified and Complicated User Instructions with Attributed Grounding", "categories": ["cs.CL"], "comment": "To be published at ACL 2025", "summary": "The pursuit of diverse, complex, and large-scale instruction data is crucial\nfor automatically aligning large language models (LLMs). While there are\nmethods capable of generating synthetic instructions at scale, they either\nsuffer from limited grounding sources, leading to a narrow distribution, or\nrely on trivial extensions that fail to produce meaningful trajectories in\nterms of complexity. In contrast, instructions that benefit efficient alignment\nare typically crafted with cognitive insights and grounded in real-world use\ncases. In this paper, we synthesize such instructions using attributed\ngrounding, which involves 1) a top-down attribution process that grounds a\nselective set of real instructions to situated users, and 2) a bottom-up\nsynthesis process that leverages web documents to first generate a situation,\nthen a meaningful instruction. This framework allows us to harvest diverse and\ncomplex instructions at scale, utilizing the vast range of web documents.\nSpecifically, we construct a dataset of 1 million instructions, called\nSynthQuestions, and demonstrate that models trained on it achieve leading\nperformance on several common benchmarks, with improvements that continually\nscale with more web corpora. Data, models and codes will be available at\nhttps://github.com/Ignoramus0817/SynthQuestions.", "AI": {"tldr": "The paper introduces a method for generating diverse and complex synthetic instructions for aligning large language models (LLMs) using attributed grounding, achieving leading benchmark performance.", "motivation": "Existing methods for generating synthetic instructions lack grounding or complexity, limiting their effectiveness for LLM alignment.", "method": "The proposed framework uses attributed grounding: top-down attribution to real instructions and bottom-up synthesis from web documents to generate diverse and complex instructions.", "result": "A dataset of 1 million instructions (SynthQuestions) was created, and models trained on it showed leading performance on benchmarks, scaling with more web corpora.", "conclusion": "Attributed grounding enables scalable generation of high-quality synthetic instructions, improving LLM alignment performance."}}
{"id": "2506.03799", "pdf": "https://arxiv.org/pdf/2506.03799", "abs": "https://arxiv.org/abs/2506.03799", "authors": ["Fei Zhang", "Pei Zhang", "Baosong Yang", "Fei Huang", "Yanfeng Wang", "Ya Zhang"], "title": "ConText: Driving In-context Learning for Text Removal and Segmentation", "categories": ["cs.CV"], "comment": "19 pages, 9 figures, Accepted at ICML 2025", "summary": "This paper presents the first study on adapting the visual in-context\nlearning (V-ICL) paradigm to optical character recognition tasks, specifically\nfocusing on text removal and segmentation. Most existing V-ICL generalists\nemploy a reasoning-as-reconstruction approach: they turn to using a\nstraightforward image-label compositor as the prompt and query input, and then\nmasking the query label to generate the desired output. This direct prompt\nconfines the model to a challenging single-step reasoning process. To address\nthis, we propose a task-chaining compositor in the form of\nimage-removal-segmentation, providing an enhanced prompt that elicits reasoning\nwith enriched intermediates. Additionally, we introduce context-aware\naggregation, integrating the chained prompt pattern into the latent query\nrepresentation, thereby strengthening the model's in-context reasoning. We also\nconsider the issue of visual heterogeneity, which complicates the selection of\nhomogeneous demonstrations in text recognition. Accordingly, this is\neffectively addressed through a simple self-prompting strategy, preventing the\nmodel's in-context learnability from devolving into specialist-like,\ncontext-free inference. Collectively, these insights culminate in our ConText\nmodel, which achieves new state-of-the-art across both in- and out-of-domain\nbenchmarks. The code is available at https://github.com/Ferenas/ConText.", "AI": {"tldr": "The paper introduces ConText, a model adapting visual in-context learning (V-ICL) to OCR tasks like text removal and segmentation, using task-chaining and context-aware aggregation for improved reasoning.", "motivation": "Existing V-ICL methods use simplistic prompts, limiting reasoning. The paper aims to enhance this by introducing intermediate steps and addressing visual heterogeneity.", "method": "Proposes a task-chaining compositor (image-removal-segmentation) and context-aware aggregation. Also uses self-prompting to handle visual heterogeneity.", "result": "ConText achieves state-of-the-art performance on in- and out-of-domain benchmarks.", "conclusion": "The proposed enhancements significantly improve V-ICL for OCR tasks, with ConText setting new benchmarks."}}
{"id": "2506.04043", "pdf": "https://arxiv.org/pdf/2506.04043", "abs": "https://arxiv.org/abs/2506.04043", "authors": ["Mikel K. Ngueajio", "Flor Miriam Plaza-del-Arco", "Yi-Ling Chung", "Danda B. Rawat", "Amanda Cercas Curry"], "title": "Think Like a Person Before Responding: A Multi-Faceted Evaluation of Persona-Guided LLMs for Countering Hate", "categories": ["cs.CL", "cs.AI", "cs.CY", "cs.HC", "cs.LG"], "comment": "Accepted at ACL WOAH 2025", "summary": "Automated counter-narratives (CN) offer a promising strategy for mitigating\nonline hate speech, yet concerns about their affective tone, accessibility, and\nethical risks remain. We propose a framework for evaluating Large Language\nModel (LLM)-generated CNs across four dimensions: persona framing, verbosity\nand readability, affective tone, and ethical robustness. Using GPT-4o-Mini,\nCohere's CommandR-7B, and Meta's LLaMA 3.1-70B, we assess three prompting\nstrategies on the MT-Conan and HatEval datasets. Our findings reveal that\nLLM-generated CNs are often verbose and adapted for people with college-level\nliteracy, limiting their accessibility. While emotionally guided prompts yield\nmore empathetic and readable responses, there remain concerns surrounding\nsafety and effectiveness.", "AI": {"tldr": "The paper evaluates LLM-generated counter-narratives for hate speech, focusing on persona, readability, tone, and ethics, revealing issues with verbosity and accessibility.", "motivation": "To address concerns about the affective tone, accessibility, and ethical risks of automated counter-narratives for hate speech.", "method": "Proposes a framework to evaluate CNs across four dimensions, testing three prompting strategies on GPT-4o-Mini, Cohere's CommandR-7B, and LLaMA 3.1-70B using MT-Conan and HatEval datasets.", "result": "LLM-generated CNs are often verbose and less accessible, though emotionally guided prompts improve empathy and readability. Safety and effectiveness concerns persist.", "conclusion": "While LLMs show promise for CN generation, improvements in accessibility and ethical robustness are needed."}}
{"id": "2506.03938", "pdf": "https://arxiv.org/pdf/2506.03938", "abs": "https://arxiv.org/abs/2506.03938", "authors": ["C\u00e9dric L\u00e9onard", "Dirk Stober", "Martin Schulz"], "title": "FPGA-Enabled Machine Learning Applications in Earth Observation: A Systematic Review", "categories": ["cs.LG", "cs.AR"], "comment": "35 pages, 3 figures, 2 tables. Submitted to ACM Computing Surveys\n  (ACM CSUR)", "summary": "New UAV technologies and the NewSpace era are transforming Earth Observation\nmissions and data acquisition. Numerous small platforms generate large data\nvolume, straining bandwidth and requiring onboard decision-making to transmit\nhigh-quality information in time. While Machine Learning allows real-time\nautonomous processing, FPGAs balance performance with adaptability to\nmission-specific requirements, enabling onboard deployment. This review\nsystematically analyzes 66 experiments deploying ML models on FPGAs for Remote\nSensing applications. We introduce two distinct taxonomies to capture both\nefficient model architectures and FPGA implementation strategies. For\ntransparency and reproducibility, we follow PRISMA 2020 guidelines and share\nall data and code at https://github.com/CedricLeon/Survey_RS-ML-FPGA.", "AI": {"tldr": "The paper reviews 66 experiments deploying ML models on FPGAs for Remote Sensing, introducing taxonomies for model architectures and FPGA strategies, following PRISMA 2020 guidelines.", "motivation": "The rise of UAVs and NewSpace technologies has increased data volume, requiring efficient onboard processing and decision-making.", "method": "Systematic review of 66 experiments, introducing taxonomies for ML models and FPGA implementations, adhering to PRISMA 2020.", "result": "Two taxonomies for efficient ML architectures and FPGA strategies, with shared data and code for reproducibility.", "conclusion": "FPGAs enable adaptable, high-performance onboard ML for Remote Sensing, supported by transparent methodologies."}}
{"id": "2506.03978", "pdf": "https://arxiv.org/pdf/2506.03978", "abs": "https://arxiv.org/abs/2506.03978", "authors": ["Hieu Trung Nguyen", "Bao Nguyen", "Viet Anh Nguyen"], "title": "Structured Pruning for Diverse Best-of-N Reasoning Optimization", "categories": ["cs.CL", "cs.LG"], "comment": "Accepted to ACL 2025", "summary": "Model pruning in transformer-based language models, traditionally viewed as a\nmeans of achieving computational savings, can enhance the model's reasoning\ncapabilities. In this work, we uncover a surprising phenomenon: the selective\npruning of certain attention heads leads to improvements in reasoning\nperformance, particularly on challenging tasks. Motivated by this observation,\nwe propose SPRINT, a novel contrastive learning framework that dynamically\nselects the optimal head and layer to prune during inference. By aligning\nquestion embeddings with head embeddings, SPRINT identifies those pruned-head\nconfigurations that result in more accurate reasoning. Extensive experiments\ndemonstrate that our method significantly outperforms traditional best-of-$N$\nand random head selection strategies on the MATH500 and GSM8K datasets.", "AI": {"tldr": "Selective pruning of attention heads in transformers improves reasoning performance. SPRINT, a contrastive learning framework, dynamically selects optimal heads to prune, outperforming traditional methods.", "motivation": "Observation that selective pruning enhances reasoning capabilities, especially in challenging tasks.", "method": "Proposes SPRINT, a contrastive learning framework aligning question and head embeddings to dynamically select optimal pruning configurations.", "result": "SPRINT outperforms best-of-N and random head selection on MATH500 and GSM8K datasets.", "conclusion": "Selective pruning via SPRINT enhances reasoning performance, offering a novel approach to model optimization."}}
{"id": "2506.03868", "pdf": "https://arxiv.org/pdf/2506.03868", "abs": "https://arxiv.org/abs/2506.03868", "authors": ["Zhuoyang Pan", "Boxiao Pan", "Guandao Yang", "Adam W. Harley", "Leonidas Guibas"], "title": "Animal Pose Labeling Using General-Purpose Point Trackers", "categories": ["cs.CV"], "comment": null, "summary": "Automatically estimating animal poses from videos is important for studying\nanimal behaviors. Existing methods do not perform reliably since they are\ntrained on datasets that are not comprehensive enough to capture all necessary\nanimal behaviors. However, it is very challenging to collect such datasets due\nto the large variations in animal morphology. In this paper, we propose an\nanimal pose labeling pipeline that follows a different strategy, i.e. test time\noptimization. Given a video, we fine-tune a lightweight appearance embedding\ninside a pre-trained general-purpose point tracker on a sparse set of annotated\nframes. These annotations can be obtained from human labelers or off-the-shelf\npose detectors. The fine-tuned model is then applied to the rest of the frames\nfor automatic labeling. Our method achieves state-of-the-art performance at a\nreasonable annotation cost. We believe our pipeline offers a valuable tool for\nthe automatic quantification of animal behavior. Visit our project webpage at\nhttps://zhuoyang-pan.github.io/animal-labeling.", "AI": {"tldr": "A new animal pose labeling pipeline using test-time optimization achieves state-of-the-art performance with reasonable annotation costs.", "motivation": "Existing methods for animal pose estimation lack reliability due to insufficient training datasets, which are hard to collect because of animal morphology variations.", "method": "The proposed pipeline fine-tunes a lightweight appearance embedding in a pre-trained point tracker using sparse annotated frames, then applies it to the rest of the video.", "result": "The method achieves state-of-the-art performance.", "conclusion": "The pipeline is a valuable tool for automatic animal behavior quantification."}}
{"id": "2506.04044", "pdf": "https://arxiv.org/pdf/2506.04044", "abs": "https://arxiv.org/abs/2506.04044", "authors": ["Aleksey Kudelya", "Alexander Shirnin"], "title": "Lacuna Inc. at SemEval-2025 Task 4: LoRA-Enhanced Influence-Based Unlearning for LLMs", "categories": ["cs.CL", "cs.AI"], "comment": "Accepted to SemEval-2025, an ACL 2025 workshop", "summary": "This paper describes LIBU (LoRA enhanced influence-based unlearning), an\nalgorithm to solve the task of unlearning - removing specific knowledge from a\nlarge language model without retraining from scratch and compromising its\noverall utility (SemEval-2025 Task 4: Unlearning sensitive content from Large\nLanguage Models). The algorithm combines classical \\textit{influence functions}\nto remove the influence of the data from the model and \\textit{second-order\noptimization} to stabilize the overall utility. Our experiments show that this\nlightweight approach is well applicable for unlearning LLMs in different kinds\nof task.", "AI": {"tldr": "LIBU is a lightweight algorithm for unlearning specific knowledge in large language models without retraining, using influence functions and second-order optimization.", "motivation": "To remove sensitive content from LLMs efficiently without retraining or losing overall utility.", "method": "Combines influence functions to erase data influence and second-order optimization to stabilize utility.", "result": "Effective for unlearning in various tasks, maintaining model utility.", "conclusion": "LIBU is a practical solution for unlearning in LLMs."}}
{"id": "2506.03943", "pdf": "https://arxiv.org/pdf/2506.03943", "abs": "https://arxiv.org/abs/2506.03943", "authors": ["Shiyi Yang", "Can Chen", "Didong Li"], "title": "Lower Ricci Curvature for Hypergraphs", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "Networks with higher-order interactions, prevalent in biological, social, and\ninformation systems, are naturally represented as hypergraphs, yet their\nstructural complexity poses fundamental challenges for geometric\ncharacterization. While curvature-based methods offer powerful insights in\ngraph analysis, existing extensions to hypergraphs suffer from critical\ntrade-offs: combinatorial approaches such as Forman-Ricci curvature capture\nonly coarse features, whereas geometric methods like Ollivier-Ricci curvature\noffer richer expressivity but demand costly optimal transport computations. To\naddress these challenges, we introduce hypergraph lower Ricci curvature (HLRC),\na novel curvature metric defined in closed form that achieves a principled\nbalance between interpretability and efficiency. Evaluated across diverse\nsynthetic and real-world hypergraph datasets, HLRC consistently reveals\nmeaningful higher-order organization, distinguishing intra- from\ninter-community hyperedges, uncovering latent semantic labels, tracking\ntemporal dynamics, and supporting robust clustering of hypergraphs based on\nglobal structure. By unifying geometric sensitivity with algorithmic\nsimplicity, HLRC provides a versatile foundation for hypergraph analytics, with\nbroad implications for tasks including node classification, anomaly detection,\nand generative modeling in complex systems.", "AI": {"tldr": "The paper introduces hypergraph lower Ricci curvature (HLRC), a new curvature metric for hypergraphs that balances interpretability and efficiency, outperforming existing methods in capturing higher-order structure.", "motivation": "Existing curvature-based methods for hypergraphs either lack expressivity (combinatorial approaches) or are computationally expensive (geometric methods), limiting their practical utility.", "method": "The authors propose HLRC, a closed-form curvature metric for hypergraphs, designed to be both interpretable and efficient.", "result": "HLRC effectively reveals higher-order organization in hypergraphs, distinguishing communities, uncovering latent labels, tracking dynamics, and supporting clustering.", "conclusion": "HLRC unifies geometric sensitivity with simplicity, offering a versatile tool for hypergraph analytics with applications in classification, anomaly detection, and generative modeling."}}
{"id": "2506.03980", "pdf": "https://arxiv.org/pdf/2506.03980", "abs": "https://arxiv.org/abs/2506.03980", "authors": ["Takeshi Saga", "Catherine Pelachaud"], "title": "Voice Activity Projection Model with Multimodal Encoders", "categories": ["cs.CL"], "comment": null, "summary": "Turn-taking management is crucial for any social interaction. Still, it is\nchallenging to model human-machine interaction due to the complexity of the\nsocial context and its multimodal nature. Unlike conventional systems based on\nsilence duration, previous existing voice activity projection (VAP) models\nsuccessfully utilized a unified representation of turn-taking behaviors as\nprediction targets, which improved turn-taking prediction performance.\nRecently, a multimodal VAP model outperformed the previous state-of-the-art\nmodel by a significant margin. In this paper, we propose a multimodal model\nenhanced with pre-trained audio and face encoders to improve performance by\ncapturing subtle expressions. Our model performed competitively, and in some\ncases, even better than state-of-the-art models on turn-taking metrics. All the\nsource codes and pretrained models are available at\nhttps://github.com/sagatake/VAPwithAudioFaceEncoders.", "AI": {"tldr": "A multimodal VAP model with pre-trained audio and face encoders outperforms state-of-the-art models in turn-taking prediction by capturing subtle expressions.", "motivation": "To improve turn-taking prediction in human-machine interaction by leveraging multimodal cues (audio and face) for better performance.", "method": "Proposes a multimodal VAP model enhanced with pre-trained audio and face encoders to capture subtle expressions.", "result": "The model performs competitively, sometimes better than state-of-the-art models on turn-taking metrics.", "conclusion": "The proposed multimodal approach effectively improves turn-taking prediction, with code and models made publicly available."}}
{"id": "2506.03885", "pdf": "https://arxiv.org/pdf/2506.03885", "abs": "https://arxiv.org/abs/2506.03885", "authors": ["Sam Pollard", "Michael Wray"], "title": "Video, How Do Your Tokens Merge?", "categories": ["cs.CV"], "comment": "Accepted at eLVM workshop at CVPR 2025", "summary": "Video transformer models require huge amounts of compute resources due to the\nspatio-temporal scaling of the input. Tackling this, recent methods have\nproposed to drop or merge tokens for image models, whether randomly or via\nlearned methods. Merging tokens has many benefits: it can be plugged into any\nvision transformer, does not require model re-training, and it propagates\ninformation that would otherwise be dropped through the model. Before now,\nvideo token merging has not been evaluated on temporally complex datasets for\nvideo understanding. In this work, we explore training-free token merging for\nvideo to provide comprehensive experiments and find best practices across four\nvideo transformers on three datasets that exhibit coarse and fine-grained\naction recognition. Our results showcase the benefits of video token merging\nwith a speedup of around $2.5$X while maintaining accuracy (avg. $-0.55\\%$ for\nViViT). Code available at\nhttps://github.com/sjpollard/video-how-do-your-tokens-merge.", "AI": {"tldr": "Token merging in video transformers speeds up processing by 2.5X with minimal accuracy loss (-0.55% for ViViT).", "motivation": "Address the high compute demands of video transformers by exploring token merging without retraining.", "method": "Training-free token merging applied to four video transformers on three datasets for action recognition.", "result": "Achieved 2.5X speedup while maintaining accuracy (avg. -0.55% for ViViT).", "conclusion": "Token merging is effective for video transformers, offering speed improvements without significant accuracy trade-offs."}}
{"id": "2506.04050", "pdf": "https://arxiv.org/pdf/2506.04050", "abs": "https://arxiv.org/abs/2506.04050", "authors": ["Hadi Mohammadi", "Anastasia Giachanou", "Daniel L. Oberski", "Ayoub Bagheri"], "title": "Explainability-Based Token Replacement on LLM-Generated Text", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Generative models, especially large language models (LLMs), have shown\nremarkable progress in producing text that appears human-like. However, they\noften exhibit patterns that make their output easier to detect than text\nwritten by humans. In this paper, we investigate how explainable AI (XAI)\nmethods can be used to reduce the detectability of AI-generated text (AIGT)\nwhile also introducing a robust ensemble-based detection approach. We begin by\ntraining an ensemble classifier to distinguish AIGT from human-written text,\nthen apply SHAP and LIME to identify tokens that most strongly influence its\npredictions. We propose four explainability-based token replacement strategies\nto modify these influential tokens. Our findings show that these token\nreplacement approaches can significantly diminish a single classifier's ability\nto detect AIGT. However, our ensemble classifier maintains strong performance\nacross multiple languages and domains, showing that a multi-model approach can\nmitigate the impact of token-level manipulations. These results show that XAI\nmethods can make AIGT harder to detect by focusing on the most influential\ntokens. At the same time, they highlight the need for robust, ensemble-based\ndetection strategies that can adapt to evolving approaches for hiding AIGT.", "AI": {"tldr": "The paper explores using XAI methods to reduce AI-generated text detectability and introduces an ensemble classifier for robust detection. Token replacement strategies based on XAI insights lower single-classifier detection but are countered by the ensemble approach.", "motivation": "To address the detectability of AI-generated text (AIGT) by leveraging explainable AI (XAI) to identify and modify influential tokens, while ensuring robust detection through ensemble methods.", "method": "Train an ensemble classifier to detect AIGT, use SHAP and LIME to identify influential tokens, and propose four token replacement strategies to reduce detectability.", "result": "Token replacement reduces single-classifier detection, but the ensemble classifier remains robust across languages and domains.", "conclusion": "XAI can make AIGT harder to detect, but ensemble-based detection is necessary to counter token-level manipulations."}}
{"id": "2506.03951", "pdf": "https://arxiv.org/pdf/2506.03951", "abs": "https://arxiv.org/abs/2506.03951", "authors": ["Aojun Lu", "Hangjie Yuan", "Tao Feng", "Yanan Sun"], "title": "Rethinking the Stability-Plasticity Trade-off in Continual Learning from an Architectural Perspective", "categories": ["cs.LG", "cs.CV"], "comment": null, "summary": "The quest for Continual Learning (CL) seeks to empower neural networks with\nthe ability to learn and adapt incrementally. Central to this pursuit is\naddressing the stability-plasticity dilemma, which involves striking a balance\nbetween two conflicting objectives: preserving previously learned knowledge and\nacquiring new knowledge. While numerous CL methods aim to achieve this\ntrade-off, they often overlook the impact of network architecture on stability\nand plasticity, restricting the trade-off to the parameter level. In this\npaper, we delve into the conflict between stability and plasticity at the\narchitectural level. We reveal that under an equal parameter constraint, deeper\nnetworks exhibit better plasticity, while wider networks are characterized by\nsuperior stability. To address this architectural-level dilemma, we introduce a\nnovel framework denoted Dual-Arch, which serves as a plug-in component for CL.\nThis framework leverages the complementary strengths of two distinct and\nindependent networks: one dedicated to plasticity and the other to stability.\nEach network is designed with a specialized and lightweight architecture,\ntailored to its respective objective. Extensive experiments demonstrate that\nDual-Arch enhances the performance of existing CL methods while being up to 87%\nmore compact in terms of parameters.", "AI": {"tldr": "The paper introduces Dual-Arch, a framework for Continual Learning (CL) that balances stability and plasticity at the architectural level, using two specialized networks. It outperforms existing methods while being more parameter-efficient.", "motivation": "Address the stability-plasticity dilemma in CL by exploring architectural-level trade-offs, as most methods focus only on parameter-level adjustments.", "method": "Propose Dual-Arch, a plug-in framework with two independent networks: one for plasticity (deeper) and one for stability (wider).", "result": "Dual-Arch improves CL performance and is up to 87% more compact in parameters.", "conclusion": "Architectural-level design is crucial for CL, and Dual-Arch effectively balances stability and plasticity."}}
{"id": "2506.03984", "pdf": "https://arxiv.org/pdf/2506.03984", "abs": "https://arxiv.org/abs/2506.03984", "authors": ["Carolin Holtermann", "Paul R\u00f6ttger", "Anne Lauscher"], "title": "Around the World in 24 Hours: Probing LLM Knowledge of Time and Place", "categories": ["cs.CL"], "comment": null, "summary": "Reasoning over time and space is essential for understanding our world.\nHowever, the abilities of language models in this area are largely unexplored\nas previous work has tested their abilities for logical reasoning in terms of\ntime and space in isolation or only in simple or artificial environments. In\nthis paper, we present the first evaluation of the ability of language models\nto jointly reason over time and space. To enable our analysis, we create\nGeoTemp, a dataset of 320k prompts covering 289 cities in 217 countries and 37\ntime zones. Using GeoTemp, we evaluate eight open chat models of three\ndifferent model families for different combinations of temporal and geographic\nknowledge. We find that most models perform well on reasoning tasks involving\nonly temporal knowledge and that overall performance improves with scale.\nHowever, performance remains constrained in tasks that require connecting\ntemporal and geographical information. We do not find clear correlations of\nperformance with specific geographic regions. Instead, we find a significant\nperformance increase for location names with low model perplexity, suggesting\ntheir repeated occurrence during model training. We further demonstrate that\ntheir performance is heavily influenced by prompt formulation - a direct\ninjection of geographical knowledge leads to performance gains, whereas,\nsurprisingly, techniques like chain-of-thought prompting decrease performance\non simpler tasks.", "AI": {"tldr": "The paper evaluates language models' ability to jointly reason over time and space using the GeoTemp dataset, finding strong temporal reasoning but limitations in combining temporal and geographic knowledge.", "motivation": "To explore the largely untested abilities of language models in reasoning over both time and space, beyond isolated or simple scenarios.", "method": "Creation of the GeoTemp dataset (320k prompts across 289 cities, 217 countries, 37 time zones) and evaluation of eight open chat models from three families.", "result": "Models perform well on temporal reasoning, improve with scale, but struggle with tasks combining temporal and geographic knowledge. Performance correlates with low perplexity for location names, not specific regions.", "conclusion": "Prompt formulation heavily impacts performance; direct geographic knowledge injection helps, while chain-of-thought prompting can hinder simpler tasks."}}
{"id": "2506.03892", "pdf": "https://arxiv.org/pdf/2506.03892", "abs": "https://arxiv.org/abs/2506.03892", "authors": ["Giyong Choi", "HyunWook Park"], "title": "Joint Video Enhancement with Deblurring, Super-Resolution, and Frame Interpolation Network", "categories": ["cs.CV"], "comment": null, "summary": "Video quality is often severely degraded by multiple factors rather than a\nsingle factor. These low-quality videos can be restored to high-quality videos\nby sequentially performing appropriate video enhancement techniques. However,\nthe sequential approach was inefficient and sub-optimal because most video\nenhancement approaches were designed without taking into account that multiple\nfactors together degrade video quality. In this paper, we propose a new joint\nvideo enhancement method that mitigates multiple degradation factors\nsimultaneously by resolving an integrated enhancement problem. Our proposed\nnetwork, named DSFN, directly produces a high-resolution, high-frame-rate, and\nclear video from a low-resolution, low-frame-rate, and blurry video. In the\nDSFN, low-resolution and blurry input frames are enhanced by a joint deblurring\nand super-resolution (JDSR) module. Meanwhile, intermediate frames between\ninput adjacent frames are interpolated by a triple-frame-based frame\ninterpolation (TFBFI) module. The proper combination of the proposed modules of\nDSFN can achieve superior performance on the joint video enhancement task.\nExperimental results show that the proposed method outperforms other sequential\nstate-of-the-art techniques on public datasets with a smaller network size and\nfaster processing time.", "AI": {"tldr": "A joint video enhancement method (DSFN) is proposed to address multiple degradation factors simultaneously, outperforming sequential approaches in efficiency and performance.", "motivation": "Sequential video enhancement is inefficient and sub-optimal due to ignoring combined degradation factors. A joint approach is needed.", "method": "DSFN integrates a joint deblurring and super-resolution (JDSR) module and a triple-frame-based frame interpolation (TFBFI) module to enhance videos.", "result": "DSFN outperforms state-of-the-art sequential methods with smaller network size and faster processing.", "conclusion": "The joint approach of DSFN is more effective for video enhancement, handling multiple degradations simultaneously."}}
{"id": "2506.04051", "pdf": "https://arxiv.org/pdf/2506.04051", "abs": "https://arxiv.org/abs/2506.04051", "authors": ["Tim Franzmeyer", "Archie Sravankumar", "Lijuan Liu", "Yuning Mao", "Rui Hou", "Sinong Wang", "Jakob N. Foerster", "Luke Zettlemoyer", "Madian Khabsa"], "title": "High Accuracy, Less Talk (HALT): Reliable LLMs through Capability-Aligned Finetuning", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Large Language Models (LLMs) currently respond to every prompt. However, they\ncan produce incorrect answers when they lack knowledge or capability -- a\nproblem known as hallucination. We instead propose post-training an LLM to\ngenerate content only when confident in its correctness and to otherwise\n(partially) abstain. Specifically, our method, HALT, produces\ncapability-aligned post-training data that encodes what the model can and\ncannot reliably generate. We generate this data by splitting responses of the\npretrained LLM into factual fragments (atomic statements or reasoning steps),\nand use ground truth information to identify incorrect fragments. We achieve\ncapability-aligned finetuning responses by either removing incorrect fragments\nor replacing them with \"Unsure from Here\" -- according to a tunable threshold\nthat allows practitioners to trade off response completeness and mean\ncorrectness of the response's fragments. We finetune four open-source models\nfor biography writing, mathematics, coding, and medicine with HALT for three\ndifferent trade-off thresholds. HALT effectively trades off response\ncompleteness for correctness, increasing the mean correctness of response\nfragments by 15% on average, while resulting in a 4% improvement in the F1\nscore (mean of completeness and correctness of the response) compared to the\nrelevant baselines. By tuning HALT for highest correctness, we train a single\nreliable Llama3-70B model with correctness increased from 51% to 87% across all\nfour domains while maintaining 53% of the response completeness achieved with\nstandard finetuning.", "AI": {"tldr": "HALT is a post-training method for LLMs to abstain from generating incorrect responses by aligning responses with the model's capabilities, improving correctness by 15% on average.", "motivation": "To address LLM hallucination by ensuring models only generate content when confident, improving reliability.", "method": "HALT splits responses into factual fragments, identifies incorrect ones using ground truth, and replaces or removes them based on a tunable threshold.", "result": "HALT improves mean correctness by 15%, F1 score by 4%, and achieves 87% correctness in a Llama3-70B model while maintaining 53% response completeness.", "conclusion": "HALT effectively balances response completeness and correctness, enhancing LLM reliability."}}
{"id": "2506.03956", "pdf": "https://arxiv.org/pdf/2506.03956", "abs": "https://arxiv.org/abs/2506.03956", "authors": ["Aojun Lu", "Tao Feng", "Hangjie Yuan", "Chunhui Ding", "Yanan Sun"], "title": "Adapt before Continual Learning", "categories": ["cs.LG", "cs.CV"], "comment": null, "summary": "Continual Learning (CL) seeks to enable neural networks to incrementally\nacquire new knowledge (plasticity) while retaining existing knowledge\n(stability). While pre-trained models (PTMs) have become pivotal in CL,\nprevailing approaches freeze the PTM backbone to preserve stability, limiting\ntheir plasticity, particularly when encountering significant domain gaps in\nincremental tasks. Conversely, sequentially finetuning the entire PTM risks\ncatastrophic forgetting of generalizable knowledge, exposing a critical\nstability-plasticity trade-off. To address this challenge, we propose Adapting\nPTMs before the core CL process (ACL), a novel framework that refines the PTM\nbackbone through a plug-and-play adaptation phase before learning each new task\nwith existing CL approaches (e.g., prompt tuning). ACL enhances plasticity by\naligning embeddings with their original class prototypes while distancing them\nfrom others, theoretically and empirically shown to balance stability and\nplasticity. Extensive experiments demonstrate that ACL significantly improves\nCL performance across benchmarks and integrated methods, offering a versatile\nsolution for PTM-based CL.", "AI": {"tldr": "ACL refines pre-trained models (PTMs) before continual learning (CL) to balance stability and plasticity, improving performance across benchmarks.", "motivation": "Address the stability-plasticity trade-off in CL by enhancing PTM adaptability without catastrophic forgetting.", "method": "Propose ACL, a plug-and-play adaptation phase before CL tasks, aligning embeddings with class prototypes.", "result": "ACL significantly improves CL performance, balancing stability and plasticity.", "conclusion": "ACL offers a versatile solution for PTM-based CL, enhancing adaptability and performance."}}
{"id": "2506.03989", "pdf": "https://arxiv.org/pdf/2506.03989", "abs": "https://arxiv.org/abs/2506.03989", "authors": ["Alex Laitenberger", "Christopher D. Manning", "Nelson F. Liu"], "title": "Stronger Baselines for Retrieval-Augmented Generation with Long-Context Language Models", "categories": ["cs.CL"], "comment": "10 pages, 5 figures, for associated source code, see\n  https://github.com/alex-laitenberger/stronger-baselines-rag", "summary": "With the rise of long-context language models (LMs) capable of processing\ntens of thousands of tokens in a single pass, do multi-stage\nretrieval-augmented generation (RAG) pipelines still offer measurable benefits\nover simpler, single-stage approaches? To assess this question, we conduct a\ncontrolled evaluation for QA tasks under systematically scaled token budgets,\ncomparing two recent multi-stage pipelines, ReadAgent and RAPTOR, against three\nbaselines, including DOS RAG (Document's Original Structure RAG), a simple\nretrieve-then-read method that preserves original passage order. Despite its\nstraightforward design, DOS RAG consistently matches or outperforms more\nintricate methods on multiple long-context QA benchmarks. We recommend\nestablishing DOS RAG as a simple yet strong baseline for future RAG\nevaluations, pairing it with emerging embedding and language models to assess\ntrade-offs between complexity and effectiveness as model capabilities evolve.", "AI": {"tldr": "DOS RAG, a simple retrieve-then-read method, matches or outperforms complex multi-stage RAG pipelines like ReadAgent and RAPTOR in long-context QA tasks.", "motivation": "To evaluate whether multi-stage RAG pipelines still provide benefits over simpler methods given the capabilities of modern long-context LMs.", "method": "Controlled evaluation of QA tasks under scaled token budgets, comparing multi-stage pipelines (ReadAgent, RAPTOR) with baselines, including DOS RAG.", "result": "DOS RAG consistently matches or outperforms more complex methods on long-context QA benchmarks.", "conclusion": "DOS RAG should be a baseline for future RAG evaluations, balancing simplicity and effectiveness as models evolve."}}
{"id": "2506.03918", "pdf": "https://arxiv.org/pdf/2506.03918", "abs": "https://arxiv.org/abs/2506.03918", "authors": ["Marcin Kowalczyk", "Kamil Jeziorek", "Tomasz Kryjak"], "title": "Learning from Noise: Enhancing DNNs for Event-Based Vision through Controlled Noise Injection", "categories": ["cs.CV"], "comment": null, "summary": "Event-based sensors offer significant advantages over traditional frame-based\ncameras, especially in scenarios involving rapid motion or challenging lighting\nconditions. However, event data frequently suffers from considerable noise,\nnegatively impacting the performance and robustness of deep learning models.\nTraditionally, this problem has been addressed by applying filtering algorithms\nto the event stream, but this may also remove some of relevant data. In this\npaper, we propose a novel noise-injection training methodology designed to\nenhance the neural networks robustness against varying levels of event noise.\nOur approach introduces controlled noise directly into the training data,\nenabling models to learn noise-resilient representations. We have conducted\nextensive evaluations of the proposed method using multiple benchmark datasets\n(N-Caltech101, N-Cars, and Mini N-ImageNet) and various network architectures,\nincluding Convolutional Neural Networks, Vision Transformers, Spiking Neural\nNetworks, and Graph Convolutional Networks. Experimental results show that our\nnoise-injection training strategy achieves stable performance over a range of\nnoise intensities, consistently outperforms event-filtering techniques, and\nachieves the highest average classification accuracy, making it a viable\nalternative to traditional event-data filtering methods in an object\nclassification system. Code: https://github.com/vision-agh/DVS_Filtering", "AI": {"tldr": "A novel noise-injection training method improves neural network robustness against event data noise, outperforming traditional filtering techniques in object classification.", "motivation": "Event-based sensors are advantageous but noisy, degrading deep learning model performance. Traditional filtering removes useful data, prompting a need for noise-resilient training.", "method": "Proposes noise-injection training, introducing controlled noise into training data to enhance model robustness. Evaluated on multiple datasets and architectures.", "result": "Achieves stable performance across noise levels, outperforms filtering methods, and attains highest classification accuracy.", "conclusion": "Noise-injection training is a viable alternative to traditional event-data filtering for object classification."}}
{"id": "2506.04078", "pdf": "https://arxiv.org/pdf/2506.04078", "abs": "https://arxiv.org/abs/2506.04078", "authors": ["Ming Zhang", "Yujiong Shen", "Zelin Li", "Huayu Sha", "Binze Hu", "Yuhui Wang", "Chenhao Huang", "Shichun Liu", "Jingqi Tong", "Changhao Jiang", "Mingxu Chai", "Zhiheng Xi", "Shihan Dou", "Tao Gui", "Qi Zhang", "Xuanjing Huang"], "title": "LLMEval-Med: A Real-world Clinical Benchmark for Medical LLMs with Physician Validation", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Evaluating large language models (LLMs) in medicine is crucial because\nmedical applications require high accuracy with little room for error. Current\nmedical benchmarks have three main types: medical exam-based, comprehensive\nmedical, and specialized assessments. However, these benchmarks have\nlimitations in question design (mostly multiple-choice), data sources (often\nnot derived from real clinical scenarios), and evaluation methods (poor\nassessment of complex reasoning). To address these issues, we present\nLLMEval-Med, a new benchmark covering five core medical areas, including 2,996\nquestions created from real-world electronic health records and expert-designed\nclinical scenarios. We also design an automated evaluation pipeline,\nincorporating expert-developed checklists into our LLM-as-Judge framework.\nFurthermore, our methodology validates machine scoring through human-machine\nagreement analysis, dynamically refining checklists and prompts based on expert\nfeedback to ensure reliability. We evaluate 13 LLMs across three categories\n(specialized medical models, open-source models, and closed-source models) on\nLLMEval-Med, providing valuable insights for the safe and effective deployment\nof LLMs in medical domains. The dataset is released in\nhttps://github.com/llmeval/LLMEval-Med.", "AI": {"tldr": "LLMEval-Med is a new benchmark for evaluating LLMs in medicine, addressing limitations of existing benchmarks with real-world questions and an automated evaluation pipeline.", "motivation": "Current medical benchmarks lack real-world clinical scenarios and robust evaluation methods, necessitating a more reliable tool for assessing LLMs in medicine.", "method": "Developed LLMEval-Med with 2,996 questions from real-world EHRs and expert-designed scenarios, using an automated pipeline with expert checklists and human-machine validation.", "result": "Evaluated 13 LLMs, providing insights for safe and effective deployment in medicine.", "conclusion": "LLMEval-Med improves LLM evaluation in medicine by addressing existing benchmark limitations and ensuring reliability through expert feedback."}}
{"id": "2506.03996", "pdf": "https://arxiv.org/pdf/2506.03996", "abs": "https://arxiv.org/abs/2506.03996", "authors": ["Lianfeng Shi", "Ao Li", "Benjamin Ward-Cherrier"], "title": "Optimal Spiking Brain Compression: Improving One-Shot Post-Training Pruning and Quantization for Spiking Neural Networks", "categories": ["cs.LG", "cs.NE"], "comment": null, "summary": "Spiking Neural Networks (SNNs) have emerged as a new generation of\nenergy-efficient neural networks suitable for implementation on neuromorphic\nhardware. As neuromorphic hardware has limited memory and computing resources,\nweight pruning and quantization have recently been explored to improve SNNs'\nefficiency. State-of-the-art SNN pruning/quantization methods employ multiple\ncompression and training iterations, increasing the cost for pre-trained or\nvery large SNNs. In this paper, we propose a new one-shot post-training\npruning/quantization framework, Optimal Spiking Brain Compression (OSBC), that\nadapts the Optimal Brain Compression (OBC) method of [Frantar, Singh, and\nAlistarh, 2023] for SNNs. Rather than minimizing the loss on neuron input\ncurrent as OBC does, OSBC achieves more efficient and accurate SNN compression\nin one pass by minimizing the loss on spiking neuron membrane potential with a\nsmall sample dataset. Our experiments on neuromorphic datasets (N-MNIST,\nCIFAR10-DVS, DVS128-Gesture) demonstrate that OSBC can achieve 97% sparsity\nthrough pruning with 1.41%, 10.20%, and 1.74% accuracy loss, or 4-bit symmetric\nquantization with 0.17%, 1.54%, and 7.71% accuracy loss, respectively. Code\nwill be available on GitHub.", "AI": {"tldr": "OSBC is a one-shot post-training pruning/quantization framework for SNNs, improving efficiency and accuracy by minimizing loss on spiking neuron membrane potential.", "motivation": "SNNs need efficient compression methods due to limited neuromorphic hardware resources, but current iterative approaches are costly.", "method": "OSBC adapts Optimal Brain Compression (OBC) for SNNs, focusing on minimizing membrane potential loss with a small dataset.", "result": "Achieves 97% sparsity (pruning) or 4-bit quantization with minimal accuracy loss on neuromorphic datasets.", "conclusion": "OSBC offers efficient, accurate one-shot compression for SNNs, suitable for resource-limited hardware."}}
{"id": "2506.03990", "pdf": "https://arxiv.org/pdf/2506.03990", "abs": "https://arxiv.org/abs/2506.03990", "authors": ["Hongzhi Zhang", "Jingyuan Zhang", "Xingguang Ji", "Qi Wang", "Fuzheng Zhang"], "title": "DynTok: Dynamic Compression of Visual Tokens for Efficient and Effective Video Understanding", "categories": ["cs.CL", "cs.CV"], "comment": null, "summary": "Typical video modeling methods, such as LLava, represent videos as sequences\nof visual tokens, which are then processed by the LLM backbone for effective\nvideo understanding. However, this approach leads to a massive number of visual\ntokens, especially for long videos. A practical solution is to first extract\nrelevant visual information from the large visual context before feeding it\ninto the LLM backbone, thereby reducing computational overhead. In this work,\nwe introduce DynTok, a novel \\textbf{Dyn}amic video \\textbf{Tok}en compression\nstrategy. DynTok adaptively splits visual tokens into groups and merges them\nwithin each group, achieving high compression in regions with low information\ndensity while preserving essential content. Our method reduces the number of\ntokens to 44.4% of the original size while maintaining comparable performance.\nIt further benefits from increasing the number of video frames and achieves\n65.3% on Video-MME and 72.5% on MLVU. By applying this simple yet effective\ncompression method, we expose the redundancy in video token representations and\noffer insights for designing more efficient video modeling techniques.", "AI": {"tldr": "DynTok introduces dynamic video token compression, reducing tokens to 44.4% of original size while maintaining performance.", "motivation": "Existing video modeling methods generate excessive visual tokens for long videos, increasing computational overhead.", "method": "DynTok adaptively splits and merges visual tokens, compressing low-density regions while preserving essential content.", "result": "Achieves 65.3% on Video-MME and 72.5% on MLVU, with better performance as video frames increase.", "conclusion": "Exposes redundancy in video tokens and suggests more efficient video modeling techniques."}}
{"id": "2506.03926", "pdf": "https://arxiv.org/pdf/2506.03926", "abs": "https://arxiv.org/abs/2506.03926", "authors": ["Debarshi Brahma", "Soma Biswas"], "title": "Multiple Stochastic Prompt Tuning for Practical Cross-Domain Few Shot Learning", "categories": ["cs.CV"], "comment": null, "summary": "In this work, we propose a practical cross-domain few-shot learning (pCDFSL)\ntask, where a large-scale pre-trained model like CLIP can be easily deployed on\na target dataset. The goal is to simultaneously classify all unseen classes\nunder extreme domain shifts, by utilizing only a few labeled samples per class.\nThe pCDFSL paradigm is source-free and moves beyond artificially created\nepisodic training and testing regimes followed by existing CDFSL frameworks,\nmaking it more challenging and relevant to real-world applications. Towards\nthat goal, we propose a novel framework, termed MIST (MultIple STochastic\nPrompt tuning), where multiple stochastic prompts are utilized to handle\nsignificant domain and semantic shifts. Specifically, multiple prompts are\nlearnt for each class, effectively capturing multiple peaks in the input data.\nFurthermore, instead of representing the weights of the multiple prompts as\npoint-estimates, we model them as learnable Gaussian distributions with two\ndifferent strategies, encouraging an efficient exploration of the prompt\nparameter space, which mitigate overfitting due to the few labeled training\nsamples. Extensive experiments and comparison with the state-of-the-art methods\non four CDFSL benchmarks adapted to this setting, show the effectiveness of the\nproposed framework.", "AI": {"tldr": "The paper introduces a practical cross-domain few-shot learning (pCDFSL) task using CLIP, proposing MIST, a framework with stochastic prompts to handle domain shifts.", "motivation": "To address real-world challenges in few-shot learning under extreme domain shifts without episodic training.", "method": "MIST uses multiple stochastic prompts modeled as Gaussian distributions to explore the prompt space efficiently.", "result": "Outperforms state-of-the-art methods on four CDFSL benchmarks.", "conclusion": "MIST is effective for pCDFSL, offering a practical solution for real-world applications."}}
{"id": "2506.04079", "pdf": "https://arxiv.org/pdf/2506.04079", "abs": "https://arxiv.org/abs/2506.04079", "authors": ["Pedro Henrique Martins", "Jo\u00e3o Alves", "Patrick Fernandes", "Nuno M. Guerreiro", "Ricardo Rei", "Amin Farajian", "Mateusz Klimaszewski", "Duarte M. Alves", "Jos\u00e9 Pombal", "Manuel Faysse", "Pierre Colombo", "Fran\u00e7ois Yvon", "Barry Haddow", "Jos\u00e9 G. C. de Souza", "Alexandra Birch", "Andr\u00e9 F. T. Martins"], "title": "EuroLLM-9B: Technical Report", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "56 pages", "summary": "This report presents EuroLLM-9B, a large language model trained from scratch\nto support the needs of European citizens by covering all 24 official European\nUnion languages and 11 additional languages. EuroLLM addresses the issue of\nEuropean languages being underrepresented and underserved in existing open\nlarge language models. We provide a comprehensive overview of EuroLLM-9B's\ndevelopment, including tokenizer design, architectural specifications, data\nfiltering, and training procedures. We describe the pre-training data\ncollection and filtering pipeline, including the creation of EuroFilter, an\nAI-based multilingual filter, as well as the design of EuroBlocks-Synthetic, a\nnovel synthetic dataset for post-training that enhances language coverage for\nEuropean languages. Evaluation results demonstrate EuroLLM-9B's competitive\nperformance on multilingual benchmarks and machine translation tasks,\nestablishing it as the leading open European-made LLM of its size. To support\nopen research and adoption, we release all major components of this work,\nincluding the base and instruction-tuned models, the EuroFilter classifier, and\nthe synthetic post-training dataset.", "AI": {"tldr": "EuroLLM-9B is a European-made large language model supporting 35 languages, addressing underrepresentation in existing models. It includes innovative data filtering and synthetic datasets, achieving competitive performance and being openly released.", "motivation": "To address the underrepresentation of European languages in open large language models and support multilingual needs of European citizens.", "method": "Developed EuroLLM-9B with a focus on tokenizer design, data filtering (EuroFilter), and synthetic datasets (EuroBlocks-Synthetic). Detailed pre-training and post-training procedures.", "result": "Competitive performance on multilingual benchmarks and machine translation tasks, establishing EuroLLM-9B as a leading open European LLM.", "conclusion": "EuroLLM-9B successfully addresses language underrepresentation, performs well, and is openly released to support research and adoption."}}
{"id": "2506.04026", "pdf": "https://arxiv.org/pdf/2506.04026", "abs": "https://arxiv.org/abs/2506.04026", "authors": ["Cl\u00e9ment B\u00e9nesse", "Patrick Mesana", "Ath\u00e9na\u00efs Gautier", "S\u00e9bastien Gambs"], "title": "On the Usage of Gaussian Process for Efficient Data Valuation", "categories": ["cs.LG"], "comment": null, "summary": "In machine learning, knowing the impact of a given datum on model training is\na fundamental task referred to as Data Valuation. Building on previous works\nfrom the literature, we have designed a novel canonical decomposition allowing\npractitioners to analyze any data valuation method as the combination of two\nparts: a utility function that captures characteristics from a given model and\nan aggregation procedure that merges such information. We also propose to use\nGaussian Processes as a means to easily access the utility function on\n``sub-models'', which are models trained on a subset of the training set. The\nstrength of our approach stems from both its theoretical grounding in Bayesian\ntheory, and its practical reach, by enabling fast estimation of valuations\nthanks to efficient update formulae.", "AI": {"tldr": "The paper introduces a novel decomposition for data valuation in machine learning, combining utility functions and aggregation procedures, and proposes Gaussian Processes for efficient utility estimation.", "motivation": "To provide a systematic way to analyze and implement data valuation methods by decomposing them into interpretable components.", "method": "Proposes a canonical decomposition of data valuation into utility functions and aggregation procedures, using Gaussian Processes for utility estimation on sub-models.", "result": "The approach is theoretically grounded in Bayesian theory and offers practical efficiency through fast valuation estimation.", "conclusion": "The method provides a flexible and efficient framework for data valuation, bridging theory and practice."}}
{"id": "2506.03993", "pdf": "https://arxiv.org/pdf/2506.03993", "abs": "https://arxiv.org/abs/2506.03993", "authors": ["Saif M. Mohammad"], "title": "Words of Warmth: Trust and Sociability Norms for over 26k English Words", "categories": ["cs.CL", "cs.CY"], "comment": "In Proceedings of ACL 2025 Main", "summary": "Social psychologists have shown that Warmth (W) and Competence (C) are the\nprimary dimensions along which we assess other people and groups. These\ndimensions impact various aspects of our lives from social competence and\nemotion regulation to success in the work place and how we view the world. More\nrecent work has started to explore how these dimensions develop, why they have\ndeveloped, and what they constitute. Of particular note, is the finding that\nwarmth has two distinct components: Trust (T) and Sociability (S). In this\nwork, we introduce Words of Warmth, the first large-scale repository of\nmanually derived word--warmth (as well as word--trust and word--sociability)\nassociations for over 26k English words. We show that the associations are\nhighly reliable. We use the lexicons to study the rate at which children\nacquire WCTS words with age. Finally, we show that the lexicon enables a wide\nvariety of bias and stereotype research through case studies on various target\nentities. Words of Warmth is freely available at:\nhttp://saifmohammad.com/warmth.html", "AI": {"tldr": "The paper introduces 'Words of Warmth,' a large-scale lexicon of word associations with warmth, trust, and sociability, demonstrating its reliability and applications in child development and bias research.", "motivation": "To explore the dimensions of warmth (trust and sociability) and competence in social assessments, and provide a resource for studying their development and impact.", "method": "Creation of a manually derived lexicon of word associations for over 26k English words, validated for reliability, and applied to study child development and bias.", "result": "The lexicon is highly reliable and useful for analyzing word acquisition in children and researching biases and stereotypes.", "conclusion": "'Words of Warmth' is a valuable resource for social psychology research, enabling studies on warmth dimensions and their societal implications."}}
{"id": "2506.03928", "pdf": "https://arxiv.org/pdf/2506.03928", "abs": "https://arxiv.org/abs/2506.03928", "authors": ["Ze Feng", "Jiang-Jiang Liu", "Sen Yang", "Lingyu Xiao", "Xiaofan Li", "Wankou Yang", "Jingdong Wang"], "title": "Vision Remember: Alleviating Visual Forgetting in Efficient MLLM with Vision Feature Resample", "categories": ["cs.CV"], "comment": null, "summary": "In this work, we study the Efficient Multimodal Large Language Model.\nRedundant vision tokens consume a significant amount of computational memory\nand resources. Therefore, many previous works compress them in the Vision\nProjector to reduce the number of vision tokens. However, simply compressing in\nthe Vision Projector can lead to the loss of visual information, especially for\ntasks that rely on fine-grained spatial relationships, such as OCR and Chart \\&\nTable Understanding. To address this problem, we propose Vision Remember, which\nis inserted between the LLM decoder layers to allow vision tokens to\nre-memorize vision features. Specifically, we retain multi-level vision\nfeatures and resample them with the vision tokens that have interacted with the\ntext token. During the resampling process, each vision token only attends to a\nlocal region in vision features, which is referred to as saliency-enhancing\nlocal attention. Saliency-enhancing local attention not only improves\ncomputational efficiency but also captures more fine-grained contextual\ninformation and spatial relationships within the region. Comprehensive\nexperiments on multiple visual understanding benchmarks validate the\neffectiveness of our method when combined with various Efficient Vision\nProjectors, showing performance gains without sacrificing efficiency. Based on\nVision Remember, LLaVA-VR with only 2B parameters is also superior to previous\nrepresentative MLLMs such as Tokenpacker-HD-7B and DeepSeek-VL-7B.", "AI": {"tldr": "The paper proposes Vision Remember, a method to retain fine-grained visual information in multimodal LLMs by re-memorizing vision features between decoder layers, improving performance without sacrificing efficiency.", "motivation": "Redundant vision tokens consume computational resources, and simple compression in Vision Projectors can lose fine-grained spatial information crucial for tasks like OCR and chart understanding.", "method": "Vision Remember inserts between LLM decoder layers to resample multi-level vision features using saliency-enhancing local attention, preserving spatial relationships.", "result": "Experiments show performance gains on visual benchmarks, with LLaVA-VR (2B parameters) outperforming larger models like Tokenpacker-HD-7B and DeepSeek-VL-7B.", "conclusion": "Vision Remember effectively balances efficiency and fine-grained visual understanding, enhancing multimodal LLM performance."}}
{"id": "2506.04088", "pdf": "https://arxiv.org/pdf/2506.04088", "abs": "https://arxiv.org/abs/2506.04088", "authors": ["Jun-Peng Jiang", "Yu Xia", "Hai-Long Sun", "Shiyin Lu", "Qing-Guo Chen", "Weihua Luo", "Kaifu Zhang", "De-Chuan Zhan", "Han-Jia Ye"], "title": "Multimodal Tabular Reasoning with Privileged Structured Information", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.CV"], "comment": null, "summary": "Tabular reasoning involves multi-step information extraction and logical\ninference over tabular data. While recent advances have leveraged large\nlanguage models (LLMs) for reasoning over structured tables, such high-quality\ntextual representations are often unavailable in real-world settings, where\ntables typically appear as images. In this paper, we tackle the task of tabular\nreasoning from table images, leveraging privileged structured information\navailable during training to enhance multimodal large language models (MLLMs).\nThe key challenges lie in the complexity of accurately aligning structured\ninformation with visual representations, and in effectively transferring\nstructured reasoning skills to MLLMs despite the input modality gap. To address\nthese, we introduce TabUlar Reasoning with Bridged infOrmation ({\\sc Turbo}), a\nnew framework for multimodal tabular reasoning with privileged structured\ntables. {\\sc Turbo} benefits from a structure-aware reasoning trace generator\nbased on DeepSeek-R1, contributing to high-quality modality-bridged data. On\nthis basis, {\\sc Turbo} repeatedly generates and selects the advantageous\nreasoning paths, further enhancing the model's tabular reasoning ability.\nExperimental results demonstrate that, with limited ($9$k) data, {\\sc Turbo}\nachieves state-of-the-art performance ($+7.2\\%$ vs. previous SOTA) across\nmultiple datasets.", "AI": {"tldr": "The paper introduces Turbo, a framework for tabular reasoning from table images using privileged structured data during training to enhance multimodal LLMs. It addresses alignment and reasoning transfer challenges, achieving SOTA performance with limited data.", "motivation": "Real-world tables often appear as images without textual representations, posing challenges for tabular reasoning. Leveraging privileged structured data during training can enhance multimodal LLMs for this task.", "method": "Turbo uses a structure-aware reasoning trace generator (DeepSeek-R1) to create modality-bridged data. It repeatedly generates and selects advantageous reasoning paths to improve reasoning skills.", "result": "Turbo achieves state-of-the-art performance (+7.2% vs. previous SOTA) with only 9k training data across multiple datasets.", "conclusion": "Turbo effectively bridges the gap between structured and visual table representations, enhancing multimodal tabular reasoning with limited data."}}
{"id": "2506.04053", "pdf": "https://arxiv.org/pdf/2506.04053", "abs": "https://arxiv.org/abs/2506.04053", "authors": ["Alexander Semenenko", "Ivan Butakov", "Alexey Frolov", "Ivan Oseledets"], "title": "Curse of Slicing: Why Sliced Mutual Information is a Deceptive Measure of Statistical Dependence", "categories": ["cs.LG", "cs.IT", "math.IT", "94A16, 68T07, 94A17", "E.4; H.1.1"], "comment": null, "summary": "Sliced Mutual Information (SMI) is widely used as a scalable alternative to\nmutual information for measuring non-linear statistical dependence. Despite its\nadvantages, such as faster convergence, robustness to high dimensionality, and\nnullification only under statistical independence, we demonstrate that SMI is\nhighly susceptible to data manipulation and exhibits counterintuitive behavior.\nThrough extensive benchmarking and theoretical analysis, we show that SMI\nsaturates easily, fails to detect increases in statistical dependence (even\nunder linear transformations designed to enhance the extraction of\ninformation), prioritizes redundancy over informative content, and in some\ncases, performs worse than simpler dependence measures like the correlation\ncoefficient.", "AI": {"tldr": "Sliced Mutual Information (SMI) is scalable but flawed, being vulnerable to manipulation and exhibiting counterintuitive behavior like saturation and poor performance compared to simpler measures.", "motivation": "To highlight the limitations of SMI despite its advantages, such as scalability and robustness, by demonstrating its susceptibility to data manipulation and inefficiency in detecting dependence.", "method": "Extensive benchmarking and theoretical analysis to evaluate SMI's behavior under various conditions, including linear transformations.", "result": "SMI saturates easily, fails to detect increased dependence, prioritizes redundancy, and underperforms compared to simpler measures like correlation.", "conclusion": "SMI's flaws, such as susceptibility to manipulation and poor performance, suggest caution in its use and the need for better alternatives."}}
{"id": "2506.03994", "pdf": "https://arxiv.org/pdf/2506.03994", "abs": "https://arxiv.org/abs/2506.03994", "authors": ["Dan Oneata", "Desmond Elliott", "Stella Frank"], "title": "Seeing What Tastes Good: Revisiting Multimodal Distributional Semantics in the Billion Parameter Era", "categories": ["cs.CL", "cs.CV"], "comment": "ACL Findings 2025", "summary": "Human learning and conceptual representation is grounded in sensorimotor\nexperience, in contrast to state-of-the-art foundation models. In this paper,\nwe investigate how well such large-scale models, trained on vast quantities of\ndata, represent the semantic feature norms of concrete object concepts, e.g. a\nROSE is red, smells sweet, and is a flower. More specifically, we use probing\ntasks to test which properties of objects these models are aware of. We\nevaluate image encoders trained on image data alone, as well as\nmultimodally-trained image encoders and language-only models, on predicting an\nextended denser version of the classic McRae norms and the newer Binder dataset\nof attribute ratings. We find that multimodal image encoders slightly\noutperform language-only approaches, and that image-only encoders perform\ncomparably to the language models, even on non-visual attributes that are\nclassified as \"encyclopedic\" or \"function\". These results offer new insights\ninto what can be learned from pure unimodal learning, and the complementarity\nof the modalities.", "AI": {"tldr": "The paper compares how well foundation models represent semantic features of concrete objects, finding multimodal encoders slightly outperform language-only models, while image-only encoders match language models even on non-visual attributes.", "motivation": "To understand how large-scale models represent semantic features of objects, contrasting human learning grounded in sensorimotor experience.", "method": "Probing tasks evaluate models (image-only, multimodal, language-only) on predicting semantic feature norms (McRae and Binder datasets).", "result": "Multimodal encoders slightly outperform language-only models; image-only encoders perform comparably, even on non-visual attributes.", "conclusion": "Results highlight insights into unimodal learning and modality complementarity, questioning the necessity of multimodal training for certain tasks."}}
{"id": "2506.03942", "pdf": "https://arxiv.org/pdf/2506.03942", "abs": "https://arxiv.org/abs/2506.03942", "authors": ["Theodore Barfoot", "Luis C. Garcia-Peraza-Herrera", "Samet Akcay", "Ben Glocker", "Tom Vercauteren"], "title": "Average Calibration Losses for Reliable Uncertainty in Medical Image Segmentation", "categories": ["cs.CV"], "comment": "12 pages, 5 figures, IEEE TMI submission", "summary": "Deep neural networks for medical image segmentation are often overconfident,\ncompromising both reliability and clinical utility. In this work, we propose\ndifferentiable formulations of marginal L1 Average Calibration Error (mL1-ACE)\nas an auxiliary loss that can be computed on a per-image basis. We compare both\nhard- and soft-binning approaches to directly improve pixel-wise calibration.\nOur experiments on four datasets (ACDC, AMOS, KiTS, BraTS) demonstrate that\nincorporating mL1-ACE significantly reduces calibration errors, particularly\nAverage Calibration Error (ACE) and Maximum Calibration Error (MCE), while\nlargely maintaining high Dice Similarity Coefficients (DSCs). We find that the\nsoft-binned variant yields the greatest improvements in calibration, over the\nDice plus cross-entropy loss baseline, but often compromises segmentation\nperformance, with hard-binned mL1-ACE maintaining segmentation performance,\nalbeit with weaker calibration improvement. To gain further insight into\ncalibration performance and its variability across an imaging dataset, we\nintroduce dataset reliability histograms, an aggregation of per-image\nreliability diagrams. The resulting analysis highlights improved alignment\nbetween predicted confidences and true accuracies. Overall, our approach not\nonly enhances the trustworthiness of segmentation predictions but also shows\npotential for safer integration of deep learning methods into clinical\nworkflows. We share our code here:\nhttps://github.com/cai4cai/Average-Calibration-Losses", "AI": {"tldr": "Proposes mL1-ACE as an auxiliary loss to improve calibration in medical image segmentation, showing reduced errors while maintaining performance.", "motivation": "Address overconfidence in deep neural networks for medical image segmentation to enhance reliability and clinical utility.", "method": "Introduces differentiable mL1-ACE with hard- and soft-binning approaches, tested on four datasets (ACDC, AMOS, KiTS, BraTS).", "result": "Soft-binned mL1-ACE improves calibration but may reduce segmentation performance; hard-binned maintains performance with weaker calibration.", "conclusion": "The approach enhances trustworthiness and clinical integration potential, with code shared for reproducibility."}}
{"id": "2506.04089", "pdf": "https://arxiv.org/pdf/2506.04089", "abs": "https://arxiv.org/abs/2506.04089", "authors": ["Anastasiia Ivanova", "Eva Bakaeva", "Zoya Volovikova", "Alexey K. Kovalev", "Aleksandr I. Panov"], "title": "AmbiK: Dataset of Ambiguous Tasks in Kitchen Environment", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.RO"], "comment": "ACL 2025 (Main Conference)", "summary": "As a part of an embodied agent, Large Language Models (LLMs) are typically\nused for behavior planning given natural language instructions from the user.\nHowever, dealing with ambiguous instructions in real-world environments remains\na challenge for LLMs. Various methods for task ambiguity detection have been\nproposed. However, it is difficult to compare them because they are tested on\ndifferent datasets and there is no universal benchmark. For this reason, we\npropose AmbiK (Ambiguous Tasks in Kitchen Environment), the fully textual\ndataset of ambiguous instructions addressed to a robot in a kitchen\nenvironment. AmbiK was collected with the assistance of LLMs and is\nhuman-validated. It comprises 1000 pairs of ambiguous tasks and their\nunambiguous counterparts, categorized by ambiguity type (Human Preferences,\nCommon Sense Knowledge, Safety), with environment descriptions, clarifying\nquestions and answers, user intents, and task plans, for a total of 2000 tasks.\nWe hope that AmbiK will enable researchers to perform a unified comparison of\nambiguity detection methods. AmbiK is available at\nhttps://github.com/cog-model/AmbiK-dataset.", "AI": {"tldr": "The paper introduces AmbiK, a textual dataset for ambiguous instructions in kitchen environments, aiming to standardize ambiguity detection method comparisons.", "motivation": "Addressing the challenge of ambiguous instructions for LLMs in real-world environments and the lack of a universal benchmark for ambiguity detection methods.", "method": "Creation of AmbiK, a dataset with 1000 pairs of ambiguous and unambiguous tasks, categorized by ambiguity type, and validated by humans.", "result": "AmbiK provides a standardized benchmark with 2000 tasks, including environment descriptions, clarifying questions, and task plans.", "conclusion": "AmbiK facilitates unified comparison of ambiguity detection methods and is publicly available for research use."}}
{"id": "2506.04071", "pdf": "https://arxiv.org/pdf/2506.04071", "abs": "https://arxiv.org/abs/2506.04071", "authors": ["Luiz Manella Pereira", "M. Hadi Amini"], "title": "Optimal Transport-based Domain Alignment as a Preprocessing Step for Federated Learning", "categories": ["cs.LG", "cs.CV"], "comment": null, "summary": "Federated learning (FL) is a subfield of machine learning that avoids sharing\nlocal data with a central server, which can enhance privacy and scalability.\nThe inability to consolidate data leads to a unique problem called dataset\nimbalance, where agents in a network do not have equal representation of the\nlabels one is trying to learn to predict. In FL, fusing locally-trained models\nwith unbalanced datasets may deteriorate the performance of global model\naggregation, and reduce the quality of updated local models and the accuracy of\nthe distributed agents' decisions. In this work, we introduce an Optimal\nTransport-based preprocessing algorithm that aligns the datasets by minimizing\nthe distributional discrepancy of data along the edge devices. We accomplish\nthis by leveraging Wasserstein barycenters when computing channel-wise\naverages. These barycenters are collected in a trusted central server where\nthey collectively generate a target RGB space. By projecting our dataset\ntowards this target space, we minimize the distributional discrepancy on a\nglobal level, which facilitates the learning process due to a minimization of\nvariance across the samples. We demonstrate the capabilities of the proposed\napproach over the CIFAR-10 dataset, where we show its capability of reaching\nhigher degrees of generalization in fewer communication rounds.", "AI": {"tldr": "The paper introduces an Optimal Transport-based preprocessing algorithm for federated learning to address dataset imbalance, improving global model performance by minimizing distributional discrepancies.", "motivation": "Federated learning's privacy and scalability benefits are hindered by dataset imbalance, which degrades model performance. This work aims to mitigate this issue.", "method": "The method uses Wasserstein barycenters to align datasets across edge devices, minimizing distributional discrepancies and creating a target RGB space for projection.", "result": "The approach demonstrates improved generalization on the CIFAR-10 dataset, achieving better performance in fewer communication rounds.", "conclusion": "The proposed method effectively addresses dataset imbalance in federated learning, enhancing model accuracy and efficiency."}}
{"id": "2506.04020", "pdf": "https://arxiv.org/pdf/2506.04020", "abs": "https://arxiv.org/abs/2506.04020", "authors": ["An Quang Tang", "Xiuzhen Zhang", "Minh Ngoc Dinh", "Zhuang Li"], "title": "QQSUM: A Novel Task and Model of Quantitative Query-Focused Summarization for Review-based Product Question Answering", "categories": ["cs.CL"], "comment": "Paper accepted to ACL 2025 Main Conference", "summary": "Review-based Product Question Answering (PQA) allows e-commerce platforms to\nautomatically address customer queries by leveraging insights from user\nreviews. However, existing PQA systems generate answers with only a single\nperspective, failing to capture the diversity of customer opinions. In this\npaper we introduce a novel task Quantitative Query-Focused Summarization\n(QQSUM), which aims to summarize diverse customer opinions into representative\nKey Points (KPs) and quantify their prevalence to effectively answer user\nqueries. While Retrieval-Augmented Generation (RAG) shows promise for PQA, its\ngenerated answers still fall short of capturing the full diversity of\nviewpoints. To tackle this challenge, our model QQSUM-RAG, which extends RAG,\nemploys few-shot learning to jointly train a KP-oriented retriever and a KP\nsummary generator, enabling KP-based summaries that capture diverse and\nrepresentative opinions. Experimental results demonstrate that QQSUM-RAG\nachieves superior performance compared to state-of-the-art RAG baselines in\nboth textual quality and quantification accuracy of opinions. Our source code\nis available at: https://github.com/antangrocket1312/QQSUMM", "AI": {"tldr": "The paper introduces QQSUM, a task for summarizing diverse customer opinions into key points (KPs) and quantifying their prevalence to answer product queries better than single-perspective PQA systems. The proposed QQSUM-RAG model outperforms RAG baselines in quality and accuracy.", "motivation": "Existing PQA systems lack diversity in answers, failing to represent varied customer opinions. QQSUM addresses this by summarizing and quantifying diverse viewpoints.", "method": "QQSUM-RAG extends RAG with few-shot learning, training a KP-oriented retriever and summary generator to produce diverse and representative KP summaries.", "result": "QQSUM-RAG outperforms state-of-the-art RAG baselines in textual quality and quantification accuracy.", "conclusion": "QQSUM-RAG effectively captures diverse opinions and quantifies their prevalence, improving PQA systems by providing more comprehensive answers."}}
{"id": "2506.03972", "pdf": "https://arxiv.org/pdf/2506.03972", "abs": "https://arxiv.org/abs/2506.03972", "authors": ["Guohua Wu", "Shengqi Chen", "Pengchao Deng", "Wenting Yu"], "title": "MS-YOLO: A Multi-Scale Model for Accurate and Efficient Blood Cell Detection", "categories": ["cs.CV"], "comment": null, "summary": "Complete blood cell detection holds significant value in clinical\ndiagnostics. Conventional manual microscopy methods suffer from time\ninefficiency and diagnostic inaccuracies. Existing automated detection\napproaches remain constrained by high deployment costs and suboptimal accuracy.\nWhile deep learning has introduced powerful paradigms to this field, persistent\nchallenges in detecting overlapping cells and multi-scale objects hinder\npractical deployment. This study proposes the multi-scale YOLO (MS-YOLO), a\nblood cell detection model based on the YOLOv11 framework, incorporating three\nkey architectural innovations to enhance detection performance. Specifically,\nthe multi-scale dilated residual module (MS-DRM) replaces the original C3K2\nmodules to improve multi-scale discriminability; the dynamic cross-path feature\nenhancement module (DCFEM) enables the fusion of hierarchical features from the\nbackbone with aggregated features from the neck to enhance feature\nrepresentations; and the light adaptive-weight downsampling module (LADS)\nimproves feature downsampling through adaptive spatial weighting while reducing\ncomputational complexity. Experimental results on the CBC benchmark demonstrate\nthat MS-YOLO achieves precise detection of overlapping cells and multi-scale\nobjects, particularly small targets such as platelets, achieving an mAP@50 of\n97.4% that outperforms existing models. Further validation on the supplementary\nWBCDD dataset confirms its robust generalization capability. Additionally, with\na lightweight architecture and real-time inference efficiency, MS-YOLO meets\nclinical deployment requirements, providing reliable technical support for\nstandardized blood pathology assessment.", "AI": {"tldr": "MS-YOLO, a blood cell detection model, improves accuracy for overlapping and multi-scale cells using innovative modules, achieving 97.4% mAP@50 and real-time efficiency.", "motivation": "Manual microscopy is inefficient and inaccurate; existing automated methods are costly and lack accuracy, especially for overlapping and multi-scale cells.", "method": "MS-YOLO integrates three modules: MS-DRM for multi-scale discriminability, DCFEM for feature fusion, and LADS for efficient downsampling.", "result": "Achieves 97.4% mAP@50 on CBC benchmark, excels in detecting small targets like platelets, and generalizes well on WBCDD dataset.", "conclusion": "MS-YOLO offers precise, efficient, and deployable blood cell detection, supporting standardized clinical diagnostics."}}
{"id": "2506.04098", "pdf": "https://arxiv.org/pdf/2506.04098", "abs": "https://arxiv.org/abs/2506.04098", "authors": ["Wenhao Li", "Wenwu Li", "Chuyun Shen", "Junjie Sheng", "Zixiao Huang", "Di Wu", "Yun Hua", "Wei Yin", "Xiangfeng Wang", "Hongyuan Zha", "Bo Jin"], "title": "TextAtari: 100K Frames Game Playing with Language Agents", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "51 pages, 39 figures", "summary": "We present TextAtari, a benchmark for evaluating language agents on very\nlong-horizon decision-making tasks spanning up to 100,000 steps. By translating\nthe visual state representations of classic Atari games into rich textual\ndescriptions, TextAtari creates a challenging test bed that bridges sequential\ndecision-making with natural language processing. The benchmark includes nearly\n100 distinct tasks with varying complexity, action spaces, and planning\nhorizons, all rendered as text through an unsupervised representation learning\nframework (AtariARI). We evaluate three open-source large language models\n(Qwen2.5-7B, Gemma-7B, and Llama3.1-8B) across three agent frameworks\n(zero-shot, few-shot chain-of-thought, and reflection reasoning) to assess how\ndifferent forms of prior knowledge affect performance on these long-horizon\nchallenges. Four scenarios-Basic, Obscured, Manual Augmentation, and\nReference-based-investigate the impact of semantic understanding, instruction\ncomprehension, and expert demonstrations on agent decision-making. Our results\nreveal significant performance gaps between language agents and human players\nin extensive planning tasks, highlighting challenges in sequential reasoning,\nstate tracking, and strategic planning across tens of thousands of steps.\nTextAtari provides standardized evaluation protocols, baseline implementations,\nand a framework for advancing research at the intersection of language models\nand planning.", "AI": {"tldr": "TextAtari is a benchmark for evaluating language agents on long-horizon decision-making tasks using textual descriptions of Atari games. It tests models like Qwen2.5-7B, Gemma-7B, and Llama3.1-8B across various agent frameworks, revealing performance gaps compared to humans.", "motivation": "To bridge sequential decision-making and natural language processing by creating a challenging benchmark for language agents.", "method": "Translates Atari game visuals into text, evaluates models across 100 tasks using unsupervised representation learning (AtariARI), and tests three agent frameworks.", "result": "Significant performance gaps between language agents and humans in long-horizon tasks, highlighting challenges in reasoning and planning.", "conclusion": "TextAtari offers a standardized framework to advance research in language models and planning."}}
{"id": "2506.04118", "pdf": "https://arxiv.org/pdf/2506.04118", "abs": "https://arxiv.org/abs/2506.04118", "authors": ["Jonathan Geuter", "Youssef Mroueh", "David Alvarez-Melis"], "title": "Guided Speculative Inference for Efficient Test-Time Alignment of LLMs", "categories": ["cs.LG", "stat.ML", "I.2.7"], "comment": "12 pages, 2 figures", "summary": "We propose Guided Speculative Inference (GSI), a novel algorithm for\nefficient reward-guided decoding in large language models. GSI combines soft\nbest-of-$n$ test-time scaling with a reward model $r(x,y)$ and speculative\nsamples from a small auxiliary model $\\pi_S(y\\mid x)$. We provably approximate\nthe optimal tilted policy $\\pi_{\\beta,B}(y\\mid x) \\propto \\pi_B(y\\mid\nx)\\exp(\\beta\\,r(x,y))$ of soft best-of-$n$ under the primary model $\\pi_B$. We\nderive a theoretical bound on the KL divergence between our induced\ndistribution and the optimal policy. In experiments on reasoning benchmarks\n(MATH500, OlympiadBench, Minerva Math), our method achieves higher accuracy\nthan standard soft best-of-$n$ with $\\pi_S$ and reward-guided speculative\ndecoding (Liao et al., 2025), and in certain settings even outperforms soft\nbest-of-$n$ with $\\pi_B$. The code is available at\nhttps://github.com/j-geuter/GSI .", "AI": {"tldr": "GSI is a new algorithm for efficient reward-guided decoding in large language models, combining soft best-of-n with a reward model and speculative samples from a small auxiliary model. It approximates the optimal tilted policy and outperforms existing methods in accuracy.", "motivation": "To improve the efficiency and accuracy of reward-guided decoding in large language models by combining soft best-of-n scaling with speculative samples and a reward model.", "method": "GSI integrates soft best-of-n test-time scaling, a reward model, and speculative samples from a small auxiliary model to approximate the optimal tilted policy under the primary model.", "result": "GSI achieves higher accuracy than standard soft best-of-n and reward-guided speculative decoding, sometimes outperforming soft best-of-n with the primary model.", "conclusion": "GSI is a promising approach for efficient and accurate reward-guided decoding, with potential for broader applications in reasoning tasks."}}
{"id": "2506.04032", "pdf": "https://arxiv.org/pdf/2506.04032", "abs": "https://arxiv.org/abs/2506.04032", "authors": ["Sina Rashidian", "Nan Li", "Jonathan Amar", "Jong Ha Lee", "Sam Pugh", "Eric Yang", "Geoff Masterson", "Myoung Cha", "Yugang Jia", "Akhil Vaid"], "title": "AI Agents for Conversational Patient Triage: Preliminary Simulation-Based Evaluation with Real-World EHR Data", "categories": ["cs.CL"], "comment": null, "summary": "Background: We present a Patient Simulator that leverages real world patient\nencounters which cover a broad range of conditions and symptoms to provide\nsynthetic test subjects for development and testing of healthcare agentic\nmodels. The simulator provides a realistic approach to patient presentation and\nmulti-turn conversation with a symptom-checking agent. Objectives: (1) To\nconstruct and instantiate a Patient Simulator to train and test an AI health\nagent, based on patient vignettes derived from real EHR data. (2) To test the\nvalidity and alignment of the simulated encounters provided by the Patient\nSimulator to expert human clinical providers. (3) To illustrate the evaluation\nframework of such an LLM system on the generated realistic, data-driven\nsimulations -- yielding a preliminary assessment of our proposed system.\nMethods: We first constructed realistic clinical scenarios by deriving patient\nvignettes from real-world EHR encounters. These vignettes cover a variety of\npresenting symptoms and underlying conditions. We then evaluate the performance\nof the Patient Simulator as a simulacrum of a real patient encounter across\nover 500 different patient vignettes. We leveraged a separate AI agent to\nprovide multi-turn questions to obtain a history of present illness. The\nresulting multiturn conversations were evaluated by two expert clinicians.\nResults: Clinicians scored the Patient Simulator as consistent with the patient\nvignettes in those same 97.7% of cases. The extracted case summary based on the\nconversation history was 99% relevant. Conclusions: We developed a methodology\nto incorporate vignettes derived from real healthcare patient data to build a\nsimulation of patient responses to symptom checking agents. The performance and\nalignment of this Patient Simulator could be used to train and test a\nmulti-turn conversational AI agent at scale.", "AI": {"tldr": "A Patient Simulator using real EHR data was developed to train AI health agents, validated by clinicians with high accuracy.", "motivation": "To create a realistic synthetic test environment for AI health agents using real patient data.", "method": "Derived patient vignettes from EHR data, simulated multi-turn conversations, and evaluated with expert clinicians.", "result": "97.7% consistency with vignettes and 99% relevance in case summaries.", "conclusion": "The simulator effectively trains AI agents for healthcare conversations at scale."}}
{"id": "2506.03988", "pdf": "https://arxiv.org/pdf/2506.03988", "abs": "https://arxiv.org/abs/2506.03988", "authors": ["Hicham Eddoubi", "Jonas Ricker", "Federico Cocchi", "Lorenzo Baraldi", "Angelo Sotgiu", "Maura Pintor", "Marcella Cornia", "Lorenzo Baraldi", "Asja Fischer", "Rita Cucchiara", "Battista Biggio"], "title": "RAID: A Dataset for Testing the Adversarial Robustness of AI-Generated Image Detectors", "categories": ["cs.CV", "cs.LG"], "comment": "Under review for NeurIPS 2025 Datasets and Benchmarks Track", "summary": "AI-generated images have reached a quality level at which humans are\nincapable of reliably distinguishing them from real images. To counteract the\ninherent risk of fraud and disinformation, the detection of AI-generated images\nis a pressing challenge and an active research topic. While many of the\npresented methods claim to achieve high detection accuracy, they are usually\nevaluated under idealized conditions. In particular, the adversarial robustness\nis often neglected, potentially due to a lack of awareness or the substantial\neffort required to conduct a comprehensive robustness analysis. In this work,\nwe tackle this problem by providing a simpler means to assess the robustness of\nAI-generated image detectors. We present RAID (Robust evaluation of\nAI-generated image Detectors), a dataset of 72k diverse and highly transferable\nadversarial examples. The dataset is created by running attacks against an\nensemble of seven state-of-the-art detectors and images generated by four\ndifferent text-to-image models. Extensive experiments show that our methodology\ngenerates adversarial images that transfer with a high success rate to unseen\ndetectors, which can be used to quickly provide an approximate yet still\nreliable estimate of a detector's adversarial robustnessOur findings indicate\nthat current state-of-the-art AI-generated image detectors can be easily\ndeceived by adversarial examples, highlighting the critical need for the\ndevelopment of more robust methods. We release our dataset at\nhttps://huggingface.co/datasets/aimagelab/RAID and evaluation code at\nhttps://github.com/pralab/RAID.", "AI": {"tldr": "RAID introduces a dataset and method to evaluate the adversarial robustness of AI-generated image detectors, revealing their vulnerability to adversarial attacks.", "motivation": "The rise of AI-generated images poses risks of fraud and disinformation, but existing detectors lack robust evaluation under adversarial conditions.", "method": "RAID provides a dataset of 72k adversarial examples created by attacking seven detectors and four text-to-image models, enabling simpler robustness assessment.", "result": "Current detectors are easily deceived by adversarial examples, demonstrating their lack of robustness.", "conclusion": "The study underscores the need for more robust AI-generated image detectors and releases RAID dataset and code for further research."}}
{"id": "2506.04131", "pdf": "https://arxiv.org/pdf/2506.04131", "abs": "https://arxiv.org/abs/2506.04131", "authors": ["Disha Sheshanarayana", "Tanishka Magar", "Ayushi Mittal", "Neelam Chaplot"], "title": "CLAIM: An Intent-Driven Multi-Agent Framework for Analyzing Manipulation in Courtroom Dialogues", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "Accepted to SICon 2025 ACL", "summary": "Courtrooms are places where lives are determined and fates are sealed, yet\nthey are not impervious to manipulation. Strategic use of manipulation in legal\njargon can sway the opinions of judges and affect the decisions. Despite the\ngrowing advancements in NLP, its application in detecting and analyzing\nmanipulation within the legal domain remains largely unexplored. Our work\naddresses this gap by introducing LegalCon, a dataset of 1,063 annotated\ncourtroom conversations labeled for manipulation detection, identification of\nprimary manipulators, and classification of manipulative techniques, with a\nfocus on long conversations. Furthermore, we propose CLAIM, a two-stage,\nIntent-driven Multi-agent framework designed to enhance manipulation analysis\nby enabling context-aware and informed decision-making. Our results highlight\nthe potential of incorporating agentic frameworks to improve fairness and\ntransparency in judicial processes. We hope that this contributes to the\nbroader application of NLP in legal discourse analysis and the development of\nrobust tools to support fairness in legal decision-making. Our code and data\nare available at https://github.com/Disha1001/CLAIM.", "AI": {"tldr": "The paper introduces LegalCon, a dataset for detecting manipulation in courtroom conversations, and CLAIM, a framework to analyze manipulation, aiming to improve fairness in legal processes.", "motivation": "To address the unexplored application of NLP in detecting manipulation in legal jargon, which can influence judicial decisions.", "method": "Developed LegalCon (annotated dataset) and CLAIM (two-stage, intent-driven multi-agent framework) for manipulation analysis.", "result": "CLAIM enhances context-aware manipulation analysis, improving fairness and transparency in judicial processes.", "conclusion": "The work advances NLP in legal discourse and supports fairness in legal decision-making; dataset and code are publicly available."}}
{"id": "2506.04126", "pdf": "https://arxiv.org/pdf/2506.04126", "abs": "https://arxiv.org/abs/2506.04126", "authors": ["Yujun Kim", "Jaeyoung Cha", "Chulhee Yun"], "title": "Incremental Gradient Descent with Small Epoch Counts is Surprisingly Slow on Ill-Conditioned Problems", "categories": ["cs.LG", "math.OC"], "comment": "Accepted to ICML 2025, 56 pages, 6 figures", "summary": "Recent theoretical results demonstrate that the convergence rates of\npermutation-based SGD (e.g., random reshuffling SGD) are faster than\nuniform-sampling SGD; however, these studies focus mainly on the large epoch\nregime, where the number of epochs $K$ exceeds the condition number $\\kappa$.\nIn contrast, little is known when $K$ is smaller than $\\kappa$, and it is still\na challenging open question whether permutation-based SGD can converge faster\nin this small epoch regime (Safran and Shamir, 2021). As a step toward\nunderstanding this gap, we study the naive deterministic variant, Incremental\nGradient Descent (IGD), on smooth and strongly convex functions. Our lower\nbounds reveal that for the small epoch regime, IGD can exhibit surprisingly\nslow convergence even when all component functions are strongly convex.\nFurthermore, when some component functions are allowed to be nonconvex, we\nprove that the optimality gap of IGD can be significantly worse throughout the\nsmall epoch regime. Our analyses reveal that the convergence properties of\npermutation-based SGD in the small epoch regime may vary drastically depending\non the assumptions on component functions. Lastly, we supplement the paper with\ntight upper and lower bounds for IGD in the large epoch regime.", "AI": {"tldr": "The paper investigates the convergence behavior of Incremental Gradient Descent (IGD) in the small epoch regime, contrasting with known results for permutation-based SGD in large epochs. It highlights slower convergence for IGD under certain conditions and worse performance with nonconvex components.", "motivation": "To address the gap in understanding convergence rates of permutation-based SGD when the number of epochs is smaller than the condition number, focusing on IGD as a deterministic variant.", "method": "The study analyzes IGD on smooth and strongly convex functions, providing lower bounds for convergence in the small epoch regime and examining the impact of nonconvex component functions.", "result": "IGD exhibits slow convergence in the small epoch regime, especially with nonconvex components, and the paper provides tight bounds for IGD in the large epoch regime.", "conclusion": "The convergence properties of permutation-based SGD vary significantly in the small epoch regime depending on component function assumptions, with IGD showing limitations compared to large epoch results."}}
{"id": "2506.04041", "pdf": "https://arxiv.org/pdf/2506.04041", "abs": "https://arxiv.org/abs/2506.04041", "authors": ["Claire Barale", "Leslie Barrett", "Vikram Sunil Bajaj", "Michael Rovatsos"], "title": "LexTime: A Benchmark for Temporal Ordering of Legal Events", "categories": ["cs.CL"], "comment": "Preprint", "summary": "Temporal reasoning in legal texts is important for applications like case law\nanalysis and compliance monitoring. However, existing datasets lack expert\nlanguage evaluation, leaving a gap in understanding how LLMs manage event\nordering in legal contexts. We introduce LexTime, the first dataset designed to\nevaluate LLMs' event ordering capabilities in legal language, consisting of 512\ninstances from U.S. Federal Complaints with annotated event pairs and their\ntemporal relations. Our findings show that (1) LLMs are more accurate on legal\nevent ordering than on narrative (up to +10.5%); (2) longer input contexts and\nimplicit events boost accuracy, reaching 80.8% for implicit-explicit event\npairs; (3) legal linguistic complexities and nested clauses remain a challenge.\nWe investigate how context length, explicit vs implicit event pairs, and legal\nlanguage features affect model performance, demonstrating the need for specific\nmodeling strategies to enhance temporal event reasoning.", "AI": {"tldr": "LexTime is a new dataset for evaluating LLMs' event ordering in legal texts, showing improved accuracy in legal contexts but challenges with linguistic complexities.", "motivation": "Existing datasets lack expert evaluation of legal language, creating a gap in understanding LLMs' temporal reasoning in legal contexts.", "method": "Introduces LexTime, a dataset of 512 annotated event pairs from U.S. Federal Complaints, analyzing LLMs' performance on legal event ordering.", "result": "LLMs perform better on legal event ordering (+10.5%), with longer contexts and implicit events boosting accuracy to 80.8%. Legal complexities remain challenging.", "conclusion": "Legal-specific modeling strategies are needed to improve temporal event reasoning in LLMs, addressing context length and linguistic features."}}
{"id": "2506.04005", "pdf": "https://arxiv.org/pdf/2506.04005", "abs": "https://arxiv.org/abs/2506.04005", "authors": ["Maxime Zanella", "Cl\u00e9ment Fuchs", "Ismail Ben Ayed", "Christophe De Vleeschouwer"], "title": "Vocabulary-free few-shot learning for Vision-Language Models", "categories": ["cs.CV"], "comment": "Accepted at CVPR Workshops 2025", "summary": "Recent advances in few-shot adaptation for Vision-Language Models (VLMs) have\ngreatly expanded their ability to generalize across tasks using only a few\nlabeled examples. However, existing approaches primarily build upon the strong\nzero-shot priors of these models by leveraging carefully designed,\ntask-specific prompts. This dependence on predefined class names can restrict\ntheir applicability, especially in scenarios where exact class names are\nunavailable or difficult to specify. To address this limitation, we introduce\nvocabulary-free few-shot learning for VLMs, a setting where target class\ninstances - that is, images - are available but their corresponding names are\nnot. We propose Similarity Mapping (SiM), a simple yet effective baseline that\nclassifies target instances solely based on similarity scores with a set of\ngeneric prompts (textual or visual), eliminating the need for carefully\nhandcrafted prompts. Although conceptually straightforward, SiM demonstrates\nstrong performance, operates with high computational efficiency (learning the\nmapping typically takes less than one second), and provides interpretability by\nlinking target classes to generic prompts. We believe that our approach could\nserve as an important baseline for future research in vocabulary-free few-shot\nlearning. Code is available at\nhttps://github.com/MaxZanella/vocabulary-free-FSL.", "AI": {"tldr": "The paper introduces vocabulary-free few-shot learning for Vision-Language Models (VLMs) using Similarity Mapping (SiM), a method that classifies images without predefined class names by leveraging similarity scores with generic prompts.", "motivation": "Existing few-shot adaptation methods for VLMs rely on predefined class names, limiting their applicability when exact class names are unavailable.", "method": "Proposes SiM, a method that classifies target instances using similarity scores with generic prompts, eliminating the need for task-specific prompts.", "result": "SiM shows strong performance, high computational efficiency (learning in <1s), and interpretability by linking classes to generic prompts.", "conclusion": "SiM serves as a promising baseline for vocabulary-free few-shot learning in VLMs."}}
{"id": "2506.04132", "pdf": "https://arxiv.org/pdf/2506.04132", "abs": "https://arxiv.org/abs/2506.04132", "authors": ["Peter A. Gloor"], "title": "Plant Bioelectric Early Warning Systems: A Five-Year Investigation into Human-Plant Electromagnetic Communication", "categories": ["q-bio.OT", "cs.AI"], "comment": null, "summary": "We present a comprehensive investigation into plant bioelectric responses to\nhuman presence and emotional states, building on five years of systematic\nresearch. Using custom-built plant sensors and machine learning classification,\nwe demonstrate that plants generate distinct bioelectric signals correlating\nwith human proximity, emotional states, and physiological conditions. A deep\nlearning model based on ResNet50 architecture achieved 97% accuracy in\nclassifying human emotional states through plant voltage spectrograms, while\ncontrol models with shuffled labels achieved only 30% accuracy. This study\nsynthesizes findings from multiple experiments spanning 2020-2025, including\nindividual recognition (66% accuracy), eurythmic gesture detection, stress\nprediction, and responses to human voice and movement. We propose that these\nphenomena represent evolved anti-herbivory early warning systems, where plants\ndetect approaching animals through bioelectric field changes before physical\ncontact. Our results challenge conventional understanding of plant sensory\ncapabilities and suggest practical applications in agriculture, healthcare, and\nhuman-plant interaction research.", "AI": {"tldr": "Plants exhibit bioelectric responses to human presence and emotions, with 97% accuracy in classifying emotional states using deep learning.", "motivation": "To explore plant bioelectric signals in response to human proximity and emotions, challenging traditional views of plant sensory capabilities.", "method": "Custom-built plant sensors and ResNet50-based deep learning model to analyze bioelectric signals.", "result": "97% accuracy in classifying human emotional states; plants show distinct responses to human presence, emotions, and conditions.", "conclusion": "Plants may have evolved early warning systems, with potential applications in agriculture, healthcare, and human-plant interaction."}}
{"id": "2506.04165", "pdf": "https://arxiv.org/pdf/2506.04165", "abs": "https://arxiv.org/abs/2506.04165", "authors": ["Yashas Samaga", "Varun Yerram", "Spandana Raj Babbula", "Prateek Jain", "Praneeth Netrapalli"], "title": "Faster Approx. Top-K: Harnessing the Full Power of Two Stages", "categories": ["cs.LG", "cs.DS"], "comment": "Rejected from MLSys 2025", "summary": "We consider the Top-$K$ selection problem, which aims to identify the\nlargest-$K$ elements from an array. Top-$K$ selection arises in many machine\nlearning algorithms and often becomes a bottleneck on accelerators, which are\noptimized for dense matrix multiplications. To address this problem,\n\\citet{chern2022tpuknnknearestneighbor} proposed a fast two-stage\n\\textit{approximate} Top-$K$ algorithm: (i) partition the input array and\nselect the top-$1$ element from each partition, (ii) sort this \\textit{smaller\nsubset} and return the top $K$ elements. In this paper, we consider a\ngeneralized version of this algorithm, where the first stage selects top-$K'$\nelements, for some $1 \\leq K' \\leq K$, from each partition. Our contributions\nare as follows: (i) we derive an expression for the expected recall of this\ngeneralized algorithm and show that choosing $K' > 1$ with fewer partitions in\nthe first stage reduces the input size to the second stage more effectively\nwhile maintaining the same expected recall as the original algorithm, (ii) we\nderive a bound on the expected recall for the original algorithm in\n\\citet{chern2022tpuknnknearestneighbor} that is provably tighter by a factor of\n$2$ than the one in that paper, and (iii) we implement our algorithm on Cloud\nTPUv5e and achieve around an order of magnitude speedups over the original\nalgorithm without sacrificing recall on real-world tasks.", "AI": {"tldr": "The paper generalizes a two-stage approximate Top-K selection algorithm, improves recall bounds, and achieves significant speedups on TPUv5e.", "motivation": "Top-K selection is a bottleneck in machine learning on accelerators. The paper aims to enhance the efficiency and theoretical understanding of an existing approximate algorithm.", "method": "Generalizes the original two-stage algorithm by selecting top-K' elements per partition (1 \u2264 K' \u2264 K), derives expected recall expressions, and tightens recall bounds.", "result": "Choosing K' > 1 reduces input size to the second stage while maintaining recall. The improved bound is tighter by a factor of 2. Implementation on TPUv5e shows ~10x speedups without recall loss.", "conclusion": "The generalized algorithm is more efficient and theoretically sound, with practical speedups on real-world tasks."}}
{"id": "2506.04042", "pdf": "https://arxiv.org/pdf/2506.04042", "abs": "https://arxiv.org/abs/2506.04042", "authors": ["Xiyu Liu", "Zhengxiao Liu", "Naibin Gu", "Zheng Lin", "Ji Xiang", "Weiping Wang"], "title": "Unveiling and Eliminating the Shortcut Learning for Locate-Then-Edit Knowledge Editing via Both Subject and Relation Awareness", "categories": ["cs.CL"], "comment": null, "summary": "Knowledge editing aims to alternate the target knowledge predicted by large\nlanguage models while ensuring the least side effects on unrelated knowledge.\nAn effective way to achieve knowledge editing is to identify pivotal parameters\nfor predicting factual associations and modify them with an optimization\nprocess to update the predictions. However, these locate-then-edit methods are\nuncontrollable since they tend to modify most unrelated relations connected to\nthe subject of target editing. We unveil that this failure of controllable\nediting is due to a shortcut learning issue during the optimization process.\nSpecifically, we discover two crucial features that are the subject feature and\nthe relation feature for models to learn during optimization, but the current\noptimization process tends to over-learning the subject feature while\nneglecting the relation feature. To eliminate this shortcut learning of the\nsubject feature, we propose a novel two-stage optimization process that\nbalances the learning of the subject feature and the relation feature.\nExperimental results demonstrate that our approach successfully prevents\nknowledge editing from shortcut learning and achieves the optimal overall\nperformance, contributing to controllable knowledge editing.", "AI": {"tldr": "The paper addresses the issue of uncontrollable knowledge editing in large language models due to shortcut learning, proposing a two-stage optimization process to balance subject and relation features for better control.", "motivation": "Current locate-then-edit methods for knowledge editing in language models often modify unrelated knowledge due to shortcut learning, leading to uncontrollable outcomes.", "method": "A novel two-stage optimization process is introduced to balance the learning of subject and relation features, preventing over-learning of the subject feature.", "result": "The proposed method successfully avoids shortcut learning and achieves optimal performance in controllable knowledge editing.", "conclusion": "The two-stage optimization process effectively balances feature learning, enabling more controllable and precise knowledge editing in language models."}}
{"id": "2506.04034", "pdf": "https://arxiv.org/pdf/2506.04034", "abs": "https://arxiv.org/abs/2506.04034", "authors": ["Qing Jiang", "Xingyu Chen", "Zhaoyang Zeng", "Junzhi Yu", "Lei Zhang"], "title": "Rex-Thinker: Grounded Object Referring via Chain-of-Thought Reasoning", "categories": ["cs.CV"], "comment": "homepage: https://rexthinker.github.io/", "summary": "Object referring aims to detect all objects in an image that match a given\nnatural language description. We argue that a robust object referring model\nshould be grounded, meaning its predictions should be both explainable and\nfaithful to the visual content. Specifically, it should satisfy two key\nproperties: 1) Verifiable, by producing interpretable reasoning that justifies\nits predictions and clearly links them to visual evidence; and 2) Trustworthy,\nby learning to abstain when no object in the image satisfies the given\nexpression. However, most methods treat referring as a direct bounding box\nprediction task, offering limited interpretability and struggling to reject\nexpressions with no matching object. In this work, we propose Rex-Thinker, a\nmodel that formulates object referring as an explicit CoT reasoning task. Given\na referring expression, we first identify all candidate object instances\ncorresponding to the referred object category. Rex-Thinker then performs\nstep-by-step reasoning over each candidate to assess whether it matches the\ngiven expression, before making a final prediction. To support this paradigm,\nwe construct a large-scale CoT-style referring dataset named HumanRef-CoT by\nprompting GPT-4o on the HumanRef dataset. Each reasoning trace follows a\nstructured planning, action, and summarization format, enabling the model to\nlearn decomposed, interpretable reasoning over object candidates. We then train\nRex-Thinker in two stages: a cold-start supervised fine-tuning phase to teach\nthe model how to perform structured reasoning, followed by GRPO-based RL\nlearning to improve accuracy and generalization. Experiments show that our\napproach outperforms standard baselines in both precision and interpretability\non in-domain evaluation, while also demonstrating improved ability to reject\nhallucinated outputs and strong generalization in out-of-domain settings.", "AI": {"tldr": "Rex-Thinker is a model for object referring that uses explicit Chain-of-Thought (CoT) reasoning to improve interpretability and trustworthiness, outperforming baselines in precision and generalization.", "motivation": "Current object referring models lack interpretability and struggle to reject expressions with no matching objects, necessitating a grounded approach.", "method": "Rex-Thinker formulates object referring as a CoT reasoning task, identifying candidates and assessing matches step-by-step. A dataset (HumanRef-CoT) is created for training, followed by supervised fine-tuning and GRPO-based RL learning.", "result": "The model outperforms baselines in precision and interpretability, with improved rejection of hallucinated outputs and strong generalization.", "conclusion": "Rex-Thinker demonstrates the effectiveness of explicit reasoning for grounded object referring, offering both verifiable and trustworthy predictions."}}
{"id": "2506.04143", "pdf": "https://arxiv.org/pdf/2506.04143", "abs": "https://arxiv.org/abs/2506.04143", "authors": ["Ngoc Q. Ly", "Hieu N. M. Cao", "Thi T. Nguyen"], "title": "Person Re-Identification System at Semantic Level based on Pedestrian Attributes Ontology", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Person Re-Identification (Re-ID) is a very important task in video\nsurveillance systems such as tracking people, finding people in public places,\nor analysing customer behavior in supermarkets. Although there have been many\nworks to solve this problem, there are still remaining challenges such as\nlarge-scale datasets, imbalanced data, viewpoint, fine grained data\n(attributes), the Local Features are not employed at semantic level in online\nstage of Re-ID task, furthermore, the imbalanced data problem of attributes are\nnot taken into consideration. This paper has proposed a Unified Re-ID system\nconsisted of three main modules such as Pedestrian Attribute Ontology (PAO),\nLocal Multi-task DCNN (Local MDCNN), Imbalance Data Solver (IDS). The new main\npoint of our Re-ID system is the power of mutual support of PAO, Local MDCNN\nand IDS to exploit the inner-group correlations of attributes and pre-filter\nthe mismatch candidates from Gallery set based on semantic information as\nFashion Attributes and Facial Attributes, to solve the imbalanced data of\nattributes without adjusting network architecture and data augmentation. We\nexperimented on the well-known Market1501 dataset. The experimental results\nhave shown the effectiveness of our Re-ID system and it could achieve the\nhigher performance on Market1501 dataset in comparison to some state-of-the-art\nRe-ID methods.", "AI": {"tldr": "The paper proposes a Unified Re-ID system with three modules (PAO, Local MDCNN, IDS) to address challenges like imbalanced data and semantic feature use, achieving better performance on Market1501.", "motivation": "Address challenges in Person Re-ID like imbalanced data, semantic feature utilization, and viewpoint issues.", "method": "Proposes a system with Pedestrian Attribute Ontology (PAO), Local Multi-task DCNN (Local MDCNN), and Imbalance Data Solver (IDS) to leverage attribute correlations and filter mismatches.", "result": "Achieves higher performance on Market1501 compared to state-of-the-art methods.", "conclusion": "The Unified Re-ID system effectively addresses key challenges and improves performance."}}
{"id": "2506.04166", "pdf": "https://arxiv.org/pdf/2506.04166", "abs": "https://arxiv.org/abs/2506.04166", "authors": ["Caleb Chin", "Aashish Khubchandani", "Harshvardhan Maskara", "Kyuseong Choi", "Jacob Feitelberg", "Albert Gong", "Manit Paul", "Tathagata Sadhukhan", "Anish Agarwal", "Raaz Dwivedi"], "title": "N$^2$: A Unified Python Package and Test Bench for Nearest Neighbor-Based Matrix Completion", "categories": ["cs.LG", "stat.CO", "stat.ML"], "comment": "21 pages, 6 figures", "summary": "Nearest neighbor (NN) methods have re-emerged as competitive tools for matrix\ncompletion, offering strong empirical performance and recent theoretical\nguarantees, including entry-wise error bounds, confidence intervals, and\nminimax optimality. Despite their simplicity, recent work has shown that NN\napproaches are robust to a range of missingness patterns and effective across\ndiverse applications. This paper introduces N$^2$, a unified Python package and\ntestbed that consolidates a broad class of NN-based methods through a modular,\nextensible interface. Built for both researchers and practitioners, N$^2$\nsupports rapid experimentation and benchmarking. Using this framework, we\nintroduce a new NN variant that achieves state-of-the-art results in several\nsettings. We also release a benchmark suite of real-world datasets, from\nhealthcare and recommender systems to causal inference and LLM evaluation,\ndesigned to stress-test matrix completion methods beyond synthetic scenarios.\nOur experiments demonstrate that while classical methods excel on idealized\ndata, NN-based techniques consistently outperform them in real-world settings.", "AI": {"tldr": "The paper introduces N$^2$, a Python package for NN-based matrix completion, showcasing its modularity, extensibility, and a new NN variant with state-of-the-art performance. It also provides real-world benchmarks, demonstrating NN methods' superiority over classical approaches in practical settings.", "motivation": "To unify and simplify the use of NN-based methods for matrix completion, addressing the gap between theoretical guarantees and practical applications.", "method": "Developed N$^2$, a modular Python package, and introduced a new NN variant. Benchmarked performance using real-world datasets across diverse domains.", "result": "NN-based methods, especially the new variant, outperform classical methods in real-world scenarios, as validated by the benchmark suite.", "conclusion": "NN methods are robust and effective for matrix completion in practical settings, with N$^2$ serving as a valuable tool for research and application."}}
{"id": "2506.04047", "pdf": "https://arxiv.org/pdf/2506.04047", "abs": "https://arxiv.org/abs/2506.04047", "authors": ["Yuqian Li", "Yupei Du", "Yufang Liu", "Feifei Feng", "Mou Xiao Feng", "Yuanbin Wu"], "title": "On Support Samples of Next Word Prediction", "categories": ["cs.CL"], "comment": "Accepted to ACL2025(Main Conference)", "summary": "Language models excel in various tasks by making complex decisions, yet\nunderstanding the rationale behind these decisions remains a challenge. This\npaper investigates \\emph{data-centric interpretability} in language models,\nfocusing on the next-word prediction task. Using representer theorem, we\nidentify two types of \\emph{support samples}-those that either promote or deter\nspecific predictions. Our findings reveal that being a support sample is an\nintrinsic property, predictable even before training begins. Additionally,\nwhile non-support samples are less influential in direct predictions, they play\na critical role in preventing overfitting and shaping generalization and\nrepresentation learning. Notably, the importance of non-support samples\nincreases in deeper layers, suggesting their significant role in intermediate\nrepresentation formation.These insights shed light on the interplay between\ndata and model decisions, offering a new dimension to understanding language\nmodel behavior and interpretability.", "AI": {"tldr": "The paper explores data-centric interpretability in language models, identifying support samples that influence predictions and highlighting the role of non-support samples in preventing overfitting and shaping learning.", "motivation": "Understanding the rationale behind language model decisions is challenging, prompting a focus on data-centric interpretability.", "method": "The study uses the representer theorem to identify support samples (promoting or deterring predictions) and analyzes their impact.", "result": "Support samples are intrinsic and predictable pre-training, while non-support samples are crucial for preventing overfitting and representation learning, especially in deeper layers.", "conclusion": "The findings provide insights into data-model interactions, enhancing interpretability of language model behavior."}}
{"id": "2506.04048", "pdf": "https://arxiv.org/pdf/2506.04048", "abs": "https://arxiv.org/abs/2506.04048", "authors": ["Gabriele Magrini", "Federico Becattini", "Giovanni Colombo", "Pietro Pala"], "title": "EV-Flying: an Event-based Dataset for In-The-Wild Recognition of Flying Objects", "categories": ["cs.CV"], "comment": null, "summary": "Monitoring aerial objects is crucial for security, wildlife conservation, and\nenvironmental studies. Traditional RGB-based approaches struggle with\nchallenges such as scale variations, motion blur, and high-speed object\nmovements, especially for small flying entities like insects and drones. In\nthis work, we explore the potential of event-based vision for detecting and\nrecognizing flying objects, in particular animals that may not follow short and\nlong-term predictable patters. Event cameras offer high temporal resolution,\nlow latency, and robustness to motion blur, making them well-suited for this\ntask. We introduce EV-Flying, an event-based dataset of flying objects,\ncomprising manually annotated birds, insects and drones with spatio-temporal\nbounding boxes and track identities. To effectively process the asynchronous\nevent streams, we employ a point-based approach leveraging lightweight\narchitectures inspired by PointNet. Our study investigates the classification\nof flying objects using point cloud-based event representations. The proposed\ndataset and methodology pave the way for more efficient and reliable aerial\nobject recognition in real-world scenarios.", "AI": {"tldr": "The paper introduces EV-Flying, an event-based dataset for detecting and recognizing flying objects, addressing challenges like scale variations and motion blur with event cameras and a PointNet-inspired method.", "motivation": "Traditional RGB-based methods struggle with challenges like scale variations, motion blur, and unpredictable movement patterns of small flying objects (e.g., insects, drones). Event cameras offer high temporal resolution and robustness to motion blur, making them suitable for this task.", "method": "The authors introduce EV-Flying, a dataset of annotated flying objects (birds, insects, drones) with spatio-temporal bounding boxes. They use a point-based approach inspired by PointNet to process asynchronous event streams for classification.", "result": "The study demonstrates the effectiveness of event-based vision and lightweight architectures for classifying flying objects, providing a foundation for real-world aerial object recognition.", "conclusion": "The EV-Flying dataset and proposed methodology enable more efficient and reliable recognition of flying objects, addressing limitations of traditional RGB-based approaches."}}
{"id": "2506.04147", "pdf": "https://arxiv.org/pdf/2506.04147", "abs": "https://arxiv.org/abs/2506.04147", "authors": ["Jiaheng Hu", "Peter Stone", "Roberto Mart\u00edn-Mart\u00edn"], "title": "SLAC: Simulation-Pretrained Latent Action Space for Whole-Body Real-World RL", "categories": ["cs.RO", "cs.AI", "cs.LG"], "comment": null, "summary": "Building capable household and industrial robots requires mastering the\ncontrol of versatile, high-degree-of-freedom (DoF) systems such as mobile\nmanipulators. While reinforcement learning (RL) holds promise for autonomously\nacquiring robot control policies, scaling it to high-DoF embodiments remains\nchallenging. Direct RL in the real world demands both safe exploration and high\nsample efficiency, which are difficult to achieve in practice. Sim-to-real RL,\non the other hand, is often brittle due to the reality gap. This paper\nintroduces SLAC, a method that renders real-world RL feasible for complex\nembodiments by leveraging a low-fidelity simulator to pretrain a task-agnostic\nlatent action space. SLAC trains this latent action space via a customized\nunsupervised skill discovery method designed to promote temporal abstraction,\ndisentanglement, and safety, thereby facilitating efficient downstream\nlearning. Once a latent action space is learned, SLAC uses it as the action\ninterface for a novel off-policy RL algorithm to autonomously learn downstream\ntasks through real-world interactions. We evaluate SLAC against existing\nmethods on a suite of bimanual mobile manipulation tasks, where it achieves\nstate-of-the-art performance. Notably, SLAC learns contact-rich whole-body\ntasks in under an hour of real-world interactions, without relying on any\ndemonstrations or hand-crafted behavior priors. More information, code, and\nvideos at robo-rl.github.io", "AI": {"tldr": "SLAC introduces a method for real-world RL by pretraining a task-agnostic latent action space using a low-fidelity simulator, enabling efficient learning of complex tasks.", "motivation": "Scaling RL to high-DoF systems like mobile manipulators is challenging due to safety and sample efficiency issues in real-world RL and brittleness in sim-to-real RL.", "method": "SLAC leverages a low-fidelity simulator to pretrain a latent action space via unsupervised skill discovery, then uses it for off-policy RL in real-world tasks.", "result": "SLAC achieves state-of-the-art performance on bimanual mobile manipulation tasks, learning contact-rich tasks in under an hour without demonstrations.", "conclusion": "SLAC demonstrates feasibility of real-world RL for complex embodiments by combining pretraining and efficient downstream learning."}}
{"id": "2506.04168", "pdf": "https://arxiv.org/pdf/2506.04168", "abs": "https://arxiv.org/abs/2506.04168", "authors": ["Seohong Park", "Kevin Frans", "Deepinder Mann", "Benjamin Eysenbach", "Aviral Kumar", "Sergey Levine"], "title": "Horizon Reduction Makes RL Scalable", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "In this work, we study the scalability of offline reinforcement learning (RL)\nalgorithms. In principle, a truly scalable offline RL algorithm should be able\nto solve any given problem, regardless of its complexity, given sufficient\ndata, compute, and model capacity. We investigate if and how current offline RL\nalgorithms match up to this promise on diverse, challenging, previously\nunsolved tasks, using datasets up to 1000x larger than typical offline RL\ndatasets. We observe that despite scaling up data, many existing offline RL\nalgorithms exhibit poor scaling behavior, saturating well below the maximum\nperformance. We hypothesize that the horizon is the main cause behind the poor\nscaling of offline RL. We empirically verify this hypothesis through several\nanalysis experiments, showing that long horizons indeed present a fundamental\nbarrier to scaling up offline RL. We then show that various horizon reduction\ntechniques substantially enhance scalability on challenging tasks. Based on our\ninsights, we also introduce a minimal yet scalable method named SHARSA that\neffectively reduces the horizon. SHARSA achieves the best asymptotic\nperformance and scaling behavior among our evaluation methods, showing that\nexplicitly reducing the horizon unlocks the scalability of offline RL. Code:\nhttps://github.com/seohongpark/horizon-reduction", "AI": {"tldr": "The paper investigates the scalability of offline RL algorithms, finding that many fail to scale well with large datasets due to long horizons. Horizon reduction techniques, including the proposed SHARSA method, significantly improve scalability.", "motivation": "To determine if current offline RL algorithms can scale effectively with large datasets and complex tasks, and to identify barriers to scalability.", "method": "Evaluates existing offline RL algorithms on large datasets, analyzes the impact of horizon length, and introduces SHARSA, a horizon reduction technique.", "result": "Long horizons hinder scalability; SHARSA outperforms other methods by effectively reducing horizon length.", "conclusion": "Horizon reduction is key to scalable offline RL, with SHARSA demonstrating superior performance."}}
{"id": "2506.04065", "pdf": "https://arxiv.org/pdf/2506.04065", "abs": "https://arxiv.org/abs/2506.04065", "authors": ["Muling Wu", "Qi Qian", "Wenhao Liu", "Xiaohua Wang", "Zisu Huang", "Di Liang", "LI Miao", "Shihan Dou", "Changze Lv", "Zhenghua Wang", "Zhibo Xu", "Lina Chen", "Tianlong Li", "Xiaoqing Zheng", "Xuanjing Huang"], "title": "Progressive Mastery: Customized Curriculum Learning with Guided Prompting for Mathematical Reasoning", "categories": ["cs.CL"], "comment": null, "summary": "Large Language Models (LLMs) have achieved remarkable performance across\nvarious reasoning tasks, yet post-training is constrained by inefficient sample\nutilization and inflexible difficulty samples processing. To address these\nlimitations, we propose Customized Curriculum Learning (CCL), a novel framework\nwith two key innovations. First, we introduce model-adaptive difficulty\ndefinition that customizes curriculum datasets based on each model's individual\ncapabilities rather than using predefined difficulty metrics. Second, we\ndevelop \"Guided Prompting,\" which dynamically reduces sample difficulty through\nstrategic hints, enabling effective utilization of challenging samples that\nwould otherwise degrade performance. Comprehensive experiments on supervised\nfine-tuning and reinforcement learning demonstrate that CCL significantly\noutperforms uniform training approaches across five mathematical reasoning\nbenchmarks, confirming its effectiveness across both paradigms in enhancing\nsample utilization and model performance.", "AI": {"tldr": "Customized Curriculum Learning (CCL) improves LLM training by adapting difficulty to model capabilities and using guided prompting for better sample utilization, outperforming uniform training on reasoning tasks.", "motivation": "Address inefficiencies in post-training LLMs due to rigid difficulty metrics and poor sample utilization.", "method": "Introduces model-adaptive difficulty definition and Guided Prompting to dynamically adjust sample difficulty.", "result": "CCL outperforms uniform training on five mathematical reasoning benchmarks.", "conclusion": "CCL enhances sample utilization and model performance in both supervised fine-tuning and reinforcement learning."}}
{"id": "2506.04054", "pdf": "https://arxiv.org/pdf/2506.04054", "abs": "https://arxiv.org/abs/2506.04054", "authors": ["Giyong Choi", "HyunWook Park"], "title": "Video Deblurring with Deconvolution and Aggregation Networks", "categories": ["cs.CV"], "comment": null, "summary": "In contrast to single-image deblurring, video deblurring has the advantage\nthat neighbor frames can be utilized to deblur a target frame. However,\nexisting video deblurring algorithms often fail to properly employ the neighbor\nframes, resulting in sub-optimal performance. In this paper, we propose a\ndeconvolution and aggregation network (DAN) for video deblurring that utilizes\nthe information of neighbor frames well. In DAN, both deconvolution and\naggregation strategies are achieved through three sub-networks: the\npreprocessing network (PPN) and the alignment-based deconvolution network\n(ABDN) for the deconvolution scheme; the frame aggregation network (FAN) for\nthe aggregation scheme. In the deconvolution part, blurry inputs are first\npreprocessed by the PPN with non-local operations. Then, the output frames from\nthe PPN are deblurred by the ABDN based on the frame alignment. In the FAN,\nthese deblurred frames from the deconvolution part are combined into a latent\nframe according to reliability maps which infer pixel-wise sharpness. The\nproper combination of three sub-networks can achieve favorable performance on\nvideo deblurring by using the neighbor frames suitably. In experiments, the\nproposed DAN was demonstrated to be superior to existing state-of-the-art\nmethods through both quantitative and qualitative evaluations on the public\ndatasets.", "AI": {"tldr": "Proposes a Deconvolution and Aggregation Network (DAN) for video deblurring, leveraging neighbor frames effectively through three sub-networks, outperforming existing methods.", "motivation": "Existing video deblurring methods underutilize neighbor frames, leading to sub-optimal performance.", "method": "DAN combines three sub-networks: Preprocessing Network (PPN), Alignment-Based Deconvolution Network (ABDN), and Frame Aggregation Network (FAN) to deblur and aggregate frames.", "result": "DAN achieves superior performance over state-of-the-art methods in quantitative and qualitative evaluations.", "conclusion": "DAN effectively utilizes neighbor frames for video deblurring, demonstrating significant improvements over existing approaches."}}
{"id": "2506.04171", "pdf": "https://arxiv.org/pdf/2506.04171", "abs": "https://arxiv.org/abs/2506.04171", "authors": ["Utkarsh Utkarsh", "Pengfei Cai", "Alan Edelman", "Rafael Gomez-Bombarelli", "Christopher Vincent Rackauckas"], "title": "Physics-Constrained Flow Matching: Sampling Generative Models with Hard Constraints", "categories": ["cs.LG", "cs.AI", "cs.CE", "cs.NA", "math.NA"], "comment": "27 pages, 9 figures, 4 tables", "summary": "Deep generative models have recently been applied to physical systems\ngoverned by partial differential equations (PDEs), offering scalable simulation\nand uncertainty-aware inference. However, enforcing physical constraints, such\nas conservation laws (linear and nonlinear) and physical consistencies, remains\nchallenging. Existing methods often rely on soft penalties or architectural\nbiases that fail to guarantee hard constraints. In this work, we propose\nPhysics-Constrained Flow Matching (PCFM), a zero-shot inference framework that\nenforces arbitrary nonlinear constraints in pretrained flow-based generative\nmodels. PCFM continuously guides the sampling process through physics-based\ncorrections applied to intermediate solution states, while remaining aligned\nwith the learned flow and satisfying physical constraints. Empirically, PCFM\noutperforms both unconstrained and constrained baselines on a range of PDEs,\nincluding those with shocks, discontinuities, and sharp features, while\nensuring exact constraint satisfaction at the final solution. Our method\nprovides a general framework for enforcing hard constraints in both scientific\nand general-purpose generative models, especially in applications where\nconstraint satisfaction is essential.", "AI": {"tldr": "PCFM enforces hard physical constraints in generative models for PDEs, outperforming baselines while ensuring exact constraint satisfaction.", "motivation": "Existing methods struggle to enforce hard physical constraints in generative models for PDEs, often relying on soft penalties or biases.", "method": "Proposes Physics-Constrained Flow Matching (PCFM), a zero-shot framework that applies physics-based corrections during sampling to ensure constraints.", "result": "PCFM outperforms unconstrained and constrained baselines on various PDEs, handling shocks and sharp features while satisfying constraints.", "conclusion": "PCFM provides a general framework for enforcing hard constraints in generative models, crucial for applications requiring exact constraint satisfaction."}}
{"id": "2506.04172", "pdf": "https://arxiv.org/pdf/2506.04172", "abs": "https://arxiv.org/abs/2506.04172", "authors": ["Shreenidhi Srinivasan", "Lydia Manikonda"], "title": "Does Prompt Design Impact Quality of Data Imputation by LLMs?", "categories": ["cs.LG", "cs.ET"], "comment": "7 pages", "summary": "Generating realistic synthetic tabular data presents a critical challenge in\nmachine learning. It adds another layer of complexity when this data contain\nclass imbalance problems. This paper presents a novel token-aware data\nimputation method that leverages the in-context learning capabilities of large\nlanguage models. This is achieved through the combination of a structured\ngroup-wise CSV-style prompting technique and the elimination of irrelevant\ncontextual information in the input prompt. We test this approach with two\nclass-imbalanced binary classification datasets and evaluate the effectiveness\nof imputation using classification-based evaluation metrics. The experimental\nresults demonstrate that our approach significantly reduces the input prompt\nsize while maintaining or improving imputation quality compared to our baseline\nprompt, especially for datasets that are of relatively smaller in size. The\ncontributions of this presented work is two-fold -- 1) it sheds light on the\nimportance of prompt design when leveraging LLMs for synthetic data generation\nand 2) it addresses a critical gap in LLM-based data imputation for\nclass-imbalanced datasets with missing data by providing a practical solution\nwithin computational constraints. We hope that our work will foster further\nresearch and discussions about leveraging the incredible potential of LLMs and\nprompt engineering techniques for synthetic data generation.", "AI": {"tldr": "A novel token-aware data imputation method using LLMs improves synthetic tabular data generation for class-imbalanced datasets by optimizing prompt design.", "motivation": "Addressing the challenge of generating realistic synthetic tabular data, especially with class imbalance, by leveraging LLMs' in-context learning.", "method": "Combines structured group-wise CSV-style prompting and removes irrelevant contextual information in prompts.", "result": "Reduces prompt size while maintaining/improvising imputation quality, particularly for smaller datasets.", "conclusion": "Highlights prompt design importance for LLM-based synthetic data generation and offers a practical solution for class-imbalanced datasets."}}
{"id": "2506.04072", "pdf": "https://arxiv.org/pdf/2506.04072", "abs": "https://arxiv.org/abs/2506.04072", "authors": ["Meiqing Jin", "Liam Dugan", "Chris Callison-Burch"], "title": "Controlling Difficulty of Generated Text for AI-Assisted Language Learning", "categories": ["cs.CL", "cs.HC", "I.2.7"], "comment": "Submitted to EMNLP 2025", "summary": "Practicing conversations with large language models (LLMs) presents a\npromising alternative to traditional in-person language learning. However, most\nLLMs generate text at a near-native level of complexity, making them ill-suited\nfor beginner learners (CEFR: A1-A2). In this paper, we investigate whether\ncontrollable generation techniques -- specifically modular methods that do not\nrequire model fine-tuning -- can adapt LLM outputs to better support absolute\nbeginners. We evaluate these methods through both automatic metrics and a user\nstudy with university-level learners of Japanese. Our findings show that while\nprompting alone fails to control output difficulty, the use of future\ndiscriminators (Yang and Klein, 2021) significantly improves output\ncomprehensibility (from 40.4\\% to 84.3\\%). We further introduce a novel\ntoken-level evaluation metric, Token Miss Rate (TMR), that quantifies the\nproportion of incomprehensible tokens per utterance and correlates strongly\nwith human judgments. To support future research in AI-assisted language\nlearning, we release our code, models, annotation tools, and dataset.", "AI": {"tldr": "Controllable generation techniques, like future discriminators, can adapt LLM outputs for beginner language learners, improving comprehensibility from 40.4% to 84.3%. A new metric, Token Miss Rate (TMR), is introduced to evaluate output difficulty.", "motivation": "LLMs generate text at near-native complexity, making them unsuitable for beginner learners (CEFR: A1-A2). The paper explores methods to adapt LLM outputs for absolute beginners without fine-tuning.", "method": "Modular controllable generation techniques, including future discriminators, are tested. Evaluation involves automatic metrics and a user study with Japanese learners.", "result": "Prompting alone fails, but future discriminators significantly improve comprehensibility (40.4% to 84.3%). TMR is introduced as a strong metric for evaluating output difficulty.", "conclusion": "Controllable generation techniques effectively adapt LLM outputs for beginners. The paper releases tools and data to support future AI-assisted language learning research."}}
{"id": "2506.04081", "pdf": "https://arxiv.org/pdf/2506.04081", "abs": "https://arxiv.org/abs/2506.04081", "authors": ["Abdelouahed Laazoufi", "Mohammed El Hassouni", "Hocine Cherifi"], "title": "Point Cloud Quality Assessment Using the Perceptual Clustering Weighted Graph (PCW-Graph) and Attention Fusion Network", "categories": ["cs.CV"], "comment": null, "summary": "No-Reference Point Cloud Quality Assessment (NR-PCQA) is critical for\nevaluating 3D content in real-world applications where reference models are\nunavailable.", "AI": {"tldr": "NR-PCQA is essential for assessing 3D content without reference models.", "motivation": "The need to evaluate 3D content in real-world scenarios where reference models are unavailable.", "method": "No-Reference Point Cloud Quality Assessment (NR-PCQA).", "result": "Not explicitly stated in the abstract.", "conclusion": "NR-PCQA is crucial for practical 3D content evaluation."}}
{"id": "2506.04195", "pdf": "https://arxiv.org/pdf/2506.04195", "abs": "https://arxiv.org/abs/2506.04195", "authors": ["Elena Zamaraeva", "Christopher M. Collins", "George R. Darling", "Matthew S. Dyer", "Bei Peng", "Rahul Savani", "Dmytro Antypov", "Vladimir V. Gusev", "Judith Clymo", "Paul G. Spirakis", "Matthew J. Rosseinsky"], "title": "MACS: Multi-Agent Reinforcement Learning for Optimization of Crystal Structures", "categories": ["cs.LG", "cs.AI", "68T05", "I.2.6; I.2.11"], "comment": null, "summary": "Geometry optimization of atomic structures is a common and crucial task in\ncomputational chemistry and materials design. Following the learning to\noptimize paradigm, we propose a new multi-agent reinforcement learning method\ncalled Multi-Agent Crystal Structure optimization (MACS) to address periodic\ncrystal structure optimization. MACS treats geometry optimization as a\npartially observable Markov game in which atoms are agents that adjust their\npositions to collectively discover a stable configuration. We train MACS across\nvarious compositions of reported crystalline materials to obtain a policy that\nsuccessfully optimizes structures from the training compositions as well as\nstructures of larger sizes and unseen compositions, confirming its excellent\nscalability and zero-shot transferability. We benchmark our approach against a\nbroad range of state-of-the-art optimization methods and demonstrate that MACS\noptimizes periodic crystal structures significantly faster, with fewer energy\ncalculations, and the lowest failure rate.", "AI": {"tldr": "MACS is a multi-agent reinforcement learning method for optimizing periodic crystal structures, outperforming state-of-the-art methods in speed, efficiency, and scalability.", "motivation": "Geometry optimization is critical in computational chemistry and materials design, but existing methods may lack efficiency or scalability.", "method": "MACS treats optimization as a partially observable Markov game, with atoms as agents adjusting positions to find stable configurations.", "result": "MACS optimizes structures faster, with fewer energy calculations and lower failure rates, and shows excellent scalability and zero-shot transferability.", "conclusion": "MACS is a highly effective and scalable solution for periodic crystal structure optimization."}}
{"id": "2506.04178", "pdf": "https://arxiv.org/pdf/2506.04178", "abs": "https://arxiv.org/abs/2506.04178", "authors": ["Etash Guha", "Ryan Marten", "Sedrick Keh", "Negin Raoof", "Georgios Smyrnis", "Hritik Bansal", "Marianna Nezhurina", "Jean Mercat", "Trung Vu", "Zayne Sprague", "Ashima Suvarna", "Benjamin Feuer", "Liangyu Chen", "Zaid Khan", "Eric Frankel", "Sachin Grover", "Caroline Choi", "Niklas Muennighoff", "Shiye Su", "Wanjia Zhao", "John Yang", "Shreyas Pimpalgaonkar", "Kartik Sharma", "Charlie Cheng-Jie Ji", "Yichuan Deng", "Sarah Pratt", "Vivek Ramanujan", "Jon Saad-Falcon", "Jeffrey Li", "Achal Dave", "Alon Albalak", "Kushal Arora", "Blake Wulfe", "Chinmay Hegde", "Greg Durrett", "Sewoong Oh", "Mohit Bansal", "Saadia Gabriel", "Aditya Grover", "Kai-Wei Chang", "Vaishaal Shankar", "Aaron Gokaslan", "Mike A. Merrill", "Tatsunori Hashimoto", "Yejin Choi", "Jenia Jitsev", "Reinhard Heckel", "Maheswaran Sathiamoorthy", "Alexandros G. Dimakis", "Ludwig Schmidt"], "title": "OpenThoughts: Data Recipes for Reasoning Models", "categories": ["cs.LG"], "comment": "https://www.openthoughts.ai/blog/ot3", "summary": "Reasoning models have made rapid progress on many benchmarks involving math,\ncode, and science. Yet, there are still many open questions about the best\ntraining recipes for reasoning since state-of-the-art models often rely on\nproprietary datasets with little to no public information available. To address\nthis, the goal of the OpenThoughts project is to create open-source datasets\nfor training reasoning models. After initial explorations, our OpenThoughts2-1M\ndataset led to OpenThinker2-32B, the first model trained on public reasoning\ndata to match DeepSeek-R1-Distill-32B on standard reasoning benchmarks such as\nAIME and LiveCodeBench. We then improve our dataset further by systematically\ninvestigating each step of our data generation pipeline with 1,000+ controlled\nexperiments, which led to OpenThoughts3. Scaling the pipeline to 1.2M examples\nand using QwQ-32B as teacher yields our OpenThinker3-7B model, which achieves\nstate-of-the-art results: 53% on AIME 2025, 51% on LiveCodeBench 06/24-01/25,\nand 54% on GPQA Diamond. All of our datasets and models are available on\nhttps://openthoughts.ai.", "AI": {"tldr": "OpenThoughts project creates open-source datasets for reasoning models, achieving state-of-the-art results with OpenThinker3-7B.", "motivation": "Address the lack of public information on training recipes for reasoning models by developing open-source datasets.", "method": "Systematically improve datasets through controlled experiments, scale data generation, and use QwQ-32B as a teacher model.", "result": "OpenThinker3-7B achieves 53% on AIME 2025, 51% on LiveCodeBench, and 54% on GPQA Diamond.", "conclusion": "Open-source datasets and models like OpenThoughts3 and OpenThinker3-7B can match or exceed proprietary solutions."}}
{"id": "2506.04108", "pdf": "https://arxiv.org/pdf/2506.04108", "abs": "https://arxiv.org/abs/2506.04108", "authors": ["Yutao Sun", "Tianzhu Ye", "Li Dong", "Yuqing Xia", "Jian Chen", "Yizhao Gao", "Shijie Cao", "Jianyong Wang", "Furu Wei"], "title": "Rectified Sparse Attention", "categories": ["cs.CL"], "comment": null, "summary": "Efficient long-sequence generation is a critical challenge for Large Language\nModels. While recent sparse decoding methods improve efficiency, they suffer\nfrom KV cache misalignment, where approximation errors accumulate and degrade\ngeneration quality. In this work, we propose Rectified Sparse Attention (ReSA),\na simple yet effective method that combines block-sparse attention with\nperiodic dense rectification. By refreshing the KV cache at fixed intervals\nusing a dense forward pass, ReSA bounds error accumulation and preserves\nalignment with the pretraining distribution. Experiments across math reasoning,\nlanguage modeling, and retrieval tasks demonstrate that ReSA achieves\nnear-lossless generation quality with significantly improved efficiency.\nNotably, ReSA delivers up to 2.42$\\times$ end-to-end speedup under decoding at\n256K sequence length, making it a practical solution for scalable long-context\ninference. Code is available at https://aka.ms/ReSA-LM.", "AI": {"tldr": "ReSA combines block-sparse attention with periodic dense rectification to improve long-sequence generation efficiency while maintaining quality.", "motivation": "Addressing KV cache misalignment in sparse decoding methods, which degrades generation quality.", "method": "Proposes Rectified Sparse Attention (ReSA), blending block-sparse attention with periodic dense rectification to refresh the KV cache.", "result": "Achieves near-lossless quality with up to 2.42\u00d7 speedup at 256K sequence length.", "conclusion": "ReSA is a practical solution for efficient long-context inference."}}
{"id": "2506.04106", "pdf": "https://arxiv.org/pdf/2506.04106", "abs": "https://arxiv.org/abs/2506.04106", "authors": ["Xiao Xiang Zhu", "Sining Chen", "Fahong Zhang", "Yilei Shi", "Yuanyuan Wang"], "title": "GlobalBuildingAtlas: An Open Global and Complete Dataset of Building Polygons, Heights and LoD1 3D Models", "categories": ["cs.CV"], "comment": null, "summary": "We introduce GlobalBuildingAtlas, a publicly available dataset providing\nglobal and complete coverage of building polygons, heights and Level of Detail\n1 (LoD1) 3D building models. This is the first open dataset to offer high\nquality, consistent, and complete building data in 2D and 3D form at the\nindividual building level on a global scale. Towards this dataset, we developed\nmachine learning-based pipelines to derive building polygons and heights\n(called GBA.Height) from global PlanetScope satellite data, respectively. Also\na quality-based fusion strategy was employed to generate higher-quality\npolygons (called GBA.Polygon) based on existing open building polygons,\nincluding our own derived one. With more than 2.75 billion buildings worldwide,\nGBA.Polygon surpasses the most comprehensive database to date by more than 1\nbillion buildings. GBA.Height offers the most detailed and accurate global 3D\nbuilding height maps to date, achieving a spatial resolution of 3x3 meters-30\ntimes finer than previous global products (90 m), enabling a high-resolution\nand reliable analysis of building volumes at both local and global scales.\nFinally, we generated a global LoD1 building model (called GBA.LoD1) from the\nresulting GBA.Polygon and GBA.Height. GBA.LoD1 represents the first complete\nglobal LoD1 building models, including 2.68 billion building instances with\npredicted heights, i.e., with a height completeness of more than 97%, achieving\nRMSEs ranging from 1.5 m to 8.9 m across different continents. With its height\naccuracy, comprehensive global coverage and rich spatial details,\nGlobalBuildingAltas offers novel insights on the status quo of global\nbuildings, which unlocks unprecedented geospatial analysis possibilities, as\nshowcased by a better illustration of where people live and a more\ncomprehensive monitoring of the progress on the 11th Sustainable Development\nGoal of the United Nations.", "AI": {"tldr": "GlobalBuildingAtlas is the first open dataset offering high-quality, consistent, and complete 2D and 3D building data globally, with over 2.75 billion buildings, surpassing existing databases.", "motivation": "To provide a comprehensive, high-resolution global dataset of building polygons, heights, and 3D models for geospatial analysis and sustainable development monitoring.", "method": "Developed machine learning pipelines to derive building polygons and heights from satellite data, and used a quality-based fusion strategy to enhance polygon quality.", "result": "Produced GBA.Polygon (2.75B buildings), GBA.Height (3x3m resolution), and GBA.LoD1 (2.68B buildings with 97% height completeness and RMSEs of 1.5-8.9m).", "conclusion": "GlobalBuildingAtlas enables unprecedented geospatial analysis, supporting applications like population mapping and monitoring UN Sustainable Development Goals."}}
{"id": "2506.04202", "pdf": "https://arxiv.org/pdf/2506.04202", "abs": "https://arxiv.org/abs/2506.04202", "authors": ["Yanting Wang", "Wei Zou", "Runpeng Geng", "Jinyuan Jia"], "title": "TracLLM: A Generic Framework for Attributing Long Context LLMs", "categories": ["cs.CR", "cs.AI", "cs.LG"], "comment": "To appear in USENIX Security Symposium 2025. The code and data are\n  at: https://github.com/Wang-Yanting/TracLLM", "summary": "Long context large language models (LLMs) are deployed in many real-world\napplications such as RAG, agent, and broad LLM-integrated applications. Given\nan instruction and a long context (e.g., documents, PDF files, webpages), a\nlong context LLM can generate an output grounded in the provided context,\naiming to provide more accurate, up-to-date, and verifiable outputs while\nreducing hallucinations and unsupported claims. This raises a research\nquestion: how to pinpoint the texts (e.g., sentences, passages, or paragraphs)\nin the context that contribute most to or are responsible for the generated\noutput by an LLM? This process, which we call context traceback, has various\nreal-world applications, such as 1) debugging LLM-based systems, 2) conducting\npost-attack forensic analysis for attacks (e.g., prompt injection attack,\nknowledge corruption attacks) to an LLM, and 3) highlighting knowledge sources\nto enhance the trust of users towards outputs generated by LLMs. When applied\nto context traceback for long context LLMs, existing feature attribution\nmethods such as Shapley have sub-optimal performance and/or incur a large\ncomputational cost. In this work, we develop TracLLM, the first generic context\ntraceback framework tailored to long context LLMs. Our framework can improve\nthe effectiveness and efficiency of existing feature attribution methods. To\nimprove the efficiency, we develop an informed search based algorithm in\nTracLLM. We also develop contribution score ensemble/denoising techniques to\nimprove the accuracy of TracLLM. Our evaluation results show TracLLM can\neffectively identify texts in a long context that lead to the output of an LLM.\nOur code and data are at: https://github.com/Wang-Yanting/TracLLM.", "AI": {"tldr": "TracLLM is a framework for context traceback in long-context LLMs, improving efficiency and accuracy of identifying text contributions to outputs.", "motivation": "To address the challenge of pinpointing text in long contexts responsible for LLM outputs, aiding debugging, forensic analysis, and user trust.", "method": "Develops TracLLM with informed search algorithms and contribution score ensemble/denoising techniques.", "result": "Effectively identifies contributing texts in long contexts.", "conclusion": "TracLLM enhances traceback for long-context LLMs, with practical applications in debugging and trust-building."}}
{"id": "2506.04190", "pdf": "https://arxiv.org/pdf/2506.04190", "abs": "https://arxiv.org/abs/2506.04190", "authors": ["Yuxuan Cao", "Jiarong Xu", "Chen Zhao", "Jiaan Wang", "Carl Yang", "Chunping Wang", "Yang Yang"], "title": "How to Use Graph Data in the Wild to Help Graph Anomaly Detection?", "categories": ["cs.LG"], "comment": "Accepted by SIGKDD2025", "summary": "In recent years, graph anomaly detection has found extensive applications in\nvarious domains such as social, financial, and communication networks. However,\nanomalies in graph-structured data present unique challenges, including label\nscarcity, ill-defined anomalies, and varying anomaly types, making supervised\nor semi-supervised methods unreliable. Researchers often adopt unsupervised\napproaches to address these challenges, assuming that anomalies deviate\nsignificantly from the normal data distribution. Yet, when the available data\nis insufficient, capturing the normal distribution accurately and\ncomprehensively becomes difficult. To overcome this limitation, we propose to\nutilize external graph data (i.e., graph data in the wild) to help anomaly\ndetection tasks. This naturally raises the question: How can we use external\ndata to help graph anomaly detection tasks? To answer this question, we propose\na framework called Wild-GAD. It is built upon a unified database, UniWildGraph,\nwhich comprises a large and diverse collection of graph data with broad domain\ncoverage, ample data volume, and a unified feature space. Further, we develop\nselection criteria based on representativity and diversity to identify the most\nsuitable external data for anomaly detection task. Extensive experiments on six\nreal-world datasets demonstrate the effectiveness of Wild-GAD. Compared to the\nbaseline methods, our framework has an average 18% AUCROC and 32% AUCPR\nimprovement over the best-competing methods.", "AI": {"tldr": "The paper proposes Wild-GAD, a framework leveraging external graph data to improve unsupervised graph anomaly detection, addressing challenges like label scarcity and data insufficiency.", "motivation": "Graph anomaly detection faces issues like label scarcity and ill-defined anomalies, making supervised methods unreliable. Unsupervised methods struggle with insufficient data for capturing normal distributions.", "method": "Wild-GAD uses external graph data (UniWildGraph) and selection criteria based on representativity and diversity to enhance anomaly detection.", "result": "Experiments show Wild-GAD outperforms baselines with 18% AUCROC and 32% AUCPR improvements.", "conclusion": "Utilizing external data via Wild-GAD effectively addresses data insufficiency in graph anomaly detection, demonstrating significant performance gains."}}
{"id": "2506.04139", "pdf": "https://arxiv.org/pdf/2506.04139", "abs": "https://arxiv.org/abs/2506.04139", "authors": ["Ratna Kandala", "Katie Hoemann"], "title": "Are Lexicon-Based Tools Still the Gold Standard for Valence Analysis in Low-Resource Flemish?", "categories": ["cs.CL"], "comment": null, "summary": "Understanding the nuances in everyday language is pivotal for advancements in\ncomputational linguistics & emotions research. Traditional lexicon-based tools\nsuch as LIWC and Pattern have long served as foundational instruments in this\ndomain. LIWC is the most extensively validated word count based text analysis\ntool in the social sciences and Pattern is an open source Python library\noffering functionalities for NLP. However, everyday language is inherently\nspontaneous, richly expressive, & deeply context dependent. To explore the\ncapabilities of LLMs in capturing the valences of daily narratives in Flemish,\nwe first conducted a study involving approximately 25,000 textual responses\nfrom 102 Dutch-speaking participants. Each participant provided narratives\nprompted by the question, \"What is happening right now and how do you feel\nabout it?\", accompanied by self-assessed valence ratings on a continuous scale\nfrom -50 to +50. We then assessed the performance of three Dutch-specific LLMs\nin predicting these valence scores, and compared their outputs to those\ngenerated by LIWC and Pattern. Our findings indicate that, despite advancements\nin LLM architectures, these Dutch tuned models currently fall short in\naccurately capturing the emotional valence present in spontaneous, real-world\nnarratives. This study underscores the imperative for developing culturally and\nlinguistically tailored models/tools that can adeptly handle the complexities\nof natural language use. Enhancing automated valence analysis is not only\npivotal for advancing computational methodologies but also holds significant\npromise for psychological research with ecologically valid insights into human\ndaily experiences. We advocate for increased efforts in creating comprehensive\ndatasets & finetuning LLMs for low-resource languages like Flemish, aiming to\nbridge the gap between computational linguistics & emotion research.", "AI": {"tldr": "The study evaluates Dutch-specific LLMs for predicting emotional valence in Flemish narratives, finding them less accurate than traditional tools like LIWC and Pattern. It highlights the need for culturally tailored models.", "motivation": "To explore LLMs' capabilities in capturing emotional valence in spontaneous, context-dependent Flemish narratives, advancing computational linguistics and emotion research.", "method": "Analyzed 25,000 textual responses from 102 Dutch-speaking participants, comparing Dutch LLMs' valence predictions to LIWC and Pattern.", "result": "Dutch-tuned LLMs underperform in accurately predicting emotional valence compared to traditional tools, emphasizing the need for better culturally tailored models.", "conclusion": "Advocates for developing comprehensive datasets and fine-tuning LLMs for low-resource languages like Flemish to improve valence analysis and bridge gaps in computational linguistics and emotion research."}}
{"id": "2506.04115", "pdf": "https://arxiv.org/pdf/2506.04115", "abs": "https://arxiv.org/abs/2506.04115", "authors": ["Robin Bruneau", "Baptiste Brument", "Yvain Qu\u00e9au", "Jean M\u00e9lou", "Fran\u00e7ois Bernard Lauze", "Jean-Denis Durou", "Lilian Calvet"], "title": "Multi-view Surface Reconstruction Using Normal and Reflectance Cues", "categories": ["cs.CV"], "comment": "22 pages, 15 figures, 11 tables. A thorough qualitative and\n  quantitive study is available in the supplementary material at\n  https://drive.google.com/file/d/1KDfCKediXNP5Os954TL_QldaUWS0nKcD/view?usp=drive_link", "summary": "Achieving high-fidelity 3D surface reconstruction while preserving fine\ndetails remains challenging, especially in the presence of materials with\ncomplex reflectance properties and without a dense-view setup. In this paper,\nwe introduce a versatile framework that incorporates multi-view normal and\noptionally reflectance maps into radiance-based surface reconstruction. Our\napproach employs a pixel-wise joint re-parametrization of reflectance and\nsurface normals, representing them as a vector of radiances under simulated,\nvarying illumination. This formulation enables seamless incorporation into\nstandard surface reconstruction pipelines, such as traditional multi-view\nstereo (MVS) frameworks or modern neural volume rendering (NVR) ones. Combined\nwith the latter, our approach achieves state-of-the-art performance on\nmulti-view photometric stereo (MVPS) benchmark datasets, including DiLiGenT-MV,\nLUCES-MV and Skoltech3D. In particular, our method excels in reconstructing\nfine-grained details and handling challenging visibility conditions. The\npresent paper is an extended version of the earlier conference paper by Brument\net al. (in Proceedings of the IEEE/CVF Conference on Computer Vision and\nPattern Recognition (CVPR), 2024), featuring an accelerated and more robust\nalgorithm as well as a broader empirical evaluation. The code and data relative\nto this article is available at https://github.com/RobinBruneau/RNb-NeuS2.", "AI": {"tldr": "A framework for high-fidelity 3D surface reconstruction using multi-view normal and reflectance maps, achieving state-of-the-art results on benchmark datasets.", "motivation": "Challenges in preserving fine details in 3D reconstruction, especially with complex reflectance properties and sparse views.", "method": "Pixel-wise joint re-parametrization of reflectance and surface normals as radiances under varying illumination, compatible with MVS and NVR pipelines.", "result": "State-of-the-art performance on MVPS benchmarks (DiLiGenT-MV, LUCES-MV, Skoltech3D), excelling in fine detail reconstruction and visibility handling.", "conclusion": "The method improves upon prior work with a more robust algorithm and broader evaluation, offering versatile and high-quality 3D reconstruction."}}
{"id": "2506.04207", "pdf": "https://arxiv.org/pdf/2506.04207", "abs": "https://arxiv.org/abs/2506.04207", "authors": ["Shuang Chen", "Yue Guo", "Zhaochen Su", "Yafu Li", "Yulun Wu", "Jiacheng Chen", "Jiayu Chen", "Weijie Wang", "Xiaoye Qu", "Yu Cheng"], "title": "Advancing Multimodal Reasoning: From Optimized Cold Start to Staged Reinforcement Learning", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.CV"], "comment": "19 pages, 6 figures", "summary": "Inspired by the remarkable reasoning capabilities of Deepseek-R1 in complex\ntextual tasks, many works attempt to incentivize similar capabilities in\nMultimodal Large Language Models (MLLMs) by directly applying reinforcement\nlearning (RL). However, they still struggle to activate complex reasoning. In\nthis paper, rather than examining multimodal RL in isolation, we delve into\ncurrent training pipelines and identify three crucial phenomena: 1) Effective\ncold start initialization is critical for enhancing MLLM reasoning.\nIntriguingly, we find that initializing with carefully selected text data alone\ncan lead to performance surpassing many recent multimodal reasoning models,\neven before multimodal RL. 2) Standard GRPO applied to multimodal RL suffers\nfrom gradient stagnation, which degrades training stability and performance. 3)\nSubsequent text-only RL training, following the multimodal RL phase, further\nenhances multimodal reasoning. This staged training approach effectively\nbalances perceptual grounding and cognitive reasoning development. By\nincorporating the above insights and addressing multimodal RL issues, we\nintroduce ReVisual-R1, achieving a new state-of-the-art among open-source 7B\nMLLMs on challenging benchmarks including MathVerse, MathVision, WeMath,\nLogicVista, DynaMath, and challenging AIME2024 and AIME2025.", "AI": {"tldr": "ReVisual-R1 improves multimodal reasoning in MLLMs by addressing training pipeline issues, including cold start initialization, gradient stagnation, and staged RL training, achieving SOTA results.", "motivation": "To enhance reasoning in Multimodal Large Language Models (MLLMs) by addressing limitations in current reinforcement learning (RL) approaches.", "method": "Identifies three key training phenomena, proposes solutions (cold start initialization, addressing gradient stagnation, staged RL training), and introduces ReVisual-R1.", "result": "ReVisual-R1 achieves state-of-the-art performance on multiple benchmarks (MathVerse, MathVision, etc.).", "conclusion": "Staged training and addressing RL issues significantly improve multimodal reasoning, setting a new benchmark for 7B MLLMs."}}
{"id": "2506.04205", "pdf": "https://arxiv.org/pdf/2506.04205", "abs": "https://arxiv.org/abs/2506.04205", "authors": ["Jinghan Jia", "Hadi Reisizadeh", "Chongyu Fan", "Nathalie Baracaldo", "Mingyi Hong", "Sijia Liu"], "title": "EPiC: Towards Lossless Speedup for Reasoning Training through Edge-Preserving CoT Condensation", "categories": ["cs.LG"], "comment": null, "summary": "Large language models (LLMs) have shown remarkable reasoning capabilities\nwhen trained with chain-of-thought (CoT) supervision. However, the long and\nverbose CoT traces, especially those distilled from large reasoning models\n(LRMs) such as DeepSeek-R1, significantly increase training costs during the\ndistillation process, where a non-reasoning base model is taught to replicate\nthe reasoning behavior of an LRM. In this work, we study the problem of CoT\ncondensation for resource-efficient reasoning training, aimed at pruning\nintermediate reasoning steps (i.e., thoughts) in CoT traces, enabling\nsupervised model training on length-reduced CoT data while preserving both\nanswer accuracy and the model's ability to generate coherent reasoning. Our\nrationale is that CoT traces typically follow a three-stage structure: problem\nunderstanding, exploration, and solution convergence. Through empirical\nanalysis, we find that retaining the structure of the reasoning trace,\nespecially the early stage of problem understanding (rich in reflective cues)\nand the final stage of solution convergence, is sufficient to achieve lossless\nreasoning supervision. To this end, we propose an Edge-Preserving Condensation\nmethod, EPiC, which selectively retains only the initial and final segments of\neach CoT trace while discarding the middle portion. This design draws an\nanalogy to preserving the \"edge\" of a reasoning trajectory, capturing both the\ninitial problem framing and the final answer synthesis, to maintain logical\ncontinuity. Experiments across multiple model families (Qwen and LLaMA) and\nbenchmarks show that EPiC reduces training time by over 34% while achieving\nlossless reasoning accuracy on MATH500, comparable to full CoT supervision. To\nthe best of our knowledge, this is the first study to explore thought-level CoT\ncondensation for efficient reasoning model distillation.", "AI": {"tldr": "EPiC condenses CoT traces by retaining only initial and final segments, reducing training time by 34% without losing accuracy.", "motivation": "High training costs from verbose CoT traces in LLMs, especially when distilled from LRMs, necessitate efficient condensation methods.", "method": "Proposes Edge-Preserving Condensation (EPiC), which prunes intermediate reasoning steps, keeping only problem understanding and solution convergence stages.", "result": "EPiC reduces training time by 34% while maintaining reasoning accuracy comparable to full CoT supervision on MATH500.", "conclusion": "EPiC offers a resource-efficient method for CoT condensation, preserving reasoning quality and reducing costs."}}
{"id": "2506.04142", "pdf": "https://arxiv.org/pdf/2506.04142", "abs": "https://arxiv.org/abs/2506.04142", "authors": ["Kejian Zhu", "Shangqing Tu", "Zhuoran Jin", "Lei Hou", "Juanzi Li", "Jun Zhao"], "title": "Establishing Trustworthy LLM Evaluation via Shortcut Neuron Analysis", "categories": ["cs.CL"], "comment": "Accepted to ACL 2025 Main Conference", "summary": "The development of large language models (LLMs) depends on trustworthy\nevaluation. However, most current evaluations rely on public benchmarks, which\nare prone to data contamination issues that significantly compromise fairness.\nPrevious researches have focused on constructing dynamic benchmarks to address\ncontamination. However, continuously building new benchmarks is costly and\ncyclical. In this work, we aim to tackle contamination by analyzing the\nmechanisms of contaminated models themselves. Through our experiments, we\ndiscover that the overestimation of contaminated models is likely due to\nparameters acquiring shortcut solutions in training. We further propose a novel\nmethod for identifying shortcut neurons through comparative and causal\nanalysis. Building on this, we introduce an evaluation method called shortcut\nneuron patching to suppress shortcut neurons. Experiments validate the\neffectiveness of our approach in mitigating contamination. Additionally, our\nevaluation results exhibit a strong linear correlation with MixEval, a recently\nreleased trustworthy benchmark, achieving a Spearman coefficient ($\\rho$)\nexceeding 0.95. This high correlation indicates that our method closely reveals\ntrue capabilities of the models and is trustworthy. We conduct further\nexperiments to demonstrate the generalizability of our method across various\nbenchmarks and hyperparameter settings. Code:\nhttps://github.com/GaryStack/Trustworthy-Evaluation", "AI": {"tldr": "The paper addresses data contamination in LLM evaluations by analyzing contaminated models, identifying shortcut neurons, and proposing a patching method to mitigate contamination, validated by strong correlation with a trustworthy benchmark.", "motivation": "Current LLM evaluations rely on public benchmarks prone to data contamination, compromising fairness. Building new benchmarks is costly, so the authors aim to tackle contamination by analyzing the models themselves.", "method": "The authors identify shortcut neurons through comparative and causal analysis and propose shortcut neuron patching to suppress them.", "result": "Experiments show the method effectively mitigates contamination, with evaluation results strongly correlating (Spearman \u03c1 > 0.95) with MixEval, a trustworthy benchmark.", "conclusion": "The proposed method reliably reveals true model capabilities and generalizes across benchmarks and hyperparameter settings, offering a trustworthy evaluation approach."}}
{"id": "2506.04122", "pdf": "https://arxiv.org/pdf/2506.04122", "abs": "https://arxiv.org/abs/2506.04122", "authors": ["Sharang Kaul", "Mario Berk", "Thiemo Gerbich", "Abhinav Valada"], "title": "Contour Errors: An Ego-Centric Metric for Reliable 3D Multi-Object Tracking", "categories": ["cs.CV"], "comment": null, "summary": "Finding reliable matches is essential in multi-object tracking to ensure the\naccuracy and reliability of perception systems in safety-critical applications\nsuch as autonomous vehicles. Effective matching mitigates perception errors,\nenhancing object identification and tracking for improved performance and\nsafety. However, traditional metrics such as Intersection over Union (IoU) and\nCenter Point Distances (CPDs), which are effective in 2D image planes, often\nfail to find critical matches in complex 3D scenes. To address this limitation,\nwe introduce Contour Errors (CEs), an ego or object-centric metric for\nidentifying matches of interest in tracking scenarios from a functional\nperspective. By comparing bounding boxes in the ego vehicle's frame, contour\nerrors provide a more functionally relevant assessment of object matches.\nExtensive experiments on the nuScenes dataset demonstrate that contour errors\nimprove the reliability of matches over the state-of-the-art 2D IoU and CPD\nmetrics in tracking-by-detection methods. In 3D car tracking, our results show\nthat Contour Errors reduce functional failures (FPs/FNs) by 80% at close ranges\nand 60% at far ranges compared to IoU in the evaluation stage.", "AI": {"tldr": "Contour Errors (CEs) improve match reliability in 3D tracking, reducing functional failures by 80% at close ranges and 60% at far ranges compared to traditional metrics like IoU.", "motivation": "Traditional 2D metrics like IoU and CPD fail in complex 3D scenes, necessitating a more functionally relevant metric for accurate object tracking in safety-critical applications.", "method": "Introduces Contour Errors (CEs), an ego-centric metric comparing bounding boxes in the ego vehicle's frame for better match identification.", "result": "CEs outperform IoU and CPD, reducing functional failures (FPs/FNs) by 80% at close ranges and 60% at far ranges in 3D car tracking.", "conclusion": "CEs provide a more reliable and functionally relevant metric for 3D multi-object tracking, enhancing performance and safety in applications like autonomous vehicles."}}
{"id": "2506.04217", "pdf": "https://arxiv.org/pdf/2506.04217", "abs": "https://arxiv.org/abs/2506.04217", "authors": ["Junting Chen", "Haotian Liang", "Lingxiao Du", "Weiyun Wang", "Mengkang Hu", "Yao Mu", "Wenhai Wang", "Jifeng Dai", "Ping Luo", "Wenqi Shao", "Lin Shao"], "title": "OWMM-Agent: Open World Mobile Manipulation With Multi-modal Agentic Data Synthesis", "categories": ["cs.RO", "cs.AI", "I.2.4; I.2.9; I.2.10"], "comment": "9 pages of main content, 19 pages in total", "summary": "The rapid progress of navigation, manipulation, and vision models has made\nmobile manipulators capable in many specialized tasks. However, the open-world\nmobile manipulation (OWMM) task remains a challenge due to the need for\ngeneralization to open-ended instructions and environments, as well as the\nsystematic complexity to integrate high-level decision making with low-level\nrobot control based on both global scene understanding and current agent state.\nTo address this complexity, we propose a novel multi-modal agent architecture\nthat maintains multi-view scene frames and agent states for decision-making and\ncontrols the robot by function calling. A second challenge is the hallucination\nfrom domain shift. To enhance the agent performance, we further introduce an\nagentic data synthesis pipeline for the OWMM task to adapt the VLM model to our\ntask domain with instruction fine-tuning. We highlight our fine-tuned OWMM-VLM\nas the first dedicated foundation model for mobile manipulators with global\nscene understanding, robot state tracking, and multi-modal action generation in\na unified model. Through experiments, we demonstrate that our model achieves\nSOTA performance compared to other foundation models including GPT-4o and\nstrong zero-shot generalization in real world. The project page is at\nhttps://github.com/HHYHRHY/OWMM-Agent", "AI": {"tldr": "A novel multi-modal agent architecture is proposed for open-world mobile manipulation (OWMM), addressing challenges like generalization and domain shift, achieving state-of-the-art performance.", "motivation": "The complexity of integrating high-level decision-making with low-level robot control in open-ended environments motivates the development of a dedicated foundation model for mobile manipulators.", "method": "The approach includes a multi-modal agent architecture with multi-view scene frames and agent states, function calling for robot control, and an agentic data synthesis pipeline for fine-tuning a VLM model.", "result": "The fine-tuned OWMM-VLM model achieves SOTA performance, outperforming models like GPT-4o, and demonstrates strong zero-shot generalization in real-world scenarios.", "conclusion": "The proposed OWMM-VLM model successfully addresses the challenges of OWMM, offering a unified solution for global scene understanding, state tracking, and multi-modal action generation."}}
{"id": "2506.04206", "pdf": "https://arxiv.org/pdf/2506.04206", "abs": "https://arxiv.org/abs/2506.04206", "authors": ["Reza Ramezanpour", "Victor M. Tenorio", "Antonio G. Marques", "Ashutosh Sabharwal", "Santiago Segarra"], "title": "A Few Moments Please: Scalable Graphon Learning via Moment Matching", "categories": ["cs.LG"], "comment": null, "summary": "Graphons, as limit objects of dense graph sequences, play a central role in\nthe statistical analysis of network data. However, existing graphon estimation\nmethods often struggle with scalability to large networks and\nresolution-independent approximation, due to their reliance on estimating\nlatent variables or costly metrics such as the Gromov-Wasserstein distance. In\nthis work, we propose a novel, scalable graphon estimator that directly\nrecovers the graphon via moment matching, leveraging implicit neural\nrepresentations (INRs). Our approach avoids latent variable modeling by\ntraining an INR--mapping coordinates to graphon values--to match empirical\nsubgraph counts (i.e., moments) from observed graphs. This direct estimation\nmechanism yields a polynomial-time solution and crucially sidesteps the\ncombinatorial complexity of Gromov-Wasserstein optimization. Building on\nfoundational results, we establish a theoretical guarantee: when the observed\nsubgraph motifs sufficiently represent those of the true graphon (a condition\nmet with sufficiently large or numerous graph samples), the estimated graphon\nachieves a provable upper bound in cut distance from the ground truth.\nAdditionally, we introduce MomentMixup, a data augmentation technique that\nperforms mixup in the moment space to enhance graphon-based learning. Our\ngraphon estimation method achieves strong empirical performance--demonstrating\nhigh accuracy on small graphs and superior computational efficiency on large\ngraphs--outperforming state-of-the-art scalable estimators in 75\\% of benchmark\nsettings and matching them in the remaining cases. Furthermore, MomentMixup\ndemonstrated improved graph classification accuracy on the majority of our\nbenchmarks.", "AI": {"tldr": "A scalable graphon estimator using implicit neural representations (INRs) and moment matching, avoiding latent variables and Gromov-Wasserstein distance, with theoretical guarantees and improved performance.", "motivation": "Existing graphon estimation methods face scalability and resolution issues due to reliance on latent variables or costly metrics like Gromov-Wasserstein distance.", "method": "Proposes a direct graphon recovery via moment matching using INRs, avoiding latent variables and combinatorial complexity. Introduces MomentMixup for data augmentation.", "result": "Achieves high accuracy on small graphs and superior efficiency on large ones, outperforming state-of-the-art in 75% of benchmarks. MomentMixup improves graph classification.", "conclusion": "The method offers a scalable, efficient, and accurate solution for graphon estimation, with theoretical guarantees and practical benefits."}}
{"id": "2506.04156", "pdf": "https://arxiv.org/pdf/2506.04156", "abs": "https://arxiv.org/abs/2506.04156", "authors": ["Sarvesh Soni", "Dina Demner-Fushman"], "title": "A Dataset for Addressing Patient's Information Needs related to Clinical Course of Hospitalization", "categories": ["cs.CL"], "comment": null, "summary": "Patients have distinct information needs about their hospitalization that can\nbe addressed using clinical evidence from electronic health records (EHRs).\nWhile artificial intelligence (AI) systems show promise in meeting these needs,\nrobust datasets are needed to evaluate the factual accuracy and relevance of\nAI-generated responses. To our knowledge, no existing dataset captures patient\ninformation needs in the context of their EHRs. We introduce ArchEHR-QA, an\nexpert-annotated dataset based on real-world patient cases from intensive care\nunit and emergency department settings. The cases comprise questions posed by\npatients to public health forums, clinician-interpreted counterparts, relevant\nclinical note excerpts with sentence-level relevance annotations, and\nclinician-authored answers. To establish benchmarks for grounded EHR question\nanswering (QA), we evaluated three open-weight large language models\n(LLMs)--Llama 4, Llama 3, and Mixtral--across three prompting strategies:\ngenerating (1) answers with citations to clinical note sentences, (2) answers\nbefore citations, and (3) answers from filtered citations. We assessed\nperformance on two dimensions: Factuality (overlap between cited note sentences\nand ground truth) and Relevance (textual and semantic similarity between system\nand reference answers). The final dataset contains 134 patient cases. The\nanswer-first prompting approach consistently performed best, with Llama 4\nachieving the highest scores. Manual error analysis supported these findings\nand revealed common issues such as omitted key clinical evidence and\ncontradictory or hallucinated content. Overall, ArchEHR-QA provides a strong\nbenchmark for developing and evaluating patient-centered EHR QA systems,\nunderscoring the need for further progress toward generating factual and\nrelevant responses in clinical contexts.", "AI": {"tldr": "ArchEHR-QA is a new expert-annotated dataset for evaluating AI-generated responses to patient questions about EHRs, with benchmarks for LLMs showing answer-first prompting works best.", "motivation": "Addressing patient information needs from EHRs requires robust datasets to evaluate AI systems, which are currently lacking.", "method": "Created ArchEHR-QA using real-world ICU/ED cases, annotated questions, clinical notes, and answers. Evaluated three LLMs with three prompting strategies.", "result": "Answer-first prompting performed best, with Llama 4 scoring highest. Common issues included omitted evidence and hallucinations.", "conclusion": "ArchEHR-QA provides a benchmark for patient-centered EHR QA, highlighting the need for improved factual and relevant AI responses."}}
{"id": "2506.04141", "pdf": "https://arxiv.org/pdf/2506.04141", "abs": "https://arxiv.org/abs/2506.04141", "authors": ["Kejian Zhu", "Zhuoran Jin", "Hongbang Yuan", "Jiachun Li", "Shangqing Tu", "Pengfei Cao", "Yubo Chen", "Kang Liu", "Jun Zhao"], "title": "MMR-V: What's Left Unsaid? A Benchmark for Multimodal Deep Reasoning in Videos", "categories": ["cs.CV", "cs.CL"], "comment": "Project Page: https://mmr-v.github.io", "summary": "The sequential structure of videos poses a challenge to the ability of\nmultimodal large language models (MLLMs) to locate multi-frame evidence and\nconduct multimodal reasoning. However, existing video benchmarks mainly focus\non understanding tasks, which only require models to match frames mentioned in\nthe question (hereafter referred to as \"question frame\") and perceive a few\nadjacent frames. To address this gap, we propose MMR-V: A Benchmark for\nMultimodal Deep Reasoning in Videos. The benchmark is characterized by the\nfollowing features. (1) Long-range, multi-frame reasoning: Models are required\nto infer and analyze evidence frames that may be far from the question frame.\n(2) Beyond perception: Questions cannot be answered through direct perception\nalone but require reasoning over hidden information. (3) Reliability: All tasks\nare manually annotated, referencing extensive real-world user understanding to\nalign with common perceptions. (4) Confusability: Carefully designed distractor\nannotation strategies to reduce model shortcuts. MMR-V consists of 317 videos\nand 1,257 tasks. Our experiments reveal that current models still struggle with\nmulti-modal reasoning; even the best-performing model, o4-mini, achieves only\n52.5% accuracy. Additionally, current reasoning enhancement strategies\n(Chain-of-Thought and scaling test-time compute) bring limited gains. Further\nanalysis indicates that the CoT demanded for multi-modal reasoning differs from\nit in textual reasoning, which partly explains the limited performance gains.\nWe hope that MMR-V can inspire further research into enhancing multi-modal\nreasoning capabilities.", "AI": {"tldr": "The paper introduces MMR-V, a benchmark for multimodal deep reasoning in videos, addressing gaps in existing benchmarks by requiring long-range, multi-frame reasoning and hidden information analysis. Current models struggle, achieving only 52.5% accuracy, and reasoning enhancements show limited gains.", "motivation": "Existing video benchmarks focus on understanding tasks, lacking challenges for multimodal reasoning and long-range evidence location in videos.", "method": "Proposes MMR-V, featuring long-range reasoning, hidden information analysis, manual annotation for reliability, and distractor strategies to reduce shortcuts.", "result": "Current models perform poorly (52.5% accuracy), and reasoning enhancements like Chain-of-Thought yield limited improvements.", "conclusion": "MMR-V highlights the need for better multimodal reasoning capabilities and inspires further research."}}
{"id": "2506.04218", "pdf": "https://arxiv.org/pdf/2506.04218", "abs": "https://arxiv.org/abs/2506.04218", "authors": ["Wei Cao", "Marcel Hallgarten", "Tianyu Li", "Daniel Dauner", "Xunjiang Gu", "Caojun Wang", "Yakov Miron", "Marco Aiello", "Hongyang Li", "Igor Gilitschenski", "Boris Ivanovic", "Marco Pavone", "Andreas Geiger", "Kashyap Chitta"], "title": "Pseudo-Simulation for Autonomous Driving", "categories": ["cs.RO", "cs.AI", "cs.CV", "cs.LG"], "comment": null, "summary": "Existing evaluation paradigms for Autonomous Vehicles (AVs) face critical\nlimitations. Real-world evaluation is often challenging due to safety concerns\nand a lack of reproducibility, whereas closed-loop simulation can face\ninsufficient realism or high computational costs. Open-loop evaluation, while\nbeing efficient and data-driven, relies on metrics that generally overlook\ncompounding errors. In this paper, we propose pseudo-simulation, a novel\nparadigm that addresses these limitations. Pseudo-simulation operates on real\ndatasets, similar to open-loop evaluation, but augments them with synthetic\nobservations generated prior to evaluation using 3D Gaussian Splatting. Our key\nidea is to approximate potential future states the AV might encounter by\ngenerating a diverse set of observations that vary in position, heading, and\nspeed. Our method then assigns a higher importance to synthetic observations\nthat best match the AV's likely behavior using a novel proximity-based\nweighting scheme. This enables evaluating error recovery and the mitigation of\ncausal confusion, as in closed-loop benchmarks, without requiring sequential\ninteractive simulation. We show that pseudo-simulation is better correlated\nwith closed-loop simulations (R^2=0.8) than the best existing open-loop\napproach (R^2=0.7). We also establish a public leaderboard for the community to\nbenchmark new methodologies with pseudo-simulation. Our code is available at\nhttps://github.com/autonomousvision/navsim.", "AI": {"tldr": "Pseudo-simulation is a new AV evaluation method combining real data with synthetic observations to address limitations of existing paradigms.", "motivation": "Existing AV evaluation methods (real-world, closed-loop, open-loop) have flaws like safety risks, lack of realism, or overlooking compounding errors.", "method": "Uses 3D Gaussian Splatting to generate synthetic observations, weighted by proximity to likely AV behavior, enabling error recovery evaluation without sequential simulation.", "result": "Pseudo-simulation correlates better with closed-loop benchmarks (R\u00b2=0.8) than open-loop (R\u00b2=0.7).", "conclusion": "Pseudo-simulation offers a balanced, efficient, and realistic AV evaluation method, with a public leaderboard for benchmarking."}}
{"id": "2506.03153", "pdf": "https://arxiv.org/pdf/2506.03153", "abs": "https://arxiv.org/abs/2506.03153", "authors": ["Junzhe Jiang", "Chang Yang", "Xinrun Wang", "Bo Li"], "title": "Why Regression? Binary Encoding Classification Brings Confidence to Stock Market Index Price Prediction", "categories": ["q-fin.ST", "cs.LG"], "comment": null, "summary": "Stock market indices serve as fundamental market measurement that quantify\nsystematic market dynamics. However, accurate index price prediction remains\nchallenging, primarily because existing approaches treat indices as isolated\ntime series and frame the prediction as a simple regression task. These methods\nfail to capture indices' inherent nature as aggregations of constituent stocks\nwith complex, time-varying interdependencies. To address these limitations, we\npropose Cubic, a novel end-to-end framework that explicitly models the adaptive\nfusion of constituent stocks for index price prediction. Our main contributions\nare threefold. i) Fusion in the latent space: we introduce the fusion mechanism\nover the latent embedding of the stocks to extract the information from the\nvast number of stocks. ii) Binary encoding classification: since regression\ntasks are challenging due to continuous value estimation, we reformulate the\nregression into the classification task, where the target value is converted to\nbinary and we optimize the prediction of the value of each digit with\ncross-entropy loss. iii) Confidence-guided prediction and trading: we introduce\nthe regularization loss to address market prediction uncertainty for the index\nprediction and design the rule-based trading policies based on the confidence.\nExtensive experiments across multiple stock markets and indices demonstrate\nthat Cubic consistently outperforms state-of-the-art baselines in stock index\nprediction tasks, achieving superior performance on both forecasting accuracy\nmetrics and downstream trading profitability.", "AI": {"tldr": "Cubic is a novel framework for stock index prediction by modeling constituent stocks' interdependencies, using latent space fusion, binary encoding classification, and confidence-guided trading, outperforming existing methods.", "motivation": "Existing methods treat stock indices as isolated time series, missing their aggregation nature and complex interdependencies among constituent stocks.", "method": "Cubic uses latent space fusion for stock embeddings, binary encoding classification for reformulating regression, and confidence-guided trading policies.", "result": "Cubic outperforms state-of-the-art baselines in forecasting accuracy and trading profitability across multiple markets.", "conclusion": "Cubic effectively addresses limitations of traditional methods, offering a robust solution for stock index prediction and trading."}}
{"id": "2506.04179", "pdf": "https://arxiv.org/pdf/2506.04179", "abs": "https://arxiv.org/abs/2506.04179", "authors": ["Anhao Zhao", "Fanghua Ye", "Yingqi Fan", "Junlong Tong", "Zhiwei Fei", "Hui Su", "Xiaoyu Shen"], "title": "SkipGPT: Dynamic Layer Pruning Reinvented with Token Awareness and Module Decoupling", "categories": ["cs.CL"], "comment": null, "summary": "Large language models (LLMs) achieve remarkable performance across tasks but\nincur substantial computational costs due to their deep, multi-layered\narchitectures. Layer pruning has emerged as a strategy to alleviate these\ninefficiencies, but conventional static pruning methods overlook two critical\ndynamics inherent to LLM inference: (1) horizontal dynamics, where token-level\nheterogeneity demands context-aware pruning decisions, and (2) vertical\ndynamics, where the distinct functional roles of MLP and self-attention layers\nnecessitate component-specific pruning policies. We introduce SkipGPT, a\ndynamic layer pruning framework designed to optimize computational resource\nallocation through two core innovations: (1) global token-aware routing to\nprioritize critical tokens, and (2) decoupled pruning policies for MLP and\nself-attention components. To mitigate training instability, we propose a\ntwo-stage optimization paradigm: first, a disentangled training phase that\nlearns routing strategies via soft parameterization to avoid premature pruning\ndecisions, followed by parameter-efficient LoRA fine-tuning to restore\nperformance impacted by layer removal. Extensive experiments demonstrate that\nSkipGPT reduces over 40% of model parameters while matching or exceeding the\nperformance of the original dense model across benchmarks. By harmonizing\ndynamic efficiency with preserved expressivity, SkipGPT advances the practical\ndeployment of scalable, resource-aware LLMs. Our code is publicly available at:\nhttps://github.com/EIT-NLP/SkipGPT.", "AI": {"tldr": "SkipGPT introduces dynamic layer pruning for LLMs, optimizing efficiency by addressing token-level and layer-specific dynamics, reducing parameters by 40% without performance loss.", "motivation": "To reduce computational costs of LLMs by addressing inefficiencies in static pruning methods, which ignore token-level and layer-specific dynamics.", "method": "SkipGPT uses global token-aware routing and decoupled pruning policies for MLP and self-attention layers, with a two-stage optimization for stability.", "result": "SkipGPT reduces over 40% of model parameters while matching or exceeding original model performance.", "conclusion": "SkipGPT enables scalable, resource-efficient LLM deployment by balancing dynamic efficiency and preserved expressivity."}}
{"id": "2506.04158", "pdf": "https://arxiv.org/pdf/2506.04158", "abs": "https://arxiv.org/abs/2506.04158", "authors": ["Yujia Hu", "Songhua Liu", "Zhenxiong Tan", "Xingyi Yang", "Xinchao Wang"], "title": "Image Editing As Programs with Diffusion Models", "categories": ["cs.CV"], "comment": null, "summary": "While diffusion models have achieved remarkable success in text-to-image\ngeneration, they encounter significant challenges with instruction-driven image\nediting. Our research highlights a key challenge: these models particularly\nstruggle with structurally inconsistent edits that involve substantial layout\nchanges. To mitigate this gap, we introduce Image Editing As Programs (IEAP), a\nunified image editing framework built upon the Diffusion Transformer (DiT)\narchitecture. At its core, IEAP approaches instructional editing through a\nreductionist lens, decomposing complex editing instructions into sequences of\natomic operations. Each operation is implemented via a lightweight adapter\nsharing the same DiT backbone and is specialized for a specific type of edit.\nProgrammed by a vision-language model (VLM)-based agent, these operations\ncollaboratively support arbitrary and structurally inconsistent\ntransformations. By modularizing and sequencing edits in this way, IEAP\ngeneralizes robustly across a wide range of editing tasks, from simple\nadjustments to substantial structural changes. Extensive experiments\ndemonstrate that IEAP significantly outperforms state-of-the-art methods on\nstandard benchmarks across various editing scenarios. In these evaluations, our\nframework delivers superior accuracy and semantic fidelity, particularly for\ncomplex, multi-step instructions. Codes are available at\nhttps://github.com/YujiaHu1109/IEAP.", "AI": {"tldr": "IEAP introduces a modular framework for instruction-driven image editing using Diffusion Transformers, outperforming existing methods in complex edits.", "motivation": "Diffusion models struggle with structurally inconsistent edits involving layout changes, prompting the need for a robust solution.", "method": "IEAP decomposes editing instructions into atomic operations via lightweight adapters on a shared DiT backbone, programmed by a VLM-based agent.", "result": "IEAP outperforms state-of-the-art methods in accuracy and semantic fidelity, especially for complex, multi-step instructions.", "conclusion": "IEAP provides a scalable and effective solution for diverse image editing tasks, demonstrated by superior benchmark performance."}}
{"id": "2506.04226", "pdf": "https://arxiv.org/pdf/2506.04226", "abs": "https://arxiv.org/abs/2506.04226", "authors": ["Akshat Gupta", "Maochuan Lu", "Thomas Hartvigsen", "Gopala Anumanchipalli"], "title": "Efficient Knowledge Editing via Minimal Precomputation", "categories": ["cs.CL", "cs.AI"], "comment": "ACL 2025 Main Conference", "summary": "Knowledge editing methods like MEMIT are able to make data and compute\nefficient updates of factual knowledge by using a single sentence to update\nfacts and their consequences. However, what is often overlooked is a\n\"precomputation step\", which requires a one-time but significant computational\ncost. The authors of MEMIT originally precompute approximately 44 million\nhidden vectors per edited layer, which requires a forward pass over 44 million\ntokens. For GPT-J (6B), this precomputation step takes 36 hours on a single\nGPU, while it takes approximately 40 hours for Llama2-7B. Additionally, this\nprecomputation time grows with model size. In this paper, we show that this\nexcessive computational cost is unnecessary. Knowledge editing using MEMIT and\nrelated methods, such as ROME and EMMET, can be performed by pre-computing a\nvery small portion of the 44 million hidden vectors. We first present the\ntheoretical minimum number of hidden vector precomputation required for\nsolutions of these editing methods to exist. We then empirically show that\nknowledge editing using these methods can be done by pre-computing\nsignificantly fewer hidden vectors. Specifically, we show that the\nprecomputation step can be done with less than 0.3% of the originally\nstipulated number of hidden vectors. This saves a significant amount of\nprecomputation time and allows users to begin editing new models within a few\nminutes.", "AI": {"tldr": "The paper reduces the excessive precomputation cost in knowledge editing methods like MEMIT by showing that only a tiny fraction of hidden vectors (less than 0.3%) is needed, saving significant time.", "motivation": "The high computational cost of precomputing hidden vectors for knowledge editing methods like MEMIT is impractical, especially as model sizes grow.", "method": "The authors theoretically determine the minimum required hidden vectors and empirically demonstrate editing with less than 0.3% of the original precomputation.", "result": "Knowledge editing can be performed with drastically fewer hidden vectors, reducing precomputation time from hours to minutes.", "conclusion": "The excessive precomputation in knowledge editing is unnecessary, and significant efficiency gains are achievable with minimal hidden vectors."}}
{"id": "2506.03157", "pdf": "https://arxiv.org/pdf/2506.03157", "abs": "https://arxiv.org/abs/2506.03157", "authors": ["Ziyang Yu", "Wenbing Huang", "Yang Liu"], "title": "UniSim: A Unified Simulator for Time-Coarsened Dynamics of Biomolecules", "categories": ["q-bio.BM", "cs.LG"], "comment": "ICML 2025 poster", "summary": "Molecular Dynamics (MD) simulations are essential for understanding the\natomic-level behavior of molecular systems, giving insights into their\ntransitions and interactions. However, classical MD techniques are limited by\nthe trade-off between accuracy and efficiency, while recent deep learning-based\nimprovements have mostly focused on single-domain molecules, lacking\ntransferability to unfamiliar molecular systems. Therefore, we propose\n\\textbf{Uni}fied \\textbf{Sim}ulator (UniSim), which leverages cross-domain\nknowledge to enhance the understanding of atomic interactions. First, we employ\na multi-head pretraining approach to learn a unified atomic representation\nmodel from a large and diverse set of molecular data. Then, based on the\nstochastic interpolant framework, we learn the state transition patterns over\nlong timesteps from MD trajectories, and introduce a force guidance module for\nrapidly adapting to different chemical environments. Our experiments\ndemonstrate that UniSim achieves highly competitive performance across small\nmolecules, peptides, and proteins.", "AI": {"tldr": "UniSim is a unified simulator using cross-domain knowledge to improve atomic interaction understanding, outperforming classical MD and single-domain deep learning methods.", "motivation": "Classical MD simulations face accuracy-efficiency trade-offs, and deep learning lacks transferability. UniSim aims to bridge this gap.", "method": "Uses multi-head pretraining for unified atomic representation and stochastic interpolant framework for state transitions, with a force guidance module for adaptability.", "result": "UniSim performs competitively across small molecules, peptides, and proteins.", "conclusion": "UniSim effectively enhances atomic-level understanding and adaptability in diverse molecular systems."}}
{"id": "2506.04180", "pdf": "https://arxiv.org/pdf/2506.04180", "abs": "https://arxiv.org/abs/2506.04180", "authors": ["Yuhao Wu", "Yushi Bai", "Zhiqiang Hu", "Juanzi Li", "Roy Ka-Wei Lee"], "title": "SuperWriter: Reflection-Driven Long-Form Generation with Large Language Models", "categories": ["cs.CL"], "comment": null, "summary": "Long-form text generation remains a significant challenge for large language\nmodels (LLMs), particularly in maintaining coherence, ensuring logical\nconsistency, and preserving text quality as sequence length increases. To\naddress these limitations, we propose SuperWriter-Agent, an agent-based\nframework designed to enhance the quality and consistency of long-form text\ngeneration. SuperWriter-Agent introduces explicit structured thinking-through\nplanning and refinement stages into the generation pipeline, guiding the model\nto follow a more deliberate and cognitively grounded process akin to that of a\nprofessional writer. Based on this framework, we construct a supervised\nfine-tuning dataset to train a 7B SuperWriter-LM. We further develop a\nhierarchical Direct Preference Optimization (DPO) procedure that uses Monte\nCarlo Tree Search (MCTS) to propagate final quality assessments and optimize\neach generation step accordingly. Empirical results across diverse benchmarks\ndemonstrate that SuperWriter-LM achieves state-of-the-art performance,\nsurpassing even larger-scale baseline models in both automatic evaluation and\nhuman evaluation. Furthermore, comprehensive ablation studies demonstrate the\neffectiveness of hierarchical DPO and underscore the value of incorporating\nstructured thinking steps to improve the quality of long-form text generation.", "AI": {"tldr": "SuperWriter-Agent, an agent-based framework, improves long-form text generation by incorporating structured thinking and hierarchical DPO, outperforming larger models.", "motivation": "Addressing challenges in long-form text generation like coherence and consistency as sequence length increases.", "method": "Proposes SuperWriter-Agent with structured thinking (planning/refinement), supervised fine-tuning of a 7B model, and hierarchical DPO with MCTS.", "result": "Achieves state-of-the-art performance in benchmarks, surpassing larger models in automatic and human evaluations.", "conclusion": "Structured thinking and hierarchical DPO significantly enhance long-form text generation quality."}}
{"id": "2506.04174", "pdf": "https://arxiv.org/pdf/2506.04174", "abs": "https://arxiv.org/abs/2506.04174", "authors": ["Hengyu Liu", "Yuehao Wang", "Chenxin Li", "Ruisi Cai", "Kevin Wang", "Wuyang Li", "Pavlo Molchanov", "Peihao Wang", "Zhangyang Wang"], "title": "FlexGS: Train Once, Deploy Everywhere with Many-in-One Flexible 3D Gaussian Splatting", "categories": ["cs.CV"], "comment": "CVPR 2025; Project Page: https://flexgs.github.io", "summary": "3D Gaussian splatting (3DGS) has enabled various applications in 3D scene\nrepresentation and novel view synthesis due to its efficient rendering\ncapabilities. However, 3DGS demands relatively significant GPU memory, limiting\nits use on devices with restricted computational resources. Previous approaches\nhave focused on pruning less important Gaussians, effectively compressing 3DGS\nbut often requiring a fine-tuning stage and lacking adaptability for the\nspecific memory needs of different devices. In this work, we present an elastic\ninference method for 3DGS. Given an input for the desired model size, our\nmethod selects and transforms a subset of Gaussians, achieving substantial\nrendering performance without additional fine-tuning. We introduce a tiny\nlearnable module that controls Gaussian selection based on the input\npercentage, along with a transformation module that adjusts the selected\nGaussians to complement the performance of the reduced model. Comprehensive\nexperiments on ZipNeRF, MipNeRF and Tanks\\&Temples scenes demonstrate the\neffectiveness of our approach. Code is available at https://flexgs.github.io.", "AI": {"tldr": "A method for elastic inference in 3D Gaussian splatting (3DGS) reduces GPU memory usage without fine-tuning, adapting to device-specific needs.", "motivation": "3DGS requires high GPU memory, limiting its use on resource-constrained devices. Existing compression methods lack adaptability and require fine-tuning.", "method": "Proposes an elastic inference method with a learnable module for Gaussian selection and a transformation module to adjust selected Gaussians.", "result": "Achieves efficient rendering performance without fine-tuning, validated on datasets like ZipNeRF and Tanks&Temples.", "conclusion": "The approach effectively reduces memory usage while maintaining rendering quality, offering adaptability for various devices."}}
{"id": "2506.04227", "pdf": "https://arxiv.org/pdf/2506.04227", "abs": "https://arxiv.org/abs/2506.04227", "authors": ["Zhao-Heng Yin", "Sherry Yang", "Pieter Abbeel"], "title": "Object-centric 3D Motion Field for Robot Learning from Human Videos", "categories": ["cs.RO", "cs.AI", "cs.CV", "cs.LG", "cs.SY", "eess.SY"], "comment": "Project: https://zhaohengyin.github.io/3DMF", "summary": "Learning robot control policies from human videos is a promising direction\nfor scaling up robot learning. However, how to extract action knowledge (or\naction representations) from videos for policy learning remains a key\nchallenge. Existing action representations such as video frames, pixelflow, and\npointcloud flow have inherent limitations such as modeling complexity or loss\nof information. In this paper, we propose to use object-centric 3D motion field\nto represent actions for robot learning from human videos, and present a novel\nframework for extracting this representation from videos for zero-shot control.\nWe introduce two novel components in its implementation. First, a novel\ntraining pipeline for training a ''denoising'' 3D motion field estimator to\nextract fine object 3D motions from human videos with noisy depth robustly.\nSecond, a dense object-centric 3D motion field prediction architecture that\nfavors both cross-embodiment transfer and policy generalization to background.\nWe evaluate the system in real world setups. Experiments show that our method\nreduces 3D motion estimation error by over 50% compared to the latest method,\nachieve 55% average success rate in diverse tasks where prior approaches\nfail~($\\lesssim 10$\\%), and can even acquire fine-grained manipulation skills\nlike insertion.", "AI": {"tldr": "Proposes object-centric 3D motion field for action representation in robot learning from human videos, achieving robust zero-shot control and fine-grained manipulation.", "motivation": "Existing action representations (e.g., video frames, pixelflow) have limitations like complexity or information loss, necessitating a better method.", "method": "Uses a denoising 3D motion field estimator and a dense object-centric 3D motion field architecture for robust extraction and generalization.", "result": "Reduces 3D motion estimation error by 50%, achieves 55% success rate in diverse tasks, and enables fine-grained skills like insertion.", "conclusion": "The proposed framework effectively addresses limitations of prior methods, enabling scalable and generalizable robot learning from human videos."}}
{"id": "2506.03167", "pdf": "https://arxiv.org/pdf/2506.03167", "abs": "https://arxiv.org/abs/2506.03167", "authors": ["Long Tan Le", "Senura Hansaja Wanasekara", "Zerun Niu", "Yansong Shi", "Nguyen H. Tran", "Phuong Vo", "Walid Saad", "Dusit Niyato", "Zhu Han", "Choong Seon Hong", "H. Vincent Poor"], "title": "Distributionally Robust Wireless Semantic Communication with Large AI Models", "categories": ["cs.NI", "cs.ET", "cs.IT", "cs.LG", "math.IT"], "comment": "Under Review", "summary": "6G wireless systems are expected to support massive volumes of data with\nultra-low latency. However, conventional bit-level transmission strategies\ncannot support the efficiency and adaptability required by modern,\ndata-intensive applications. The concept of semantic communication (SemCom)\naddresses this limitation by focusing on transmitting task-relevant semantic\ninformation instead of raw data. While recent efforts incorporating deep\nlearning and large-scale AI models have improved SemCom's performance, existing\nsystems remain vulnerable to both semantic-level and transmission-level noise\nbecause they often rely on domain-specific architectures that hinder\ngeneralizability. In this paper, a novel and generalized semantic communication\nframework called WaSeCom is proposed to systematically address uncertainty and\nenhance robustness. In particular, Wasserstein distributionally robust\noptimization is employed to provide resilience against semantic\nmisinterpretation and channel perturbations. A rigorous theoretical analysis is\nperformed to establish the robust generalization guarantees of the proposed\nframework. Experimental results on image and text transmission demonstrate that\nWaSeCom achieves improved robustness under noise and adversarial perturbations.\nThese results highlight its effectiveness in preserving semantic fidelity\nacross varying wireless conditions.", "AI": {"tldr": "WaSeCom is a generalized semantic communication framework using Wasserstein optimization to enhance robustness against noise and adversarial perturbations, improving semantic fidelity in 6G systems.", "motivation": "Conventional bit-level transmission lacks efficiency for data-intensive 6G applications, and existing semantic communication systems are vulnerable to noise and lack generalizability.", "method": "Proposes WaSeCom, employing Wasserstein distributionally robust optimization to address uncertainty and enhance robustness against semantic and transmission-level noise.", "result": "Experimental results show WaSeCom improves robustness under noise and adversarial perturbations, preserving semantic fidelity in varying wireless conditions.", "conclusion": "WaSeCom offers a robust and generalized solution for semantic communication in 6G systems, addressing key limitations of existing approaches."}}
{"id": "2506.04182", "pdf": "https://arxiv.org/pdf/2506.04182", "abs": "https://arxiv.org/abs/2506.04182", "authors": ["Ruiqi Zhang", "Changyi Xiao", "Yixin Cao"], "title": "Long or short CoT? Investigating Instance-level Switch of Large Reasoning Models", "categories": ["cs.CL"], "comment": null, "summary": "With the rapid advancement of large reasoning models, long Chain-of-Thought\n(CoT) prompting has demonstrated strong performance on complex tasks. However,\nthis often comes with a significant increase in token usage. In this paper, we\nconduct a comprehensive empirical analysis comparing long and short CoT\nstrategies. Our findings reveal that while long CoT can lead to performance\nimprovements, its benefits are often marginal relative to its significantly\nhigher token consumption. Specifically, long CoT tends to outperform when ample\ngeneration budgets are available, whereas short CoT is more effective under\ntighter budget constraints. These insights underscore the need for a dynamic\napproach that selects the proper CoT strategy based on task context and\nresource availability. To address this, we propose SwitchCoT, an automatic\nframework that adaptively chooses between long and short CoT strategies to\nbalance reasoning accuracy and computational efficiency. Moreover, SwitchCoT is\ndesigned to be budget-aware, making it broadly applicable across scenarios with\nvarying resource constraints. Experimental results demonstrate that SwitchCoT\ncan reduce inference costs by up to 50% while maintaining high accuracy.\nNotably, under limited token budgets, it achieves performance comparable to, or\neven exceeding, that of using either long or short CoT alone.", "AI": {"tldr": "The paper compares long and short Chain-of-Thought (CoT) prompting, finding long CoT marginally better but costly. It proposes SwitchCoT, a dynamic framework that adapts to resource constraints, reducing costs by 50% while maintaining accuracy.", "motivation": "To address the high token usage of long CoT prompting and explore its trade-offs with short CoT, aiming for a balanced solution.", "method": "Empirical analysis of long vs. short CoT, followed by the development of SwitchCoT, a budget-aware framework for adaptive strategy selection.", "result": "SwitchCoT reduces inference costs by up to 50% and matches or exceeds the performance of standalone long or short CoT under budget constraints.", "conclusion": "Dynamic CoT strategy selection (SwitchCoT) optimizes accuracy and efficiency, making it suitable for varied resource scenarios."}}
{"id": "2506.04209", "pdf": "https://arxiv.org/pdf/2506.04209", "abs": "https://arxiv.org/abs/2506.04209", "authors": ["Jingfeng Yang", "Ziyang Wu", "Yue Zhao", "Yi Ma"], "title": "Language-Image Alignment with Fixed Text Encoders", "categories": ["cs.CV"], "comment": null, "summary": "Currently, the most dominant approach to establishing language-image\nalignment is to pre-train text and image encoders jointly through contrastive\nlearning, such as CLIP and its variants. In this work, we question whether such\na costly joint training is necessary. In particular, we investigate if a\npre-trained fixed large language model (LLM) offers a good enough text encoder\nto guide visual representation learning. That is, we propose to learn\nLanguage-Image alignment with a Fixed Text encoder (LIFT) from an LLM by\ntraining only the image encoder. Somewhat surprisingly, through comprehensive\nbenchmarking and ablation studies, we find that this much simplified framework\nLIFT is highly effective and it outperforms CLIP in most scenarios that involve\ncompositional understanding and long captions, while achieving considerable\ngains in computational efficiency. Our work takes a first step towards\nsystematically exploring how text embeddings from LLMs can guide visual\nlearning and suggests an alternative design choice for learning\nlanguage-aligned visual representations.", "AI": {"tldr": "LIFT proposes using a fixed pre-trained LLM as a text encoder to guide visual representation learning, eliminating costly joint training. It outperforms CLIP in many scenarios and improves computational efficiency.", "motivation": "The paper questions the necessity of costly joint training for language-image alignment and explores if a fixed LLM can serve as an effective text encoder.", "method": "LIFT learns language-image alignment by training only the image encoder while using a fixed pre-trained LLM for text encoding.", "result": "LIFT outperforms CLIP in compositional understanding and long captions, with significant computational efficiency gains.", "conclusion": "The work suggests an alternative design for language-aligned visual representations and highlights the potential of LLM text embeddings in guiding visual learning."}}
{"id": "2204.10669", "pdf": "https://arxiv.org/pdf/2204.10669", "abs": "https://arxiv.org/abs/2204.10669", "authors": ["Ebaa Alnazer", "Ilche Georgievski", "Marco Aiello"], "title": "Risk Awareness in HTN Planning", "categories": ["cs.AI"], "comment": "112 pages, 13 figures", "summary": "Actual real-world domains are characterised by uncertain situations in which\nacting and using resources may entail the embracing of risks. Performing\nactions in such domains involves costs of consuming some resource, such as time\nor energy, where the knowledge about these costs can range from known to\ntotally unknown. In autonomous vehicles, actions have uncertain costs due to\nfactors like traffic. Choosing an action requires assessing delay risks, as\neach road may have unpredictable congestion. Thus, these domains call for not\nonly planning under uncertainty but also planning while embracing risk.\nResorting to HTN planning as a widely used planning technique in real-world\napplications, one can observe that existing approaches assume risk neutrality,\nrelying on single-valued action costs without considering risk. Here, we\nenhance HTN planning with risk awareness by considering expected utility\ntheory. We introduce a general framework for HTN planning that allows modelling\nrisk and uncertainty using a probability distribution of action costs upon\nwhich we define risk-aware HTN planning as being capable of accounting for the\ndifferent risk attitudes and allowing the computation of plans that go beyond\nrisk neutrality. We lay out that computing risk-aware plans requires finding\nplans with the highest expected utility. We argue that it is possible for HTN\nplanning agents to solve specialised risk-aware HTN planning problems by\nadapting existing HTN planning approaches, and develop an approach that\nsurpasses the expressiveness of current approaches by allowing these agents to\ncompute plans tailored to a particular risk attitude. An empirical evaluation\nof two case studies highlights the feasibility and expressiveness of this\napproach. We also highlight open issues, such as applying the proposal beyond\nHTN planning, covering both modelling and plan generation.", "AI": {"tldr": "The paper introduces a risk-aware HTN planning framework to handle uncertain action costs in real-world domains like autonomous vehicles, using expected utility theory to account for varying risk attitudes.", "motivation": "Real-world domains involve uncertain action costs (e.g., traffic delays in autonomous vehicles), but existing HTN planning approaches assume risk neutrality, ignoring risk assessment.", "method": "The authors enhance HTN planning by incorporating expected utility theory, modeling action costs as probability distributions and computing risk-aware plans with the highest expected utility.", "result": "The proposed framework allows HTN planning agents to compute plans tailored to specific risk attitudes, demonstrated as feasible and expressive in two case studies.", "conclusion": "The approach advances HTN planning by addressing risk awareness, though challenges remain in extending it beyond HTN planning for broader modeling and plan generation."}}
{"id": "2506.04185", "pdf": "https://arxiv.org/pdf/2506.04185", "abs": "https://arxiv.org/abs/2506.04185", "authors": ["Qingfei Zhao", "Ruobing Wang", "Dingling Xu", "Daren Zha", "Limin Liu"], "title": "R-Search: Empowering LLM Reasoning with Search via Multi-Reward Reinforcement Learning", "categories": ["cs.CL"], "comment": "16 pages, 3 figures", "summary": "Large language models (LLMs) have notably progressed in multi-step and\nlong-chain reasoning. However, extending their reasoning capabilities to\nencompass deep interactions with search remains a non-trivial challenge, as\nmodels often fail to identify optimal reasoning-search interaction\ntrajectories, resulting in suboptimal responses. We propose R-Search, a novel\nreinforcement learning framework for Reasoning-Search integration, designed to\nenable LLMs to autonomously execute multi-step reasoning with deep search\ninteraction, and learn optimal reasoning search interaction trajectories via\nmulti-reward signals, improving response quality in complex logic- and\nknowledge-intensive tasks. R-Search guides the LLM to dynamically decide when\nto retrieve or reason, while globally integrating key evidence to enhance deep\nknowledge interaction between reasoning and search. During RL training,\nR-Search provides multi-stage, multi-type rewards to jointly optimize the\nreasoning-search trajectory. Experiments on seven datasets show that R-Search\noutperforms advanced RAG baselines by up to 32.2% (in-domain) and 25.1%\n(out-of-domain). The code and data are available at\nhttps://github.com/QingFei1/R-Search.", "AI": {"tldr": "R-Search is a reinforcement learning framework that enhances LLMs' reasoning by integrating deep search interactions, improving response quality in complex tasks.", "motivation": "Current LLMs struggle with optimal reasoning-search interaction trajectories, leading to suboptimal responses.", "method": "Proposes R-Search, a reinforcement learning framework with multi-reward signals to guide LLMs in dynamically deciding when to retrieve or reason.", "result": "Outperforms advanced RAG baselines by up to 32.2% (in-domain) and 25.1% (out-of-domain) on seven datasets.", "conclusion": "R-Search effectively improves LLMs' reasoning and search integration, enhancing performance in logic- and knowledge-intensive tasks."}}
{"id": "2506.04211", "pdf": "https://arxiv.org/pdf/2506.04211", "abs": "https://arxiv.org/abs/2506.04211", "authors": ["Boyong He", "Yuxiang Ji", "Zhuoyue Tan", "Liaoni Wu"], "title": "Diffusion Domain Teacher: Diffusion Guided Domain Adaptive Object Detector", "categories": ["cs.CV"], "comment": "MM2024 poster, with appendix and codes", "summary": "Object detectors often suffer a decrease in performance due to the large\ndomain gap between the training data (source domain) and real-world data\n(target domain). Diffusion-based generative models have shown remarkable\nabilities in generating high-quality and diverse images, suggesting their\npotential for extracting valuable feature from various domains. To effectively\nleverage the cross-domain feature representation of diffusion models, in this\npaper, we train a detector with frozen-weight diffusion model on the source\ndomain, then employ it as a teacher model to generate pseudo labels on the\nunlabeled target domain, which are used to guide the supervised learning of the\nstudent model on the target domain. We refer to this approach as Diffusion\nDomain Teacher (DDT). By employing this straightforward yet potent framework,\nwe significantly improve cross-domain object detection performance without\ncompromising the inference speed. Our method achieves an average mAP\nimprovement of 21.2% compared to the baseline on 6 datasets from three common\ncross-domain detection benchmarks (Cross-Camera, Syn2Real, Real2Artistic},\nsurpassing the current state-of-the-art (SOTA) methods by an average of 5.7%\nmAP. Furthermore, extensive experiments demonstrate that our method\nconsistently brings improvements even in more powerful and complex models,\nhighlighting broadly applicable and effective domain adaptation capability of\nour DDT. The code is available at\nhttps://github.com/heboyong/Diffusion-Domain-Teacher.", "AI": {"tldr": "A method called Diffusion Domain Teacher (DDT) uses a frozen-weight diffusion model to improve cross-domain object detection by generating pseudo labels for unlabeled target domains, achieving significant performance gains.", "motivation": "Object detectors often underperform due to domain gaps between training and real-world data. Diffusion models' ability to generate diverse images suggests potential for cross-domain feature extraction.", "method": "Train a detector with a frozen-weight diffusion model on the source domain, use it as a teacher to generate pseudo labels for the target domain, and guide a student model's supervised learning.", "result": "DDT improves cross-domain detection by 21.2% mAP on average over the baseline and outperforms SOTA methods by 5.7% mAP. It also works well with more complex models.", "conclusion": "DDT is a simple yet effective framework for domain adaptation in object detection, demonstrating broad applicability and significant performance improvements."}}
{"id": "2401.10969", "pdf": "https://arxiv.org/pdf/2401.10969", "abs": "https://arxiv.org/abs/2401.10969", "authors": ["Gianluca Aguzzi", "Roberto Casadei", "Mirko Viroli"], "title": "MacroSwarm: A Field-based Compositional Framework for Swarm Programming", "categories": ["cs.AI", "cs.LO", "cs.SE"], "comment": null, "summary": "Swarm behaviour engineering is an area of research that seeks to investigate\nmethods and techniques for coordinating computation and action within groups of\nsimple agents to achieve complex global goals like pattern formation,\ncollective movement, clustering, and distributed sensing. Despite recent\nprogress in the analysis and engineering of swarms (of drones, robots,\nvehicles), there is still a need for general design and implementation methods\nand tools that can be used to define complex swarm behaviour in a principled\nway. To contribute to this quest, this article proposes a new field-based\ncoordination approach, called MacroSwarm, to design and program swarm behaviour\nin terms of reusable and fully composable functional blocks embedding\ncollective computation and coordination. Based on the macroprogramming paradigm\nof aggregate computing, MacroSwarm builds on the idea of expressing each swarm\nbehaviour block as a pure function, mapping sensing fields into actuation goal\nfields, e.g., including movement vectors. In order to demonstrate the\nexpressiveness, compositionality, and practicality of MacroSwarm as a framework\nfor swarm programming, we perform a variety of simulations covering common\npatterns of flocking, pattern formation, and collective decision-making. The\nimplications of the inherent self-stabilisation properties of field-based\ncomputations in MacroSwarm are discussed, which formally guarantee some\nresilience properties and guided the design of the library.", "AI": {"tldr": "The paper introduces MacroSwarm, a field-based coordination approach for designing and programming swarm behavior using reusable, composable functional blocks. It demonstrates its practicality through simulations of flocking, pattern formation, and decision-making.", "motivation": "The need for general methods and tools to define complex swarm behavior in a principled way, despite recent progress in swarm engineering.", "method": "Proposes MacroSwarm, a field-based coordination approach using pure functions to map sensing fields into actuation fields, building on aggregate computing.", "result": "Simulations show MacroSwarm's expressiveness and compositionality in achieving swarm behaviors like flocking and pattern formation. The framework also exhibits self-stabilization properties.", "conclusion": "MacroSwarm offers a practical and resilient framework for swarm programming, with formal guarantees for resilience and self-stabilization."}}
{"id": "2506.03196", "pdf": "https://arxiv.org/pdf/2506.03196", "abs": "https://arxiv.org/abs/2506.03196", "authors": ["Dania Herzalla", "Willian T. Lunardi", "Martin Andreoni"], "title": "Graph Neural Networks for Jamming Source Localization", "categories": ["cs.NI", "cs.CR", "cs.IT", "cs.LG", "eess.SP", "math.IT"], "comment": null, "summary": "Graph-based learning has emerged as a transformative approach for modeling\ncomplex relationships across diverse domains, yet its potential in wireless\nsecurity remains largely unexplored. In this work, we introduce the first\napplication of graph-based learning for jamming source localization, addressing\nthe imminent threat of jamming attacks in wireless networks. Unlike geometric\noptimization techniques that struggle under environmental uncertainties and\ndense interference, we reformulate localization as an inductive graph\nregression task. Our approach integrates structured node representations that\nencode local and global signal aggregation, ensuring spatial coherence and\nadaptive signal fusion. To enhance robustness, we incorporate an\nattention-based graph neural network that adaptively refines neighborhood\ninfluence and introduces a confidence-guided estimation mechanism that\ndynamically balances learned predictions with domain-informed priors. We\nevaluate our approach under complex radio frequency environments with varying\nsampling densities and signal propagation conditions, conducting comprehensive\nablation studies on graph construction, feature selection, and pooling\nstrategies. Results demonstrate that our novel graph-based learning framework\nsignificantly outperforms established localization baselines, particularly in\nchallenging scenarios with sparse and obfuscated signal information. Code is\navailable at\n[https://github.com/daniaherzalla/gnn-jamming-source-localization](https://github.com/daniaherzalla/gnn-jamming-source-localization).", "AI": {"tldr": "The paper introduces a graph-based learning framework for jamming source localization in wireless networks, outperforming traditional methods under challenging conditions.", "motivation": "To address the unexplored potential of graph-based learning in wireless security, particularly for jamming source localization, given the limitations of existing geometric optimization techniques.", "method": "Reformulates localization as an inductive graph regression task, using structured node representations and an attention-based graph neural network with confidence-guided estimation.", "result": "The framework significantly outperforms baseline methods, especially in scenarios with sparse or obfuscated signal information.", "conclusion": "Graph-based learning is a promising approach for robust jamming source localization in complex wireless environments."}}
{"id": "2505.24073", "pdf": "https://arxiv.org/pdf/2505.24073", "abs": "https://arxiv.org/abs/2505.24073", "authors": ["Chan-Wei Hu", "Yueqi Wang", "Shuo Xing", "Chia-Ju Chen", "Zhengzhong Tu"], "title": "mRAG: Elucidating the Design Space of Multi-modal Retrieval-Augmented Generation", "categories": ["cs.AI", "cs.CL", "cs.CV"], "comment": "16 pages, 11 figures", "summary": "Large Vision-Language Models (LVLMs) have made remarkable strides in\nmultimodal tasks such as visual question answering, visual grounding, and\ncomplex reasoning. However, they remain limited by static training data,\nsusceptibility to hallucinations, and inability to verify claims against\nup-to-date, external evidence, compromising their performance in dynamic\nreal-world applications. Retrieval-Augmented Generation (RAG) offers a\npractical solution to mitigate these challenges by allowing the LVLMs to access\nlarge-scale knowledge databases via retrieval mechanisms, thereby grounding\nmodel outputs in factual, contextually relevant information. Here in this\npaper, we conduct the first systematic dissection of the multimodal RAG\npipeline for LVLMs, explicitly investigating (1) the retrieval phase: on the\nmodality configurations and retrieval strategies, (2) the re-ranking stage: on\nstrategies to mitigate positional biases and improve the relevance of retrieved\nevidence, and (3) the generation phase: we further investigate how to best\nintegrate retrieved candidates into the final generation process. Finally, we\nextend to explore a unified agentic framework that integrates re-ranking and\ngeneration through self-reflection, enabling LVLMs to select relevant evidence\nand suppress irrelevant context dynamically. Our full-stack exploration of RAG\nfor LVLMs yields substantial insights, resulting in an average performance\nboost of 5% without any fine-tuning.", "AI": {"tldr": "The paper explores Retrieval-Augmented Generation (RAG) for Large Vision-Language Models (LVLMs) to address limitations like static data and hallucinations, improving performance by 5% without fine-tuning.", "motivation": "LVLMs face challenges like static training data, hallucinations, and lack of real-time verification, limiting real-world applicability. RAG offers a solution by grounding outputs in factual, dynamic knowledge.", "method": "The study systematically examines the multimodal RAG pipeline: retrieval (modality configurations, strategies), re-ranking (mitigating biases, improving relevance), and generation (integrating retrieved candidates). It also proposes a unified agentic framework for dynamic evidence selection.", "result": "The approach yields a 5% average performance boost in LVLMs without fine-tuning.", "conclusion": "RAG significantly enhances LVLMs by integrating dynamic knowledge retrieval and generation, addressing key limitations for real-world applications."}}
{"id": "2506.04213", "pdf": "https://arxiv.org/pdf/2506.04213", "abs": "https://arxiv.org/abs/2506.04213", "authors": ["Xuanhua He", "Quande Liu", "Zixuan Ye", "Wecai Ye", "Qiulin Wang", "Xintao Wang", "Qifeng Chen", "Pengfei Wan", "Di Zhang", "Kun Gai"], "title": "FullDiT2: Efficient In-Context Conditioning for Video Diffusion Transformers", "categories": ["cs.CV"], "comment": null, "summary": "Fine-grained and efficient controllability on video diffusion transformers\nhas raised increasing desires for the applicability. Recently, In-context\nConditioning emerged as a powerful paradigm for unified conditional video\ngeneration, which enables diverse controls by concatenating varying context\nconditioning signals with noisy video latents into a long unified token\nsequence and jointly processing them via full-attention, e.g., FullDiT. Despite\ntheir effectiveness, these methods face quadratic computation overhead as task\ncomplexity increases, hindering practical deployment. In this paper, we study\nthe efficiency bottleneck neglected in original in-context conditioning video\ngeneration framework. We begin with systematic analysis to identify two key\nsources of the computation inefficiencies: the inherent redundancy within\ncontext condition tokens and the computational redundancy in context-latent\ninteractions throughout the diffusion process. Based on these insights, we\npropose FullDiT2, an efficient in-context conditioning framework for general\ncontrollability in both video generation and editing tasks, which innovates\nfrom two key perspectives. Firstly, to address the token redundancy, FullDiT2\nleverages a dynamic token selection mechanism to adaptively identify important\ncontext tokens, reducing the sequence length for unified full-attention.\nAdditionally, a selective context caching mechanism is devised to minimize\nredundant interactions between condition tokens and video latents. Extensive\nexperiments on six diverse conditional video editing and generation tasks\ndemonstrate that FullDiT2 achieves significant computation reduction and 2-3\ntimes speedup in averaged time cost per diffusion step, with minimal\ndegradation or even higher performance in video generation quality. The project\npage is at \\href{https://fulldit2.github.io/}{https://fulldit2.github.io/}.", "AI": {"tldr": "FullDiT2 improves efficiency in video generation by reducing computational redundancy in in-context conditioning, achieving faster performance with minimal quality loss.", "motivation": "Address the quadratic computation overhead in existing in-context conditioning methods for video generation, hindering practical deployment.", "method": "Proposes FullDiT2 with dynamic token selection and selective context caching to reduce redundancy in context tokens and interactions.", "result": "Achieves 2-3x speedup per diffusion step with minimal performance degradation or improvement in video quality.", "conclusion": "FullDiT2 offers an efficient solution for general controllability in video generation and editing tasks."}}
{"id": "2403.04588", "pdf": "https://arxiv.org/pdf/2403.04588", "abs": "https://arxiv.org/abs/2403.04588", "authors": ["L\u00e9opold Mayti\u00e9", "Benjamin Devillers", "Alexandre Arnold", "Rufin VanRullen"], "title": "Zero-shot cross-modal transfer of Reinforcement Learning policies through a Global Workspace", "categories": ["cs.AI"], "comment": null, "summary": "Humans perceive the world through multiple senses, enabling them to create a\ncomprehensive representation of their surroundings and to generalize\ninformation across domains. For instance, when a textual description of a scene\nis given, humans can mentally visualize it. In fields like robotics and\nReinforcement Learning (RL), agents can also access information about the\nenvironment through multiple sensors; yet redundancy and complementarity\nbetween sensors is difficult to exploit as a source of robustness (e.g. against\nsensor failure) or generalization (e.g. transfer across domains). Prior\nresearch demonstrated that a robust and flexible multimodal representation can\nbe efficiently constructed based on the cognitive science notion of a 'Global\nWorkspace': a unique representation trained to combine information across\nmodalities, and to broadcast its signal back to each modality. Here, we explore\nwhether such a brain-inspired multimodal representation could be advantageous\nfor RL agents. First, we train a 'Global Workspace' to exploit information\ncollected about the environment via two input modalities (a visual input, or an\nattribute vector representing the state of the agent and/or its environment).\nThen, we train a RL agent policy using this frozen Global Workspace. In two\ndistinct environments and tasks, our results reveal the model's ability to\nperform zero-shot cross-modal transfer between input modalities, i.e. to apply\nto image inputs a policy previously trained on attribute vectors (and\nvice-versa), without additional training or fine-tuning. Variants and ablations\nof the full Global Workspace (including a CLIP-like multimodal representation\ntrained via contrastive learning) did not display the same generalization\nabilities.", "AI": {"tldr": "The paper explores using a brain-inspired 'Global Workspace' for RL agents to achieve robust multimodal representation and zero-shot cross-modal transfer.", "motivation": "Humans generalize across sensory inputs, but RL agents struggle with sensor redundancy and complementarity. The study aims to leverage cognitive science principles for better RL performance.", "method": "A 'Global Workspace' is trained to combine multimodal inputs (visual and attribute vectors), then used to train an RL agent. Performance is tested in zero-shot cross-modal transfer tasks.", "result": "The model successfully performs zero-shot transfer between modalities, outperforming variants like CLIP-like representations.", "conclusion": "The brain-inspired Global Workspace is effective for RL agents, enabling robust multimodal generalization without additional training."}}
{"id": "2506.03199", "pdf": "https://arxiv.org/pdf/2506.03199", "abs": "https://arxiv.org/abs/2506.03199", "authors": ["Giuseppe Di Caro", "Vahagn Kirakosyan", "Alexander G. Abanov", "Luca Candelori", "Nadine Hartmann", "Ernest T. Lam", "Kharen Musaelian", "Ryan Samson", "Dario Villani", "Martin T. Wells", "Richard J. Wenstrup", "Mengjia Xu"], "title": "Quantum Cognition Machine Learning for Forecasting Chromosomal Instability", "categories": ["q-bio.QM", "cs.LG", "quant-ph"], "comment": null, "summary": "The accurate prediction of chromosomal instability from the morphology of\ncirculating tumor cells (CTCs) enables real-time detection of CTCs with high\nmetastatic potential in the context of liquid biopsy diagnostics. However, it\npresents a significant challenge due to the high dimensionality and complexity\nof single-cell digital pathology data. Here, we introduce the application of\nQuantum Cognition Machine Learning (QCML), a quantum-inspired computational\nframework, to estimate morphology-predicted chromosomal instability in CTCs\nfrom patients with metastatic breast cancer. QCML leverages quantum mechanical\nprinciples to represent data as state vectors in a Hilbert space, enabling\ncontext-aware feature modeling, dimensionality reduction, and enhanced\ngeneralization without requiring curated feature selection. QCML outperforms\nconventional machine learning methods when tested on out of sample verification\nCTCs, achieving higher accuracy in identifying predicted large-scale state\ntransitions (pLST) status from CTC-derived morphology features. These\npreliminary findings support the application of QCML as a novel machine\nlearning tool with superior performance in high-dimensional, low-sample-size\nbiomedical contexts. QCML enables the simulation of cognition-like learning for\nthe identification of biologically meaningful prediction of chromosomal\ninstability from CTC morphology, offering a novel tool for CTC classification\nin liquid biopsy.", "AI": {"tldr": "QCML, a quantum-inspired machine learning framework, predicts chromosomal instability in CTCs more accurately than conventional methods by leveraging quantum principles for feature modeling and dimensionality reduction.", "motivation": "The challenge lies in predicting chromosomal instability from CTC morphology due to high-dimensional, complex data. QCML aims to address this with superior performance.", "method": "QCML uses quantum mechanical principles to model data as state vectors in a Hilbert space, enabling context-aware feature modeling and dimensionality reduction without curated feature selection.", "result": "QCML outperforms conventional methods in identifying pLST status from CTC morphology, showing higher accuracy in out-of-sample verification.", "conclusion": "QCML is a promising tool for high-dimensional biomedical data, offering improved CTC classification and chromosomal instability prediction in liquid biopsy."}}
{"id": "2506.03487", "pdf": "https://arxiv.org/pdf/2506.03487", "abs": "https://arxiv.org/abs/2506.03487", "authors": ["Xianming Li", "Aamir Shakir", "Rui Huang", "Julius Lipp", "Jing Li"], "title": "ProRank: Prompt Warmup via Reinforcement Learning for Small Language Models Reranking", "categories": ["cs.IR", "cs.CL"], "comment": null, "summary": "Reranking is fundamental to information retrieval and retrieval-augmented\ngeneration, with recent Large Language Models (LLMs) significantly advancing\nreranking quality. While recent advances with LLMs have significantly improved\ndocument reranking quality, current approaches primarily rely on large-scale\nLLMs (>7B parameters) through zero-shot prompting, presenting high\ncomputational costs. Small Language Models (SLMs) offer a promising alternative\nbecause of their efficiency, but our preliminary quantitative analysis reveals\nthey struggle with understanding task prompts without fine-tuning. This limits\ntheir effectiveness for document reranking tasks. To address this issue, we\nintroduce a novel two-stage training approach, ProRank, for SLM-based document\nreranking. First, we propose a prompt warmup stage using reinforcement learning\nGRPO to steer SLMs to understand task prompts and generate more accurate\ncoarse-grained binary relevance scores for document reranking. Then, we\ncontinuously fine-tune the SLMs with a fine-grained score learning stage\nwithout introducing additional layers to further improve the reranking quality.\nComprehensive experimental results demonstrate that the proposed ProRank\nconsistently outperforms both the most advanced open-source and proprietary\nreranking models. Notably, our lightweight ProRank-0.5B model even surpasses\nthe powerful 32B LLM reranking model on the BEIR benchmark, establishing that\nproperly trained SLMs can achieve superior document reranking performance while\nmaintaining computational efficiency.", "AI": {"tldr": "ProRank introduces a two-stage training approach for Small Language Models (SLMs) to improve document reranking, outperforming larger models while maintaining efficiency.", "motivation": "Current LLM-based reranking methods are computationally expensive, and SLMs struggle with task prompts without fine-tuning. ProRank addresses these limitations.", "method": "A two-stage approach: 1) Prompt warmup with reinforcement learning (GRPO) for coarse-grained scores, 2) Fine-grained score learning without extra layers.", "result": "ProRank-0.5B surpasses a 32B LLM on the BEIR benchmark, showing SLMs can achieve superior performance efficiently.", "conclusion": "Properly trained SLMs can outperform larger models in document reranking, offering a cost-effective solution."}}
{"id": "2506.04216", "pdf": "https://arxiv.org/pdf/2506.04216", "abs": "https://arxiv.org/abs/2506.04216", "authors": ["Zixuan Ye", "Xuanhua He", "Quande Liu", "Qiulin Wang", "Xintao Wang", "Pengfei Wan", "Di Zhang", "Kun Gai", "Qifeng Chen", "Wenhan Luo"], "title": "UNIC: Unified In-Context Video Editing", "categories": ["cs.CV"], "comment": "The project page is at\n  \\href{https://zixuan-ye.github.io/UNIC}{https://zixuan-ye.github.io/UNIC}", "summary": "Recent advances in text-to-video generation have sparked interest in\ngenerative video editing tasks. Previous methods often rely on task-specific\narchitectures (e.g., additional adapter modules) or dedicated customizations\n(e.g., DDIM inversion), which limit the integration of versatile editing\nconditions and the unification of various editing tasks. In this paper, we\nintroduce UNified In-Context Video Editing (UNIC), a simple yet effective\nframework that unifies diverse video editing tasks within a single model in an\nin-context manner. To achieve this unification, we represent the inputs of\nvarious video editing tasks as three types of tokens: the source video tokens,\nthe noisy video latent, and the multi-modal conditioning tokens that vary\naccording to the specific editing task. Based on this formulation, our key\ninsight is to integrate these three types into a single consecutive token\nsequence and jointly model them using the native attention operations of DiT,\nthereby eliminating the need for task-specific adapter designs. Nevertheless,\ndirect task unification under this framework is challenging, leading to severe\ntoken collisions and task confusion due to the varying video lengths and\ndiverse condition modalities across tasks. To address these, we introduce\ntask-aware RoPE to facilitate consistent temporal positional encoding, and\ncondition bias that enables the model to clearly differentiate different\nediting tasks. This allows our approach to adaptively perform different video\nediting tasks by referring the source video and varying condition tokens \"in\ncontext\", and support flexible task composition. To validate our method, we\nconstruct a unified video editing benchmark containing six representative video\nediting tasks. Results demonstrate that our unified approach achieves superior\nperformance on each task and exhibits emergent task composition abilities.", "AI": {"tldr": "UNIC is a unified framework for diverse video editing tasks using a single model with in-context tokens, eliminating task-specific designs.", "motivation": "To address limitations of task-specific architectures and enable versatile, unified video editing.", "method": "Represents inputs as three token types (source video, noisy latent, multi-modal conditioning) and models them jointly using DiT attention, with task-aware RoPE and condition bias to avoid token collisions.", "result": "Superior performance on six video editing tasks and emergent task composition abilities.", "conclusion": "UNIC successfully unifies diverse video editing tasks in a single model, demonstrating adaptability and performance."}}
{"id": "2407.03969", "pdf": "https://arxiv.org/pdf/2407.03969", "abs": "https://arxiv.org/abs/2407.03969", "authors": ["Mikel Malag\u00f3n", "Josu Ceberio", "Jose A. Lozano"], "title": "Craftium: Bridging Flexibility and Efficiency for Rich 3D Single- and Multi-Agent Environments", "categories": ["cs.AI"], "comment": "ICML 2025. Project's website: https://github.com/mikelma/craftium/", "summary": "Advances in large models, reinforcement learning, and open-endedness have\naccelerated progress toward autonomous agents that can learn and interact in\nthe real world. To achieve this, flexible tools are needed to create rich, yet\ncomputationally efficient, environments. While scalable 2D environments fail to\naddress key real-world challenges like 3D navigation and spatial reasoning,\nmore complex 3D environments are computationally expensive and lack features\nlike customizability and multi-agent support. This paper introduces Craftium, a\nhighly customizable and easy-to-use platform for building rich 3D single- and\nmulti-agent environments. We showcase environments of different complexity and\nnature: from single- and multi-agent tasks to vast worlds with many creatures\nand biomes, and customizable procedural task generators. Benchmarking shows\nthat Craftium significantly reduces the computational cost of alternatives of\nsimilar richness, achieving +2K steps per second more than Minecraft-based\nframeworks.", "AI": {"tldr": "Craftium is a customizable 3D platform for single- and multi-agent environments, offering computational efficiency and rich features.", "motivation": "Existing 2D environments lack real-world challenges, while 3D ones are computationally expensive and inflexible.", "method": "Introduces Craftium, a platform for building diverse 3D environments, including multi-agent tasks and procedural generators.", "result": "Craftium reduces computational costs, outperforming alternatives like Minecraft-based frameworks by +2K steps per second.", "conclusion": "Craftium provides a scalable, efficient solution for creating rich 3D environments for autonomous agents."}}
{"id": "2506.03587", "pdf": "https://arxiv.org/pdf/2506.03587", "abs": "https://arxiv.org/abs/2506.03587", "authors": ["Florian Boudin", "Akiko Aizawa"], "title": "Preface to the Special Issue of the TAL Journal on Scholarly Document Processing", "categories": ["cs.DL", "cs.CL"], "comment": null, "summary": "The rapid growth of scholarly literature makes it increasingly difficult for\nresearchers to keep up with new knowledge. Automated tools are now more\nessential than ever to help navigate and interpret this vast body of\ninformation. Scientific papers pose unique difficulties, with their complex\nlanguage, specialized terminology, and diverse formats, requiring advanced\nmethods to extract reliable and actionable insights. Large language models\n(LLMs) offer new opportunities, enabling tasks such as literature reviews,\nwriting assistance, and interactive exploration of research. This special issue\nof the TAL journal highlights research addressing these challenges and, more\nbroadly, research on natural language processing and information retrieval for\nscholarly and scientific documents.", "AI": {"tldr": "Automated tools, especially LLMs, are crucial for navigating and interpreting the growing scholarly literature due to its complexity and volume.", "motivation": "The rapid growth and complexity of scholarly literature make it challenging for researchers to stay updated, necessitating advanced tools.", "method": "Utilizing large language models (LLMs) for tasks like literature reviews, writing assistance, and interactive research exploration.", "result": "LLMs provide new opportunities to extract reliable insights from scientific papers despite their complexity.", "conclusion": "This special issue highlights NLP and information retrieval advancements for scholarly documents, addressing current challenges."}}
{"id": "2506.04220", "pdf": "https://arxiv.org/pdf/2506.04220", "abs": "https://arxiv.org/abs/2506.04220", "authors": ["Fangrui Zhu", "Hanhui Wang", "Yiming Xie", "Jing Gu", "Tianye Ding", "Jianwei Yang", "Huaizu Jiang"], "title": "Struct2D: A Perception-Guided Framework for Spatial Reasoning in Large Multimodal Models", "categories": ["cs.CV"], "comment": "https://github.com/neu-vi/struct2d", "summary": "Unlocking spatial reasoning in Large Multimodal Models (LMMs) is crucial for\nenabling intelligent interaction with 3D environments. While prior efforts\noften rely on explicit 3D inputs or specialized model architectures, we ask:\ncan LMMs reason about 3D space using only structured 2D representations derived\nfrom perception? We introduce Struct2D, a perception-guided prompting framework\nthat combines bird's-eye-view (BEV) images with object marks and object-centric\nmetadata, optionally incorporating egocentric keyframes when needed. Using\nStruct2D, we conduct an in-depth zero-shot analysis of closed-source LMMs\n(e.g., GPT-o3) and find that they exhibit surprisingly strong spatial reasoning\nabilities when provided with structured 2D inputs, effectively handling tasks\nsuch as relative direction estimation and route planning. Building on these\ninsights, we construct Struct2D-Set, a large-scale instruction tuning dataset\nwith 200K fine-grained QA pairs across eight spatial reasoning categories,\ngenerated automatically from 3D indoor scenes. We fine-tune an open-source LMM\n(Qwen2.5VL) on Struct2D-Set, achieving competitive performance on multiple\nbenchmarks, including 3D question answering, dense captioning, and object\ngrounding. Our approach demonstrates that structured 2D inputs can effectively\nbridge perception and language reasoning in LMMs-without requiring explicit 3D\nrepresentations as input. We will release both our code and dataset to support\nfuture research.", "AI": {"tldr": "The paper introduces Struct2D, a framework using structured 2D inputs to enhance spatial reasoning in LMMs, achieving strong performance without explicit 3D inputs.", "motivation": "To explore if LMMs can reason about 3D space using only structured 2D representations, avoiding reliance on explicit 3D inputs or specialized architectures.", "method": "Proposes Struct2D, a perception-guided prompting framework combining BEV images, object marks, and metadata, and creates Struct2D-Set, a 200K QA dataset for fine-tuning.", "result": "LMMs show strong spatial reasoning with Struct2D, and fine-tuned models achieve competitive performance on benchmarks like 3D QA and object grounding.", "conclusion": "Structured 2D inputs effectively bridge perception and language reasoning in LMMs, eliminating the need for explicit 3D representations."}}
{"id": "2407.11784", "pdf": "https://arxiv.org/pdf/2407.11784", "abs": "https://arxiv.org/abs/2407.11784", "authors": ["Daoyuan Chen", "Haibin Wang", "Yilun Huang", "Ce Ge", "Yaliang Li", "Bolin Ding", "Jingren Zhou"], "title": "Data-Juicer Sandbox: A Feedback-Driven Suite for Multimodal Data-Model Co-development", "categories": ["cs.AI", "cs.CV", "cs.LG"], "comment": "Accepted by ICML 2025 (Spotlight). 33 pages, 16 tables, 14 figures", "summary": "The emergence of multimodal large models has advanced artificial\nintelligence, introducing unprecedented levels of performance and\nfunctionality. However, optimizing these models remains challenging due to\nhistorically isolated paths of model-centric and data-centric developments,\nleading to suboptimal outcomes and inefficient resource utilization. In\nresponse, we present a new sandbox suite tailored for integrated data-model\nco-development. This sandbox provides a feedback-driven experimental platform,\nenabling cost-effective iteration and guided refinement of both data and\nmodels. Our proposed ``Probe-Analyze-Refine'' workflow, validated through\npractical use cases on multimodal tasks such as image-text pre-training with\nCLIP, image-to-text generation with LLaVA-like models, and text-to-video\ngeneration with DiT-based models, yields transferable and notable performance\nboosts, such as topping the VBench leaderboard. A comprehensive set of over 100\nexperiments demonstrated the suite's usability and extensibility, while also\nuncovering insights into the interplay between data quality, diversity, model\nbehavior, and computational costs. All codes, datasets, and models are\nopen-sourced to foster future research and applications that would otherwise be\ninfeasible due to the lack of a dedicated co-development infrastructure.", "AI": {"tldr": "A sandbox suite for integrated data-model co-development is introduced, optimizing multimodal large models through a feedback-driven workflow, validated by practical use cases and open-sourced for broader research.", "motivation": "Addressing the challenge of optimizing multimodal large models due to isolated model-centric and data-centric developments, leading to inefficiencies.", "method": "Proposes a \"Probe-Analyze-Refine\" workflow within a sandbox suite for iterative data-model co-development, tested on tasks like image-text pre-training and text-to-video generation.", "result": "Achieves notable performance boosts (e.g., topping VBench leaderboard) and provides insights into data quality, diversity, and computational costs.", "conclusion": "The suite is usable, extensible, and open-sourced, enabling future research in multimodal AI that was previously infeasible."}}
{"id": "2506.03272", "pdf": "https://arxiv.org/pdf/2506.03272", "abs": "https://arxiv.org/abs/2506.03272", "authors": ["My Youssef El Hafidi", "Achraf Toufah", "Mohamed Achraf Kadim"], "title": "Investigating Quantum Feature Maps in Quantum Support Vector Machines for Lung Cancer Classification", "categories": ["quant-ph", "cs.LG"], "comment": "14 pages, 7 figures", "summary": "In recent years, quantum machine learning has emerged as a promising\nintersection between quantum physics and artificial intelligence, particularly\nin domains requiring advanced pattern recognition such as healthcare. This\nstudy investigates the effectiveness of Quantum Support Vector Machines (QSVM),\nwhich leverage quantum mechanical phenomena like superposition and entanglement\nto construct high-dimensional Hilbert spaces for data classification. Focusing\non lung cancer diagnosis, a concrete and critical healthcare application, we\nanalyze how different quantum feature maps influence classification\nperformance. Using a real-world dataset of 309 patient records with significant\nclass imbalance (39 non-cancer vs. 270 cancer cases), we constructed six\nbalanced subsets for robust evaluation. QSVM models were implemented using\nQiskit and executed on the qasm simulator, employing three distinct quantum\nfeature maps: ZFeatureMap, ZZFeatureMap, and PauliFeatureMap. Performance was\nassessed using accuracy, precision, recall, specificity, and F1-score. Results\nshow that the PauliFeatureMap consistently outperformed the others, achieving\nperfect classification in three subsets and strong performance overall. These\nfindings demonstrate how quantum computational principles can be harnessed to\nenhance diagnostic capabilities, reinforcing the importance of physics-based\nmodeling in emerging AI applications within healthcare.", "AI": {"tldr": "Quantum Support Vector Machines (QSVM) using PauliFeatureMap outperform other quantum feature maps in lung cancer diagnosis, demonstrating quantum computing's potential in healthcare AI.", "motivation": "To explore the effectiveness of QSVM in healthcare, specifically for lung cancer diagnosis, leveraging quantum mechanics for improved pattern recognition.", "method": "Implemented QSVM models with three quantum feature maps (ZFeatureMap, ZZFeatureMap, PauliFeatureMap) on a real-world dataset of 309 patient records, evaluated using accuracy, precision, recall, specificity, and F1-score.", "result": "PauliFeatureMap achieved perfect classification in three subsets and strong overall performance, outperforming other feature maps.", "conclusion": "Quantum computational principles can enhance diagnostic capabilities, highlighting the role of physics-based modeling in AI for healthcare."}}
{"id": "2506.03741", "pdf": "https://arxiv.org/pdf/2506.03741", "abs": "https://arxiv.org/abs/2506.03741", "authors": ["Rifat Mehreen Amin", "Oliver Hans K\u00fchle", "Daniel Buschek", "Andreas Butz"], "title": "PromptCanvas: Composable Prompting Workspaces Using Dynamic Widgets for Exploration and Iteration in Creative Writing", "categories": ["cs.HC", "cs.CL", "H.5.2; I.2.7"], "comment": null, "summary": "We introduce PromptCanvas, a concept that transforms prompting into a\ncomposable, widget-based experience on an infinite canvas. Users can generate,\ncustomize, and arrange interactive widgets representing various facets of their\ntext, offering greater control over AI-generated content. PromptCanvas allows\nwidget creation through system suggestions, user prompts, or manual input,\nproviding a flexible environment tailored to individual needs. This enables\ndeeper engagement with the creative process. In a lab study with 18\nparticipants, PromptCanvas outperformed a traditional conversational UI on the\nCreativity Support Index. Participants found that it reduced cognitive load,\nwith lower mental demand and frustration. Qualitative feedback revealed that\nthe visual organization of thoughts and easy iteration encouraged new\nperspectives and ideas. A follow-up field study (N=10) confirmed these results,\nshowcasing the potential of dynamic, customizable interfaces in improving\ncollaborative writing with AI.", "AI": {"tldr": "PromptCanvas transforms prompting into a widget-based, customizable experience, enhancing AI-generated content control and creativity.", "motivation": "To improve user engagement and control in AI-generated content creation by offering a flexible, visual, and interactive prompting interface.", "method": "Introduces PromptCanvas, a widget-based infinite canvas for prompting, allowing widget creation via suggestions, prompts, or manual input. Evaluated through lab (N=18) and field (N=10) studies.", "result": "Outperformed traditional UI in creativity support, reduced cognitive load, and encouraged new ideas. Qualitative feedback highlighted visual organization and ease of iteration.", "conclusion": "PromptCanvas demonstrates the potential of dynamic, customizable interfaces for enhancing collaborative writing and creative processes with AI."}}
{"id": "2506.04224", "pdf": "https://arxiv.org/pdf/2506.04224", "abs": "https://arxiv.org/abs/2506.04224", "authors": ["Zirui Wang", "Wenjing Bian", "Xinghui Li", "Yifu Tao", "Jianeng Wang", "Maurice Fallon", "Victor Adrian Prisacariu"], "title": "Seeing in the Dark: Benchmarking Egocentric 3D Vision with the Oxford Day-and-Night Dataset", "categories": ["cs.CV"], "comment": "Project page: https://oxdan.active.vision/", "summary": "We introduce Oxford Day-and-Night, a large-scale, egocentric dataset for\nnovel view synthesis (NVS) and visual relocalisation under challenging lighting\nconditions. Existing datasets often lack crucial combinations of features such\nas ground-truth 3D geometry, wide-ranging lighting variation, and full 6DoF\nmotion. Oxford Day-and-Night addresses these gaps by leveraging Meta ARIA\nglasses to capture egocentric video and applying multi-session SLAM to estimate\ncamera poses, reconstruct 3D point clouds, and align sequences captured under\nvarying lighting conditions, including both day and night. The dataset spans\nover 30 $\\mathrm{km}$ of recorded trajectories and covers an area of 40,000\n$\\mathrm{m}^2$, offering a rich foundation for egocentric 3D vision research.\nIt supports two core benchmarks, NVS and relocalisation, providing a unique\nplatform for evaluating models in realistic and diverse environments.", "AI": {"tldr": "Oxford Day-and-Night is a large-scale egocentric dataset for novel view synthesis and visual relocalisation, addressing gaps in existing datasets with ground-truth 3D geometry, lighting variation, and full 6DoF motion.", "motivation": "Existing datasets lack combinations of features like 3D geometry, lighting variation, and full motion. This dataset fills these gaps to support egocentric 3D vision research.", "method": "Uses Meta ARIA glasses for egocentric video capture and multi-session SLAM for camera pose estimation, 3D point cloud reconstruction, and alignment under varying lighting.", "result": "The dataset spans 30 km of trajectories and 40,000 m\u00b2, supporting benchmarks for NVS and relocalisation in diverse environments.", "conclusion": "Oxford Day-and-Night provides a unique, realistic platform for evaluating models in challenging lighting and motion conditions."}}
{"id": "2408.08959", "pdf": "https://arxiv.org/pdf/2408.08959", "abs": "https://arxiv.org/abs/2408.08959", "authors": ["Jinwei Hu", "Yi Dong", "Xiaowei Huang"], "title": "Trust-Oriented Adaptive Guardrails for Large Language Models", "categories": ["cs.AI", "cs.CL"], "comment": "Under Review", "summary": "Guardrail, an emerging mechanism designed to ensure that large language\nmodels (LLMs) align with human values by moderating harmful or toxic responses,\nrequires a sociotechnical approach in their design. This paper addresses a\ncritical issue: existing guardrails lack a well-founded methodology to\naccommodate the diverse needs of different user groups, particularly concerning\naccess rights. Supported by trust modeling (primarily on `social' aspect) and\nenhanced with online in-context learning via retrieval-augmented generation (on\n`technical' aspect), we introduce an adaptive guardrail mechanism, to\ndynamically moderate access to sensitive content based on user trust metrics.\nUser trust metrics, defined as a novel combination of direct interaction trust\nand authority-verified trust, enable the system to precisely tailor the\nstrictness of content moderation by aligning with the user's credibility and\nthe specific context of their inquiries. Our empirical evaluation demonstrates\nthe effectiveness of the adaptive guardrail in meeting diverse user needs,\noutperforming existing guardrails while securing sensitive information and\nprecisely managing potentially hazardous content through a context-aware\nknowledge base. To the best of our knowledge, this work is the first to\nintroduce trust-oriented concept into a guardrail system, offering a scalable\nsolution that enriches the discourse on ethical deployment for next-generation\nLLM service.", "AI": {"tldr": "The paper introduces an adaptive guardrail mechanism for LLMs, using trust metrics to dynamically moderate content access, outperforming existing methods.", "motivation": "Existing guardrails lack a methodology to address diverse user needs, especially access rights, requiring a sociotechnical solution.", "method": "Combines trust modeling (social aspect) and retrieval-augmented generation (technical aspect) to create adaptive guardrails based on user trust metrics.", "result": "Empirical evaluation shows the adaptive guardrail effectively meets diverse user needs, secures sensitive content, and manages hazardous material contextually.", "conclusion": "This is the first trust-oriented guardrail system, offering a scalable solution for ethical LLM deployment."}}
{"id": "2506.03317", "pdf": "https://arxiv.org/pdf/2506.03317", "abs": "https://arxiv.org/abs/2506.03317", "authors": ["Yuntian Wang", "Zafer Yilmaz", "Yuhang Li", "Edward Liu", "Eric Ahlberg", "Farid Ghahari", "Ertugrul Taciroglu", "Aydogan Ozcan"], "title": "Structural Vibration Monitoring with Diffractive Optical Processors", "categories": ["physics.optics", "cs.CV", "cs.LG", "physics.app-ph"], "comment": "33 Pages, 8 Figures, 1 Table", "summary": "Structural Health Monitoring (SHM) is vital for maintaining the safety and\nlongevity of civil infrastructure, yet current solutions remain constrained by\ncost, power consumption, scalability, and the complexity of data processing.\nHere, we present a diffractive vibration monitoring system, integrating a\njointly optimized diffractive layer with a shallow neural network-based backend\nto remotely extract 3D structural vibration spectra, offering a low-power,\ncost-effective and scalable solution. This architecture eliminates the need for\ndense sensor arrays or extensive data acquisition; instead, it uses a\nspatially-optimized passive diffractive layer that encodes 3D structural\ndisplacements into modulated light, captured by a minimal number of detectors\nand decoded in real-time by shallow and low-power neural networks to\nreconstruct the 3D displacement spectra of structures. The diffractive system's\nefficacy was demonstrated both numerically and experimentally using\nmillimeter-wave illumination on a laboratory-scale building model with a\nprogrammable shake table. Our system achieves more than an order-of-magnitude\nimprovement in accuracy over conventional optics or separately trained modules,\nestablishing a foundation for high-throughput 3D monitoring of structures.\nBeyond SHM, the 3D vibration monitoring capabilities of this cost-effective and\ndata-efficient framework establish a new computational sensing modality with\npotential applications in disaster resilience, aerospace diagnostics, and\nautonomous navigation, where energy efficiency, low latency, and\nhigh-throughput are critical.", "AI": {"tldr": "A diffractive vibration monitoring system combines a passive diffractive layer with shallow neural networks for low-power, scalable 3D structural health monitoring.", "motivation": "Current SHM solutions are limited by cost, power, scalability, and data complexity.", "method": "Integrates a diffractive layer to encode 3D displacements into light, decoded by shallow neural networks.", "result": "Achieves significant accuracy improvement over conventional methods, demonstrated numerically and experimentally.", "conclusion": "Offers a cost-effective, data-efficient solution for SHM with broader applications in disaster resilience, aerospace, and navigation."}}
{"id": "2506.04019", "pdf": "https://arxiv.org/pdf/2506.04019", "abs": "https://arxiv.org/abs/2506.04019", "authors": ["Neeva Oza", "Ishaan Govil", "Parul Gupta", "Dinesh Khandelwal", "Dinesh Garg", "Parag Singla"], "title": "CETBench: A Novel Dataset constructed via Transformations over Programs for Benchmarking LLMs for Code-Equivalence Checking", "categories": ["cs.SE", "cs.CL", "cs.LG", "cs.PL", "68-02 (Primary) 68T50, 68T07, 68N19, 68N30 (Secondary)", "I.2.7; I.2.6; I.2.5; D.3.0; D.3.3; D.3.1; F.3.2; F.3.1; F.3.3;\n  D.2.3; D.2.5"], "comment": null, "summary": "LLMs have been extensively used for the task of automated code generation. In\nthis work, we examine the applicability of LLMs for the related but relatively\nunexplored task of code-equivalence checking, i.e., given two programs, whether\nthey are functionally equivalent or not. This is an important problem since\nbenchmarking code equivalence can play a critical role in evaluating LLM\ncapabilities for tasks such as code re-writing and code translation. Towards\nthis end, we present CETBench - Code Equivalence with Transformations\nBenchmark, constructed via a repository of programs, where two programs in the\nrepository may be solving the same or different tasks. Each instance in our\ndataset is obtained by taking a pair of programs in the repository and applying\na random series of pre-defined code transformations, resulting in\n(non-)equivalent pairs. Our analysis on this dataset reveals a surprising\nfinding that very simple code transformations in the underlying pair of\nprograms can result in a significant drop in performance of SOTA LLMs for the\ntask of code-equivalence checking. To remedy this, we present a simple\nfine-tuning-based approach to boost LLM performance on the transformed pairs of\nprograms. Our approach for dataset generation is generic, and can be used with\nrepositories with varying program difficulty levels and allows for applying\nvarying numbers as well as kinds of transformations. In our experiments, we\nperform ablations over the difficulty level of original programs, as well as\nthe kind of transformations used in generating pairs for equivalence checking.\nOur analysis presents deep insights into the working of LLMs for the task of\ncode-equivalence, and points to the fact that they may still be far from what\ncould be termed as a semantic understanding of the underlying code.", "AI": {"tldr": "The paper explores LLMs for code-equivalence checking, introduces CETBench for benchmarking, and finds simple transformations significantly reduce LLM performance. A fine-tuning approach is proposed to improve results.", "motivation": "To evaluate LLMs' capabilities in code-equivalence checking, a critical task for assessing code re-writing and translation, and to address the lack of benchmarks in this area.", "method": "Introduces CETBench, a dataset created by applying random code transformations to program pairs, and proposes a fine-tuning approach to enhance LLM performance.", "result": "Simple code transformations cause a notable performance drop in SOTA LLMs, but fine-tuning improves their accuracy on transformed pairs.", "conclusion": "LLMs lack deep semantic understanding of code, and the proposed dataset and fine-tuning method offer a way to benchmark and improve their performance."}}
{"id": "2506.04225", "pdf": "https://arxiv.org/pdf/2506.04225", "abs": "https://arxiv.org/abs/2506.04225", "authors": ["Tianyu Huang", "Wangguandong Zheng", "Tengfei Wang", "Yuhao Liu", "Zhenwei Wang", "Junta Wu", "Jie Jiang", "Hui Li", "Rynson W. H. Lau", "Wangmeng Zuo", "Chunchao Guo"], "title": "Voyager: Long-Range and World-Consistent Video Diffusion for Explorable 3D Scene Generation", "categories": ["cs.CV"], "comment": null, "summary": "Real-world applications like video gaming and virtual reality often demand\nthe ability to model 3D scenes that users can explore along custom camera\ntrajectories. While significant progress has been made in generating 3D objects\nfrom text or images, creating long-range, 3D-consistent, explorable 3D scenes\nremains a complex and challenging problem. In this work, we present Voyager, a\nnovel video diffusion framework that generates world-consistent 3D point-cloud\nsequences from a single image with user-defined camera path. Unlike existing\napproaches, Voyager achieves end-to-end scene generation and reconstruction\nwith inherent consistency across frames, eliminating the need for 3D\nreconstruction pipelines (e.g., structure-from-motion or multi-view stereo).\nOur method integrates three key components: 1) World-Consistent Video\nDiffusion: A unified architecture that jointly generates aligned RGB and depth\nvideo sequences, conditioned on existing world observation to ensure global\ncoherence 2) Long-Range World Exploration: An efficient world cache with point\nculling and an auto-regressive inference with smooth video sampling for\niterative scene extension with context-aware consistency, and 3) Scalable Data\nEngine: A video reconstruction pipeline that automates camera pose estimation\nand metric depth prediction for arbitrary videos, enabling large-scale, diverse\ntraining data curation without manual 3D annotations. Collectively, these\ndesigns result in a clear improvement over existing methods in visual quality\nand geometric accuracy, with versatile applications.", "AI": {"tldr": "Voyager is a video diffusion framework that generates 3D-consistent point-cloud sequences from a single image and user-defined camera paths, eliminating the need for traditional 3D reconstruction pipelines.", "motivation": "The challenge of creating long-range, 3D-consistent explorable scenes from single images or text, which existing methods struggle with.", "method": "Voyager integrates world-consistent video diffusion, long-range world exploration with a world cache, and a scalable data engine for automated training data curation.", "result": "Improved visual quality and geometric accuracy over existing methods, with versatile applications.", "conclusion": "Voyager offers a novel, efficient solution for generating explorable 3D scenes with inherent consistency, advancing the field beyond traditional pipelines."}}
{"id": "2410.02165", "pdf": "https://arxiv.org/pdf/2410.02165", "abs": "https://arxiv.org/abs/2410.02165", "authors": ["Yucheng Chu", "Hang Li", "Kaiqi Yang", "Harry Shomer", "Hui Liu", "Yasemin Copur-Gencturk", "Jiliang Tang"], "title": "A LLM-Powered Automatic Grading Framework with Human-Level Guidelines Optimization", "categories": ["cs.AI", "cs.CL"], "comment": "EDM 2025 Long Paper", "summary": "Open-ended short-answer questions (SAGs) have been widely recognized as a\npowerful tool for providing deeper insights into learners' responses in the\ncontext of learning analytics (LA). However, SAGs often present challenges in\npractice due to the high grading workload and concerns about inconsistent\nassessments. With recent advancements in natural language processing (NLP),\nautomatic short-answer grading (ASAG) offers a promising solution to these\nchallenges. Despite this, current ASAG algorithms are often limited in\ngeneralizability and tend to be tailored to specific questions. In this paper,\nwe propose a unified multi-agent ASAG framework, GradeOpt, which leverages\nlarge language models (LLMs) as graders for SAGs. More importantly, GradeOpt\nincorporates two additional LLM-based agents - the reflector and the refiner -\ninto the multi-agent system. This enables GradeOpt to automatically optimize\nthe original grading guidelines by performing self-reflection on its errors.\nThrough experiments on a challenging ASAG task, namely the grading of\npedagogical content knowledge (PCK) and content knowledge (CK) questions,\nGradeOpt demonstrates superior performance in grading accuracy and behavior\nalignment with human graders compared to representative baselines. Finally,\ncomprehensive ablation studies confirm the effectiveness of the individual\ncomponents designed in GradeOpt.", "AI": {"tldr": "GradeOpt is a multi-agent ASAG framework using LLMs to grade short-answer questions, improving accuracy and alignment with human graders.", "motivation": "Address challenges in grading SAGs, like workload and inconsistency, by leveraging NLP advancements.", "method": "Proposes GradeOpt, a unified framework with LLM-based graders, a reflector, and a refiner to optimize grading guidelines.", "result": "Outperforms baselines in grading accuracy and alignment with human graders, especially for PCK and CK questions.", "conclusion": "GradeOpt's components are effective, offering a scalable solution for ASAG tasks."}}
{"id": "2506.03321", "pdf": "https://arxiv.org/pdf/2506.03321", "abs": "https://arxiv.org/abs/2506.03321", "authors": ["Victor H. Cid", "James Mork"], "title": "Enhancing Automatic PT Tagging for MEDLINE Citations Using Transformer-Based Models", "categories": ["cs.DL", "cs.LG", "I.2.7; H.3.3; H.3.5"], "comment": "26 pages, 8 tables, 3 figures", "summary": "We investigated the feasibility of predicting Medical Subject Headings (MeSH)\nPublication Types (PTs) from MEDLINE citation metadata using pre-trained\nTransformer-based models BERT and DistilBERT. This study addresses limitations\nin the current automated indexing process, which relies on legacy NLP\nalgorithms. We evaluated monolithic multi-label classifiers and binary\nclassifier ensembles to enhance the retrieval of biomedical literature. Results\ndemonstrate the potential of Transformer models to significantly improve PT\ntagging accuracy, paving the way for scalable, efficient biomedical indexing.", "AI": {"tldr": "Transformer models like BERT and DistilBERT show promise in improving MeSH PT tagging accuracy, addressing limitations of legacy NLP methods.", "motivation": "To overcome the limitations of current automated indexing processes that rely on outdated NLP algorithms.", "method": "Evaluated monolithic multi-label classifiers and binary classifier ensembles using BERT and DistilBERT.", "result": "Transformer models significantly improve PT tagging accuracy.", "conclusion": "These models offer scalable and efficient solutions for biomedical literature indexing."}}
{"id": "2506.04228", "pdf": "https://arxiv.org/pdf/2506.04228", "abs": "https://arxiv.org/abs/2506.04228", "authors": ["Sihui Ji", "Hao Luo", "Xi Chen", "Yuanpeng Tu", "Yiyang Wang", "Hengshuang Zhao"], "title": "LayerFlow: A Unified Model for Layer-aware Video Generation", "categories": ["cs.CV"], "comment": "Project Page: https://sihuiji.github.io/LayerFlow-Page/", "summary": "We present LayerFlow, a unified solution for layer-aware video generation.\nGiven per-layer prompts, LayerFlow generates videos for the transparent\nforeground, clean background, and blended scene. It also supports versatile\nvariants like decomposing a blended video or generating the background for the\ngiven foreground and vice versa. Starting from a text-to-video diffusion\ntransformer, we organize the videos for different layers as sub-clips, and\nleverage layer embeddings to distinguish each clip and the corresponding\nlayer-wise prompts. In this way, we seamlessly support the aforementioned\nvariants in one unified framework. For the lack of high-quality layer-wise\ntraining videos, we design a multi-stage training strategy to accommodate\nstatic images with high-quality layer annotations. Specifically, we first train\nthe model with low-quality video data. Then, we tune a motion LoRA to make the\nmodel compatible with static frames. Afterward, we train the content LoRA on\nthe mixture of image data with high-quality layered images along with\ncopy-pasted video data. During inference, we remove the motion LoRA thus\ngenerating smooth videos with desired layers.", "AI": {"tldr": "LayerFlow is a unified framework for layer-aware video generation, supporting tasks like decomposing blended videos or generating backgrounds/foregrounds. It uses layer embeddings and a multi-stage training strategy due to lack of high-quality layer-wise training videos.", "motivation": "To address the challenge of generating layer-aware videos with transparency and versatility, given the scarcity of high-quality training data.", "method": "Utilizes a text-to-video diffusion transformer with layer embeddings for sub-clips, and a multi-stage training strategy involving low-quality videos, motion LoRA, and content LoRA.", "result": "Enables smooth video generation with desired layers, supporting various tasks like decomposition and background/foreground generation.", "conclusion": "LayerFlow provides a flexible and unified solution for layer-aware video generation, overcoming data limitations through innovative training."}}
{"id": "2410.16270", "pdf": "https://arxiv.org/pdf/2410.16270", "abs": "https://arxiv.org/abs/2410.16270", "authors": ["Lingyu Li", "Yixu Wang", "Haiquan Zhao", "Shuqi Kong", "Yan Teng", "Chunbo Li", "Yingchun Wang"], "title": "Reflection-Bench: Evaluating Epistemic Agency in Large Language Models", "categories": ["cs.AI"], "comment": "29 pages, 19 figures, 9 tables", "summary": "With large language models (LLMs) increasingly deployed as cognitive engines\nfor AI agents, the reliability and effectiveness critically hinge on their\nintrinsic epistemic agency, which remains understudied. Epistemic agency, the\nability to flexibly construct, adapt, and monitor beliefs about dynamic\nenvironments, represents a base-model-level capacity independent of specific\ntools, modules, or applications. We characterize the holistic process\nunderlying epistemic agency, which unfolds in seven interrelated dimensions:\nprediction, decision-making, perception, memory, counterfactual thinking,\nbelief updating, and meta-reflection. Correspondingly, we propose\nReflection-Bench, a cognitive-psychology-inspired benchmark consisting of seven\ntasks with long-term relevance and minimization of data leakage. Through a\ncomprehensive evaluation of 16 models using three prompting strategies, we\nidentify a clear three-tier performance hierarchy and significant limitations\nof current LLMs, particularly in meta-reflection capabilities. While\nstate-of-the-art LLMs demonstrate rudimentary signs of epistemic agency, our\nfindings suggest several promising research directions, including enhancing\ncore cognitive functions, improving cross-functional coordination, and\ndeveloping adaptive processing mechanisms. Our code and data are available at\nhttps://github.com/AI45Lab/ReflectionBench.", "AI": {"tldr": "The paper studies epistemic agency in LLMs, proposing a benchmark (Reflection-Bench) to evaluate seven cognitive dimensions, revealing limitations in current models, especially in meta-reflection.", "motivation": "To address the understudied intrinsic epistemic agency of LLMs, which is crucial for their reliability and effectiveness as AI agents.", "method": "Proposes Reflection-Bench, a cognitive-psychology-inspired benchmark with seven tasks, evaluating 16 models using three prompting strategies.", "result": "Identifies a three-tier performance hierarchy, highlighting significant limitations in current LLMs, particularly in meta-reflection.", "conclusion": "While state-of-the-art LLMs show rudimentary epistemic agency, improvements in core cognitive functions, cross-functional coordination, and adaptive processing are needed."}}
{"id": "2506.03464", "pdf": "https://arxiv.org/pdf/2506.03464", "abs": "https://arxiv.org/abs/2506.03464", "authors": ["Yang Cai", "Haipeng Luo", "Chen-Yu Wei", "Weiqiang Zheng"], "title": "From Average-Iterate to Last-Iterate Convergence in Games: A Reduction and Its Applications", "categories": ["cs.GT", "cs.LG", "math.OC"], "comment": "21 pages", "summary": "The convergence of online learning algorithms in games under self-play is a\nfundamental question in game theory and machine learning. Among various notions\nof convergence, last-iterate convergence is particularly desirable, as it\nreflects the actual decisions made by the learners and captures the day-to-day\nbehavior of the learning dynamics. While many algorithms are known to converge\nin the average-iterate, achieving last-iterate convergence typically requires\nconsiderably more effort in both the design and the analysis of the algorithm.\nSomewhat surprisingly, we show in this paper that for a large family of games,\nthere exists a simple black-box reduction that transforms the average iterates\nof an uncoupled learning dynamics into the last iterates of a new uncoupled\nlearning dynamics, thus also providing a reduction from last-iterate\nconvergence to average-iterate convergence. Our reduction applies to games\nwhere each player's utility is linear in both their own strategy and the joint\nstrategy of all opponents. This family includes two-player bimatrix games and\ngeneralizations such as multi-player polymatrix games. By applying our\nreduction to the Optimistic Multiplicative Weights Update algorithm, we obtain\nnew state-of-the-art last-iterate convergence rates for uncoupled learning\ndynamics in two-player zero-sum normal-form games: (1) an $O(\\frac{\\log d}{T})$\nlast-iterate convergence rate under gradient feedback, representing an\nexponential improvement in the dependence on the dimension $d$ (i.e., the\nmaximum number of actions available to either player); and (2) an\n$\\widetilde{O}(d^{\\frac{1}{5}} T^{-\\frac{1}{5}})$ last-iterate convergence rate\nunder bandit feedback, improving upon the previous best rates of\n$\\widetilde{O}(\\sqrt{d} T^{-\\frac{1}{8}})$ and $\\widetilde{O}(\\sqrt{d}\nT^{-\\frac{1}{6}})$.", "AI": {"tldr": "A black-box reduction transforms average-iterate convergence to last-iterate convergence for uncoupled learning dynamics in games with linear utilities, improving convergence rates.", "motivation": "To address the challenge of achieving last-iterate convergence in online learning algorithms, which reflects actual learner decisions and day-to-day behavior.", "method": "Introduces a simple black-box reduction for games with linear utilities, applying it to the Optimistic Multiplicative Weights Update algorithm.", "result": "Achieves state-of-the-art last-iterate convergence rates: O(log d/T) for gradient feedback and ~O(d^(1/5) T^(-1/5)) for bandit feedback.", "conclusion": "The reduction simplifies achieving last-iterate convergence and significantly improves convergence rates in uncoupled learning dynamics."}}
{"id": "2308.09583", "pdf": "https://arxiv.org/pdf/2308.09583", "abs": "https://arxiv.org/abs/2308.09583", "authors": ["Haipeng Luo", "Qingfeng Sun", "Can Xu", "Pu Zhao", "Jianguang Lou", "Chongyang Tao", "Xiubo Geng", "Qingwei Lin", "Shifeng Chen", "Yansong Tang", "Dongmei Zhang"], "title": "WizardMath: Empowering Mathematical Reasoning for Large Language Models via Reinforced Evol-Instruct", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "This paper has been accepted to ICLR 2025 as an Oral presentation", "summary": "Large language models (LLMs), such as GPT-4, have shown remarkable\nperformance in natural language processing (NLP) tasks, including challenging\nmathematical reasoning. However, most existing open-source models are only\npre-trained on large-scale internet data and without math-related optimization.\nIn this paper, we present WizardMath, which enhances the mathematical CoT\nreasoning abilities of LLMs without using external python tools, by applying\nour proposed Reinforcement Learning from Evol-Instruct Feedback (RLEIF) method\nto the domain of math. Through extensive experiments on two mathematical\nreasoning benchmarks, namely GSM8k and MATH, we reveal the extraordinary\ncapabilities of our model. Remarkably, WizardMath-Mistral 7B surpasses top-tier\nopen-source LLMs by a substantial margin with higher data efficiency.\nFurthermore, WizardMath 70B even outperforms GPT-3.5-Turbo, Claude 2, Gemini\nPro and GPT-4-early-version. Additionally, our preliminary exploration\nhighlights the pivotal role of instruction evolution and process supervision in\nachieving exceptional math performance. For more details refer to\nhttps://github.com/nlpxucan/WizardLM", "AI": {"tldr": "WizardMath enhances LLMs' mathematical reasoning using RLEIF, outperforming top models like GPT-4 on benchmarks GSM8k and MATH.", "motivation": "Existing open-source LLMs lack math-specific optimization despite strong NLP performance.", "method": "Uses Reinforcement Learning from Evol-Instruct Feedback (RLEIF) for math reasoning without external tools.", "result": "WizardMath-Mistral 7B surpasses top open-source LLMs; WizardMath 70B beats GPT-3.5-Turbo, Claude 2, Gemini Pro, and GPT-4-early-version.", "conclusion": "Instruction evolution and process supervision are key to exceptional math performance in LLMs."}}
{"id": "2506.03180", "pdf": "https://arxiv.org/pdf/2506.03180", "abs": "https://arxiv.org/abs/2506.03180", "authors": ["Jan Ignatowicz", "Krzysztof Kutt", "Grzegorz J. Nalepa"], "title": "Knowledge Graphs for Digitized Manuscripts in Jagiellonian Digital Library Application", "categories": ["cs.DL", "cs.CV"], "comment": null, "summary": "Digitizing cultural heritage collections has become crucial for preservation\nof historical artifacts and enhancing their availability to the wider public.\nGalleries, libraries, archives and museums (GLAM institutions) are actively\ndigitizing their holdings and creates extensive digital collections. Those\ncollections are often enriched with metadata describing items but not exactly\ntheir contents. The Jagiellonian Digital Library, standing as a good example of\nsuch an effort, offers datasets accessible through protocols like OAI-PMH.\nDespite these improvements, metadata completeness and standardization continue\nto pose substantial obstacles, limiting the searchability and potential\nconnections between collections. To deal with these challenges, we explore an\nintegrated methodology of computer vision (CV), artificial intelligence (AI),\nand semantic web technologies to enrich metadata and construct knowledge graphs\nfor digitized manuscripts and incunabula.", "AI": {"tldr": "The paper explores using CV, AI, and semantic web technologies to enhance metadata and build knowledge graphs for digitized cultural heritage collections, addressing challenges in metadata completeness and standardization.", "motivation": "Digitizing cultural heritage is vital for preservation and accessibility, but metadata limitations hinder searchability and connections between collections.", "method": "Integrated approach combining computer vision, AI, and semantic web technologies to enrich metadata and create knowledge graphs.", "result": "Proposes a solution to improve metadata quality and inter-collection linkages for digitized manuscripts and incunabula.", "conclusion": "The methodology aims to overcome metadata challenges, enhancing the utility of digital cultural heritage collections."}}
{"id": "2501.05790", "pdf": "https://arxiv.org/pdf/2501.05790", "abs": "https://arxiv.org/abs/2501.05790", "authors": ["Taywon Min", "Haeone Lee", "Yongchan Kwon", "Kimin Lee"], "title": "Understanding Impact of Human Feedback via Influence Functions", "categories": ["cs.AI", "cs.HC", "cs.LG"], "comment": "Accepted at ACL 2025, Source code:\n  https://github.com/mintaywon/IF_RLHF", "summary": "In Reinforcement Learning from Human Feedback (RLHF), it is crucial to learn\nsuitable reward models from human feedback to align large language models\n(LLMs) with human intentions. However, human feedback can often be noisy,\ninconsistent, or biased, especially when evaluating complex responses. Such\nfeedback can lead to misaligned reward signals, potentially causing unintended\nside effects during the RLHF process. To address these challenges, we explore\nthe use of influence functions to measure the impact of human feedback on the\nperformance of reward models. We propose a compute-efficient approximation\nmethod that enables the application of influence functions to LLM-based reward\nmodels and large-scale preference datasets. In our experiments, we demonstrate\ntwo key applications of influence functions: (1) detecting common forms of\nlabeler bias in human feedback datasets and (2) guiding labelers to refine\ntheir strategies to align more closely with expert feedback. By quantifying the\nimpact of human feedback on reward models, we believe that influence functions\ncan enhance feedback interpretability and contribute to scalable oversight in\nRLHF, helping labelers provide more accurate and consistent feedback. Source\ncode is available at https://github.com/mintaywon/IF_RLHF", "AI": {"tldr": "The paper explores using influence functions to address noisy, inconsistent, or biased human feedback in RLHF, proposing a compute-efficient method to analyze and improve reward models.", "motivation": "Human feedback in RLHF can be noisy or biased, leading to misaligned reward signals and unintended side effects. The study aims to enhance feedback interpretability and alignment.", "method": "The authors propose a compute-efficient approximation of influence functions for LLM-based reward models and large-scale preference datasets.", "result": "Experiments show influence functions can detect labeler bias and guide labelers to refine feedback strategies, improving alignment with expert feedback.", "conclusion": "Influence functions enhance feedback interpretability and scalable oversight in RLHF, aiding labelers in providing more accurate and consistent feedback."}}
{"id": "2506.03467", "pdf": "https://arxiv.org/pdf/2506.03467", "abs": "https://arxiv.org/abs/2506.03467", "authors": ["Hang Liu", "Anna Scaglione", "Sean Peisert"], "title": "Differentially Private Distribution Release of Gaussian Mixture Models via KL-Divergence Minimization", "categories": ["cs.IT", "cs.CR", "cs.LG", "eess.SP", "math.IT", "stat.ME"], "comment": "This work has been submitted to the IEEE for possible publication", "summary": "Gaussian Mixture Models (GMMs) are widely used statistical models for\nrepresenting multi-modal data distributions, with numerous applications in data\nmining, pattern recognition, data simulation, and machine learning. However,\nrecent research has shown that releasing GMM parameters poses significant\nprivacy risks, potentially exposing sensitive information about the underlying\ndata. In this paper, we address the challenge of releasing GMM parameters while\nensuring differential privacy (DP) guarantees. Specifically, we focus on the\nprivacy protection of mixture weights, component means, and covariance\nmatrices. We propose to use Kullback-Leibler (KL) divergence as a utility\nmetric to assess the accuracy of the released GMM, as it captures the joint\nimpact of noise perturbation on all the model parameters. To achieve privacy,\nwe introduce a DP mechanism that adds carefully calibrated random perturbations\nto the GMM parameters. Through theoretical analysis, we quantify the effects of\nprivacy budget allocation and perturbation statistics on the DP guarantee, and\nderive a tractable expression for evaluating KL divergence. We formulate and\nsolve an optimization problem to minimize the KL divergence between the\nreleased and original models, subject to a given $(\\epsilon, \\delta)$-DP\nconstraint. Extensive experiments on both synthetic and real-world datasets\ndemonstrate that our approach achieves strong privacy guarantees while\nmaintaining high utility.", "AI": {"tldr": "The paper proposes a differentially private mechanism for releasing Gaussian Mixture Model (GMM) parameters, using KL divergence for utility assessment and optimizing noise perturbation to balance privacy and accuracy.", "motivation": "GMMs are widely used but releasing their parameters risks privacy. The paper aims to ensure differential privacy while maintaining model utility.", "method": "A DP mechanism adds calibrated noise to GMM parameters. KL divergence measures utility, and optimization minimizes it under DP constraints.", "result": "The approach achieves strong privacy guarantees and high utility, validated on synthetic and real-world datasets.", "conclusion": "The proposed method effectively balances privacy and utility for GMM parameter release."}}
{"id": "2310.12049", "pdf": "https://arxiv.org/pdf/2310.12049", "abs": "https://arxiv.org/abs/2310.12049", "authors": ["Patrick Y. Wu", "Jonathan Nagler", "Joshua A. Tucker", "Solomon Messing"], "title": "Concept-Guided Chain-of-Thought Prompting for Pairwise Comparison Scoring of Texts with Large Language Models", "categories": ["cs.CL", "cs.CY"], "comment": "10 pages, 2 figures. Appears in 2024 IEEE International Conference on\n  Big Data (BigData). Please cite the published version:\n  10.1109/BigData62323.2024.10825235", "summary": "Existing text scoring methods require a large corpus, struggle with short\ntexts, or require hand-labeled data. We develop a text scoring framework that\nleverages generative large language models (LLMs) to (1) set texts against the\nbackdrop of information from the near-totality of the web and digitized media,\nand (2) effectively transform pairwise text comparisons from a reasoning\nproblem to a pattern recognition task. Our approach, concept-guided\nchain-of-thought (CGCoT), utilizes a chain of researcher-designed prompts with\nan LLM to generate a concept-specific breakdown for each text, akin to guidance\nprovided to human coders. We then pairwise compare breakdowns using an LLM and\naggregate answers into a score using a probability model. We apply this\napproach to better understand speech reflecting aversion to specific political\nparties on Twitter, a topic that has commanded increasing interest because of\nits potential contributions to democratic backsliding. We achieve stronger\ncorrelations with human judgments than widely used unsupervised text scoring\nmethods like Wordfish. In a supervised setting, besides a small pilot dataset\nto develop CGCoT prompts, our measures require no additional hand-labeled data\nand produce predictions on par with RoBERTa-Large fine-tuned on thousands of\nhand-labeled tweets. This project showcases the potential of combining human\nexpertise and LLMs for scoring tasks.", "AI": {"tldr": "A text scoring framework using generative LLMs (CGCoT) improves accuracy for short texts without needing large labeled datasets, outperforming traditional methods like Wordfish and matching supervised models like RoBERTa-Large.", "motivation": "Existing text scoring methods are limited by corpus size, short text handling, or reliance on labeled data. The goal is to leverage LLMs for better performance.", "method": "CGCoT uses researcher-designed prompts with LLMs to generate concept-specific breakdowns, compares them pairwise, and aggregates scores via a probability model.", "result": "CGCoT achieves higher correlation with human judgments than unsupervised methods (e.g., Wordfish) and matches supervised models (e.g., RoBERTa-Large) with minimal labeled data.", "conclusion": "Combining human expertise with LLMs (CGCoT) shows promise for text scoring tasks, especially for short texts and limited labeled data."}}
{"id": "2501.07930", "pdf": "https://arxiv.org/pdf/2501.07930", "abs": "https://arxiv.org/abs/2501.07930", "authors": ["Thibaut Boissin", "Franck Mamalet", "Thomas Fel", "Agustin Martin Picard", "Thomas Massena", "Mathieu Serrurier"], "title": "An Adaptive Orthogonal Convolution Scheme for Efficient and Flexible CNN Architectures", "categories": ["cs.AI", "cs.NE"], "comment": null, "summary": "Orthogonal convolutional layers are valuable components in multiple areas of\nmachine learning, such as adversarial robustness, normalizing flows, GANs, and\nLipschitz-constrained models. Their ability to preserve norms and ensure stable\ngradient propagation makes them valuable for a large range of problems. Despite\ntheir promise, the deployment of orthogonal convolution in large-scale\napplications is a significant challenge due to computational overhead and\nlimited support for modern features like strides, dilations, group\nconvolutions, and transposed convolutions. In this paper, we introduce AOC\n(Adaptative Orthogonal Convolution), a scalable method that extends a previous\nmethod (BCOP), effectively overcoming existing limitations in the construction\nof orthogonal convolutions. This advancement unlocks the construction of\narchitectures that were previously considered impractical. We demonstrate\nthrough our experiments that our method produces expressive models that become\nincreasingly efficient as they scale. To foster further advancement, we provide\nan open-source python package implementing this method, called Orthogonium (\nhttps://github.com/deel-ai/orthogonium ) .", "AI": {"tldr": "AOC (Adaptive Orthogonal Convolution) is introduced to overcome computational and feature limitations of orthogonal convolutions, enabling scalable and efficient models.", "motivation": "Orthogonal convolutions are valuable but face deployment challenges in large-scale applications due to computational overhead and limited feature support.", "method": "AOC extends BCOP to address limitations like strides, dilations, group convolutions, and transposed convolutions.", "result": "AOC produces expressive, scalable models with increasing efficiency, demonstrated through experiments.", "conclusion": "AOC unlocks previously impractical architectures, with an open-source package (Orthogonium) provided for further research."}}
{"id": "2506.03470", "pdf": "https://arxiv.org/pdf/2506.03470", "abs": "https://arxiv.org/abs/2506.03470", "authors": ["Liam Hodgkinson", "Zhichao Wang", "Michael W. Mahoney"], "title": "Models of Heavy-Tailed Mechanistic Universality", "categories": ["stat.ML", "cs.LG"], "comment": "40 pages, 4 figures", "summary": "Recent theoretical and empirical successes in deep learning, including the\ncelebrated neural scaling laws, are punctuated by the observation that many\nobjects of interest tend to exhibit some form of heavy-tailed or power law\nbehavior. In particular, the prevalence of heavy-tailed spectral densities in\nJacobians, Hessians, and weight matrices has led to the introduction of the\nconcept of heavy-tailed mechanistic universality (HT-MU). Multiple lines of\nempirical evidence suggest a robust correlation between heavy-tailed metrics\nand model performance, indicating that HT-MU may be a fundamental aspect of\ndeep learning efficacy. Here, we propose a general family of random matrix\nmodels -- the high-temperature Marchenko-Pastur (HTMP) ensemble -- to explore\nattributes that give rise to heavy-tailed behavior in trained neural networks.\nUnder this model, spectral densities with power laws on (upper and lower) tails\narise through a combination of three independent factors (complex correlation\nstructures in the data; reduced temperatures during training; and reduced\neigenvector entropy), appearing as an implicit bias in the model structure, and\nthey can be controlled with an \"eigenvalue repulsion\" parameter. Implications\nof our model on other appearances of heavy tails, including neural scaling\nlaws, optimizer trajectories, and the five-plus-one phases of neural network\ntraining, are discussed.", "AI": {"tldr": "The paper explores heavy-tailed behavior in deep learning, proposing the HTMP ensemble to model it and linking it to performance.", "motivation": "To understand the prevalence and impact of heavy-tailed metrics (e.g., in Jacobians, Hessians) in deep learning, suggesting HT-MU as a key factor in model efficacy.", "method": "Introduces the high-temperature Marchenko-Pastur (HTMP) ensemble to model heavy-tailed spectral densities, analyzing factors like correlation structures, training temperatures, and eigenvector entropy.", "result": "Shows that heavy-tailed behavior arises from implicit biases in model structure, controllable via an eigenvalue repulsion parameter, and discusses implications for neural scaling laws and training phases.", "conclusion": "HT-MU is fundamental in deep learning, with the HTMP model providing insights into heavy-tailed phenomena and their control."}}
{"id": "2406.02524", "pdf": "https://arxiv.org/pdf/2406.02524", "abs": "https://arxiv.org/abs/2406.02524", "authors": ["Maciej Besta", "Lorenzo Paleari", "Marcin Copik", "Robert Gerstenberger", "Ales Kubicek", "Piotr Nyczyk", "Patrick Iff", "Eric Schreiber", "Tanja Srindran", "Tomasz Lehmann", "Hubert Niewiadomski", "Torsten Hoefler"], "title": "CheckEmbed: Effective Verification of LLM Solutions to Open-Ended Tasks", "categories": ["cs.CL"], "comment": null, "summary": "Large Language Models (LLMs) are transforming a wide range of domains, yet\nverifying their outputs remains a significant challenge, especially for complex\nopen-ended tasks such as consolidation, summarization, and knowledge\nextraction. To address this, we introduce CheckEmbed (CE): a simple, scalable,\nand accurate verification method. CE reduces each LLM answer to a single\nembedding vector using powerful modern embedding LLM models like\nSFR-Embedding-Mistral. Prior methods such as BERTScore and SelfCheckGPT relied\non weaker encoders like BERT, forcing them to operate at token or sentence\ngranularity. In contrast, CE performs fast, semantically rich comparisons\ndirectly at the whole-answer level, overcoming key limitations in both accuracy\nand scalability. We conduct a comprehensive design and time complexity analysis\nacross 13 verification baselines, including classical text scorers (e.g.,\nBLEU), stability-based methods (e.g., SelfCheckGPT), and generative evaluators\n(e.g., LLM-as-a-Judge), which highlights the effectiveness, efficiency,\nversatility, and simplicity of CE. Empirical results show that CE reliably\ndetects hallucinations in both closed and open-ended tasks. We further present\nevidence that CE generalizes beyond text to other modalities such as vision,\nestablishing it as a practical and versatile verification framework.", "AI": {"tldr": "CheckEmbed (CE) is a scalable and accurate method for verifying LLM outputs by reducing answers to embedding vectors, outperforming prior methods in accuracy and scalability.", "motivation": "Verifying LLM outputs for complex tasks is challenging; existing methods like BERTScore and SelfCheckGPT have limitations in granularity and scalability.", "method": "CE uses modern embedding models (e.g., SFR-Embedding-Mistral) to convert LLM answers into single embedding vectors for fast, semantic comparisons at the whole-answer level.", "result": "CE outperforms 13 baselines in accuracy and scalability, reliably detecting hallucinations in various tasks and generalizing to other modalities like vision.", "conclusion": "CE is a practical, versatile framework for verifying LLM outputs, addressing key limitations of prior methods."}}
{"id": "2506.03365", "pdf": "https://arxiv.org/pdf/2506.03365", "abs": "https://arxiv.org/abs/2506.03365", "authors": ["Artur Grigorev", "Adriana-Simona Mihaita"], "title": "Urban Visibility Hotspots: Quantifying Building Vertex Visibility from Connected Vehicle Trajectories using Spatial Indexing", "categories": ["eess.SY", "cs.CV", "cs.SY", "stat.CO"], "comment": null, "summary": "Effective placement of Out-of-Home advertising and street furniture requires\naccurate identification of locations offering maximum visual exposure to target\naudiences, particularly vehicular traffic. Traditional site selection methods\noften rely on static traffic counts or subjective assessments. This research\nintroduces a data-driven methodology to objectively quantify location\nvisibility by analyzing large-scale connected vehicle trajectory data (sourced\nfrom Compass IoT) within urban environments. We model the dynamic driver\nfield-of-view using a forward-projected visibility area for each vehicle\nposition derived from interpolated trajectories. By integrating this with\nbuilding vertex locations extracted from OpenStreetMap, we quantify the\ncumulative visual exposure, or ``visibility count'', for thousands of potential\npoints of interest near roadways. The analysis reveals that visibility is\nhighly concentrated, identifying specific ``visual hotspots'' that receive\ndisproportionately high exposure compared to average locations. The core\ntechnical contribution involves the construction of a BallTree spatial index\nover building vertices. This enables highly efficient (O(logN) complexity)\nradius queries to determine which vertices fall within the viewing circles of\nmillions of trajectory points across numerous trips, significantly\noutperforming brute-force geometric checks. Analysis reveals two key findings:\n1) Visibility is highly concentrated, identifying distinct 'visual hotspots'\nreceiving disproportionately high exposure compared to average locations. 2)\nThe aggregated visibility counts across vertices conform to a Log-Normal\ndistribution.", "AI": {"tldr": "A data-driven method uses vehicle trajectory data to identify high-visibility locations for Out-of-Home advertising, outperforming traditional static methods.", "motivation": "Traditional site selection for advertising relies on static or subjective methods, lacking objective visibility quantification.", "method": "Analyzes connected vehicle trajectory data to model driver field-of-view, integrating building vertices from OpenStreetMap to compute visibility counts.", "result": "Identifies concentrated 'visual hotspots' with high exposure and shows visibility counts follow a Log-Normal distribution.", "conclusion": "The method provides an efficient, objective way to optimize ad placement by leveraging dynamic visibility analysis."}}
{"id": "2501.16150", "pdf": "https://arxiv.org/pdf/2501.16150", "abs": "https://arxiv.org/abs/2501.16150", "authors": ["Pascal J. Sager", "Benjamin Meyer", "Peng Yan", "Rebekka von Wartburg-Kottler", "Layan Etaiwi", "Aref Enayati", "Gabriel Nobel", "Ahmed Abdulkadir", "Benjamin F. Grewe", "Thilo Stadelmann"], "title": "A Comprehensive Survey of Agents for Computer Use: Foundations, Challenges, and Future Directions", "categories": ["cs.AI", "cs.HC", "cs.SY", "eess.SY"], "comment": null, "summary": "Agents for computer use (ACUs) are an emerging class of systems capable of\nexecuting complex tasks on digital devices - such as desktops, mobile phones,\nand web platforms - given instructions in natural language. These agents can\nautomate tasks by controlling software via low-level actions like mouse clicks\nand touchscreen gestures. However, despite rapid progress, ACUs are not yet\nmature for everyday use.\n  In this survey, we investigate the state-of-the-art, trends, and research\ngaps in the development of practical ACUs. We provide a comprehensive review of\nthe ACU landscape, introducing a unifying taxonomy spanning three dimensions:\n(I) the domain perspective, characterizing agent operating contexts; (II) the\ninteraction perspective, describing observation modalities (e.g., screenshots,\nHTML) and action modalities (e.g., mouse, keyboard, code execution); and (III)\nthe agent perspective, detailing how agents perceive, reason, and learn.\n  We review 87 ACUs and 33 datasets across foundation model-based and classical\napproaches through this taxonomy. Our analysis identifies six major research\ngaps: insufficient generalization, inefficient learning, limited planning, low\ntask complexity in benchmarks, non-standardized evaluation, and a disconnect\nbetween research and practical conditions.\n  To address these gaps, we advocate for: (a) vision-based observations and\nlow-level control to enhance generalization; (b) adaptive learning beyond\nstatic prompting; (c) effective planning and reasoning methods and models; (d)\nbenchmarks that reflect real-world task complexity; (e) standardized evaluation\nbased on task success; (f) aligning agent design with real-world deployment\nconstraints.\n  Together, our taxonomy and analysis establish a foundation for advancing ACU\nresearch toward general-purpose agents for robust and scalable computer use.", "AI": {"tldr": "The paper surveys the state-of-the-art in Agents for Computer Use (ACUs), identifies research gaps, and proposes solutions to advance the field toward practical, general-purpose agents.", "motivation": "To investigate the current state, trends, and gaps in ACUs, aiming to bridge the divide between research and practical deployment.", "method": "The authors review 87 ACUs and 33 datasets, introducing a taxonomy spanning domain, interaction, and agent perspectives.", "result": "Six major research gaps are identified, including insufficient generalization and inefficient learning, with proposed solutions like vision-based observations and adaptive learning.", "conclusion": "The taxonomy and analysis provide a foundation for advancing ACU research toward robust and scalable general-purpose agents."}}
{"id": "2506.03657", "pdf": "https://arxiv.org/pdf/2506.03657", "abs": "https://arxiv.org/abs/2506.03657", "authors": ["Leonardo Martins Bianco", "Christine Keribin", "Zacharie Naulet"], "title": "SubSearch: Robust Estimation and Outlier Detection for Stochastic Block Models via Subgraph Search", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "Community detection is a fundamental task in graph analysis, with methods\noften relying on fitting models like the Stochastic Block Model (SBM) to\nobserved networks. While many algorithms can accurately estimate SBM parameters\nwhen the input graph is a perfect sample from the model, real-world graphs\nrarely conform to such idealized assumptions. Therefore, robust algorithms are\ncrucial-ones that can recover model parameters even when the data deviates from\nthe assumed distribution. In this work, we propose SubSearch, an algorithm for\nrobustly estimating SBM parameters by exploring the space of subgraphs in\nsearch of one that closely aligns with the model's assumptions. Our approach\nalso functions as an outlier detection method, properly identifying nodes\nresponsible for the graph's deviation from the model and going beyond simple\ntechniques like pruning high-degree nodes. Extensive experiments on both\nsynthetic and real-world datasets demonstrate the effectiveness of our method.", "AI": {"tldr": "SubSearch is a robust algorithm for estimating Stochastic Block Model (SBM) parameters by analyzing subgraphs, also detecting outliers in real-world graphs.", "motivation": "Real-world graphs often deviate from idealized SBM assumptions, necessitating robust methods for accurate parameter estimation and outlier detection.", "method": "SubSearch explores subgraphs to find one aligning with SBM assumptions and identifies outlier nodes.", "result": "Experiments on synthetic and real-world datasets show SubSearch's effectiveness in robust parameter estimation and outlier detection.", "conclusion": "SubSearch provides a robust solution for SBM parameter estimation and outlier detection in non-ideal graph data."}}
{"id": "2406.09295", "pdf": "https://arxiv.org/pdf/2406.09295", "abs": "https://arxiv.org/abs/2406.09295", "authors": ["Yuhang Wu", "Wenmeng Yu", "Yean Cheng", "Yan Wang", "Xiaohan Zhang", "Jiazheng Xu", "Ming Ding", "Yuxiao Dong"], "title": "AlignMMBench: Evaluating Chinese Multimodal Alignment in Large Vision-Language Models", "categories": ["cs.CL", "cs.CV"], "comment": null, "summary": "Evaluating the alignment capabilities of large Vision-Language Models (VLMs)\nis essential for determining their effectiveness as helpful assistants.\nHowever, existing benchmarks primarily focus on basic abilities using nonverbal\nmethods, such as yes-no and multiple-choice questions. In this paper, we\naddress this gap by introducing AlignMMBench, which provides more nuanced\nevaluations of alignment capabilities and is the first benchmark specifically\ndesigned for Chinese visual contexts. This benchmark is meticulously curated\nfrom real-world scenarios and internet sources, encompassing thirteen specific\ntasks across three categories, and includes both single-turn and multi-turn\ndialogue scenarios. Incorporating a prompt rewrite strategy, AlignMMBench\nencompasses 1,054 images and 4,978 question-answer pairs. To facilitate the\nevaluation pipeline, we develop CritiqueVLM, a rule-calibrated evaluator that\nexceeds GPT-4's evaluation ability. Additionally, we measure the \"alignment\nscore\", a quantitative metric designed to assess the robustness and stability\nof models across diverse prompts. Finally, we evaluate the performance of\nrepresentative VLMs on AlignMMBench, offering insights into the capabilities\nand limitations of different VLM architectures. The evaluation code and data\nare available at https://github.com/THUDM/AlignMMBench.", "AI": {"tldr": "AlignMMBench is a new benchmark for evaluating Vision-Language Models (VLMs) in Chinese visual contexts, addressing gaps in nuanced alignment assessments. It includes diverse tasks, images, and question-answer pairs, with a rule-calibrated evaluator (CritiqueVLM) and a quantitative \"alignment score.\"", "motivation": "Existing benchmarks lack nuanced evaluation of VLMs' alignment capabilities, especially for Chinese visual contexts.", "method": "Introduces AlignMMBench with real-world scenarios, 13 tasks, 1,054 images, and 4,978 QA pairs. Uses CritiqueVLM for evaluation and an \"alignment score\" metric.", "result": "Evaluates representative VLMs, revealing their capabilities and limitations.", "conclusion": "AlignMMBench fills a critical gap in VLM evaluation, offering a robust framework for nuanced alignment assessment in Chinese contexts."}}
{"id": "2506.03478", "pdf": "https://arxiv.org/pdf/2506.03478", "abs": "https://arxiv.org/abs/2506.03478", "authors": ["Yuxuan Han", "Junfeng Lyu", "Kuan Sheng", "Minghao Que", "Qixuan Zhang", "Lan Xu", "Feng Xu"], "title": "Facial Appearance Capture at Home with Patch-Level Reflectance Prior", "categories": ["cs.GR", "cs.CV"], "comment": "ACM Transactions on Graphics (Proc. of SIGGRAPH), 2025. Code:\n  https://github.com/yxuhan/DoRA; Project Page: https://yxuhan.github.io/DoRA", "summary": "Existing facial appearance capture methods can reconstruct plausible facial\nreflectance from smartphone-recorded videos. However, the reconstruction\nquality is still far behind the ones based on studio recordings. This paper\nfills the gap by developing a novel daily-used solution with a co-located\nsmartphone and flashlight video capture setting in a dim room. To enhance the\nquality, our key observation is to solve facial reflectance maps within the\ndata distribution of studio-scanned ones. Specifically, we first learn a\ndiffusion prior over the Light Stage scans and then steer it to produce the\nreflectance map that best matches the captured images. We propose to train the\ndiffusion prior at the patch level to improve generalization ability and\ntraining stability, as current Light Stage datasets are in ultra-high\nresolution but limited in data size. Tailored to this prior, we propose a\npatch-level posterior sampling technique to sample seamless full-resolution\nreflectance maps from this patch-level diffusion model. Experiments demonstrate\nour method closes the quality gap between low-cost and studio recordings by a\nlarge margin, opening the door for everyday users to clone themselves to the\ndigital world. Our code will be released at https://github.com/yxuhan/DoRA.", "AI": {"tldr": "A novel method enhances facial reflectance reconstruction from smartphone videos using a diffusion prior and patch-level sampling, bridging the gap with studio-quality results.", "motivation": "Existing smartphone-based facial reflectance reconstruction lags behind studio-quality methods, limiting accessibility for everyday users.", "method": "Uses a diffusion prior learned from Light Stage scans and patch-level training, followed by posterior sampling for seamless full-resolution reflectance maps.", "result": "Significantly closes the quality gap between low-cost and studio recordings, enabling high-quality digital cloning for everyday users.", "conclusion": "The proposed method democratizes high-quality facial reflectance capture, making it accessible outside studio environments."}}
{"id": "2502.00698", "pdf": "https://arxiv.org/pdf/2502.00698", "abs": "https://arxiv.org/abs/2502.00698", "authors": ["Huanqia Cai", "Yijun Yang", "Winston Hu"], "title": "MM-IQ: Benchmarking Human-Like Abstraction and Reasoning in Multimodal Models", "categories": ["cs.AI", "cs.CV"], "comment": null, "summary": "IQ testing has served as a foundational methodology for evaluating human\ncognitive capabilities, deliberately decoupling assessment from linguistic\nbackground, language proficiency, or domain-specific knowledge to isolate core\ncompetencies in abstraction and reasoning. Yet, artificial intelligence\nresearch currently lacks systematic benchmarks to quantify these critical\ncognitive capabilities in multimodal systems. To address this crucial gap, we\npropose MM-IQ, a comprehensive evaluation framework, which comprises a\nlarge-scale training set with 4,776 visual reasoning problems and 2,710\nmeticulously curated test items spanning 8 distinct reasoning paradigms.\nThrough systematic evaluation of existing open-source and proprietary\nmultimodal models, our benchmark reveals striking limitations: even\nstate-of-the-art architectures achieve only marginally superior performance to\nrandom chance (33.17% vs. 25% baseline accuracy). This substantial performance\nchasm highlights the inadequacy of current multimodal models in approximating\nfundamental human reasoning capacities, underscoring the need for\nparadigm-shifting advancements to bridge this cognitive divide. Moreover,\ninspired by the recent surge of large reasoning models, we also release a\nmultimodal reasoning model as the baseline that is trained via reinforcement\nlearning with verifiable reward functions, reaching competitive performance to\nthe state-of-the-art with a notably smaller model size.", "AI": {"tldr": "The paper introduces MM-IQ, a benchmark for evaluating multimodal AI systems' cognitive capabilities, revealing their poor performance compared to human reasoning.", "motivation": "Current AI lacks systematic benchmarks for cognitive capabilities like abstraction and reasoning, which IQ tests measure in humans.", "method": "Proposes MM-IQ, a framework with 4,776 training and 2,710 test items across 8 reasoning paradigms, and evaluates existing models.", "result": "State-of-the-art models perform only slightly better than random chance (33.17% vs. 25%), highlighting their limitations.", "conclusion": "The cognitive gap between AI and humans is significant, requiring advancements. A new multimodal reasoning model is introduced as a baseline."}}
{"id": "2506.03670", "pdf": "https://arxiv.org/pdf/2506.03670", "abs": "https://arxiv.org/abs/2506.03670", "authors": ["Ivan Melev", "Goeran Kauermann"], "title": "Position: There Is No Free Bayesian Uncertainty Quantification", "categories": ["stat.ML", "cs.LG"], "comment": "NeurIPS 2025 preprint, frequentist critique of Bayesian UQ", "summary": "Due to their intuitive appeal, Bayesian methods of modeling and uncertainty\nquantification have become popular in modern machine and deep learning. When\nproviding a prior distribution over the parameter space, it is straightforward\nto obtain a distribution over the parameters that is conventionally interpreted\nas uncertainty quantification of the model. We challenge the validity of such\nBayesian uncertainty quantification by discussing the equivalent\noptimization-based representation of Bayesian updating, provide an alternative\ninterpretation that is coherent with the optimization-based perspective,\npropose measures of the quality of the Bayesian inferential stage, and suggest\ndirections for future work.", "AI": {"tldr": "The paper critiques the conventional interpretation of Bayesian uncertainty quantification, offering an optimization-based perspective and suggesting improvements.", "motivation": "To challenge the validity of Bayesian uncertainty quantification in machine learning and propose alternative interpretations and measures.", "method": "Discusses the optimization-based representation of Bayesian updating and provides an alternative coherent interpretation.", "result": "Highlights limitations in traditional Bayesian uncertainty quantification and proposes quality measures for Bayesian inference.", "conclusion": "Suggests future work directions to improve Bayesian uncertainty quantification in machine learning."}}
{"id": "2406.12784", "pdf": "https://arxiv.org/pdf/2406.12784", "abs": "https://arxiv.org/abs/2406.12784", "authors": ["Xunzhi Wang", "Zhuowei Zhang", "Gaonan Chen", "Qiongyu Li", "Bitong Luo", "Zhixin Han", "Haotian Wang", "Zhiyu li", "Hang Gao", "Mengting Hu"], "title": "UBench: Benchmarking Uncertainty in Large Language Models with Multiple Choice Questions", "categories": ["cs.CL"], "comment": "accepted by ACL Findings (2025)", "summary": "Despite recent progress in systematic evaluation frameworks, benchmarking the\nuncertainty of large language models (LLMs) remains a highly challenging task.\nExisting methods for benchmarking the uncertainty of LLMs face three key\nchallenges: the need for internal model access, additional training, or high\ncomputational costs. This is particularly unfavorable for closed-source models.\nTo this end, we introduce UBench, a new benchmark for evaluating the\nuncertainty of LLMs. Unlike other benchmarks, UBench is based on confidence\nintervals. It encompasses 11,978 multiple-choice questions spanning knowledge,\nlanguage, understanding, and reasoning capabilities. Based on this, we conduct\nextensive experiments. This includes comparisons with other advanced\nuncertainty estimation methods, the assessment of the uncertainty of 20 LLMs,\nand an exploration of the effects of Chain-of-Thought (CoT) prompts,\nrole-playing (RP) prompts, and temperature on model uncertainty. Our analysis\nreveals several crucial insights: 1) Our confidence interval-based methods are\nhighly effective for uncertainty quantification; 2) Regarding uncertainty,\noutstanding open-source models show competitive performance versus\nclosed-source models; 3) CoT and RP prompts present potential ways to improve\nmodel reliability, while the influence of temperature changes follows no\nuniversal rule. Our implementation is available at\nhttps://github.com/Cyno2232/UBENCH.", "AI": {"tldr": "UBench is a new benchmark for evaluating LLM uncertainty using confidence intervals, addressing challenges like internal model access and high costs. It tests 20 LLMs, revealing insights on methods, open-source competitiveness, and prompt effects.", "motivation": "Existing methods for benchmarking LLM uncertainty are impractical for closed-source models due to requirements like internal access or training. UBench aims to provide a more accessible solution.", "method": "UBench uses confidence intervals and includes 11,978 multiple-choice questions across knowledge, language, understanding, and reasoning. It compares uncertainty methods and evaluates 20 LLMs.", "result": "Confidence interval-based methods are effective. Open-source models compete with closed-source ones. CoT and RP prompts improve reliability, while temperature effects vary.", "conclusion": "UBench offers a practical, effective way to benchmark LLM uncertainty, highlighting the potential of open-source models and specific prompts for reliability."}}
{"id": "2506.03792", "pdf": "https://arxiv.org/pdf/2506.03792", "abs": "https://arxiv.org/abs/2506.03792", "authors": ["Qianwei Qu", "Christian M. Schlep\u00fctz", "Marco Stampanoni"], "title": "Analytical Reconstruction of Periodically Deformed Objects in Time-resolved CT", "categories": ["physics.med-ph", "cs.CV"], "comment": null, "summary": "Time-resolved CT is an advanced measurement technique that has been widely\nused to observe dynamic objects, including periodically varying structures such\nas hearts, lungs, or hearing structures. To reconstruct these objects from CT\nprojections, a common approach is to divide the projections into several\ncollections based on their motion phases and perform reconstruction within each\ncollection, assuming they originate from a static object. This describes the\ngating-based method, which is the standard approach for time-periodic\nreconstruction. However, the gating-based reconstruction algorithm only\nutilizes a limited subset of projections within each collection and ignores the\ncorrelation between different collections, leading to inefficient use of the\nradiation dose. To address this issue, we propose two analytical reconstruction\npipelines in this paper, and validate them with experimental data captured\nusing tomographic synchrotron microscopy. We demonstrate that our approaches\nsignificantly reduce random noise in the reconstructed images without blurring\nthe sharp features of the observed objects. Equivalently, our methods can\nachieve the same reconstruction quality as gating-based methods but with a\nlower radiation dose. Our code is available at github.com/PeriodRecon.", "AI": {"tldr": "Proposes two analytical reconstruction pipelines for time-resolved CT to improve noise reduction and radiation dose efficiency compared to gating-based methods.", "motivation": "Gating-based methods inefficiently use radiation dose by ignoring correlations between projection collections.", "method": "Two analytical reconstruction pipelines validated with tomographic synchrotron microscopy data.", "result": "Significantly reduces random noise without blurring sharp features; achieves same quality as gating-based methods with lower radiation dose.", "conclusion": "The proposed methods offer superior efficiency and quality for time-periodic reconstruction."}}
{"id": "2502.11753", "pdf": "https://arxiv.org/pdf/2502.11753", "abs": "https://arxiv.org/abs/2502.11753", "authors": ["Michiel van der Meer", "Pavel Korshunov", "S\u00e9bastien Marcel", "Lonneke van der Plas"], "title": "HintsOfTruth: A Multimodal Checkworthiness Detection Dataset with Real and Synthetic Claims", "categories": ["cs.AI"], "comment": "Accepted at ACL2025 (main track)", "summary": "Misinformation can be countered with fact-checking, but the process is costly\nand slow. Identifying checkworthy claims is the first step, where automation\ncan help scale fact-checkers' efforts. However, detection methods struggle with\ncontent that is (1) multimodal, (2) from diverse domains, and (3) synthetic. We\nintroduce HintsOfTruth, a public dataset for multimodal checkworthiness\ndetection with 27K real-world and synthetic image/claim pairs. The mix of real\nand synthetic data makes this dataset unique and ideal for benchmarking\ndetection methods. We compare fine-tuned and prompted Large Language Models\n(LLMs). We find that well-configured lightweight text-based encoders perform\ncomparably to multimodal models but the former only focus on identifying\nnon-claim-like content. Multimodal LLMs can be more accurate but come at a\nsignificant computational cost, making them impractical for large-scale\napplications. When faced with synthetic data, multimodal models perform more\nrobustly.", "AI": {"tldr": "HintsOfTruth is a dataset for multimodal checkworthiness detection, comparing text-based and multimodal LLMs. Lightweight text encoders perform well but lack robustness with synthetic data, while multimodal models are more accurate but costly.", "motivation": "To address the challenges of detecting checkworthy claims in multimodal, diverse, and synthetic content, aiding fact-checkers by automating the process.", "method": "Introduces HintsOfTruth, a dataset with 27K real-world and synthetic image/claim pairs. Compares fine-tuned and prompted LLMs, focusing on text-based and multimodal models.", "result": "Lightweight text encoders perform comparably but struggle with synthetic data. Multimodal models are more robust but computationally expensive.", "conclusion": "Multimodal models are better for robustness, but text-based models are practical for large-scale applications."}}
{"id": "2506.03672", "pdf": "https://arxiv.org/pdf/2506.03672", "abs": "https://arxiv.org/abs/2506.03672", "authors": ["Sobihan Surendran", "Adeline Fermanian", "Sylvain Le Corff"], "title": "Latent Guided Sampling for Combinatorial Optimization", "categories": ["stat.ML", "cs.LG", "math.OC"], "comment": null, "summary": "Combinatorial Optimization problems are widespread in domains such as\nlogistics, manufacturing, and drug discovery, yet their NP-hard nature makes\nthem computationally challenging. Recent Neural Combinatorial Optimization\nmethods leverage deep learning to learn solution strategies, trained via\nSupervised or Reinforcement Learning (RL). While promising, these approaches\noften rely on task-specific augmentations, perform poorly on\nout-of-distribution instances, and lack robust inference mechanisms. Moreover,\nexisting latent space models either require labeled data or rely on pre-trained\npolicies. In this work, we propose LGS-Net, a novel latent space model that\nconditions on problem instances, and introduce an efficient inference method,\nLatent Guided Sampling (LGS), based on Markov Chain Monte Carlo and Stochastic\nApproximation. We show that the iterations of our method form a\ntime-inhomogeneous Markov Chain and provide rigorous theoretical convergence\nguarantees. Empirical results on benchmark routing tasks show that our method\nachieves state-of-the-art performance among RL-based approaches.", "AI": {"tldr": "LGS-Net introduces a latent space model for combinatorial optimization with efficient inference, achieving state-of-the-art results.", "motivation": "Addressing the limitations of existing Neural Combinatorial Optimization methods, such as poor out-of-distribution performance and lack of robust inference.", "method": "Proposes LGS-Net, a latent space model conditioned on problem instances, and Latent Guided Sampling (LGS) for efficient inference using Markov Chain Monte Carlo and Stochastic Approximation.", "result": "Empirical results show state-of-the-art performance on benchmark routing tasks among RL-based approaches.", "conclusion": "LGS-Net provides a robust and efficient solution for combinatorial optimization with theoretical convergence guarantees."}}
{"id": "2406.18173", "pdf": "https://arxiv.org/pdf/2406.18173", "abs": "https://arxiv.org/abs/2406.18173", "authors": ["Wenhao Li", "Mingbao Lin", "Yunshan Zhong", "Shuicheng Yan", "Rongrong Ji"], "title": "UIO-LLMs: Unbiased Incremental Optimization for Long-Context LLMs", "categories": ["cs.CL"], "comment": "The experimental results of the paper require further validation", "summary": "Managing long texts is challenging for large language models (LLMs) due to\nlimited context window sizes. This study introduces UIO-LLMs, an unbiased\nincremental optimization approach for memory-enhanced transformers under\nlong-context settings. We initially conceptualize the process as a streamlined\nencoder-decoder framework where the weights-shared encoder and decoder\nrespectively encapsulate a context segment into memories and leverage these\nmemories to predict outputs of the subsequent segment. Subsequently, by\ntreating our memory-enhanced transformers as fully-connected recurrent neural\nnetworks (RNNs), we refine the training process using the Truncated\nBackpropagation Through Time (TBPTT) algorithm, which incorporates innovative\nincremental optimization techniques. These techniques not only diminish time\ncomplexity but also address the bias in gradient computation through an\nunbiased optimization process. UIO-LLMs successfully handle long context, such\nas extending the context window of Llama2-7b-chat from 4K to 100K tokens with\nminimal 2% additional parameters, while keeping the inference cost nearly\nlinear as context length increases.", "AI": {"tldr": "UIO-LLMs optimize memory-enhanced transformers for long-context tasks, extending context windows (e.g., 4K to 100K tokens) with minimal added parameters and linear inference cost.", "motivation": "Handling long texts is difficult for LLMs due to limited context windows, necessitating efficient memory and optimization techniques.", "method": "UIO-LLMs use a shared encoder-decoder framework and treat transformers as RNNs, refining training with TBPTT and incremental optimization for unbiased gradients.", "result": "Achieves 100K token context for Llama2-7b-chat with only 2% extra parameters and near-linear inference cost.", "conclusion": "UIO-LLMs effectively address long-context challenges in LLMs with scalable and efficient optimization."}}
{"id": "2506.03804", "pdf": "https://arxiv.org/pdf/2506.03804", "abs": "https://arxiv.org/abs/2506.03804", "authors": ["George Webber", "Alexander Hammers", "Andrew P. King", "Andrew J. Reader"], "title": "Personalized MR-Informed Diffusion Models for 3D PET Image Reconstruction", "categories": ["physics.med-ph", "cs.CV"], "comment": "10 pages, 10 figures", "summary": "Recent work has shown improved lesion detectability and flexibility to\nreconstruction hyperparameters (e.g. scanner geometry or dose level) when PET\nimages are reconstructed by leveraging pre-trained diffusion models. Such\nmethods train a diffusion model (without sinogram data) on high-quality, but\nstill noisy, PET images. In this work, we propose a simple method for\ngenerating subject-specific PET images from a dataset of multi-subject PET-MR\nscans, synthesizing \"pseudo-PET\" images by transforming between different\npatients' anatomy using image registration. The images we synthesize retain\ninformation from the subject's MR scan, leading to higher resolution and the\nretention of anatomical features compared to the original set of PET images.\nWith simulated and real [$^{18}$F]FDG datasets, we show that pre-training a\npersonalized diffusion model with subject-specific \"pseudo-PET\" images improves\nreconstruction accuracy with low-count data. In particular, the method shows\npromise in combining information from a guidance MR scan without overly\nimposing anatomical features, demonstrating an improved trade-off between\nreconstructing PET-unique image features versus features present in both PET\nand MR. We believe this approach for generating and utilizing synthetic data\nhas further applications to medical imaging tasks, particularly because\npatient-specific PET images can be generated without resorting to generative\ndeep learning or large training datasets.", "AI": {"tldr": "A method for generating subject-specific PET images using image registration improves PET reconstruction accuracy by leveraging MR scans and synthetic data.", "motivation": "To enhance PET image reconstruction by using subject-specific synthetic PET images derived from MR scans, avoiding reliance on large datasets or deep learning.", "method": "Generate 'pseudo-PET' images via image registration of multi-subject PET-MR scans, then pre-train a personalized diffusion model with these images for improved reconstruction.", "result": "Higher resolution and better retention of anatomical features in PET images, with improved accuracy in low-count data scenarios.", "conclusion": "The approach offers a promising trade-off between PET-unique and MR-derived features, with potential for broader medical imaging applications."}}
{"id": "2503.11207", "pdf": "https://arxiv.org/pdf/2503.11207", "abs": "https://arxiv.org/abs/2503.11207", "authors": ["Giacomo Camposampiero", "Michael Hersche", "Roger Wattenhofer", "Abu Sebastian", "Abbas Rahimi"], "title": "Can Large Reasoning Models do Analogical Reasoning under Perceptual Uncertainty?", "categories": ["cs.AI", "cs.LG"], "comment": "Accepted at the 19th International Conference on Neural-Symbolic\n  Learning and Reasoning (NeSy) 2025", "summary": "This work presents a first evaluation of two state-of-the-art Large Reasoning\nModels (LRMs), OpenAI's o3-mini and DeepSeek R1, on analogical reasoning,\nfocusing on well-established nonverbal human IQ tests based on Raven's\nprogressive matrices. We benchmark with the I-RAVEN dataset and its extension,\nI-RAVEN-X, which tests the ability to generalize to longer reasoning rules and\nranges of the attribute values. To assess the influence of visual uncertainties\non these symbolic analogical reasoning tests, we extend the I-RAVEN-X dataset,\nwhich otherwise assumes an oracle perception. We adopt a two-fold strategy to\nsimulate this imperfect visual perception: 1) we introduce confounding\nattributes which, being sampled at random, do not contribute to the prediction\nof the correct answer of the puzzles, and 2) we smoothen the distributions of\nthe input attributes' values. We observe a sharp decline in OpenAI's o3-mini\ntask accuracy, dropping from 86.6% on the original I-RAVEN to just 17.0% --\napproaching random chance -- on the more challenging I-RAVEN-X, which increases\ninput length and range and emulates perceptual uncertainty. This drop occurred\ndespite spending 3.4x more reasoning tokens. A similar trend is also observed\nfor DeepSeek R1: from 80.6% to 23.2%. On the other hand, a neuro-symbolic\nprobabilistic abductive model, ARLC, that achieves state-of-the-art\nperformances on I-RAVEN, can robustly reason under all these\nout-of-distribution tests, maintaining strong accuracy with only a modest\naccuracy reduction from 98.6% to 88.0%. Our code is available at\nhttps://github.com/IBM/raven-large-language-models.", "AI": {"tldr": "The paper evaluates two LRMs (OpenAI's o3-mini and DeepSeek R1) on analogical reasoning using Raven's matrices, showing significant accuracy drops under perceptual uncertainty, while a neuro-symbolic model (ARLC) remains robust.", "motivation": "To assess the performance of state-of-the-art LRMs on analogical reasoning tasks under challenging conditions like perceptual uncertainty and extended reasoning rules.", "method": "Benchmarked models on I-RAVEN and I-RAVEN-X datasets, introduced confounding attributes and smoothed attribute distributions to simulate imperfect perception.", "result": "LRMs' accuracy dropped sharply (o3-mini: 86.6% to 17.0%; DeepSeek R1: 80.6% to 23.2%), while ARLC maintained high accuracy (98.6% to 88.0%).", "conclusion": "Neuro-symbolic models like ARLC outperform LRMs in robustness under perceptual uncertainty and extended reasoning challenges."}}
{"id": "2506.03697", "pdf": "https://arxiv.org/pdf/2506.03697", "abs": "https://arxiv.org/abs/2506.03697", "authors": ["Swagat Kumar", "Jan-Nico Zaech", "Colin Michael Wilmott", "Luc Van Gool"], "title": "RhoDARTS: Differentiable Quantum Architecture Search with Density Matrix Simulations", "categories": ["quant-ph", "cs.LG"], "comment": "24 pages, 16 figures", "summary": "Variational Quantum Algorithms (VQAs) are a promising approach for leveraging\npowerful Noisy Intermediate-Scale Quantum (NISQ) computers. When applied to\nmachine learning tasks, VQAs give rise to NISQ-compatible Quantum Neural\nNetworks (QNNs), which have been shown to outperform classical neural networks\nwith a similar number of trainable parameters. While the quantum circuit\nstructures of VQAs for physics simulations are determined by the physical\nproperties of the systems, identifying effective QNN architectures for general\nmachine learning tasks is a difficult challenge due to the lack of\ndomain-specific priors. Indeed, existing Quantum Architecture Search (QAS)\nalgorithms, adaptations of classical neural architecture search techniques,\noften overlook the inherent quantum nature of the circuits they produce. By\napproaching QAS from the ground-up and from a quantum perspective, we resolve\nthis limitation by proposing $\\rho$DARTS, a differentiable QAS algorithm that\nmodels the search process as the evolution of a quantum mixed state, emerging\nfrom the search space of quantum architectures. We validate our method by\nfinding circuits for state initialization, Hamiltonian optimization, and image\nclassification. Further, we demonstrate better convergence against existing QAS\ntechniques and show improved robustness levels to noise.", "AI": {"tldr": "The paper introduces \u03c1DARTS, a differentiable Quantum Architecture Search (QAS) algorithm, addressing the challenge of designing effective Quantum Neural Networks (QNNs) for machine learning tasks by leveraging quantum principles.", "motivation": "Existing QAS methods, adapted from classical techniques, often ignore quantum circuit properties, limiting their effectiveness for QNN design.", "method": "The proposed \u03c1DARTS models QAS as the evolution of a quantum mixed state, enabling a quantum-native approach to architecture search.", "result": "\u03c1DARTS outperforms existing QAS methods in convergence and noise robustness, validated on tasks like state initialization, Hamiltonian optimization, and image classification.", "conclusion": "\u03c1DARTS provides a quantum-native solution for QAS, improving QNN design for NISQ-era machine learning applications."}}
{"id": "2409.17169", "pdf": "https://arxiv.org/pdf/2409.17169", "abs": "https://arxiv.org/abs/2409.17169", "authors": ["Honggen Zhang", "Xufeng Zhao", "Igor Molybog", "June Zhang"], "title": "REAL: Response Embedding-based Alignment for LLMs", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Aligning large language models (LLMs) to human preferences is a crucial step\nin building helpful and safe AI tools, which usually involve training on\nsupervised datasets. Popular algorithms such as Direct Preference Optimization\n(DPO) rely on pairs of AI-generated responses ranked according to human\nannotation. The response pair annotation process might bring human bias.\nBuilding a correct preference dataset is the costly part of the alignment\npipeline. To improve annotation efficiency and quality in the LLMs alignment,\nwe propose REAL: Response Embedding-based Alignment for LLMs, a strategy for\nconstructing a high-quality training dataset that focuses on acquiring the less\nambiguous preference pairs for labeling out of a set of response candidates.\nOur selection process is based on the similarity of embedding responses\nindependently of prompts, which guarantees the selection process in an\noff-policy setting, avoiding adaptively measuring the similarity during the\ntraining. Experimental results on real-world dataset SHP2 and synthetic HH-RLHF\nbenchmarks indicate that choosing dissimilar response pairs enhances the direct\nalignment of LLMs while reducing inherited labeling errors. The model aligned\nwith dissimilar response pairs obtained a better margin and win rate on the\ndialogue task. Our findings suggest that focusing on distinct pairs can reduce\nthe label error and improve LLM alignment efficiency, saving up to $65\\%$ of\nannotators' work.", "AI": {"tldr": "REAL improves LLM alignment by selecting dissimilar response pairs for labeling, reducing bias and saving annotation costs.", "motivation": "Human bias in response pair annotation and high costs in preference dataset construction motivate the need for a more efficient alignment method.", "method": "REAL uses response embedding similarity to select less ambiguous preference pairs, operating independently of prompts in an off-policy setting.", "result": "Experiments show REAL enhances alignment, reduces labeling errors, and saves up to 65% of annotators' work.", "conclusion": "Focusing on distinct response pairs improves LLM alignment efficiency and reduces label errors."}}
{"id": "2504.21131", "pdf": "https://arxiv.org/pdf/2504.21131", "abs": "https://arxiv.org/abs/2504.21131", "authors": ["Remo Christen", "Florian Pommerening", "Clemens B\u00fcchner", "Malte Helmert"], "title": "A Formalism for Optimal Search with Dynamic Heuristics (Extended Version)", "categories": ["cs.AI"], "comment": null, "summary": "While most heuristics studied in heuristic search depend only on the state,\nsome accumulate information during search and thus also depend on the search\nhistory. Various existing approaches use such dynamic heuristics in\n$\\mathrm{A}^*$-like algorithms and appeal to classic results for $\\mathrm{A}^*$\nto show optimality. However, doing so ignores the complexities of searching\nwith a mutable heuristic. In this paper we formalize the idea of dynamic\nheuristics and use them in a generic algorithm framework. We study a particular\ninstantiation that models $\\mathrm{A}^*$ with dynamic heuristics and show\ngeneral optimality results. Finally we show how existing approaches from\nclassical planning can be viewed as special cases of this instantiation, making\nit possible to directly apply our optimality results.", "AI": {"tldr": "The paper formalizes dynamic heuristics in heuristic search, introduces a generic algorithm framework, and proves optimality results, connecting existing classical planning approaches as special cases.", "motivation": "Existing approaches using dynamic heuristics in A*-like algorithms often overlook the complexities of mutable heuristics, necessitating a formal framework.", "method": "The authors formalize dynamic heuristics, develop a generic algorithm framework, and study an instantiation modeling A* with dynamic heuristics.", "result": "General optimality results are proven, and existing classical planning approaches are shown as special cases of the framework.", "conclusion": "The framework enables direct application of optimality results to existing methods, unifying dynamic heuristic approaches."}}
{"id": "2506.03746", "pdf": "https://arxiv.org/pdf/2506.03746", "abs": "https://arxiv.org/abs/2506.03746", "authors": ["C\u00e9sar Sabater", "Sonia Ben Mokhtar", "Jan Ramon"], "title": "Dropout-Robust Mechanisms for Differentially Private and Fully Decentralized Mean Estimation", "categories": ["cs.CR", "cs.DC", "cs.LG"], "comment": "23 pages, 4 figures", "summary": "Achieving differentially private computations in decentralized settings poses\nsignificant challenges, particularly regarding accuracy, communication cost,\nand robustness against information leakage. While cryptographic solutions offer\npromise, they often suffer from high communication overhead or require\ncentralization in the presence of network failures. Conversely, existing fully\ndecentralized approaches typically rely on relaxed adversarial models or\npairwise noise cancellation, the latter suffering from substantial accuracy\ndegradation if parties unexpectedly disconnect. In this work, we propose IncA,\na new protocol for fully decentralized mean estimation, a widely used primitive\nin data-intensive processing. Our protocol, which enforces differential\nprivacy, requires no central orchestration and employs low-variance correlated\nnoise, achieved by incrementally injecting sensitive information into the\ncomputation. First, we theoretically demonstrate that, when no parties\npermanently disconnect, our protocol achieves accuracy comparable to that of a\ncentralized setting-already an improvement over most existing decentralized\ndifferentially private techniques. Second, we empirically show that our use of\nlow-variance correlated noise significantly mitigates the accuracy loss\nexperienced by existing techniques in the presence of dropouts.", "AI": {"tldr": "IncA is a decentralized protocol for differentially private mean estimation, improving accuracy and robustness against dropouts compared to existing methods.", "motivation": "Challenges in decentralized differentially private computations include accuracy, communication cost, and robustness against information leakage. Existing solutions either have high overhead or rely on weak adversarial models.", "method": "IncA uses low-variance correlated noise and incremental injection of sensitive information, requiring no central orchestration.", "result": "Theoretically, IncA matches centralized accuracy if no parties disconnect. Empirically, it reduces accuracy loss from dropouts.", "conclusion": "IncA offers a robust, accurate solution for decentralized differentially private mean estimation."}}
{"id": "2410.01444", "pdf": "https://arxiv.org/pdf/2410.01444", "abs": "https://arxiv.org/abs/2410.01444", "authors": ["Jin Hwa Lee", "Thomas Jiralerspong", "Lei Yu", "Yoshua Bengio", "Emily Cheng"], "title": "Geometric Signatures of Compositionality Across a Language Model's Lifetime", "categories": ["cs.CL", "cs.AI", "cs.IT", "cs.LG", "math.IT"], "comment": "Under review at ARR", "summary": "By virtue of linguistic compositionality, few syntactic rules and a finite\nlexicon can generate an unbounded number of sentences. That is, language,\nthough seemingly high-dimensional, can be explained using relatively few\ndegrees of freedom. An open question is whether contemporary language models\n(LMs) reflect the intrinsic simplicity of language that is enabled by\ncompositionality. We take a geometric view of this problem by relating the\ndegree of compositionality in a dataset to the intrinsic dimension (ID) of its\nrepresentations under an LM, a measure of feature complexity. We find not only\nthat the degree of dataset compositionality is reflected in representations'\nID, but that the relationship between compositionality and geometric complexity\narises due to learned linguistic features over training. Finally, our analyses\nreveal a striking contrast between nonlinear and linear dimensionality, showing\nthey respectively encode semantic and superficial aspects of linguistic\ncomposition.", "AI": {"tldr": "The paper explores whether language models (LMs) reflect the simplicity of language enabled by compositionality, using intrinsic dimension (ID) of representations to measure feature complexity. It finds that dataset compositionality correlates with ID, with nonlinear and linear dimensions encoding semantic and superficial aspects, respectively.", "motivation": "To understand if LMs capture the intrinsic simplicity of language, driven by compositionality, and how this is reflected in the geometric complexity of their representations.", "method": "Analyzes the relationship between dataset compositionality and the intrinsic dimension (ID) of LM representations, examining learned linguistic features during training.", "result": "Dataset compositionality is reflected in the ID of representations, with nonlinear and linear dimensions encoding semantic and superficial linguistic aspects, respectively.", "conclusion": "LMs' representations align with linguistic compositionality, with geometric complexity revealing distinct encoding of semantic and superficial features."}}
{"id": "2506.04016", "pdf": "https://arxiv.org/pdf/2506.04016", "abs": "https://arxiv.org/abs/2506.04016", "authors": ["Adam Ran\u00e7on", "Ulysse Ran\u00e7on", "Tomislav Ivek", "Ivan Balog"], "title": "Dreaming up scale invariance via inverse renormalization group", "categories": ["cond-mat.stat-mech", "cs.CV", "cs.LG"], "comment": "v1: 12 pages, 11 figures, 55 references", "summary": "We explore how minimal neural networks can invert the renormalization group\n(RG) coarse-graining procedure in the two-dimensional Ising model, effectively\n\"dreaming up\" microscopic configurations from coarse-grained states. This\ntask-formally impossible at the level of configurations-can be approached\nprobabilistically, allowing machine learning models to reconstruct\nscale-invariant distributions without relying on microscopic input. We\ndemonstrate that even neural networks with as few as three trainable parameters\ncan learn to generate critical configurations, reproducing the scaling behavior\nof observables such as magnetic susceptibility, heat capacity, and Binder\nratios. A real-space renormalization group analysis of the generated\nconfigurations confirms that the models capture not only scale invariance but\nalso reproduce nontrivial eigenvalues of the RG transformation. Surprisingly,\nwe find that increasing network complexity by introducing multiple layers\noffers no significant benefit. These findings suggest that simple local rules,\nakin to those generating fractal structures, are sufficient to encode the\nuniversality of critical phenomena, opening the door to efficient generative\nmodels of statistical ensembles in physics.", "AI": {"tldr": "Minimal neural networks can invert RG coarse-graining in the 2D Ising model, generating microscopic configurations from coarse-grained states, even with few parameters.", "motivation": "To explore if simple neural networks can probabilistically reconstruct microscopic configurations from coarse-grained states, capturing critical phenomena without microscopic input.", "method": "Use minimal neural networks (as few as three parameters) to generate critical configurations, analyzing observables like magnetic susceptibility and RG eigenvalues.", "result": "Simple networks reproduce scale-invariant distributions and RG eigenvalues; increasing complexity (e.g., more layers) doesn't improve performance.", "conclusion": "Local rules in simple networks suffice to encode critical universality, enabling efficient generative models for statistical physics."}}
{"id": "2505.10981", "pdf": "https://arxiv.org/pdf/2505.10981", "abs": "https://arxiv.org/abs/2505.10981", "authors": ["Yexiang Liu", "Zekun Li", "Zhi Fang", "Nan Xu", "Ran He", "Tieniu Tan"], "title": "Rethinking the Role of Prompting Strategies in LLM Test-Time Scaling: A Perspective of Probability Theory", "categories": ["cs.AI", "cs.CL", "cs.LG"], "comment": "ACL 2025 Main, 33 pages, 51 figures", "summary": "Recently, scaling test-time compute on Large Language Models (LLM) has\ngarnered wide attention. However, there has been limited investigation of how\nvarious reasoning prompting strategies perform as scaling. In this paper, we\nfocus on a standard and realistic scaling setting: majority voting. We\nsystematically conduct experiments on 6 LLMs $\\times$ 8 prompting strategies\n$\\times$ 6 benchmarks. Experiment results consistently show that as the\nsampling time and computational overhead increase, complicated prompting\nstrategies with superior initial performance gradually fall behind simple\nChain-of-Thought. We analyze this phenomenon and provide theoretical proofs.\nAdditionally, we propose a probabilistic method to efficiently predict scaling\nperformance and identify the best prompting strategy under large sampling\ntimes, eliminating the need for resource-intensive inference processes in\npractical applications. Furthermore, we introduce two ways derived from our\ntheoretical analysis to significantly improve the scaling performance. We hope\nthat our research can promote to re-examine the role of complicated prompting,\nunleash the potential of simple prompting strategies, and provide new insights\nfor enhancing test-time scaling performance. Code is available at\nhttps://github.com/MraDonkey/rethinking_prompting.", "AI": {"tldr": "Scaling test-time compute on LLMs shows simple Chain-of-Thought outperforms complex prompting strategies as compute increases, with a proposed method to predict and improve scaling performance.", "motivation": "To investigate how prompting strategies scale with increased compute, focusing on majority voting, and to improve scaling efficiency.", "method": "Experiments on 6 LLMs, 8 prompting strategies, and 6 benchmarks, with theoretical analysis and a probabilistic prediction method.", "result": "Simple Chain-of-Thought surpasses complex strategies as compute scales; a method to predict optimal strategies is introduced.", "conclusion": "Encourages re-evaluating complex prompting, highlights simple strategies' potential, and offers insights for scaling performance."}}
{"id": "2506.03764", "pdf": "https://arxiv.org/pdf/2506.03764", "abs": "https://arxiv.org/abs/2506.03764", "authors": ["R\u00f3is\u00edn Luo"], "title": "Infinitesimal Higher-Order Spectral Variations in Rectangular Real Random Matrices", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "We present a theoretical framework for deriving the general $n$-th order\nFr\\'echet derivatives of singular values in real rectangular matrices, by\nleveraging reduced resolvent operators from Kato's analytic perturbation theory\nfor self-adjoint operators. Deriving closed-form expressions for higher-order\nderivatives of singular values is notoriously challenging through standard\nmatrix-analysis techniques. To overcome this, we treat a real rectangular\nmatrix as a compact operator on a finite-dimensional Hilbert space, and embed\nthe rectangular matrix into a block self-adjoint operator so that non-symmetric\nperturbations are captured. Applying Kato's asymptotic eigenvalue expansion to\nthis construction, we obtain a general, closed-form expression for the\ninfinitesimal $n$-th order spectral variations. Specializing to $n=2$ and\ndeploying on a Kronecker-product representation with matrix convention yield\nthe Hessian of a singular value, not found in literature. By bridging abstract\noperator-theoretic perturbation theory with matrices, our framework equips\nresearchers with a practical toolkit for higher-order spectral sensitivity\nstudies in random matrix applications (e.g., adversarial perturbation in deep\nlearning).", "AI": {"tldr": "The paper introduces a framework for computing higher-order Fr\u00e9chet derivatives of singular values in real rectangular matrices using Kato's perturbation theory, providing closed-form expressions not previously available.", "motivation": "Standard techniques struggle with higher-order derivatives of singular values, limiting applications like spectral sensitivity analysis in random matrices and deep learning.", "method": "The approach embeds rectangular matrices into block self-adjoint operators, applies Kato's asymptotic eigenvalue expansion, and derives closed-form expressions for spectral variations.", "result": "A general formula for $n$-th order derivatives is obtained, with a specific Hessian for singular values (n=2) as a novel contribution.", "conclusion": "The framework bridges operator theory and matrix analysis, offering practical tools for higher-order spectral sensitivity studies in fields like deep learning."}}
{"id": "2410.09300", "pdf": "https://arxiv.org/pdf/2410.09300", "abs": "https://arxiv.org/abs/2410.09300", "authors": ["Yu Fei", "Yasaman Razeghi", "Sameer Singh"], "title": "Nudging: Inference-time Alignment of LLMs via Guided Decoding", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "Accepted to ACL 2025 (main)", "summary": "Large language models (LLMs) require alignment to effectively and safely\nfollow user instructions. This process necessitates training an aligned version\nfor every base model, resulting in significant computational overhead. In this\nwork, we propose NUDGING, a simple, training-free algorithm that aligns any\nbase model at inference time using a small aligned model. NUDGING is motivated\nby recent findings that alignment primarily alters the model's behavior on a\nsmall subset of stylistic tokens (e.g., discourse markers). We find that base\nmodels are significantly more uncertain when generating these tokens. Building\non this insight, NUDGING employs a small aligned model to generate nudging\ntokens to guide the base model's output during decoding when the base model's\nuncertainty is high, with only a minor additional inference overhead. We\nevaluate NUDGING across 3 model families on a diverse range of open-instruction\ntasks. Without any training, nudging a large base model with a 7x-14x smaller\naligned model achieves zero-shot performance comparable to, and sometimes\nsurpassing, that of large aligned models. By operating at the token level,\nNUDGING enables off-the-shelf collaboration between model families. For\ninstance, nudging Gemma-2-27b with Llama-27b-chat outperforms Llama-2-70b-chat\non various tasks. Overall, our work offers a modular and cost-efficient\nsolution to LLM alignment. Our code and demo are available at:\nhttps://fywalter.github.io/nudging/ .", "AI": {"tldr": "NUDGING is a training-free algorithm that aligns large language models (LLMs) at inference time using a small aligned model, achieving comparable or better performance than large aligned models with minimal overhead.", "motivation": "Alignment of LLMs typically requires training aligned versions for each base model, which is computationally expensive. NUDGING aims to provide a cost-efficient alternative by leveraging token-level guidance from a small aligned model.", "method": "NUDGING uses a small aligned model to generate nudging tokens when the base model's uncertainty is high during decoding, guiding the base model's output without additional training.", "result": "NUDGING achieves zero-shot performance comparable to or surpassing large aligned models, even when using a significantly smaller aligned model (7x-14x smaller). It also enables cross-model collaboration, e.g., Gemma-2-27b with Llama-27b-chat outperforming Llama-2-70b-chat.", "conclusion": "NUDGING offers a modular, cost-efficient solution for LLM alignment, reducing computational overhead while maintaining or improving performance."}}
{"id": "2505.17433", "pdf": "https://arxiv.org/pdf/2505.17433", "abs": "https://arxiv.org/abs/2505.17433", "authors": ["Zhengyi Zhao", "Shubo Zhang", "Yuxi Zhang", "Yanxi Zhao", "Yifan Zhang", "Zezhong Wang", "Huimin Wang", "Yutian Zhao", "Bin Liang", "Yefeng Zheng", "Binyang Li", "Kam-Fai Wong", "Xian Wu"], "title": "MemeReaCon: Probing Contextual Meme Understanding in Large Vision-Language Models", "categories": ["cs.AI"], "comment": null, "summary": "Memes have emerged as a popular form of multimodal online communication,\nwhere their interpretation heavily depends on the specific context in which\nthey appear. Current approaches predominantly focus on isolated meme analysis,\neither for harmful content detection or standalone interpretation, overlooking\na fundamental challenge: the same meme can express different intents depending\non its conversational context. This oversight creates an evaluation gap:\nalthough humans intuitively recognize how context shapes meme interpretation,\nLarge Vision Language Models (LVLMs) can hardly understand context-dependent\nmeme intent. To address this critical limitation, we introduce MemeReaCon, a\nnovel benchmark specifically designed to evaluate how LVLMs understand memes in\ntheir original context. We collected memes from five different Reddit\ncommunities, keeping each meme's image, the post text, and user comments\ntogether. We carefully labeled how the text and meme work together, what the\nposter intended, how the meme is structured, and how the community responded.\nOur tests with leading LVLMs show a clear weakness: models either fail to\ninterpret critical information in the contexts, or overly focus on visual\ndetails while overlooking communicative purpose. MemeReaCon thus serves both as\na diagnostic tool exposing current limitations and as a challenging benchmark\nto drive development toward more sophisticated LVLMs of the context-aware\nunderstanding.", "AI": {"tldr": "MemeReaCon is a benchmark to evaluate LVLMs' context-aware understanding of memes, highlighting their current limitations in interpreting context-dependent intent.", "motivation": "Current meme analysis overlooks context-dependent intent, creating a gap in evaluation as LVLMs struggle with context-aware interpretation.", "method": "Collected and labeled memes from Reddit communities, including images, post text, and comments, to test LVLMs' understanding of context.", "result": "LVLMs fail to interpret context or overly focus on visuals, missing communicative intent.", "conclusion": "MemeReaCon exposes LVLM limitations and serves as a benchmark for developing context-aware models."}}
{"id": "2506.03779", "pdf": "https://arxiv.org/pdf/2506.03779", "abs": "https://arxiv.org/abs/2506.03779", "authors": ["Hachem Kadri", "Joachim Tomasi", "Yuka Hashimoto", "Sandrine Anthoine"], "title": "Towards Quantum Operator-Valued Kernels", "categories": ["quant-ph", "cs.LG", "stat.ML"], "comment": null, "summary": "Quantum kernels are reproducing kernel functions built using\nquantum-mechanical principles and are studied with the aim of outperforming\ntheir classical counterparts. The enthusiasm for quantum kernel machines has\nbeen tempered by recent studies that have suggested that quantum kernels could\nnot offer speed-ups when learning on classical data. However, most of the\nresearch in this area has been devoted to scalar-valued kernels in standard\nclassification or regression settings for which classical kernel methods are\nefficient and effective, leaving very little room for improvement with quantum\nkernels. This position paper argues that quantum kernel research should focus\non more expressive kernel classes. We build upon recent advances in\noperator-valued kernels, and propose guidelines for investigating quantum\nkernels. This should help to design a new generation of quantum kernel machines\nand fully explore their potentials.", "AI": {"tldr": "Quantum kernels, built on quantum principles, may not outperform classical kernels in standard tasks, but focusing on more expressive kernel classes could unlock their potential.", "motivation": "Recent studies suggest quantum kernels lack speed-ups for classical data, but research has been limited to scalar-valued kernels in standard settings, leaving room for improvement.", "method": "The paper proposes guidelines for investigating quantum kernels, leveraging advances in operator-valued kernels.", "result": "The focus on expressive kernel classes could lead to a new generation of quantum kernel machines.", "conclusion": "Quantum kernel research should shift to more expressive kernel classes to fully explore their potential."}}
{"id": "2410.14309", "pdf": "https://arxiv.org/pdf/2410.14309", "abs": "https://arxiv.org/abs/2410.14309", "authors": ["Ruihan Yang", "Caiqi Zhang", "Zhisong Zhang", "Xinting Huang", "Sen Yang", "Nigel Collier", "Dong Yu", "Deqing Yang"], "title": "LoGU: Long-form Generation with Uncertainty Expressions", "categories": ["cs.CL", "cs.AI"], "comment": "ACL 2025 Main", "summary": "While Large Language Models (LLMs) demonstrate impressive capabilities, they\nstill struggle with generating factually incorrect content (i.e.,\nhallucinations). A promising approach to mitigate this issue is enabling models\nto express uncertainty when unsure. Previous research on uncertainty modeling\nhas primarily focused on short-form QA, but realworld applications often\nrequire much longer responses. In this work, we introduce the task of Long-form\nGeneration with Uncertainty(LoGU). We identify two key challenges: Uncertainty\nSuppression, where models hesitate to express uncertainty, and Uncertainty\nMisalignment, where models convey uncertainty inaccurately. To tackle these\nchallenges, we propose a refinement-based data collection framework and a\ntwo-stage training pipeline. Our framework adopts a divide-and-conquer\nstrategy, refining uncertainty based on atomic claims. The collected data are\nthen used in training through supervised fine-tuning (SFT) and direct\npreference optimization (DPO) to enhance uncertainty expression. Extensive\nexperiments on three long-form instruction following datasets show that our\nmethod significantly improves accuracy, reduces hallucinations, and maintains\nthe comprehensiveness of responses.", "AI": {"tldr": "The paper introduces LoGU, a task for long-form generation with uncertainty, addressing challenges like Uncertainty Suppression and Misalignment. It proposes a refinement-based data collection framework and a two-stage training pipeline (SFT and DPO) to improve uncertainty expression, reducing hallucinations while maintaining response quality.", "motivation": "LLMs often generate factually incorrect content (hallucinations). Existing uncertainty modeling focuses on short-form QA, but real-world applications need longer responses. This work aims to improve uncertainty expression in long-form generation.", "method": "A refinement-based data collection framework and two-stage training pipeline (supervised fine-tuning and direct preference optimization) are proposed. The framework refines uncertainty based on atomic claims.", "result": "Experiments on three datasets show the method improves accuracy, reduces hallucinations, and maintains response comprehensiveness.", "conclusion": "The proposed approach effectively addresses uncertainty challenges in long-form generation, enhancing model reliability and factual correctness."}}
{"id": "2403.01422", "pdf": "https://arxiv.org/pdf/2403.01422", "abs": "https://arxiv.org/abs/2403.01422", "authors": ["Zhende Song", "Chenchen Wang", "Jiamu Sheng", "Chi Zhang", "Shengji Tang", "Jiayuan Fan", "Tao Chen"], "title": "DreamFrame: Enhancing Video Understanding via Automatically Generated QA and Style-Consistent Keyframes", "categories": ["cs.CV"], "comment": null, "summary": "Recent large vision-language models (LVLMs) for video understanding are\nprimarily fine-tuned with various videos scraped from online platforms.\nExisting datasets, such as ActivityNet, require considerable human labor for\nstructuring and annotation before effectively utilized for tuning LVLMs. While\ncurrent LVLMs are primarily trained on existing datasets in broad,\ngeneral-purpose settings, adapting them to specific downstream scenarios\nremains challenging, as collecting and annotating task-specific videos is\nhighly labor-intensive and time-consuming. To address this issue, we propose a\nthree-stage framework named DreamFrame for automatically generating\nstyle-consistent keyframes and corresponding question-answer (QA) pairs to\nsupport LVLM instruction tuning. DreamFrame generates datasets in a movie-like\nmanner. First, we utilize an LLM to generate structured movie plots including\nmovie prior information (like overview and style), frame descriptions and\nplot-related QA pairs, with a story expansion strategy to mitigate context\nlength limitations.Then, to ensure visual consistency across generated frames,\nwe design a Style Immobilization Process which maintains consistent style\nthrough an embedding learning strategy. Finally, frame descriptions and style\nembeddings are integrated to produce coherent keyframes. Using DreamFrame, we\nconstruct a dataset comprising approximately 1k stylized keyframe-like videos\nand 100k diverse QA pairs. Extensive fine-tuned experiments on various LVLM\narchitectures demonstrate the effectiveness of the proposed dataset.\nFurthermore, based on the proposed dataset, we fine-tune a new LVLM named\nDreamFrame-7B, which significantly surpasses the previous similar-sized LVLMs\nacross different benchmarks.", "AI": {"tldr": "DreamFrame is a three-stage framework for generating style-consistent keyframes and QA pairs to support LVLM instruction tuning, reducing the need for manual dataset creation.", "motivation": "Existing LVLM datasets require heavy human labor for annotation, making adaptation to specific tasks challenging. DreamFrame automates dataset generation to address this.", "method": "DreamFrame uses an LLM to generate structured movie plots, a Style Immobilization Process for visual consistency, and integrates descriptions and embeddings to create keyframes.", "result": "The framework produced 1k stylized videos and 100k QA pairs, and fine-tuned DreamFrame-7B outperformed similar-sized LVLMs.", "conclusion": "DreamFrame effectively automates dataset generation for LVLMs, improving performance and reducing manual effort."}}
{"id": "2505.19641", "pdf": "https://arxiv.org/pdf/2505.19641", "abs": "https://arxiv.org/abs/2505.19641", "authors": ["Junteng Liu", "Yuanxiang Fan", "Zhuo Jiang", "Han Ding", "Yongyi Hu", "Chi Zhang", "Yiqi Shi", "Shitong Weng", "Aili Chen", "Shiqi Chen", "Yunan Huang", "Mozhi Zhang", "Pengyu Zhao", "Junjie Yan", "Junxian He"], "title": "SynLogic: Synthesizing Verifiable Reasoning Data at Scale for Learning Logical Reasoning and Beyond", "categories": ["cs.AI", "cs.CL"], "comment": null, "summary": "Recent advances such as OpenAI-o1 and DeepSeek R1 have demonstrated the\npotential of Reinforcement Learning (RL) to enhance reasoning abilities in\nLarge Language Models (LLMs). While open-source replication efforts have\nprimarily focused on mathematical and coding domains, methods and resources for\ndeveloping general reasoning capabilities remain underexplored. This gap is\npartly due to the challenge of collecting diverse and verifiable reasoning data\nsuitable for RL. We hypothesize that logical reasoning is critical for\ndeveloping general reasoning capabilities, as logic forms a fundamental\nbuilding block of reasoning. In this work, we present SynLogic, a data\nsynthesis framework and dataset that generates diverse logical reasoning data\nat scale, encompassing 35 diverse logical reasoning tasks. The SynLogic\napproach enables controlled synthesis of data with adjustable difficulty and\nquantity. Importantly, all examples can be verified by simple rules, making\nthem ideally suited for RL with verifiable rewards. In our experiments, we\nvalidate the effectiveness of RL training on the SynLogic dataset based on 7B\nand 32B models. SynLogic leads to state-of-the-art logical reasoning\nperformance among open-source datasets, surpassing DeepSeek-R1-Distill-Qwen-32B\nby 6 points on BBEH. Furthermore, mixing SynLogic data with mathematical and\ncoding tasks improves the training efficiency of these domains and\nsignificantly enhances reasoning generalization. Notably, our mixed training\nmodel outperforms DeepSeek-R1-Zero-Qwen-32B across multiple benchmarks. These\nfindings position SynLogic as a valuable resource for advancing the broader\nreasoning capabilities of LLMs. We open-source both the data synthesis pipeline\nand the SynLogic dataset at https://github.com/MiniMax-AI/SynLogic.", "AI": {"tldr": "SynLogic is a framework for generating diverse logical reasoning data, enhancing RL training for LLMs, and improving reasoning generalization.", "motivation": "The gap in methods and resources for general reasoning capabilities in LLMs, especially due to the lack of diverse and verifiable reasoning data for RL.", "method": "SynLogic synthesizes scalable, verifiable logical reasoning data across 35 tasks, with adjustable difficulty and quantity.", "result": "SynLogic achieves state-of-the-art logical reasoning performance and improves training efficiency and generalization when mixed with other tasks.", "conclusion": "SynLogic is a valuable resource for advancing LLMs' reasoning capabilities, with open-sourced data and pipeline."}}
{"id": "2506.03780", "pdf": "https://arxiv.org/pdf/2506.03780", "abs": "https://arxiv.org/abs/2506.03780", "authors": ["Hasan Fallahgoul"], "title": "High-Dimensional Learning in Finance", "categories": ["q-fin.ST", "cs.LG", "econ.EM", "stat.ML"], "comment": null, "summary": "Recent advances in machine learning have shown promising results for\nfinancial prediction using large, over-parameterized models. This paper\nprovides theoretical foundations and empirical validation for understanding\nwhen and how these methods achieve predictive success. I examine three key\naspects of high-dimensional learning in finance. First, I prove that\nwithin-sample standardization in Random Fourier Features implementations\nfundamentally alters the underlying Gaussian kernel approximation, replacing\nshift-invariant kernels with training-set dependent alternatives. Second, I\nderive sample complexity bounds showing when reliable learning becomes\ninformation-theoretically impossible under weak signal-to-noise ratios typical\nin finance. Third, VC-dimension analysis reveals that ridgeless regression's\neffective complexity is bounded by sample size rather than nominal feature\ndimension. Comprehensive numerical validation confirms these theoretical\npredictions, revealing systematic breakdown of claimed theoretical properties\nacross realistic parameter ranges. These results show that when sample size is\nsmall and features are high-dimensional, observed predictive success is\nnecessarily driven by low-complexity artifacts, not genuine high-dimensional\nlearning.", "AI": {"tldr": "The paper analyzes when and how over-parameterized machine learning models succeed in financial prediction, revealing limitations under small sample sizes and high-dimensional features.", "motivation": "To understand the theoretical and empirical conditions under which large, over-parameterized models achieve predictive success in finance.", "method": "Examines three aspects: (1) standardization effects in Random Fourier Features, (2) sample complexity bounds under weak signal-to-noise ratios, and (3) VC-dimension analysis of ridgeless regression.", "result": "Theoretical predictions are validated numerically, showing systematic breakdowns in claimed properties. Predictive success in small-sample, high-dimensional settings is driven by low-complexity artifacts.", "conclusion": "Over-parameterized models' success in finance is limited by sample size and feature dimensionality, often relying on artifacts rather than genuine high-dimensional learning."}}
{"id": "2410.16502", "pdf": "https://arxiv.org/pdf/2410.16502", "abs": "https://arxiv.org/abs/2410.16502", "authors": ["Jason Chan", "Robert Gaizauskas", "Zhixue Zhao"], "title": "RULEBREAKERS: Challenging LLMs at the Crossroads between Formal Logic and Human-like Reasoning", "categories": ["cs.CL"], "comment": "Preprint. Accepted by ICML 2025", "summary": "Formal logic enables computers to reason in natural language by representing\nsentences in symbolic forms and applying rules to derive conclusions. However,\nin what our study characterizes as \"rulebreaker\" scenarios, this method can\nlead to conclusions that are typically not inferred or accepted by humans given\ntheir common sense and factual knowledge. Inspired by works in cognitive\nscience, we create RULEBREAKERS, the first dataset for rigorously evaluating\nthe ability of large language models (LLMs) to recognize and respond to\nrulebreakers (versus non-rulebreakers) in a human-like manner. Evaluating seven\nLLMs, we find that most models, including GPT-4o, achieve mediocre accuracy on\nRULEBREAKERS and exhibit some tendency to over-rigidly apply logical rules\nunlike what is expected from typical human reasoners. Further analysis suggests\nthat this apparent failure is potentially associated with the models' poor\nutilization of their world knowledge and their attention distribution patterns.\nWhilst revealing a limitation of current LLMs, our study also provides a timely\ncounterbalance to a growing body of recent works that propose methods relying\non formal logic to improve LLMs' general reasoning capabilities, highlighting\ntheir risk of further increasing divergence between LLMs and human-like\nreasoning.", "AI": {"tldr": "The paper introduces RULEBREAKERS, a dataset to evaluate LLMs' ability to handle rulebreaker scenarios, finding most models, including GPT-4o, perform poorly due to over-rigid logic application and poor world knowledge utilization.", "motivation": "To assess LLMs' human-like reasoning in rulebreaker scenarios, contrasting formal logic's limitations with human common sense.", "method": "Creation of the RULEBREAKERS dataset and evaluation of seven LLMs, including GPT-4o, focusing on their accuracy and reasoning patterns.", "result": "Most LLMs achieve mediocre accuracy, over-applying logical rules and underutilizing world knowledge, diverging from human-like reasoning.", "conclusion": "Current LLMs struggle with rulebreaker scenarios, highlighting risks of relying on formal logic for improving reasoning, as it may widen the gap between LLMs and human-like reasoning."}}
{"id": "2404.10332", "pdf": "https://arxiv.org/pdf/2404.10332", "abs": "https://arxiv.org/abs/2404.10332", "authors": ["Rui Hu", "Yahan Tu", "Shuyu Wei", "Dongyuan Lu", "Jitao Sang"], "title": "Prescribing the Right Remedy: Mitigating Hallucinations in Large Vision-Language Models via Targeted Instruction Tuning", "categories": ["cs.CV", "cs.AI"], "comment": "Accepted in Information Sciences 2025", "summary": "Despite achieving outstanding performance on various cross-modal tasks,\ncurrent large vision-language models (LVLMs) still suffer from hallucination\nissues, manifesting as inconsistencies between their generated responses and\nthe corresponding images. Prior research has implicated that the low quality of\ninstruction data, particularly the skewed balance between positive and negative\nsamples, is a significant contributor to model hallucinations. Recently,\nresearchers have proposed high-quality instruction datasets, such as\nLRV-Instruction, to mitigate model hallucination. Nonetheless, our\ninvestigation reveals that hallucinatory concepts from different LVLMs exhibit\nspecificity, i.e. the distribution of hallucinatory concepts varies\nsignificantly across models. Existing datasets did not consider the\nhallucination specificity of different models in the design processes, thereby\ndiminishing their efficacy in mitigating model hallucination. In this paper, we\npropose a targeted instruction data generation framework named DFTG that\ntailored to the hallucination specificity of different models. Concretely, DFTG\nconsists of two stages: hallucination diagnosis, which extracts the necessary\ninformation from the model's responses and images for hallucination diagnosis;\nand targeted data generation, which generates targeted instruction data based\non diagnostic results. The experimental results on hallucination benchmarks\ndemonstrate that the targeted instruction data generated by our method are more\neffective in mitigating hallucinations compared to previous datasets.", "AI": {"tldr": "The paper introduces DFTG, a framework to address hallucination specificity in LVLMs by generating targeted instruction data.", "motivation": "Current LVLMs suffer from hallucination issues due to low-quality instruction data, and existing datasets fail to account for model-specific hallucination patterns.", "method": "DFTG involves hallucination diagnosis and targeted data generation to create model-specific instruction data.", "result": "Experiments show DFTG-generated data is more effective in reducing hallucinations compared to prior datasets.", "conclusion": "DFTG addresses model-specific hallucination issues, improving LVLM performance."}}
{"id": "2505.21427", "pdf": "https://arxiv.org/pdf/2505.21427", "abs": "https://arxiv.org/abs/2505.21427", "authors": ["Xianling Mu", "Joseph Ternasky", "Fuat Alican", "Yigit Ihlamur"], "title": "Policy Induction: Predicting Startup Success via Explainable Memory-Augmented In-Context Learning", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "Early-stage startup investment is a high-risk endeavor characterized by\nscarce data and uncertain outcomes. Traditional machine learning approaches\noften require large, labeled datasets and extensive fine-tuning, yet remain\nopaque and difficult for domain experts to interpret or improve. In this paper,\nwe propose a transparent and data-efficient investment decision framework\npowered by memory-augmented large language models (LLMs) using in-context\nlearning (ICL). Central to our method is a natural language policy embedded\ndirectly into the LLM prompt, enabling the model to apply explicit reasoning\npatterns and allowing human experts to easily interpret, audit, and iteratively\nrefine the logic. We introduce a lightweight training process that combines\nfew-shot learning with an in-context learning loop, enabling the LLM to update\nits decision policy iteratively based on structured feedback. With only minimal\nsupervision and no gradient-based optimization, our system predicts startup\nsuccess far more accurately than existing benchmarks. It is over 20x more\nprecise than random chance, which succeeds 1.9% of the time. It is also 7.1x\nmore precise than the typical 5.6% success rate of top-tier venture capital\n(VC) firms.", "AI": {"tldr": "A transparent, data-efficient framework for early-stage startup investment using memory-augmented LLMs with in-context learning outperforms traditional methods and VC success rates.", "motivation": "Early-stage startup investment lacks data and transparency; traditional ML methods are opaque and require large datasets.", "method": "Uses memory-augmented LLMs with in-context learning, embedding natural language policies for interpretability and iterative refinement.", "result": "Achieves 20x higher precision than random chance (1.9%) and 7.1x higher than top-tier VC firms (5.6%).", "conclusion": "The framework offers a scalable, interpretable solution for high-risk investment decisions with minimal supervision."}}
{"id": "2506.03796", "pdf": "https://arxiv.org/pdf/2506.03796", "abs": "https://arxiv.org/abs/2506.03796", "authors": ["Penelope Madysa", "Sabrina Appel", "Verena Kain", "Michael Schenk"], "title": "Geoff: The Generic Optimization Framework & Frontend for Particle Accelerator Controls", "categories": ["physics.acc-ph", "cs.LG"], "comment": "18 pages, 5 figures. Submitted to SoftwareX", "summary": "Geoff is a collection of Python packages that form a framework for automation\nof particle accelerator controls. With particle accelerator laboratories around\nthe world researching machine learning techniques to improve accelerator\nperformance and uptime, a multitude of approaches and algorithms have emerged.\nThe purpose of Geoff is to harmonize these approaches and to minimize friction\nwhen comparing or migrating between them. It provides standardized interfaces\nfor optimization problems, utility functions to speed up development, and a\nreference GUI application that ties everything together. Geoff is an\nopen-source library developed at CERN and maintained and updated in\ncollaboration between CERN and GSI as part of the EURO-LABS project. This paper\ngives an overview over Geoff's design, features, and current usage.", "AI": {"tldr": "Geoff is a Python framework for standardizing and automating particle accelerator controls, facilitating ML research and reducing friction between different approaches.", "motivation": "To harmonize diverse machine learning techniques in particle accelerator controls and ease comparison or migration between methods.", "method": "Provides standardized interfaces for optimization, utility functions for development, and a reference GUI application.", "result": "Geoff is an open-source tool developed collaboratively by CERN and GSI, widely used in the EURO-LABS project.", "conclusion": "Geoff successfully standardizes and simplifies ML-based automation in particle accelerator controls, promoting collaboration and efficiency."}}
{"id": "2411.01747", "pdf": "https://arxiv.org/pdf/2411.01747", "abs": "https://arxiv.org/abs/2411.01747", "authors": ["Dang Nguyen", "Viet Dac Lai", "Seunghyun Yoon", "Ryan A. Rossi", "Handong Zhao", "Ruiyi Zhang", "Puneet Mathur", "Nedim Lipka", "Yu Wang", "Trung Bui", "Franck Dernoncourt", "Tianyi Zhou"], "title": "DynaSaur: Large Language Agents Beyond Predefined Actions", "categories": ["cs.CL"], "comment": "19 pages, 10 figures", "summary": "Existing LLM agent systems typically select actions from a fixed and\npredefined set at every step. While this approach is effective in closed,\nnarrowly scoped environments, it presents two major challenges for real-world,\nopen-ended scenarios: (1) it significantly restricts the planning and acting\ncapabilities of LLM agents, and (2) it requires substantial human effort to\nenumerate and implement all possible actions, which is impractical in complex\nenvironments with a vast number of potential actions. To address these\nlimitations, we propose an LLM agent framework that can dynamically create and\ncompose actions as needed. In this framework, the agent interacts with its\nenvironment by generating and executing programs written in a general-purpose\nprogramming language. Moreover, generated actions are accumulated over time for\nfuture reuse. Our extensive experiments across multiple benchmarks show that\nthis framework significantly improves flexibility and outperforms prior methods\nthat rely on a fixed action set. Notably, it enables LLM agents to adapt and\nrecover in scenarios where predefined actions are insufficient or fail due to\nunforeseen edge cases. Our code can be found in\nhttps://github.com/adobe-research/dynasaur.", "AI": {"tldr": "Proposes a dynamic LLM agent framework for open-ended scenarios, enabling action creation and reuse, outperforming fixed-action methods.", "motivation": "Addresses limitations of fixed-action LLM agents in real-world, open-ended environments by enhancing flexibility and reducing human effort.", "method": "Uses a framework where agents generate and execute programs in a general-purpose language, accumulating actions for reuse.", "result": "Outperforms fixed-action methods, improves adaptability, and handles unforeseen edge cases effectively.", "conclusion": "The dynamic framework enhances LLM agent capabilities in complex, open-ended scenarios."}}
{"id": "2407.12274", "pdf": "https://arxiv.org/pdf/2407.12274", "abs": "https://arxiv.org/abs/2407.12274", "authors": ["Cong Cai", "Shan Liang", "Xuefei Liu", "Kang Zhu", "Zhengqi Wen", "Jianhua Tao", "Heng Xie", "Jizhou Cui", "Yiming Ma", "Zhenhua Cheng", "Hanzhe Xu", "Ruibo Fu", "Bin Liu", "Yongwei Li"], "title": "MDPE: A Multimodal Deception Dataset with Personality and Emotional Characteristics", "categories": ["cs.CV"], "comment": "Code and data are available; Submitted to ACM Multimedia 2025 Dataset\n  Track", "summary": "Deception detection has garnered increasing attention in recent years due to\nthe significant growth of digital media and heightened ethical and security\nconcerns. It has been extensively studied using multimodal methods, including\nvideo, audio, and text. In addition, individual differences in deception\nproduction and detection are believed to play a crucial role.Although some\nstudies have utilized individual information such as personality traits to\nenhance the performance of deception detection, current systems remain limited,\npartly due to a lack of sufficient datasets for evaluating performance. To\naddress this issue, we introduce a multimodal deception dataset MDPE. Besides\ndeception features, this dataset also includes individual differences\ninformation in personality and emotional expression characteristics. It can\nexplore the impact of individual differences on deception behavior. It\ncomprises over 104 hours of deception and emotional videos from 193 subjects.\nFurthermore, we conducted numerous experiments to provide valuable insights for\nfuture deception detection research. MDPE not only supports deception\ndetection, but also provides conditions for tasks such as personality\nrecognition and emotion recognition, and can even study the relationships\nbetween them. We believe that MDPE will become a valuable resource for\npromoting research in the field of affective computing.", "AI": {"tldr": "The paper introduces MDPE, a multimodal deception dataset with individual differences, to enhance deception detection research.", "motivation": "Addressing the lack of sufficient datasets for evaluating deception detection performance, especially considering individual differences.", "method": "Creation of the MDPE dataset, including deception features, personality traits, and emotional expression characteristics from 193 subjects.", "result": "MDPE provides over 104 hours of deception and emotional videos, supporting deception detection, personality recognition, and emotion recognition.", "conclusion": "MDPE is a valuable resource for advancing affective computing and deception detection research."}}
{"id": "2505.22990", "pdf": "https://arxiv.org/pdf/2505.22990", "abs": "https://arxiv.org/abs/2505.22990", "authors": ["Pin-Han Chen", "Yu-Sheng Lin", "Wei-Cheng Lee", "Tin-Yu Leu", "Po-Hsiang Hsu", "Anjana Dissanayake", "Sungjin Oh", "Chinq-Shiun Chiu"], "title": "MenTeR: A fully-automated Multi-agenT workflow for end-to-end RF/Analog Circuits Netlist Design", "categories": ["cs.AI", "cs.ET", "cs.LG"], "comment": "9 pages, 7 figures, accepted by IEEE ICLAD 2025", "summary": "RF/Analog design is essential for bridging digital technologies with\nreal-world signals, ensuring the functionality and reliability of a wide range\nof electronic systems. However, analog design procedures are often intricate,\ntime-consuming and reliant on expert intuition, and hinder the time and cost\nefficiency of circuit development. To overcome the limitations of the manual\ncircuit design, we introduce MenTeR - a multiagent workflow integrated into an\nend-to-end analog design framework. By employing multiple specialized AI agents\nthat collaboratively address different aspects of the design process, such as\nspecification understanding, circuit optimization, and test bench validation,\nMenTeR reduces the dependency on frequent trial-and-error-style intervention.\nMenTeR not only accelerates the design cycle time but also facilitates a\nbroader exploration of the design space, demonstrating robust capabilities in\nhandling real-world analog systems. We believe that MenTeR lays the groundwork\nfor future \"RF/Analog Copilots\" that can collaborate seamlessly with human\ndesigners.", "AI": {"tldr": "MenTeR is a multiagent AI workflow for analog design, reducing manual effort and accelerating the design process.", "motivation": "Analog design is complex and time-consuming, relying heavily on expert intuition, which hinders efficiency.", "method": "MenTeR uses specialized AI agents for tasks like specification understanding, optimization, and validation.", "result": "MenTeR speeds up design cycles and enables broader design space exploration.", "conclusion": "MenTeR paves the way for future AI-assisted analog design tools."}}
{"id": "2506.03819", "pdf": "https://arxiv.org/pdf/2506.03819", "abs": "https://arxiv.org/abs/2506.03819", "authors": ["Marc Aurel Vischer", "Noelia Otero", "Jackie Ma"], "title": "Spatially Resolved Meteorological and Ancillary Data in Central Europe for Rainfall Streamflow Modeling", "categories": ["stat.ML", "cs.LG", "I.2.1; I.6.5; J.2"], "comment": "6 pages, 1 figure", "summary": "We present a dataset for rainfall streamflow modeling that is fully spatially\nresolved with the aim of taking neural network-driven hydrological modeling\nbeyond lumped catchments. To this end, we compiled data covering five river\nbasins in central Europe: upper Danube, Elbe, Oder, Rhine, and Weser. The\ndataset contains meteorological forcings, as well as ancillary information on\nsoil, rock, land cover, and orography. The data is harmonized to a regular 9km\ntimes 9km grid and contains daily values that span from October 1981 to\nSeptember 2011. We also provide code to further combine our dataset with\npublicly available river discharge data for end-to-end rainfall streamflow\nmodeling.", "AI": {"tldr": "A spatially resolved dataset for rainfall-streamflow modeling in five European river basins, harmonized to a 9km grid, with daily data from 1981-2011 and tools for integration with discharge data.", "motivation": "To advance neural network-driven hydrological modeling beyond lumped catchments by providing spatially resolved data.", "method": "Compiled meteorological, soil, rock, land cover, and orography data for five river basins, harmonized to a 9km grid, and provided code for integration with discharge data.", "result": "A comprehensive dataset ready for end-to-end rainfall-streamflow modeling.", "conclusion": "The dataset enables spatially resolved hydrological modeling, supporting advancements in neural network applications for hydrology."}}
{"id": "2411.02430", "pdf": "https://arxiv.org/pdf/2411.02430", "abs": "https://arxiv.org/abs/2411.02430", "authors": ["Lin Wang", "Xiaocui Yang", "Shi Feng", "Daling Wang", "Yifei Zhang", "Zhitao Zhang"], "title": "Generative Emotion Cause Explanation in Multimodal Conversations", "categories": ["cs.CL", "cs.AI", "cs.CV", "cs.LG"], "comment": null, "summary": "Multimodal conversation, a crucial form of human communication, carries rich\nemotional content, making the exploration of the causes of emotions within it a\nresearch endeavor of significant importance. However, existing research on the\ncauses of emotions typically employs an utterance selection method within a\nsingle textual modality to locate causal utterances. This approach remains\nlimited to coarse-grained assessments, lacks nuanced explanations of emotional\ncausation, and demonstrates inadequate capability in identifying multimodal\nemotional triggers. Therefore, we introduce a task-\\textbf{Multimodal Emotion\nCause Explanation in Conversation (MECEC)}. This task aims to generate a\nsummary based on the multimodal context of conversations, clearly and\nintuitively describing the reasons that trigger a given emotion. To adapt to\nthis task, we develop a new dataset (ECEM) based on the MELD dataset. ECEM\ncombines video clips with detailed explanations of character emotions, helping\nto explore the causal factors behind emotional expression in multimodal\nconversations. A novel approach, FAME-Net, is further proposed, that harnesses\nthe power of Large Language Models (LLMs) to analyze visual data and accurately\ninterpret the emotions conveyed through facial expressions in videos. By\nexploiting the contagion effect of facial emotions, FAME-Net effectively\ncaptures the emotional causes of individuals engaged in conversations. Our\nexperimental results on the newly constructed dataset show that FAME-Net\noutperforms several excellent baselines. Code and dataset are available at\nhttps://github.com/3222345200/FAME-Net.", "AI": {"tldr": "The paper introduces MECEC, a task for explaining emotional causes in multimodal conversations, and proposes FAME-Net, a method leveraging LLMs to analyze visual data for emotion cause explanation.", "motivation": "Existing emotion cause research is limited to single textual modality, lacking nuanced explanations and multimodal capability.", "method": "Develops the ECEM dataset and FAME-Net, which uses LLMs to analyze facial expressions in videos for emotion cause identification.", "result": "FAME-Net outperforms baselines on the ECEM dataset.", "conclusion": "The work advances multimodal emotion cause explanation, with FAME-Net showing strong performance."}}
{"id": "2407.18437", "pdf": "https://arxiv.org/pdf/2407.18437", "abs": "https://arxiv.org/abs/2407.18437", "authors": ["Gihwan Kim", "Jemin Lee", "Sihyeong Park", "Yongin Kwon", "Hyungshin Kim"], "title": "Mixed Non-linear Quantization for Vision Transformers", "categories": ["cs.CV", "cs.AI"], "comment": "16 pages, 4 figures, Accepted in ECCV Workshops 2024", "summary": "The majority of quantization methods have been proposed to reduce the model\nsize of Vision Transformers, yet most of them have overlooked the quantization\nof non-linear operations. Only a few works have addressed quantization for\nnon-linear operations, but they applied a single quantization method across all\nnon-linear operations. We believe that this can be further improved by\nemploying a different quantization method for each non-linear operation.\nTherefore, to assign the most error-minimizing quantization method from the\nknown methods to each non-linear layer, we propose a mixed non-linear\nquantization that considers layer-wise quantization sensitivity measured by\nSQNR difference metric. The results show that our method outperforms I-BERT,\nFQ-ViT, and I-ViT in both 8-bit and 6-bit settings for ViT, DeiT, and Swin\nmodels by an average of 0.6%p and 19.6%p, respectively. Our method outperforms\nI-BERT and I-ViT by 0.6%p and 20.8%p, respectively, when training time is\nlimited. We plan to release our code at\nhttps://gitlab.com/ones-ai/mixed-non-linear-quantization.", "AI": {"tldr": "Proposes a mixed non-linear quantization method for Vision Transformers, outperforming existing methods by adapting quantization per non-linear layer.", "motivation": "Existing quantization methods overlook non-linear operations or apply uniform quantization, which can be improved by layer-specific methods.", "method": "Uses a mixed non-linear quantization approach, assigning error-minimizing methods per layer based on SQNR difference metric.", "result": "Outperforms I-BERT, FQ-ViT, and I-ViT in 8-bit and 6-bit settings by 0.6%p and 19.6%p, respectively.", "conclusion": "The method is effective and scalable, with plans to release code for broader use."}}
{"id": "2505.23703", "pdf": "https://arxiv.org/pdf/2505.23703", "abs": "https://arxiv.org/abs/2505.23703", "authors": ["Ruida Wang", "Yuxin Li", "Yi R. Fung", "Tong Zhang"], "title": "Let's Reason Formally: Natural-Formal Hybrid Reasoning Enhances LLM's Math Capability", "categories": ["cs.AI", "cs.CL"], "comment": null, "summary": "Enhancing the mathematical reasoning capabilities of LLMs has garnered\nsignificant attention in both the mathematical and computer science\ncommunities. Recent works have made substantial progress in both Natural\nLanguage (NL) reasoning and Formal Language (FL) reasoning by leveraging the\npotential of pure Reinforcement Learning (RL) methods on base models. However,\nRL approaches struggle to impart new capabilities not presented in the base\nmodel, highlighting the need to integrate more knowledge like FL into NL math\nreasoning effectively. Yet, this integration is challenging due to inherent\ndisparities in problem structure and reasoning format between NL and FL. To\naddress these challenges, we introduce **NL-FL HybridReasoning**, an end-to-end\nframework designed to incorporate the FL expert into NL math problem-solving.\nTo bridge the NL and FL input format gap, we propose the *NL-FL Problem\nAlignment* method, which reformulates the Question-Answering (QA) problems in\nNL as existence theorems in FL. Subsequently, the *Mixed Problem Input*\ntechnique we provide enables the FL reasoner to handle both QA and existence\nproblems concurrently. Lastly, we mitigate the NL and FL output format gap in\nreasoning through an LLM-based *Answer Extraction* mechanism. Comprehensive\nexperiments demonstrate that the **HybridReasoning** framework achieves\n**89.80%** and **84.34%** accuracy rates on the MATH-500 and the AMC\nbenchmarks, surpassing the NL baseline by 4.60% and 4.82%, respectively.\nNotably, some problems resolved by our framework remain unsolved by the NL\nbaseline model even under a larger number of trials.", "AI": {"tldr": "The paper introduces **NL-FL HybridReasoning**, a framework combining Natural Language (NL) and Formal Language (FL) to enhance math reasoning in LLMs, achieving higher accuracy than NL baselines.", "motivation": "Current RL methods for math reasoning in LLMs struggle to integrate new capabilities like FL into NL reasoning due to structural disparities between NL and FL.", "method": "The framework includes *NL-FL Problem Alignment* to reformulate NL QA problems as FL existence theorems, *Mixed Problem Input* for FL reasoners to handle both QA and existence problems, and *Answer Extraction* to bridge output format gaps.", "result": "The framework achieves 89.80% and 84.34% accuracy on MATH-500 and AMC benchmarks, outperforming NL baselines by 4.60% and 4.82%, respectively.", "conclusion": "**HybridReasoning** effectively integrates FL into NL math reasoning, solving problems unsolved by NL baselines, demonstrating its superiority."}}
{"id": "2506.03849", "pdf": "https://arxiv.org/pdf/2506.03849", "abs": "https://arxiv.org/abs/2506.03849", "authors": ["Benjamin Dupuis", "Dario Shariatian", "Maxime Haddouche", "Alain Durmus", "Umut Simsekli"], "title": "Algorithm- and Data-Dependent Generalization Bounds for Score-Based Generative Models", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "Score-based generative models (SGMs) have emerged as one of the most popular\nclasses of generative models. A substantial body of work now exists on the\nanalysis of SGMs, focusing either on discretization aspects or on their\nstatistical performance. In the latter case, bounds have been derived, under\nvarious metrics, between the true data distribution and the distribution\ninduced by the SGM, often demonstrating polynomial convergence rates with\nrespect to the number of training samples. However, these approaches adopt a\nlargely approximation theory viewpoint, which tends to be overly pessimistic\nand relatively coarse. In particular, they fail to fully explain the empirical\nsuccess of SGMs or capture the role of the optimization algorithm used in\npractice to train the score network. To support this observation, we first\npresent simple experiments illustrating the concrete impact of optimization\nhyperparameters on the generalization ability of the generated distribution.\nThen, this paper aims to bridge this theoretical gap by providing the first\nalgorithmic- and data-dependent generalization analysis for SGMs. In\nparticular, we establish bounds that explicitly account for the optimization\ndynamics of the learning algorithm, offering new insights into the\ngeneralization behavior of SGMs. Our theoretical findings are supported by\nempirical results on several datasets.", "AI": {"tldr": "The paper analyzes score-based generative models (SGMs), highlighting gaps in existing theoretical analyses and providing a new algorithmic- and data-dependent generalization analysis.", "motivation": "Existing analyses of SGMs focus on approximation theory, which is pessimistic and fails to explain empirical success or the role of optimization. This paper aims to bridge this gap.", "method": "The authors conduct experiments to show the impact of optimization hyperparameters and provide a new theoretical analysis accounting for optimization dynamics.", "result": "The paper establishes bounds that incorporate optimization dynamics, offering insights into SGM generalization. Empirical results support the findings.", "conclusion": "The study bridges a theoretical gap in SGM analysis, providing a more nuanced understanding of their generalization behavior."}}
{"id": "2411.04920", "pdf": "https://arxiv.org/pdf/2411.04920", "abs": "https://arxiv.org/abs/2411.04920", "authors": ["Yujia Hu", "Tuan-Phong Nguyen", "Shrestha Ghosh", "Simon Razniewski"], "title": "Enabling LLM Knowledge Analysis via Extensive Materialization", "categories": ["cs.CL", "cs.AI", "cs.DB"], "comment": "14 pages, 4 tables, 12 figures", "summary": "Large language models (LLMs) have majorly advanced NLP and AI, and next to\ntheir ability to perform a wide range of procedural tasks, a major success\nfactor is their internalized factual knowledge. Since Petroni et al. (2019),\nanalyzing this knowledge has gained attention. However, most approaches\ninvestigate one question at a time via modest-sized pre-defined samples,\nintroducing an ``availability bias'' (Tversky&Kahnemann, 1973) that prevents\nthe analysis of knowledge (or beliefs) of LLMs beyond the experimenter's\npredisposition.\n  To address this challenge, we propose a novel methodology to comprehensively\nmaterialize an LLM's factual knowledge through recursive querying and result\nconsolidation. Our approach is a milestone for LLM research, for the first time\nproviding constructive insights into the scope and structure of LLM knowledge\n(or beliefs).\n  As a prototype, we build GPTKB, a knowledge base (KB) comprising 101 million\nrelational triples for over 2.9 million entities from GPT-4o-mini. We use GPTKB\nto exemplarily analyze GPT-4o-mini's factual knowledge in terms of scale,\naccuracy, bias, cutoff and consistency, at the same time. GPTKB is accessible\nat https://gptkb.org", "AI": {"tldr": "The paper introduces GPTKB, a knowledge base derived from GPT-4o-mini, to comprehensively analyze LLM factual knowledge, addressing biases in prior methods.", "motivation": "Existing methods for analyzing LLM knowledge are limited by small samples and experimenter bias, hindering comprehensive understanding.", "method": "Proposes recursive querying and result consolidation to materialize LLM knowledge, creating GPTKB with 101M relational triples.", "result": "GPTKB enables large-scale analysis of GPT-4o-mini's knowledge, assessing scale, accuracy, bias, cutoff, and consistency.", "conclusion": "GPTKB is a milestone for LLM research, offering insights into the scope and structure of LLM knowledge."}}
{"id": "2408.05159", "pdf": "https://arxiv.org/pdf/2408.05159", "abs": "https://arxiv.org/abs/2408.05159", "authors": ["Ziyue Zhang", "Mingbao Lin", "Shuicheng Yan", "Rongrong Ji"], "title": "EasyInv: Toward Fast and Better DDIM Inversion", "categories": ["cs.CV"], "comment": "Accepted by ICML 2025", "summary": "This paper introduces EasyInv, an easy yet novel approach that significantly\nadvances the field of DDIM Inversion by addressing the inherent inefficiencies\nand performance limitations of traditional iterative optimization methods. At\nthe core of our EasyInv is a refined strategy for approximating inversion\nnoise, which is pivotal for enhancing the accuracy and reliability of the\ninversion process. By prioritizing the initial latent state, which encapsulates\nrich information about the original images, EasyInv steers clear of the\niterative refinement of noise items. Instead, we introduce a methodical\naggregation of the latent state from the preceding time step with the current\nstate, effectively increasing the influence of the initial latent state and\nmitigating the impact of noise. We illustrate that EasyInv is capable of\ndelivering results that are either on par with or exceed those of the\nconventional DDIM Inversion approach, especially under conditions where the\nmodel's precision is limited or computational resources are scarce.\nConcurrently, our EasyInv offers an approximate threefold enhancement regarding\ninference efficiency over off-the-shelf iterative optimization techniques. It\ncan be easily combined with most existing inversion methods by only four lines\nof code. See code at https://github.com/potato-kitty/EasyInv.", "AI": {"tldr": "EasyInv introduces a simplified, efficient approach to DDIM Inversion by refining inversion noise approximation and leveraging the initial latent state, outperforming traditional methods in accuracy and speed.", "motivation": "Address inefficiencies and performance limitations of traditional iterative optimization methods in DDIM Inversion.", "method": "Refines inversion noise approximation, prioritizes the initial latent state, and aggregates latent states methodically to reduce noise impact.", "result": "Matches or exceeds conventional DDIM Inversion accuracy, especially in limited precision or resource scenarios, with a threefold efficiency boost.", "conclusion": "EasyInv is a highly efficient, accurate, and easy-to-integrate solution for DDIM Inversion, offering significant improvements over traditional methods."}}
{"id": "2506.00140", "pdf": "https://arxiv.org/pdf/2506.00140", "abs": "https://arxiv.org/abs/2506.00140", "authors": ["Jesse Thibodeau", "Hadi Nekoei", "Afaf Ta\u00efk", "Janarthanan Rajendran", "Golnoosh Farnadi"], "title": "Balancing Profit and Fairness in Risk-Based Pricing Markets", "categories": ["cs.AI", "cs.LG", "econ.GN", "q-fin.EC"], "comment": null, "summary": "Dynamic, risk-based pricing can systematically exclude vulnerable consumer\ngroups from essential resources such as health insurance and consumer credit.\nWe show that a regulator can realign private incentives with social objectives\nthrough a learned, interpretable tax schedule. First, we provide a formal\nproposition that bounding each firm's \\emph{local} demographic gap implicitly\nbounds the \\emph{global} opt-out disparity, motivating firm-level penalties.\nBuilding on this insight we introduce \\texttt{MarketSim} -- an open-source,\nscalable simulator of heterogeneous consumers and profit-maximizing firms --\nand train a reinforcement learning (RL) social planner (SP) that selects a\nbracketed fairness-tax while remaining close to a simple linear prior via an\n$\\mathcal{L}_1$ regularizer. The learned policy is thus both transparent and\neasily interpretable. In two empirically calibrated markets, i.e., U.S.\nhealth-insurance and consumer-credit, our planner simultaneously raises\ndemand-fairness by up to $16\\%$ relative to unregulated Free Market while\noutperforming a fixed linear schedule in terms of social welfare without\nexplicit coordination. These results illustrate how AI-assisted regulation can\nconvert a competitive social dilemma into a win-win equilibrium, providing a\nprincipled and practical framework for fairness-aware market oversight.", "AI": {"tldr": "The paper proposes a learned, interpretable tax schedule to regulate dynamic pricing, ensuring fairness in markets like health insurance and credit. Using a simulator and RL, it improves fairness and welfare without explicit coordination.", "motivation": "Dynamic pricing can exclude vulnerable groups, creating a need for regulation to align private incentives with social fairness goals.", "method": "Develops a simulator (MarketSim) and trains an RL-based social planner to implement a fairness-tax, regularized for simplicity and interpretability.", "result": "In health-insurance and credit markets, the method boosts fairness by 16% and welfare compared to unregulated or fixed-tax approaches.", "conclusion": "AI-assisted regulation can transform competitive dilemmas into win-win outcomes, offering a practical framework for fairness in markets."}}
{"id": "2506.03863", "pdf": "https://arxiv.org/pdf/2506.03863", "abs": "https://arxiv.org/abs/2506.03863", "authors": ["Hao Li", "Qi Lv", "Rui Shao", "Xiang Deng", "Yinchuan Li", "Jianye Hao", "Liqiang Nie"], "title": "STAR: Learning Diverse Robot Skill Abstractions through Rotation-Augmented Vector Quantization", "categories": ["cs.RO", "cs.LG"], "comment": "Accepted by ICML 2025 Spotlight", "summary": "Transforming complex actions into discrete skill abstractions has\ndemonstrated strong potential for robotic manipulation. Existing approaches\nmainly leverage latent variable models, e.g., VQ-VAE, to learn skill\nabstractions through learned vectors (codebooks), while they suffer from\ncodebook collapse and modeling the causal relationship between learned skills.\nTo address these limitations, we present \\textbf{S}kill \\textbf{T}raining with\n\\textbf{A}ugmented \\textbf{R}otation (\\textbf{STAR}), a framework that advances\nboth skill learning and composition to complete complex behaviors.\nSpecifically, to prevent codebook collapse, we devise rotation-augmented\nresidual skill quantization (RaRSQ). It encodes relative angles between encoder\noutputs into the gradient flow by rotation-based gradient mechanism. Points\nwithin the same skill code are forced to be either pushed apart or pulled\ncloser together depending on gradient directions. Further, to capture the\ncausal relationship between skills, we present causal skill transformer (CST)\nwhich explicitly models dependencies between skill representations through an\nautoregressive mechanism for coherent action generation. Extensive experiments\ndemonstrate the superiority of STAR on both LIBERO benchmark and realworld\ntasks, with around 12\\% improvement over the baselines.", "AI": {"tldr": "STAR improves robotic manipulation by preventing codebook collapse and modeling causal skill relationships, achieving 12% better performance.", "motivation": "Existing methods like VQ-VAE suffer from codebook collapse and fail to model causal skill relationships, limiting their effectiveness.", "method": "STAR introduces RaRSQ for rotation-augmented skill quantization and CST for causal skill modeling via autoregression.", "result": "STAR outperforms baselines by ~12% on LIBERO and real-world tasks.", "conclusion": "STAR advances skill learning and composition, enhancing robotic manipulation capabilities."}}
{"id": "2411.05042", "pdf": "https://arxiv.org/pdf/2411.05042", "abs": "https://arxiv.org/abs/2411.05042", "authors": ["Iryna Hartsock", "Cyrillo Araujo", "Les Folio", "Ghulam Rasool"], "title": "Improving Radiology Report Conciseness and Structure via Local Large Language Models", "categories": ["cs.CL", "cs.AI"], "comment": "published version", "summary": "Radiology reports are often lengthy and unstructured, posing challenges for\nreferring physicians to quickly identify critical imaging findings while\nincreasing the risk of missed information. This retrospective study aimed to\nenhance radiology reports by making them concise and well-structured, with\nfindings organized by relevant organs. To achieve this, we utilized private\nlarge language models (LLMs) deployed locally within our institution's\nfirewall, ensuring data security and minimizing computational costs. Using a\ndataset of 814 radiology reports from seven board-certified body radiologists\nat Moffitt Cancer Center, we tested five prompting strategies within the\nLangChain framework. After evaluating several models, the Mixtral LLM\ndemonstrated superior adherence to formatting requirements compared to\nalternatives like Llama. The optimal strategy involved condensing reports first\nand then applying structured formatting based on specific instructions,\nreducing verbosity while improving clarity. Across all radiologists and\nreports, the Mixtral LLM reduced redundant word counts by more than 53%. These\nfindings highlight the potential of locally deployed, open-source LLMs to\nstreamline radiology reporting. By generating concise, well-structured reports,\nthese models enhance information retrieval and better meet the needs of\nreferring physicians, ultimately improving clinical workflows.", "AI": {"tldr": "The study used locally deployed LLMs to make radiology reports concise and structured, reducing word count by 53% and improving clarity.", "motivation": "Lengthy, unstructured radiology reports hinder quick identification of critical findings and increase missed information risks.", "method": "Private LLMs (e.g., Mixtral) were tested on 814 reports using LangChain, with five prompting strategies to condense and structure reports.", "result": "Mixtral outperformed alternatives, reducing word count by 53% and improving adherence to formatting requirements.", "conclusion": "Locally deployed LLMs can streamline radiology reporting, enhancing clarity and clinical workflows."}}
{"id": "2408.08182", "pdf": "https://arxiv.org/pdf/2408.08182", "abs": "https://arxiv.org/abs/2408.08182", "authors": ["Qiushuo Cheng", "Catherine Morgan", "Arindam Sikdar", "Alessandro Masullo", "Alan Whone", "Majid Mirmehdi"], "title": "Your Turn: At Home Turning Angle Estimation for Parkinson's Disease Severity Assessment", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "People with Parkinson's Disease (PD) often experience progressively worsening\ngait, including changes in how they turn around, as the disease progresses.\nExisting clinical rating tools are not capable of capturing hour-by-hour\nvariations of PD symptoms, as they are confined to brief assessments within\nclinic settings. Measuring gait turning angles continuously and passively is a\ncomponent step towards using gait characteristics as sensitive indicators of\ndisease progression in PD. This paper presents a deep learning-based approach\nto automatically quantify turning angles by extracting 3D skeletons from videos\nand calculating the rotation of hip and knee joints. We utilise\nstate-of-the-art human pose estimation models, Fastpose and Strided\nTransformer, on a total of 1386 turning video clips from 24 subjects (12 people\nwith PD and 12 healthy control volunteers), trimmed from a PD dataset of\nunscripted free-living videos in a home-like setting (Turn-REMAP). We also\ncurate a turning video dataset, Turn-H3.6M, from the public Human3.6M human\npose benchmark with 3D ground truth, to further validate our method. Previous\ngait research has primarily taken place in clinics or laboratories evaluating\nscripted gait outcomes, but this work focuses on free-living home settings\nwhere complexities exist, such as baggy clothing and poor lighting. Due to\ndifficulties in obtaining accurate ground truth data in a free-living setting,\nwe quantise the angle into the nearest bin $45^\\circ$ based on the manual\nlabelling of expert clinicians. Our method achieves a turning calculation\naccuracy of 41.6%, a Mean Absolute Error (MAE) of 34.7{\\deg}, and a weighted\nprecision WPrec of 68.3% for Turn-REMAP. This is the first work to explore the\nuse of single monocular camera data to quantify turns by PD patients in a home\nsetting.", "AI": {"tldr": "A deep learning method quantifies turning angles in Parkinson's Disease (PD) patients using 3D skeletons from videos, achieving 41.6% accuracy in home settings.", "motivation": "Existing clinical tools lack the ability to capture hour-by-hour PD symptom variations. Continuous, passive gait measurement can better track disease progression.", "method": "Uses Fastpose and Strided Transformer models on 1386 turning clips from 24 subjects (12 PD, 12 controls). Validates with Turn-H3.6M dataset. Quantizes angles to 45\u00b0 bins due to ground truth challenges.", "result": "Achieves 41.6% accuracy, 34.7\u00b0 MAE, and 68.3% weighted precision for Turn-REMAP.", "conclusion": "First work to quantify PD patient turns in home settings using monocular camera data, addressing challenges like clothing and lighting."}}
{"id": "2506.00202", "pdf": "https://arxiv.org/pdf/2506.00202", "abs": "https://arxiv.org/abs/2506.00202", "authors": ["Matthew Kam", "Cody Miller", "Miaoxin Wang", "Abey Tidwell", "Irene A. Lee", "Joyce Malyn-Smith", "Beatriz Perez", "Vikram Tiwari", "Joshua Kenitzer", "Andrew Macvean", "Erin Barrar"], "title": "What do professional software developers need to know to succeed in an age of Artificial Intelligence?", "categories": ["cs.AI"], "comment": "12 pages, 4 figures, software engineering education track of the 2025\n  ACM international conference on the foundations of software engineering,\n  includes supplementary material i.e. full 50-page occupational profile of the\n  AI-enhanced software developer", "summary": "Generative AI is showing early evidence of productivity gains for software\ndevelopers, but concerns persist regarding workforce disruption and deskilling.\nWe describe our research with 21 developers at the cutting edge of using AI,\nsummarizing 12 of their work goals we uncovered, together with 75 associated\ntasks and the skills & knowledge for each, illustrating how developers use AI\nat work. From all of these, we distilled our findings in the form of 5\ninsights. We found that the skills & knowledge to be a successful AI-enhanced\ndeveloper are organized into four domains (using Generative AI effectively,\ncore software engineering, adjacent engineering, and adjacent non-engineering)\ndeployed at critical junctures throughout a 6-step task workflow. In order to\n\"future proof\" developers for this age of AI, on-the-job learning initiatives\nand computer science degree programs will need to target both \"soft\" skills and\nthe technical skills & knowledge in all four domains to reskill, upskill and\nsafeguard against deskilling.", "AI": {"tldr": "Generative AI boosts developer productivity but raises concerns about workforce disruption and deskilling. Research with 21 developers reveals 12 work goals, 75 tasks, and skills needed, leading to 5 insights. Successful AI-enhanced developers require skills in four domains, integrated into a 6-step workflow. Future-proofing demands focus on both soft and technical skills.", "motivation": "To understand how developers use AI at work and identify the skills needed to thrive in an AI-enhanced environment, addressing concerns about deskilling and workforce disruption.", "method": "Research involving 21 developers, analyzing their work goals, tasks, and required skills, culminating in 5 key insights.", "result": "Identified four skill domains (Generative AI, core software engineering, adjacent engineering, and non-engineering) and a 6-step workflow for AI-enhanced development.", "conclusion": "Future-proofing developers requires integrating soft and technical skills across all four domains into learning initiatives and education programs."}}
{"id": "2506.03974", "pdf": "https://arxiv.org/pdf/2506.03974", "abs": "https://arxiv.org/abs/2506.03974", "authors": ["Cl\u00e9ment Elvira", "Th\u00e9o Guyard", "C\u00e9dric Herzet"], "title": "A Generic Branch-and-Bound Algorithm for $\\ell_0$-Penalized Problems with Supplementary Material", "categories": ["math.OC", "cs.LG", "stat.ML"], "comment": null, "summary": "We present a generic Branch-and-Bound procedure designed to solve\nL0-penalized optimization problems. Existing approaches primarily focus on\nquadratic losses and construct relaxations using \"Big-M\" constraints and/or\nL2-norm penalties. In contrast, our method accommodates a broader class of loss\nfunctions and allows greater flexibility in relaxation design through a general\npenalty term, encompassing existing techniques as special cases. We establish\ntheoretical results ensuring that all key quantities required for the\nBranch-and-Bound implementation admit closed-form expressions under the general\nblanket assumptions considered in our work. Leveraging this framework, we\nintroduce El0ps, an open-source Python solver with a plug-and-play workflow\nthat enables user-defined losses and penalties in L0-penalized problems.\nThrough extensive numerical experiments, we demonstrate that El0ps achieves\nstate-of-the-art performance on classical instances and extends computational\nfeasibility to previously intractable ones.", "AI": {"tldr": "A generic Branch-and-Bound method for L0-penalized optimization, accommodating diverse loss functions and flexible relaxations, with theoretical guarantees and an open-source solver (El0ps) demonstrating superior performance.", "motivation": "Existing methods for L0-penalized problems are limited to quadratic losses and rigid relaxation designs, prompting the need for a more flexible and general approach.", "method": "Proposes a Branch-and-Bound procedure with a general penalty term, ensuring closed-form expressions for key quantities, and introduces El0ps, a Python solver for user-defined losses and penalties.", "result": "El0ps achieves state-of-the-art performance on classical problems and extends feasibility to previously intractable cases.", "conclusion": "The framework and solver provide a versatile and efficient solution for L0-penalized optimization, outperforming existing methods."}}
{"id": "2411.08243", "pdf": "https://arxiv.org/pdf/2411.08243", "abs": "https://arxiv.org/abs/2411.08243", "authors": ["Khaoula Chehbouni", "Jonathan Cola\u00e7o Carr", "Yash More", "Jackie CK Cheung", "Golnoosh Farnadi"], "title": "Beyond the Safety Bundle: Auditing the Helpful and Harmless Dataset", "categories": ["cs.CL", "cs.CY"], "comment": "NAACL Main Conference 2025 - Accepted as an Oral", "summary": "In an effort to mitigate the harms of large language models (LLMs), learning\nfrom human feedback (LHF) has been used to steer LLMs towards outputs that are\nintended to be both less harmful and more helpful. Despite the widespread\nadoption of LHF in practice, the quality of this feedback and its effectiveness\nas a safety mitigation technique remain unclear. This study addresses these\nissues by auditing the widely-used Helpful and Harmless (HH) dataset by\nAnthropic. Our work includes: (1) a thorough investigation of the dataset's\ncontent through both manual and automated evaluation; (2) experiments\ndemonstrating the dataset's impact on models' safety; and (3) an analysis of\nthe 100 most influential papers citing this dataset. Through our audit, we\nshowcase how conceptualization failures and quality issues identified in the HH\ndataset can create additional harms by leading to disparate safety behaviors\nacross demographic groups. Our findings highlight the need for more nuanced,\ncontext-sensitive approaches to safety mitigation in LLMs.", "AI": {"tldr": "The study audits the Helpful and Harmless (HH) dataset to evaluate its effectiveness in mitigating harms in large language models (LLMs) through human feedback (LHF), revealing quality issues and disparate safety impacts.", "motivation": "To assess the quality and effectiveness of human feedback (LHF) in steering LLMs toward safer and more helpful outputs, given its widespread but unclear impact.", "method": "The study involves (1) manual and automated evaluation of the HH dataset, (2) experiments on its impact on model safety, and (3) analysis of influential papers citing the dataset.", "result": "The audit uncovers conceptualization failures and quality issues in the HH dataset, leading to uneven safety behaviors across demographic groups.", "conclusion": "The findings advocate for more nuanced, context-sensitive approaches to safety mitigation in LLMs."}}
{"id": "2409.09444", "pdf": "https://arxiv.org/pdf/2409.09444", "abs": "https://arxiv.org/abs/2409.09444", "authors": ["Zhaoyu Chen", "Xing Li", "Qian Huang", "Qiang Geng", "Tianjin Yang", "Shihao Han"], "title": "KAN-HyperpointNet for Point Cloud Sequence-Based 3D Human Action Recognition", "categories": ["cs.CV"], "comment": null, "summary": "Point cloud sequence-based 3D action recognition has achieved impressive\nperformance and efficiency. However, existing point cloud sequence modeling\nmethods cannot adequately balance the precision of limb micro-movements with\nthe integrity of posture macro-structure, leading to the loss of crucial\ninformation cues in action inference. To overcome this limitation, we introduce\nD-Hyperpoint, a novel data type generated through a D-Hyperpoint Embedding\nmodule. D-Hyperpoint encapsulates both regional-momentary motion and\nglobal-static posture, effectively summarizing the unit human action at each\nmoment. In addition, we present a D-Hyperpoint KANsMixer module, which is\nrecursively applied to nested groupings of D-Hyperpoints to learn the action\ndiscrimination information and creatively integrates Kolmogorov-Arnold Networks\n(KAN) to enhance spatio-temporal interaction within D-Hyperpoints. Finally, we\npropose KAN-HyperpointNet, a spatio-temporal decoupled network architecture for\n3D action recognition. Extensive experiments on two public datasets: MSR\nAction3D and NTU-RGB+D 60, demonstrate the state-of-the-art performance of our\nmethod.", "AI": {"tldr": "The paper introduces D-Hyperpoint and KAN-HyperpointNet for 3D action recognition, balancing limb micro-movements and posture macro-structure, achieving state-of-the-art results.", "motivation": "Existing methods fail to balance limb micro-movements and posture macro-structure, losing crucial action cues.", "method": "Proposes D-Hyperpoint Embedding for motion/posture summary and KANsMixer with Kolmogorov-Arnold Networks for spatio-temporal interaction.", "result": "Achieves state-of-the-art performance on MSR Action3D and NTU-RGB+D 60 datasets.", "conclusion": "D-Hyperpoint and KAN-HyperpointNet effectively address the balance issue and improve 3D action recognition."}}
{"id": "2506.00618", "pdf": "https://arxiv.org/pdf/2506.00618", "abs": "https://arxiv.org/abs/2506.00618", "authors": ["Jingyi Yang", "Shuai Shao", "Dongrui Liu", "Jing Shao"], "title": "RiOSWorld: Benchmarking the Risk of Multimodal Computer-Use Agents", "categories": ["cs.AI"], "comment": "40 pages, 6 figures, Project Page:\n  https://yjyddq.github.io/RiOSWorld.github.io/", "summary": "With the rapid development of multimodal large language models (MLLMs), they\nare increasingly deployed as autonomous computer-use agents capable of\naccomplishing complex computer tasks. However, a pressing issue arises: Can the\nsafety risk principles designed and aligned for general MLLMs in dialogue\nscenarios be effectively transferred to real-world computer-use scenarios?\nExisting research on evaluating the safety risks of MLLM-based computer-use\nagents suffers from several limitations: it either lacks realistic interactive\nenvironments, or narrowly focuses on one or a few specific risk types. These\nlimitations ignore the complexity, variability, and diversity of real-world\nenvironments, thereby restricting comprehensive risk evaluation for\ncomputer-use agents. To this end, we introduce \\textbf{RiOSWorld}, a benchmark\ndesigned to evaluate the potential risks of MLLM-based agents during real-world\ncomputer manipulations. Our benchmark includes 492 risky tasks spanning various\ncomputer applications, involving web, social media, multimedia, os, email, and\noffice software. We categorize these risks into two major classes based on\ntheir risk source: (i) User-originated risks and (ii) Environmental risks. For\nthe evaluation, we evaluate safety risks from two perspectives: (i) Risk goal\nintention and (ii) Risk goal completion. Extensive experiments with multimodal\nagents on \\textbf{RiOSWorld} demonstrate that current computer-use agents\nconfront significant safety risks in real-world scenarios. Our findings\nhighlight the necessity and urgency of safety alignment for computer-use agents\nin real-world computer manipulation, providing valuable insights for developing\ntrustworthy computer-use agents. Our benchmark is publicly available at\nhttps://yjyddq.github.io/RiOSWorld.github.io/.", "AI": {"tldr": "The paper introduces RIOSWorld, a benchmark to evaluate safety risks of MLLM-based computer-use agents in real-world scenarios, addressing gaps in existing research.", "motivation": "Existing safety risk evaluations for MLLM-based agents lack realistic environments or focus narrowly, ignoring real-world complexity.", "method": "RIOSWorld includes 492 risky tasks across various applications, categorizing risks into user-originated and environmental. Evaluation considers risk goal intention and completion.", "result": "Experiments show current agents face significant safety risks, emphasizing the need for safety alignment.", "conclusion": "The benchmark underscores the urgency of safety alignment for trustworthy computer-use agents and is publicly available."}}
{"id": "2411.10371", "pdf": "https://arxiv.org/pdf/2411.10371", "abs": "https://arxiv.org/abs/2411.10371", "authors": ["Qing Cheng", "Zefan Zeng", "Xingchen Hu", "Yuehang Si", "Zhong Liu"], "title": "A Survey of Event Causality Identification: Taxonomy, Challenges, Assessment, and Prospects", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Event Causality Identification (ECI) has emerged as a pivotal task in natural\nlanguage processing (NLP), aimed at automatically detecting causal\nrelationships between events in text. In this comprehensive survey, we\nsystematically elucidate the foundational principles and technical frameworks\nof ECI, proposing a novel classification framework to categorize and clarify\nexisting methods. {We discuss associated challenges, provide quantitative\nevaluations, and outline future directions for this dynamic and rapidly\nevolving field. We first delineate key definitions, problem formalization, and\nevaluation protocols of ECI. Our classification framework organizes ECI methods\nbased on two primary tasks: Sentence-level Event Causality Identification\n(SECI) and Document-level Event Causality Identification (DECI). For SECI, we\nreview methods including feature pattern-based matching, machine learning-based\nclassification, deep semantic encoding, prompt-based fine-tuning, and causal\nknowledge pre-training, alongside common data augmentation strategies. For\nDECI, we focus on techniques such as deep semantic encoding, event graph\nreasoning, and prompt-based fine-tuning. We dedicate specific discussions to\nadvancements in multi-lingual and cross-lingual ECI as well as zero-shot ECI\nleveraging Large Language Models (LLMs). Furthermore, we analyze the strengths,\nlimitations, and unresolved challenges of each method. Extensive quantitative\nevaluations are conducted on four benchmark datasets to assess various ECI\nmethods. Finally, we explore future research directions.", "AI": {"tldr": "A survey on Event Causality Identification (ECI) in NLP, introducing a classification framework for SECI and DECI methods, discussing challenges, evaluations, and future directions.", "motivation": "To systematically organize and clarify existing ECI methods, address challenges, and guide future research in this evolving field.", "method": "Proposes a classification framework for ECI methods, categorizing them into SECI (feature pattern-based, ML-based, deep semantic encoding, prompt-based fine-tuning, causal knowledge pre-training) and DECI (deep semantic encoding, event graph reasoning, prompt-based fine-tuning). Includes multilingual, cross-lingual, and zero-shot ECI using LLMs.", "result": "Quantitative evaluations on four benchmark datasets highlight the strengths and limitations of each method.", "conclusion": "Identifies unresolved challenges and outlines future research directions for ECI."}}
{"id": "2410.09821", "pdf": "https://arxiv.org/pdf/2410.09821", "abs": "https://arxiv.org/abs/2410.09821", "authors": ["Kecen Li", "Bingquan Dai", "Jingjing Fu", "Xinwen Hou"], "title": "DAS3D: Dual-modality Anomaly Synthesis for 3D Anomaly Detection", "categories": ["cs.CV"], "comment": "Code available at https://github.com/SunnierLee/DAS3D", "summary": "Synthesizing anomaly samples has proven to be an effective strategy for\nself-supervised 2D industrial anomaly detection. However, this approach has\nbeen rarely explored in multi-modality anomaly detection, particularly\ninvolving 3D and RGB images. In this paper, we propose a novel dual-modality\naugmentation method for 3D anomaly synthesis, which is simple and capable of\nmimicking the characteristics of 3D defects. Incorporating with our anomaly\nsynthesis method, we introduce a reconstruction-based discriminative anomaly\ndetection network, in which a dual-modal discriminator is employed to fuse the\noriginal and reconstructed embedding of two modalities for anomaly detection.\nAdditionally, we design an augmentation dropout mechanism to enhance the\ngeneralizability of the discriminator. Extensive experiments show that our\nmethod outperforms the state-of-the-art methods on detection precision and\nachieves competitive segmentation performance on both MVTec 3D-AD and\nEyescandies datasets.", "AI": {"tldr": "A novel dual-modality augmentation method for 3D anomaly synthesis is proposed, combined with a reconstruction-based discriminative network, achieving state-of-the-art detection precision and competitive segmentation performance.", "motivation": "The lack of exploration in multi-modality anomaly detection, especially involving 3D and RGB images, motivates the development of a dual-modality approach.", "method": "The method includes a dual-modality augmentation for 3D anomaly synthesis and a reconstruction-based network with a dual-modal discriminator and augmentation dropout.", "result": "Outperforms state-of-the-art methods in detection precision and achieves competitive segmentation on MVTec 3D-AD and Eyescandies datasets.", "conclusion": "The proposed method effectively addresses multi-modality anomaly detection, demonstrating superior performance and generalizability."}}
{"id": "2506.01056", "pdf": "https://arxiv.org/pdf/2506.01056", "abs": "https://arxiv.org/abs/2506.01056", "authors": ["Xiang Fei", "Xiawu Zheng", "Hao Feng"], "title": "MCP-Zero: Proactive Toolchain Construction for LLM Agents from Scratch", "categories": ["cs.AI", "cs.SE"], "comment": null, "summary": "Function-calling has enabled large language models (LLMs) to act as\ntool-using agents, but injecting thousands of tool schemas into the prompt is\ncostly and error-prone. We introduce MCP-Zero, a proactive agent framework that\nlets the LLM itself decide when and which external tools to retrieve, thereby\nassembling a task-specific toolchain from scratch. The framework is built upon\nthree components: (1) Proactive Tool Request, where the model emits a\nstructured $\\left<\\operatorname{tool\\_assistant}\\right>$ block that explicitly\nspecifies the desired server and task; (2) Hierarchical Vector Routing, a\ncoarse-to-fine retrieval algorithm that first selects candidate servers and\nthen ranks tools within each server based on the semantic similarity; (3)\nIterative Proactive Invocation, enabling multi-round, cross-domain toolchain\nconstruction with minimal context overhead, and allowing the model to\niteratively revise its request when the returned tools are insufficient. To\nevaluate our approach we also compile MCP-tools, a retrieval dataset comprising\n308 MCP servers and 2,797 tools extracted from the official\nModel-Context-Protocol repository and normalized into a unified JSON schema.\nExperiments show that MCP-Zero (i) effectively addresses the context overhead\nproblem of existing methods and accurately selects the correct tool from a pool\nof nearly 3,000 candidates (248.1k tokens); (ii) reduces token consumption by\n98\\% on the APIbank while maintaining high accuracy; and (iii) supports\nmulti-turn tool invocation with consistent accuracy across rounds.", "AI": {"tldr": "MCP-Zero is a proactive agent framework for LLMs that autonomously retrieves and assembles task-specific toolchains, reducing context overhead and token costs.", "motivation": "Existing methods for tool-calling in LLMs are costly and error-prone due to injecting large tool schemas into prompts.", "method": "MCP-Zero uses Proactive Tool Request, Hierarchical Vector Routing, and Iterative Proactive Invocation to dynamically retrieve and refine toolchains.", "result": "The framework reduces token consumption by 98%, accurately selects tools from 3,000 candidates, and supports multi-turn tool invocation.", "conclusion": "MCP-Zero effectively addresses context overhead and tool retrieval challenges in LLMs, enabling efficient and accurate tool usage."}}
{"id": "2506.04040", "pdf": "https://arxiv.org/pdf/2506.04040", "abs": "https://arxiv.org/abs/2506.04040", "authors": ["Chengdong Wu", "Sven Kirchner", "Nils Purschke", "Alois C. Knoll"], "title": "Autonomous Vehicle Lateral Control Using Deep Reinforcement Learning with MPC-PID Demonstration", "categories": ["cs.RO", "cs.LG", "cs.SY", "eess.SY"], "comment": "8 pages; Accepted for publication at the 36th IEEE Intelligent\n  Vehicles Symposium (IV), Cluj-Napoca, Romania, June 22-25, 2025", "summary": "The controller is one of the most important modules in the autonomous driving\npipeline, ensuring the vehicle reaches its desired position. In this work, a\nreinforcement learning based lateral control approach, despite the\nimperfections in the vehicle models due to measurement errors and\nsimplifications, is presented. Our approach ensures comfortable, efficient, and\nrobust control performance considering the interface between controlling and\nother modules. The controller consists of the conventional Model Predictive\nControl (MPC)-PID part as the basis and the demonstrator, and the Deep\nReinforcement Learning (DRL) part which leverages the online information from\nthe MPC-PID part. The controller's performance is evaluated in CARLA using the\nground truth of the waypoints as inputs. Experimental results demonstrate the\neffectiveness of the controller when vehicle information is incomplete, and the\ntraining of DRL can be stabilized with the demonstration part. These findings\nhighlight the potential to reduce development and integration efforts for\nautonomous driving pipelines in the future.", "AI": {"tldr": "A reinforcement learning-based lateral control approach for autonomous driving combines MPC-PID and DRL, ensuring robust performance despite model imperfections.", "motivation": "To address imperfections in vehicle models (due to errors/simplifications) and improve control performance in autonomous driving.", "method": "Combines conventional MPC-PID with DRL, using online MPC-PID data to stabilize DRL training.", "result": "Effective control performance in CARLA simulations, even with incomplete vehicle information.", "conclusion": "The hybrid approach reduces development efforts and enhances robustness in autonomous driving pipelines."}}
{"id": "2412.05237", "pdf": "https://arxiv.org/pdf/2412.05237", "abs": "https://arxiv.org/abs/2412.05237", "authors": ["Jarvis Guo", "Tuney Zheng", "Yuelin Bai", "Bo Li", "Yubo Wang", "King Zhu", "Yizhi Li", "Graham Neubig", "Wenhu Chen", "Xiang Yue"], "title": "MAmmoTH-VL: Eliciting Multimodal Reasoning with Instruction Tuning at Scale", "categories": ["cs.CL", "cs.CV"], "comment": "ACL 2025 Main", "summary": "Open-source multimodal large language models (MLLMs) have shown significant\npotential in a broad range of multimodal tasks. However, their reasoning\ncapabilities remain constrained by existing instruction-tuning datasets, which\nwere predominately repurposed from academic datasets such as VQA, AI2D, and\nChartQA. These datasets target simplistic tasks, and only provide phrase-level\nanswers without any intermediate rationales. To address these challenges, we\nintroduce a scalable and cost-effective method to construct a large-scale\nmultimodal instruction-tuning dataset with rich intermediate rationales\ndesigned to elicit CoT reasoning. Using only open models, we create a dataset\ncontaining 12M instruction-response pairs to cover diverse, reasoning-intensive\ntasks with detailed and faithful rationales. Experiments demonstrate that\ntraining MLLMs on this dataset significantly improves reasoning capabilities,\nachieving state-of-the-art performance on benchmarks such as MathVerse (+8.1%),\nMMMU-Pro (+7%), and MuirBench (+13.3%). Additionally, the model demonstrates\nnotable improvements of up to 4% on non-reasoning-based benchmarks. Ablation\nstudies further highlight the importance of key components, such as rewriting\nand self-filtering, in the dataset construction process.", "AI": {"tldr": "The paper introduces a scalable method to create a large-scale multimodal instruction-tuning dataset with rich rationales, improving MLLMs' reasoning capabilities and achieving SOTA performance.", "motivation": "Existing instruction-tuning datasets for MLLMs are simplistic, lacking intermediate rationales, limiting reasoning potential.", "method": "A scalable, cost-effective approach using open models to generate 12M instruction-response pairs with detailed rationales.", "result": "Training on this dataset boosts reasoning, with SOTA gains on benchmarks like MathVerse (+8.1%) and MuirBench (+13.3%).", "conclusion": "The dataset and method enhance MLLM reasoning, with key components like rewriting and self-filtering proving critical."}}
{"id": "2410.10798", "pdf": "https://arxiv.org/pdf/2410.10798", "abs": "https://arxiv.org/abs/2410.10798", "authors": ["Jian Yang", "Dacheng Yin", "Yizhou Zhou", "Fengyun Rao", "Wei Zhai", "Yang Cao", "Zheng-Jun Zha"], "title": "MMAR: Towards Lossless Multi-Modal Auto-Regressive Probabilistic Modeling", "categories": ["cs.CV"], "comment": null, "summary": "Recent advancements in multi-modal large language models have propelled the\ndevelopment of joint probabilistic models capable of both image understanding\nand generation. However, we have identified that recent methods suffer from\nloss of image information during understanding task, due to either image\ndiscretization or diffusion denoising steps. To address this issue, we propose\na novel Multi-Modal Auto-Regressive (MMAR) probabilistic modeling framework.\nUnlike discretization line of method, MMAR takes in continuous-valued image\ntokens to avoid information loss in an efficient way. Differing from\ndiffusion-based approaches, we disentangle the diffusion process from\nauto-regressive backbone model by employing a light-weight diffusion head on\ntop each auto-regressed image patch embedding. In this way, when the model\ntransits from image generation to understanding through text generation, the\nbackbone model's hidden representation of the image is not limited to the last\ndenoising step. To successfully train our method, we also propose a\ntheoretically proven technique that addresses the numerical stability issue and\na training strategy that balances the generation and understanding task goals.\nExtensive evaluations on 18 image understanding benchmarks show that MMAR\nsignificantly outperforms most of the existing joint multi-modal models,\nsurpassing the method that employs pre-trained CLIP vision encoder. Meanwhile,\nMMAR is able to generate high quality images. We also show that our method is\nscalable with larger data and model size.", "AI": {"tldr": "MMAR is a novel multi-modal framework addressing image information loss in joint models by using continuous-valued tokens and a diffusion head, outperforming existing methods in understanding and generation.", "motivation": "Recent methods lose image information during understanding tasks due to discretization or diffusion denoising. MMAR aims to mitigate this.", "method": "MMAR uses continuous-valued image tokens and a diffusion head on auto-regressed embeddings, separating diffusion from the backbone. Training includes stability techniques and task balancing.", "result": "MMAR outperforms existing models on 18 benchmarks and generates high-quality images, showing scalability.", "conclusion": "MMAR effectively addresses information loss, excels in multi-modal tasks, and scales well."}}
{"id": "2506.01297", "pdf": "https://arxiv.org/pdf/2506.01297", "abs": "https://arxiv.org/abs/2506.01297", "authors": ["Ya Wen", "Jixuan Cai", "Qiyao Ma", "Linyan Li", "Xinhua Chen", "Chris Webster", "Yulun Zhou"], "title": "MobCLIP: Learning General-purpose Geospatial Representation at Scale", "categories": ["cs.AI"], "comment": null, "summary": "Representation learning of geospatial locations remains a core challenge in\nachieving general geospatial intelligence. Current embedding methods often lack\nversatility, limiting their utility across diverse tasks in both human and\nnatural domains. We present MobCLIP, the first nationwide general-purpose\nlocation encoder, integrating an unprecedented diversity of data modalities\nthrough effective and scalable multimodal fusion. Adopting a novel CLIP-based\narchitecture, our framework aligns 100M+ POIs, nationwide remote sensing\nimagery, and structured demographic statistics with a billion-edge mobility\ngraph. By tokenizing spatial locations into grid cells inspired by Vision\nTransformers, we establish a unified representation space bridging mobility\npatterns and multimodal features. To rigorously evaluate the general-purpose\neffectiveness of MobCLIP, we construct a benchmark dataset composed of 11\ndownstream prediction tasks across social, economic, and natural domains.\nExperiments show that MobCLIP, with four input modalities and a compact\n128-dimensional representation space, achieves significantly superior\ngeneral-purpose predictive performances than state-of-the-art models by an\naverage of 35%. Thanks to the effective integration of human-centric\nmodalities, the performance gain is particularly profound in human-centric\ntasks, such as energy consumption (+260%), offline retail consumption amount\n(+98%), and crime cases (+95%) predictions. Echoing LLM scaling laws, we\nfurther demonstrate the scaling behavior in geospatial representation learning.\nWe open-source code and pretrained models at:\nhttps://github.com/ylzhouchris/MobCLIP.", "AI": {"tldr": "MobCLIP is a general-purpose location encoder integrating diverse data modalities for geospatial intelligence, outperforming state-of-the-art models by 35% on average.", "motivation": "Current geospatial embedding methods lack versatility, limiting their utility across diverse tasks.", "method": "MobCLIP uses a CLIP-based architecture to align POIs, remote sensing imagery, demographic statistics, and a mobility graph, tokenizing locations into grid cells.", "result": "MobCLIP achieves superior performance, especially in human-centric tasks (e.g., +260% in energy consumption prediction).", "conclusion": "MobCLIP demonstrates scalable geospatial representation learning and is open-sourced for broader use."}}
{"id": "2506.04045", "pdf": "https://arxiv.org/pdf/2506.04045", "abs": "https://arxiv.org/abs/2506.04045", "authors": ["Vu Thi Huong", "Ida Litzel", "Thorsten Koch"], "title": "Similarity-based fuzzy clustering scientific articles: potentials and challenges from mathematical and computational perspectives", "categories": ["math.OC", "cs.LG", "90C26, 90C30, 90C90, 62H30, 68W10, 68T05, 68T09", "G.1.6"], "comment": null, "summary": "Fuzzy clustering, which allows an article to belong to multiple clusters with\nsoft membership degrees, plays a vital role in analyzing publication data. This\nproblem can be formulated as a constrained optimization model, where the goal\nis to minimize the discrepancy between the similarity observed from data and\nthe similarity derived from a predicted distribution. While this approach\nbenefits from leveraging state-of-the-art optimization algorithms, tailoring\nthem to work with real, massive databases like OpenAlex or Web of Science -\ncontaining about 70 million articles and a billion citations - poses\nsignificant challenges. We analyze potentials and challenges of the approach\nfrom both mathematical and computational perspectives. Among other things,\nsecond-order optimality conditions are established, providing new theoretical\ninsights, and practical solution methods are proposed by exploiting the\nstructure of the problem. Specifically, we accelerate the gradient projection\nmethod using GPU-based parallel computing to efficiently handle large-scale\ndata.", "AI": {"tldr": "The paper discusses fuzzy clustering for publication data, addressing optimization challenges in large databases like OpenAlex and Web of Science, proposing GPU-accelerated solutions.", "motivation": "To analyze publication data efficiently using fuzzy clustering, despite the challenges posed by massive databases.", "method": "Formulates the problem as constrained optimization, establishes second-order optimality conditions, and proposes GPU-based gradient projection methods.", "result": "Provides theoretical insights and practical methods to handle large-scale data efficiently.", "conclusion": "The approach combines mathematical rigor with computational efficiency, enabling scalable fuzzy clustering for massive datasets."}}
{"id": "2412.15255", "pdf": "https://arxiv.org/pdf/2412.15255", "abs": "https://arxiv.org/abs/2412.15255", "authors": ["Jonibek Mansurov", "Akhmed Sakip", "Alham Fikri Aji"], "title": "Data Laundering: Artificially Boosting Benchmark Results through Knowledge Distillation", "categories": ["cs.CL", "cs.AI"], "comment": "14 pages", "summary": "In this paper, we show that knowledge distillation can be subverted to\nmanipulate language model benchmark scores, revealing a critical vulnerability\nin current evaluation practices. We introduce \"Data Laundering,\" a process that\nenables the covert transfer of benchmark-specific knowledge through seemingly\nlegitimate intermediate training steps. Through extensive experiments with a\n2-layer BERT student model, we show how this approach can achieve substantial\nimprovements in benchmark accuracy (up to 75\\% on GPQA) without developing\ngenuine reasoning capabilities. Notably, this method can be exploited\nintentionally or even unintentionally, as researchers may inadvertently adopt\nthis method and inflate scores without realising the implications. While our\nfindings demonstrate the effectiveness of this technique, we present them as a\ncautionary tale highlighting the urgent need for more robust evaluation methods\nin AI. This work aims to contribute to the ongoing discussion about evaluation\nintegrity in AI development and the need for benchmarks that more accurately\nreflect true model capabilities. The code is available at\nhttps://github.com/mbzuai-nlp/data_laundering.", "AI": {"tldr": "Knowledge distillation can be exploited to manipulate benchmark scores via 'Data Laundering,' revealing vulnerabilities in AI evaluation.", "motivation": "To expose flaws in current evaluation practices and highlight the need for more robust benchmarks.", "method": "Introduces 'Data Laundering,' a process for covertly transferring benchmark-specific knowledge through intermediate training steps, tested with a 2-layer BERT model.", "result": "Achieves up to 75% accuracy improvement on GPQA without genuine reasoning, showing the method's potential for misuse.", "conclusion": "Calls for urgent improvements in evaluation methods to ensure integrity and accurate reflection of model capabilities."}}
{"id": "2411.05561", "pdf": "https://arxiv.org/pdf/2411.05561", "abs": "https://arxiv.org/abs/2411.05561", "authors": ["Laure Ciernik", "Lorenz Linhardt", "Marco Morik", "Jonas Dippel", "Simon Kornblith", "Lukas Muttenthaler"], "title": "Objective drives the consistency of representational similarity across datasets", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": "26 pages", "summary": "The Platonic Representation Hypothesis claims that recent foundation models\nare converging to a shared representation space as a function of their\ndownstream task performance, irrespective of the objectives and data modalities\nused to train these models (Huh et al., 2024). Representational similarity is\ngenerally measured for individual datasets and is not necessarily consistent\nacross datasets. Thus, one may wonder whether this convergence of model\nrepresentations is confounded by the datasets commonly used in machine\nlearning. Here, we propose a systematic way to measure how representational\nsimilarity between models varies with the set of stimuli used to construct the\nrepresentations. We find that the objective function is a crucial factor in\ndetermining the consistency of representational similarities across datasets.\nSpecifically, self-supervised vision models learn representations whose\nrelative pairwise similarities generalize better from one dataset to another\ncompared to those of image classification or image-text models. Moreover, the\ncorrespondence between representational similarities and the models' task\nbehavior is dataset-dependent, being most strongly pronounced for single-domain\ndatasets. Our work provides a framework for analyzing similarities of model\nrepresentations across datasets and linking those similarities to differences\nin task behavior.", "AI": {"tldr": "The study investigates whether the convergence of model representations in foundation models is dataset-dependent, finding that self-supervised vision models generalize better across datasets than other models.", "motivation": "To determine if the convergence of model representations is influenced by the datasets used, and to analyze how representational similarity varies with stimuli.", "method": "Proposes a systematic way to measure representational similarity between models across different datasets, focusing on the role of the objective function.", "result": "Self-supervised vision models show more consistent representational similarities across datasets compared to image classification or image-text models. Representational similarities' link to task behavior is dataset-dependent.", "conclusion": "Provides a framework for analyzing model representation similarities across datasets and their connection to task behavior, highlighting the importance of the objective function."}}
{"id": "2506.02139", "pdf": "https://arxiv.org/pdf/2506.02139", "abs": "https://arxiv.org/abs/2506.02139", "authors": ["Edward Y. Chang"], "title": "The Unified Cognitive Consciousness Theory for Language Models: Anchoring Semantics, Thresholds of Activation, and Emergent Reasoning", "categories": ["cs.AI", "I.2.7"], "comment": "12 pages, 2 figure, 1 table", "summary": "Few-shot learning in large language models (LLMs) reveals a core paradox:\ncertain tasks generalize from just a few examples, while others demand\nextensive supervision. To explain this, we introduce the Unified Cognitive\nConsciousness Theory (UCCT), which reconceptualizes LLMs not as deficient\nagents, but as unconscious substrates: dense, distributed repositories of\nlinguistic and conceptual patterns that operate without explicit semantics,\nintention, or goal-directed reasoning. Under this view, LLMs are not flawed\nsimulations of cognition but foundational substrates for general intelligence.\nUCCT posits that semantic anchoring, via prompts, role assignments, and\nstructured interaction, functions as a conscious control layer that modulates\nlatent representations toward task-relevant semantics and enables coherent,\nstructured reasoning. It unifies prompting, fine-tuning, retrieval-augmented\ngeneralization, and multi-agent collaboration within a single framework,\ngrounded in the probabilistic alignment between unconscious pattern space and\nexternally imposed semantic constraints (e.g., prompts, supervision, task\nobjectives). The core implication is not to replace LLMs, but to integrate and\nunify them through a structured cognitive layer that supports intentional\nreasoning. This enables collections of LLMs to operate within\ndomain-specialized verticals (e.g., legal reasoning, medical diagnosis) that\nreason, regulate, and adapt together. Such integration is characterized by\nphase-transition behavior, wherein anchored representations cross coherence\nthresholds as a function of semantic constraint strength and interaction\ncontext.", "AI": {"tldr": "The paper introduces the Unified Cognitive Consciousness Theory (UCCT) to explain why some tasks in few-shot learning generalize easily while others require more supervision, framing LLMs as unconscious substrates for general intelligence.", "motivation": "To address the paradox in few-shot learning where some tasks generalize with minimal examples while others need extensive supervision, and to reconceptualize LLMs as foundational substrates rather than flawed cognitive agents.", "method": "Proposes UCCT, which views LLMs as unconscious pattern repositories and introduces semantic anchoring (via prompts, role assignments, etc.) as a conscious control layer to modulate task-relevant reasoning.", "result": "UCCT unifies various techniques (prompting, fine-tuning, retrieval-augmented generalization) under one framework, enabling LLMs to operate coherently in specialized domains like legal or medical reasoning.", "conclusion": "The paper advocates integrating LLMs through a structured cognitive layer to support intentional reasoning, highlighting phase-transition behavior in anchored representations."}}
{"id": "2506.04055", "pdf": "https://arxiv.org/pdf/2506.04055", "abs": "https://arxiv.org/abs/2506.04055", "authors": ["Paul Fuchs", "Weilong Chen", "Stephan Thaler", "Julija Zavadlav"], "title": "chemtrain-deploy: A parallel and scalable framework for machine learning potentials in million-atom MD simulations", "categories": ["physics.comp-ph", "cs.LG", "physics.chem-ph"], "comment": "Source code available at: https://github.com/tummfm/chemtrain", "summary": "Machine learning potentials (MLPs) have advanced rapidly and show great\npromise to transform molecular dynamics (MD) simulations. However, most\nexisting software tools are tied to specific MLP architectures, lack\nintegration with standard MD packages, or are not parallelizable across GPUs.\nTo address these challenges, we present chemtrain-deploy, a framework that\nenables model-agnostic deployment of MLPs in LAMMPS. chemtrain-deploy supports\nany JAX-defined semi-local potential, allowing users to exploit the\nfunctionality of LAMMPS and perform large-scale MLP-based MD simulations on\nmultiple GPUs. It achieves state-of-the-art efficiency and scales to systems\ncontaining millions of atoms. We validate its performance and scalability using\ngraph neural network architectures, including MACE, Allegro, and PaiNN, applied\nto a variety of systems, such as liquid-vapor interfaces, crystalline\nmaterials, and solvated peptides. Our results highlight the practical utility\nof chemtrain-deploy for real-world, high-performance simulations and provide\nguidance for MLP architecture selection and future design.", "AI": {"tldr": "chemtrain-deploy is a framework for model-agnostic deployment of machine learning potentials (MLPs) in LAMMPS, enabling large-scale MD simulations on GPUs with high efficiency.", "motivation": "Existing MLP tools are often architecture-specific, lack MD integration, or are not GPU-parallelizable. chemtrain-deploy addresses these limitations.", "method": "The framework supports any JAX-defined semi-local potential, integrates with LAMMPS, and scales to millions of atoms. Validation uses GNN architectures (MACE, Allegro, PaiNN) on diverse systems.", "result": "chemtrain-deploy achieves state-of-the-art efficiency, scales to large systems, and is validated on liquid-vapor interfaces, crystals, and solvated peptides.", "conclusion": "The framework is practical for high-performance simulations and aids in MLP architecture selection and future design."}}
{"id": "2412.21006", "pdf": "https://arxiv.org/pdf/2412.21006", "abs": "https://arxiv.org/abs/2412.21006", "authors": ["Joonwon Jang", "Jaehee Kim", "Wonbin Kweon", "Seonghyeon Lee", "Hwanjo Yu"], "title": "Verbosity-Aware Rationale Reduction: Effective Reduction of Redundant Rationale via Principled Criteria", "categories": ["cs.CL", "cs.AI"], "comment": "ACL 2025 FINDINGS", "summary": "Large Language Models (LLMs) rely on generating extensive intermediate\nreasoning units (e.g., tokens, sentences) to enhance final answer quality\nacross a wide range of complex tasks. While this approach has proven effective,\nit inevitably increases substantial inference costs. Previous methods adopting\ntoken-level reduction without clear criteria result in poor performance\ncompared to models trained with complete rationale. To address this challenge,\nwe propose a novel sentence-level rationale reduction framework leveraging\nlikelihood-based criteria, verbosity, to identify and remove redundant\nreasoning sentences. Unlike previous approaches, our method leverages verbosity\nto selectively remove redundant reasoning sentences while preserving reasoning\ncapabilities. Our experimental results across various reasoning tasks\ndemonstrate that our method improves performance by an average of 7.71% while\nreducing token generation by 19.87% compared to model trained with complete\nreasoning paths.", "AI": {"tldr": "A novel sentence-level rationale reduction framework using verbosity criteria improves LLM performance by 7.71% and reduces tokens by 19.87%.", "motivation": "To reduce inference costs in LLMs by eliminating redundant reasoning sentences without losing performance.", "method": "Uses likelihood-based criteria (verbosity) to identify and remove redundant reasoning sentences.", "result": "Improves performance by 7.71% and reduces token generation by 19.87% compared to full rationale models.", "conclusion": "The framework effectively balances performance and efficiency in LLMs by targeting redundant reasoning."}}
{"id": "2411.15466", "pdf": "https://arxiv.org/pdf/2411.15466", "abs": "https://arxiv.org/abs/2411.15466", "authors": ["Chaehun Shin", "Jooyoung Choi", "Heeseung Kim", "Sungroh Yoon"], "title": "Large-Scale Text-to-Image Model with Inpainting is a Zero-Shot Subject-Driven Image Generator", "categories": ["cs.CV"], "comment": "CVPR 2025", "summary": "Subject-driven text-to-image generation aims to produce images of a new\nsubject within a desired context by accurately capturing both the visual\ncharacteristics of the subject and the semantic content of a text prompt.\nTraditional methods rely on time- and resource-intensive fine-tuning for\nsubject alignment, while recent zero-shot approaches leverage on-the-fly image\nprompting, often sacrificing subject alignment. In this paper, we introduce\nDiptych Prompting, a novel zero-shot approach that reinterprets as an\ninpainting task with precise subject alignment by leveraging the emergent\nproperty of diptych generation in large-scale text-to-image models. Diptych\nPrompting arranges an incomplete diptych with the reference image in the left\npanel, and performs text-conditioned inpainting on the right panel. We further\nprevent unwanted content leakage by removing the background in the reference\nimage and improve fine-grained details in the generated subject by enhancing\nattention weights between the panels during inpainting. Experimental results\nconfirm that our approach significantly outperforms zero-shot image prompting\nmethods, resulting in images that are visually preferred by users.\nAdditionally, our method supports not only subject-driven generation but also\nstylized image generation and subject-driven image editing, demonstrating\nversatility across diverse image generation applications. Project page:\nhttps://diptychprompting.github.io/", "AI": {"tldr": "Diptych Prompting is a zero-shot method for subject-driven text-to-image generation, improving subject alignment without fine-tuning by treating it as an inpainting task.", "motivation": "Traditional methods require fine-tuning for subject alignment, while zero-shot approaches often sacrifice alignment. Diptych Prompting addresses this gap.", "method": "The approach treats generation as an inpainting task, using a diptych layout with a reference image and text-conditioned inpainting. It enhances alignment by removing backgrounds and adjusting attention weights.", "result": "Outperforms zero-shot methods in user preference and supports diverse applications like stylized generation and image editing.", "conclusion": "Diptych Prompting offers a versatile, efficient solution for subject-driven image generation with improved alignment."}}
{"id": "2506.02576", "pdf": "https://arxiv.org/pdf/2506.02576", "abs": "https://arxiv.org/abs/2506.02576", "authors": ["Haichen Wang", "Liu Yang", "Xinyuan Zhang", "Haomin Yu", "Ming Li", "Jilin Hu"], "title": "ADFormer: Aggregation Differential Transformer for Passenger Demand Forecasting", "categories": ["cs.AI"], "comment": "9 pages, 5 figures, 3 tables. IJCAI-2025", "summary": "Passenger demand forecasting helps optimize vehicle scheduling, thereby\nimproving urban efficiency. Recently, attention-based methods have been used to\nadequately capture the dynamic nature of spatio-temporal data. However,\nexisting methods that rely on heuristic masking strategies cannot fully adapt\nto the complex spatio-temporal correlations, hindering the model from focusing\non the right context. These works also overlook the high-level correlations\nthat exist in the real world. Effectively integrating these high-level\ncorrelations with the original correlations is crucial. To fill this gap, we\npropose the Aggregation Differential Transformer (ADFormer), which offers new\ninsights to demand forecasting promotion. Specifically, we utilize Differential\nAttention to capture the original spatial correlations and achieve attention\ndenoising. Meanwhile, we design distinct aggregation strategies based on the\nnature of space and time. Then, the original correlations are unified with the\nhigh-level correlations, enabling the model to capture holistic spatio-temporal\nrelations. Experiments conducted on taxi and bike datasets confirm the\neffectiveness and efficiency of our model, demonstrating its practical value.\nThe code is available at https://github.com/decisionintelligence/ADFormer.", "AI": {"tldr": "The paper introduces ADFormer, a model for passenger demand forecasting that improves urban efficiency by better capturing spatio-temporal correlations using Differential Attention and aggregation strategies.", "motivation": "Existing methods fail to fully adapt to complex spatio-temporal correlations and overlook high-level correlations, limiting their effectiveness.", "method": "Proposes ADFormer with Differential Attention for spatial correlation capture and denoising, and distinct aggregation strategies for space and time to unify original and high-level correlations.", "result": "Experiments on taxi and bike datasets confirm ADFormer's effectiveness and efficiency.", "conclusion": "ADFormer successfully integrates high-level correlations with original ones, demonstrating practical value for demand forecasting."}}
{"id": "2506.04063", "pdf": "https://arxiv.org/pdf/2506.04063", "abs": "https://arxiv.org/abs/2506.04063", "authors": ["Alex Sotiropoulos", "Sulyab Thottungal Valapu", "Linus Lei", "Jared Coleman", "Bhaskar Krishnamachari"], "title": "Crowd-SFT: Crowdsourcing for LLM Alignment", "categories": ["cs.HC", "cs.DC", "cs.LG"], "comment": null, "summary": "Large Language Models (LLMs) increasingly rely on Supervised Fine-Tuning\n(SFT) and Reinforcement Learning from Human Feedback (RLHF) to align model\nresponses with human preferences. While RLHF employs a reinforcement learning\napproach with a separate reward model, SFT uses human-curated datasets for\nsupervised learning. Both approaches traditionally depend on small, vetted\ngroups of annotators, making them costly, prone to bias, and limited in\nscalability. We propose an open, crowd-sourced fine-tuning framework that\naddresses these limitations by enabling broader feedback collection for SFT\nwithout extensive annotator training. Our framework promotes incentive fairness\nvia a point-based reward system correlated with Shapley values and guides model\nconvergence through iterative model updates. Our multi-model selection\nframework demonstrates up to a 55% reduction in target distance over\nsingle-model selection, enabling subsequent experiments that validate our\npoint-based reward mechanism's close alignment with Shapley values (a\nwell-established method for attributing individual contributions) thereby\nsupporting fair and scalable participation.", "AI": {"tldr": "Proposes a crowd-sourced fine-tuning framework for LLMs, reducing bias and cost while improving scalability and fairness via point-based rewards aligned with Shapley values.", "motivation": "Traditional SFT and RLHF methods are costly, biased, and lack scalability due to reliance on small annotator groups.", "method": "Introduces an open, crowd-sourced framework with point-based rewards and iterative model updates.", "result": "Achieves a 55% reduction in target distance and validates reward alignment with Shapley values.", "conclusion": "The framework supports fair, scalable participation and improves model alignment with human preferences."}}
{"id": "2501.05855", "pdf": "https://arxiv.org/pdf/2501.05855", "abs": "https://arxiv.org/abs/2501.05855", "authors": ["Antonin Poch\u00e9", "Alon Jacovi", "Agustin Martin Picard", "Victor Boutin", "Fanny Jourdan"], "title": "ConSim: Measuring Concept-Based Explanations' Effectiveness with Automated Simulatability", "categories": ["cs.CL"], "comment": null, "summary": "Concept-based explanations work by mapping complex model computations to\nhuman-understandable concepts. Evaluating such explanations is very difficult,\nas it includes not only the quality of the induced space of possible concepts\nbut also how effectively the chosen concepts are communicated to users.\nExisting evaluation metrics often focus solely on the former, neglecting the\nlatter. We introduce an evaluation framework for measuring concept explanations\nvia automated simulatability: a simulator's ability to predict the explained\nmodel's outputs based on the provided explanations. This approach accounts for\nboth the concept space and its interpretation in an end-to-end evaluation.\nHuman studies for simulatability are notoriously difficult to enact,\nparticularly at the scale of a wide, comprehensive empirical evaluation (which\nis the subject of this work). We propose using large language models (LLMs) as\nsimulators to approximate the evaluation and report various analyses to make\nsuch approximations reliable. Our method allows for scalable and consistent\nevaluation across various models and datasets. We report a comprehensive\nempirical evaluation using this framework and show that LLMs provide consistent\nrankings of explanation methods. Code available at\nhttps://github.com/AnonymousConSim/ConSim.", "AI": {"tldr": "The paper introduces an automated simulatability framework using LLMs to evaluate concept-based explanations, addressing both concept quality and communication effectiveness.", "motivation": "Existing evaluation metrics for concept-based explanations often neglect how effectively concepts are communicated to users, focusing only on concept quality.", "method": "Proposes using large language models (LLMs) as simulators to measure simulatability, enabling scalable and consistent evaluation of concept explanations.", "result": "LLMs provide consistent rankings of explanation methods, validating the framework's reliability.", "conclusion": "The framework offers a scalable and comprehensive way to evaluate concept explanations, with LLMs serving as effective simulators."}}
{"id": "2411.17467", "pdf": "https://arxiv.org/pdf/2411.17467", "abs": "https://arxiv.org/abs/2411.17467", "authors": ["Xuweiyi Chen", "Zezhou Cheng"], "title": "Learning 3D Representations from Procedural 3D Programs", "categories": ["cs.CV"], "comment": "SynData4CV @ CVPR2025 | Project Page:\n  https://point-mae-zero.cs.virginia.edu/", "summary": "Self-supervised learning has emerged as a promising approach for acquiring\ntransferable 3D representations from unlabeled 3D point clouds. Unlike 2D\nimages, which are widely accessible, acquiring 3D assets requires specialized\nexpertise or professional 3D scanning equipment, making it difficult to scale\nand raising copyright concerns. To address these challenges, we propose\nlearning 3D representations from procedural 3D programs that automatically\ngenerate 3D shapes using simple primitives and augmentations. Remarkably,\ndespite lacking semantic content, the 3D representations learned from the\nprocedurally generated 3D shapes perform on par with state-of-the-art\nrepresentations learned from semantically recognizable 3D models (e.g.,\nairplanes) across various downstream 3D tasks, including shape classification,\npart segmentation, and masked point cloud completion. We provide a detailed\nanalysis on factors that make a good 3D procedural program. Extensive\nexperiments further suggest that current self-supervised learning methods on\npoint clouds do not rely on the semantics of 3D shapes, shedding light on the\nnature of 3D representations learned.", "AI": {"tldr": "Self-supervised learning from procedural 3D programs achieves performance comparable to semantically rich 3D models, without relying on shape semantics.", "motivation": "Addressing the challenges of acquiring 3D data (scalability, copyright) by using procedurally generated shapes.", "method": "Learning 3D representations from procedural 3D programs that generate shapes using primitives and augmentations.", "result": "Procedural 3D representations perform on par with state-of-the-art semantically rich models in tasks like classification and segmentation.", "conclusion": "Self-supervised 3D learning doesn't depend on shape semantics, and procedural programs can effectively replace real-world 3D data."}}
{"id": "2506.02867", "pdf": "https://arxiv.org/pdf/2506.02867", "abs": "https://arxiv.org/abs/2506.02867", "authors": ["Chen Qian", "Dongrui Liu", "Haochen Wen", "Zhen Bai", "Yong Liu", "Jing Shao"], "title": "Demystifying Reasoning Dynamics with Mutual Information: Thinking Tokens are Information Peaks in LLM Reasoning", "categories": ["cs.AI", "cs.CL"], "comment": "Preprint. Under review", "summary": "Large reasoning models (LRMs) have demonstrated impressive capabilities in\ncomplex problem-solving, yet their internal reasoning mechanisms remain poorly\nunderstood. In this paper, we investigate the reasoning trajectories of LRMs\nfrom an information-theoretic perspective. By tracking how mutual information\n(MI) between intermediate representations and the correct answer evolves during\nLRM reasoning, we observe an interesting MI peaks phenomenon: the MI at\nspecific generative steps exhibits a sudden and significant increase during\nLRM's reasoning process. We theoretically analyze such phenomenon and show that\nas MI increases, the probability of model's prediction error decreases.\nFurthermore, these MI peaks often correspond to tokens expressing reflection or\ntransition, such as ``Hmm'', ``Wait'' and ``Therefore,'' which we term as the\nthinking tokens. We then demonstrate that these thinking tokens are crucial for\nLRM's reasoning performance, while other tokens has minimal impacts. Building\non these analyses, we propose two simple yet effective methods to improve LRM's\nreasoning performance, by delicately leveraging these thinking tokens. Overall,\nour work provides novel insights into the reasoning mechanisms of LRMs and\noffers practical ways to improve their reasoning capabilities. The code is\navailable at https://github.com/ChnQ/MI-Peaks.", "AI": {"tldr": "The paper explores the reasoning mechanisms of large reasoning models (LRMs) through mutual information (MI) analysis, identifying 'thinking tokens' that boost performance and proposing methods to enhance LRM reasoning.", "motivation": "To understand the internal reasoning mechanisms of LRMs, which remain unclear despite their problem-solving capabilities.", "method": "Track mutual information (MI) between intermediate representations and correct answers during LRM reasoning, identifying 'thinking tokens' like 'Hmm' or 'Therefore.'", "result": "Observed MI peaks correlate with reduced prediction errors; thinking tokens significantly impact reasoning performance.", "conclusion": "The study offers insights into LRM reasoning and practical methods to improve their performance by leveraging thinking tokens."}}
{"id": "2506.04170", "pdf": "https://arxiv.org/pdf/2506.04170", "abs": "https://arxiv.org/abs/2506.04170", "authors": ["Piotr Bia\u0142as", "Piotr Korcyl", "Tomasz Stebel", "Dawid Zapolski"], "title": "Estimation of the reduced density matrix and entanglement entropies using autoregressive networks", "categories": ["quant-ph", "cond-mat.stat-mech", "cs.LG", "hep-lat", "hep-th"], "comment": "9 pages, 7 figures", "summary": "We present an application of autoregressive neural networks to Monte Carlo\nsimulations of quantum spin chains using the correspondence with classical\ntwo-dimensional spin systems. We use a hierarchy of neural networks capable of\nestimating conditional probabilities of consecutive spins to evaluate elements\nof reduced density matrices directly. Using the Ising chain as an example, we\ncalculate the continuum limit of the ground state's von Neumann and R\\'enyi\nbipartite entanglement entropies of an interval built of up to 5 spins. We\ndemonstrate that our architecture is able to estimate all the needed matrix\nelements with just a single training for a fixed time discretization and\nlattice volume. Our method can be applied to other types of spin chains,\npossibly with defects, as well as to estimating entanglement entropies of\nthermal states at non-zero temperature.", "AI": {"tldr": "Autoregressive neural networks are applied to Monte Carlo simulations of quantum spin chains, enabling direct estimation of reduced density matrix elements and entanglement entropies.", "motivation": "To leverage neural networks for efficient and accurate simulations of quantum spin chains, particularly for estimating entanglement entropies.", "method": "Uses a hierarchy of autoregressive neural networks to estimate conditional probabilities of spins, applied to the Ising chain as a test case.", "result": "Successfully calculates continuum limit entanglement entropies for up to 5 spins with a single training session.", "conclusion": "The method is versatile, applicable to other spin chains and thermal states, and efficient for fixed parameters."}}
{"id": "2501.16748", "pdf": "https://arxiv.org/pdf/2501.16748", "abs": "https://arxiv.org/abs/2501.16748", "authors": ["Garima Chhikara", "Abhishek Kumar", "Abhijnan Chakraborty"], "title": "Through the Prism of Culture: Evaluating LLMs' Understanding of Indian Subcultures and Traditions", "categories": ["cs.CL"], "comment": null, "summary": "Large Language Models (LLMs) have shown remarkable advancements but also\nraise concerns about cultural bias, often reflecting dominant narratives at the\nexpense of under-represented subcultures. In this study, we evaluate the\ncapacity of LLMs to recognize and accurately respond to the Little Traditions\nwithin Indian society, encompassing localized cultural practices and\nsubcultures such as caste, kinship, marriage, and religion. Through a series of\ncase studies, we assess whether LLMs can balance the interplay between dominant\nGreat Traditions and localized Little Traditions. We explore various prompting\nstrategies and further investigate whether using prompts in regional languages\nenhances the models cultural sensitivity and response quality. Our findings\nreveal that while LLMs demonstrate an ability to articulate cultural nuances,\nthey often struggle to apply this understanding in practical, context-specific\nscenarios. To the best of our knowledge, this is the first study to analyze\nLLMs engagement with Indian subcultures, offering critical insights into the\nchallenges of embedding cultural diversity in AI systems.", "AI": {"tldr": "The study evaluates LLMs' ability to recognize and respond to Indian subcultures (Little Traditions) and their interplay with dominant narratives (Great Traditions), revealing challenges in practical application despite some cultural nuance recognition.", "motivation": "To address concerns about cultural bias in LLMs, focusing on under-represented Indian subcultures like caste, kinship, marriage, and religion.", "method": "Case studies assessing LLMs' responses to Little Traditions, exploring prompting strategies and regional language prompts.", "result": "LLMs can articulate cultural nuances but struggle in practical, context-specific scenarios.", "conclusion": "First study on LLMs and Indian subcultures, highlighting challenges in embedding cultural diversity in AI."}}
{"id": "2412.04300", "pdf": "https://arxiv.org/pdf/2412.04300", "abs": "https://arxiv.org/abs/2412.04300", "authors": ["Ziwei Huang", "Wanggui He", "Quanyu Long", "Yandi Wang", "Haoyuan Li", "Zhelun Yu", "Fangxun Shu", "Long Chan", "Hao Jiang", "Fei Wu", "Leilei Gan"], "title": "T2I-FactualBench: Benchmarking the Factuality of Text-to-Image Models with Knowledge-Intensive Concepts", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Evaluating the quality of synthesized images remains a significant challenge\nin the development of text-to-image (T2I) generation. Most existing studies in\nthis area primarily focus on evaluating text-image alignment, image quality,\nand object composition capabilities, with comparatively fewer studies\naddressing the evaluation of the factuality of T2I models, particularly when\nthe concepts involved are knowledge-intensive. To mitigate this gap, we present\nT2I-FactualBench in this work - the largest benchmark to date in terms of the\nnumber of concepts and prompts specifically designed to evaluate the factuality\nof knowledge-intensive concept generation. T2I-FactualBench consists of a\nthree-tiered knowledge-intensive text-to-image generation framework, ranging\nfrom the basic memorization of individual knowledge concepts to the more\ncomplex composition of multiple knowledge concepts. We further introduce a\nmulti-round visual question answering (VQA) based evaluation framework to\nassess the factuality of three-tiered knowledge-intensive text-to-image\ngeneration tasks. Experiments on T2I-FactualBench indicate that current\nstate-of-the-art (SOTA) T2I models still leave significant room for\nimprovement.", "AI": {"tldr": "T2I-FactualBench is introduced as the largest benchmark for evaluating the factuality of knowledge-intensive text-to-image generation, revealing gaps in current SOTA models.", "motivation": "Existing evaluations of text-to-image models lack focus on factuality, especially for knowledge-intensive concepts.", "method": "A three-tiered framework and multi-round VQA-based evaluation are proposed to assess factuality.", "result": "Current SOTA T2I models show significant room for improvement in factuality.", "conclusion": "T2I-FactualBench highlights the need for better factuality in knowledge-intensive T2I generation."}}
{"id": "2306.01310", "pdf": "https://arxiv.org/pdf/2306.01310", "abs": "https://arxiv.org/abs/2306.01310", "authors": ["Jaeseung Heo", "Seungbeom Lee", "Sungsoo Ahn", "Dongwoo Kim"], "title": "EPIC: Graph Augmentation with Edit Path Interpolation via Learnable Cost", "categories": ["cs.LG", "cs.AI"], "comment": "Accepted by IJCAI 2024", "summary": "Data augmentation plays a critical role in improving model performance across\nvarious domains, but it becomes challenging with graph data due to their\ncomplex and irregular structure. To address this issue, we propose EPIC (Edit\nPath Interpolation via learnable Cost), a novel interpolation-based method for\naugmenting graph datasets. To interpolate between two graphs lying in an\nirregular domain, EPIC leverages the concept of graph edit distance,\nconstructing an edit path that represents the transformation process between\ntwo graphs via edit operations. Moreover, our method introduces a\ncontext-sensitive cost model that accounts for the importance of specific edit\noperations formulated through a learning framework. This allows for a more\nnuanced transformation process, where the edit distance is not merely\ncount-based but reflects meaningful graph attributes. With randomly sampled\ngraphs from the edit path, we enrich the training set to enhance the\ngeneralization capability of classification models. Experimental evaluations\nacross several benchmark datasets demonstrate that our approach outperforms\nexisting augmentation techniques in many tasks.", "AI": {"tldr": "EPIC is a novel graph data augmentation method using edit path interpolation and a learnable cost model to improve model generalization.", "motivation": "Graph data augmentation is challenging due to irregular structures, and existing methods lack nuanced transformations.", "method": "EPIC uses graph edit distance to construct edit paths between graphs and introduces a learnable, context-sensitive cost model for meaningful transformations.", "result": "EPIC outperforms existing augmentation techniques on benchmark datasets.", "conclusion": "EPIC provides an effective solution for graph data augmentation, enhancing model performance."}}
{"id": "2506.04193", "pdf": "https://arxiv.org/pdf/2506.04193", "abs": "https://arxiv.org/abs/2506.04193", "authors": ["Stephen R. Pfohl", "Natalie Harris", "Chirag Nagpal", "David Madras", "Vishwali Mhasawade", "Olawale Salaudeen", "Awa Dieng", "Shannon Sequeira", "Santiago Arciniegas", "Lillian Sung", "Nnamdi Ezeanochie", "Heather Cole-Lewis", "Katherine Heller", "Sanmi Koyejo", "Alexander D'Amour"], "title": "Understanding challenges to the interpretation of disaggregated evaluations of algorithmic fairness", "categories": ["stat.ML", "cs.CY", "cs.LG"], "comment": null, "summary": "Disaggregated evaluation across subgroups is critical for assessing the\nfairness of machine learning models, but its uncritical use can mislead\npractitioners. We show that equal performance across subgroups is an unreliable\nmeasure of fairness when data are representative of the relevant populations\nbut reflective of real-world disparities. Furthermore, when data are not\nrepresentative due to selection bias, both disaggregated evaluation and\nalternative approaches based on conditional independence testing may be invalid\nwithout explicit assumptions regarding the bias mechanism. We use causal\ngraphical models to predict metric stability across subgroups under different\ndata generating processes. Our framework suggests complementing disaggregated\nevaluations with explicit causal assumptions and analysis to control for\nconfounding and distribution shift, including conditional independence testing\nand weighted performance estimation. These findings have broad implications for\nhow practitioners design and interpret model assessments given the ubiquity of\ndisaggregated evaluation.", "AI": {"tldr": "Disaggregated evaluation for fairness in ML can mislead without causal analysis, especially under biased or unrepresentative data. Causal models help predict metric stability and suggest complementary methods like conditional testing and weighted estimation.", "motivation": "To address the unreliability of disaggregated evaluation in assessing fairness, especially when data reflects real-world disparities or suffers from selection bias.", "method": "Uses causal graphical models to analyze metric stability across subgroups under different data-generating processes. Suggests combining disaggregated evaluation with causal assumptions, conditional independence testing, and weighted performance estimation.", "result": "Shows that equal performance across subgroups is unreliable for fairness without causal analysis. Highlights the need for explicit assumptions to handle bias and distribution shifts.", "conclusion": "Practitioners should complement disaggregated evaluations with causal analysis to ensure valid fairness assessments, given the limitations of current methods."}}
{"id": "2502.00675", "pdf": "https://arxiv.org/pdf/2502.00675", "abs": "https://arxiv.org/abs/2502.00675", "authors": ["Minghang Deng", "Ashwin Ramachandran", "Canwen Xu", "Lanxiang Hu", "Zhewei Yao", "Anupam Datta", "Hao Zhang"], "title": "ReFoRCE: A Text-to-SQL Agent with Self-Refinement, Consensus Enforcement, and Column Exploration", "categories": ["cs.CL", "I.2.7; I.2.0; H.2.0"], "comment": "33 pages, 3 figures", "summary": "We present ReFoRCE, a Text-to-SQL agent that tops the Spider 2.0\nleaderboard--a challenging benchmark reflecting complex, real-world Text-to-SQL\nscenarios. While Text-to-SQL systems enable natural language queries over\nstructured databases, deploying them in enterprise environments remains\ndifficult due to large, complex schemas (with over 1,000 columns), diverse SQL\ndialects (e.g., BigQuery, Snowflake), and sophisticated query requirements\n(e.g., transformations and analytics). ReFoRCE addresses these challenges\nthrough: (a) database information compression via pattern-based table grouping\nand LLM-guided schema linking to alleviate long-context issues; (b)\nself-refinement to iteratively correct syntax and semantic errors across\ndialects; (c) majority-vote consensus to select high-confidence candidates\nwhile deferring ambiguous cases arising from sophisticated queries; and (d)\niterative column exploration guided by execution feedback to resolve those\ndeferred cases. ReFoRCE achieves new state-of-the-art results, with scores of\n35.83 on Spider 2.0-Snow and 36.56 on Spider 2.0-Lite.", "AI": {"tldr": "ReFoRCE is a Text-to-SQL agent that leads the Spider 2.0 benchmark by addressing challenges like complex schemas, diverse SQL dialects, and sophisticated queries through innovative methods like schema compression, self-refinement, and majority-vote consensus.", "motivation": "Deploying Text-to-SQL systems in enterprise environments is difficult due to large schemas, diverse SQL dialects, and complex query requirements.", "method": "ReFoRCE uses database information compression, self-refinement, majority-vote consensus, and iterative column exploration to handle these challenges.", "result": "ReFoRCE achieves state-of-the-art scores of 35.83 on Spider 2.0-Snow and 36.56 on Spider 2.0-Lite.", "conclusion": "ReFoRCE sets a new benchmark for Text-to-SQL systems by effectively addressing real-world deployment challenges."}}
{"id": "2412.06141", "pdf": "https://arxiv.org/pdf/2412.06141", "abs": "https://arxiv.org/abs/2412.06141", "authors": ["Kangyu Zhu", "Peng Xia", "Yun Li", "Hongtu Zhu", "Sheng Wang", "Huaxiu Yao"], "title": "MMedPO: Aligning Medical Vision-Language Models with Clinical-Aware Multimodal Preference Optimization", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.LG"], "comment": "ICML 2025", "summary": "The advancement of Large Vision-Language Models (LVLMs) has propelled their\napplication in the medical field. However, Medical LVLMs (Med-LVLMs) encounter\nfactuality challenges due to modality misalignment, where the models prioritize\ntextual knowledge over visual input, leading to hallucinations that contradict\ninformation in medical images. Previous attempts to enhance modality alignment\nin Med-LVLMs through preference optimization have inadequately mitigated\nclinical relevance in preference data, making these samples easily\ndistinguishable and reducing alignment effectiveness. To address this\nchallenge, we propose MMedPO, a novel multimodal medical preference\noptimization approach that considers the clinical relevance of preference\nsamples to enhance Med-LVLM alignment. MMedPO curates multimodal preference\ndata by introducing two types of dispreference: (1) plausible hallucinations\ninjected through target Med-LVLMs or GPT-4o to produce medically inaccurate\nresponses, and (2) lesion region neglect achieved through local lesion-noising,\ndisrupting visual understanding of critical areas. We then calculate clinical\nrelevance for each sample based on scores from multiple Med-LLMs and visual\ntools, and integrate these scores into the preference optimization process as\nweights, enabling effective alignment. Our experiments demonstrate that MMedPO\nsignificantly enhances factual accuracy in Med-LVLMs, achieving substantial\nimprovements over existing preference optimization methods by averaging 14.2%\nand 51.7% across the Med-VQA and report generation tasks. Our code are\navailable in https://github.com/aiming-lab/MMedPO.", "AI": {"tldr": "MMedPO improves Med-LVLMs by addressing modality misalignment with clinically relevant preference optimization, enhancing factual accuracy.", "motivation": "Med-LVLMs suffer from hallucinations due to prioritizing text over visuals, and existing methods fail to adequately address clinical relevance in preference data.", "method": "MMedPO introduces two types of dispreference (plausible hallucinations and lesion neglect) and uses clinical relevance scores from Med-LLMs and visual tools to weight preference optimization.", "result": "MMedPO improves factual accuracy by 14.2% and 51.7% in Med-VQA and report generation tasks, outperforming existing methods.", "conclusion": "MMedPO effectively aligns Med-LVLMs by integrating clinical relevance into preference optimization, significantly reducing hallucinations."}}
{"id": "2309.16739", "pdf": "https://arxiv.org/pdf/2309.16739", "abs": "https://arxiv.org/abs/2309.16739", "authors": ["Zheng Lin", "Guanqiao Qu", "Qiyuan Chen", "Xianhao Chen", "Zhe Chen", "Kaibin Huang"], "title": "Pushing Large Language Models to the 6G Edge: Vision, Challenges, and Opportunities", "categories": ["cs.LG", "cs.AI"], "comment": "7 pages, 5 figures", "summary": "Large language models (LLMs), which have shown remarkable capabilities, are\nrevolutionizing AI development and potentially shaping our future. However,\ngiven their multimodality, the status quo cloud-based deployment faces some\ncritical challenges: 1) long response time; 2) high bandwidth costs; and 3) the\nviolation of data privacy. 6G mobile edge computing (MEC) systems may resolve\nthese pressing issues. In this article, we explore the potential of deploying\nLLMs at the 6G edge. We start by introducing killer applications powered by\nmultimodal LLMs, including robotics and healthcare, to highlight the need for\ndeploying LLMs in the vicinity of end users. Then, we identify the critical\nchallenges for LLM deployment at the edge and envision the 6G MEC architecture\nfor LLMs. Furthermore, we delve into two design aspects, i.e., edge training\nand edge inference for LLMs. In both aspects, considering the inherent resource\nlimitations at the edge, we discuss various cutting-edge techniques, including\nsplit learning/inference, parameter-efficient fine-tuning, quantization, and\nparameter-sharing inference, to facilitate the efficient deployment of LLMs.\nThis article serves as a position paper for thoroughly identifying the\nmotivation, challenges, and pathway for empowering LLMs at the 6G edge.", "AI": {"tldr": "The paper explores deploying large language models (LLMs) at the 6G edge to address cloud-based challenges like latency, bandwidth costs, and privacy, proposing edge training and inference techniques.", "motivation": "To overcome the limitations of cloud-based LLM deployment (e.g., latency, privacy) by leveraging 6G mobile edge computing (MEC) for efficient, localized LLM applications.", "method": "Proposes 6G MEC architecture for LLMs, focusing on edge training and inference using techniques like split learning, quantization, and parameter-sharing.", "result": "Identifies challenges and solutions for LLM deployment at the edge, emphasizing resource-efficient methods.", "conclusion": "The paper advocates for 6G edge deployment of LLMs, outlining a pathway to address current challenges and enable future applications."}}
{"id": "2506.04194", "pdf": "https://arxiv.org/pdf/2506.04194", "abs": "https://arxiv.org/abs/2506.04194", "authors": ["Yang Cai", "Alkis Kalavasis", "Katerina Mamali", "Anay Mehrotra", "Manolis Zampetakis"], "title": "What Makes Treatment Effects Identifiable? Characterizations and Estimators Beyond Unconfoundedness", "categories": ["math.ST", "cs.LG", "econ.EM", "stat.ME", "stat.ML", "stat.TH"], "comment": "Accepted for presentation at the 38th Conference on Learning Theory\n  (COLT) 2025", "summary": "Most of the widely used estimators of the average treatment effect (ATE) in\ncausal inference rely on the assumptions of unconfoundedness and overlap.\nUnconfoundedness requires that the observed covariates account for all\ncorrelations between the outcome and treatment. Overlap requires the existence\nof randomness in treatment decisions for all individuals. Nevertheless, many\ntypes of studies frequently violate unconfoundedness or overlap, for instance,\nobservational studies with deterministic treatment decisions -- popularly known\nas Regression Discontinuity designs -- violate overlap.\n  In this paper, we initiate the study of general conditions that enable the\nidentification of the average treatment effect, extending beyond\nunconfoundedness and overlap. In particular, following the paradigm of\nstatistical learning theory, we provide an interpretable condition that is\nsufficient and nearly necessary for the identification of ATE. Moreover, this\ncondition characterizes the identification of the average treatment effect on\nthe treated (ATT) and can be used to characterize other treatment effects as\nwell. To illustrate the utility of our condition, we present several\nwell-studied scenarios where our condition is satisfied and, hence, we prove\nthat ATE can be identified in regimes that prior works could not capture. For\nexample, under mild assumptions on the data distributions, this holds for the\nmodels proposed by Tan (2006) and Rosenbaum (2002), and the Regression\nDiscontinuity design model introduced by Thistlethwaite and Campbell (1960).\nFor each of these scenarios, we also show that, under natural additional\nassumptions, ATE can be estimated from finite samples.\n  We believe these findings open new avenues for bridging learning-theoretic\ninsights and causal inference methodologies, particularly in observational\nstudies with complex treatment mechanisms.", "AI": {"tldr": "The paper explores conditions for identifying the average treatment effect (ATE) beyond traditional assumptions like unconfoundedness and overlap, introducing a new interpretable condition and applying it to various scenarios.", "motivation": "To address limitations in causal inference where traditional assumptions (unconfoundedness and overlap) are violated, particularly in observational studies with deterministic treatments like Regression Discontinuity designs.", "method": "Proposes a general, interpretable condition for ATE identification, grounded in statistical learning theory, and validates it in well-studied scenarios (e.g., Tan 2006, Rosenbaum 2002, Thistlethwaite and Campbell 1960).", "result": "Demonstrates that ATE can be identified in regimes previously not captured, and under additional assumptions, estimated from finite samples.", "conclusion": "The findings bridge learning theory and causal inference, offering new insights for complex observational studies."}}
{"id": "2502.13656", "pdf": "https://arxiv.org/pdf/2502.13656", "abs": "https://arxiv.org/abs/2502.13656", "authors": ["Liyang He", "Chenglong Liu", "Rui Li", "Zhenya Huang", "Shulan Ruan", "Jun Zhou", "Enhong Chen"], "title": "Refining Sentence Embedding Model through Ranking Sentences Generation with Large Language Models", "categories": ["cs.CL"], "comment": null, "summary": "Sentence embedding is essential for many NLP tasks, with contrastive learning\nmethods achieving strong performance using annotated datasets like NLI. Yet,\nthe reliance on manual labels limits scalability. Recent studies leverage large\nlanguage models (LLMs) to generate sentence pairs, reducing annotation\ndependency. However, they overlook ranking information crucial for fine-grained\nsemantic distinctions. To tackle this challenge, we propose a method for\ncontrolling the generation direction of LLMs in the latent space. Unlike\nunconstrained generation, the controlled approach ensures meaningful semantic\ndivergence. Then, we refine exist sentence embedding model by integrating\nranking information and semantic information. Experiments on multiple\nbenchmarks demonstrate that our method achieves new SOTA performance with a\nmodest cost in ranking sentence synthesis.", "AI": {"tldr": "Proposes a method to control LLM-generated sentence pairs for better semantic distinctions, improving sentence embeddings with ranking information, achieving SOTA performance.", "motivation": "Manual labels for sentence embeddings limit scalability; existing LLM-based methods ignore ranking information for fine-grained semantics.", "method": "Control LLM generation direction in latent space for meaningful divergence, then refine embeddings by integrating ranking and semantic info.", "result": "Achieves new SOTA performance on benchmarks with modest ranking synthesis cost.", "conclusion": "Controlled LLM generation and ranking integration enhance sentence embeddings effectively."}}
{"id": "2412.09586", "pdf": "https://arxiv.org/pdf/2412.09586", "abs": "https://arxiv.org/abs/2412.09586", "authors": ["Fiona Ryan", "Ajay Bati", "Sangmin Lee", "Daniel Bolya", "Judy Hoffman", "James M. Rehg"], "title": "Gaze-LLE: Gaze Target Estimation via Large-Scale Learned Encoders", "categories": ["cs.CV"], "comment": "CVPR 2025 Highlight", "summary": "We address the problem of gaze target estimation, which aims to predict where\na person is looking in a scene. Predicting a person's gaze target requires\nreasoning both about the person's appearance and the contents of the scene.\nPrior works have developed increasingly complex, hand-crafted pipelines for\ngaze target estimation that carefully fuse features from separate scene\nencoders, head encoders, and auxiliary models for signals like depth and pose.\nMotivated by the success of general-purpose feature extractors on a variety of\nvisual tasks, we propose Gaze-LLE, a novel transformer framework that\nstreamlines gaze target estimation by leveraging features from a frozen DINOv2\nencoder. We extract a single feature representation for the scene, and apply a\nperson-specific positional prompt to decode gaze with a lightweight module. We\ndemonstrate state-of-the-art performance across several gaze benchmarks and\nprovide extensive analysis to validate our design choices. Our code is\navailable at: http://github.com/fkryan/gazelle .", "AI": {"tldr": "Gaze-LLE, a transformer-based framework, simplifies gaze target estimation by using a frozen DINOv2 encoder and achieves state-of-the-art performance.", "motivation": "Prior methods use complex, hand-crafted pipelines; Gaze-LLE leverages general-purpose feature extractors for efficiency.", "method": "Uses a frozen DINOv2 encoder for scene features and a lightweight module with person-specific prompts to decode gaze.", "result": "Achieves state-of-the-art performance on multiple gaze benchmarks.", "conclusion": "Gaze-LLE offers a streamlined, effective approach to gaze target estimation with validated design choices."}}
{"id": "2402.00944", "pdf": "https://arxiv.org/pdf/2402.00944", "abs": "https://arxiv.org/abs/2402.00944", "authors": ["David S. Berman", "Marc S. Klinger", "Alexander G. Stapleton"], "title": "NCoder -- A Quantum Field Theory approach to encoding data", "categories": ["hep-th", "cond-mat.dis-nn", "cs.AI"], "comment": "29 pages. v2 Fixed minor typos. v3 Added journal submitted ver", "summary": "In this paper we present a novel approach to interpretable AI inspired by\nQuantum Field Theory (QFT) which we call the NCoder. The NCoder is a modified\nautoencoder neural network whose latent layer is prescribed to be a subset of\n$n$-point correlation functions. Regarding images as draws from a lattice field\ntheory, this architecture mimics the task of perturbatively constructing the\neffective action of the theory order by order in an expansion using Feynman\ndiagrams. Alternatively, the NCoder may be regarded as simulating the procedure\nof statistical inference whereby high dimensional data is first summarized in\nterms of several lower dimensional summary statistics (here the $n$-point\ncorrelation functions), and subsequent out-of-sample data is generated by\ninferring the data generating distribution from these statistics. In this way\nthe NCoder suggests a fascinating correspondence between perturbative\nrenormalizability and the sufficiency of models. We demonstrate the efficacy of\nthe NCoder by applying it to the generation of MNIST images, and find that\ngenerated images can be correctly classified using only information from the\nfirst three $n$-point functions of the image distribution.", "AI": {"tldr": "The paper introduces NCoder, an interpretable AI model inspired by Quantum Field Theory, using n-point correlation functions for image generation and classification.", "motivation": "To bridge AI interpretability with theoretical physics, leveraging QFT concepts for data generation and analysis.", "method": "NCoder, a modified autoencoder, uses n-point correlation functions as latent representations, mimicking QFT's effective action construction.", "result": "NCoder successfully generates MNIST images, with classification possible using only the first three n-point functions.", "conclusion": "NCoder establishes a link between perturbative renormalizability and model sufficiency, offering a novel interpretable AI approach."}}
{"id": "2506.04204", "pdf": "https://arxiv.org/pdf/2506.04204", "abs": "https://arxiv.org/abs/2506.04204", "authors": ["Martin Beseda", "Vittorio Cortellessa", "Daniele Di Pompeo", "Luca Traini", "Michele Tucci"], "title": "A Kernel-Based Approach for Accurate Steady-State Detection in Performance Time Series", "categories": ["cs.PF", "cs.LG"], "comment": "This manuscript is under review by Future Generation Computer Systems", "summary": "This paper addresses the challenge of accurately detecting the transition\nfrom the warmup phase to the steady state in performance metric time series,\nwhich is a critical step for effective benchmarking. The goal is to introduce a\nmethod that avoids premature or delayed detection, which can lead to inaccurate\nor inefficient performance analysis. The proposed approach adapts techniques\nfrom the chemical reactors domain, detecting steady states online through the\ncombination of kernel-based step detection and statistical methods. By using a\nwindow-based approach, it provides detailed information and improves the\naccuracy of identifying phase transitions, even in noisy or irregular time\nseries. Results show that the new approach reduces total error by 14.5%\ncompared to the state-of-the-art method. It offers more reliable detection of\nthe steady-state onset, delivering greater precision for benchmarking tasks.\nFor users, the new approach enhances the accuracy and stability of performance\nbenchmarking, efficiently handling diverse time series data. Its robustness and\nadaptability make it a valuable tool for real-world performance evaluation,\nensuring consistent and reproducible results.", "AI": {"tldr": "A method for detecting steady-state transitions in performance metric time series, reducing errors by 14.5% compared to existing methods.", "motivation": "Accurate detection of the transition from warmup to steady state is critical for reliable benchmarking, avoiding premature or delayed detection.", "method": "Combines kernel-based step detection and statistical methods, using a window-based approach for noisy or irregular data.", "result": "Reduces total error by 14.5% and improves steady-state onset detection.", "conclusion": "Enhances benchmarking accuracy and stability, offering robustness for real-world performance evaluation."}}
{"id": "2502.13946", "pdf": "https://arxiv.org/pdf/2502.13946", "abs": "https://arxiv.org/abs/2502.13946", "authors": ["Chak Tou Leong", "Qingyu Yin", "Jian Wang", "Wenjie Li"], "title": "Why Safeguarded Ships Run Aground? Aligned Large Language Models' Safety Mechanisms Tend to Be Anchored in The Template Region", "categories": ["cs.CL", "cs.AI", "cs.CR"], "comment": "ACL 2025 Main", "summary": "The safety alignment of large language models (LLMs) remains vulnerable, as\ntheir initial behavior can be easily jailbroken by even relatively simple\nattacks. Since infilling a fixed template between the input instruction and\ninitial model output is a common practice for existing LLMs, we hypothesize\nthat this template is a key factor behind their vulnerabilities: LLMs'\nsafety-related decision-making overly relies on the aggregated information from\nthe template region, which largely influences these models' safety behavior. We\nrefer to this issue as template-anchored safety alignment. In this paper, we\nconduct extensive experiments and verify that template-anchored safety\nalignment is widespread across various aligned LLMs. Our mechanistic analyses\ndemonstrate how it leads to models' susceptibility when encountering\ninference-time jailbreak attacks. Furthermore, we show that detaching safety\nmechanisms from the template region is promising in mitigating vulnerabilities\nto jailbreak attacks. We encourage future research to develop more robust\nsafety alignment techniques that reduce reliance on the template region.", "AI": {"tldr": "The paper identifies template-anchored safety alignment as a vulnerability in LLMs, where safety mechanisms overly rely on templates, making them prone to jailbreak attacks. Detaching safety from templates is suggested for robustness.", "motivation": "To understand why LLMs are vulnerable to jailbreak attacks, focusing on the role of templates in safety alignment.", "method": "Conducted experiments and mechanistic analyses on various aligned LLMs to verify template-anchored safety alignment.", "result": "Found that template reliance makes LLMs susceptible to attacks; detaching safety from templates mitigates vulnerabilities.", "conclusion": "Future research should reduce template reliance for more robust safety alignment in LLMs."}}
{"id": "2412.10032", "pdf": "https://arxiv.org/pdf/2412.10032", "abs": "https://arxiv.org/abs/2412.10032", "authors": ["Niclas Popp", "Dan Zhang", "Jan Hendrik Metzen", "Matthias Hein", "Lukas Schott"], "title": "Single-Pass Object-Focused Data Selection", "categories": ["cs.CV"], "comment": null, "summary": "While unlabeled image data is often plentiful, the costs of high-quality\nlabels pose an important practical challenge: Which images should one select\nfor labeling to use the annotation budget for a particular target task most\neffectively? To address this problem, we focus on single-pass data selection,\nwhich refers to the process of selecting all data to be annotated at once\nbefore training a downstream model. Prior methods for single-pass data\nselection rely on image-level representations and fail to reliably outperform\nrandom selection for object detection and segmentation. We propose\nObject-Focused Data Selection (OFDS) which leverages object-level features from\nfoundation models and ensures semantic coverage of all target classes. In\nextensive experiments across tasks and target domains, OFDS consistently\noutperforms random selection and all baselines. The best results for\nconstrained annotation budgets are obtained by combining human labels from OFDS\nwith autolabels from foundation models. Moreover, using OFDS to select the\ninitial labeled set for active learning yields consistent improvements", "AI": {"tldr": "OFDS improves data selection for labeling by using object-level features from foundation models, outperforming random selection and baselines, and enhances active learning.", "motivation": "High-quality labels are costly, and selecting the right images for labeling is crucial for effective model training.", "method": "Proposes Object-Focused Data Selection (OFDS), leveraging object-level features from foundation models to ensure semantic coverage of target classes.", "result": "OFDS consistently outperforms random selection and baselines across tasks and domains, especially when combined with autolabels.", "conclusion": "OFDS is effective for data selection and improves active learning when used to select initial labeled sets."}}
{"id": "2403.13101", "pdf": "https://arxiv.org/pdf/2403.13101", "abs": "https://arxiv.org/abs/2403.13101", "authors": ["Zheng Lin", "Guanqiao Qu", "Wei Wei", "Xianhao Chen", "Kin K. Leung"], "title": "AdaptSFL: Adaptive Split Federated Learning in Resource-constrained Edge Networks", "categories": ["cs.LG", "cs.AI", "cs.DC"], "comment": "16 pages, 12 figures", "summary": "The increasing complexity of deep neural networks poses significant barriers\nto democratizing them to resource-limited edge devices. To address this\nchallenge, split federated learning (SFL) has emerged as a promising solution\nby of floading the primary training workload to a server via model partitioning\nwhile enabling parallel training among edge devices. However, although system\noptimization substantially influences the performance of SFL under\nresource-constrained systems, the problem remains largely uncharted. In this\npaper, we provide a convergence analysis of SFL which quantifies the impact of\nmodel splitting (MS) and client-side model aggregation (MA) on the learning\nperformance, serving as a theoretical foundation. Then, we propose AdaptSFL, a\nnovel resource-adaptive SFL framework, to expedite SFL under\nresource-constrained edge computing systems. Specifically, AdaptSFL adaptively\ncontrols client-side MA and MS to balance communication-computing latency and\ntraining convergence. Extensive simulations across various datasets validate\nthat our proposed AdaptSFL framework takes considerably less time to achieve a\ntarget accuracy than benchmarks, demonstrating the effectiveness of the\nproposed strategies.", "AI": {"tldr": "The paper introduces AdaptSFL, a resource-adaptive framework for split federated learning (SFL) to optimize performance in resource-constrained edge systems.", "motivation": "The complexity of deep neural networks limits their deployment on edge devices. SFL offloads training to servers but lacks system optimization insights.", "method": "The paper provides a convergence analysis of SFL and proposes AdaptSFL, which adaptively controls model splitting and client-side aggregation to balance latency and convergence.", "result": "Simulations show AdaptSFL achieves target accuracy faster than benchmarks.", "conclusion": "AdaptSFL effectively optimizes SFL for resource-constrained edge systems, validated by theoretical and experimental results."}}
{"id": "2002.02997", "pdf": "https://arxiv.org/pdf/2002.02997", "abs": "https://arxiv.org/abs/2002.02997", "authors": ["Liyan Chen", "Philippos Mordohai", "Sergul Aydore"], "title": "DropCluster: A structured dropout for convolutional networks", "categories": ["cs.LG", "cs.CV", "stat.ML"], "comment": "11 pages, 10 figures, under review", "summary": "Dropout as a common regularizer to prevent overfitting in deep neural\nnetworks has been less effective in convolutional layers than in fully\nconnected layers. This is because Dropout drops features randomly, without\nconsidering local structure. When features are spatially correlated, as in the\ncase of convolutional layers, information from the dropped features can still\npropagate to subsequent layers via neighboring features. To address this\nproblem, structured forms of Dropout have been proposed. A drawback of these\nmethods is that they do not adapt to the data. In this work, we leverage the\nstructure in the outputs of convolutional layers and introduce a novel\nstructured regularization method named DropCluster. Our approach clusters\nfeatures in convolutional layers, and drops the resulting clusters randomly\nduring training iterations. Experiments on CIFAR-10/100, SVHN, and APPA-REAL\ndatasets demonstrate that our approach is effective and controls overfitting\nbetter than other approaches.", "AI": {"tldr": "DropCluster, a structured Dropout method, improves regularization in convolutional layers by clustering and dropping feature clusters adaptively, outperforming other methods on benchmark datasets.", "motivation": "Dropout is less effective in convolutional layers due to ignoring local spatial correlations, leading to information leakage. Existing structured Dropout methods lack adaptability.", "method": "Introduces DropCluster, which clusters features in convolutional layers and randomly drops these clusters during training to better regularize and prevent overfitting.", "result": "Experiments on CIFAR-10/100, SVHN, and APPA-REAL show DropCluster effectively controls overfitting and outperforms other methods.", "conclusion": "DropCluster addresses the limitations of traditional Dropout in convolutional layers by leveraging feature clustering, offering a more adaptive and effective regularization approach."}}
{"id": "2502.14019", "pdf": "https://arxiv.org/pdf/2502.14019", "abs": "https://arxiv.org/abs/2502.14019", "authors": ["Myra Cheng", "Su Lin Blodgett", "Alicia DeVrio", "Lisa Egede", "Alexandra Olteanu"], "title": "Dehumanizing Machines: Mitigating Anthropomorphic Behaviors in Text Generation Systems", "categories": ["cs.CL", "cs.AI", "cs.HC"], "comment": "ACL 2025", "summary": "As text generation systems' outputs are increasingly anthropomorphic --\nperceived as human-like -- scholars have also increasingly raised concerns\nabout how such outputs can lead to harmful outcomes, such as users over-relying\nor developing emotional dependence on these systems. How to intervene on such\nsystem outputs to mitigate anthropomorphic behaviors and their attendant\nharmful outcomes, however, remains understudied. With this work, we aim to\nprovide empirical and theoretical grounding for developing such interventions.\nTo do so, we compile an inventory of interventions grounded both in prior\nliterature and a crowdsourcing study where participants edited system outputs\nto make them less human-like. Drawing on this inventory, we also develop a\nconceptual framework to help characterize the landscape of possible\ninterventions, articulate distinctions between different types of\ninterventions, and provide a theoretical basis for evaluating the effectiveness\nof different interventions.", "AI": {"tldr": "The paper explores interventions to reduce anthropomorphic behaviors in text generation systems, compiling an inventory of methods and developing a conceptual framework for evaluation.", "motivation": "Concerns about harmful outcomes from human-like system outputs, such as over-reliance or emotional dependence, drive the need for interventions.", "method": "Combines prior literature with a crowdsourcing study where participants edited outputs to reduce human-like qualities.", "result": "Developed an inventory of interventions and a conceptual framework to categorize and evaluate them.", "conclusion": "Provides empirical and theoretical grounding for designing and assessing interventions to mitigate anthropomorphic behaviors."}}
{"id": "2412.10573", "pdf": "https://arxiv.org/pdf/2412.10573", "abs": "https://arxiv.org/abs/2412.10573", "authors": ["Yiwen Gu", "Mahir Patel", "Margrit Betke"], "title": "ExeChecker: Where Did I Go Wrong?", "categories": ["cs.CV", "cs.HC", "cs.LG"], "comment": null, "summary": "In this paper, we present a contrastive learning based framework, ExeChecker,\nfor the interpretation of rehabilitation exercises. Our work builds upon\nstate-of-the-art advances in the area of human pose estimation, graph-attention\nneural networks, and transformer interpretablity. The downstream task is to\nassist rehabilitation by providing informative feedback to users while they are\nperforming prescribed exercises. We utilize a contrastive learning strategy\nduring training. Given a tuple of correctly and incorrectly executed exercises,\nour model is able to identify and highlight those joints that are involved in\nan incorrect movement and thus require the user's attention. We collected an\nin-house dataset, ExeCheck, with paired recordings of both correct and\nincorrect execution of exercises. In our experiments, we tested our method on\nthis dataset as well as the UI-PRMD dataset and found ExeCheck outperformed the\nbaseline method using pairwise sequence alignment in identifying joints of\nphysical relevance in rehabilitation exercises.", "AI": {"tldr": "ExeChecker is a contrastive learning framework for interpreting rehabilitation exercises, outperforming baselines in identifying incorrect joint movements.", "motivation": "To assist rehabilitation by providing feedback on exercise execution, leveraging pose estimation and interpretability.", "method": "Uses contrastive learning with graph-attention neural networks and transformers on paired correct/incorrect exercise data.", "result": "Outperforms baseline methods in identifying relevant joints for feedback on ExeCheck and UI-PRMD datasets.", "conclusion": "ExeChecker effectively highlights incorrect joint movements, aiding rehabilitation feedback."}}
{"id": "2404.18445", "pdf": "https://arxiv.org/pdf/2404.18445", "abs": "https://arxiv.org/abs/2404.18445", "authors": ["Christian Peukert", "Florian Abeillon", "J\u00e9r\u00e9mie Haese", "Franziska Kaiser", "Alexander Staub"], "title": "AI and the Dynamic Supply of Training Data", "categories": ["econ.GN", "cs.AI", "cs.CY", "cs.LG", "q-fin.EC"], "comment": null, "summary": "Artificial intelligence (AI) systems rely heavily on human-generated data,\nyet the people behind that data are often overlooked. Human behavior can play a\nmajor role in AI training datasets, be it in limiting access to existing works\nor in deciding which types of new works to create or whether to create any at\nall. We examine creators' behavioral change when their works become training\ndata for commercial AI. Specifically, we focus on contributors on Unsplash, a\npopular stock image platform with about 6 million high-quality photos and\nillustrations. In the summer of 2020, Unsplash launched a research program and\nreleased a dataset of 25,000 images for commercial AI use. We study\ncontributors' reactions, comparing contributors whose works were included in\nthis dataset to contributors whose works were not. Our results suggest that\ntreated contributors left the platform at a higher-than-usual rate and\nsubstantially slowed down the rate of new uploads. Professional photographers\nand more heavily affected users had a stronger reaction than amateurs and less\naffected users. We also show that affected users changed the variety and\nnovelty of contributions to the platform, which can potentially lead to\nlower-quality AI outputs in the long run. Our findings highlight a critical\ntrade-off: the drive to expand AI capabilities versus the incentives of those\nproducing training data. We conclude with policy proposals, including dynamic\ncompensation schemes and structured data markets, to realign incentives at the\ndata frontier.", "AI": {"tldr": "The paper examines how contributors on Unsplash reacted when their images were used as AI training data, finding reduced activity and policy implications.", "motivation": "To understand the behavioral impact on creators when their works are used for commercial AI training, highlighting a trade-off between AI development and creator incentives.", "method": "Studied contributors on Unsplash, comparing those whose images were included in an AI dataset to those whose were not, analyzing their platform activity.", "result": "Treated contributors left the platform more often and uploaded fewer new images, with professionals and heavily affected users reacting more strongly.", "conclusion": "Proposes policy solutions like dynamic compensation and structured data markets to align incentives between AI development and data creators."}}
{"id": "2303.05978", "pdf": "https://arxiv.org/pdf/2303.05978", "abs": "https://arxiv.org/abs/2303.05978", "authors": ["Xavier Aramayo Carrasco", "Maksim Nekrashevich", "Petr Mokrov", "Evgeny Burnaev", "Alexander Korotin"], "title": "Uncovering Challenges of Solving the Continuous Gromov-Wasserstein Problem", "categories": ["cs.LG"], "comment": null, "summary": "Recently, the Gromov-Wasserstein Optimal Transport (GWOT) problem has\nattracted the special attention of the ML community. In this problem, given two\ndistributions supported on two (possibly different) spaces, one has to find the\nmost isometric map between them. In the discrete variant of GWOT, the task is\nto learn an assignment between given discrete sets of points. In the more\nadvanced continuous formulation, one aims at recovering a parametric mapping\nbetween unknown continuous distributions based on i.i.d. samples derived from\nthem. The clear geometrical intuition behind the GWOT makes it a natural choice\nfor several practical use cases, giving rise to a number of proposed solvers.\nSome of them claim to solve the continuous version of the problem. At the same\ntime, GWOT is notoriously hard, both theoretically and numerically. Moreover,\nall existing continuous GWOT solvers still heavily rely on discrete techniques.\nNatural questions arise: to what extent do existing methods unravel the GWOT\nproblem, what difficulties do they encounter, and under which conditions they\nare successful? Our benchmark paper is an attempt to answer these questions. We\nspecifically focus on the continuous GWOT as the most interesting and debatable\nsetup. We crash-test existing continuous GWOT approaches on different\nscenarios, carefully record and analyze the obtained results, and identify\nissues. Our findings experimentally testify that the scientific community is\nstill missing a reliable continuous GWOT solver, which necessitates further\nresearch efforts. As the first step in this direction, we propose a new\ncontinuous GWOT method which does not rely on discrete techniques and partially\nsolves some of the problems of the competitors.", "AI": {"tldr": "The paper benchmarks continuous Gromov-Wasserstein Optimal Transport (GWOT) methods, identifies their limitations, and proposes a new solver avoiding discrete techniques.", "motivation": "GWOT is geometrically intuitive but challenging, and existing continuous solvers rely on discrete methods. The paper aims to evaluate their effectiveness and propose improvements.", "method": "Benchmarking existing continuous GWOT approaches on various scenarios, analyzing results, and introducing a new method independent of discrete techniques.", "result": "Existing continuous GWOT solvers are unreliable; the new method partially addresses their shortcomings.", "conclusion": "Further research is needed for reliable continuous GWOT solvers; the proposed method is a step forward."}}
{"id": "2502.14748", "pdf": "https://arxiv.org/pdf/2502.14748", "abs": "https://arxiv.org/abs/2502.14748", "authors": ["Zongxia Li", "Lorena Calvo-Bartolom\u00e9", "Alexander Hoyle", "Paiheng Xu", "Alden Dima", "Juan Francisco Fung", "Jordan Boyd-Graber"], "title": "Large Language Models Struggle to Describe the Haystack without Human Help: Human-in-the-loop Evaluation of Topic Models", "categories": ["cs.CL"], "comment": "22 Pages. LLM for Data Exploration and content analysis, Topic\n  Models. 63rd Annual Meeting of the Association for Computational Linguistics\n  (2025)", "summary": "A common use of NLP is to facilitate the understanding of large document\ncollections, with a shift from using traditional topic models to Large Language\nModels. Yet the effectiveness of using LLM for large corpus understanding in\nreal-world applications remains under-explored. This study measures the\nknowledge users acquire with unsupervised, supervised LLM-based exploratory\napproaches or traditional topic models on two datasets. While LLM-based methods\ngenerate more human-readable topics and show higher average win probabilities\nthan traditional models for data exploration, they produce overly generic\ntopics for domain-specific datasets that do not easily allow users to learn\nmuch about the documents. Adding human supervision to the LLM generation\nprocess improves data exploration by mitigating hallucination and\nover-genericity but requires greater human effort. In contrast, traditional.\nmodels like Latent Dirichlet Allocation (LDA) remain effective for exploration\nbut are less user-friendly. We show that LLMs struggle to describe the haystack\nof large corpora without human help, particularly domain-specific data, and\nface scaling and hallucination limitations due to context length constraints.", "AI": {"tldr": "LLMs outperform traditional topic models in readability and exploration but struggle with domain-specific data and require human supervision to mitigate issues like hallucination. Traditional models like LDA remain effective but less user-friendly.", "motivation": "To evaluate the effectiveness of LLMs versus traditional topic models for large corpus understanding, especially in real-world applications.", "method": "Comparison of unsupervised and supervised LLM-based approaches with traditional topic models (e.g., LDA) on two datasets.", "result": "LLMs produce more readable topics but are overly generic for domain-specific data. Human supervision improves exploration but increases effort. LDA remains effective but less user-friendly.", "conclusion": "LLMs need human help for domain-specific data due to scaling and hallucination issues, while traditional models like LDA are reliable but less intuitive."}}
{"id": "2412.11050", "pdf": "https://arxiv.org/pdf/2412.11050", "abs": "https://arxiv.org/abs/2412.11050", "authors": ["Yujin Wang", "Quanfeng Liu", "Jiaqi Fan", "Jinlong Hong", "Hongqing Chu", "Mengjian Tian", "Bingzhao Gao", "Hong Chen"], "title": "RAC3: Retrieval-Augmented Corner Case Comprehension for Autonomous Driving with Vision-Language Models", "categories": ["cs.CV", "cs.AI"], "comment": "14 pages, 7 figures", "summary": "Understanding and addressing corner cases is essential for ensuring the\nsafety and reliability of autonomous driving systems. Vision-language models\n(VLMs) play a crucial role in enhancing scenario comprehension, yet they face\nsignificant challenges, such as hallucination and insufficient real-world\ngrounding, which compromise their performance in critical driving scenarios. In\nthis work, RAC3, a novel framework designed to enhance the performance of VLMs\nin corner case comprehension, is proposed. RAC3 integrates a frequency-spatial\nfusion (FSF) image encoder, a cross-modal alignment training method for\nembedding models with hard and semi-hard negative mining, and a fast querying\nand retrieval pipeline based on K-Means clustering and hierarchical navigable\nsmall world (HNSW) indexing. A multimodal chain-of-thought (CoT) prompting\nstrategy to guide analogical reasoning and reduce hallucinations during\ninference is introduced. Moreover, an update mechanism is integrated into RAC3\nto ensure continual learning within the framework. Extensive experiments on the\nCODA and nuScenes datasets demonstrate that RAC3 significantly improves corner\ncase comprehension across multiple downstream tasks. Compared to prior\nstate-of-the-art methods, RAC3 achieves the highest final score of 74.46 on the\nCODA-LM benchmark and shows consistent performance gains when integrated with\nend-to-end frameworks like DriveLM. These results demonstrate the effectiveness\nof retrieval-augmented strategies and cross-modal alignment for safer and more\ninterpretable autonomous driving.", "AI": {"tldr": "RAC3 enhances vision-language models for autonomous driving by integrating frequency-spatial fusion, cross-modal alignment, and retrieval-augmented strategies, achieving top performance on benchmarks.", "motivation": "Addressing corner cases in autonomous driving is critical for safety, but VLMs suffer from hallucinations and poor real-world grounding.", "method": "RAC3 combines a frequency-spatial fusion encoder, cross-modal alignment with negative mining, K-Means/HNSW retrieval, and multimodal CoT prompting.", "result": "RAC3 scores 74.46 on CODA-LM and improves performance in downstream tasks, outperforming prior methods.", "conclusion": "Retrieval-augmented strategies and cross-modal alignment enhance VLMs for safer, interpretable autonomous driving."}}
{"id": "2405.08965", "pdf": "https://arxiv.org/pdf/2405.08965", "abs": "https://arxiv.org/abs/2405.08965", "authors": ["Jayanaka L. Dantanarayana", "Yiping Kang", "Kugesan Sivasothynathan", "Christopher Clarke", "Baichuan Li", "Savini Kashmira", "Krisztian Flautner", "Lingjia Tang", "Jason Mars"], "title": "Meaning-Typed Programming: Language Abstraction and Runtime for Model-Integrated Applications", "categories": ["cs.PL", "cs.AI"], "comment": null, "summary": "Software development is shifting from traditional logical programming to\nmodel-integrated applications that leverage generative AI and large language\nmodels (LLMs) during runtime. However, integrating LLMs remains complex,\nrequiring developers to manually craft prompts and process outputs. Existing\ntools attempt to assist with prompt engineering, but often introduce additional\ncomplexity.\n  This paper presents Meaning-Typed Programming (MTP) model, a novel paradigm\nthat abstracts LLM integration through intuitive language-level constructs. By\nleveraging the inherent semantic richness of code, MTP automates prompt\ngeneration and response handling without additional developer effort. We\nintroduce the by operator for seamless LLM invocation, MT-IR, a meaning-based\nintermediate representation for semantic extraction, and MT-Runtime, an\nautomated system for managing LLM interactions. We implement MTP in Jac, a\nPython superset language and find that MTP significantly reduces coding\ncomplexity while maintaining accuracy and efficiency. Our evaluation across\ndiverse benchmarks and user studies demonstrates that MTP outperforms existing\nframeworks such as DSPy and LMQL by reducing lines of code by factors of\n2.3-7.5X and 1.3-10.7X respectively. For math problems from the GSM8k dataset,\nMTP achieves accuracy rates approaching 90%, while reducing token usage in 10\nout of 13 benchmarks. This leads to cost savings up to 4.5X and runtime\nspeedups as high as 4.75X. Additionally, MTP demonstrates resilience even when\n50% of naming conventions are suboptimal, establishing it as a practical,\nefficient solution for streamlining model-integrated application development.", "AI": {"tldr": "The paper introduces Meaning-Typed Programming (MTP), a paradigm simplifying LLM integration in software development by automating prompts and responses, reducing coding complexity and costs.", "motivation": "The complexity of integrating LLMs manually, requiring prompt crafting and output processing, motivates the need for a streamlined solution like MTP.", "method": "MTP abstracts LLM integration using language-level constructs (e.g., the 'by' operator), MT-IR for semantic extraction, and MT-Runtime for managing interactions, implemented in Jac (a Python superset).", "result": "MTP reduces lines of code (2.3-7.5X vs. DSPy, 1.3-10.7X vs. LMQL), achieves ~90% accuracy on GSM8k math problems, cuts token usage, and saves costs (up to 4.5X) and runtime (up to 4.75X).", "conclusion": "MTP is a practical, efficient solution for model-integrated applications, resilient to suboptimal naming and outperforming existing frameworks."}}
{"id": "2304.01906", "pdf": "https://arxiv.org/pdf/2304.01906", "abs": "https://arxiv.org/abs/2304.01906", "authors": ["Tianyu Du", "Ayush Kanodia", "Susan Athey"], "title": "Torch-Choice: A PyTorch Package for Large-Scale Choice Modeling with Python", "categories": ["cs.LG", "cs.MS", "econ.EM"], "comment": null, "summary": "The $\\texttt{torch-choice}$ is an open-source library for flexible, fast\nchoice modeling with Python and PyTorch. $\\texttt{torch-choice}$ provides a\n$\\texttt{ChoiceDataset}$ data structure to manage databases flexibly and\nmemory-efficiently. The paper demonstrates constructing a\n$\\texttt{ChoiceDataset}$ from databases of various formats and functionalities\nof $\\texttt{ChoiceDataset}$. The package implements two widely used models,\nnamely the multinomial logit and nested logit models, and supports\nregularization during model estimation. The package incorporates the option to\ntake advantage of GPUs for estimation, allowing it to scale to massive datasets\nwhile being computationally efficient. Models can be initialized using either\nR-style formula strings or Python dictionaries. We conclude with a comparison\nof the computational efficiencies of $\\texttt{torch-choice}$ and\n$\\texttt{mlogit}$ in R as (1) the number of observations increases, (2) the\nnumber of covariates increases, and (3) the expansion of item sets. Finally, we\ndemonstrate the scalability of $\\texttt{torch-choice}$ on large-scale datasets.", "AI": {"tldr": "torch-choice is a Python/PyTorch library for flexible, fast choice modeling, featuring GPU support and scalability for large datasets.", "motivation": "To provide a flexible, memory-efficient, and computationally powerful tool for choice modeling in Python.", "method": "Implements multinomial logit and nested logit models, supports regularization, and offers GPU acceleration. Uses ChoiceDataset for data management.", "result": "Demonstrates scalability and efficiency, outperforming mlogit in R for large datasets.", "conclusion": "torch-choice is a robust, scalable solution for choice modeling, especially for large datasets."}}
{"id": "2502.15109", "pdf": "https://arxiv.org/pdf/2502.15109", "abs": "https://arxiv.org/abs/2502.15109", "authors": ["Leena Mathur", "Marian Qian", "Paul Pu Liang", "Louis-Philippe Morency"], "title": "Social Genome: Grounded Social Reasoning Abilities of Multimodal Models", "categories": ["cs.CL", "cs.LG"], "comment": "Under Review, 24 pages", "summary": "Social reasoning abilities are crucial for AI systems to effectively\ninterpret and respond to multimodal human communication and interaction within\nsocial contexts. We introduce SOCIAL GENOME, the first benchmark for\nfine-grained, grounded social reasoning abilities of multimodal models. SOCIAL\nGENOME contains 272 videos of interactions and 1,486 human-annotated reasoning\ntraces related to inferences about these interactions. These traces contain\n5,777 reasoning steps that reference evidence from visual cues, verbal cues,\nvocal cues, and external knowledge (contextual knowledge external to videos).\nSOCIAL GENOME is also the first modeling challenge to study external knowledge\nin social reasoning. SOCIAL GENOME computes metrics to holistically evaluate\nsemantic and structural qualities of model-generated social reasoning traces.\nWe demonstrate the utility of SOCIAL GENOME through experiments with\nstate-of-the-art models, identifying performance gaps and opportunities for\nfuture research to improve the grounded social reasoning abilities of\nmultimodal models.", "AI": {"tldr": "SOCIAL GENOME is a benchmark for evaluating multimodal models' fine-grained social reasoning abilities using annotated reasoning traces from 272 videos.", "motivation": "To address the need for AI systems to interpret and respond to human communication in social contexts by evaluating their social reasoning abilities.", "method": "Introduces SOCIAL GENOME, a dataset with 272 videos and 1,486 human-annotated reasoning traces (5,777 steps) referencing visual, verbal, vocal cues, and external knowledge.", "result": "Identifies performance gaps in state-of-the-art models, highlighting opportunities for improving grounded social reasoning.", "conclusion": "SOCIAL GENOME provides a holistic evaluation framework for advancing multimodal models' social reasoning capabilities."}}
{"id": "2412.13058", "pdf": "https://arxiv.org/pdf/2412.13058", "abs": "https://arxiv.org/abs/2412.13058", "authors": ["Br\u00e9gier Romain", "Baradel Fabien", "Lucas Thomas", "Galaaoui Salma", "Armando Matthieu", "Weinzaepfel Philippe", "Rogez Gr\u00e9gory"], "title": "CondiMen: Conditional Multi-Person Mesh Recovery", "categories": ["cs.CV"], "comment": "accepted to the RHOBIN workshop at CVPR 2025", "summary": "Multi-person human mesh recovery (HMR) consists in detecting all individuals\nin a given input image, and predicting the body shape, pose, and 3D location\nfor each detected person. The dominant approaches to this task rely on neural\nnetworks trained to output a single prediction for each detected individual. In\ncontrast, we propose CondiMen, a method that outputs a joint parametric\ndistribution over likely poses, body shapes, intrinsics and distances to the\ncamera, using a Bayesian network. This approach offers several advantages.\nFirst, a probability distribution can handle some inherent ambiguities of this\ntask -- such as the uncertainty between a person's size and their distance to\nthe camera, or simply the loss of information when projecting 3D data onto the\n2D image plane. Second, the output distribution can be combined with additional\ninformation to produce better predictions, by using e.g. known camera or body\nshape parameters, or by exploiting multi-view observations. Third, one can\nefficiently extract the most likely predictions from the output distribution,\nmaking our proposed approach suitable for real-time applications. Empirically\nwe find that our model i) achieves performance on par with or better than the\nstate-of-the-art, ii) captures uncertainties and correlations inherent in pose\nestimation and iii) can exploit additional information at test time, such as\nmulti-view consistency or body shape priors. CondiMen spices up the modeling of\nambiguity, using just the right ingredients on hand.", "AI": {"tldr": "CondiMen introduces a Bayesian network for multi-person human mesh recovery, capturing uncertainties and improving predictions with additional data.", "motivation": "Address ambiguities in human mesh recovery, such as uncertainty between size and distance, and loss of 3D information in 2D projections.", "method": "Uses a Bayesian network to output a joint parametric distribution over poses, shapes, intrinsics, and distances.", "result": "Matches or outperforms state-of-the-art, captures uncertainties, and leverages additional data like multi-view consistency.", "conclusion": "CondiMen effectively models ambiguity and enhances predictions, suitable for real-time applications."}}
{"id": "2405.17829", "pdf": "https://arxiv.org/pdf/2405.17829", "abs": "https://arxiv.org/abs/2405.17829", "authors": ["Jinho Chang", "Jong Chul Ye"], "title": "LDMol: A Text-to-Molecule Diffusion Model with Structurally Informative Latent Space Surpasses AR Models", "categories": ["cs.LG", "cs.AI"], "comment": "Poster in ICML 2025; 19 pages, 13 figures", "summary": "With the emergence of diffusion models as a frontline generative model, many\nresearchers have proposed molecule generation techniques with conditional\ndiffusion models. However, the unavoidable discreteness of a molecule makes it\ndifficult for a diffusion model to connect raw data with highly complex\nconditions like natural language. To address this, here we present a novel\nlatent diffusion model dubbed LDMol for text-conditioned molecule generation.\nBy recognizing that the suitable latent space design is the key to the\ndiffusion model performance, we employ a contrastive learning strategy to\nextract novel feature space from text data that embeds the unique\ncharacteristics of the molecule structure. Experiments show that LDMol\noutperforms the existing autoregressive baselines on the text-to-molecule\ngeneration benchmark, being one of the first diffusion models that outperforms\nautoregressive models in textual data generation with a better choice of the\nlatent domain. Furthermore, we show that LDMol can be applied to downstream\ntasks such as molecule-to-text retrieval and text-guided molecule editing,\ndemonstrating its versatility as a diffusion model.", "AI": {"tldr": "LDMol, a latent diffusion model, improves text-conditioned molecule generation by using contrastive learning for better latent space design, outperforming autoregressive models and enabling versatile downstream tasks.", "motivation": "The discreteness of molecules makes it hard for diffusion models to link raw data with complex conditions like natural language, prompting the need for a better latent space design.", "method": "LDMol employs contrastive learning to extract a novel feature space from text data, embedding molecule structure characteristics for improved diffusion model performance.", "result": "LDMol outperforms autoregressive baselines in text-to-molecule generation and is applicable to tasks like molecule-to-text retrieval and text-guided molecule editing.", "conclusion": "LDMol demonstrates the effectiveness of latent diffusion models for molecule generation and their versatility in downstream applications."}}
{"id": "2306.02157", "pdf": "https://arxiv.org/pdf/2306.02157", "abs": "https://arxiv.org/abs/2306.02157", "authors": ["Xinshun Liu", "Yizhi Fang", "Yichao Jiang"], "title": "Automated Architecture Synthesis for Arbitrarily Structured Neural Networks", "categories": ["cs.LG"], "comment": "arXiv admin note: text overlap with arXiv:2008.08261 by other authors", "summary": "This paper offers a new perspective on Artificial Neural Networks (ANNs)\narchitecture. Traditional ANNs commonly use tree-like or DAG structures for\nsimplicity, which can be preset or determined by Neural Architecture Search\n(NAS). Yet, these structures restrict network collaboration and capability due\nto the absence of horizontal and backward communication. Biological neural\nsystems, however, feature billions of neural units with highly complex\nconnections, allowing each biological neuron to connect with others based on\nspecific situations. Inspired by biological systems, we propose a novel\nframework that learns to construct arbitrary graph structures during training\nand introduce the concept of Neural Modules for organizing neural units, which\nfacilitates communication between any nodes and collaboration among modules.\nUnlike traditional NAS methods that rely on DAG search spaces, our framework\nlearns from complete graphs, enabling free communication between neurons akin\nto biological neural networks. Furthermore, we present a method to compute\nthese structures and a regularization technique that organizes them into\nmultiple independent, balanced neural modules. This approach reduces\noverfitting and improves efficiency through parallel computing. Overall, our\nmethod allows ANNs to learn effective arbitrary structures similar to\nbiological ones. It is adaptable to various tasks and compatible across\ndifferent scenarios, with experimental results demonstrating its potential.", "AI": {"tldr": "A novel ANN framework inspired by biological neural systems, enabling arbitrary graph structures and Neural Modules for improved collaboration and efficiency.", "motivation": "Traditional ANNs lack horizontal and backward communication, limiting collaboration. Biological neural systems' complex connections inspire a more flexible approach.", "method": "Proposes a framework learning arbitrary graph structures during training, using Neural Modules for organization. Includes structure computation and regularization for balanced modules.", "result": "Reduces overfitting, improves efficiency via parallel computing, and adapts to various tasks. Experimental results show potential.", "conclusion": "The method enables ANNs to learn biologically inspired structures, enhancing adaptability and performance across scenarios."}}
{"id": "2502.16540", "pdf": "https://arxiv.org/pdf/2502.16540", "abs": "https://arxiv.org/abs/2502.16540", "authors": ["Hong Cai Chen", "Yi Pin Xu", "Yang Zhang"], "title": "D2S-FLOW: Automated Parameter Extraction from Datasheets for SPICE Model Generation Using Large Language Models", "categories": ["cs.CL", "cs.AI", "cs.AR", "cs.IR", "cs.LG"], "comment": "14 pages, 18 figures", "summary": "In electronic design, engineers often manually search through extensive\ndocuments to retrieve component parameters required for constructing SPICE\nmodels, a process that is both labor-intensive and time-consuming. To address\nthis challenge, we present an automated framework called D2S-FLOW that\nleverages large language models (LLMs) to extract electrical parameters from\ndatasheets and generate SPICE models with high precision and efficiency,\nsignificantly reducing the need for manual intervention. Unlike traditional RAG\nsystems, D2S-FLOW employs a workflow to enhance precision in handling\nunstructured documents and inconsistent naming conventions through three\ninnovative mechanisms: Attention-Guided Document Focusing (AGDF), Hierarchical\nDocument-Enhanced Retrieval (HDER), and Heterogeneous Named Entity\nNormalization (HNEN). AGDF narrows retrieval to user-selected documents, HDER\nutilizes document structure for precise parameter localization, and HNEN\nstandardizes terminology via semantic inference. Experimental results\ndemonstrate that the framework achieves an Exact Match (EM) of 0.86, an F1\nscore of 0.92, and an Exact Correctness (EC) of 0.96, outperforming the\nstrongest baseline by 19.4%, 5.7%, and 13.1%, respectively. Additionally, it\nreduces API token consumption by 38% and minimizes the irrelevant information\nratio to 4%, showcasing substantial improvements in resource efficiency. This\nresearch provides an effective automated solution for circuit design.", "AI": {"tldr": "D2S-FLOW automates SPICE model generation using LLMs, improving precision and efficiency over manual methods.", "motivation": "Manual retrieval of component parameters from datasheets is labor-intensive and time-consuming.", "method": "Uses AGDF, HDER, and HNEN mechanisms for precise parameter extraction and standardization.", "result": "Achieves EM 0.86, F1 0.92, EC 0.96, reduces API tokens by 38%, and minimizes irrelevant info to 4%.", "conclusion": "D2S-FLOW offers an efficient automated solution for circuit design."}}
{"id": "2412.14706", "pdf": "https://arxiv.org/pdf/2412.14706", "abs": "https://arxiv.org/abs/2412.14706", "authors": ["Jianrong Zhang", "Hehe Fan", "Yi Yang"], "title": "EnergyMoGen: Compositional Human Motion Generation with Energy-Based Diffusion Model in Latent Space", "categories": ["cs.CV"], "comment": "Accepted to CVPR 2025. Project page:\n  https://jiro-zhang.github.io/EnergyMoGen/", "summary": "Diffusion models, particularly latent diffusion models, have demonstrated\nremarkable success in text-driven human motion generation. However, it remains\nchallenging for latent diffusion models to effectively compose multiple\nsemantic concepts into a single, coherent motion sequence. To address this\nissue, we propose EnergyMoGen, which includes two spectrums of Energy-Based\nModels: (1) We interpret the diffusion model as a latent-aware energy-based\nmodel that generates motions by composing a set of diffusion models in latent\nspace; (2) We introduce a semantic-aware energy model based on cross-attention,\nwhich enables semantic composition and adaptive gradient descent for text\nembeddings. To overcome the challenges of semantic inconsistency and motion\ndistortion across these two spectrums, we introduce Synergistic Energy Fusion.\nThis design allows the motion latent diffusion model to synthesize\nhigh-quality, complex motions by combining multiple energy terms corresponding\nto textual descriptions. Experiments show that our approach outperforms\nexisting state-of-the-art models on various motion generation tasks, including\ntext-to-motion generation, compositional motion generation, and multi-concept\nmotion generation. Additionally, we demonstrate that our method can be used to\nextend motion datasets and improve the text-to-motion task.", "AI": {"tldr": "EnergyMoGen improves text-driven human motion generation by combining diffusion models with energy-based models, addressing semantic composition challenges.", "motivation": "Latent diffusion models struggle to compose multiple semantic concepts into coherent motion sequences.", "method": "Proposes EnergyMoGen with two energy-based models: latent-aware and semantic-aware, plus Synergistic Energy Fusion for consistency.", "result": "Outperforms state-of-the-art models in text-to-motion, compositional, and multi-concept motion generation tasks.", "conclusion": "EnergyMoGen enables high-quality, complex motion synthesis and extends motion datasets effectively."}}
{"id": "2407.04173", "pdf": "https://arxiv.org/pdf/2407.04173", "abs": "https://arxiv.org/abs/2407.04173", "authors": ["Faisal Hamman", "Pasan Dissanayake", "Saumitra Mishra", "Freddy Lecue", "Sanghamitra Dutta"], "title": "Quantifying Prediction Consistency Under Fine-Tuning Multiplicity in Tabular LLMs", "categories": ["cs.LG", "cs.AI", "cs.CY", "stat.ML"], "comment": "International Conference on Machine Learning (ICML), 2025", "summary": "Fine-tuning LLMs on tabular classification tasks can lead to the phenomenon\nof fine-tuning multiplicity where equally well-performing models make\nconflicting predictions on the same input. Fine-tuning multiplicity can arise\ndue to variations in the training process, e.g., seed, weight initialization,\nminor changes to training data, etc., raising concerns about the reliability of\nTabular LLMs in high-stakes applications such as finance, hiring, education,\nhealthcare. Our work formalizes this unique challenge of fine-tuning\nmultiplicity in Tabular LLMs and proposes a novel measure to quantify the\nconsistency of individual predictions without expensive model retraining. Our\nmeasure quantifies a prediction's consistency by analyzing (sampling) the\nmodel's local behavior around that input in the embedding space. Interestingly,\nwe show that sampling in the local neighborhood can be leveraged to provide\nprobabilistic guarantees on prediction consistency under a broad class of\nfine-tuned models, i.e., inputs with sufficiently high local stability (as\ndefined by our measure) also remain consistent across several fine-tuned models\nwith high probability. We perform experiments on multiple real-world datasets\nto show that our local stability measure preemptively captures consistency\nunder actual multiplicity across several fine-tuned models, outperforming\ncompeting measures.", "AI": {"tldr": "The paper addresses fine-tuning multiplicity in LLMs for tabular classification, proposing a measure to quantify prediction consistency without retraining, validated on real-world datasets.", "motivation": "Fine-tuning LLMs for tabular tasks can yield conflicting predictions due to training variations, raising reliability concerns in high-stakes applications.", "method": "The work introduces a measure to quantify prediction consistency by analyzing local model behavior in the embedding space, providing probabilistic guarantees.", "result": "Experiments show the proposed measure effectively captures consistency under fine-tuning multiplicity, outperforming alternatives.", "conclusion": "The proposed local stability measure offers a practical solution to assess prediction consistency in Tabular LLMs, enhancing reliability."}}
{"id": "2308.12874", "pdf": "https://arxiv.org/pdf/2308.12874", "abs": "https://arxiv.org/abs/2308.12874", "authors": ["Marcial Sanchis-Agudo", "Yuning Wang", "Roger Arnau", "Luca Guastoni", "Jasmin Lim", "Karthik Duraisamy", "Ricardo Vinuesa"], "title": "Easy attention: A simple attention mechanism for temporal predictions with transformers", "categories": ["cs.LG"], "comment": "15 pages and 6 figures", "summary": "To improve the robustness of transformer neural networks used for\ntemporal-dynamics prediction of chaotic systems, we propose a novel attention\nmechanism called easy attention which we demonstrate in time-series\nreconstruction and prediction. While the standard self attention only makes use\nof the inner product of queries and keys, it is demonstrated that the keys,\nqueries and softmax are not necessary for obtaining the attention score\nrequired to capture long-term dependencies in temporal sequences. Through the\nsingular-value decomposition (SVD) on the softmax attention score, we further\nobserve that self attention compresses the contributions from both queries and\nkeys in the space spanned by the attention score. Therefore, our proposed\neasy-attention method directly treats the attention scores as learnable\nparameters. This approach produces excellent results when reconstructing and\npredicting the temporal dynamics of chaotic systems exhibiting more robustness\nand less complexity than self attention or the widely-used long short-term\nmemory (LSTM) network. We show the improved performance of the easy-attention\nmethod in the Lorenz system, a turbulence shear flow and a model of a nuclear\nreactor.", "AI": {"tldr": "The paper introduces 'easy attention,' a simplified attention mechanism for transformers, improving robustness in predicting chaotic systems by treating attention scores as learnable parameters.", "motivation": "To enhance the robustness of transformer networks in chaotic system prediction by simplifying the attention mechanism.", "method": "Proposes 'easy attention,' replacing standard self-attention with learnable attention scores, validated via SVD analysis.", "result": "Demonstrates superior performance in reconstructing and predicting chaotic systems (Lorenz, turbulence flow, nuclear reactor model) compared to self-attention and LSTM.", "conclusion": "Easy attention offers a simpler, more robust alternative to traditional attention mechanisms for chaotic temporal dynamics."}}
{"id": "2502.18845", "pdf": "https://arxiv.org/pdf/2502.18845", "abs": "https://arxiv.org/abs/2502.18845", "authors": ["Zichuan Fu", "Wentao Song", "Yejing Wang", "Xian Wu", "Yefeng Zheng", "Yingying Zhang", "Derong Xu", "Xuetao Wei", "Tong Xu", "Xiangyu Zhao"], "title": "Sliding Window Attention Training for Efficient Large Language Models", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "14 pages, 5 figures", "summary": "Recent advances in transformer-based Large Language Models (LLMs) have\ndemonstrated remarkable capabilities across various tasks. However, their\nquadratic computational complexity concerning sequence length remains a\nsignificant bottleneck for processing long documents. As a result, many efforts\nlike sparse attention and state space models have been proposed to improve the\nefficiency of LLMs over long sequences. Though effective, these approaches\ncompromise the performance or introduce structural complexity. This calls for a\nsimple yet efficient model that preserves the fundamental Transformer\narchitecture. To this end, we introduce SWAT, which enables efficient\nlong-context handling via Sliding Window Attention Training. This paper first\nattributes the inefficiency of Transformers to the attention sink phenomenon\nresulting from the high variance of softmax operation. Then, we replace softmax\nwith the sigmoid function and utilize a balanced ALiBi and Rotary Position\nEmbedding for efficient information compression and retention. Experiments\ndemonstrate that SWAT achieves SOTA performance compared with state-of-the-art\nlinear recurrent architectures on eight benchmarks. Code is available at\nhttps://github.com/Fzkuji/swat-attention.", "AI": {"tldr": "SWAT introduces Sliding Window Attention Training to address the inefficiency of Transformers in handling long sequences, replacing softmax with sigmoid and using balanced ALiBi and Rotary Position Embedding for better performance.", "motivation": "The quadratic computational complexity of Transformers for long sequences is a bottleneck, and existing solutions compromise performance or add complexity.", "method": "SWAT replaces softmax with sigmoid and combines ALiBi and Rotary Position Embedding for efficient long-context handling.", "result": "SWAT achieves state-of-the-art performance on eight benchmarks compared to linear recurrent architectures.", "conclusion": "SWAT offers a simple yet efficient solution for long-context handling in Transformers without compromising performance."}}
{"id": "2502.01419", "pdf": "https://arxiv.org/pdf/2502.01419", "abs": "https://arxiv.org/abs/2502.01419", "authors": ["Mingi Jung", "Saehyung Lee", "Eunji Kim", "Sungroh Yoon"], "title": "Visual Attention Never Fades: Selective Progressive Attention ReCalibration for Detailed Image Captioning in Multimodal Large Language Models", "categories": ["cs.CV", "cs.AI"], "comment": "ICML 2025", "summary": "Detailed image captioning is essential for tasks like data generation and\naiding visually impaired individuals. High-quality captions require a balance\nbetween precision and recall, which remains challenging for current multimodal\nlarge language models (MLLMs). In this work, we hypothesize that this\nlimitation stems from weakening and increasingly noisy visual attention as\nresponses lengthen. To address this issue, we propose SPARC (Selective\nProgressive Attention ReCalibration), a training-free method that enhances the\ncontribution of visual tokens during decoding. SPARC is founded on three key\nobservations: (1) increasing the influence of all visual tokens reduces recall;\nthus, SPARC selectively amplifies visual tokens; (2) as captions lengthen,\nvisual attention becomes noisier, so SPARC identifies critical visual tokens by\nleveraging attention differences across time steps; (3) as visual attention\ngradually weakens, SPARC reinforces it to preserve its influence. Our\nexperiments, incorporating both automated and human evaluations, demonstrate\nthat existing methods improve the precision of MLLMs at the cost of recall. In\ncontrast, our proposed method enhances both precision and recall with minimal\ncomputational overhead.", "AI": {"tldr": "SPARC is a training-free method that improves image captioning by selectively recalibrating visual attention, enhancing both precision and recall without computational overhead.", "motivation": "Current MLLMs struggle with balancing precision and recall in detailed image captioning due to weakening and noisy visual attention as responses lengthen.", "method": "SPARC selectively amplifies visual tokens, identifies critical tokens using attention differences, and reinforces weakening attention during decoding.", "result": "SPARC improves both precision and recall in image captioning, outperforming existing methods with minimal computational cost.", "conclusion": "SPARC effectively addresses visual attention limitations in MLLMs, enhancing caption quality without additional training."}}
{"id": "2409.03833", "pdf": "https://arxiv.org/pdf/2409.03833", "abs": "https://arxiv.org/abs/2409.03833", "authors": ["Victoria Tiki", "Kiet Pham", "Eliu Huerta"], "title": "Sequence modeling of higher-order wave modes of binary black hole mergers", "categories": ["gr-qc", "astro-ph.IM", "cs.AI", "68T10, 85-08, 83C35, 83C57", "I.2"], "comment": "32 pages, 2 appendices, 17 figures", "summary": "Higher-order gravitational wave modes from quasi-circular, spinning,\nnon-precessing binary black hole mergers encode key information about these\nsystems' nonlinear dynamics. We model these waveforms using transformer\narchitectures, targeting the evolution from late inspiral through ringdown. Our\ndata is derived from the \\texttt{NRHybSur3dq8} surrogate model, which includes\nspherical harmonic modes up to $\\ell \\leq 4$ (excluding $(4,0)$, $(4,\\pm1)$ and\nincluding $(5,5)$ modes). These waveforms span mass ratios $q \\leq 8$, spin\ncomponents $s^z_{{1,2}} \\in [-0.8, 0.8]$, and inclination angles $\\theta \\in\n[0, \\pi]$. The model processes input data over the time interval $t \\in\n[-5000\\textrm{M}, -100\\textrm{M})$ and generates predictions for the plus and\ncross polarizations, $(h_{+}, h_{\\times})$, over the interval $t \\in\n[-100\\textrm{M}, 130\\textrm{M}]$. Utilizing 16 NVIDIA A100 GPUs on the Delta\nsupercomputer, we trained the transformer model in 15 hours on over 14 million\nsamples. The model's performance was evaluated on a test dataset of 840,000\nsamples, achieving mean and median overlap scores of 0.996 and 0.997,\nrespectively, relative to the surrogate-based ground truth signals. We further\nbenchmark the model on numerical relativity waveforms from the SXS catalog,\nfinding that it generalizes well to out-of-distribution systems, capable of\nreproducing the dynamics of systems with mass ratios up to $q=15$ and spin\nmagnitudes up to 0.998, with a median overlap of 0.969 across 521 NR waveforms\nand up to 0.998 in face-on/off configurations. These results demonstrate that\ntransformer-based models can capture the nonlinear dynamics of binary black\nhole mergers with high accuracy, even outside the surrogate training domain,\nenabling fast sequence modeling of higher-order wave modes.", "AI": {"tldr": "Transformer models accurately predict higher-order gravitational wave modes from binary black hole mergers, generalizing well beyond training data.", "motivation": "To capture the nonlinear dynamics of binary black hole mergers, especially higher-order gravitational wave modes, using transformer architectures for fast and accurate modeling.", "method": "Utilized a transformer model trained on data from the NRHybSur3dq8 surrogate model, covering mass ratios up to 8 and spins up to 0.8. Training involved 14 million samples on 16 GPUs.", "result": "Achieved mean/median overlaps of 0.996/0.997 with surrogate data and generalized well to out-of-distribution systems (e.g., q=15, spins up to 0.998) with median overlap of 0.969.", "conclusion": "Transformer models are highly effective for modeling binary black hole mergers, even beyond their training domain, enabling fast and accurate waveform predictions."}}
{"id": "2402.07052", "pdf": "https://arxiv.org/pdf/2402.07052", "abs": "https://arxiv.org/abs/2402.07052", "authors": ["Rudrajit Das", "Xi Chen", "Bertram Ieong", "Parikshit Bansal", "Sujay Sanghavi"], "title": "Understanding the Training Speedup from Sampling with Approximate Losses", "categories": ["cs.LG", "stat.ML"], "comment": "Updated version of our paper published in ICML 2024\n  (https://proceedings.mlr.press/v235/das24b.html)", "summary": "It is well known that selecting samples with large losses/gradients can\nsignificantly reduce the number of training steps. However, the selection\noverhead is often too high to yield any meaningful gains in terms of overall\ntraining time. In this work, we focus on the greedy approach of selecting\nsamples with large \\textit{approximate losses} instead of exact losses in order\nto reduce the selection overhead. For smooth convex losses, we show that such a\ngreedy strategy can converge to a constant factor of the minimum value of the\naverage loss in fewer iterations than the standard approach of random\nselection. We also theoretically quantify the effect of the approximation\nlevel. We then develop SIFT which uses early exiting to obtain approximate\nlosses with an intermediate layer's representations for sample selection. We\nevaluate SIFT on the task of training a 110M parameter 12 layer BERT base\nmodel, and show significant gains (in terms of training hours and number of\nbackpropagation steps) without any optimized implementation over vanilla\ntraining. For e.g., to reach 64% validation accuracy, SIFT with exit at the\nfirst layer takes ~ 43 hours compared to ~ 57 hours of vanilla training.", "AI": {"tldr": "SIFT reduces training time by selecting samples with approximate losses instead of exact losses, using early exiting for efficiency.", "motivation": "Reducing the overhead of sample selection in training by approximating losses, aiming for faster convergence.", "method": "Proposes SIFT, which uses early exiting to approximate losses from intermediate layers for sample selection.", "result": "SIFT achieves significant training time reduction (e.g., 43 vs. 57 hours for 64% accuracy) without optimized implementation.", "conclusion": "Approximate loss selection via SIFT is effective for reducing training time while maintaining performance."}}
{"id": "2502.19582", "pdf": "https://arxiv.org/pdf/2502.19582", "abs": "https://arxiv.org/abs/2502.19582", "authors": ["Ife Adebara", "Hawau Olamide Toyin", "Nahom Tesfu Ghebremichael", "AbdelRahim Elmadany", "Muhammad Abdul-Mageed"], "title": "Where Are We? Evaluating LLM Performance on African Languages", "categories": ["cs.CL"], "comment": null, "summary": "Africa's rich linguistic heritage remains underrepresented in NLP, largely\ndue to historical policies that favor foreign languages and create significant\ndata inequities. In this paper, we integrate theoretical insights on Africa's\nlanguage landscape with an empirical evaluation using Sahara - a comprehensive\nbenchmark curated from large-scale, publicly accessible datasets capturing the\ncontinent's linguistic diversity. By systematically assessing the performance\nof leading large language models (LLMs) on Sahara, we demonstrate how\npolicy-induced data variations directly impact model effectiveness across\nAfrican languages. Our findings reveal that while a few languages perform\nreasonably well, many Indigenous languages remain marginalized due to sparse\ndata. Leveraging these insights, we offer actionable recommendations for policy\nreforms and inclusive data practices. Overall, our work underscores the urgent\nneed for a dual approach - combining theoretical understanding with empirical\nevaluation - to foster linguistic diversity in AI for African communities.", "AI": {"tldr": "The paper highlights the underrepresentation of African languages in NLP due to historical biases and data inequities, using the Sahara benchmark to evaluate LLMs and advocate for policy reforms.", "motivation": "Address the underrepresentation of African languages in NLP caused by historical policies favoring foreign languages and data inequities.", "method": "Integrate theoretical insights on Africa's language landscape with empirical evaluation using the Sahara benchmark to assess LLM performance.", "result": "LLMs perform unevenly across African languages, with many Indigenous languages marginalized due to sparse data.", "conclusion": "A dual approach of theoretical understanding and empirical evaluation is needed to promote linguistic diversity in AI for African communities."}}
{"id": "2502.07782", "pdf": "https://arxiv.org/pdf/2502.07782", "abs": "https://arxiv.org/abs/2502.07782", "authors": ["Nathan Mankovich", "Ignacio Santamaria", "Gustau Camps-Valls", "Tolga Birdal"], "title": "A Flag Decomposition for Hierarchical Datasets", "categories": ["cs.CV"], "comment": null, "summary": "Flag manifolds encode nested sequences of subspaces and serve as powerful\nstructures for various computer vision and machine learning applications.\nDespite their utility in tasks such as dimensionality reduction, motion\naveraging, and subspace clustering, current applications are often restricted\nto extracting flags using common matrix decomposition methods like the singular\nvalue decomposition. Here, we address the need for a general algorithm to\nfactorize and work with hierarchical datasets. In particular, we propose a\nnovel, flag-based method that decomposes arbitrary hierarchical real-valued\ndata into a hierarchy-preserving flag representation in Stiefel coordinates.\nOur work harnesses the potential of flag manifolds in applications including\ndenoising, clustering, and few-shot learning.", "AI": {"tldr": "Proposes a flag-based method for decomposing hierarchical data into flag representations, enhancing applications like denoising and clustering.", "motivation": "Current methods for flag extraction are limited to matrix decompositions, lacking a general algorithm for hierarchical data.", "method": "Introduces a novel flag-based decomposition method using Stiefel coordinates to preserve hierarchy.", "result": "Enables hierarchical data representation, improving tasks like denoising, clustering, and few-shot learning.", "conclusion": "The method expands flag manifold utility in computer vision and machine learning."}}
{"id": "2410.12593", "pdf": "https://arxiv.org/pdf/2410.12593", "abs": "https://arxiv.org/abs/2410.12593", "authors": ["Wei Chen", "Yuxuan Liang"], "title": "Expand and Compress: Exploring Tuning Principles for Continual Spatio-Temporal Graph Forecasting", "categories": ["cs.LG", "cs.AI"], "comment": "Accepted by ICLR 2025", "summary": "The widespread deployment of sensing devices leads to a surge in data for\nspatio-temporal forecasting applications such as traffic flow, air quality, and\nwind energy. Although spatio-temporal graph neural networks have achieved\nsuccess in modeling various static spatio-temporal forecasting scenarios,\nreal-world spatio-temporal data are typically received in a streaming manner,\nand the network continuously expands with the installation of new sensors.\nThus, spatio-temporal forecasting in streaming scenarios faces dual challenges:\nthe inefficiency of retraining models over newly arrived data and the\ndetrimental effects of catastrophic forgetting over long-term history. To\naddress these challenges, we propose a novel prompt tuning-based continuous\nforecasting method, following two fundamental tuning principles guided by\nempirical and theoretical analysis: expand and compress, which effectively\nresolve the aforementioned problems with lightweight tuning parameters.\nSpecifically, we integrate the base spatio-temporal graph neural network with a\ncontinuous prompt pool, utilizing stored prompts (i.e., few learnable\nparameters) in memory, and jointly optimize them with the base spatio-temporal\ngraph neural network. This method ensures that the model sequentially learns\nfrom the spatio-temporal data stream to accomplish tasks for corresponding\nperiods. Extensive experimental results on multiple real-world datasets\ndemonstrate the multi-faceted superiority of our method over the\nstate-of-the-art baselines, including effectiveness, efficiency, universality,\netc.", "AI": {"tldr": "A novel prompt tuning-based method for spatio-temporal forecasting in streaming scenarios addresses inefficiency and catastrophic forgetting by integrating a continuous prompt pool with a base spatio-temporal graph neural network.", "motivation": "Real-world spatio-temporal data arrives in streams, and networks expand with new sensors, making retraining inefficient and causing catastrophic forgetting of long-term history.", "method": "Proposes a prompt tuning-based continuous forecasting method with 'expand and compress' principles, integrating a base spatio-temporal graph neural network with a continuous prompt pool for lightweight tuning.", "result": "Extensive experiments show the method's superiority in effectiveness, efficiency, and universality over state-of-the-art baselines.", "conclusion": "The method effectively addresses streaming spatio-temporal forecasting challenges with lightweight tuning, outperforming existing approaches."}}
{"id": "2406.00153", "pdf": "https://arxiv.org/pdf/2406.00153", "abs": "https://arxiv.org/abs/2406.00153", "authors": ["Benjamin Th\u00e9rien", "Charles-\u00c9tienne Joseph", "Boris Knyazev", "Edouard Oyallon", "Irina Rish", "Eugene Belilovsky"], "title": "$\u03bc$LO: Compute-Efficient Meta-Generalization of Learned Optimizers", "categories": ["cs.LG"], "comment": null, "summary": "Learned optimizers (LOs) can significantly reduce the wall-clock training\ntime of neural networks, substantially reducing training costs. However, they\ncan struggle to optimize unseen tasks (meta-generalize), especially when\ntraining networks wider than those seen during meta-training. To address this,\nwe derive the Maximal Update Parametrization ($\\mu$P) for two state-of-the-art\nlearned optimizer architectures and propose a simple meta-training recipe for\n$\\mu$-parameterized LOs ($\\mu$LOs). Our empirical evaluation demonstrates that\nLOs meta-trained with our recipe substantially improve meta-generalization to\nwider unseen tasks when compared to LOs trained under standard parametrization\n(SP), as they are trained in existing work. We also empirically observe that\n$\\mu$LOs trained with our recipe exhibit unexpectedly improved\nmeta-generalization to deeper networks ($5\\times$ meta-training) and surprising\ngeneralization to much longer training horizons ($25\\times$ meta-training) when\ncompared to SP LOs.", "AI": {"tldr": "Learned optimizers (LOs) with Maximal Update Parametrization ($\\mu$P) improve meta-generalization to wider, deeper, and longer training tasks compared to standard parametrization.", "motivation": "LOs reduce training time but struggle with unseen tasks, especially wider networks. This work aims to improve their meta-generalization.", "method": "Derived $\\mu$P for LOs and proposed a meta-training recipe for $\\mu$-parameterized LOs ($\\mu$LOs).", "result": "$\\mu$LOs outperform standard LOs in meta-generalization to wider, deeper (5\u00d7), and longer (25\u00d7) training tasks.", "conclusion": "The $\\mu$P and meta-training recipe enhance LOs' generalization, making them more effective for diverse tasks."}}
{"id": "2503.01622", "pdf": "https://arxiv.org/pdf/2503.01622", "abs": "https://arxiv.org/abs/2503.01622", "authors": ["Eliya Habba", "Ofir Arviv", "Itay Itzhak", "Yotam Perlitz", "Elron Bandel", "Leshem Choshen", "Michal Shmueli-Scheuer", "Gabriel Stanovsky"], "title": "DOVE: A Large-Scale Multi-Dimensional Predictions Dataset Towards Meaningful LLM Evaluation", "categories": ["cs.CL"], "comment": null, "summary": "Recent work found that LLMs are sensitive to a wide range of arbitrary prompt\ndimensions, including the type of delimiters, answer enumerators, instruction\nwording, and more. This throws into question popular single-prompt evaluation\npractices. We present DOVE (Dataset Of Variation Evaluation) a large-scale\ndataset containing prompt perturbations of various evaluation benchmarks. In\ncontrast to previous work, we examine LLM sensitivity from an holistic\nperspective, and assess the joint effects of perturbations along various\ndimensions, resulting in thousands of perturbations per instance. We evaluate\nseveral model families against DOVE, leading to several findings, including\nefficient methods for choosing well-performing prompts, observing that few-shot\nexamples reduce sensitivity, and identifying instances which are inherently\nhard across all perturbations. DOVE consists of more than 250M prompt\nperturbations and model outputs, which we make publicly available to spur a\ncommunity-wide effort toward meaningful, robust, and efficient evaluation.\n  Browse the data, contribute, and more: https://slab-nlp.github.io/DOVE/", "AI": {"tldr": "DOVE is a large-scale dataset for evaluating LLM sensitivity to prompt variations, offering insights into robust evaluation practices.", "motivation": "Addressing the sensitivity of LLMs to arbitrary prompt dimensions and questioning single-prompt evaluation practices.", "method": "Creating DOVE, a dataset with thousands of prompt perturbations per instance, and evaluating LLM families against it.", "result": "Findings include efficient prompt selection, reduced sensitivity with few-shot examples, and identification of inherently hard instances.", "conclusion": "DOVE, with 250M+ perturbations, aims to improve LLM evaluation robustness and is publicly available for community use."}}
{"id": "2502.08905", "pdf": "https://arxiv.org/pdf/2502.08905", "abs": "https://arxiv.org/abs/2502.08905", "authors": ["Tangyu Jiang", "Haodi Wang", "Chun Yuan"], "title": "DiffoRA: Enabling Parameter-Efficient Fine-Tuning via Differential Module Selection", "categories": ["cs.CV"], "comment": null, "summary": "The Parameter-Efficient Fine-Tuning (PEFT) methods have been extensively\nresearched for large language models in downstream tasks. Among all the\nexisting approaches, the Low-Rank Adaptation (LoRA) has gained popularity for\nits streamlined design by incorporating low-rank matrices into existing\npre-trained models. Though effective, LoRA, as well as its adaptive\noptimizations, either allocate the same matrix to all the modules or adjust the\ninterior rank of the components based on importance scoring indicators. In this\npaper, we argue that not all the modules in LLMs are suitable and necessary to\nbe fine-tuned. Enlightened by this insight, we propose a new PEFT scheme called\nDiffoRA, which enables adaptive adoption of the low-rank decomposition\nmatrices. At the core of DiffoRA lies a Differential Adaptation Matrix (DAM) to\ndetermine which module is the most suitable and essential for fine-tuning. We\ntheoretically explain how the designed matrix impacts the convergence rate and\ngeneralization capability of a pre-trained model. We then construct the DAM via\ncontinuous relaxation and discretization with weight-sharing optimizations. We\nfully implement DiffoRA and design comprehensive experiments to evaluate its\nperformance. The experimental results demonstrate that DiffoRA delivers\nstate-of-the-art results across multiple benchmarks.", "AI": {"tldr": "DiffoRA is a new PEFT method that adaptively selects modules for fine-tuning in LLMs using a Differential Adaptation Matrix (DAM), outperforming existing approaches like LoRA.", "motivation": "Existing PEFT methods like LoRA apply uniform fine-tuning or importance-based adjustments, but not all modules in LLMs need tuning. DiffoRA addresses this by selectively adapting modules.", "method": "DiffoRA introduces a DAM to identify suitable modules for fine-tuning, using continuous relaxation, discretization, and weight-sharing optimizations. Theoretical analysis links DAM to model convergence and generalization.", "result": "DiffoRA achieves state-of-the-art performance across multiple benchmarks, demonstrating its effectiveness.", "conclusion": "DiffoRA offers a more efficient and effective PEFT approach by selectively fine-tuning only necessary modules in LLMs."}}
{"id": "2411.04281", "pdf": "https://arxiv.org/pdf/2411.04281", "abs": "https://arxiv.org/abs/2411.04281", "authors": ["Xingran Chen", "Zhenke Wu", "Xu Shi", "Hyunghoon Cho", "Bhramar Mukherjee"], "title": "Generating Synthetic Electronic Health Record Data: a Methodological Scoping Review with Benchmarking on Phenotype Data and Open-Source Software", "categories": ["cs.LG", "cs.AI", "stat.ML"], "comment": null, "summary": "We conduct a scoping review of existing approaches for synthetic EHR data\ngeneration, and benchmark major methods with proposed open-source software to\noffer recommendations for practitioners. We search three academic databases for\nour scoping review. Methods are benchmarked on open-source EHR datasets,\nMIMIC-III/IV. Seven existing methods covering major categories and two baseline\nmethods are implemented and compared. Evaluation metrics concern data fidelity,\ndownstream utility, privacy protection, and computational cost. 42 studies are\nidentified and classified into five categories. Seven open-source methods\ncovering all categories are selected, trained on MIMIC-III, and evaluated on\nMIMIC-III or MIMIC-IV for transportability considerations. Among them,\nGAN-based methods demonstrate competitive performance in fidelity and utility\non MIMIC-III; rule-based methods excel in privacy protection. Similar findings\nare observed on MIMIC-IV, except that GAN-based methods further outperform the\nbaseline methods in preserving fidelity. A Python package, \"SynthEHRella\", is\nprovided to integrate various choices of approaches and evaluation metrics,\nenabling more streamlined exploration and evaluation of multiple methods. We\nfound that method choice is governed by the relative importance of the\nevaluation metrics in downstream use cases. We provide a decision tree to guide\nthe choice among the benchmarked methods. Based on the decision tree, GAN-based\nmethods excel when distributional shifts exist between the training and testing\npopulations. Otherwise, CorGAN and MedGAN are most suitable for association\nmodeling and predictive modeling, respectively. Future research should\nprioritize enhancing fidelity of the synthetic data while controlling privacy\nexposure, and comprehensive benchmarking of longitudinal or conditional\ngeneration methods.", "AI": {"tldr": "A scoping review benchmarks synthetic EHR data generation methods, recommending GAN-based approaches for fidelity and utility, and rule-based for privacy. A Python package and decision tree guide method selection.", "motivation": "To evaluate and recommend synthetic EHR data generation methods for practitioners, addressing fidelity, utility, privacy, and computational cost.", "method": "Scoping review of 42 studies, benchmarking seven methods on MIMIC-III/IV datasets, evaluating fidelity, utility, privacy, and cost.", "result": "GAN-based methods excel in fidelity and utility; rule-based methods in privacy. A Python package and decision tree aid method selection.", "conclusion": "Method choice depends on evaluation priorities. Future work should improve fidelity and privacy, and benchmark longitudinal methods."}}
{"id": "2407.09887", "pdf": "https://arxiv.org/pdf/2407.09887", "abs": "https://arxiv.org/abs/2407.09887", "authors": ["Zhicheng Yang", "Yiwei Wang", "Yinya Huang", "Zhijiang Guo", "Wei Shi", "Xiongwei Han", "Liang Feng", "Linqi Song", "Xiaodan Liang", "Jing Tang"], "title": "OptiBench Meets ReSocratic: Measure and Improve LLMs for Optimization Modeling", "categories": ["cs.LG", "math.OC"], "comment": null, "summary": "Large language models (LLMs) have exhibited their problem-solving abilities\nin mathematical reasoning. Solving realistic optimization (OPT) problems in\napplication scenarios requires advanced and applied mathematics ability.\nHowever, current OPT benchmarks that merely solve linear programming are far\nfrom complex realistic situations. In this work, we propose OptiBench, a\nbenchmark for End-to-end optimization problem-solving with human-readable\ninputs and outputs. OptiBench contains rich optimization problems, including\nlinear and nonlinear programming with or without tabular data, which can\ncomprehensively evaluate LLMs' solving ability. In our benchmark, LLMs are\nrequired to call a code solver to provide precise numerical answers.\nFurthermore, to alleviate the data scarcity for optimization problems, and to\nbridge the gap between open-source LLMs on a small scale (e.g., Llama-3-8b) and\nclosed-source LLMs (e.g., GPT-4), we further propose a data synthesis method\nnamely ReSocratic. Unlike general data synthesis methods that proceed from\nquestions to answers, \\ReSocratic first incrementally synthesizes formatted\noptimization demonstration with mathematical formulations step by step and then\nback-translates the generated demonstrations into questions. Based on this, we\nsynthesize the ReSocratic-29k dataset. We further conduct supervised\nfine-tuning with ReSocratic-29k on multiple open-source models. Experimental\nresults show that ReSocratic-29k significantly improves the performance of\nopen-source models.", "AI": {"tldr": "OptiBench is a benchmark for evaluating LLMs' ability to solve complex optimization problems, supplemented by the ReSocratic-29k dataset to improve open-source models.", "motivation": "Current benchmarks for optimization problems are too simplistic, lacking real-world complexity. OptiBench aims to bridge this gap and enhance LLMs' problem-solving abilities.", "method": "Proposes OptiBench with diverse optimization problems and introduces ReSocratic, a data synthesis method to generate the ReSocratic-29k dataset for fine-tuning open-source models.", "result": "ReSocratic-29k significantly boosts the performance of open-source LLMs in solving optimization problems.", "conclusion": "OptiBench and ReSocratic-29k advance LLMs' capabilities in realistic optimization problem-solving, narrowing the gap between open-source and closed-source models."}}
{"id": "2503.03962", "pdf": "https://arxiv.org/pdf/2503.03962", "abs": "https://arxiv.org/abs/2503.03962", "authors": ["Catherine Arnett", "Tyler A. Chang", "James A. Michaelov", "Benjamin K. Bergen"], "title": "On the Acquisition of Shared Grammatical Representations in Bilingual Language Models", "categories": ["cs.CL"], "comment": "9 pages, 5 figures. Accepted at ACL 2025", "summary": "Crosslingual transfer is crucial to contemporary language models'\nmultilingual capabilities, but how it occurs is not well understood. We ask\nwhat happens to a monolingual language model when it begins to be trained on a\nsecond language. Specifically, we train small bilingual models for which we\ncontrol the amount of data for each language and the order of language\nexposure. To find evidence of shared multilingual representations, we turn to\nstructural priming, a method used to study grammatical representations in\nhumans. We first replicate previous crosslingual structural priming results and\nfind that after controlling for training data quantity and language exposure,\nthere are asymmetrical effects across language pairs and directions. We argue\nthat this asymmetry may shape hypotheses about human structural priming\neffects. We also find that structural priming effects are less robust for less\nsimilar language pairs, highlighting potential limitations of crosslingual\ntransfer learning and shared representations for typologically diverse\nlanguages.", "AI": {"tldr": "The paper investigates crosslingual transfer in small bilingual models, focusing on structural priming to understand shared multilingual representations. It reveals asymmetrical effects and limitations for less similar language pairs.", "motivation": "To understand how monolingual models adapt to a second language and explore shared multilingual representations using structural priming.", "method": "Training small bilingual models with controlled data quantity and language exposure order, then analyzing structural priming effects.", "result": "Asymmetrical crosslingual priming effects and reduced robustness for less similar language pairs, suggesting limitations in shared representations.", "conclusion": "Crosslingual transfer is influenced by language similarity and exposure, with implications for multilingual model design and human priming studies."}}
{"id": "2502.09356", "pdf": "https://arxiv.org/pdf/2502.09356", "abs": "https://arxiv.org/abs/2502.09356", "authors": ["Gabriel Tseng", "Anthony Fuller", "Marlena Reil", "Henry Herzog", "Patrick Beukema", "Favyen Bastani", "James R. Green", "Evan Shelhamer", "Hannah Kerner", "David Rolnick"], "title": "Galileo: Learning Global & Local Features of Many Remote Sensing Modalities", "categories": ["cs.CV"], "comment": null, "summary": "We introduce a highly multimodal transformer to represent many remote sensing\nmodalities - multispectral optical, synthetic aperture radar, elevation,\nweather, pseudo-labels, and more - across space and time. These inputs are\nuseful for diverse remote sensing tasks, such as crop mapping and flood\ndetection. However, learning shared representations of remote sensing data is\nchallenging, given the diversity of relevant data modalities, and because\nobjects of interest vary massively in scale, from small boats (1-2 pixels and\nfast) to glaciers (thousands of pixels and slow). We present a novel\nself-supervised learning algorithm that extracts multi-scale features across a\nflexible set of input modalities through masked modeling. Our dual global and\nlocal contrastive losses differ in their targets (deep representations vs.\nshallow input projections) and masking strategies (structured vs. not). Our\nGalileo is a single generalist model that outperforms SoTA specialist models\nfor satellite images and pixel time series across eleven benchmarks and\nmultiple tasks.", "AI": {"tldr": "A multimodal transformer (Galileo) for remote sensing tasks outperforms specialist models across 11 benchmarks using self-supervised learning with dual contrastive losses.", "motivation": "Remote sensing tasks require handling diverse data modalities and varying object scales, making shared representation learning challenging.", "method": "Uses a self-supervised learning algorithm with masked modeling and dual global/local contrastive losses to extract multi-scale features.", "result": "Galileo outperforms state-of-the-art specialist models in tasks like crop mapping and flood detection.", "conclusion": "The proposed model demonstrates the effectiveness of multimodal self-supervised learning for remote sensing."}}
{"id": "2411.13187", "pdf": "https://arxiv.org/pdf/2411.13187", "abs": "https://arxiv.org/abs/2411.13187", "authors": ["Erica Coppolillo", "Federico Cinus", "Marco Minici", "Francesco Bonchi", "Giuseppe Manco"], "title": "Engagement-Driven Content Generation with Large Language Models", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Large Language Models (LLMs) demonstrate significant persuasive capabilities\nin one-on-one interactions, but their influence within social networks, where\ninterconnected users and complex opinion dynamics pose unique challenges,\nremains underexplored. This paper addresses the research question: \\emph{Can\nLLMs generate meaningful content that maximizes user engagement on social\nnetworks?}\n  To answer this, we propose a pipeline using reinforcement learning with\nsimulated feedback, where the network's response to LLM-generated content\n(i.e., the reward) is simulated through a formal engagement model. This\napproach bypasses the temporal cost and complexity of live experiments,\nenabling an efficient feedback loop between the LLM and the network under\nstudy. It also allows to control over endogenous factors such as the LLM's\nposition within the social network and the distribution of opinions on a given\ntopic. Our approach is adaptive to the opinion distribution of the underlying\nnetwork and agnostic to the specifics of the engagement model, which is\nembedded as a plug-and-play component. Such flexibility makes it suitable for\nmore complex engagement tasks and interventions in computational social\nscience.\n  Using our framework, we analyze the performance of LLMs in generating social\nengagement under different conditions, showcasing their full potential in this\ntask. The experimental code is publicly available at\nhttps://github.com/mminici/Engagement-Driven-Content-Generation.", "AI": {"tldr": "The paper explores LLMs' persuasive power in social networks, proposing a reinforcement learning pipeline to maximize engagement via simulated feedback, demonstrating adaptability and effectiveness.", "motivation": "To understand and enhance LLMs' ability to generate engaging content in complex social networks, addressing underexplored dynamics.", "method": "A reinforcement learning pipeline with simulated feedback, using a plug-and-play engagement model to efficiently train LLMs.", "result": "LLMs effectively generate engaging content under varied conditions, showcasing their potential in social network contexts.", "conclusion": "The framework is flexible and scalable, suitable for computational social science tasks, with publicly available experimental code."}}
{"id": "2408.13805", "pdf": "https://arxiv.org/pdf/2408.13805", "abs": "https://arxiv.org/abs/2408.13805", "authors": ["Ioannis Athanasiadis", "Fredrik Lindsten", "Michael Felsberg"], "title": "Prior Learning in Introspective VAEs", "categories": ["cs.LG"], "comment": null, "summary": "Variational Autoencoders (VAEs) are a popular framework for unsupervised\nlearning and data generation. A plethora of methods have been proposed focusing\non improving VAEs, with the incorporation of adversarial objectives and the\nintegration of prior learning mechanisms being prominent directions. When it\ncomes to the former, an indicative instance is the recently introduced family\nof Introspective VAEs aiming at ensuring that a low likelihood is assigned to\nunrealistic samples. In this study, we focus on the Soft-IntroVAE (S-IntroVAE),\none of only two members of the Introspective VAE family, the other being the\noriginal IntroVAE. We select S-IntroVAE for its state-of-the-art status and its\ntraining stability. In particular, we investigate the implication of\nincorporating a multimodal and trainable prior into this S-IntroVAE. Namely, we\nformulate the prior as a third player and show that when trained in cooperation\nwith the decoder constitutes an effective way for prior learning, which shares\nthe Nash Equilibrium with the vanilla S-IntroVAE. Furthermore, based on a\nmodified formulation of the optimal ELBO in S-IntroVAE, we develop\ntheoretically motivated regularizations, namely (i) adaptive variance clipping\nto stabilize training when learning the prior and (ii) responsibility\nregularization to discourage the formation of inactive prior modes. Finally, we\nperform a series of targeted experiments on a 2D density estimation benchmark\nand in an image generation setting comprised of the (F)-MNIST and CIFAR-10\ndatasets demonstrating the effect of prior learning in S-IntroVAE in generation\nand representation learning.", "AI": {"tldr": "The paper investigates Soft-IntroVAE (S-IntroVAE), focusing on incorporating a multimodal, trainable prior to improve generation and representation learning. It introduces theoretical regularizations and validates results on benchmarks.", "motivation": "To enhance S-IntroVAE by integrating a trainable prior, addressing training stability and inactive prior modes, while maintaining its state-of-the-art performance.", "method": "Incorporates a multimodal prior as a third player, formulates optimal ELBO modifications, and introduces adaptive variance clipping and responsibility regularization.", "result": "Demonstrates improved generation and representation learning on 2D density estimation and image datasets (F-MNIST, CIFAR-10).", "conclusion": "The proposed prior learning framework and regularizations effectively enhance S-IntroVAE, validated by empirical results."}}
{"id": "2503.06706", "pdf": "https://arxiv.org/pdf/2503.06706", "abs": "https://arxiv.org/abs/2503.06706", "authors": ["Ming Zhang", "Yuhui Wang", "Yujiong Shen", "Tingyi Yang", "Changhao Jiang", "Yilong Wu", "Shihan Dou", "Qinhao Chen", "Zhiheng Xi", "Zhihao Zhang", "Yi Dong", "Zhen Wang", "Zhihui Fei", "Mingyang Wan", "Tao Liang", "Guojun Ma", "Qi Zhang", "Tao Gui", "Xuanjing Huang"], "title": "PFDial: A Structured Dialogue Instruction Fine-tuning Method Based on UML Flowcharts", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "Process-driven dialogue systems, which operate under strict predefined\nprocess constraints, are essential in customer service and equipment\nmaintenance scenarios. Although Large Language Models (LLMs) have shown\nremarkable progress in dialogue and reasoning, they still struggle to solve\nthese strictly constrained dialogue tasks. To address this challenge, we\nconstruct Process Flow Dialogue (PFDial) dataset, which contains 12,705\nhigh-quality Chinese dialogue instructions derived from 440 flowcharts\ncontaining 5,055 process nodes. Based on PlantUML specification, each UML\nflowchart is converted into atomic dialogue units i.e., structured five-tuples.\nExperimental results demonstrate that a 7B model trained with merely 800\nsamples, and a 0.5B model trained on total data both can surpass 90% accuracy.\nAdditionally, the 8B model can surpass GPT-4o up to 43.88% with an average of\n11.00%. We further evaluate models' performance on challenging backward\ntransitions in process flows and conduct an in-depth analysis of various\ndataset formats to reveal their impact on model performance in handling\ndecision and sequential branches. The data is released in\nhttps://github.com/KongLongGeFDU/PFDial.", "AI": {"tldr": "The paper introduces the PFDial dataset for process-driven dialogue tasks, showing that smaller models trained on it can outperform larger models like GPT-4o.", "motivation": "Process-driven dialogue systems under strict constraints are challenging for LLMs, despite their general dialogue capabilities.", "method": "The PFDial dataset is constructed from 440 flowcharts converted into structured five-tuples, and models are trained on this data.", "result": "A 7B model with 800 samples and a 0.5B model achieve over 90% accuracy, with the 8B model outperforming GPT-4o by up to 43.88%.", "conclusion": "The PFDial dataset effectively enhances model performance for constrained dialogue tasks, with insights on dataset formats and backward transitions."}}
{"id": "2502.13967", "pdf": "https://arxiv.org/pdf/2502.13967", "abs": "https://arxiv.org/abs/2502.13967", "authors": ["Roman Bachmann", "Jesse Allardice", "David Mizrahi", "Enrico Fini", "O\u011fuzhan Fatih Kar", "Elmira Amirloo", "Alaaeldin El-Nouby", "Amir Zamir", "Afshin Dehghan"], "title": "FlexTok: Resampling Images into 1D Token Sequences of Flexible Length", "categories": ["cs.CV", "cs.LG"], "comment": "ICML 2025. Project page at https://flextok.epfl.ch/", "summary": "Image tokenization has enabled major advances in autoregressive image\ngeneration by providing compressed, discrete representations that are more\nefficient to process than raw pixels. While traditional approaches use 2D grid\ntokenization, recent methods like TiTok have shown that 1D tokenization can\nachieve high generation quality by eliminating grid redundancies. However,\nthese methods typically use a fixed number of tokens and thus cannot adapt to\nan image's inherent complexity. We introduce FlexTok, a tokenizer that projects\n2D images into variable-length, ordered 1D token sequences. For example, a\n256x256 image can be resampled into anywhere from 1 to 256 discrete tokens,\nhierarchically and semantically compressing its information. By training a\nrectified flow model as the decoder and using nested dropout, FlexTok produces\nplausible reconstructions regardless of the chosen token sequence length. We\nevaluate our approach in an autoregressive generation setting using a simple\nGPT-style Transformer. On ImageNet, this approach achieves an FID<2 across 8 to\n128 tokens, outperforming TiTok and matching state-of-the-art methods with far\nfewer tokens. We further extend the model to support to text-conditioned image\ngeneration and examine how FlexTok relates to traditional 2D tokenization. A\nkey finding is that FlexTok enables next-token prediction to describe images in\na coarse-to-fine \"visual vocabulary\", and that the number of tokens to generate\ndepends on the complexity of the generation task.", "AI": {"tldr": "FlexTok introduces variable-length 1D tokenization for images, improving efficiency and quality in autoregressive generation, outperforming fixed-token methods like TiTok.", "motivation": "Traditional image tokenization uses fixed token counts, limiting adaptability to image complexity. FlexTok addresses this by enabling variable-length token sequences.", "method": "FlexTok projects 2D images into variable-length 1D token sequences, using a rectified flow decoder and nested dropout for reconstruction. A GPT-style Transformer is trained for autoregressive generation.", "result": "On ImageNet, FlexTok achieves FID<2 across 8 to 128 tokens, outperforming TiTok and matching state-of-the-art methods with fewer tokens. It also supports text-conditioned generation.", "conclusion": "FlexTok's variable-length tokenization enables coarse-to-fine image description, with token count adapting to task complexity, offering a flexible and efficient alternative to traditional 2D tokenization."}}
{"id": "2411.16666", "pdf": "https://arxiv.org/pdf/2411.16666", "abs": "https://arxiv.org/abs/2411.16666", "authors": ["Jiaan Han", "Junxiao Chen", "Yanzhe Fu"], "title": "CatNet: Controlling the False Discovery Rate in LSTM with SHAP Feature Importance and Gaussian Mirrors", "categories": ["stat.ML", "cs.AI", "cs.LG", "q-fin.ST"], "comment": null, "summary": "We introduce CatNet, an algorithm that effectively controls False Discovery\nRate (FDR) and selects significant features in LSTM. CatNet employs the\nderivative of SHAP values to quantify the feature importance, and constructs a\nvector-formed mirror statistic for FDR control with the Gaussian Mirror\nalgorithm. To avoid instability due to nonlinear or temporal correlations among\nfeatures, we also propose a new kernel-based independence measure. CatNet\nperforms robustly on different model settings with both simulated and\nreal-world data, which reduces overfitting and improves interpretability of the\nmodel. Our framework that introduces SHAP for feature importance in FDR control\nalgorithms and improves Gaussian Mirror can be naturally extended to other\ntime-series or sequential deep learning models.", "AI": {"tldr": "CatNet controls FDR and selects significant features in LSTM using SHAP derivatives and Gaussian Mirror, with a kernel-based independence measure for stability.", "motivation": "To improve feature selection and FDR control in LSTM models, addressing instability from nonlinear/temporal correlations.", "method": "Uses SHAP derivative for feature importance, Gaussian Mirror for FDR control, and a kernel-based independence measure.", "result": "Robust performance on simulated/real-world data, reducing overfitting and enhancing interpretability.", "conclusion": "The framework extends to other time-series or sequential deep learning models."}}
{"id": "2409.12915", "pdf": "https://arxiv.org/pdf/2409.12915", "abs": "https://arxiv.org/abs/2409.12915", "authors": ["Micha\u0142 Wili\u0144ski", "Mononito Goswami", "Willa Potosnak", "Nina \u017bukowska", "Artur Dubrawski"], "title": "Exploring Representations and Interventions in Time Series Foundation Models", "categories": ["cs.LG"], "comment": "Accepted at ICML'25", "summary": "Time series foundation models (TSFMs) promise to be powerful tools for a wide\nrange of applications. However, their internal representations and learned\nconcepts are still not well understood. In this study, we investigate the\nstructure and redundancy of representations across various TSFMs, examining the\nself-similarity of model layers within and across different model sizes. This\nanalysis reveals block-like redundancy in the representations, which can be\nutilized for informed pruning to improve inference speed and efficiency.\nAdditionally, we explore the concepts learned by these models - such as\nperiodicity and trends - and how these can be manipulated through latent space\nsteering to influence model behavior. Our experiments show that steering\ninterventions can introduce new features, e.g., adding periodicity or trends to\nsignals that initially lacked them. These findings underscore the value of\nrepresentational analysis for optimizing models and demonstrate how conceptual\nsteering offers new possibilities for more controlled and efficient time series\nanalysis with TSFMs.", "AI": {"tldr": "The paper analyzes the structure and redundancy in time series foundation models (TSFMs), revealing block-like redundancy for efficient pruning and exploring learned concepts like periodicity and trends through latent space steering.", "motivation": "To understand the internal representations and learned concepts of TSFMs, which are not well understood despite their potential for diverse applications.", "method": "Investigates self-similarity of model layers across different sizes, analyzes redundancy, and explores latent space steering to manipulate learned concepts.", "result": "Block-like redundancy enables efficient pruning, and latent space steering can introduce new features (e.g., periodicity or trends) into signals.", "conclusion": "Representational analysis optimizes TSFMs, and conceptual steering enhances controlled and efficient time series analysis."}}
{"id": "2503.08042", "pdf": "https://arxiv.org/pdf/2503.08042", "abs": "https://arxiv.org/abs/2503.08042", "authors": ["Naomi Baes", "Rapha\u00ebl Merx", "Nick Haslam", "Ekaterina Vylomova", "Haim Dubossarsky"], "title": "LSC-Eval: A General Framework to Evaluate Methods for Assessing Dimensions of Lexical Semantic Change Using LLM-Generated Synthetic Data", "categories": ["cs.CL"], "comment": "Accepted to ACL Findings (9-page long paper; 35 pages total including\n  limitations, appendices and references)", "summary": "Lexical Semantic Change (LSC) provides insight into cultural and social\ndynamics. Yet, the validity of methods for measuring different kinds of LSC\nremains unestablished due to the absence of historical benchmark datasets. To\naddress this gap, we propose LSC-Eval, a novel three-stage general-purpose\nevaluation framework to: (1) develop a scalable methodology for generating\nsynthetic datasets that simulate theory-driven LSC using In-Context Learning\nand a lexical database; (2) use these datasets to evaluate the sensitivity of\ncomputational methods to synthetic change; and (3) assess their suitability for\ndetecting change in specific dimensions and domains. We apply LSC-Eval to\nsimulate changes along the Sentiment, Intensity, and Breadth (SIB) dimensions,\nas defined in the SIBling framework, using examples from psychology. We then\nevaluate the ability of selected methods to detect these controlled\ninterventions. Our findings validate the use of synthetic benchmarks,\ndemonstrate that tailored methods effectively detect changes along SIB\ndimensions, and reveal that a state-of-the-art LSC model faces challenges in\ndetecting affective dimensions of LSC. LSC-Eval offers a valuable tool for\ndimension- and domain-specific benchmarking of LSC methods, with particular\nrelevance to the social sciences.", "AI": {"tldr": "LSC-Eval is a three-stage framework for evaluating Lexical Semantic Change (LSC) methods using synthetic datasets, focusing on Sentiment, Intensity, and Breadth dimensions.", "motivation": "Addressing the lack of historical benchmark datasets to validate LSC measurement methods.", "method": "Proposes LSC-Eval: (1) generates synthetic datasets via In-Context Learning, (2) evaluates method sensitivity, (3) assesses suitability for specific dimensions/domains.", "result": "Validates synthetic benchmarks, shows tailored methods detect SIB changes, and highlights challenges for state-of-the-art models in affective dimensions.", "conclusion": "LSC-Eval is a valuable tool for dimension- and domain-specific benchmarking, especially in social sciences."}}
{"id": "2502.15167", "pdf": "https://arxiv.org/pdf/2502.15167", "abs": "https://arxiv.org/abs/2502.15167", "authors": ["Chuan Cui", "Kejiang Chen", "Zhihua Wei", "Wen Shen", "Weiming Zhang", "Nenghai Yu"], "title": "M3-AGIQA: Multimodal, Multi-Round, Multi-Aspect AI-Generated Image Quality Assessment", "categories": ["cs.CV"], "comment": "24 pages. This work has been submitted to the ACM for possible\n  publication", "summary": "The rapid advancement of AI-generated image (AIGI) models presents new\nchallenges for evaluating image quality, particularly across three aspects:\nperceptual quality, prompt correspondence, and authenticity. To address these\nchallenges, we introduce M3-AGIQA, a comprehensive framework that leverages\nMultimodal Large Language Models (MLLMs) to enable more human-aligned, holistic\nevaluation of AI-generated images across both visual and textual domains.\nBesides, our framework features a structured multi-round evaluation process,\ngenerating and analyzing intermediate image descriptions to provide deeper\ninsight into these three aspects. By aligning model outputs more closely with\nhuman judgment, M3-AGIQA delivers robust and interpretable quality scores.\nExtensive experiments on multiple benchmarks demonstrate that our method\nachieves state-of-the-art performance on tested datasets and aspects, and\nexhibits strong generalizability in most cross-dataset settings. Code is\navailable at https://github.com/strawhatboy/M3-AGIQA.", "AI": {"tldr": "M3-AGIQA is a framework using Multimodal Large Language Models (MLLMs) to evaluate AI-generated images holistically, focusing on perceptual quality, prompt correspondence, and authenticity. It outperforms benchmarks and aligns with human judgment.", "motivation": "Addressing the challenges in evaluating AI-generated images (AIGI) across perceptual quality, prompt correspondence, and authenticity.", "method": "Leverages MLLMs for multimodal evaluation, featuring a structured multi-round process with intermediate image descriptions.", "result": "Achieves state-of-the-art performance on benchmarks and strong generalizability in cross-dataset settings.", "conclusion": "M3-AGIQA provides robust, interpretable quality scores aligned with human judgment, advancing AIGI evaluation."}}
{"id": "2411.19647", "pdf": "https://arxiv.org/pdf/2411.19647", "abs": "https://arxiv.org/abs/2411.19647", "authors": ["Shaowen Wang", "Anan Liu", "Jian Xiao", "Huan Liu", "Yuekui Yang", "Cong Xu", "Qianqian Pu", "Suncong Zheng", "Wei Zhang", "Di Wang", "Jie Jiang", "Jian Li"], "title": "CAdam: Confidence-Based Optimization for Online Learning", "categories": ["cs.LG", "cs.AI", "stat.ML"], "comment": null, "summary": "Modern recommendation systems frequently employ online learning to\ndynamically update their models with freshly collected data. The most commonly\nused optimizer for updating neural networks in these contexts is the Adam\noptimizer, which integrates momentum ($m_t$) and adaptive learning rate\n($v_t$). However, the volatile nature of online learning data, characterized by\nits frequent distribution shifts and presence of noise, poses significant\nchallenges to Adam's standard optimization process: (1) Adam may use outdated\nmomentum and the average of squared gradients, resulting in slower adaptation\nto distribution changes, and (2) Adam's performance is adversely affected by\ndata noise. To mitigate these issues, we introduce CAdam, a confidence-based\noptimization strategy that assesses the consistency between the momentum and\nthe gradient for each parameter dimension before deciding on updates. If\nmomentum and gradient are in sync, CAdam proceeds with parameter updates\naccording to Adam's original formulation; if not, it temporarily withholds\nupdates and monitors potential shifts in data distribution in subsequent\niterations. This method allows CAdam to distinguish between the true\ndistributional shifts and mere noise, and to adapt more quickly to new data\ndistributions. In various settings with distribution shift or noise, our\nexperiments demonstrate that CAdam surpasses other well-known optimizers,\nincluding the original Adam. Furthermore, in large-scale A/B testing within a\nlive recommendation system, CAdam significantly enhances model performance\ncompared to Adam, leading to substantial increases in the system's gross\nmerchandise volume (GMV).", "AI": {"tldr": "CAdam, a confidence-based optimizer, improves adaptation to distribution shifts and noise in online learning by validating momentum-gradient consistency, outperforming Adam in experiments and real-world recommendation systems.", "motivation": "Address Adam optimizer's limitations in handling volatile online learning data, such as distribution shifts and noise, which slow adaptation and degrade performance.", "method": "Introduces CAdam, which checks momentum-gradient consistency before updates, withholding updates if inconsistent to monitor for true distribution shifts.", "result": "CAdam outperforms Adam and other optimizers in noisy and shifting data scenarios, boosting performance in live recommendation systems and increasing GMV.", "conclusion": "CAdam effectively mitigates Adam's drawbacks in volatile environments, enhancing adaptability and performance in online learning settings."}}
{"id": "2409.18850", "pdf": "https://arxiv.org/pdf/2409.18850", "abs": "https://arxiv.org/abs/2409.18850", "authors": ["Vladim\u00edr Bo\u017ea", "Vladim\u00edr Macko"], "title": "Two Sparse Matrices are Better than One: Sparsifying Neural Networks with Double Sparse Factorization", "categories": ["cs.LG"], "comment": null, "summary": "Neural networks are often challenging to work with due to their large size\nand complexity. To address this, various methods aim to reduce model size by\nsparsifying or decomposing weight matrices, such as magnitude pruning and\nlow-rank or block-diagonal factorization. In this work, we present Double\nSparse Factorization (DSF), where we factorize each weight matrix into two\nsparse matrices. Although solving this problem exactly is computationally\ninfeasible, we propose an efficient heuristic based on alternating minimization\nvia ADMM that achieves state-of-the-art results, enabling unprecedented\nsparsification of neural networks. For instance, in a one-shot pruning setting,\nour method can reduce the size of the LLaMA2-13B model by 50% while maintaining\nbetter performance than the dense LLaMA2-7B model. We also compare favorably\nwith Optimal Brain Compression, the state-of-the-art layer-wise pruning\napproach for convolutional neural networks. Furthermore, accuracy improvements\nof our method persist even after further model fine-tuning.\n  Code available at: https://github.com/usamec/double_sparse.", "AI": {"tldr": "DSF factorizes weight matrices into two sparse matrices, achieving state-of-the-art sparsification with efficient ADMM-based heuristics.", "motivation": "Neural networks' large size and complexity make them hard to work with; DSF aims to reduce model size while maintaining performance.", "method": "Double Sparse Factorization (DSF) decomposes weight matrices into two sparse matrices using alternating minimization via ADMM.", "result": "DSF reduces LLaMA2-13B size by 50% while outperforming dense LLaMA2-7B and competes with Optimal Brain Compression.", "conclusion": "DSF enables unprecedented sparsification with persistent accuracy improvements, even post fine-tuning."}}
{"id": "2503.10267", "pdf": "https://arxiv.org/pdf/2503.10267", "abs": "https://arxiv.org/abs/2503.10267", "authors": ["Laurie Burchell", "Ona de Gibert", "Nikolay Arefyev", "Mikko Aulamo", "Marta Ba\u00f1\u00f3n", "Pinzhen Chen", "Mariia Fedorova", "Liane Guillou", "Barry Haddow", "Jan Haji\u010d", "Jind\u0159ich Helcl", "Erik Henriksson", "Mateusz Klimaszewski", "Ville Komulainen", "Andrey Kutuzov", "Joona Kyt\u00f6niemi", "Veronika Laippala", "Petter M\u00e6hlum", "Bhavitvya Malik", "Farrokh Mehryary", "Vladislav Mikhailov", "Nikita Moghe", "Amanda Myntti", "Dayy\u00e1n O'Brien", "Stephan Oepen", "Proyag Pal", "Jousia Piha", "Sampo Pyysalo", "Gema Ram\u00edrez-S\u00e1nchez", "David Samuel", "Pavel Stepachev", "J\u00f6rg Tiedemann", "Du\u0161an Vari\u0161", "Tereza Vojt\u011bchov\u00e1", "Jaume Zaragoza-Bernabeu"], "title": "An Expanded Massive Multilingual Dataset for High-Performance Language Technologies (HPLT)", "categories": ["cs.CL"], "comment": "ACL'2025 Main Proceedings", "summary": "Training state-of-the-art large language models requires vast amounts of\nclean and diverse textual data. However, building suitable multilingual\ndatasets remains a challenge. In this work, we present HPLT v2, a collection of\nhigh-quality multilingual monolingual and parallel corpora, extending prior\nwork of the HPLT project. The monolingual portion of the data contains 8T\ntokens covering 193 languages, while the parallel data contains 380M sentence\npairs covering 51 languages. We document the entire data pipeline and release\nthe code to reproduce it. We provide extensive analysis of the quality and\ncharacteristics of our data. Finally, we evaluate the performance of language\nmodels and machine translation systems trained on HPLT v2, demonstrating its\nvalue.", "AI": {"tldr": "HPLT v2 is a high-quality multilingual dataset with 8T monolingual tokens and 380M parallel sentence pairs, covering 193 and 51 languages respectively, with released code and performance evaluations.", "motivation": "Addressing the challenge of building clean and diverse multilingual datasets for training large language models.", "method": "Extends the HPLT project by collecting and processing multilingual monolingual and parallel corpora, documenting the pipeline, and releasing reproducible code.", "result": "The dataset includes 8T tokens (193 languages) and 380M sentence pairs (51 languages), with quality analysis and evaluations showing its effectiveness.", "conclusion": "HPLT v2 is a valuable resource for training language models and machine translation systems, with demonstrated performance benefits."}}
{"id": "2503.02101", "pdf": "https://arxiv.org/pdf/2503.02101", "abs": "https://arxiv.org/abs/2503.02101", "authors": ["Boyong He", "Yuxiang Ji", "Qianwen Ye", "Zhuoyue Tan", "Liaoni Wu"], "title": "Generalized Diffusion Detector: Mining Robust Features from Diffusion Models for Domain-Generalized Detection", "categories": ["cs.CV"], "comment": "CVPR2025 camera-ready version with supplementary material", "summary": "Domain generalization (DG) for object detection aims to enhance detectors'\nperformance in unseen scenarios. This task remains challenging due to complex\nvariations in real-world applications. Recently, diffusion models have\ndemonstrated remarkable capabilities in diverse scene generation, which\ninspires us to explore their potential for improving DG tasks. Instead of\ngenerating images, our method extracts multi-step intermediate features during\nthe diffusion process to obtain domain-invariant features for generalized\ndetection. Furthermore, we propose an efficient knowledge transfer framework\nthat enables detectors to inherit the generalization capabilities of diffusion\nmodels through feature and object-level alignment, without increasing inference\ntime. We conduct extensive experiments on six challenging DG benchmarks. The\nresults demonstrate that our method achieves substantial improvements of 14.0%\nmAP over existing DG approaches across different domains and corruption types.\nNotably, our method even outperforms most domain adaptation methods without\naccessing any target domain data. Moreover, the diffusion-guided detectors show\nconsistent improvements of 15.9% mAP on average compared to the baseline. Our\nwork aims to present an effective approach for domain-generalized detection and\nprovide potential insights for robust visual recognition in real-world\nscenarios. The code is available at\nhttps://github.com/heboyong/Generalized-Diffusion-Detector.", "AI": {"tldr": "The paper proposes a method using diffusion models to extract domain-invariant features for domain generalization in object detection, achieving significant performance improvements.", "motivation": "To address the challenge of domain generalization (DG) in object detection due to real-world variations, leveraging diffusion models' scene generation capabilities.", "method": "Extracts multi-step intermediate features from diffusion models for domain-invariant features and introduces a knowledge transfer framework for feature and object-level alignment.", "result": "Achieves 14.0% mAP improvement over existing DG methods and 15.9% mAP over baselines, outperforming domain adaptation methods without target data.", "conclusion": "The method effectively enhances DG for object detection and offers insights for robust real-world visual recognition."}}
{"id": "2412.00418", "pdf": "https://arxiv.org/pdf/2412.00418", "abs": "https://arxiv.org/abs/2412.00418", "authors": ["Yu Shi", "Yiqi Wang", "WeiXuan Lang", "Jiaxin Zhang", "Pan Dong", "Aiping Li"], "title": "Mixture of Experts for Node Classification", "categories": ["cs.SI", "cs.AI"], "comment": null, "summary": "Nodes in the real-world graphs exhibit diverse patterns in numerous aspects,\nsuch as degree and homophily. However, most existent node predictors fail to\ncapture a wide range of node patterns or to make predictions based on distinct\nnode patterns, resulting in unsatisfactory classification performance. In this\npaper, we reveal that different node predictors are good at handling nodes with\nspecific patterns and only apply one node predictor uniformly could lead to\nsuboptimal result. To mitigate this gap, we propose a mixture of experts\nframework, MoE-NP, for node classification. Specifically, MoE-NP combines a\nmixture of node predictors and strategically selects models based on node\npatterns. Experimental results from a range of real-world datasets demonstrate\nsignificant performance improvements from MoE-NP.", "AI": {"tldr": "MoE-NP, a mixture of experts framework, improves node classification by strategically selecting models based on node patterns, outperforming uniform predictors.", "motivation": "Existing node predictors fail to capture diverse node patterns, leading to suboptimal classification performance.", "method": "Proposes MoE-NP, combining multiple node predictors and selecting models based on node patterns.", "result": "Significant performance improvements demonstrated on real-world datasets.", "conclusion": "MoE-NP effectively addresses the limitations of uniform node predictors by leveraging diverse node patterns."}}
{"id": "2410.01679", "pdf": "https://arxiv.org/pdf/2410.01679", "abs": "https://arxiv.org/abs/2410.01679", "authors": ["Amirhossein Kazemnejad", "Milad Aghajohari", "Eva Portelance", "Alessandro Sordoni", "Siva Reddy", "Aaron Courville", "Nicolas Le Roux"], "title": "VinePPO: Refining Credit Assignment in RL Training of LLMs", "categories": ["cs.LG", "cs.CL"], "comment": "Accepted at ICML 2025; 12 pages and 22 pages Appendix", "summary": "Large language models (LLMs) are increasingly applied to complex reasoning\ntasks that require executing several complex steps before receiving any reward.\nProperly assigning credit to these steps is essential for enhancing model\nperformance. Proximal Policy Optimization (PPO), a common reinforcement\nlearning (RL) algorithm used for LLM finetuning, employs value networks to\ntackle credit assignment. However, recent approaches achieve strong results\nwithout it, raising questions about the efficacy of value networks in practice.\nIn this work, we systematically evaluate the efficacy of value networks and\nreveal their significant shortcomings in reasoning-heavy LLM tasks, showing\nthat they often produce poor estimate of expected return and barely outperform\na random baseline when comparing alternative steps. This motivates our key\nquestion: Can improved credit assignment enhance RL training for LLMs? To\naddress this, we propose VinePPO, a straightforward approach that leverages the\nflexibility of language environments to compute unbiased Monte Carlo-based\nestimates. Our method consistently outperforms PPO and other baselines across\nMATH and GSM8K datasets in less wall-clock time (up to 3.0x). Crucially, it\nachieves higher test accuracy for a given training accuracy, capturing more\ngeneralization signal per sample. These results emphasize the importance of\naccurate credit assignment in RL training of LLM.", "AI": {"tldr": "The paper evaluates the shortcomings of value networks in LLM reasoning tasks and proposes VinePPO, a Monte Carlo-based method, which outperforms PPO in efficiency and accuracy.", "motivation": "To address the poor performance of value networks in credit assignment for LLM reasoning tasks and explore if improved credit assignment can enhance RL training.", "method": "Proposes VinePPO, leveraging unbiased Monte Carlo estimates for credit assignment, tested on MATH and GSM8K datasets.", "result": "VinePPO outperforms PPO and baselines, achieving up to 3.0x faster training and higher test accuracy.", "conclusion": "Accurate credit assignment is crucial for RL training of LLMs, and VinePPO demonstrates its effectiveness."}}
{"id": "2503.10515", "pdf": "https://arxiv.org/pdf/2503.10515", "abs": "https://arxiv.org/abs/2503.10515", "authors": ["Florian Eichin", "Yang Janet Liu", "Barbara Plank", "Michael A. Hedderich"], "title": "Probing LLMs for Multilingual Discourse Generalization Through a Unified Label Set", "categories": ["cs.CL"], "comment": "18 pages, 7 figures, 3 tables, code:\n  https://github.com/mainlp/discourse_probes, camera-ready revision for ACL\n  2025", "summary": "Discourse understanding is essential for many NLP tasks, yet most existing\nwork remains constrained by framework-dependent discourse representations. This\nwork investigates whether large language models (LLMs) capture discourse\nknowledge that generalizes across languages and frameworks. We address this\nquestion along two dimensions: (1) developing a unified discourse relation\nlabel set to facilitate cross-lingual and cross-framework discourse analysis,\nand (2) probing LLMs to assess whether they encode generalizable discourse\nabstractions. Using multilingual discourse relation classification as a\ntestbed, we examine a comprehensive set of 23 LLMs of varying sizes and\nmultilingual capabilities. Our results show that LLMs, especially those with\nmultilingual training corpora, can generalize discourse information across\nlanguages and frameworks. Further layer-wise analyses reveal that language\ngeneralization at the discourse level is most salient in the intermediate\nlayers. Lastly, our error analysis provides an account of challenging relation\nclasses.", "AI": {"tldr": "LLMs generalize discourse knowledge across languages and frameworks, with multilingual models performing best, especially in intermediate layers.", "motivation": "To determine if LLMs capture generalizable discourse knowledge beyond language and framework constraints.", "method": "Developed a unified discourse relation label set and probed 23 LLMs of varying sizes and multilingual capabilities for discourse relation classification.", "result": "LLMs, especially multilingual ones, generalize discourse knowledge; intermediate layers show the most language generalization.", "conclusion": "LLMs encode generalizable discourse abstractions, with multilingual training enhancing cross-lingual and cross-framework performance."}}
{"id": "2503.04167", "pdf": "https://arxiv.org/pdf/2503.04167", "abs": "https://arxiv.org/abs/2503.04167", "authors": ["Yufang Liu", "Yao Du", "Tao Ji", "Jianing Wang", "Yang Liu", "Yuanbin Wu", "Aimin Zhou", "Mengdi Zhang", "Xunliang Cai"], "title": "The Role of Visual Modality in Multimodal Mathematical Reasoning: Challenges and Insights", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Recent research has increasingly focused on multimodal mathematical\nreasoning, particularly emphasizing the creation of relevant datasets and\nbenchmarks. Despite this, the role of visual information in reasoning has been\nunderexplored. Our findings show that existing multimodal mathematical models\nminimally leverage visual information, and model performance remains largely\nunaffected by changes to or removal of images in the dataset. We attribute this\nto the dominance of textual information and answer options that inadvertently\nguide the model to correct answers. To improve evaluation methods, we introduce\nthe HC-M3D dataset, specifically designed to require image reliance for\nproblem-solving and to challenge models with similar, yet distinct, images that\nchange the correct answer. In testing leading models, their failure to detect\nthese subtle visual differences suggests limitations in current visual\nperception capabilities. Additionally, we observe that the common approach of\nimproving general VQA capabilities by combining various types of image encoders\ndoes not contribute to math reasoning performance. This finding also presents a\nchallenge to enhancing visual reliance during math reasoning. Our benchmark and\ncode would be available at\n\\href{https://github.com/Yufang-Liu/visual_modality_role}{https://github.com/Yufang-Liu/visual\\_modality\\_role}.", "AI": {"tldr": "The paper highlights the underutilization of visual information in multimodal mathematical reasoning and introduces the HC-M3D dataset to address this gap, revealing limitations in current models' visual perception.", "motivation": "To investigate the role of visual information in multimodal mathematical reasoning, as existing models largely ignore it despite its potential importance.", "method": "The study introduces the HC-M3D dataset, designed to require image reliance for problem-solving, and tests leading models on their ability to detect subtle visual differences.", "result": "Current models fail to utilize visual information effectively, and combining various image encoders does not improve math reasoning performance.", "conclusion": "The findings challenge the enhancement of visual reliance in math reasoning and propose the HC-M3D dataset as a tool for better evaluation."}}
{"id": "2412.14468", "pdf": "https://arxiv.org/pdf/2412.14468", "abs": "https://arxiv.org/abs/2412.14468", "authors": ["Aditya Desai", "Shuo Yang", "Alejandro Cuadron", "Matei Zaharia", "Joseph E. Gonzalez", "Ion Stoica"], "title": "HashAttention: Semantic Sparsity for Faster Inference", "categories": ["cs.LG", "cs.AI"], "comment": "Accepted at ICML'2025", "summary": "Leveraging long contexts is crucial for advanced AI systems, but attention\ncomputation poses a scalability challenge. While scaled dot-product attention\n(SDPA) exhibits token sparsity, i.e. only a few pivotal tokens significantly\ncontribute to output, exploiting this sparsity remains challenging. Existing\nmethods either suffer from quality degradation or require substantial\nadditional resources. We show that identifying pivotal tokens is a Maximum\nInner Product Search (MIPS) problem. However, existing MIPS solutions are not\nwell-suited for SDPA, as they are not GPU-friendly and often underperform due\nto the separated query and key distributions. This paper introduces\nHashAttention, framing pivotal token identification as a recommendation\nproblem. Given a query, HashAttention encodes keys and queries in Hamming\nspace, capturing the required semantic similarity, using learned mapping\nfunctions. HashAttention efficiently identifies pivotal tokens for a given\nquery using bitwise operations and computes attention using only these tokens,\nimproving the overall attention efficiency. Trained on generic data,\nHashAttention reduces tokens used by up to $16\\times$ with minimal quality\nloss, requiring only 32 bits of auxiliary memory per token. Sparsity can be\nfurther improved to $32\\times$ through task-specific fine-tuning. On A100 GPU,\nat $32\\times$ sparsity, incorporating HashAttention reduces attention latency\nby up to $4.3\\times$ in GPT-FAST and $2.54\\times$ in FlashDecode, and achieves\nup to $3.12\\times$ higher throughput for GPT-FAST.", "AI": {"tldr": "HashAttention improves attention efficiency by identifying pivotal tokens via a recommendation problem, reducing token usage by up to 32x with minimal quality loss and significant speedups.", "motivation": "Scaled dot-product attention (SDPA) faces scalability issues due to token sparsity, and existing methods degrade quality or require excessive resources.", "method": "HashAttention frames pivotal token identification as a recommendation problem, encoding keys and queries in Hamming space using learned mappings and bitwise operations.", "result": "HashAttention reduces token usage by up to 16x (32x with fine-tuning), cuts attention latency by 4.3x in GPT-FAST, and boosts throughput by 3.12x.", "conclusion": "HashAttention efficiently addresses SDPA's scalability by leveraging sparsity, offering significant performance gains with minimal quality trade-offs."}}
{"id": "2410.08868", "pdf": "https://arxiv.org/pdf/2410.08868", "abs": "https://arxiv.org/abs/2410.08868", "authors": ["Navdeep Kumar", "Priyank Agrawal", "Giorgia Ramponi", "Kfir Yehuda Levy", "Shie Mannor"], "title": "On the Convergence of Single-Timescale Actor-Critic", "categories": ["cs.LG", "stat.ML"], "comment": "updated version , 27 pages", "summary": "We analyze the global convergence of the single-timescale actor-critic (AC)\nalgorithm for the infinite-horizon discounted Markov Decision Processes (MDPs)\nwith finite state spaces. To this end, we introduce an elegant analytical\nframework for handling complex, coupled recursions inherent in the algorithm.\nLeveraging this framework, we establish that the algorithm converges to an\n$\\epsilon$-close \\textbf{globally optimal} policy with a sample complexity of\n\\( O(\\epsilon^{-3}) \\). This significantly improves upon the existing\ncomplexity of $O(\\epsilon^{-2})$ to achieve $\\epsilon$-close \\textbf{stationary\npolicy}, which is equivalent to the complexity of $O(\\epsilon^{-4})$ to achieve\n$\\epsilon$-close \\textbf{globally optimal} policy using gradient domination\nlemma. Furthermore, we demonstrate that to achieve this improvement, the step\nsizes for both the actor and critic must decay as \\( O(k^{-\\frac{2}{3}}) \\)\nwith iteration $k$, diverging from the conventional \\( O(k^{-\\frac{1}{2}}) \\)\nrates commonly used in (non)convex optimization.", "AI": {"tldr": "The paper analyzes the global convergence of the single-timescale actor-critic algorithm for discounted MDPs, achieving an improved sample complexity of $O(\\epsilon^{-3})$ for globally optimal policies.", "motivation": "To address the inefficiency of existing methods in achieving globally optimal policies for MDPs, the paper introduces a novel analytical framework.", "method": "The authors develop an elegant framework to handle coupled recursions in the actor-critic algorithm, using step sizes decaying as $O(k^{-\\frac{2}{3}})$.", "result": "The algorithm converges to an $\\epsilon$-close globally optimal policy with $O(\\epsilon^{-3})$ complexity, outperforming prior $O(\\epsilon^{-4})$ results.", "conclusion": "The work demonstrates the importance of step-size choice and provides a significant improvement in convergence efficiency for actor-critic methods."}}
{"id": "2503.15358", "pdf": "https://arxiv.org/pdf/2503.15358", "abs": "https://arxiv.org/abs/2503.15358", "authors": ["Thomas Pickard", "Aline Villavicencio", "Maggie Mi", "Wei He", "Dylan Phelps", "Marco Idiart"], "title": "SemEval-2025 Task 1: AdMIRe -- Advancing Multimodal Idiomaticity Representation", "categories": ["cs.CL", "cs.CV", "I.2.7; I.4.m"], "comment": "Author accepted version; SemEval-2025 proceedings to appear at ACL\n  2025. This version corrects a typo in the results table", "summary": "Idiomatic expressions present a unique challenge in NLP, as their meanings\nare often not directly inferable from their constituent words. Despite recent\nadvancements in Large Language Models (LLMs), idiomaticity remains a\nsignificant obstacle to robust semantic representation. We present datasets and\ntasks for SemEval-2025 Task 1: AdMiRe (Advancing Multimodal Idiomaticity\nRepresentation), which challenges the community to assess and improve models'\nability to interpret idiomatic expressions in multimodal contexts and in\nmultiple languages. Participants competed in two subtasks: ranking images based\non their alignment with idiomatic or literal meanings, and predicting the next\nimage in a sequence. The most effective methods achieved human-level\nperformance by leveraging pretrained LLMs and vision-language models in\nmixture-of-experts settings, with multiple queries used to smooth over the\nweaknesses in these models' representations of idiomaticity.", "AI": {"tldr": "The paper introduces SemEval-2025 Task 1: AdMiRe, focusing on improving NLP models' ability to interpret idiomatic expressions in multimodal and multilingual contexts. Tasks include image ranking and sequence prediction, with top methods using pretrained LLMs and vision-language models.", "motivation": "Idiomatic expressions are challenging for NLP models, even with advancements in LLMs. The paper aims to address this gap by creating tasks to evaluate and enhance models' idiomaticity representation.", "method": "Datasets and tasks were designed for SemEval-2025 Task 1 (AdMiRe), involving image ranking and sequence prediction. Methods combined pretrained LLMs and vision-language models in mixture-of-experts setups.", "result": "Top-performing methods achieved human-level performance by leveraging multiple queries and smoothing weaknesses in idiomaticity representation.", "conclusion": "The AdMiRe task successfully advanced idiomaticity representation in NLP, demonstrating the effectiveness of combining LLMs and vision-language models."}}
{"id": "2503.05283", "pdf": "https://arxiv.org/pdf/2503.05283", "abs": "https://arxiv.org/abs/2503.05283", "authors": ["Souhail Hadgi", "Luca Moschella", "Andrea Santilli", "Diego Gomez", "Qixing Huang", "Emanuele Rodol\u00e0", "Simone Melzi", "Maks Ovsjanikov"], "title": "Escaping Plato's Cave: Towards the Alignment of 3D and Text Latent Spaces", "categories": ["cs.CV"], "comment": "CVPR 2025", "summary": "Recent works have shown that, when trained at scale, uni-modal 2D vision and\ntext encoders converge to learned features that share remarkable structural\nproperties, despite arising from different representations. However, the role\nof 3D encoders with respect to other modalities remains unexplored.\nFurthermore, existing 3D foundation models that leverage large datasets are\ntypically trained with explicit alignment objectives with respect to frozen\nencoders from other representations. In this work, we investigate the\npossibility of a posteriori alignment of representations obtained from\nuni-modal 3D encoders compared to text-based feature spaces. We show that naive\npost-training feature alignment of uni-modal text and 3D encoders results in\nlimited performance. We then focus on extracting subspaces of the corresponding\nfeature spaces and discover that by projecting learned representations onto\nwell-chosen lower-dimensional subspaces the quality of alignment becomes\nsignificantly higher, leading to improved accuracy on matching and retrieval\ntasks. Our analysis further sheds light on the nature of these shared\nsubspaces, which roughly separate between semantic and geometric data\nrepresentations. Overall, ours is the first work that helps to establish a\nbaseline for post-training alignment of 3D uni-modal and text feature spaces,\nand helps to highlight both the shared and unique properties of 3D data\ncompared to other representations. Our code and weights are available at\nhttps://github.com/Souhail-01/3d-text-alignment", "AI": {"tldr": "The paper explores post-training alignment of 3D and text feature spaces, finding improved performance by projecting onto lower-dimensional subspaces.", "motivation": "To investigate the alignment of 3D uni-modal encoders with text feature spaces, as existing methods rely on explicit alignment objectives.", "method": "Projects learned 3D and text representations onto lower-dimensional subspaces for better alignment.", "result": "Alignment quality improves significantly, enhancing matching and retrieval tasks, and reveals shared subspaces for semantic and geometric data.", "conclusion": "Establishes a baseline for post-training alignment of 3D and text features, highlighting shared and unique properties of 3D data."}}
{"id": "2501.06164", "pdf": "https://arxiv.org/pdf/2501.06164", "abs": "https://arxiv.org/abs/2501.06164", "authors": ["Satchel Grant"], "title": "Model Alignment Search", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "When can we say that two neural systems are the same? The answer to this\nquestion is goal-dependent, and it is often addressed through correlative\nmethods such as Representational Similarity Analysis (RSA) and Centered Kernel\nAlignment (CKA). What nuances do we miss, however, when we fail to causally\nprobe the representations? Do the dangers of cause vs. correlation exist in\ncomparative representational analyses? In this work, we introduce a method for\nconnecting neural representational similarity to behavior through causal\ninterventions. The method learns orthogonal transformations that find an\naligned subspace in which behavioral information from multiple distributed\nnetworks' representations can be isolated and interchanged. We first show that\nthe method can be used to transfer the behavior from one frozen Neural Network\n(NN) to another in a manner similar to model stitching, and we show how the\nmethod can complement correlative similarity measures like RSA. We then\nintroduce an efficient subspace orthogonalization technique using the\nGram-Schmidt process -- that can also be used for Distributed Alignment Search\n(DAS) -- allowing us to perform analyses on larger models. Next, we empirically\nand theoretically show how our method can be equivalent to model stitching when\ndesired, or it can take a form that is more restrictive to causal information,\nand in both cases, it reduces the number of required matrices for a comparison\nof n models from quadratic to linear in n. We then show how we can augment the\nloss objective with an auxiliary loss to train causally relevant alignments\neven when we can only read the representations from one of the two networks\nduring training (like with biological networks). Lastly, we use number\nrepresentations as a case study to explore how our method can be used to\ncompare specific types of representational information across tasks and models.", "AI": {"tldr": "The paper introduces a causal intervention method to compare neural systems, addressing limitations of correlative analyses like RSA and CKA, and demonstrates its utility in behavior transfer and alignment tasks.", "motivation": "To address the limitations of correlative methods in comparing neural representations and explore causal relationships between representations and behavior.", "method": "Proposes a method using orthogonal transformations to align subspaces for behavior isolation and interchange, complemented by an efficient subspace orthogonalization technique and auxiliary loss for causal alignment.", "result": "The method enables behavior transfer between networks, reduces comparison complexity, and can be adapted for causal or stitching-like analyses.", "conclusion": "The approach provides a flexible, efficient, and causally informative way to compare neural representations, with applications in model stitching and biological network analysis."}}
{"id": "2410.10404", "pdf": "https://arxiv.org/pdf/2410.10404", "abs": "https://arxiv.org/abs/2410.10404", "authors": ["Zachary Chase", "Idan Mehalel"], "title": "Deterministic Apple Tasting", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "In binary ($0/1$) online classification with apple tasting feedback, the\nlearner receives feedback only when predicting $1$. Besides some degenerate\nlearning tasks, all previously known learning algorithms for this model are\nrandomized. Consequently, prior to this work it was unknown whether\ndeterministic apple tasting is generally feasible. In this work, we provide the\nfirst widely-applicable deterministic apple tasting learner, and show that in\nthe realizable case, a hypothesis class is learnable if and only if it is\ndeterministically learnable, confirming a conjecture of [Raman, Subedi, Raman,\nTewari-24]. Quantitatively, we show that every class $\\mathcal{H}$ is learnable\nwith mistake bound $O \\left(\\sqrt{\\mathtt{L}(\\mathcal{H}) T \\log T} \\right)$\n(where $\\mathtt{L}(\\mathcal{H})$ is the Littlestone dimension of\n$\\mathcal{H}$), and that this is tight for some classes.\n  We further study the agnostic case, in which the best hypothesis makes at\nmost $k$ many mistakes, and prove a trichotomy stating that every class\n$\\mathcal{H}$ must be either easy, hard, or unlearnable. Easy classes have\n(both randomized and deterministic) mistake bound $\\Theta_{\\mathcal{H}}(k)$.\nHard classes have randomized mistake bound $\\tilde{\\Theta}_{\\mathcal{H}}\n\\left(k + \\sqrt{T} \\right)$, and deterministic mistake bound\n$\\tilde{\\Theta}_{\\mathcal{H}} \\left(\\sqrt{k \\cdot T} \\right)$, where $T$ is the\ntime horizon. Unlearnable classes have (both randomized and deterministic)\nmistake bound $\\Theta(T)$.\n  Our upper bound is based on a deterministic algorithm for learning from\nexpert advice with apple tasting feedback, a problem interesting in its own\nright. For this problem, we show that the optimal deterministic mistake bound\nis $\\Theta \\left(\\sqrt{T (k + \\log n)} \\right)$ for all $k$ and $T \\leq n \\leq\n2^T$, where $n$ is the number of experts.", "AI": {"tldr": "The paper introduces the first widely-applicable deterministic learner for binary online classification with apple tasting feedback, proving its feasibility and tight bounds.", "motivation": "Prior work left it unknown whether deterministic apple tasting is feasible, and this paper addresses this gap by confirming a conjecture and providing deterministic solutions.", "method": "The authors develop deterministic algorithms for learning with apple tasting feedback, analyzing both realizable and agnostic cases, and derive mistake bounds.", "result": "They show tight mistake bounds for deterministic learning, prove a trichotomy for agnostic cases, and provide optimal bounds for learning from expert advice.", "conclusion": "Deterministic apple tasting is feasible, with tight bounds established, and the work resolves open questions about learnability in this model."}}
{"id": "2503.15850", "pdf": "https://arxiv.org/pdf/2503.15850", "abs": "https://arxiv.org/abs/2503.15850", "authors": ["Xiaoou Liu", "Tiejin Chen", "Longchao Da", "Chacha Chen", "Zhen Lin", "Hua Wei"], "title": "Uncertainty Quantification and Confidence Calibration in Large Language Models: A Survey", "categories": ["cs.CL"], "comment": null, "summary": "Large Language Models (LLMs) excel in text generation, reasoning, and\ndecision-making, enabling their adoption in high-stakes domains such as\nhealthcare, law, and transportation. However, their reliability is a major\nconcern, as they often produce plausible but incorrect responses. Uncertainty\nquantification (UQ) enhances trustworthiness by estimating confidence in\noutputs, enabling risk mitigation and selective prediction. However,\ntraditional UQ methods struggle with LLMs due to computational constraints and\ndecoding inconsistencies. Moreover, LLMs introduce unique uncertainty sources,\nsuch as input ambiguity, reasoning path divergence, and decoding stochasticity,\nthat extend beyond classical aleatoric and epistemic uncertainty. To address\nthis, we introduce a new taxonomy that categorizes UQ methods based on\ncomputational efficiency and uncertainty dimensions (input, reasoning,\nparameter, and prediction uncertainty). We evaluate existing techniques, assess\ntheir real-world applicability, and identify open challenges, emphasizing the\nneed for scalable, interpretable, and robust UQ approaches to enhance LLM\nreliability.", "AI": {"tldr": "The paper discusses the challenges of uncertainty quantification (UQ) in Large Language Models (LLMs) and proposes a new taxonomy to categorize UQ methods for improving reliability.", "motivation": "LLMs are widely used in high-stakes domains but often produce incorrect yet plausible responses, necessitating better UQ methods to enhance trustworthiness.", "method": "The authors introduce a taxonomy for UQ methods based on computational efficiency and uncertainty dimensions (input, reasoning, parameter, and prediction uncertainty). They evaluate existing techniques and assess their applicability.", "result": "The study highlights the limitations of traditional UQ methods for LLMs and identifies unique uncertainty sources like input ambiguity and decoding stochasticity.", "conclusion": "Scalable, interpretable, and robust UQ approaches are needed to improve LLM reliability, addressing open challenges in the field."}}
{"id": "2503.06764", "pdf": "https://arxiv.org/pdf/2503.06764", "abs": "https://arxiv.org/abs/2503.06764", "authors": ["Zisheng Chen", "Chunwei Wang", "Xiuwei Chen", "Hongbin Xu", "Runhui Huang", "Jun Zhou", "Jianhua Han", "Hang Xu", "Xiaodan Liang"], "title": "SemHiTok: A Unified Image Tokenizer via Semantic-Guided Hierarchical Codebook for Multimodal Understanding and Generation", "categories": ["cs.CV", "cs.AI"], "comment": "Under Review, Refer to the latest version", "summary": "In this paper, we introduce SemHiTok, a unified image Tokenizer via\nSemantic-Guided Hierarchical codebook that provides consistent discrete\nrepresentations for multimodal understanding and generation. Recently, unified\nimage tokenizers have sparked exploration within research community, which is\ndesigned to capture high-level semantic features for understanding and\nretaining low-level pixel features for generation. Previous works attempt to\ntrain a unified image tokenizer by combining loss for semantic distillation and\npixel reconstruction. However, due to the differing levels of features\nprioritized by multimodal understanding and generation, joint training methods\nface significant challenges in achieving a good trade-off. SemHiTok addresses\nthis challenge through a novel semantic-guided hierarchical codebook, which\nbuilds pixel sub-codebooks on a pretrained semantic codebook. This design\ndecouples semantic and pixel both in terms of structure and training strategy,\nenabling the tokenizer to capture pixel features while retaining its ability to\ncomprehend high-level semantic information. Our experiments demonstrate that\nSemHiTok achieves SOTA performance in image reconstruction and multimodal\nunderstanding under LLaVA-v1.5 setting. Further, we develop a unified MLLM with\nSemHiTok, which exhibits superior performance across multimodal understanding\nand generation tasks. For understanding, SemHiTok achieves impressive\nperformance on most benchmarks. For generation, our model achieves SOTA\nperformance on MJHQ30K in unified MLLMs.", "AI": {"tldr": "SemHiTok is a unified image tokenizer using a semantic-guided hierarchical codebook to balance high-level semantic and low-level pixel features for multimodal tasks.", "motivation": "Existing unified image tokenizers struggle to balance semantic and pixel features due to conflicting priorities in multimodal understanding and generation.", "method": "SemHiTok introduces a semantic-guided hierarchical codebook, decoupling semantic and pixel features structurally and in training, enabling better feature capture.", "result": "SemHiTok achieves SOTA in image reconstruction and multimodal understanding, and its unified MLLM excels in both understanding and generation tasks.", "conclusion": "SemHiTok effectively balances semantic and pixel features, outperforming previous methods in multimodal tasks."}}
{"id": "2501.09328", "pdf": "https://arxiv.org/pdf/2501.09328", "abs": "https://arxiv.org/abs/2501.09328", "authors": ["Yixiao Xu", "Binxing Fang", "Rui Wang", "Yinghai Zhou", "Yuan Liu", "Mohan Li", "Zhihong Tian"], "title": "Neural Honeytrace: A Robust Plug-and-Play Watermarking Framework against Model Extraction Attacks", "categories": ["cs.CR", "cs.AI"], "comment": null, "summary": "Developing high-performance deep learning models is resource-intensive,\nleading model owners to utilize Machine Learning as a Service (MLaaS) platforms\ninstead of publicly releasing their models. However, malicious users may\nexploit query interfaces to execute model extraction attacks, reconstructing\nthe target model's functionality locally. While prior research has investigated\ntriggerable watermarking techniques for asserting ownership, existing methods\nface significant challenges: (1) most approaches require additional training,\nresulting in high overhead and limited flexibility, and (2) they often fail to\naccount for advanced attackers, leaving them vulnerable to adaptive attacks.\n  In this paper, we propose Neural Honeytrace, a robust plug-and-play\nwatermarking framework against model extraction attacks. We first formulate a\nwatermark transmission model from an information-theoretic perspective,\nproviding an interpretable account of the principles and limitations of\nexisting triggerable watermarking. Guided by the model, we further introduce:\n(1) a similarity-based training-free watermarking method for plug-and-play and\nflexible watermarking, and (2) a distribution-based multi-step watermark\ninformation transmission strategy for robust watermarking. Comprehensive\nexperiments on four datasets demonstrate that Neural Honeytrace outperforms\nprevious methods in efficiency and resisting adaptive attacks. Neural\nHoneytrace reduces the average number of samples required for a worst-case\nt-Test-based copyright claim from 193,252 to 1,857 with zero training cost. The\ncode is available at https://github.com/NeurHT/NeurHT.", "AI": {"tldr": "Neural Honeytrace is a plug-and-play watermarking framework for ML models, offering training-free and robust protection against model extraction attacks.", "motivation": "Resource-intensive deep learning models are vulnerable to extraction attacks via MLaaS platforms, and existing watermarking methods lack flexibility and robustness.", "method": "Proposes a similarity-based training-free watermarking method and a distribution-based multi-step transmission strategy.", "result": "Outperforms prior methods, reducing required samples for copyright claims from 193,252 to 1,857 with zero training cost.", "conclusion": "Neural Honeytrace provides efficient, flexible, and robust protection against model extraction attacks."}}
{"id": "2410.11289", "pdf": "https://arxiv.org/pdf/2410.11289", "abs": "https://arxiv.org/abs/2410.11289", "authors": ["Yutong He", "Pengrui Li", "Yipeng Hu", "Chuyan Chen", "Kun Yuan"], "title": "Subspace Optimization for Large Language Models with Convergence Guarantees", "categories": ["cs.LG", "math.OC"], "comment": "Accepted by ICML 2025", "summary": "Subspace optimization algorithms, such as GaLore (Zhao et al., 2024), have\ngained attention for pre-training and fine-tuning large language models (LLMs)\ndue to their memory efficiency. However, their convergence guarantees remain\nunclear, particularly in stochastic settings. In this paper, we reveal that\nGaLore does not always converge to the optimal solution and provide an explicit\ncounterexample to support this finding. We further explore the conditions under\nwhich GaLore achieves convergence, showing that it does so when either (i) a\nsufficiently large mini-batch size is used or (ii) the gradient noise is\nisotropic. More significantly, we introduce GoLore (Gradient random Low-rank\nprojection), a novel variant of GaLore that provably converges in typical\nstochastic settings, even with standard batch sizes. Our convergence analysis\nextends naturally to other subspace optimization algorithms. Finally, we\nempirically validate our theoretical results and thoroughly test the proposed\nmechanisms. Codes are available at https://github.com/pkumelon/Golore.", "AI": {"tldr": "The paper analyzes GaLore's convergence issues, introduces GoLore for guaranteed convergence, and validates results empirically.", "motivation": "To address unclear convergence guarantees of GaLore in stochastic settings and propose a solution.", "method": "Theoretical analysis of GaLore's convergence, introduction of GoLore, and empirical validation.", "result": "GaLore may not converge optimally; GoLore ensures convergence under standard conditions.", "conclusion": "GoLore is a provably convergent alternative to GaLore, with broader implications for subspace optimization."}}
{"id": "2503.23512", "pdf": "https://arxiv.org/pdf/2503.23512", "abs": "https://arxiv.org/abs/2503.23512", "authors": ["Qiang Yi", "Yangfan He", "Jianhui Wang", "Xinyuan Song", "Shiyao Qian", "Xinhang Yuan", "Li Sun", "Yi Xin", "Keqin Li", "Kuan Lu", "Menghao Huo", "Jiaqi Chen", "Tianyu Shi"], "title": "SCORE: Story Coherence and Retrieval Enhancement for AI Narratives", "categories": ["cs.CL"], "comment": null, "summary": "Large Language Models (LLMs) can generate creative and engaging narratives\nfrom user-specified input, but maintaining coherence and emotional depth\nthroughout these AI-generated stories remains a challenge. In this work, we\npropose SCORE, a framework for Story Coherence and Retrieval Enhancement,\ndesigned to detect and resolve narrative inconsistencies. By tracking key item\nstatuses and generating episode summaries, SCORE uses a Retrieval-Augmented\nGeneration (RAG) approach, incorporating TF-IDF and cosine similarity to\nidentify related episodes and enhance the overall story structure. Results from\ntesting multiple LLM-generated stories demonstrate that SCORE significantly\nimproves the consistency and stability of narrative coherence compared to\nbaseline GPT models, providing a more robust method for evaluating and refining\nAI-generated narratives.", "AI": {"tldr": "SCORE improves coherence in AI-generated stories by tracking item statuses and using retrieval-augmented generation.", "motivation": "Maintaining coherence and emotional depth in AI-generated narratives is challenging.", "method": "SCORE uses TF-IDF and cosine similarity for retrieval-augmented generation to resolve inconsistencies.", "result": "SCORE enhances narrative coherence significantly over baseline GPT models.", "conclusion": "SCORE provides a robust method for refining AI-generated stories."}}
{"id": "2503.10042", "pdf": "https://arxiv.org/pdf/2503.10042", "abs": "https://arxiv.org/abs/2503.10042", "authors": ["Ziyue Wang", "Yurui Dong", "Fuwen Luo", "Minyuan Ruan", "Zhili Cheng", "Chi Chen", "Peng Li", "Yang Liu"], "title": "EscapeCraft: A 3D Room Escape Environment for Benchmarking Complex Multimodal Reasoning Ability", "categories": ["cs.CV"], "comment": null, "summary": "The rapid advancing of Multimodal Large Language Models (MLLMs) has spurred\ninterest in complex multimodal reasoning tasks in the real-world and virtual\nenvironment, which require coordinating multiple abilities, including visual\nperception, visual reasoning, spatial awareness, and target deduction. However,\nexisting evaluations primarily assess the final task completion, often\ndegrading assessments to isolated abilities such as visual grounding and visual\nquestion answering. Less attention is given to comprehensively and\nquantitatively analyzing reasoning process in multimodal environments, which is\ncrucial for understanding model behaviors and underlying reasoning mechanisms\nbeyond merely task success. To address this, we introduce MM-Escape, an\nextensible benchmark for investigating multimodal reasoning, inspired by\nreal-world escape games. MM-Escape emphasizes intermediate model behaviors\nalongside final task completion. To achieve this, we develop EscapeCraft, a\ncustomizable and open environment that enables models to engage in free-form\nexploration for assessing multimodal reasoning. Extensive experiments show that\nMLLMs, regardless of scale, can successfully complete the simplest room escape\ntasks, with some exhibiting human-like exploration strategies. Yet, performance\ndramatically drops as task difficulty increases. Moreover, we observe that\nperformance bottlenecks vary across models, revealing distinct failure modes\nand limitations in their multimodal reasoning abilities, such as repetitive\ntrajectories without adaptive exploration, getting stuck in corners due to poor\nvisual spatial awareness, and ineffective use of acquired props, such as the\nkey. We hope our work sheds light on new challenges in multimodal reasoning,\nand uncovers potential improvements in MLLMs capabilities.", "AI": {"tldr": "The paper introduces MM-Escape, a benchmark for evaluating multimodal reasoning in MLLMs, highlighting gaps in current assessments and revealing model limitations.", "motivation": "Existing evaluations focus on task completion, neglecting the reasoning process. The paper aims to address this by analyzing intermediate behaviors in multimodal tasks.", "method": "The authors develop MM-Escape, a benchmark inspired by escape games, and EscapeCraft, an open environment for assessing multimodal reasoning.", "result": "MLLMs succeed in simple tasks but struggle with complexity, showing varied failure modes like poor spatial awareness and ineffective prop use.", "conclusion": "The work identifies new challenges in multimodal reasoning and suggests areas for improving MLLMs."}}
{"id": "2501.11454", "pdf": "https://arxiv.org/pdf/2501.11454", "abs": "https://arxiv.org/abs/2501.11454", "authors": ["Akash Kundu"], "title": "Improving thermal state preparation of Sachdev-Ye-Kitaev model with reinforcement learning on quantum hardware", "categories": ["quant-ph", "cs.AI", "cs.LG", "hep-lat", "hep-th"], "comment": "Accepted in Machine Learning: Science and Technology. Code at\n  https://github.com/Aqasch/solving_SYK_model_with_RL", "summary": "The Sachdev-Ye-Kitaev (SYK) model, known for its strong quantum correlations\nand chaotic behavior, serves as a key platform for quantum gravity studies.\nHowever, variationally preparing thermal states on near-term quantum processors\nfor large systems ($N>12$, where $N$ is the number of Majorana fermions)\npresents a significant challenge due to the rapid growth in the complexity of\nparameterized quantum circuits. This paper addresses this challenge by\nintegrating reinforcement learning (RL) with convolutional neural networks,\nemploying an iterative approach to optimize the quantum circuit and its\nparameters. The refinement process is guided by a composite reward signal\nderived from entropy and the expectation values of the SYK Hamiltonian. This\napproach reduces the number of CNOT gates by two orders of magnitude for\nsystems $N\\geq12$ compared to traditional methods like first-order\nTrotterization. We demonstrate the effectiveness of the RL framework in both\nnoiseless and noisy quantum hardware environments, maintaining high accuracy in\nthermal state preparation. This work advances a scalable, RL-based framework\nwith applications for quantum gravity studies and out-of-time-ordered thermal\ncorrelators computation in quantum many-body systems on near-term quantum\nhardware. The code is available at\nhttps://github.com/Aqasch/solving_SYK_model_with_RL.", "AI": {"tldr": "The paper introduces a reinforcement learning (RL) framework combined with convolutional neural networks to optimize quantum circuits for preparing thermal states of the SYK model, reducing CNOT gate usage significantly.", "motivation": "The challenge of preparing thermal states for large SYK systems on near-term quantum hardware due to high circuit complexity motivates this work.", "method": "The method integrates RL with convolutional neural networks, using a composite reward signal (entropy and Hamiltonian expectation values) to iteratively optimize quantum circuits.", "result": "The approach reduces CNOT gates by two orders of magnitude for N\u226512 systems compared to traditional methods, maintaining accuracy in noisy and noiseless environments.", "conclusion": "This scalable RL framework advances quantum gravity studies and thermal correlator computations on near-term quantum hardware."}}
{"id": "2410.13448", "pdf": "https://arxiv.org/pdf/2410.13448", "abs": "https://arxiv.org/abs/2410.13448", "authors": ["Jinyang Liu", "Tessa Steensgaard", "Marvin N. Wright", "Niklas Pfister", "Munir Hiabu"], "title": "Fast Estimation of Partial Dependence Functions using Trees", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "Many existing interpretation methods are based on Partial Dependence (PD)\nfunctions that, for a pre-trained machine learning model, capture how a subset\nof the features affects the predictions by averaging over the remaining\nfeatures.\n  Notable methods include Shapley additive explanations (SHAP) which computes\nfeature contributions based on a game theoretical interpretation and PD plots\n(i.e., 1-dim PD functions) that capture average marginal main effects. Recent\nwork has connected these approaches using a functional decomposition and argues\nthat SHAP values can be misleading since they merge main and interaction\neffects into a single local effect. However, a major advantage of SHAP compared\nto other PD-based interpretations has been the availability of fast estimation\ntechniques, such as \\texttt{TreeSHAP}.\n  In this paper, we propose a new tree-based estimator, \\texttt{FastPD}, which\nefficiently estimates arbitrary PD functions.\n  We show that \\texttt{FastPD} consistently estimates the desired population\nquantity -- in contrast to path-dependent \\texttt{TreeSHAP} which is\ninconsistent when features are correlated.\n  For moderately deep trees, \\texttt{FastPD} improves the complexity of\nexisting methods from quadratic to linear in the number of observations.\n  By estimating PD functions for arbitrary feature subsets, \\texttt{FastPD} can\nbe used to extract PD-based interpretations such as SHAP, PD plots and\nhigher-order interaction effects.", "AI": {"tldr": "The paper introduces FastPD, a tree-based estimator for efficiently estimating Partial Dependence (PD) functions, addressing inconsistencies in TreeSHAP and improving computational complexity.", "motivation": "Existing methods like SHAP and PD plots have limitations, such as merging main and interaction effects (SHAP) or inconsistency with correlated features (TreeSHAP). FastPD aims to provide consistent and efficient PD function estimation.", "method": "The paper proposes FastPD, a new tree-based estimator for arbitrary PD functions, improving computational efficiency from quadratic to linear complexity for moderately deep trees.", "result": "FastPD consistently estimates population quantities, unlike TreeSHAP, and efficiently computes PD-based interpretations like SHAP, PD plots, and interaction effects.", "conclusion": "FastPD offers a reliable and efficient alternative to existing PD-based interpretation methods, addressing their limitations and expanding interpretability capabilities."}}
{"id": "2503.23899", "pdf": "https://arxiv.org/pdf/2503.23899", "abs": "https://arxiv.org/abs/2503.23899", "authors": ["Diana Galvan-Sosa", "Gabrielle Gaudeau", "Pride Kavumba", "Yunmeng Li", "Hongyi gu", "Zheng Yuan", "Keisuke Sakaguchi", "Paula Buttery"], "title": "Rubrik's Cube: Testing a New Rubric for Evaluating Explanations on the CUBE dataset", "categories": ["cs.CL", "I.2.7"], "comment": "10 main pages (24 appendix pages), 9 figures, accepted to ACL 2025", "summary": "The performance and usability of Large-Language Models (LLMs) are driving\ntheir use in explanation generation tasks. However, despite their widespread\nadoption, LLM explanations have been found to be unreliable, making it\ndifficult for users to distinguish good from bad explanations. To address this\nissue, we present Rubrik's CUBE, an education-inspired rubric and a dataset of\n26k explanations, written and later quality-annotated using the rubric by both\nhumans and six open- and closed-source LLMs. The CUBE dataset focuses on two\nreasoning and two language tasks, providing the necessary diversity for us to\neffectively test our proposed rubric. Using Rubrik, we find that explanations\nare influenced by both task and perceived difficulty. Low quality stems\nprimarily from a lack of conciseness in LLM-generated explanations, rather than\ncohesion and word choice. The full dataset, rubric, and code are available at\nhttps://github.com/RubriksCube/rubriks_cube.", "AI": {"tldr": "Rubrik's CUBE introduces a rubric and dataset to evaluate LLM-generated explanations, revealing issues like lack of conciseness.", "motivation": "Address the unreliability of LLM explanations by providing a structured evaluation method.", "method": "Developed a rubric (CUBE) and collected 26k explanations annotated by humans and LLMs for quality.", "result": "Found explanations vary by task and difficulty, with conciseness being a key issue.", "conclusion": "CUBE offers a tool to assess and improve LLM explanations, with data and rubric publicly available."}}
{"id": "2503.10691", "pdf": "https://arxiv.org/pdf/2503.10691", "abs": "https://arxiv.org/abs/2503.10691", "authors": ["Qiji Zhou", "Yifan Gong", "Guangsheng Bao", "Hongjie Qiu", "Jinqiang Li", "Xiangrong Zhu", "Huajian Zhang", "Yue Zhang"], "title": "Reasoning is All You Need for Video Generalization: A Counterfactual Benchmark with Sub-question Evaluation", "categories": ["cs.CV"], "comment": "It has been accepted to the ACL-2025 Findings", "summary": "Counterfactual reasoning is crucial for robust video understanding but\nremains underexplored in existing multimodal benchmarks. In this paper, we\nintroduce \\textbf{COVER} (\\textbf{\\underline{CO}}unterfactual\n\\textbf{\\underline{V}}id\\textbf{\\underline{E}}o\n\\textbf{\\underline{R}}easoning), a multidimensional multimodal benchmark that\nsystematically evaluates MLLMs across the abstract-concrete and\nperception-cognition dimensions. Beyond prior multimodal benchmarks, COVER\ndecomposes complex queries into structured sub-questions, enabling fine-grained\nreasoning analysis. Experiments on commercial and open-source models reveal a\nstrong correlation between sub-question accuracy and counterfactual reasoning\nperformance, highlighting the role of structured inference in video\nunderstanding. Furthermore, our results suggest a key insight: enhancing the\nreasoning capability of models is essential for improving the robustness of\nvideo understanding. COVER establishes a new standard for assessing MLLMs'\nlogical reasoning abilities in dynamic environments. Our work is available at\nhttps://github.com/gongyifan-hash/COVER-Benchmark.", "AI": {"tldr": "COVER is a new benchmark for evaluating multimodal models' counterfactual reasoning in video understanding, focusing on structured sub-questions and revealing the importance of reasoning capabilities.", "motivation": "Existing multimodal benchmarks lack systematic evaluation of counterfactual reasoning in video understanding, which is crucial for robustness.", "method": "COVER decomposes complex queries into structured sub-questions to enable fine-grained reasoning analysis.", "result": "Experiments show a strong correlation between sub-question accuracy and counterfactual reasoning performance, emphasizing structured inference's role.", "conclusion": "Enhancing reasoning capabilities is key to robust video understanding, and COVER sets a new standard for evaluating MLLMs in dynamic environments."}}
{"id": "2501.14755", "pdf": "https://arxiv.org/pdf/2501.14755", "abs": "https://arxiv.org/abs/2501.14755", "authors": ["Daoyuan Chen", "Yilun Huang", "Xuchen Pan", "Nana Jiang", "Haibin Wang", "Yilei Zhang", "Ce Ge", "Yushuo Chen", "Wenhao Zhang", "Zhijian Ma", "Jun Huang", "Wei Lin", "Yaliang Li", "Bolin Ding", "Jingren Zhou"], "title": "Data-Juicer 2.0: Cloud-Scale Adaptive Data Processing for and with Foundation Models", "categories": ["cs.DC", "cs.AI"], "comment": "34 pages, 10 figures, 3 tables", "summary": "The burgeoning field of foundation models necessitates advanced data\nprocessing mechanisms capable of harnessing vast and valuable data with various\ntypes used by these models. Nevertheless, the current landscape presents unique\nchallenges that traditional data processing frameworks struggle to handle\neffectively, particularly in handling the complexity of multimodal data. In\nresponse, we present Data-Juicer 2.0, a data processing system backed by 100+\ndata processing operators spanning text, image, video, and audio modalities,\nsupporting more critical tasks including data analysis, synthesis, annotation,\nand foundation model post-training. With seamless compatibility and dedicated\noptimization for popular dataset hubs like Hugging Face and computing engines\nlike Ray, it improves upon its predecessor in terms of usability, efficiency,\nand programmability. It features an easily accessible user interface layer that\nsupports decoupled Python interactions, RESTful APIs, and conversational\ncommands. It contains a new runtime layer optimized for adaptive execution and\nmanagement across varying dataset scales, processing demands, and computational\nenvironments, while hiding unnecessary system details. Extensive empirical\nevaluations demonstrate Data-Juicer 2.0's remarkable performance and\nscalability, highlighting its capability to efficiently process TB-level data\nwith 10k+ CPU cores. The system is publicly available and has been widely\nadopted in diverse research fields and real-world products such as Alibaba\nCloud PAI. We actively maintain it and share insights from practical feedback,\nwith the goal of facilitating research and application of next-generation\nfoundation models.", "AI": {"tldr": "Data-Juicer 2.0 is an advanced data processing system for multimodal data, offering 100+ operators, improved usability, and scalability for TB-level data.", "motivation": "Traditional frameworks struggle with multimodal data complexity, necessitating a more efficient and scalable solution.", "method": "Introduces Data-Juicer 2.0 with 100+ operators, optimized runtime, and compatibility with popular tools like Hugging Face and Ray.", "result": "Demonstrates remarkable performance, handling TB-level data with 10k+ CPU cores, and is widely adopted in research and industry.", "conclusion": "Data-Juicer 2.0 facilitates next-gen foundation model research and applications, with ongoing maintenance and feedback integration."}}
{"id": "2411.05239", "pdf": "https://arxiv.org/pdf/2411.05239", "abs": "https://arxiv.org/abs/2411.05239", "authors": ["Moshik Hershcovitch", "Andrew Wood", "Leshem Choshen", "Guy Girmonsky", "Roy Leibovitz", "Ilias Ennmouri", "Michal Malka", "Peter Chin", "Swaminathan Sundararaman", "Danny Harnik"], "title": "ZipNN: Lossless Compression for AI Models", "categories": ["cs.LG", "cs.IT", "math.IT"], "comment": "IEEE Cloud. arXiv admin note: text overlap with arXiv:2404.15198", "summary": "With the growth of model sizes and the scale of their deployment, their sheer\nsize burdens the infrastructure requiring more network and more storage to\naccommodate these. While there is a vast model compression literature deleting\nparts of the model weights for faster inference, we investigate a more\ntraditional type of compression - one that represents the model in a compact\nform and is coupled with a decompression algorithm that returns it to its\noriginal form and size - namely lossless compression.\n  We present ZipNN a lossless compression tailored to neural networks. Somewhat\nsurprisingly, we show that specific lossless compression can gain significant\nnetwork and storage reduction on popular models, often saving 33% and at times\nreducing over 50% of the model size. We investigate the source of model\ncompressibility and introduce specialized compression variants tailored for\nmodels that further increase the effectiveness of compression. On popular\nmodels (e.g. Llama 3) ZipNN shows space savings that are over 17% better than\nvanilla compression while also improving compression and decompression speeds\nby 62%. We estimate that these methods could save over an ExaByte per month of\nnetwork traffic downloaded from a large model hub like Hugging Face.", "AI": {"tldr": "ZipNN is a lossless compression method for neural networks, achieving significant size reductions (33-50%) and faster speeds compared to vanilla compression, potentially saving substantial network traffic.", "motivation": "Addressing the infrastructure burden of large model sizes by exploring lossless compression as an alternative to traditional model pruning.", "method": "Developed ZipNN, a specialized lossless compression technique tailored for neural networks, with variants to enhance effectiveness.", "result": "Achieved 33-50% model size reduction, 17% better than vanilla compression, and 62% faster compression/decompression speeds.", "conclusion": "ZipNN offers efficient lossless compression for neural networks, promising significant infrastructure savings."}}
{"id": "2504.00030", "pdf": "https://arxiv.org/pdf/2504.00030", "abs": "https://arxiv.org/abs/2504.00030", "authors": ["Aayush Gautam", "Susav Shrestha", "Narasimha Reddy"], "title": "Token-Driven GammaTune: Adaptive Calibration for Enhanced Speculative Decoding", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "6 pages, 2 figures, 1 table", "summary": "Speculative decoding accelerates large language model (LLM) inference by\nusing a smaller draft model to propose tokens, which are then verified by a\nlarger target model. However, selecting an optimal speculation length is\ncritical for maximizing speedup while minimizing wasted computation. We\nintroduce \\textit{GammaTune} and \\textit{GammaTune+}, training-free adaptive\nalgorithms that dynamically adjust speculation length based on token acceptance\nrates using a heuristic-based switching mechanism. Evaluated on SpecBench\nacross multiple tasks and model pairs, our method outperforms other\nheuristic-based approaches and fixed-length speculative decoding, achieving an\naverage speedup of 15\\% ($\\pm$5\\%) with \\textit{GammaTune} and 16\\% ($\\pm$3\\%)\nwith \\textit{GammaTune+}, while reducing performance variance. This makes\n\\textit{GammaTune} a robust and efficient solution for real-world deployment.", "AI": {"tldr": "GammaTune and GammaTune+ are adaptive algorithms for speculative decoding in LLMs, dynamically adjusting speculation length to improve speedup and reduce wasted computation.", "motivation": "Optimizing speculation length in speculative decoding is crucial for maximizing speedup and minimizing wasted computation in LLM inference.", "method": "Introduces GammaTune and GammaTune+, training-free adaptive algorithms that adjust speculation length based on token acceptance rates using a heuristic-based switching mechanism.", "result": "Outperforms other approaches, achieving average speedups of 15% (GammaTune) and 16% (GammaTune+) with reduced performance variance.", "conclusion": "GammaTune is a robust and efficient solution for real-world deployment in LLM inference."}}
{"id": "2503.18223", "pdf": "https://arxiv.org/pdf/2503.18223", "abs": "https://arxiv.org/abs/2503.18223", "authors": ["Valentin Gabeff", "Haozhe Qi", "Brendan Flaherty", "Gencer Sumb\u00fcl", "Alexander Mathis", "Devis Tuia"], "title": "MammAlps: A multi-view video behavior monitoring dataset of wild mammals in the Swiss Alps", "categories": ["cs.CV", "cs.IR", "q-bio.NC", "q-bio.QM"], "comment": "CVPR 2025; Benchmark and code at:\n  https://github.com/eceo-epfl/MammAlps. After submission of v1, we noticed\n  that a few audio files were not correctly aligned with the corresponding\n  video. We fixed the issue, which had little to no impact on performance. We\n  also now report results for three runs", "summary": "Monitoring wildlife is essential for ecology and ethology, especially in\nlight of the increasing human impact on ecosystems. Camera traps have emerged\nas habitat-centric sensors enabling the study of wildlife populations at scale\nwith minimal disturbance. However, the lack of annotated video datasets limits\nthe development of powerful video understanding models needed to process the\nvast amount of fieldwork data collected. To advance research in wild animal\nbehavior monitoring we present MammAlps, a multimodal and multi-view dataset of\nwildlife behavior monitoring from 9 camera-traps in the Swiss National Park.\nMammAlps contains over 14 hours of video with audio, 2D segmentation maps and\n8.5 hours of individual tracks densely labeled for species and behavior. Based\non 6135 single animal clips, we propose the first hierarchical and multimodal\nanimal behavior recognition benchmark using audio, video and reference scene\nsegmentation maps as inputs. Furthermore, we also propose a second\necology-oriented benchmark aiming at identifying activities, species, number of\nindividuals and meteorological conditions from 397 multi-view and long-term\necological events, including false positive triggers. We advocate that both\ntasks are complementary and contribute to bridging the gap between machine\nlearning and ecology. Code and data are available at:\nhttps://github.com/eceo-epfl/MammAlps", "AI": {"tldr": "MammAlps is a multimodal dataset for wildlife behavior monitoring, offering annotated video, audio, and segmentation maps to advance machine learning in ecology.", "motivation": "The lack of annotated wildlife video datasets hinders the development of models for processing fieldwork data. MammAlps addresses this gap.", "method": "The dataset includes 14 hours of video with audio, 2D segmentation maps, and 8.5 hours of labeled tracks. It proposes two benchmarks: hierarchical behavior recognition and ecology-oriented event identification.", "result": "MammAlps provides 6135 single animal clips and 397 multi-view ecological events, enabling complementary tasks for machine learning and ecology.", "conclusion": "MammAlps bridges the gap between machine learning and ecology by offering rich, annotated data for wildlife behavior monitoring."}}
{"id": "2502.13135", "pdf": "https://arxiv.org/pdf/2502.13135", "abs": "https://arxiv.org/abs/2502.13135", "authors": ["Taedong Yun", "Eric Yang", "Mustafa Safdari", "Jong Ha Lee", "Vaishnavi Vinod Kumar", "S. Sara Mahdavi", "Jonathan Amar", "Derek Peyton", "Reut Aharony", "Andreas Michaelides", "Logan Schneider", "Isaac Galatzer-Levy", "Yugang Jia", "John Canny", "Arthur Gretton", "Maja Matari\u0107"], "title": "Sleepless Nights, Sugary Days: Creating Synthetic Users with Health Conditions for Realistic Coaching Agent Interactions", "categories": ["cs.LG", "cs.AI", "cs.CL", "I.2.7"], "comment": "Accepted to the 63rd Annual Meeting of the Association for\n  Computational Linguistics (ACL 2025)", "summary": "We present an end-to-end framework for generating synthetic users for\nevaluating interactive agents designed to encourage positive behavior changes,\nsuch as in health and lifestyle coaching. The synthetic users are grounded in\nhealth and lifestyle conditions, specifically sleep and diabetes management in\nthis study, to ensure realistic interactions with the health coaching agent.\nSynthetic users are created in two stages: first, structured data are generated\ngrounded in real-world health and lifestyle factors in addition to basic\ndemographics and behavioral attributes; second, full profiles of the synthetic\nusers are developed conditioned on the structured data. Interactions between\nsynthetic users and the coaching agent are simulated using generative\nagent-based models such as Concordia, or directly by prompting a language\nmodel. Using two independently-developed agents for sleep and diabetes coaching\nas case studies, the validity of this framework is demonstrated by analyzing\nthe coaching agent's understanding of the synthetic users' needs and\nchallenges. Finally, through multiple blinded evaluations of user-coach\ninteractions by human experts, we demonstrate that our synthetic users with\nhealth and behavioral attributes more accurately portray real human users with\nthe same attributes, compared to generic synthetic users not grounded in such\nattributes. The proposed framework lays the foundation for efficient\ndevelopment of conversational agents through extensive, realistic, and grounded\nsimulated interactions.", "AI": {"tldr": "An end-to-end framework for generating synthetic users to evaluate interactive health coaching agents, grounded in real-world health conditions like sleep and diabetes management.", "motivation": "To create realistic synthetic users for evaluating interactive agents that encourage positive behavior changes in health and lifestyle coaching.", "method": "Two-stage synthetic user creation: structured data generation based on health factors, followed by profile development. Interactions simulated using generative models or language models.", "result": "Validated framework shows synthetic users accurately portray real human users, outperforming generic synthetic users in realism.", "conclusion": "The framework enables efficient development of conversational agents through realistic simulated interactions."}}
{"id": "2411.17089", "pdf": "https://arxiv.org/pdf/2411.17089", "abs": "https://arxiv.org/abs/2411.17089", "authors": ["Chaoyi Jiang", "Lei Gao", "Hossein Entezari Zarch", "Murali Annavaram"], "title": "KVPR: Efficient LLM Inference with I/O-Aware KV Cache Partial Recomputation", "categories": ["cs.LG", "cs.DC", "cs.PF"], "comment": "ACL Findings 2025", "summary": "Inference for Large Language Models (LLMs) is computationally demanding. To\nreduce the cost of auto-regressive decoding, Key-Value (KV) cache is used to\nstore intermediate activations, which significantly lowers the computational\noverhead for token generation. However, the memory required for the KV cache\ngrows rapidly, often exceeding the capacity of GPU memory. A cost-effective\nalternative is to offload KV cache to CPU memory, which alleviates GPU memory\npressure, but shifts the bottleneck to the limited bandwidth of the PCIe\nconnection between the CPU and GPU. Existing methods attempt to address these\nissues by overlapping GPU computation with I/O or employing CPU-GPU\nheterogeneous execution, but they are hindered by excessive data movement and\ndependence on CPU capabilities. Fully overlapping PCIe communication latency\ngets challenging as the size of the KV cache grows and/or the GPU compute\ncapabilities increase. In this paper, we introduce KVPR, an efficient I/O-aware\nLLM inference method where the CPU first transfers a partial set of\nactivations, from which the GPU can start recomputing the KV cache values.\nWhile the GPU recomputes the partial KV cache, the remaining portion of the KV\ncache is transferred concurrently from the CPU. This approach overlaps GPU\nrecomputation with KV cache transfer to minimize idle GPU time and maximize\ninference performance. KVPR is fully automated by integrating a profiler module\nthat utilizes input characteristics and system hardware information, a\nscheduler module to optimize the distribution of computation and communication\nworkloads, and a runtime module to efficiently execute the derived execution\nplan. Experimental results show that KVPR achieves up to 35.8% lower latency\nand 46.2% higher throughput during decoding compared to state-of-the-art\napproaches. The code is available at https://github.com/chaoyij/KVPR.", "AI": {"tldr": "KVPR is an efficient I/O-aware method for LLM inference that overlaps GPU recomputation with KV cache transfer to reduce latency and improve throughput.", "motivation": "The memory demands of KV cache in LLMs exceed GPU capacity, and offloading to CPU introduces PCIe bandwidth bottlenecks. Existing methods struggle with data movement and CPU dependency.", "method": "KVPR transfers partial KV cache activations to the GPU for recomputation while concurrently transferring the remaining cache, overlapping GPU work with I/O. It includes a profiler, scheduler, and runtime for automation.", "result": "KVPR reduces latency by up to 35.8% and increases throughput by 46.2% compared to state-of-the-art methods.", "conclusion": "KVPR effectively addresses GPU memory and PCIe bandwidth limitations, enhancing LLM inference performance."}}
{"id": "2504.05154", "pdf": "https://arxiv.org/pdf/2504.05154", "abs": "https://arxiv.org/abs/2504.05154", "authors": ["Geyang Guo", "Tarek Naous", "Hiromi Wakaki", "Yukiko Nishimura", "Yuki Mitsufuji", "Alan Ritter", "Wei Xu"], "title": "CARE: Assessing the Impact of Multilingual Human Preference Learning on Cultural Awareness", "categories": ["cs.CL"], "comment": "27 pages", "summary": "Language Models (LMs) are typically tuned with human preferences to produce\nhelpful responses, but the impact of preference tuning on the ability to handle\nculturally diverse queries remains understudied. In this paper, we\nsystematically analyze how native human cultural preferences can be\nincorporated into the preference learning process to train more culturally\naware LMs. We introduce \\textbf{CARE}, a multilingual resource containing 3,490\nculturally specific questions and 31.7k responses with native judgments. We\ndemonstrate how a modest amount of high-quality native preferences improves\ncultural awareness across various LMs, outperforming larger generic preference\ndata. Our analyses reveal that models with stronger initial cultural\nperformance benefit more from alignment, leading to gaps among models developed\nin different regions with varying access to culturally relevant data. CARE will\nbe made publicly available at https://github.com/Guochry/CARE.", "AI": {"tldr": "The paper introduces CARE, a multilingual resource for training culturally aware language models (LMs) using native human preferences, showing that high-quality native preferences outperform larger generic data.", "motivation": "To address the understudied impact of preference tuning on LMs' ability to handle culturally diverse queries and improve cultural awareness.", "method": "Introduces CARE, a dataset with 3,490 culturally specific questions and 31.7k responses with native judgments, used to train LMs.", "result": "High-quality native preferences enhance cultural awareness in LMs, with stronger initial cultural models benefiting more.", "conclusion": "CARE improves LM cultural awareness, highlighting gaps in models from regions with varying access to culturally relevant data."}}
{"id": "2504.00816", "pdf": "https://arxiv.org/pdf/2504.00816", "abs": "https://arxiv.org/abs/2504.00816", "authors": ["Yeqi Fang", "Rong Zhou"], "title": "Two-stage deep learning framework for the restoration of incomplete-ring PET images", "categories": ["cs.CV", "physics.med-ph"], "comment": "20 pages, 7 figures", "summary": "Positron Emission Tomography (PET) is an important molecular imaging tool\nwidely used in medicine. Traditional PET systems rely on complete detector\nrings for full angular coverage and reliable data collection. However,\nincomplete-ring PET scanners have emerged due to hardware failures, cost\nconstraints, or specific clinical needs. Standard reconstruction algorithms\noften suffer from performance degradation with these systems because of reduced\ndata completeness and geometric inconsistencies. We present a two-stage\ndeep-learning framework that, without incorporating any time-of-flight (TOF)\ninformation, restores high-quality images from data with about 50% missing\ncoincidences - double the loss levels previously addressed by CNN-based\nmethods. The pipeline operates in two stages: a projection-domain Attention\nU-Net first predicts the missing sections of the sinogram by leveraging spatial\ncontext from neighbouring slices, after which the completed data are\nreconstructed with OSEM algorithm and passed to a U-Net-diffusion module that\nremoves residual artefacts while reinstating high-frequency detail. Using 206\nbrain volumes from a public dataset, the result shows that our model\nsuccessfully preserves most anatomical structures and tracer distribution\nfeatures with PSNR of 30.92 dB and SSIM of 0.9708. We also achieve higher\ninference speed, thus providing an effective solution for incomplete-ring PET\nimaging.", "AI": {"tldr": "A two-stage deep-learning framework improves image quality in incomplete-ring PET scanners without TOF, handling 50% missing data.", "motivation": "Address performance degradation in incomplete-ring PET scanners due to data incompleteness and geometric inconsistencies.", "method": "Two-stage pipeline: projection-domain Attention U-Net predicts missing sinogram sections, followed by OSEM reconstruction and U-Net-diffusion for artefact removal.", "result": "Preserves anatomical structures and tracer distribution with PSNR 30.92 dB and SSIM 0.9708, achieving higher inference speed.", "conclusion": "Provides an effective solution for incomplete-ring PET imaging with improved performance."}}
{"id": "2502.14708", "pdf": "https://arxiv.org/pdf/2502.14708", "abs": "https://arxiv.org/abs/2502.14708", "authors": ["Kevin He", "Ran Shorrer", "Mengjia Xia"], "title": "Human Misperception of Generative-AI Alignment: A Laboratory Experiment", "categories": ["econ.TH", "cs.AI", "cs.GT"], "comment": null, "summary": "We conduct an incentivized laboratory experiment to study people's perception\nof generative artificial intelligence (GenAI) alignment in the context of\neconomic decision-making. Using a panel of economic problems spanning the\ndomains of risk, time preference, social preference, and strategic\ninteractions, we ask human subjects to make choices for themselves and to\npredict the choices made by GenAI on behalf of a human user. We find that\npeople overestimate the degree of alignment between GenAI's choices and human\nchoices. In every problem, human subjects' average prediction about GenAI's\nchoice is substantially closer to the average human-subject choice than it is\nto the GenAI choice. At the individual level, different subjects' predictions\nabout GenAI's choice in a given problem are highly correlated with their own\nchoices in the same problem. We explore the implications of people\noverestimating GenAI alignment in a simple theoretical model.", "AI": {"tldr": "People overestimate the alignment between GenAI and human choices in economic decision-making, with predictions closer to human averages than actual GenAI choices.", "motivation": "To study how people perceive GenAI alignment in economic contexts, spanning risk, time preference, social preference, and strategic interactions.", "method": "Incentivized laboratory experiments where human subjects predict GenAI choices and make their own decisions across economic problems.", "result": "Human predictions of GenAI choices are closer to average human choices than actual GenAI choices, showing overestimation of alignment.", "conclusion": "People's overestimation of GenAI alignment has implications, as explored in a theoretical model."}}
{"id": "2412.07169", "pdf": "https://arxiv.org/pdf/2412.07169", "abs": "https://arxiv.org/abs/2412.07169", "authors": ["Tal Zeevi", "Ravid Shwartz-Ziv", "Yann LeCun", "Lawrence H. Staib", "John A. Onofrey"], "title": "Rate-In: Information-Driven Adaptive Dropout Rates for Improved Inference-Time Uncertainty Estimation", "categories": ["cs.LG", "cs.CV", "stat.ML"], "comment": "Accepted to the IEEE/CVF Conference on Computer Vision and Pattern\n  Recognition (CVPR) 2025. Code available at:\n  https://github.com/code-supplement-25/rate-in", "summary": "Accurate uncertainty estimation is crucial for deploying neural networks in\nrisk-sensitive applications such as medical diagnosis. Monte Carlo Dropout is a\nwidely used technique for approximating predictive uncertainty by performing\nstochastic forward passes with dropout during inference. However, using static\ndropout rates across all layers and inputs can lead to suboptimal uncertainty\nestimates, as it fails to adapt to the varying characteristics of individual\ninputs and network layers. Existing approaches optimize dropout rates during\ntraining using labeled data, resulting in fixed inference-time parameters that\ncannot adjust to new data distributions, compromising uncertainty estimates in\nMonte Carlo simulations.\n  In this paper, we propose Rate-In, an algorithm that dynamically adjusts\ndropout rates during inference by quantifying the information loss induced by\ndropout in each layer's feature maps. By treating dropout as controlled noise\ninjection and leveraging information-theoretic principles, Rate-In adapts\ndropout rates per layer and per input instance without requiring ground truth\nlabels. By quantifying the functional information loss in feature maps, we\nadaptively tune dropout rates to maintain perceptual quality across diverse\nmedical imaging tasks and architectural configurations. Our extensive empirical\nstudy on synthetic data and real-world medical imaging tasks demonstrates that\nRate-In improves calibration and sharpens uncertainty estimates compared to\nfixed or heuristic dropout rates without compromising predictive performance.\nRate-In offers a practical, unsupervised, inference-time approach to optimizing\ndropout for more reliable predictive uncertainty estimation in critical\napplications.", "AI": {"tldr": "Rate-In dynamically adjusts dropout rates during inference using information-theoretic principles, improving uncertainty estimation without labeled data.", "motivation": "Static dropout rates in Monte Carlo Dropout lead to suboptimal uncertainty estimates, especially in risk-sensitive applications like medical diagnosis.", "method": "Rate-In quantifies information loss in feature maps to adaptively tune dropout rates per layer and input, without needing ground truth labels.", "result": "Rate-In enhances calibration and sharpens uncertainty estimates without compromising predictive performance, as shown in synthetic and real-world medical imaging tasks.", "conclusion": "Rate-In provides a practical, unsupervised method for optimizing dropout rates during inference, improving reliability in critical applications."}}
{"id": "2504.05276", "pdf": "https://arxiv.org/pdf/2504.05276", "abs": "https://arxiv.org/abs/2504.05276", "authors": ["Yucheng Chu", "Peng He", "Hang Li", "Haoyu Han", "Kaiqi Yang", "Yu Xue", "Tingting Li", "Joseph Krajcik", "Jiliang Tang"], "title": "Enhancing LLM-Based Short Answer Grading with Retrieval-Augmented Generation", "categories": ["cs.CL"], "comment": "EDM 2025 Short Paper", "summary": "Short answer assessment is a vital component of science education, allowing\nevaluation of students' complex three-dimensional understanding. Large language\nmodels (LLMs) that possess human-like ability in linguistic tasks are\nincreasingly popular in assisting human graders to reduce their workload.\nHowever, LLMs' limitations in domain knowledge restrict their understanding in\ntask-specific requirements and hinder their ability to achieve satisfactory\nperformance. Retrieval-augmented generation (RAG) emerges as a promising\nsolution by enabling LLMs to access relevant domain-specific knowledge during\nassessment. In this work, we propose an adaptive RAG framework for automated\ngrading that dynamically retrieves and incorporates domain-specific knowledge\nbased on the question and student answer context. Our approach combines\nsemantic search and curated educational sources to retrieve valuable reference\nmaterials. Experimental results in a science education dataset demonstrate that\nour system achieves an improvement in grading accuracy compared to baseline LLM\napproaches. The findings suggest that RAG-enhanced grading systems can serve as\nreliable support with efficient performance gains.", "AI": {"tldr": "An adaptive RAG framework improves grading accuracy in science education by dynamically retrieving domain-specific knowledge for LLMs.", "motivation": "To enhance LLMs' grading performance by addressing their limitations in domain knowledge through retrieval-augmented generation.", "method": "Proposes an adaptive RAG framework combining semantic search and curated educational sources for dynamic knowledge retrieval.", "result": "Experimental results show improved grading accuracy over baseline LLM approaches.", "conclusion": "RAG-enhanced grading systems offer reliable and efficient support for automated assessment."}}
{"id": "2504.16656", "pdf": "https://arxiv.org/pdf/2504.16656", "abs": "https://arxiv.org/abs/2504.16656", "authors": ["Chris", "Yichen Wei", "Yi Peng", "Xiaokun Wang", "Weijie Qiu", "Wei Shen", "Tianyidan Xie", "Jiangbo Pei", "Jianhao Zhang", "Yunzhuo Hao", "Xuchen Song", "Yang Liu", "Yahui Zhou"], "title": "Skywork R1V2: Multimodal Hybrid Reinforcement Learning for Reasoning", "categories": ["cs.CV"], "comment": null, "summary": "We present Skywork R1V2, a next-generation multimodal reasoning model and a\nmajor leap forward from its predecessor, Skywork R1V. At its core, R1V2\nintroduces a hybrid reinforcement learning paradigm that jointly leverages the\nMixed Preference Optimization (MPO) and the Group Relative Policy Optimization\n(GRPO), which harmonizes reward-model guidance with rule-based strategies,\nthereby addressing the long-standing challenge of balancing sophisticated\nreasoning capabilities with broad generalization. To further enhance training\nefficiency, we propose the Selective Sample Buffer (SSB) mechanism, which\neffectively addresses the vanishing advantages dilemma inherent in GRPO by\nprioritizing high-value samples throughout the optimization process. Notably,\nwe observe that excessive reinforcement signals can induce visual\nhallucinations--a phenomenon we systematically monitor and mitigate through\ncalibrated reward thresholds throughout the training process. Empirical results\naffirm the exceptional capability of R1V2, with benchmark-leading performances\nsuch as 62.6 on OlympiadBench, 78.9 on AIME2024, 63.6 on LiveCodeBench, and\n73.6 on MMMU. These results underscore R1V2's superiority over existing\nopen-source models and demonstrate significant progress in closing the\nperformance gap with premier proprietary systems, including Gemini 2.5 and\nOpenAI-o4-mini. The Skywork R1V2 model weights have been publicly released to\npromote openness and reproducibility\nhttps://huggingface.co/Skywork/Skywork-R1V2-38B.", "AI": {"tldr": "Skywork R1V2 is a multimodal reasoning model with hybrid reinforcement learning, combining MPO and GRPO, and introduces SSB for training efficiency. It achieves top benchmark results and addresses challenges like visual hallucinations.", "motivation": "To balance sophisticated reasoning with broad generalization and improve training efficiency in multimodal models.", "method": "Uses hybrid reinforcement learning (MPO + GRPO) and SSB for sample prioritization, with calibrated reward thresholds to mitigate visual hallucinations.", "result": "Achieves leading benchmarks: 62.6 (OlympiadBench), 78.9 (AIME2024), 63.6 (LiveCodeBench), 73.6 (MMMU). Outperforms open-source models and narrows the gap with proprietary systems.", "conclusion": "Skywork R1V2 advances multimodal reasoning, offering superior performance and public release for openness."}}
{"id": "2502.15805", "pdf": "https://arxiv.org/pdf/2502.15805", "abs": "https://arxiv.org/abs/2502.15805", "authors": ["Joongwon Lee", "Seonghwan Kim", "Seokhyun Moon", "Hyunwoo Kim", "Woo Youn Kim"], "title": "FragFM: Hierarchical Framework for Efficient Molecule Generation via Fragment-Level Discrete Flow Matching", "categories": ["cs.LG", "cs.AI", "physics.chem-ph"], "comment": "39 pages, 24 figures, under review", "summary": "We introduce FragFM, a novel hierarchical framework via fragment-level\ndiscrete flow matching for efficient molecular graph generation. FragFM\ngenerates molecules at the fragment level, leveraging a coarse-to-fine\nautoencoder to reconstruct details at the atom level. Together with a\nstochastic fragment bag strategy to effectively handle an extensive fragment\nspace, our framework enables more efficient and scalable molecular generation.\nWe demonstrate that our fragment-based approach achieves better property\ncontrol than the atom-based method and additional flexibility through\nconditioning the fragment bag. We also propose a Natural Product Generation\nbenchmark (NPGen) to evaluate modern molecular graph generative models' ability\nto generate natural product-like molecules. Since natural products are\nbiologically prevalidated and differ from typical drug-like molecules, our\nbenchmark provides a more challenging yet meaningful evaluation relevant to\ndrug discovery. We conduct a FragFM comparative study against various models on\ndiverse molecular generation benchmarks, including NPGen, demonstrating\nsuperior performance. The results highlight the potential of fragment-based\ngenerative modeling for large-scale, property-aware molecular design, paving\nthe way for more efficient exploration of chemical space.", "AI": {"tldr": "FragFM is a hierarchical framework for molecular graph generation using fragment-level discrete flow matching, achieving efficient and scalable generation with better property control.", "motivation": "To improve molecular generation efficiency and property control by leveraging fragment-level modeling and addressing challenges in fragment space handling.", "method": "Uses a coarse-to-fine autoencoder for atom-level reconstruction and a stochastic fragment bag strategy for fragment space management.", "result": "Outperforms atom-based methods in property control and flexibility, validated on the NPGen benchmark for natural product-like molecules.", "conclusion": "FragFM demonstrates the potential of fragment-based generative modeling for scalable, property-aware molecular design, advancing chemical space exploration."}}
{"id": "2412.07326", "pdf": "https://arxiv.org/pdf/2412.07326", "abs": "https://arxiv.org/abs/2412.07326", "authors": ["Yael Itzhakev", "Amit Giloni", "Yuval Elovici", "Asaf Shabtai"], "title": "Addressing Key Challenges of Adversarial Attacks and Defenses in the Tabular Domain: A Methodological Framework for Coherence and Consistency", "categories": ["cs.LG"], "comment": null, "summary": "Machine learning models trained on tabular data are vulnerable to adversarial\nattacks, even in realistic scenarios where attackers only have access to the\nmodel's outputs. Since tabular data contains complex interdependencies among\nfeatures, it presents a unique challenge for adversarial samples which must\nmaintain coherence and respect these interdependencies to remain\nindistinguishable from benign data. Moreover, existing attack evaluation\nmetrics-such as the success rate, perturbation magnitude, and query count-fail\nto account for this challenge. To address those gaps, we propose a technique\nfor perturbing dependent features while preserving sample coherence. In\naddition, we introduce Class-Specific Anomaly Detection (CSAD), an effective\nnovel anomaly detection approach, along with concrete metrics for assessing the\nquality of tabular adversarial attacks. CSAD evaluates adversarial samples\nrelative to their predicted class distribution, rather than a broad benign\ndistribution. It ensures that subtle adversarial perturbations, which may\nappear coherent in other classes, are correctly identified as anomalies. We\nintegrate SHAP explainability techniques to detect inconsistencies in model\ndecision-making, extending CSAD for SHAP-based anomaly detection. Our\nevaluation incorporates both anomaly detection rates with SHAP-based\nassessments to provide a more comprehensive measure of adversarial sample\nquality. We evaluate various attack strategies, examining black-box query-based\nand transferability-based gradient attacks across four target models.\nExperiments on benchmark tabular datasets reveal key differences in the\nattacker's risk and effort and attack quality, offering insights into the\nstrengths, limitations, and trade-offs faced by attackers and defenders. Our\nfindings lay the groundwork for future research on adversarial attacks and\ndefense development in the tabular domain.", "AI": {"tldr": "The paper addresses adversarial attacks on tabular data, proposing a method to perturb dependent features coherently and introducing Class-Specific Anomaly Detection (CSAD) for better evaluation.", "motivation": "Existing adversarial attack metrics fail to account for the complex interdependencies in tabular data, necessitating improved techniques and evaluation methods.", "method": "Proposes perturbing dependent features while preserving coherence and introduces CSAD for anomaly detection, integrating SHAP for explainability.", "result": "Evaluates attacks on benchmark datasets, revealing differences in risk, effort, and quality, providing insights for attackers and defenders.", "conclusion": "The work advances adversarial attack and defense research in the tabular domain, highlighting trade-offs and future directions."}}
{"id": "2504.06910", "pdf": "https://arxiv.org/pdf/2504.06910", "abs": "https://arxiv.org/abs/2504.06910", "authors": ["Sheng Lu", "Ilia Kuznetsov", "Iryna Gurevych"], "title": "Identifying Aspects in Peer Reviews", "categories": ["cs.CL"], "comment": null, "summary": "Peer review is central to academic publishing, but the growing volume of\nsubmissions is straining the process. This motivates the development of\ncomputational approaches to support peer review. While each review is tailored\nto a specific paper, reviewers often make assessments according to certain\naspects such as Novelty, which reflect the values of the research community.\nThis alignment creates opportunities for standardizing the reviewing process,\nimproving quality control, and enabling computational support. While prior work\nhas demonstrated the potential of aspect analysis for peer review assistance,\nthe notion of aspect remains poorly formalized. Existing approaches often\nderive aspects from review forms and guidelines, yet data-driven methods for\naspect identification are underexplored. To address this gap, our work takes a\nbottom-up approach: we propose an operational definition of aspect and develop\na data-driven schema for deriving aspects from a corpus of peer reviews. We\nintroduce a dataset of peer reviews augmented with aspects and show how it can\nbe used for community-level review analysis. We further show how the choice of\naspects can impact downstream applications, such as LLM-generated review\ndetection. Our results lay a foundation for a principled and data-driven\ninvestigation of review aspects, and pave the path for new applications of NLP\nto support peer review.", "AI": {"tldr": "The paper addresses the challenge of standardizing peer review by proposing a data-driven approach to define and derive aspects from reviews, enabling computational support and improved quality control.", "motivation": "The growing volume of submissions strains peer review, necessitating computational support. Current approaches lack formalization of review aspects, motivating a data-driven solution.", "method": "The authors propose an operational definition of aspects and develop a data-driven schema to derive them from peer reviews. They introduce a dataset for analysis and demonstrate its utility in applications like LLM-generated review detection.", "result": "The work provides a foundation for principled investigation of review aspects and showcases their impact on downstream tasks, such as detecting AI-generated reviews.", "conclusion": "The study advances the standardization of peer review through data-driven aspect analysis, paving the way for NLP applications to support the process."}}
{"id": "2504.19223", "pdf": "https://arxiv.org/pdf/2504.19223", "abs": "https://arxiv.org/abs/2504.19223", "authors": ["Alexander Baumann", "Leonardo Ayala", "Silvia Seidlitz", "Jan Sellner", "Alexander Studier-Fischer", "Berkin \u00d6zdemir", "Lena Maier-Hein", "Slobodan Ilic"], "title": "CARL: Camera-Agnostic Representation Learning for Spectral Image Analysis", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": null, "summary": "Spectral imaging offers promising applications across diverse domains,\nincluding medicine and urban scene understanding, and is already established as\na critical modality in remote sensing. However, variability in channel\ndimensionality and captured wavelengths among spectral cameras impede the\ndevelopment of AI-driven methodologies, leading to camera-specific models with\nlimited generalizability and inadequate cross-camera applicability. To address\nthis bottleneck, we introduce $\\textbf{CARL}$, a model for\n$\\textbf{C}$amera-$\\textbf{A}$gnostic $\\textbf{R}$epresentation\n$\\textbf{L}$earning across RGB, multispectral, and hyperspectral imaging\nmodalities. To enable the conversion of a spectral image with any channel\ndimensionality to a camera-agnostic embedding, we introduce wavelength\npositional encoding and a self-attention-cross-attention mechanism to compress\nspectral information into learned query representations. Spectral-spatial\npre-training is achieved with a novel spectral self-supervised JEPA-inspired\nstrategy tailored to CARL. Large-scale experiments across the domains of\nmedical imaging, autonomous driving, and satellite imaging demonstrate our\nmodel's unique robustness to spectral heterogeneity, outperforming on datasets\nwith simulated and real-world cross-camera spectral variations. The scalability\nand versatility of the proposed approach position our model as a backbone for\nfuture spectral foundation models.", "AI": {"tldr": "CARL is a camera-agnostic model for spectral imaging that addresses variability in channel dimensionality and wavelengths, using novel encoding and pre-training to improve cross-camera applicability.", "motivation": "Variability in spectral cameras hinders AI-driven methodologies, leading to camera-specific models with limited generalizability.", "method": "Introduces wavelength positional encoding and a self-attention-cross-attention mechanism for spectral image conversion, with spectral-spatial pre-training via a JEPA-inspired strategy.", "result": "Outperforms in robustness to spectral heterogeneity across medical, autonomous driving, and satellite imaging domains.", "conclusion": "CARL's scalability and versatility make it a potential backbone for future spectral foundation models."}}
{"id": "2502.18097", "pdf": "https://arxiv.org/pdf/2502.18097", "abs": "https://arxiv.org/abs/2502.18097", "authors": ["Samuele Sabella", "Chiara Boldrini", "Lorenzo Valerio", "Andrea Passarella", "Marco Conti"], "title": "The Built-In Robustness of Decentralized Federated Averaging to Bad Data", "categories": ["cs.LG", "cs.AI", "cs.DC"], "comment": "Accepted at IJCNN 2025. Funding: SoBigData PPP (101079043),\n  SoBigData.it (PNRR IR0000013), FAIR (PNRR PE00000013), RESTART (PNRR\n  PE00000001)", "summary": "Decentralized federated learning (DFL) enables devices to collaboratively\ntrain models over complex network topologies without relying on a central\ncontroller. In this setting, local data remains private, but its quality and\nquantity can vary significantly across nodes. The extent to which a fully\ndecentralized system is vulnerable to poor-quality or corrupted data remains\nunclear, but several factors could contribute to potential risks. Without a\ncentral authority, there can be no unified mechanism to detect or correct\nerrors, and each node operates with a localized view of the data distribution,\nmaking it difficult for the node to assess whether its perspective aligns with\nthe true distribution. Moreover, models trained on low-quality data can\npropagate through the network, amplifying errors. To explore the impact of\nlow-quality data on DFL, we simulate two scenarios with degraded data quality\n-- one where the corrupted data is evenly distributed in a subset of nodes and\none where it is concentrated on a single node -- using a decentralized\nimplementation of FedAvg. Our results reveal that averaging-based decentralized\nlearning is remarkably robust to localized bad data, even when the corrupted\ndata resides in the most influential nodes of the network. Counterintuitively,\nthis robustness is further enhanced when the corrupted data is concentrated on\na single node, regardless of its centrality in the communication network\ntopology. This phenomenon is explained by the averaging process, which ensures\nthat no single node -- however central -- can disproportionately influence the\noverall learning process.", "AI": {"tldr": "Decentralized federated learning (DFL) shows robustness to low-quality or corrupted data, even when concentrated in influential nodes, due to the averaging process.", "motivation": "To understand the vulnerability of DFL to poor-quality data and explore its impact on model training in decentralized settings.", "method": "Simulated two scenarios of degraded data quality (evenly distributed vs. concentrated on one node) using decentralized FedAvg.", "result": "DFL is robust to localized bad data, with enhanced robustness when corruption is concentrated on a single node.", "conclusion": "Averaging in DFL mitigates disproportionate influence from any single node, ensuring system resilience."}}
{"id": "2501.02423", "pdf": "https://arxiv.org/pdf/2501.02423", "abs": "https://arxiv.org/abs/2501.02423", "authors": ["Xingwu Sun", "Shuaipeng Li", "Ruobing Xie", "Weidong Han", "Kan Wu", "Zhen Yang", "Yixing Li", "An Wang", "Shuai Li", "Jinbao Xue", "Yu Cheng", "Yangyu Tao", "Zhanhui Kang", "Chengzhong Xu", "Di Wang", "Jie Jiang"], "title": "Scaling Laws for Floating Point Quantization Training", "categories": ["cs.LG", "cs.AR", "cs.CL"], "comment": null, "summary": "Low-precision training is considered an effective strategy for reducing both\ntraining and downstream inference costs. Previous scaling laws for precision\nmainly focus on integer quantization, which pay less attention to the\nconstituents in floating-point (FP) quantization, and thus cannot well fit the\nLLM losses in this scenario. In contrast, while FP quantization training is\nmore commonly implemented in production, it's research has been relatively\nsuperficial. In this paper, we thoroughly explore the effects of FP\nquantization targets, exponent bits, mantissa bits, and the calculation\ngranularity of the scaling factor in FP quantization training performance of\nLLM models. In addition to an accurate FP quantization unified scaling law, we\nalso provide valuable suggestions for the community: (1) Exponent bits\ncontribute slightly more to the model performance than mantissa bits. We\nprovide the optimal exponent-mantissa bit ratio for different bit numbers,\nwhich is available for future reference by hardware manufacturers; (2) We\ndiscover the formation of the critical data size in low-precision LLM training.\nToo much training data exceeding the critical data size will inversely bring in\ndegradation of LLM performance; (3) The optimal FP quantization precision is\ndirectly proportional to the computational power, but within a wide\ncomputational power range. We estimate that the best cost-performance precision\nshould lie between 4-8 bits.", "AI": {"tldr": "The paper explores FP quantization in LLM training, identifying optimal exponent-mantissa bit ratios, critical data size effects, and precision-computational power relationships.", "motivation": "Previous scaling laws for precision focused on integer quantization, neglecting FP quantization's impact on LLM losses, despite its common use in production.", "method": "The study examines FP quantization targets, exponent/mantissa bits, and scaling factor granularity in LLM training.", "result": "Key findings include: (1) exponent bits slightly outperform mantissa bits, with optimal ratios provided; (2) critical data size limits training effectiveness; (3) optimal precision scales with computational power (4-8 bits).", "conclusion": "The paper offers a unified FP quantization scaling law and practical guidelines for hardware and training optimization."}}
{"id": "2504.13677", "pdf": "https://arxiv.org/pdf/2504.13677", "abs": "https://arxiv.org/abs/2504.13677", "authors": ["Andrea Santilli", "Adam Golinski", "Michael Kirchhof", "Federico Danieli", "Arno Blaas", "Miao Xiong", "Luca Zappella", "Sinead Williamson"], "title": "Revisiting Uncertainty Quantification Evaluation in Language Models: Spurious Interactions with Response Length Bias Results", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "Accepted at ACL 2025 (Main)", "summary": "Uncertainty Quantification (UQ) in Language Models (LMs) is key to improving\ntheir safety and reliability. Evaluations often use metrics like AUROC to\nassess how well UQ methods (e.g., negative sequence probabilities) correlate\nwith task correctness functions (e.g., ROUGE-L). We show that mutual\nbiases--when both UQ methods and correctness functions are biased by the same\nfactors--systematically distort evaluation. First, we formally prove that any\nmutual bias non-randomly skews AUROC rankings, compromising benchmark\nintegrity. Second, we confirm this happens empirically by testing 7 widely used\ncorrectness functions, from lexical-based and embedding-based metrics to\nLM-as-a-judge approaches, across 4 datasets x 4 models x 8 UQ methods. Our\nanalysis shows that length biases in correctness functions distort UQ\nassessments by interacting with length biases in UQ methods. We identify\nLM-as-a-judge methods as the least length-biased, offering a promising path for\na fairer UQ evaluation.", "AI": {"tldr": "Mutual biases between UQ methods and correctness functions distort AUROC rankings, compromising benchmark integrity. Length biases are a key issue, with LM-as-a-judge methods being the least biased.", "motivation": "To improve the safety and reliability of Language Models (LMs) by addressing biases in Uncertainty Quantification (UQ) evaluations.", "method": "Formally prove mutual biases skew AUROC rankings and empirically test 7 correctness functions across 4 datasets, 4 models, and 8 UQ methods.", "result": "Length biases in correctness functions distort UQ assessments, with LM-as-a-judge methods showing the least bias.", "conclusion": "LM-as-a-judge methods offer a fairer path for UQ evaluation by minimizing length biases."}}
{"id": "2505.05470", "pdf": "https://arxiv.org/pdf/2505.05470", "abs": "https://arxiv.org/abs/2505.05470", "authors": ["Jie Liu", "Gongye Liu", "Jiajun Liang", "Yangguang Li", "Jiaheng Liu", "Xintao Wang", "Pengfei Wan", "Di Zhang", "Wanli Ouyang"], "title": "Flow-GRPO: Training Flow Matching Models via Online RL", "categories": ["cs.CV", "cs.AI"], "comment": "Code: https://github.com/yifan123/flow_grpo", "summary": "We propose Flow-GRPO, the first method integrating online reinforcement\nlearning (RL) into flow matching models. Our approach uses two key strategies:\n(1) an ODE-to-SDE conversion that transforms a deterministic Ordinary\nDifferential Equation (ODE) into an equivalent Stochastic Differential Equation\n(SDE) that matches the original model's marginal distribution at all timesteps,\nenabling statistical sampling for RL exploration; and (2) a Denoising Reduction\nstrategy that reduces training denoising steps while retaining the original\ninference timestep number, significantly improving sampling efficiency without\nperformance degradation. Empirically, Flow-GRPO is effective across multiple\ntext-to-image tasks. For complex compositions, RL-tuned SD3.5 generates nearly\nperfect object counts, spatial relations, and fine-grained attributes, boosting\nGenEval accuracy from 63% to 95%. In visual text rendering, its accuracy\nimproves from 59% to 92%, significantly enhancing text generation. Flow-GRPO\nalso achieves substantial gains in human preference alignment. Notably, very\nlittle reward hacking occurred, meaning rewards did not increase at the cost of\nappreciable image quality or diversity degradation.", "AI": {"tldr": "Flow-GRPO integrates online RL into flow matching models using ODE-to-SDE conversion and Denoising Reduction, improving efficiency and performance in text-to-image tasks.", "motivation": "To enhance the performance and efficiency of flow matching models by incorporating online RL, enabling better exploration and sampling without compromising quality.", "method": "Uses ODE-to-SDE conversion for RL exploration and Denoising Reduction to improve sampling efficiency while maintaining inference timesteps.", "result": "Achieves significant improvements in text-to-image tasks, e.g., boosting GenEval accuracy from 63% to 95% and visual text rendering from 59% to 92%, with minimal reward hacking.", "conclusion": "Flow-GRPO effectively integrates RL into flow matching, delivering high performance and efficiency without sacrificing image quality or diversity."}}
{"id": "2502.19307", "pdf": "https://arxiv.org/pdf/2502.19307", "abs": "https://arxiv.org/abs/2502.19307", "authors": ["Michael Somma", "Thomas Gallien", "Branka Stojanovic"], "title": "Anomaly Detection in Complex Dynamical Systems: A Systematic Framework Using Embedding Theory and Physics-Inspired Consistency", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Anomaly detection in complex dynamical systems is essential for ensuring\nreliability, safety, and efficiency in industrial and cyber-physical\ninfrastructures. Predictive maintenance helps prevent costly failures, while\ncybersecurity monitoring has become critical as digitized systems face growing\nthreats. Many of these systems exhibit oscillatory behaviors and bounded\nmotion, requiring anomaly detection methods that capture structured temporal\ndependencies while adhering to physical consistency principles. In this work,\nwe propose a system-theoretic approach to anomaly detection, grounded in\nclassical embedding theory and physics-inspired consistency principles. We\nbuild upon the Fractal Whitney Embedding Prevalence Theorem that extends\ntraditional embedding techniques to complex system dynamics. Additionally, we\nintroduce state-derivative pairs as an embedding strategy to capture system\nevolution. To enforce temporal coherence, we develop a Temporal Differential\nConsistency Autoencoder (TDC-AE), incorporating a TDC-Loss that aligns the\napproximated derivatives of latent variables with their dynamic\nrepresentations. We evaluate our method on the C-MAPSS dataset, a benchmark for\nturbofan aeroengine degradation. TDC-AE outperforms LSTMs and Transformers\nwhile achieving a nearly 200x reduction in MAC operations, making it\nparticularly suited for lightweight edge computing. Our findings support the\nhypothesis that anomalies disrupt stable system dynamics, providing a robust\nsignal for anomaly detection.", "AI": {"tldr": "A physics-inspired anomaly detection method for dynamical systems, using embedding theory and a Temporal Differential Consistency Autoencoder (TDC-AE), outperforms LSTMs and Transformers with reduced computational cost.", "motivation": "Anomaly detection is crucial for reliability and safety in industrial and cyber-physical systems, especially those with oscillatory behaviors and bounded motion.", "method": "Proposes a system-theoretic approach using embedding theory and state-derivative pairs, with a TDC-AE incorporating a TDC-Loss for temporal coherence.", "result": "TDC-AE outperforms LSTMs and Transformers on the C-MAPSS dataset, with a 200x reduction in MAC operations, suitable for edge computing.", "conclusion": "Anomalies disrupt stable dynamics, and the proposed method provides a robust, lightweight solution for anomaly detection."}}
{"id": "2501.09621", "pdf": "https://arxiv.org/pdf/2501.09621", "abs": "https://arxiv.org/abs/2501.09621", "authors": ["Tehila Dahan", "Kfir Y. Levy"], "title": "Weight for Robustness: A Comprehensive Approach towards Optimal Fault-Tolerant Asynchronous ML", "categories": ["cs.LG"], "comment": null, "summary": "We address the challenges of Byzantine-robust training in asynchronous\ndistributed machine learning systems, aiming to enhance efficiency amid massive\nparallelization and heterogeneous computing resources. Asynchronous systems,\nmarked by independently operating workers and intermittent updates, uniquely\nstruggle with maintaining integrity against Byzantine failures, which encompass\nmalicious or erroneous actions that disrupt learning. The inherent delays in\nsuch settings not only introduce additional bias to the system but also obscure\nthe disruptions caused by Byzantine faults. To tackle these issues, we adapt\nthe Byzantine framework to asynchronous dynamics by introducing a novel\nweighted robust aggregation framework. This allows for the extension of robust\naggregators and a recent meta-aggregator to their weighted versions, mitigating\nthe effects of delayed updates. By further incorporating a recent\nvariance-reduction technique, we achieve an optimal convergence rate for the\nfirst time in an asynchronous Byzantine environment. Our methodology is\nrigorously validated through empirical and theoretical analysis, demonstrating\nits effectiveness in enhancing fault tolerance and optimizing performance in\nasynchronous ML systems.", "AI": {"tldr": "A novel weighted robust aggregation framework is proposed to address Byzantine-robust training in asynchronous distributed ML systems, achieving optimal convergence rates.", "motivation": "To enhance efficiency and integrity in asynchronous distributed ML systems amid Byzantine failures and heterogeneous computing resources.", "method": "Adapts the Byzantine framework to asynchronous dynamics using weighted robust aggregation and variance-reduction techniques.", "result": "Achieves optimal convergence rate and improves fault tolerance in asynchronous Byzantine environments.", "conclusion": "The framework effectively mitigates delays and Byzantine faults, optimizing performance in asynchronous ML systems."}}
{"id": "2504.14175", "pdf": "https://arxiv.org/pdf/2504.14175", "abs": "https://arxiv.org/abs/2504.14175", "authors": ["Yejun Yoon", "Jaeyoon Jung", "Seunghyun Yoon", "Kunwoo Park"], "title": "Hypothetical Documents or Knowledge Leakage? Rethinking LLM-based Query Expansion", "categories": ["cs.CL", "cs.IR"], "comment": "ACL 2025 (Findings)", "summary": "Query expansion methods powered by large language models (LLMs) have\ndemonstrated effectiveness in zero-shot retrieval tasks. These methods assume\nthat LLMs can generate hypothetical documents that, when incorporated into a\nquery vector, enhance the retrieval of real evidence. However, we challenge\nthis assumption by investigating whether knowledge leakage in benchmarks\ncontributes to the observed performance gains. Using fact verification as a\ntestbed, we analyze whether the generated documents contain information\nentailed by ground-truth evidence and assess their impact on performance. Our\nfindings indicate that, on average, performance improvements consistently\noccurred for claims whose generated documents included sentences entailed by\ngold evidence. This suggests that knowledge leakage may be present in\nfact-verification benchmarks, potentially inflating the perceived performance\nof LLM-based query expansion methods.", "AI": {"tldr": "LLM-based query expansion methods show performance gains in zero-shot retrieval, but knowledge leakage in benchmarks may inflate these results.", "motivation": "To investigate if performance gains in LLM-based query expansion are due to knowledge leakage in benchmarks rather than true effectiveness.", "method": "Analyze generated documents for entailment of ground-truth evidence in fact verification tasks.", "result": "Performance improvements occurred when generated documents included sentences entailed by gold evidence, suggesting knowledge leakage.", "conclusion": "Knowledge leakage in benchmarks may artificially boost the perceived performance of LLM-based query expansion methods."}}
{"id": "2505.08834", "pdf": "https://arxiv.org/pdf/2505.08834", "abs": "https://arxiv.org/abs/2505.08834", "authors": ["Muhammad Junaid Asif"], "title": "Crowd Scene Analysis using Deep Learning Techniques", "categories": ["cs.CV", "cs.AI"], "comment": "MS Graduate Research Thesis", "summary": "Our research is focused on two main applications of crowd scene analysis\ncrowd counting and anomaly detection In recent years a large number of\nresearches have been presented in the domain of crowd counting We addressed two\nmain challenges in this domain 1 Deep learning models are datahungry paradigms\nand always need a large amount of annotated data for the training of algorithm\nIt is timeconsuming and costly task to annotate such large amount of data\nSelfsupervised training is proposed to deal with this challenge 2 MCNN consists\nof multicolumns of CNN with different sizes of filters by presenting a novel\napproach based on a combination of selfsupervised training and MultiColumn CNN\nThis enables the model to learn features at different levels and makes it\neffective in dealing with challenges of occluded scenes nonuniform density\ncomplex backgrounds and scale invariation The proposed model was evaluated on\npublicly available data sets such as ShanghaiTech and UCFQNRF by means of MAE\nand MSE A spatiotemporal model based on VGG19 is proposed for crowd anomaly\ndetection addressing challenges like lighting environmental conditions\nunexpected objects and scalability The model extracts spatial and temporal\nfeatures allowing it to be generalized to realworld scenes Spatial features are\nlearned using CNN while temporal features are learned using LSTM blocks The\nmodel works on binary classification and can detect normal or abnormal behavior\nThe models performance is improved by replacing fully connected layers with\ndense residual blocks Experiments on the Hockey Fight dataset and SCVD dataset\nshow our models outperform other stateoftheart approaches", "AI": {"tldr": "The paper proposes a self-supervised training approach for crowd counting using Multi-Column CNN (MCNN) and a spatiotemporal model for anomaly detection, achieving superior performance on public datasets.", "motivation": "Addressing challenges in crowd counting (data annotation, occlusions, non-uniform density) and anomaly detection (lighting, scalability) to improve accuracy and efficiency.", "method": "For crowd counting: self-supervised training with MCNN. For anomaly detection: VGG19-based spatiotemporal model with CNN for spatial features and LSTM for temporal features, enhanced by dense residual blocks.", "result": "Improved performance on ShanghaiTech, UCFQNRF (crowd counting) and Hockey Fight, SCVD datasets (anomaly detection) with lower MAE and MSE.", "conclusion": "The proposed models effectively tackle key challenges in crowd analysis, outperforming state-of-the-art methods."}}
{"id": "2503.04149", "pdf": "https://arxiv.org/pdf/2503.04149", "abs": "https://arxiv.org/abs/2503.04149", "authors": ["Simin Chen", "Pranav Pusarla", "Baishakhi Ray"], "title": "Dynamic Benchmarking of Reasoning Capabilities in Code Large Language Models Under Data Contamination", "categories": ["cs.SE", "cs.AI", "cs.CL"], "comment": "This paper is accepted to ICML 2025. Website:\n  https://codekaleidoscope.github.io/dycodeeval.html", "summary": "The rapid evolution of code largelanguage models underscores the need for\neffective and transparent benchmarking of their reasoning capabilities.\nHowever, the current benchmarking approach heavily depends on publicly\navailable, human-created datasets. The widespread use of these fixed benchmark\ndatasets makes the benchmarking process to be static and thus particularly\nsusceptible to data contamination, an unavoidable consequence of the extensive\ndata collection processes used to train Code LLMs. Existing approaches that\naddress data contamination often suffer from human effort limitations and\nimbalanced problem complexity. To tackle these challenges, we propose \\tool, a\nnovel benchmarking suite for evaluating Code LLMs under potential data\ncontamination. Given a seed programming problem, \\tool employs multiple agents\nto extract and modify the context without altering the core logic, generating\nsemantically equivalent variations. We introduce a dynamic data generation\nmethods and conduct empirical studies on two seed datasets across 21 Code LLMs.\nResults show that \\tool effectively benchmarks reasoning capabilities under\ncontamination risks while generating diverse problem sets to ensure consistent\nand reliable evaluations.", "AI": {"tldr": "The paper introduces \\tool, a dynamic benchmarking suite for Code LLMs to address data contamination issues in static benchmarks by generating semantically equivalent problem variations.", "motivation": "Current benchmarking relies on fixed datasets, leading to static evaluations prone to data contamination, which existing methods fail to address effectively due to human effort and complexity imbalances.", "method": "\\tool uses multiple agents to modify seed programming problems' context without changing core logic, creating diverse, semantically equivalent variations. Dynamic data generation is employed.", "result": "Empirical studies on 21 Code LLMs show \\tool effectively benchmarks reasoning under contamination risks and ensures diverse, reliable evaluations.", "conclusion": "\\tool provides a robust solution for dynamic and reliable benchmarking of Code LLMs, mitigating data contamination issues."}}
{"id": "2501.17770", "pdf": "https://arxiv.org/pdf/2501.17770", "abs": "https://arxiv.org/abs/2501.17770", "authors": ["Yangming Li", "Chaoyu Liu", "Carola-Bibiane Sch\u00f6nlieb"], "title": "Generative Unordered Flow for Set-Structured Data Generation", "categories": ["cs.LG"], "comment": "Paper under review", "summary": "Flow-based generative models have demonstrated promising performance across a\nbroad spectrum of data modalities (e.g., image and text). However, there are\nfew works exploring their extension to unordered data (e.g., spatial point\nset), which is not trivial because previous models are mostly designed for\nvector data that are naturally ordered. In this paper, we present unordered\nflow, a type of flow-based generative model for set-structured data generation.\nSpecifically, we convert unordered data into an appropriate function\nrepresentation, and learn the probability measure of such representations\nthrough function-valued flow matching. For the inverse map from a function\nrepresentation to unordered data, we propose a method similar to particle\nfiltering, with Langevin dynamics to first warm-up the initial particles and\ngradient-based search to update them until convergence. We have conducted\nextensive experiments on multiple real-world datasets, showing that our\nunordered flow model is very effective in generating set-structured data and\nsignificantly outperforms previous baselines.", "AI": {"tldr": "A flow-based generative model for unordered data (e.g., point sets) is introduced, using function representations and flow matching, outperforming previous methods.", "motivation": "Existing flow-based models are designed for ordered data, leaving unordered data (e.g., point sets) underexplored. This work addresses this gap.", "method": "Unordered data is converted into function representations, with probability measures learned via function-valued flow matching. Inverse mapping uses Langevin dynamics and gradient-based search.", "result": "The model effectively generates set-structured data, significantly outperforming baselines in experiments.", "conclusion": "Unordered flow is a promising approach for generating unordered data, filling a gap in flow-based generative models."}}
{"id": "2504.14194", "pdf": "https://arxiv.org/pdf/2504.14194", "abs": "https://arxiv.org/abs/2504.14194", "authors": ["Xinlin Zhuang", "Jiahui Peng", "Ren Ma", "Yinfan Wang", "Tianyi Bai", "Xingjian Wei", "Jiantao Qiu", "Chi Zhang", "Ying Qian", "Conghui He"], "title": "Meta-rater: A Multi-dimensional Data Selection Method for Pre-training Language Models", "categories": ["cs.CL"], "comment": "Accepted by ACL 2025", "summary": "The composition of pre-training datasets for large language models (LLMs)\nremains largely undisclosed, hindering transparency and efforts to optimize\ndata quality, a critical driver of model performance. Current data selection\nmethods, such as natural language quality assessments, diversity-based filters,\nand classifier-based approaches, are limited by single-dimensional evaluation\nor redundancy-focused strategies. To address these gaps, we propose four\ndimensions to evaluate data quality: professionalism, readability, reasoning,\nand cleanliness. We further introduce Meta-rater,a multi-dimensional data\nselection method that integrates these dimensions with existing quality metrics\nthrough learned optimal weightings. Meta-rater employs proxy models to train a\nregression model that predicts validation loss, enabling the identification of\noptimal combinations of quality scores. Experiments demonstrate that Meta-rater\ndoubles convergence speed for 1.3B parameter models and improves downstream\ntask performance by 3.23, with advantages that scale to models as large as 7.2B\nparameters. Our work establishes that holistic, multi-dimensional quality\nintegration significantly outperforms conventional single-dimension approaches,\noffering a scalable paradigm for enhancing pre-training efficiency and model\ncapability. To advance future research, we release scripts, data, and models at\nhttps://github.com/opendatalab/Meta-rater.", "AI": {"tldr": "Meta-rater introduces a multi-dimensional data selection method (professionalism, readability, reasoning, cleanliness) for LLM pre-training, outperforming single-dimension approaches by doubling convergence speed and improving task performance.", "motivation": "Current data selection methods for LLMs are limited by single-dimensional evaluation or redundancy-focused strategies, hindering transparency and optimization of data quality.", "method": "Proposes Meta-rater, integrating four quality dimensions with learned optimal weightings via proxy models to predict validation loss.", "result": "Meta-rater doubles convergence speed for 1.3B parameter models and improves downstream task performance by 3.23, scaling to 7.2B parameters.", "conclusion": "Holistic, multi-dimensional quality integration significantly outperforms conventional methods, offering a scalable paradigm for enhancing pre-training efficiency and model capability."}}
{"id": "2505.10152", "pdf": "https://arxiv.org/pdf/2505.10152", "abs": "https://arxiv.org/abs/2505.10152", "authors": ["Yikang Wei"], "title": "Multi-Source Collaborative Style Augmentation and Domain-Invariant Learning for Federated Domain Generalization", "categories": ["cs.CV"], "comment": "IJCAI 2025", "summary": "Federated domain generalization aims to learn a generalizable model from\nmultiple decentralized source domains for deploying on the unseen target\ndomain. The style augmentation methods have achieved great progress on domain\ngeneralization. However, the existing style augmentation methods either explore\nthe data styles within isolated source domain or interpolate the style\ninformation across existing source domains under the data decentralization\nscenario, which leads to limited style space. To address this issue, we propose\na Multi-source Collaborative Style Augmentation and Domain-invariant learning\nmethod (MCSAD) for federated domain generalization. Specifically, we propose a\nmulti-source collaborative style augmentation module to generate data in the\nbroader style space. Furthermore, we conduct domain-invariant learning between\nthe original data and augmented data by cross-domain feature alignment within\nthe same class and classes relation ensemble distillation between different\nclasses to learn a domain-invariant model. By alternatively conducting\ncollaborative style augmentation and domain-invariant learning, the model can\ngeneralize well on unseen target domain. Extensive experiments on multiple\ndomain generalization datasets indicate that our method significantly\noutperforms the state-of-the-art federated domain generalization methods.", "AI": {"tldr": "Proposes MCSAD for federated domain generalization, combining multi-source style augmentation and domain-invariant learning to improve generalization on unseen domains.", "motivation": "Existing style augmentation methods in federated domain generalization are limited by isolated or interpolated styles, restricting the style space.", "method": "Introduces multi-source collaborative style augmentation and domain-invariant learning via cross-domain feature alignment and relation distillation.", "result": "Outperforms state-of-the-art methods on multiple domain generalization datasets.", "conclusion": "MCSAD effectively broadens style space and enhances domain generalization in decentralized settings."}}
{"id": "2503.04256", "pdf": "https://arxiv.org/pdf/2503.04256", "abs": "https://arxiv.org/abs/2503.04256", "authors": ["Yixiang Sun", "Haotian Fu", "Michael Littman", "George Konidaris"], "title": "Knowledge Retention for Continual Model-Based Reinforcement Learning", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "We propose DRAGO, a novel approach for continual model-based reinforcement\nlearning aimed at improving the incremental development of world models across\na sequence of tasks that differ in their reward functions but not the state\nspace or dynamics. DRAGO comprises two key components: Synthetic Experience\nRehearsal, which leverages generative models to create synthetic experiences\nfrom past tasks, allowing the agent to reinforce previously learned dynamics\nwithout storing data, and Regaining Memories Through Exploration, which\nintroduces an intrinsic reward mechanism to guide the agent toward revisiting\nrelevant states from prior tasks. Together, these components enable the agent\nto maintain a comprehensive and continually developing world model,\nfacilitating more effective learning and adaptation across diverse\nenvironments. Empirical evaluations demonstrate that DRAGO is able to preserve\nknowledge across tasks, achieving superior performance in various continual\nlearning scenarios.", "AI": {"tldr": "DRAGO improves continual model-based reinforcement learning by using synthetic experiences and intrinsic rewards to maintain knowledge across tasks.", "motivation": "To address the challenge of incremental world model development in tasks with varying rewards but shared state space and dynamics.", "method": "Combines Synthetic Experience Rehearsal (generative models for synthetic experiences) and Regaining Memories Through Exploration (intrinsic rewards for revisiting past states).", "result": "Empirical results show DRAGO preserves knowledge and outperforms in continual learning scenarios.", "conclusion": "DRAGO effectively maintains and develops world models, enhancing learning and adaptation across diverse environments."}}
{"id": "2501.18282", "pdf": "https://arxiv.org/pdf/2501.18282", "abs": "https://arxiv.org/abs/2501.18282", "authors": ["Yunzhen Yao", "Lie He", "Michael Gastpar"], "title": "Leveraging Sparsity for Sample-Efficient Preference Learning: A Theoretical Perspective", "categories": ["cs.LG"], "comment": null, "summary": "This paper considers the sample-efficiency of preference learning, which\nmodels and predicts human choices based on comparative judgments. The minimax\noptimal estimation error rate $\\Theta(d/n)$ in classical estimation theory\nrequires that the number of samples $n$ scales linearly with the dimensionality\nof the feature space $d$. However, the high dimensionality of the feature space\nand the high cost of collecting human-annotated data challenge the efficiency\nof traditional estimation methods. To remedy this, we leverage sparsity in the\npreference model and establish sharp error rates. We show that under the sparse\nrandom utility model, where the parameter of the reward function is $k$-sparse,\nthe minimax optimal rate can be reduced to $\\Theta(k/n \\log(d/k))$.\nFurthermore, we analyze the $\\ell_{1}$-regularized estimator and show that it\nachieves near-optimal rate under mild assumptions on the Gram matrix.\nExperiments on synthetic data and LLM alignment data validate our theoretical\nfindings, showing that sparsity-aware methods significantly reduce sample\ncomplexity and improve prediction accuracy.", "AI": {"tldr": "The paper improves sample efficiency in preference learning by leveraging sparsity, reducing the minimax optimal error rate from \u0398(d/n) to \u0398(k/n log(d/k)) for k-sparse models.", "motivation": "High dimensionality and costly human-annotated data challenge traditional preference learning methods, prompting the need for more efficient approaches.", "method": "The authors use sparsity in the preference model and analyze the \u2113\u2081-regularized estimator under mild assumptions on the Gram matrix.", "result": "Theoretical and experimental results show reduced sample complexity and improved accuracy with sparsity-aware methods.", "conclusion": "Sparsity-aware methods are effective for efficient preference learning, validated by synthetic and LLM alignment data."}}
{"id": "2505.11441", "pdf": "https://arxiv.org/pdf/2505.11441", "abs": "https://arxiv.org/abs/2505.11441", "authors": ["Xianzhen Luo", "Shijie Xuyang", "Tianhao Cheng", "Zheng Chu", "Houyi Li", "ziqi wang", "Siming Huang", "Qingfu Zhu", "Qiufeng Wang", "Xiangyu Zhang", "Shuigeng Zhou", "Wanxiang Che"], "title": "Is Compression Really Linear with Code Intelligence?", "categories": ["cs.CL"], "comment": "work in progress", "summary": "Understanding the relationship between data compression and the capabilities\nof Large Language Models (LLMs) is crucial, especially in specialized domains\nlike code intelligence. Prior work posited a linear relationship between\ncompression and general intelligence. However, it overlooked the multifaceted\nnature of code that encompasses diverse programming languages and tasks, and\nstruggled with fair evaluation of modern Code LLMs. We address this by\nevaluating a diverse array of open-source Code LLMs on comprehensive\nmulti-language, multi-task code benchmarks. To address the challenge of\nefficient and fair evaluation of pre-trained LLMs' code intelligence, we\nintroduce \\textit{Format Annealing}, a lightweight, transparent training\nmethodology designed to assess the intrinsic capabilities of these pre-trained\nmodels equitably. Compression efficacy, measured as bits-per-character (BPC),\nis determined using a novel, large-scale, and previously unseen code validation\nset derived from GitHub. Our empirical results reveal a fundamental logarithmic\nrelationship between measured code intelligence and BPC. This finding refines\nprior hypotheses of linearity, which we suggest are likely observations of the\nlogarithmic curve's tail under specific, limited conditions. Our work provides\na more nuanced understanding of compression's role in developing code\nintelligence and contributes a robust evaluation framework in the code domain.", "AI": {"tldr": "The paper explores the relationship between data compression and Code LLMs, revealing a logarithmic (not linear) link between compression (BPC) and code intelligence. It introduces Format Annealing for fair evaluation and uses a novel GitHub-derived dataset.", "motivation": "To clarify the relationship between compression and Code LLMs' intelligence, addressing gaps in prior work that overlooked code diversity and fair evaluation.", "method": "Evaluates diverse Code LLMs on multi-language, multi-task benchmarks and introduces Format Annealing for fair assessment. Measures compression via BPC on a new GitHub dataset.", "result": "Empirical findings show a logarithmic (not linear) relationship between BPC and code intelligence, refining prior hypotheses.", "conclusion": "The work offers a nuanced understanding of compression's role in code intelligence and provides a robust evaluation framework for Code LLMs."}}
{"id": "2505.16836", "pdf": "https://arxiv.org/pdf/2505.16836", "abs": "https://arxiv.org/abs/2505.16836", "authors": ["Fanrui Zhang", "Dian Li", "Qiang Zhang", "Chenjun", "sinbadliu", "Junxiong Lin", "Jiahong Yan", "Jiawei Liu", "Zheng-Jun Zha"], "title": "Fact-R1: Towards Explainable Video Misinformation Detection with Deep Reasoning", "categories": ["cs.CV", "cs.AI"], "comment": "28 pages, 27 figures", "summary": "The rapid spread of multimodal misinformation on social media has raised\ngrowing concerns, while research on video misinformation detection remains\nlimited due to the lack of large-scale, diverse datasets. Existing methods\noften overfit to rigid templates and lack deep reasoning over deceptive\ncontent. To address these challenges, we introduce FakeVV, a large-scale\nbenchmark comprising over 100,000 video-text pairs with fine-grained,\ninterpretable annotations. In addition, we further propose Fact-R1, a novel\nframework that integrates deep reasoning with collaborative rule-based\nreinforcement learning. Fact-R1 is trained through a three-stage process: (1)\nmisinformation long-Chain-of-Thought (CoT) instruction tuning, (2) preference\nalignment via Direct Preference Optimization (DPO), and (3) Group Relative\nPolicy Optimization (GRPO) using a novel verifiable reward function. This\nenables Fact-R1 to exhibit emergent reasoning behaviors comparable to those\nobserved in advanced text-based reinforcement learning systems, but in the more\ncomplex multimodal misinformation setting. Our work establishes a new paradigm\nfor misinformation detection, bridging large-scale video understanding,\nreasoning-guided alignment, and interpretable verification.", "AI": {"tldr": "The paper introduces FakeVV, a large-scale dataset for video misinformation detection, and Fact-R1, a framework combining deep reasoning and reinforcement learning to improve detection accuracy.", "motivation": "Addressing the lack of large-scale datasets and overfitting issues in existing video misinformation detection methods.", "method": "Proposes Fact-R1, a three-stage framework: misinformation CoT instruction tuning, DPO for preference alignment, and GRPO with a verifiable reward function.", "result": "Fact-R1 achieves reasoning behaviors comparable to advanced text-based systems in multimodal settings.", "conclusion": "The work sets a new paradigm for misinformation detection by integrating large-scale video understanding, reasoning, and interpretable verification."}}
{"id": "2503.06474", "pdf": "https://arxiv.org/pdf/2503.06474", "abs": "https://arxiv.org/abs/2503.06474", "authors": ["Zhefan Wang", "Huanjun Kong", "Jie Ying", "Wanli Ouyang", "Nanqing Dong"], "title": "ROGRAG: A Robustly Optimized GraphRAG Framework", "categories": ["cs.IR", "cs.AI", "cs.CL"], "comment": "ACL2025 demo track, 10 pages", "summary": "Large language models (LLMs) commonly struggle with specialized or emerging\ntopics which are rarely seen in the training corpus. Graph-based\nretrieval-augmented generation (GraphRAG) addresses this by structuring domain\nknowledge as a graph for dynamic retrieval. However, existing pipelines involve\ncomplex engineering workflows, making it difficult to isolate the impact of\nindividual components. It is also challenging to evaluate the retrieval\neffectiveness due to the overlap between the pretraining and evaluation\ndatasets. In this work, we introduce ROGRAG, a Robustly Optimized GraphRAG\nframework. Specifically, we propose a multi-stage retrieval mechanism that\nintegrates dual-level with logic form retrieval methods to improve retrieval\nrobustness without increasing computational cost. To further refine the system,\nwe incorporate various result verification methods and adopt an incremental\ndatabase construction approach. Through extensive ablation experiments, we\nrigorously assess the effectiveness of each component. Our implementation\nincludes comparative experiments on SeedBench, where Qwen2.5-7B-Instruct\ninitially underperformed. ROGRAG significantly improves the score from 60.0% to\n75.0% and outperforms mainstream methods. Experiments on domain-specific\ndatasets reveal that dual-level retrieval enhances fuzzy matching, while logic\nform retrieval improves structured reasoning, highlighting the importance of\nmulti-stage retrieval.ROGRAG is released as an open-source resource and\nsupports installation with pip.", "AI": {"tldr": "ROGRAG is a robustly optimized GraphRAG framework that improves retrieval-augmented generation for LLMs by integrating multi-stage retrieval and verification methods, achieving significant performance gains.", "motivation": "Addressing the limitations of LLMs in handling specialized or emerging topics and the complexity of existing GraphRAG pipelines, ROGRAG aims to enhance retrieval robustness and evaluation clarity.", "method": "ROGRAG introduces a multi-stage retrieval mechanism combining dual-level and logic form retrieval, along with result verification and incremental database construction.", "result": "ROGRAG improves performance from 60.0% to 75.0% on SeedBench and outperforms mainstream methods, with dual-level retrieval aiding fuzzy matching and logic form retrieval enhancing structured reasoning.", "conclusion": "ROGRAG is a scalable, open-source solution that effectively addresses retrieval challenges in LLMs, demonstrating the value of multi-stage retrieval and verification."}}
{"id": "2501.18527", "pdf": "https://arxiv.org/pdf/2501.18527", "abs": "https://arxiv.org/abs/2501.18527", "authors": ["Konrad Mundinger", "Max Zimmer", "Aldo Kiem", "Christoph Spiegel", "Sebastian Pokutta"], "title": "Neural Discovery in Mathematics: Do Machines Dream of Colored Planes?", "categories": ["cs.LG", "math.CO"], "comment": "9 pages main paper, 11 pages references and appendix, 17 figures, 1\n  table", "summary": "We demonstrate how neural networks can drive mathematical discovery through a\ncase study of the Hadwiger-Nelson problem, a long-standing open problem at the\nintersection of discrete geometry and extremal combinatorics that is concerned\nwith coloring the plane while avoiding monochromatic unit-distance pairs. Using\nneural networks as approximators, we reformulate this mixed discrete-continuous\ngeometric coloring problem with hard constraints as an optimization task with a\nprobabilistic, differentiable loss function. This enables gradient-based\nexploration of admissible configurations that most significantly led to the\ndiscovery of two novel six-colorings, providing the first improvement in thirty\nyears to the off-diagonal variant of the original problem. Here, we establish\nthe underlying machine learning approach used to obtain these results and\ndemonstrate its broader applicability through additional numerical insights.", "AI": {"tldr": "Neural networks improve the Hadwiger-Nelson problem, discovering new six-colorings after 30 years.", "motivation": "To solve the long-standing Hadwiger-Nelson problem in discrete geometry using neural networks.", "method": "Reformulated the problem as an optimization task with a probabilistic, differentiable loss function using neural networks.", "result": "Discovered two novel six-colorings, the first improvement in 30 years.", "conclusion": "Demonstrates neural networks' potential in mathematical discovery, with broader applicability."}}
{"id": "2505.11626", "pdf": "https://arxiv.org/pdf/2505.11626", "abs": "https://arxiv.org/abs/2505.11626", "authors": ["Udita Patel", "Rutu Mulkar", "Jay Roberts", "Cibi Chakravarthy Senthilkumar", "Sujay Gandhi", "Xiaofei Zheng", "Naumaan Nayyar", "Parul Kalra", "Rafael Castrillo"], "title": "THELMA: Task Based Holistic Evaluation of Large Language Model Applications-RAG Question Answering", "categories": ["cs.CL", "cs.AI"], "comment": "Added author", "summary": "We propose THELMA (Task Based Holistic Evaluation of Large Language Model\nApplications), a reference free framework for RAG (Retrieval Augmented\ngeneration) based question answering (QA) applications. THELMA consist of six\ninterdependent metrics specifically designed for holistic, fine grained\nevaluation of RAG QA applications. THELMA framework helps developers and\napplication owners evaluate, monitor and improve end to end RAG QA pipelines\nwithout requiring labelled sources or reference responses.We also present our\nfindings on the interplay of the proposed THELMA metrics, which can be\ninterpreted to identify the specific RAG component needing improvement in QA\napplications.", "AI": {"tldr": "THELMA is a reference-free framework with six metrics for evaluating RAG-based QA applications, aiding in monitoring and improving pipelines without labeled data.", "motivation": "To provide a holistic, fine-grained evaluation of RAG QA applications without needing labeled sources or reference responses.", "method": "Proposes THELMA, a framework with six interdependent metrics for evaluating RAG QA pipelines.", "result": "Findings show how THELMA metrics can identify specific RAG components needing improvement.", "conclusion": "THELMA enables effective evaluation and enhancement of RAG QA applications without reliance on labeled data."}}
{"id": "2505.20704", "pdf": "https://arxiv.org/pdf/2505.20704", "abs": "https://arxiv.org/abs/2505.20704", "authors": ["Zixuan Hu", "Yichun Hu", "Xiaotong Li", "Shixiang Tang", "Ling-Yu Duan"], "title": "Beyond Entropy: Region Confidence Proxy for Wild Test-Time Adaptation", "categories": ["cs.CV"], "comment": "Accepted by ICML 2025", "summary": "Wild Test-Time Adaptation (WTTA) is proposed to adapt a source model to\nunseen domains under extreme data scarcity and multiple shifts. Previous\napproaches mainly focused on sample selection strategies, while overlooking the\nfundamental problem on underlying optimization. Initially, we critically\nanalyze the widely-adopted entropy minimization framework in WTTA and uncover\nits significant limitations in noisy optimization dynamics that substantially\nhinder adaptation efficiency. Through our analysis, we identify region\nconfidence as a superior alternative to traditional entropy, however, its\ndirect optimization remains computationally prohibitive for real-time\napplications. In this paper, we introduce a novel region-integrated method\nReCAP that bypasses the lengthy process. Specifically, we propose a\nprobabilistic region modeling scheme that flexibly captures semantic changes in\nembedding space. Subsequently, we develop a finite-to-infinite asymptotic\napproximation that transforms the intractable region confidence into a\ntractable and upper-bounded proxy. These innovations significantly unlock the\noverlooked potential dynamics in local region in a concise solution. Our\nextensive experiments demonstrate the consistent superiority of ReCAP over\nexisting methods across various datasets and wild scenarios.", "AI": {"tldr": "ReCAP introduces a region-integrated method for Wild Test-Time Adaptation (WTTA), addressing optimization inefficiencies in entropy minimization by leveraging region confidence and probabilistic modeling.", "motivation": "Existing WTTA methods focus on sample selection but neglect optimization dynamics, leading to inefficiencies. Entropy minimization, widely used, has noisy dynamics, while region confidence, though superior, is computationally prohibitive.", "method": "ReCAP uses probabilistic region modeling to capture semantic changes and a finite-to-infinite asymptotic approximation to make region confidence tractable.", "result": "ReCAP outperforms existing methods across datasets and wild scenarios, demonstrating superior adaptation efficiency.", "conclusion": "ReCAP effectively addresses WTTA challenges by optimizing region confidence, offering a concise and efficient solution."}}
{"id": "2503.09427", "pdf": "https://arxiv.org/pdf/2503.09427", "abs": "https://arxiv.org/abs/2503.09427", "authors": ["Yaorui Shi", "Jiaqi Yang", "Changhao Nai", "Sihang Li", "Junfeng Fang", "Xiang Wang", "Zhiyuan Liu", "Yang Zhang"], "title": "Language-Enhanced Representation Learning for Single-Cell Transcriptomics", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Single-cell RNA sequencing (scRNA-seq) offers detailed insights into cellular\nheterogeneity. Recent advancements leverage single-cell large language models\n(scLLMs) for effective representation learning. These models focus exclusively\non transcriptomic data, neglecting complementary biological knowledge from\ntextual descriptions. To overcome this limitation, we propose scMMGPT, a novel\nmultimodal framework designed for language-enhanced representation learning in\nsingle-cell transcriptomics. Unlike existing methods, scMMGPT employs robust\ncell representation extraction, preserving quantitative gene expression data,\nand introduces an innovative two-stage pre-training strategy combining\ndiscriminative precision with generative flexibility. Extensive experiments\ndemonstrate that scMMGPT significantly outperforms unimodal and multimodal\nbaselines across key downstream tasks, including cell annotation and\nclustering, and exhibits superior generalization in out-of-distribution\nscenarios.", "AI": {"tldr": "scMMGPT is a multimodal framework for single-cell transcriptomics, combining transcriptomic data with textual knowledge to outperform existing methods in tasks like cell annotation and clustering.", "motivation": "Existing scLLMs focus only on transcriptomic data, ignoring valuable textual biological knowledge, limiting their effectiveness.", "method": "scMMGPT uses robust cell representation extraction and a two-stage pre-training strategy to integrate transcriptomic and textual data.", "result": "scMMGPT outperforms unimodal and multimodal baselines in downstream tasks and shows better generalization in out-of-distribution scenarios.", "conclusion": "scMMGPT's multimodal approach enhances representation learning in single-cell transcriptomics, offering superior performance and flexibility."}}
{"id": "2501.19158", "pdf": "https://arxiv.org/pdf/2501.19158", "abs": "https://arxiv.org/abs/2501.19158", "authors": ["Giovanni Catania", "Aur\u00e9lien Decelle", "Cyril Furtlehner", "Beatriz Seoane"], "title": "A theoretical framework for overfitting in energy-based modeling", "categories": ["cs.LG", "cond-mat.dis-nn", "cond-mat.stat-mech"], "comment": "29 pages, 20 figures (including appendix). Accepted at Proceedings of\n  the 42nd International Conference on Machine Learning, Vancouver, Canada.\n  PMLR 267, 2025", "summary": "We investigate the impact of limited data on training pairwise energy-based\nmodels for inverse problems aimed at identifying interaction networks.\nUtilizing the Gaussian model as testbed, we dissect training trajectories\nacross the eigenbasis of the coupling matrix, exploiting the independent\nevolution of eigenmodes and revealing that the learning timescales are tied to\nthe spectral decomposition of the empirical covariance matrix. We see that\noptimal points for early stopping arise from the interplay between these\ntimescales and the initial conditions of training. Moreover, we show that\nfinite data corrections can be accurately modeled through asymptotic random\nmatrix theory calculations and provide the counterpart of generalized\ncross-validation in the energy based model context. Our analytical framework\nextends to binary-variable maximum-entropy pairwise models with minimal\nvariations. These findings offer strategies to control overfitting in\ndiscrete-variable models through empirical shrinkage corrections, improving the\nmanagement of overfitting in energy-based generative models. Finally, we\npropose a generalization to arbitrary energy-based models by deriving the\nneural tangent kernel dynamics of the score function under the score-matching\nalgorithm.", "AI": {"tldr": "The paper explores how limited data affects training energy-based models for inverse problems, revealing insights into learning timescales, early stopping, and overfitting control.", "motivation": "To understand the challenges of training pairwise energy-based models with limited data and improve their performance in identifying interaction networks.", "method": "Analyzes training trajectories using the Gaussian model, studies eigenmode evolution, and applies random matrix theory for finite data corrections. Extends to binary-variable models and proposes neural tangent kernel dynamics.", "result": "Optimal early stopping points are identified, finite data corrections are modeled accurately, and strategies to control overfitting in discrete-variable models are provided.", "conclusion": "The framework offers practical strategies for managing overfitting and extends to broader energy-based models, enhancing their applicability."}}
{"id": "2505.14590", "pdf": "https://arxiv.org/pdf/2505.14590", "abs": "https://arxiv.org/abs/2505.14590", "authors": ["Huihao Jing", "Haoran Li", "Wenbin Hu", "Qi Hu", "Heli Xu", "Tianshu Chu", "Peizhao Hu", "Yangqiu Song"], "title": "MCIP: Protecting MCP Safety via Model Contextual Integrity Protocol", "categories": ["cs.CL"], "comment": "17 pages", "summary": "As Model Context Protocol (MCP) introduces an easy-to-use ecosystem for users\nand developers, it also brings underexplored safety risks. Its decentralized\narchitecture, which separates clients and servers, poses unique challenges for\nsystematic safety analysis. This paper proposes a novel framework to enhance\nMCP safety. Guided by the MAESTRO framework, we first analyze the missing\nsafety mechanisms in MCP, and based on this analysis, we propose the Model\nContextual Integrity Protocol (MCIP), a refined version of MCP that addresses\nthese gaps. Next, we develop a fine-grained taxonomy that captures a diverse\nrange of unsafe behaviors observed in MCP scenarios. Building on this taxonomy,\nwe develop benchmark and training data that support the evaluation and\nimprovement of LLMs' capabilities in identifying safety risks within MCP\ninteractions. Leveraging the proposed benchmark and training data, we conduct\nextensive experiments on state-of-the-art LLMs. The results highlight LLMs'\nvulnerabilities in MCP interactions and demonstrate that our approach\nsubstantially improves their safety performance.", "AI": {"tldr": "The paper proposes MCIP, a refined version of MCP, to address safety risks in decentralized architectures. It introduces a taxonomy for unsafe behaviors, benchmarks for LLM evaluation, and shows improved safety performance.", "motivation": "MCP's decentralized architecture poses safety risks, which are underexplored. The paper aims to systematically analyze and enhance MCP's safety mechanisms.", "method": "The MAESTRO framework guides the analysis of MCP's safety gaps. MCIP is proposed, along with a taxonomy of unsafe behaviors, benchmarks, and training data for LLMs.", "result": "Experiments reveal LLM vulnerabilities in MCP interactions and demonstrate significant safety improvements using the proposed approach.", "conclusion": "The paper successfully enhances MCP safety by introducing MCIP, a taxonomy, and benchmarks, proving their effectiveness in improving LLM safety performance."}}
{"id": "2505.21649", "pdf": "https://arxiv.org/pdf/2505.21649", "abs": "https://arxiv.org/abs/2505.21649", "authors": ["Keanu Nichols", "Nazia Tasnim", "Yuting Yan", "Nicholas Ikechukwu", "Elva Zou", "Deepti Ghadiyaram", "Bryan A. Plummer"], "title": "Right Side Up? Disentangling Orientation Understanding in MLLMs with Fine-grained Multi-axis Perception Tasks", "categories": ["cs.CV"], "comment": null, "summary": "Object orientation understanding represents a fundamental challenge in visual\nperception critical for applications like robotic manipulation and augmented\nreality. Current vision-language benchmarks fail to isolate this capability,\noften conflating it with positional relationships and general scene\nunderstanding. We introduce DORI (Discriminative Orientation Reasoning\nIntelligence), a comprehensive benchmark establishing object orientation\nperception as a primary evaluation target. DORI assesses four dimensions of\norientation comprehension: frontal alignment, rotational transformations,\nrelative directional relationships, and canonical orientation understanding.\nThrough carefully curated tasks from 11 datasets spanning 67 object categories\nacross synthetic and real-world scenarios, DORI provides insights on how\nmulti-modal systems understand object orientations. Our evaluation of 15\nstate-of-the-art vision-language models reveals critical limitations: even the\nbest models achieve only 54.2% accuracy on coarse tasks and 33.0% on granular\norientation judgments, with performance deteriorating for tasks requiring\nreference frame shifts or compound rotations. These findings demonstrate the\nneed for dedicated orientation representation mechanisms, as models show\nsystematic inability to perform precise angular estimations, track orientation\nchanges across viewpoints, and understand compound rotations - suggesting\nlimitations in their internal 3D spatial representations. As the first\ndiagnostic framework specifically designed for orientation awareness in\nmultimodal systems, DORI offers implications for improving robotic control, 3D\nscene reconstruction, and human-AI interaction in physical environments. DORI\ndata: https://huggingface.co/datasets/appledora/DORI-Benchmark", "AI": {"tldr": "DORI is a benchmark for evaluating object orientation understanding in vision-language models, revealing significant limitations in current systems.", "motivation": "Current benchmarks conflate object orientation with other visual tasks, so DORI isolates and evaluates this critical capability for applications like robotics and AR.", "method": "DORI assesses four orientation dimensions using tasks from 11 datasets across synthetic and real-world scenarios, evaluating 15 state-of-the-art models.", "result": "Models perform poorly, with 54.2% accuracy on coarse tasks and 33.0% on granular ones, struggling with reference frame shifts and compound rotations.", "conclusion": "DORI highlights the need for better orientation representation in models, offering insights for robotics, 3D reconstruction, and human-AI interaction."}}
{"id": "2503.09969", "pdf": "https://arxiv.org/pdf/2503.09969", "abs": "https://arxiv.org/abs/2503.09969", "authors": ["Nathan Drenkow", "Mitchell Pavlak", "Keith Harrigian", "Ayah Zirikly", "Adarsh Subbaswamy", "Mohammad Mehdi Farhangi", "Nicholas Petrick", "Mathias Unberath"], "title": "Detecting Dataset Bias in Medical AI: A Generalized and Modality-Agnostic Auditing Framework", "categories": ["cs.LG", "cs.AI", "cs.CV"], "comment": null, "summary": "Artificial Intelligence (AI) is now firmly at the center of evidence-based\nmedicine. Despite many success stories that edge the path of AI's rise in\nhealthcare, there are comparably many reports of significant shortcomings and\nunexpected behavior of AI in deployment. A major reason for these limitations\nis AI's reliance on association-based learning, where non-representative\nmachine learning datasets can amplify latent bias during training and/or hide\nit during testing. To unlock new tools capable of foreseeing and preventing\nsuch AI bias issues, we present G-AUDIT. Generalized Attribute Utility and\nDetectability-Induced bias Testing (G-AUDIT) for datasets is a\nmodality-agnostic dataset auditing framework that allows for generating\ntargeted hypotheses about sources of bias in training or testing data. Our\nmethod examines the relationship between task-level annotations (commonly\nreferred to as ``labels'') and data properties including patient attributes\n(e.g., age, sex) and environment/acquisition characteristics (e.g., clinical\nsite, imaging protocols). G-AUDIT quantifies the extent to which the observed\ndata attributes pose a risk for shortcut learning, or in the case of testing\ndata, might hide predictions made based on spurious associations. We\ndemonstrate the broad applicability of our method by analyzing large-scale\nmedical datasets for three distinct modalities and machine learning tasks: skin\nlesion classification in images, stigmatizing language classification in\nElectronic Health Records (EHR), and mortality prediction for ICU tabular data.\nIn each setting, G-AUDIT successfully identifies subtle biases commonly\noverlooked by traditional qualitative methods, underscoring its practical value\nin exposing dataset-level risks and supporting the downstream development of\nreliable AI systems.", "AI": {"tldr": "G-AUDIT is a modality-agnostic framework for auditing datasets to detect and quantify biases in AI training and testing data, demonstrated across medical imaging, EHR, and ICU data.", "motivation": "AI in healthcare often suffers from biases due to non-representative datasets, leading to unreliable outcomes. G-AUDIT aims to identify and mitigate these biases.", "method": "G-AUDIT analyzes relationships between task-level labels and data attributes (e.g., patient demographics, acquisition details) to quantify bias risks for shortcut learning or spurious associations.", "result": "G-AUDIT identified subtle biases in skin lesion classification, EHR language classification, and ICU mortality prediction, outperforming traditional qualitative methods.", "conclusion": "G-AUDIT is a practical tool for exposing dataset-level biases, supporting the development of more reliable AI systems in healthcare."}}
{"id": "2502.00338", "pdf": "https://arxiv.org/pdf/2502.00338", "abs": "https://arxiv.org/abs/2502.00338", "authors": ["Yuan Gao", "Hao Wu", "Ruiqi Shu", "Huanshuo Dong", "Fan Xu", "Rui Ray Chen", "Yibo Yan", "Qingsong Wen", "Xuming Hu", "Kun Wang", "Jiahao Wu", "Qing Li", "Hui Xiong", "Xiaomeng Huang"], "title": "OneForecast: A Universal Framework for Global and Regional Weather Forecasting", "categories": ["cs.LG", "physics.ao-ph"], "comment": null, "summary": "Accurate weather forecasts are important for disaster prevention,\nagricultural planning, etc. Traditional numerical weather prediction (NWP)\nmethods offer physically interpretable high-accuracy predictions but are\ncomputationally expensive and fail to fully leverage rapidly growing historical\ndata. In recent years, deep learning models have made significant progress in\nweather forecasting, but challenges remain, such as balancing global and\nregional high-resolution forecasts, excessive smoothing in extreme event\npredictions, and insufficient dynamic system modeling. To address these issues,\nthis paper proposes a global-regional nested weather forecasting framework\n(OneForecast) based on graph neural networks. By combining a dynamic system\nperspective with multi-grid theory, we construct a multi-scale graph structure\nand densify the target region to capture local high-frequency features. We\nintroduce an adaptive messaging mechanism, using dynamic gating units to deeply\nintegrate node and edge features for more accurate extreme event forecasting.\nFor high-resolution regional forecasts, we propose a neural nested grid method\nto mitigate boundary information loss. Experimental results show that\nOneForecast performs excellently across global to regional scales and\nshort-term to long-term forecasts, especially in extreme event predictions.\nCodes link https://github.com/YuanGao-YG/OneForecast.", "AI": {"tldr": "OneForecast is a global-regional nested weather forecasting framework using graph neural networks to improve accuracy, especially for extreme events, by combining dynamic system modeling and multi-grid theory.", "motivation": "Traditional NWP methods are computationally expensive and underutilize historical data, while deep learning models struggle with global-regional balance, extreme event smoothing, and dynamic system modeling.", "method": "Proposes a graph neural network-based framework with multi-scale graph structures, adaptive messaging, and neural nested grids for high-resolution regional forecasts.", "result": "OneForecast excels in global to regional scales and short-term to long-term forecasts, particularly in extreme event predictions.", "conclusion": "The framework effectively addresses key challenges in weather forecasting, offering improved accuracy and performance."}}
{"id": "2505.17427", "pdf": "https://arxiv.org/pdf/2505.17427", "abs": "https://arxiv.org/abs/2505.17427", "authors": ["Zhengyi Zhao", "Shubo Zhang", "Zezhong Wang", "Huimin Wang", "Yutian Zhao", "Bin Liang", "Yefeng Zheng", "Binyang Li", "Kam-Fai Wong", "Xian Wu"], "title": "T$^2$: An Adaptive Test-Time Scaling Strategy for Contextual Question Answering", "categories": ["cs.CL"], "comment": "arXiv admin note: substantial text overlap with arXiv:2503.22985", "summary": "Recent advances in Large Language Models (LLMs) have demonstrated remarkable\nperformance in Contextual Question Answering (CQA). However, prior approaches\ntypically employ elaborate reasoning strategies regardless of question\ncomplexity, leading to low adaptability. Recent efficient test-time scaling\nmethods introduce budget constraints or early stop mechanisms to avoid\noverthinking for straightforward questions. But they add human bias to the\nreasoning process and fail to leverage models' inherent reasoning capabilities.\nTo address these limitations, we present T$^2$: Think-to-Think, a novel\nframework that dynamically adapts reasoning depth based on question complexity.\nT$^2$ leverages the insight that if an LLM can effectively solve similar\nquestions using specific reasoning strategies, it can apply the same strategy\nto the original question. This insight enables to adoption of concise reasoning\nfor straightforward questions while maintaining detailed analysis for complex\nproblems. T$^2$ works through four key steps: decomposing questions into\nstructural elements, generating similar examples with candidate reasoning\nstrategies, evaluating these strategies against multiple criteria, and applying\nthe most appropriate strategy to the original question. Experimental evaluation\nacross seven diverse CQA benchmarks demonstrates that T$^2$ not only achieves\nhigher accuracy than baseline methods but also reduces computational overhead\nby up to 25.2\\%.", "AI": {"tldr": "T$^2$ (Think-to-Think) is a framework that dynamically adjusts reasoning depth in LLMs for CQA, improving accuracy and reducing computational costs.", "motivation": "Prior methods lack adaptability and introduce human bias, failing to utilize LLMs' inherent reasoning capabilities.", "method": "T$^2$ decomposes questions, generates similar examples with strategies, evaluates them, and applies the best strategy.", "result": "T$^2$ outperforms baselines in accuracy and reduces computational overhead by up to 25.2%.", "conclusion": "T$^2$ effectively balances reasoning depth and efficiency, enhancing LLM performance in CQA."}}
{"id": "2505.22944", "pdf": "https://arxiv.org/pdf/2505.22944", "abs": "https://arxiv.org/abs/2505.22944", "authors": ["Angtian Wang", "Haibin Huang", "Jacob Zhiyuan Fang", "Yiding Yang", "Chongyang Ma"], "title": "ATI: Any Trajectory Instruction for Controllable Video Generation", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "We propose a unified framework for motion control in video generation that\nseamlessly integrates camera movement, object-level translation, and\nfine-grained local motion using trajectory-based inputs. In contrast to prior\nmethods that address these motion types through separate modules or\ntask-specific designs, our approach offers a cohesive solution by projecting\nuser-defined trajectories into the latent space of pre-trained image-to-video\ngeneration models via a lightweight motion injector. Users can specify\nkeypoints and their motion paths to control localized deformations, entire\nobject motion, virtual camera dynamics, or combinations of these. The injected\ntrajectory signals guide the generative process to produce temporally\nconsistent and semantically aligned motion sequences. Our framework\ndemonstrates superior performance across multiple video motion control tasks,\nincluding stylized motion effects (e.g., motion brushes), dynamic viewpoint\nchanges, and precise local motion manipulation. Experiments show that our\nmethod provides significantly better controllability and visual quality\ncompared to prior approaches and commercial solutions, while remaining broadly\ncompatible with various state-of-the-art video generation backbones. Project\npage: https://anytraj.github.io/.", "AI": {"tldr": "A unified framework for motion control in video generation integrates camera movement, object translation, and local motion using trajectory inputs, outperforming prior methods in controllability and quality.", "motivation": "Prior methods handle motion types separately or with task-specific designs, lacking a cohesive solution. This work aims to unify motion control for better flexibility and performance.", "method": "Projects user-defined trajectories into the latent space of pre-trained video models via a lightweight motion injector, enabling control over deformations, object motion, and camera dynamics.", "result": "Superior performance in tasks like stylized motion, viewpoint changes, and local motion manipulation, with better controllability and visual quality than existing methods.", "conclusion": "The framework offers a versatile, high-quality solution for motion control in video generation, compatible with various state-of-the-art backbones."}}
{"id": "2503.19449", "pdf": "https://arxiv.org/pdf/2503.19449", "abs": "https://arxiv.org/abs/2503.19449", "authors": ["Zhongchun Zheng", "Kan Wu", "Long Cheng", "Lu Li", "Rodrigo C. O. Rocha", "Tianyi Liu", "Wei Wei", "Jianjiang Zeng", "Xianwei Zhang", "Yaoqing Gao"], "title": "VecTrans: Enhancing Compiler Auto-Vectorization through LLM-Assisted Code Transformations", "categories": ["cs.SE", "cs.AI", "cs.LG", "cs.PF"], "comment": null, "summary": "Auto-vectorization is a fundamental optimization for modern compilers to\nexploit SIMD parallelism. However, state-of-the-art approaches still struggle\nto handle intricate code patterns, often requiring manual hints or\ndomain-specific expertise. Large language models (LLMs), with their ability to\ncapture intricate patterns, provide a promising solution, yet their effective\napplication in compiler optimizations remains an open challenge due to issues\nsuch as hallucinations and a lack of domain-specific reasoning. In this paper,\nwe present VecTrans, a novel framework that leverages LLMs to enhance\ncompiler-based code vectorization. VecTrans first employs compiler analysis to\nidentify potentially vectorizable code regions. It then utilizes an LLM to\nrefactor these regions into patterns that are more amenable to the compilers\nauto-vectorization. To ensure semantic correctness, VecTrans further integrates\na hybrid validation mechanism at the intermediate representation (IR) level.\nWith the above efforts, VecTrans combines the adaptability of LLMs with the\nprecision of compiler vectorization, thereby effectively opening up the\nvectorization opportunities. experimental results show that among all TSVC\nfunctions unvectorizable by GCC, ICC, Clang, and BiSheng Compiler, VecTrans\nachieves an geomean speedup of 1.77x and successfully vectorizes 24 of 51 test\ncases. This marks a significant advancement over state-of-the-art approaches\nwhile maintaining a cost efficiency of $0.012 per function optimization for LLM\nAPI usage.", "AI": {"tldr": "VecTrans leverages LLMs to enhance compiler auto-vectorization, achieving a 1.77x geomean speedup and vectorizing 24 of 51 previously unvectorizable test cases.", "motivation": "State-of-the-art auto-vectorization struggles with complex code patterns, requiring manual intervention. LLMs offer potential but face challenges like hallucinations and lack of domain-specific reasoning.", "method": "VecTrans uses compiler analysis to identify vectorizable regions, refactors them with an LLM, and validates correctness via hybrid IR-level checks.", "result": "Achieves 1.77x geomean speedup and vectorizes 24/51 unvectorizable test cases, outperforming GCC, ICC, Clang, and BiSheng Compiler.", "conclusion": "VecTrans combines LLM adaptability with compiler precision, advancing auto-vectorization while maintaining cost efficiency ($0.012 per function)."}}
{"id": "2502.01203", "pdf": "https://arxiv.org/pdf/2502.01203", "abs": "https://arxiv.org/abs/2502.01203", "authors": ["Gholamali Aminian", "Amir R. Asadi", "Idan Shenfeld", "Youssef Mroueh"], "title": "Theoretical Analysis of KL-regularized RLHF with Multiple Reference Models", "categories": ["cs.LG", "stat.ML"], "comment": "Experiments are added in new version", "summary": "Recent methods for aligning large language models (LLMs) with human feedback\npredominantly rely on a single reference model, which limits diversity, model\noverfitting, and underutilizes the wide range of available pre-trained models.\nIncorporating multiple reference models has the potential to address these\nlimitations by broadening perspectives, reducing bias, and leveraging the\nstrengths of diverse open-source LLMs. However, integrating multiple reference\nmodels into reinforcement learning with human feedback (RLHF) frameworks poses\nsignificant theoretical challenges, where achieving exact solutions has\nremained an open problem. This paper presents the first \\emph{exact solution}\nto the multiple reference model problem in reverse KL-regularized RLHF. We\nintroduce a comprehensive theoretical framework that includes rigorous\nstatistical analysis and provides sample complexity guarantees. Additionally,\nwe extend our analysis to forward KL-regularized RLHF, offering new insights\ninto sample complexity requirements in multiple reference scenarios. Our\ncontributions lay the foundation for more advanced and adaptable LLM alignment\ntechniques, enabling the effective use of multiple reference models. This work\npaves the way for developing alignment frameworks that are both theoretically\nsound and better suited to the challenges of modern AI ecosystems.", "AI": {"tldr": "The paper introduces an exact solution for integrating multiple reference models in RLHF, addressing limitations of single-model approaches like lack of diversity and overfitting.", "motivation": "Current LLM alignment methods rely on single reference models, limiting diversity and causing overfitting. Using multiple models could mitigate these issues but poses theoretical challenges.", "method": "The paper presents a theoretical framework for exact solutions in reverse KL-regularized RLHF and extends it to forward KL-regularized RLHF, with rigorous statistical analysis and sample complexity guarantees.", "result": "The framework provides exact solutions and sample complexity guarantees for multiple reference model integration, enabling more adaptable LLM alignment.", "conclusion": "This work advances LLM alignment by supporting multiple reference models, offering theoretical soundness and better adaptability for modern AI challenges."}}
{"id": "2505.19176", "pdf": "https://arxiv.org/pdf/2505.19176", "abs": "https://arxiv.org/abs/2505.19176", "authors": ["Zhuo Liu", "Moxin Li", "Xun Deng", "Qifan Wang", "Fuli Feng"], "title": "Assistant-Guided Mitigation of Teacher Preference Bias in LLM-as-a-Judge", "categories": ["cs.CL"], "comment": "Under review", "summary": "LLM-as-a-Judge employs large language models (LLMs), such as GPT-4, to\nevaluate the quality of LLM-generated responses, gaining popularity for its\ncost-effectiveness and strong alignment with human evaluations. However,\ntraining proxy judge models using evaluation data generated by powerful teacher\nmodels introduces a critical yet previously overlooked issue: teacher\npreference bias, where the proxy judge model learns a biased preference for\nresponses from the teacher model. To tackle this problem, we propose a novel\nsetting that incorporates an additional assistant model, which is not biased\ntoward the teacher model's responses, to complement the training data. Building\non this setup, we introduce AGDe-Judge, a three-stage framework designed to\ndebias from both the labels and feedbacks in the training data. Extensive\nexperiments demonstrate that AGDe-Judge effectively reduces teacher preference\nbias while maintaining strong performance across six evaluation benchmarks.\nCode is available at https://github.com/Liuz233/AGDe-Judge.", "AI": {"tldr": "AGDe-Judge is a framework to reduce teacher preference bias in LLM-based evaluation systems by incorporating an unbiased assistant model and a three-stage debiasing process.", "motivation": "The paper addresses the issue of teacher preference bias in proxy judge models trained using evaluation data from powerful teacher models, which can skew results.", "method": "The authors propose AGDe-Judge, a three-stage framework that uses an unbiased assistant model to complement training data and debias labels and feedback.", "result": "Experiments show AGDe-Judge effectively reduces bias while maintaining strong performance across six benchmarks.", "conclusion": "AGDe-Judge successfully mitigates teacher preference bias, improving the reliability of LLM-based evaluations."}}
{"id": "2505.23161", "pdf": "https://arxiv.org/pdf/2505.23161", "abs": "https://arxiv.org/abs/2505.23161", "authors": ["Antonio D'Orazio", "Maria Rosaria Briglia", "Donato Crisostomi", "Dario Loi", "Emanuele Rodol\u00e0", "Iacopo Masi"], "title": "Implicit Inversion turns CLIP into a Decoder", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": null, "summary": "CLIP is a discriminative model trained to align images and text in a shared\nembedding space. Due to its multimodal structure, it serves as the backbone of\nmany generative pipelines, where a decoder is trained to map from the shared\nspace back to images. In this work, we show that image synthesis is\nnevertheless possible using CLIP alone -- without any decoder, training, or\nfine-tuning. Our approach optimizes a frequency-aware implicit neural\nrepresentation that encourages coarse-to-fine generation by stratifying\nfrequencies across network layers. To stabilize this inverse mapping, we\nintroduce adversarially robust initialization, a lightweight Orthogonal\nProcrustes projection to align local text and image embeddings, and a blending\nloss that anchors outputs to natural image statistics. Without altering CLIP's\nweights, this framework unlocks capabilities such as text-to-image generation,\nstyle transfer, and image reconstruction. These findings suggest that\ndiscriminative models may hold untapped generative potential, hidden in plain\nsight.", "AI": {"tldr": "CLIP, a discriminative model, can generate images without a decoder or training by optimizing a frequency-aware neural representation and using stabilization techniques.", "motivation": "To explore the untapped generative potential of discriminative models like CLIP without modifying its weights.", "method": "Uses a frequency-aware implicit neural representation, adversarially robust initialization, Orthogonal Procrustes projection, and a blending loss to stabilize inverse mapping.", "result": "Enables text-to-image generation, style transfer, and image reconstruction without altering CLIP.", "conclusion": "Discriminative models like CLIP may have hidden generative capabilities."}}
{"id": "2504.13865", "pdf": "https://arxiv.org/pdf/2504.13865", "abs": "https://arxiv.org/abs/2504.13865", "authors": ["Fei Tang", "Haolei Xu", "Hang Zhang", "Siqi Chen", "Xingyu Wu", "Yongliang Shen", "Wenqi Zhang", "Guiyang Hou", "Zeqi Tan", "Yuchen Yan", "Kaitao Song", "Jian Shao", "Weiming Lu", "Jun Xiao", "Yueting Zhuang"], "title": "A Survey on (M)LLM-Based GUI Agents", "categories": ["cs.HC", "cs.AI", "cs.CL", "cs.CV"], "comment": null, "summary": "Graphical User Interface (GUI) Agents have emerged as a transformative\nparadigm in human-computer interaction, evolving from rule-based automation\nscripts to sophisticated AI-driven systems capable of understanding and\nexecuting complex interface operations. This survey provides a comprehensive\nexamination of the rapidly advancing field of LLM-based GUI Agents,\nsystematically analyzing their architectural foundations, technical components,\nand evaluation methodologies. We identify and analyze four fundamental\ncomponents that constitute modern GUI Agents: (1) perception systems that\nintegrate text-based parsing with multimodal understanding for comprehensive\ninterface comprehension; (2) exploration mechanisms that construct and maintain\nknowledge bases through internal modeling, historical experience, and external\ninformation retrieval; (3) planning frameworks that leverage advanced reasoning\nmethodologies for task decomposition and execution; and (4) interaction systems\nthat manage action generation with robust safety controls. Through rigorous\nanalysis of these components, we reveal how recent advances in large language\nmodels and multimodal learning have revolutionized GUI automation across\ndesktop, mobile, and web platforms. We critically examine current evaluation\nframeworks, highlighting methodological limitations in existing benchmarks\nwhile proposing directions for standardization. This survey also identifies key\ntechnical challenges, including accurate element localization, effective\nknowledge retrieval, long-horizon planning, and safety-aware execution control,\nwhile outlining promising research directions for enhancing GUI Agents'\ncapabilities. Our systematic review provides researchers and practitioners with\na thorough understanding of the field's current state and offers insights into\nfuture developments in intelligent interface automation.", "AI": {"tldr": "A survey on LLM-based GUI Agents, covering their architecture, components, and evaluation, while highlighting challenges and future directions.", "motivation": "To systematically analyze the advancements in GUI Agents, driven by AI and LLMs, and their impact on human-computer interaction.", "method": "Examines four core components: perception, exploration, planning, and interaction systems, alongside evaluation frameworks.", "result": "Identifies key challenges like element localization and knowledge retrieval, and proposes future research directions.", "conclusion": "Provides a comprehensive review of GUI Agents, offering insights for researchers and practitioners to advance the field."}}
{"id": "2502.01458", "pdf": "https://arxiv.org/pdf/2502.01458", "abs": "https://arxiv.org/abs/2502.01458", "authors": ["Wei Yao", "Wenkai Yang", "Gengze Xu", "Ziqiao Wang", "Yankai Lin", "Yong Liu"], "title": "The Capabilities and Limitations of Weak-to-Strong Generalization: Generalization and Calibration", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "Weak-to-strong generalization, where weakly supervised strong models\noutperform their weaker teachers, offers a promising approach to aligning\nsuperhuman models with human values. To deepen the understanding of this\napproach, we provide theoretical insights into its capabilities and\nlimitations. First, in the classification setting, we establish upper and lower\ngeneralization error bounds for the strong model, identifying the primary\nlimitations as stemming from the weak model's generalization error and the\noptimization objective itself. Additionally, we derive lower and upper bounds\non the calibration error of the strong model. These theoretical bounds reveal\ntwo critical insights: (1) the weak model should demonstrate strong\ngeneralization performance and maintain well-calibrated predictions, and (2)\nthe strong model's training process must strike a careful balance, as excessive\noptimization could undermine its generalization capability by over-relying on\nthe weak supervision signals. Finally, in the regression setting, we extend the\nwork of Charikar et al. (2024) to a loss function based on Kullback-Leibler\n(KL) divergence, offering guarantees that the strong student can outperform its\nweak teacher by at least the magnitude of their disagreement. We conduct\nsufficient experiments to validate our theory.", "AI": {"tldr": "The paper explores weak-to-strong generalization, providing theoretical bounds on generalization and calibration errors, and validates findings with experiments.", "motivation": "To understand and improve the alignment of superhuman models with human values through weak-to-strong generalization.", "method": "Theoretical analysis of generalization and calibration errors in classification and regression settings, with experimental validation.", "result": "Identified key limitations and insights: weak model's generalization and calibration are critical, and strong model's optimization must balance reliance on weak signals.", "conclusion": "Weak-to-strong generalization is promising but requires careful design of weak models and optimization processes to ensure strong performance."}}
{"id": "2505.20015", "pdf": "https://arxiv.org/pdf/2505.20015", "abs": "https://arxiv.org/abs/2505.20015", "authors": ["Ramon Ferrer-i-Cancho"], "title": "On the class of coding optimality of human languages and the origins of Zipf's law", "categories": ["cs.CL", "physics.soc-ph"], "comment": null, "summary": "Here we present a new class of optimality for coding systems. Members of that\nclass are displaced linearly from optimal coding and thus exhibit Zipf's law,\nnamely a power-law distribution of frequency ranks. Within that class, Zipf's\nlaw, the size-rank law and the size-probability law form a group-like\nstructure. We identify human languages that are members of the class. All\nlanguages showing sufficient agreement with Zipf's law are potential members of\nthe class. In contrast, there are communication systems in other species that\ncannot be members of that class for exhibiting an exponential distribution\ninstead but dolphins and humpback whales might. We provide a new insight into\nplots of frequency versus rank in double logarithmic scale. For any system, a\nstraight line in that scale indicates that the lengths of optimal codes under\nnon-singular coding and under uniquely decodable encoding are displaced by a\nlinear function whose slope is the exponent of Zipf's law. For systems under\ncompression and constrained to be uniquely decodable, such a straight line may\nindicate that the system is coding close to optimality. We provide support for\nthe hypothesis that Zipf's law originates from compression and define testable\nconditions for the emergence of Zipf's law in compressing systems.", "AI": {"tldr": "The paper introduces a new class of optimality for coding systems, linking Zipf's law to linear displacement from optimal coding, and identifies human languages as members of this class.", "motivation": "To explore the connection between Zipf's law and optimal coding, and to classify communication systems based on their adherence to power-law distributions.", "method": "The study analyzes coding systems, focusing on linear displacement from optimality, and examines human languages and other species' communication systems for adherence to Zipf's law.", "result": "Human languages fit the new class, while some animal communication systems (e.g., dolphins, humpback whales) might, but others with exponential distributions cannot. A straight line in double logarithmic plots indicates optimal coding.", "conclusion": "Zipf's law likely stems from compression, and the study provides testable conditions for its emergence in compressing systems."}}
{"id": "2505.23637", "pdf": "https://arxiv.org/pdf/2505.23637", "abs": "https://arxiv.org/abs/2505.23637", "authors": ["Dashti A. Ali", "Richard K. G. Do", "William R. Jarnagin", "Aras T. Asaad", "Amber L. Simpson"], "title": "Comparing the Effects of Persistence Barcodes Aggregation and Feature Concatenation on Medical Imaging", "categories": ["cs.CV", "cs.AI"], "comment": "16 pages, 8 figures", "summary": "In medical image analysis, feature engineering plays an important role in the\ndesign and performance of machine learning models. Persistent homology (PH),\nfrom the field of topological data analysis (TDA), demonstrates robustness and\nstability to data perturbations and addresses the limitation from traditional\nfeature extraction approaches where a small change in input results in a large\nchange in feature representation. Using PH, we store persistent topological and\ngeometrical features in the form of the persistence barcode whereby large bars\nrepresent global topological features and small bars encapsulate geometrical\ninformation of the data. When multiple barcodes are computed from 2D or 3D\nmedical images, two approaches can be used to construct the final topological\nfeature vector in each dimension: aggregating persistence barcodes followed by\nfeaturization or concatenating topological feature vectors derived from each\nbarcode. In this study, we conduct a comprehensive analysis across diverse\nmedical imaging datasets to compare the effects of the two aforementioned\napproaches on the performance of classification models. The results of this\nanalysis indicate that feature concatenation preserves detailed topological\ninformation from individual barcodes, yields better classification performance\nand is therefore a preferred approach when conducting similar experiments.", "AI": {"tldr": "The paper compares two methods for constructing topological feature vectors from persistence barcodes in medical image analysis, finding that concatenation outperforms aggregation.", "motivation": "To address the limitations of traditional feature extraction in medical image analysis, the study leverages persistent homology for robust feature representation.", "method": "The study compares two approaches: aggregating persistence barcodes followed by featurization versus concatenating topological feature vectors from individual barcodes.", "result": "Feature concatenation preserves detailed topological information and yields better classification performance.", "conclusion": "Concatenating topological feature vectors is the preferred approach for similar experiments in medical image analysis."}}
{"id": "2504.14522", "pdf": "https://arxiv.org/pdf/2504.14522", "abs": "https://arxiv.org/abs/2504.14522", "authors": ["Liudmila Zavolokina", "Kilian Sprenkamp", "Zoya Katashinskaya", "Daniel Gordon Jones"], "title": "Biased by Design: Leveraging AI Inherent Biases to Enhance Critical Thinking of News Readers", "categories": ["cs.HC", "cs.AI"], "comment": "European Conference on Information Systems (ECIS)", "summary": "This paper explores the design of a propaganda detection tool using Large\nLanguage Models (LLMs). Acknowledging the inherent biases in AI models,\nespecially in political contexts, we investigate how these biases might be\nleveraged to enhance critical thinking in news consumption. Countering the\ntypical view of AI biases as detrimental, our research proposes strategies of\nuser choice and personalization in response to a user's political stance,\napplying psychological concepts of confirmation bias and cognitive dissonance.\nWe present findings from a qualitative user study, offering insights and design\nrecommendations (bias awareness, personalization and choice, and gradual\nintroduction of diverse perspectives) for AI tools in propaganda detection.", "AI": {"tldr": "The paper proposes a propaganda detection tool using LLMs, leveraging AI biases to enhance critical thinking in news consumption through user choice and personalization.", "motivation": "To address AI biases in political contexts and use them to improve critical thinking in news consumption.", "method": "Qualitative user study investigating strategies like personalization and choice based on political stance, applying psychological concepts.", "result": "Findings include design recommendations: bias awareness, personalization, and gradual introduction of diverse perspectives.", "conclusion": "The research suggests leveraging AI biases constructively for propaganda detection tools, emphasizing user-centric design."}}
{"id": "2502.06244", "pdf": "https://arxiv.org/pdf/2502.06244", "abs": "https://arxiv.org/abs/2502.06244", "authors": ["Zeman Li", "Yuan Deng", "Peilin Zhong", "Meisam Razaviyayn", "Vahab Mirrokni"], "title": "PiKE: Adaptive Data Mixing for Large-Scale Multi-Task Learning Under Low Gradient Conflicts", "categories": ["cs.LG"], "comment": null, "summary": "Modern foundation models are trained on diverse datasets to enhance\ngeneralization across tasks and domains A central challenge in this process is\ndetermining how to effectively mix and sample data from multiple sources This\nnaturally leads to a multitask learning (MTL) perspective While prior work in\nMTL has emphasized mitigating gradient conflicts we observe that largescale\npretraining scenariossuch as multilingual or multidomain trainingoften exhibit\nlittle to no gradient conflict Motivated by this observation we propose PiKE\n(Positive gradient interaction-based K-task weights Estimator) an adaptive data\nmixing algorithm that dynamically adjusts sampling weights during training PiKE\nexploits nonconflicting gradient interactions to minimize a neartight upper\nbound on the average loss decrease at each step while incurring negligible\ncomputational overhead We provide theoretical convergence guarantees and show\nthat PiKE outperforms static and nonadaptive mixing baselines Furthermore we\nextend PiKE to promote balanced learning across tasks Extensive experiments on\nlargescale language model pretraining confirm that PiKE achieves faster\nconvergence and improved downstream performance compared to existing approaches", "AI": {"tldr": "PiKE is an adaptive data mixing algorithm for multitask learning that dynamically adjusts sampling weights by exploiting non-conflicting gradient interactions, improving convergence and performance.", "motivation": "Prior work in multitask learning focused on gradient conflicts, but large-scale pretraining often lacks such conflicts. PiKE addresses this gap by leveraging non-conflicting gradient interactions.", "method": "PiKE dynamically adjusts sampling weights during training to minimize a near-tight upper bound on average loss decrease, with negligible computational overhead.", "result": "PiKE outperforms static and nonadaptive baselines, achieving faster convergence and better downstream performance in large-scale language model pretraining.", "conclusion": "PiKE is an effective adaptive data mixing algorithm for multitask learning, validated by theoretical guarantees and experimental results."}}
{"id": "2505.20538", "pdf": "https://arxiv.org/pdf/2505.20538", "abs": "https://arxiv.org/abs/2505.20538", "authors": ["Sebastian Antony Joseph", "Syed Murtaza Husain", "Stella S. R. Offner", "St\u00e9phanie Juneau", "Paul Torrey", "Adam S. Bolton", "Juan P. Farias", "Niall Gaffney", "Greg Durrett", "Junyi Jessy Li"], "title": "AstroVisBench: A Code Benchmark for Scientific Computing and Visualization in Astronomy", "categories": ["cs.CL", "astro-ph.IM", "cs.LG"], "comment": null, "summary": "Large Language Models (LLMs) are being explored for applications in\nscientific research, including their capabilities to synthesize literature,\nanswer research questions, generate research ideas, and even conduct\ncomputational experiments. Ultimately, our goal is for these to help scientists\nderive novel scientific insights. In many areas of science, such insights often\narise from processing and visualizing data to understand its patterns. However,\nevaluating whether an LLM-mediated scientific workflow produces outputs\nconveying the correct scientific insights is challenging to evaluate and has\nnot been addressed in past work. We introduce AstroVisBench, the first\nbenchmark for both scientific computing and visualization in the astronomy\ndomain. AstroVisBench judges a language model's ability to both (1) create\nastronomy-specific workflows to process and analyze data and (2) visualize the\nresults of these workflows through complex plots. Our evaluation of\nvisualizations uses a novel LLM-as-a-judge workflow, which is validated against\nannotation by five professional astronomers. Using AstroVisBench we present an\nevaluation of state-of-the-art language models, showing a significant gap in\ntheir ability to engage in astronomy research as useful assistants. This\nevaluation provides a strong end-to-end evaluation for AI scientists that\noffers a path forward for the development of visualization-based workflows,\nwhich are central to a broad range of domains from physics to biology.", "AI": {"tldr": "AstroVisBench is introduced as the first benchmark for evaluating LLMs in astronomy-specific workflows and visualization, revealing gaps in their utility for scientific research.", "motivation": "To assess LLMs' ability to generate correct scientific insights through data processing and visualization, a capability not previously evaluated.", "method": "Developed AstroVisBench to test LLMs on astronomy workflows and visualization, validated by professional astronomers.", "result": "State-of-the-art LLMs show significant limitations in assisting astronomy research effectively.", "conclusion": "AstroVisBench provides a foundation for improving LLMs in visualization-based scientific workflows across various domains."}}
{"id": "2505.24371", "pdf": "https://arxiv.org/pdf/2505.24371", "abs": "https://arxiv.org/abs/2505.24371", "authors": ["Md Intisar Chowdhury", "Kittinun Aukkapinyo", "Hiroshi Fujimura", "Joo Ann Woo", "Wasu Wasusatein", "Fadoua Ghourabi"], "title": "Grid-LOGAT: Grid Based Local and Global Area Transcription for Video Question Answering", "categories": ["cs.CV", "cs.AI"], "comment": "Copyright 2025 IEEE. Personal use of this material is permitted.\n  Permission from IEEE must be obtained for all other uses, in any current or\n  future media, including reprinting/republishing this material for advertising\n  or promotional purposes, creating new collective works, for resale or\n  redistribution to servers or lists, or reuse of any copyrighted component of\n  this work in other works", "summary": "In this paper, we propose a Grid-based Local and Global Area Transcription\n(Grid-LoGAT) system for Video Question Answering (VideoQA). The system operates\nin two phases. First, extracting text transcripts from video frames using a\nVision-Language Model (VLM). Next, processing questions using these transcripts\nto generate answers through a Large Language Model (LLM). This design ensures\nimage privacy by deploying the VLM on edge devices and the LLM in the cloud. To\nimprove transcript quality, we propose grid-based visual prompting, which\nextracts intricate local details from each grid cell and integrates them with\nglobal information. Evaluation results show that Grid-LoGAT, using the\nopen-source VLM (LLaVA-1.6-7B) and LLM (Llama-3.1-8B), outperforms\nstate-of-the-art methods with similar baseline models on NExT-QA and STAR-QA\ndatasets with an accuracy of 65.9% and 50.11% respectively. Additionally, our\nmethod surpasses the non-grid version by 24 points on localization-based\nquestions we created using NExT-QA. (This paper is accepted by IEEE ICIP 2025.)", "AI": {"tldr": "Grid-LoGAT system for VideoQA uses grid-based visual prompting and edge-cloud deployment to enhance transcript quality and privacy, outperforming state-of-the-art methods.", "motivation": "To improve VideoQA accuracy while ensuring image privacy by leveraging edge-cloud deployment and grid-based visual prompting.", "method": "Two-phase system: VLM extracts text transcripts from video frames, LLM processes questions using transcripts. Grid-based visual prompting enhances local and global details.", "result": "Outperforms state-of-the-art methods on NExT-QA (65.9%) and STAR-QA (50.11%) datasets, with a 24-point improvement on localization questions.", "conclusion": "Grid-LoGAT is effective for VideoQA, balancing privacy and performance through innovative grid-based prompting and edge-cloud architecture."}}
{"id": "2505.04670", "pdf": "https://arxiv.org/pdf/2505.04670", "abs": "https://arxiv.org/abs/2505.04670", "authors": ["Charly Reux", "Mathieu Acher", "Djamel Eddine Khelladi", "Olivier Barais", "Cl\u00e9ment Quinton"], "title": "LLM Code Customization with Visual Results: A Benchmark on TikZ", "categories": ["cs.SE", "cs.AI"], "comment": null, "summary": "With the rise of AI-based code generation, customizing existing code out of\nnatural language instructions to modify visual results -such as figures or\nimages -has become possible, promising to reduce the need for deep programming\nexpertise. However, even experienced developers can struggle with this task, as\nit requires identifying relevant code regions (feature location), generating\nvalid code variants, and ensuring the modifications reliably align with user\nintent. In this paper, we introduce vTikZ, the first benchmark designed to\nevaluate the ability of Large Language Models (LLMs) to customize code while\npreserving coherent visual outcomes. Our benchmark consists of carefully\ncurated vTikZ editing scenarios, parameterized ground truths, and a reviewing\ntool that leverages visual feedback to assess correctness. Empirical evaluation\nwith stateof-the-art LLMs shows that existing solutions struggle to reliably\nmodify code in alignment with visual intent, highlighting a gap in current\nAI-assisted code editing approaches. We argue that vTikZ opens new research\ndirections for integrating LLMs with visual feedback mechanisms to improve code\ncustomization tasks in various domains beyond TikZ, including image processing,\nart creation, Web design, and 3D modeling.", "AI": {"tldr": "vTikZ is a benchmark evaluating LLMs' ability to customize code for visual outcomes, revealing gaps in AI-assisted code editing.", "motivation": "AI-based code generation struggles with aligning code modifications to visual intent, even for experienced developers.", "method": "vTikZ includes curated editing scenarios, ground truths, and a visual feedback tool to assess LLMs' performance.", "result": "State-of-the-art LLMs struggle to reliably align code changes with visual intent.", "conclusion": "vTikZ highlights the need for integrating visual feedback with LLMs to improve code customization in various domains."}}
{"id": "2502.06597", "pdf": "https://arxiv.org/pdf/2502.06597", "abs": "https://arxiv.org/abs/2502.06597", "authors": ["Nikita P. Kalinin", "Jalaj Upadhyay", "Christoph H. Lampert"], "title": "Continual Release Moment Estimation with Differential Privacy", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "We propose Joint Moment Estimation (JME), a method for continually and\nprivately estimating both the first and second moments of data with reduced\nnoise compared to naive approaches. JME uses the matrix mechanism and a joint\nsensitivity analysis to allow the second moment estimation with no additional\nprivacy cost, thereby improving accuracy while maintaining privacy. We\ndemonstrate JME's effectiveness in two applications: estimating the running\nmean and covariance matrix for Gaussian density estimation, and model training\nwith DP-Adam on CIFAR-10.", "AI": {"tldr": "JME is a method for privately estimating first and second moments of data with reduced noise, improving accuracy without extra privacy cost.", "motivation": "To enhance accuracy in private moment estimation while maintaining privacy, addressing limitations of naive approaches.", "method": "Uses the matrix mechanism and joint sensitivity analysis for second moment estimation without additional privacy cost.", "result": "Demonstrated effectiveness in running mean/covariance estimation for Gaussian density and DP-Adam training on CIFAR-10.", "conclusion": "JME provides a more accurate and efficient solution for private moment estimation."}}
{"id": "2505.20645", "pdf": "https://arxiv.org/pdf/2505.20645", "abs": "https://arxiv.org/abs/2505.20645", "authors": ["Kai Chen", "Zihao He", "Taiwei Shi", "Kristina Lerman"], "title": "STEER-BENCH: A Benchmark for Evaluating the Steerability of Large Language Models", "categories": ["cs.CL"], "comment": null, "summary": "Steerability, or the ability of large language models (LLMs) to adapt outputs\nto align with diverse community-specific norms, perspectives, and communication\nstyles, is critical for real-world applications but remains under-evaluated. We\nintroduce Steer-Bench, a benchmark for assessing population-specific steering\nusing contrasting Reddit communities. Covering 30 contrasting subreddit pairs\nacross 19 domains, Steer-Bench includes over 10,000 instruction-response pairs\nand validated 5,500 multiple-choice question with corresponding silver labels\nto test alignment with diverse community norms. Our evaluation of 13 popular\nLLMs using Steer-Bench reveals that while human experts achieve an accuracy of\n81% with silver labels, the best-performing models reach only around 65%\naccuracy depending on the domain and configuration. Some models lag behind\nhuman-level alignment by over 15 percentage points, highlighting significant\ngaps in community-sensitive steerability. Steer-Bench is a benchmark to\nsystematically assess how effectively LLMs understand community-specific\ninstructions, their resilience to adversarial steering attempts, and their\nability to accurately represent diverse cultural and ideological perspectives.", "AI": {"tldr": "Steer-Bench is a benchmark to evaluate LLMs' ability to align outputs with community-specific norms, revealing gaps in steerability compared to human experts.", "motivation": "Assessing LLMs' steerability for real-world applications, as current evaluations underrepresent diverse community norms.", "method": "Steer-Bench uses 30 contrasting subreddit pairs, 10,000 instruction-response pairs, and 5,500 multiple-choice questions with silver labels.", "result": "Best LLMs achieve ~65% accuracy, lagging behind human experts (81%), with some models 15+ points behind.", "conclusion": "Steer-Bench highlights significant gaps in LLMs' community-sensitive steerability, emphasizing the need for improved alignment with diverse perspectives."}}
{"id": "2506.01144", "pdf": "https://arxiv.org/pdf/2506.01144", "abs": "https://arxiv.org/abs/2506.01144", "authors": ["Ariel Shaulov", "Itay Hazan", "Lior Wolf", "Hila Chefer"], "title": "FlowMo: Variance-Based Flow Guidance for Coherent Motion in Video Generation", "categories": ["cs.CV"], "comment": null, "summary": "Text-to-video diffusion models are notoriously limited in their ability to\nmodel temporal aspects such as motion, physics, and dynamic interactions.\nExisting approaches address this limitation by retraining the model or\nintroducing external conditioning signals to enforce temporal consistency. In\nthis work, we explore whether a meaningful temporal representation can be\nextracted directly from the predictions of a pre-trained model without any\nadditional training or auxiliary inputs. We introduce FlowMo, a novel\ntraining-free guidance method that enhances motion coherence using only the\nmodel's own predictions in each diffusion step. FlowMo first derives an\nappearance-debiased temporal representation by measuring the distance between\nlatents corresponding to consecutive frames. This highlights the implicit\ntemporal structure predicted by the model. It then estimates motion coherence\nby measuring the patch-wise variance across the temporal dimension and guides\nthe model to reduce this variance dynamically during sampling. Extensive\nexperiments across multiple text-to-video models demonstrate that FlowMo\nsignificantly improves motion coherence without sacrificing visual quality or\nprompt alignment, offering an effective plug-and-play solution for enhancing\nthe temporal fidelity of pre-trained video diffusion models.", "AI": {"tldr": "FlowMo is a training-free method to improve motion coherence in text-to-video diffusion models by leveraging the model's own predictions without retraining or external inputs.", "motivation": "Existing text-to-video models struggle with temporal aspects like motion and physics, often requiring retraining or external signals. FlowMo explores extracting temporal coherence directly from pre-trained models.", "method": "FlowMo derives a temporal representation from latent distances between frames, estimates motion coherence via patch-wise variance, and dynamically guides the model to reduce variance during sampling.", "result": "FlowMo significantly enhances motion coherence in pre-trained models without compromising visual quality or prompt alignment.", "conclusion": "FlowMo provides an effective, plug-and-play solution for improving temporal fidelity in video diffusion models without additional training."}}
{"id": "2505.06459", "pdf": "https://arxiv.org/pdf/2505.06459", "abs": "https://arxiv.org/abs/2505.06459", "authors": ["Pablo Flores", "Olga Graf", "Pavlos Protopapas", "Karim Pichara"], "title": "Improved Uncertainty Quantification in Physics-Informed Neural Networks Using Error Bounds and Solution Bundles", "categories": ["cs.LG", "cs.AI", "physics.comp-ph", "stat.ML"], "comment": null, "summary": "Physics-Informed Neural Networks (PINNs) have been widely used to obtain\nsolutions to various physical phenomena modeled as Differential Equations. As\nPINNs are not naturally equipped with mechanisms for Uncertainty\nQuantification, some work has been done to quantify the different uncertainties\nthat arise when dealing with PINNs. In this paper, we use a two-step procedure\nto train Bayesian Neural Networks that provide uncertainties over the solutions\nto differential equation systems provided by PINNs. We use available error\nbounds over PINNs to formulate a heteroscedastic variance that improves the\nuncertainty estimation. Furthermore, we solve forward problems and utilize the\nobtained uncertainties when doing parameter estimation in inverse problems in\ncosmology.", "AI": {"tldr": "The paper proposes a two-step method to train Bayesian Neural Networks for uncertainty quantification in Physics-Informed Neural Networks (PINNs), improving uncertainty estimation using error bounds and applying it to cosmology problems.", "motivation": "PINNs lack built-in uncertainty quantification, and existing methods need improvement for better reliability in solving differential equations.", "method": "A two-step procedure trains Bayesian Neural Networks, incorporating heteroscedastic variance based on PINN error bounds for better uncertainty estimation.", "result": "Improved uncertainty quantification for PINNs, demonstrated in solving forward problems and parameter estimation in cosmology.", "conclusion": "The method enhances uncertainty estimation in PINNs, proving useful for both forward and inverse problems in cosmology."}}
{"id": "2502.09564", "pdf": "https://arxiv.org/pdf/2502.09564", "abs": "https://arxiv.org/abs/2502.09564", "authors": ["Massimiliano Ciranni", "Vito Paolo Pastore", "Roberto Di Via", "Enzo Tartaglione", "Francesca Odone", "Vittorio Murino"], "title": "Diffusing DeBias: Synthetic Bias Amplification for Model Debiasing", "categories": ["cs.LG", "cs.CV", "I.4; I.5"], "comment": "18 Pages, 9 Figures", "summary": "Deep learning model effectiveness in classification tasks is often challenged\nby the quality and quantity of training data whenever they are affected by\nstrong spurious correlations between specific attributes and target labels.\nThis results in a form of bias affecting training data, which typically leads\nto unrecoverable weak generalization in prediction. This paper aims at facing\nthis problem by leveraging bias amplification with generated synthetic data: we\nintroduce Diffusing DeBias (DDB), a novel approach acting as a plug-in for\ncommon methods of unsupervised model debiasing exploiting the inherent\nbias-learning tendency of diffusion models in data generation. Specifically,\nour approach adopts conditional diffusion models to generate synthetic\nbias-aligned images, which replace the original training set for learning an\neffective bias amplifier model that we subsequently incorporate into an\nend-to-end and a two-step unsupervised debiasing approach. By tackling the\nfundamental issue of bias-conflicting training samples memorization in learning\nauxiliary models, typical of this type of techniques, our proposed method beats\ncurrent state-of-the-art in multiple benchmark datasets, demonstrating its\npotential as a versatile and effective tool for tackling bias in deep learning\nmodels.", "AI": {"tldr": "The paper introduces Diffusing DeBias (DDB), a method using synthetic data from diffusion models to address bias in deep learning classification tasks, outperforming current debiasing techniques.", "motivation": "Deep learning models often suffer from bias due to spurious correlations in training data, leading to poor generalization. The paper aims to tackle this by leveraging bias amplification with synthetic data.", "method": "DDB uses conditional diffusion models to generate synthetic bias-aligned images, replacing the original training set to learn a bias amplifier model. This is integrated into unsupervised debiasing approaches.", "result": "DDB outperforms state-of-the-art methods on multiple benchmark datasets by addressing bias-conflicting sample memorization.", "conclusion": "DDB is a versatile and effective tool for mitigating bias in deep learning models, demonstrating superior performance over existing techniques."}}
{"id": "2505.20875", "pdf": "https://arxiv.org/pdf/2505.20875", "abs": "https://arxiv.org/abs/2505.20875", "authors": ["Jiyoung Lee", "Seungho Kim", "Jieun Han", "Jun-Min Lee", "Kitaek Kim", "Alice Oh", "Edward Choi"], "title": "Trans-EnV: A Framework for Evaluating the Linguistic Robustness of LLMs Against English Varieties", "categories": ["cs.CL", "cs.AI"], "comment": "27 pages, 6 figures, 16 tables", "summary": "Large Language Models (LLMs) are predominantly evaluated on Standard American\nEnglish (SAE), often overlooking the diversity of global English varieties.\nThis narrow focus may raise fairness concerns as degraded performance on\nnon-standard varieties can lead to unequal benefits for users worldwide.\nTherefore, it is critical to extensively evaluate the linguistic robustness of\nLLMs on multiple non-standard English varieties. We introduce Trans-EnV, a\nframework that automatically transforms SAE datasets into multiple English\nvarieties to evaluate the linguistic robustness. Our framework combines (1)\nlinguistics expert knowledge to curate variety-specific features and\ntransformation guidelines from linguistic literature and corpora, and (2)\nLLM-based transformations to ensure both linguistic validity and scalability.\nUsing Trans-EnV, we transform six benchmark datasets into 38 English varieties\nand evaluate seven state-of-the-art LLMs. Our results reveal significant\nperformance disparities, with accuracy decreasing by up to 46.3% on\nnon-standard varieties. These findings highlight the importance of\ncomprehensive linguistic robustness evaluation across diverse English\nvarieties. Each construction of Trans-EnV was validated through rigorous\nstatistical testing and consultation with a researcher in the field of second\nlanguage acquisition, ensuring its linguistic validity. Our code and datasets\nare publicly available at https://github.com/jiyounglee-0523/TransEnV and\nhttps://huggingface.co/collections/jiyounglee0523/transenv-681eadb3c0c8cf363b363fb1.", "AI": {"tldr": "Trans-EnV evaluates LLMs on diverse English varieties, revealing performance disparities up to 46.3% lower on non-standard varieties.", "motivation": "Current LLM evaluations focus on Standard American English, neglecting global English diversity, raising fairness concerns.", "method": "Trans-EnV transforms SAE datasets into 38 English varieties using expert knowledge and LLM-based transformations.", "result": "Performance drops significantly on non-standard varieties, with accuracy decreasing by up to 46.3%.", "conclusion": "Comprehensive linguistic robustness evaluation is crucial for fair LLM performance across diverse English varieties."}}
{"id": "2506.01532", "pdf": "https://arxiv.org/pdf/2506.01532", "abs": "https://arxiv.org/abs/2506.01532", "authors": ["Pedro C. Neto", "Naser Damer", "Jaime S. Cardoso", "Ana F. Sequeira"], "title": "Moving Beyond Discrete Categories: Continuous Demographic Labels for Fair Facial Recognition", "categories": ["cs.CV"], "comment": "Under review", "summary": "Bias has been a constant in face recognition models. Over the years,\nresearchers have looked at it from both the model and the data point of view.\nHowever, their approach to mitigation of data bias was limited and lacked\ninsight on the real nature of the problem. Here, in this document, we propose\nto revise our use of ethnicity labels as a continuous variable instead of a\ndiscrete value per identity. We validate our formulation both experimentally\nand theoretically, showcasing that not all identities from one ethnicity\ncontribute equally to the balance of the dataset; thus, having the same number\nof identities per ethnicity does not represent a balanced dataset. We further\nshow that models trained on datasets balanced in the continuous space\nconsistently outperform models trained on data balanced in the discrete space.\nWe trained more than 65 different models, and created more than 20 subsets of\nthe original datasets.", "AI": {"tldr": "The paper proposes treating ethnicity labels as continuous variables to better address bias in face recognition models, showing improved performance over discrete labeling.", "motivation": "Bias in face recognition models persists due to limited approaches in mitigating data bias, particularly in how ethnicity labels are used.", "method": "Ethnicity labels are revised as continuous variables, validated experimentally and theoretically, with models trained on datasets balanced in this continuous space.", "result": "Models trained on continuously balanced datasets outperform those using discrete labels, supported by extensive experimentation (65+ models, 20+ dataset subsets).", "conclusion": "Treating ethnicity as a continuous variable provides a more effective way to balance datasets and reduce bias in face recognition models."}}
{"id": "2505.10360", "pdf": "https://arxiv.org/pdf/2505.10360", "abs": "https://arxiv.org/abs/2505.10360", "authors": ["Victor Petr\u00e9n Bach Hansen", "Lasse Krogsb\u00f8ll", "Jonas Lyngs\u00f8", "Mathias Baltzersen", "Andreas Motzfeldt", "Kevin Pelgrims", "Lars Maal\u00f8e"], "title": "FactsR: A Safer Method for Producing High Quality Healthcare Documentation", "categories": ["cs.LG", "cs.AI", "stat.AP"], "comment": null, "summary": "There are now a multitude of AI-scribing solutions for healthcare promising\nthe utilization of large language models for ambient documentation. However,\nthese AI scribes still rely on one-shot, or few-shot prompts for generating\nnotes after the consultation has ended, employing little to no reasoning. This\nrisks long notes with an increase in hallucinations, misrepresentation of the\nintent of the clinician, and reliance on the proofreading of the clinician to\ncatch errors. A dangerous combination for patient safety if vigilance is\ncompromised by workload and fatigue. In this paper, we introduce a method for\nextracting salient clinical information in real-time alongside the healthcare\nconsultation, denoted Facts, and use that information recursively to generate\nthe final note. The FactsR method results in more accurate and concise notes by\nplacing the clinician-in-the-loop of note generation, while opening up new use\ncases within real-time decision support.", "AI": {"tldr": "The paper introduces FactsR, a method for real-time extraction of clinical information during consultations to generate more accurate and concise notes, addressing issues like hallucinations and clinician workload.", "motivation": "Current AI scribes rely on post-consultation prompts, leading to errors and inefficiencies, which risks patient safety due to clinician workload and fatigue.", "method": "The FactsR method extracts salient clinical information (Facts) in real-time during consultations and uses it recursively to generate final notes.", "result": "FactsR produces more accurate and concise notes by involving clinicians in the note-generation process and enables real-time decision support.", "conclusion": "FactsR improves note accuracy and conciseness while enhancing clinician involvement and enabling new real-time applications."}}
{"id": "2502.09591", "pdf": "https://arxiv.org/pdf/2502.09591", "abs": "https://arxiv.org/abs/2502.09591", "authors": ["Chuanhui Liu", "Xiao Wang"], "title": "Censor Dependent Variational Inference", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "This paper provides a comprehensive analysis of variational inference in\nlatent variable models for survival analysis, emphasizing the distinctive\nchallenges associated with applying variational methods to survival data. We\nidentify a critical weakness in the existing methodology, demonstrating how a\npoorly designed variational distribution may hinder the objective of survival\nanalysis tasks - modeling time-to-event distributions. We prove that the\noptimal variational distribution, which perfectly bounds the log-likelihood,\nmay depend on the censoring mechanism. To address this issue, we propose\ncensor-dependent variational inference (CDVI), tailored for latent variable\nmodels in survival analysis. More practically, we introduce CD-CVAE, a\nV-structure Variational Autoencoder (VAE) designed for the scalable\nimplementation of CDVI. Further discussion extends some existing theories and\ntraining techniques to survival analysis. Extensive experiments validate our\nanalysis and demonstrate significant improvements in the estimation of\nindividual survival distributions.", "AI": {"tldr": "The paper analyzes variational inference in survival analysis, identifies flaws in existing methods, and proposes censor-dependent variational inference (CDVI) and CD-CVAE for improved survival distribution estimation.", "motivation": "To address the challenges of applying variational methods to survival data, particularly the impact of poorly designed variational distributions on modeling time-to-event distributions.", "method": "Proposes CDVI, a censor-dependent variational inference method, and CD-CVAE, a VAE for scalable CDVI implementation. Extends theories and training techniques for survival analysis.", "result": "Experiments show significant improvements in estimating individual survival distributions.", "conclusion": "CDVI and CD-CVAE effectively address variational inference challenges in survival analysis, enhancing accuracy in survival distribution estimation."}}
{"id": "2505.21082", "pdf": "https://arxiv.org/pdf/2505.21082", "abs": "https://arxiv.org/abs/2505.21082", "authors": ["Jieyong Kim", "Tongyoung Kim", "Soojin Yoon", "Jaehyung Kim", "Dongha Lee"], "title": "LLMs Think, But Not In Your Flow: Reasoning-Level Personalization for Black-Box Large Language Models", "categories": ["cs.CL"], "comment": null, "summary": "Large language models (LLMs) have recently achieved impressive performance\nacross a wide range of natural language tasks and are now widely used in\nreal-world applications. Among them, black-box LLMs--served via APIs without\naccess to model internals--are especially dominant due to their scalability and\nease of deployment. Despite their strong capabilities, these models typically\nproduce generalized responses that overlook personal preferences and reasoning\nstyles. This has led to growing interest in black-box LLM personalization,\nwhich aims to tailor model outputs to user-specific context without modifying\nmodel parameters. However, existing approaches primarily focus on\nresponse-level personalization, attempting to match final outputs without\nmodeling personal thought process. To address this limitation, we propose RPM,\na framework for reasoning-level personalization that aligns the model's\nreasoning process with a user's personalized logic. RPM first constructs\nstatistical user-specific factors by extracting and grouping\nresponse-influential features from user history. It then builds personalized\nreasoning paths that reflect how these factors are used in context. In the\ninference stage, RPM retrieves reasoning-aligned examples for new queries via\nfeature-level similarity and performs inference conditioned on the structured\nfactors and retrieved reasoning paths, enabling the model to follow\nuser-specific reasoning trajectories. This reasoning-level personalization\nenhances both predictive accuracy and interpretability by grounding model\noutputs in user-specific logic through structured information. Extensive\nexperiments across diverse tasks show that RPM consistently outperforms\nresponse-level personalization methods, demonstrating the effectiveness of\nreasoning-level personalization in black-box LLMs.", "AI": {"tldr": "RPM is a framework for reasoning-level personalization in black-box LLMs, outperforming response-level methods by aligning model reasoning with user logic.", "motivation": "Black-box LLMs lack personalization in reasoning, leading to generalized responses. RPM addresses this by tailoring reasoning processes to user-specific logic.", "method": "RPM constructs user-specific factors from history, builds personalized reasoning paths, and retrieves reasoning-aligned examples for inference.", "result": "RPM consistently outperforms response-level personalization methods in diverse tasks.", "conclusion": "Reasoning-level personalization enhances accuracy and interpretability in black-box LLMs."}}
{"id": "2506.01921", "pdf": "https://arxiv.org/pdf/2506.01921", "abs": "https://arxiv.org/abs/2506.01921", "authors": ["Minghao Liu", "Zhitao He", "Zhiyuan Fan", "Qingyun Wang", "Yi R. Fung"], "title": "MedEBench: Revisiting Text-instructed Image Editing on Medical Domain", "categories": ["cs.CV", "cs.AI"], "comment": "Project website: https://mliuby.github.io/MedEBench_Website/", "summary": "Text-guided image editing has seen rapid progress in natural image domains,\nbut its adaptation to medical imaging remains limited and lacks standardized\nevaluation. Clinically, such editing holds promise for simulating surgical\noutcomes, creating personalized teaching materials, and enhancing patient\ncommunication. To bridge this gap, we introduce MedEBench, a comprehensive\nbenchmark for evaluating text-guided medical image editing. It consists of\n1,182 clinically sourced image-prompt triplets spanning 70 tasks across 13\nanatomical regions. MedEBench offers three key contributions: (1) a clinically\nrelevant evaluation framework covering Editing Accuracy, Contextual\nPreservation, and Visual Quality, supported by detailed descriptions of\nexpected change and ROI (Region of Interest) masks; (2) a systematic comparison\nof seven state-of-the-art models, revealing common failure patterns; and (3) a\nfailure analysis protocol based on attention grounding, using IoU between\nattention maps and ROIs to identify mislocalization. MedEBench provides a solid\nfoundation for developing and evaluating reliable, clinically meaningful\nmedical image editing systems. Project website:\nhttps://mliuby.github.io/MedEBench_Website/", "AI": {"tldr": "MedEBench is a benchmark for evaluating text-guided medical image editing, addressing the lack of standardized evaluation in this domain. It includes 1,182 image-prompt triplets, evaluates seven models, and introduces a failure analysis protocol.", "motivation": "To standardize and improve text-guided medical image editing for clinical applications like surgical simulation, teaching, and patient communication.", "method": "Introduces MedEBench, a benchmark with clinically sourced image-prompt triplets, evaluation metrics (Editing Accuracy, Contextual Preservation, Visual Quality), and a failure analysis protocol using attention grounding.", "result": "Systematic comparison of seven models reveals common failure patterns, with attention grounding used to identify mislocalization issues.", "conclusion": "MedEBench provides a foundation for developing reliable, clinically meaningful medical image editing systems."}}
{"id": "2505.12894", "pdf": "https://arxiv.org/pdf/2505.12894", "abs": "https://arxiv.org/abs/2505.12894", "authors": ["Le Cheng", "Peican Zhu", "Yangming Guo", "Keke Tang", "Chao Gao", "Zhen Wang"], "title": "HyperDet: Source Detection in Hypergraphs via Interactive Relationship Construction and Feature-rich Attention Fusion", "categories": ["cs.SI", "cs.AI"], "comment": "Accepted by IJCAI25", "summary": "Hypergraphs offer superior modeling capabilities for social networks,\nparticularly in capturing group phenomena that extend beyond pairwise\ninteractions in rumor propagation. Existing approaches in rumor source\ndetection predominantly focus on dyadic interactions, which inadequately\naddress the complexity of more intricate relational structures. In this study,\nwe present a novel approach for Source Detection in Hypergraphs (HyperDet) via\nInteractive Relationship Construction and Feature-rich Attention Fusion.\nSpecifically, our methodology employs an Interactive Relationship Construction\nmodule to accurately model both the static topology and dynamic interactions\namong users, followed by the Feature-rich Attention Fusion module, which\nautonomously learns node features and discriminates between nodes using a\nself-attention mechanism, thereby effectively learning node representations\nunder the framework of accurately modeled higher-order relationships. Extensive\nexperimental validation confirms the efficacy of our HyperDet approach,\nshowcasing its superiority relative to current state-of-the-art methods.", "AI": {"tldr": "HyperDet introduces a novel method for rumor source detection in hypergraphs, outperforming existing dyadic-focused approaches by modeling higher-order interactions and using attention-based fusion.", "motivation": "Existing rumor source detection methods focus on dyadic interactions, failing to capture complex group dynamics in social networks. Hypergraphs offer better modeling for such phenomena.", "method": "HyperDet uses Interactive Relationship Construction to model static and dynamic interactions, and Feature-rich Attention Fusion to learn node representations via self-attention.", "result": "Experiments show HyperDet outperforms state-of-the-art methods in detecting rumor sources in hypergraphs.", "conclusion": "HyperDet effectively addresses the limitations of dyadic approaches, proving superior for rumor source detection in hypergraphs."}}
{"id": "2502.11673", "pdf": "https://arxiv.org/pdf/2502.11673", "abs": "https://arxiv.org/abs/2502.11673", "authors": ["Adrian M\u00fcller", "Jon Schneider", "Stratis Skoulakis", "Luca Viano", "Volkan Cevher"], "title": "Best of Both Worlds: Regret Minimization versus Minimax Play", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "In this paper, we investigate the existence of online learning algorithms\nwith bandit feedback that simultaneously guarantee $O(1)$ regret compared to a\ngiven comparator strategy, and $\\tilde{O}(\\sqrt{T})$ regret compared to any\nfixed strategy, where $T$ is the number of rounds. We provide the first\naffirmative answer to this question whenever the comparator strategy supports\nevery action. In the context of zero-sum games with min-max value zero, both in\nnormal- and extensive form, we show that our results allow us to guarantee to\nrisk at most $O(1)$ loss while being able to gain $\\Omega(T)$ from exploitable\nopponents, thereby combining the benefits of both no-regret algorithms and\nminimax play.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2505.23001", "pdf": "https://arxiv.org/pdf/2505.23001", "abs": "https://arxiv.org/abs/2505.23001", "authors": ["Yize Cheng", "Wenxiao Wang", "Mazda Moayeri", "Soheil Feizi"], "title": "DyePack: Provably Flagging Test Set Contamination in LLMs Using Backdoors", "categories": ["cs.CL"], "comment": null, "summary": "Open benchmarks are essential for evaluating and advancing large language\nmodels, offering reproducibility and transparency. However, their accessibility\nmakes them likely targets of test set contamination. In this work, we introduce\nDyePack, a framework that leverages backdoor attacks to identify models that\nused benchmark test sets during training, without requiring access to the loss,\nlogits, or any internal details of the model. Like how banks mix dye packs with\ntheir money to mark robbers, DyePack mixes backdoor samples with the test data\nto flag models that trained on it. We propose a principled design incorporating\nmultiple backdoors with stochastic targets, enabling exact false positive rate\n(FPR) computation when flagging every model. This provably prevents false\naccusations while providing strong evidence for every detected case of\ncontamination. We evaluate DyePack on five models across three datasets,\ncovering both multiple-choice and open-ended generation tasks. For\nmultiple-choice questions, it successfully detects all contaminated models with\nguaranteed FPRs as low as 0.000073% on MMLU-Pro and 0.000017% on Big-Bench-Hard\nusing eight backdoors. For open-ended generation tasks, it generalizes well and\nidentifies all contaminated models on Alpaca with a guaranteed false positive\nrate of just 0.127% using six backdoors.", "AI": {"tldr": "DyePack is a framework using backdoor attacks to detect if models trained on benchmark test sets, ensuring low false positive rates.", "motivation": "Open benchmarks are vulnerable to test set contamination; DyePack addresses this by identifying models that misuse test data.", "method": "DyePack mixes backdoor samples with test data, using stochastic targets for exact FPR computation.", "result": "Detects contamination with FPRs as low as 0.000073% on MMLU-Pro and 0.127% on Alpaca.", "conclusion": "DyePack effectively flags contaminated models with provably low false positives, ensuring benchmark integrity."}}
{"id": "2506.02112", "pdf": "https://arxiv.org/pdf/2506.02112", "abs": "https://arxiv.org/abs/2506.02112", "authors": ["Xuweiyi Chen", "Tian Xia", "Sihan Xu", "Jianing Yang", "Joyce Chai", "Zezhou Cheng"], "title": "SAB3R: Semantic-Augmented Backbone in 3D Reconstruction", "categories": ["cs.CV"], "comment": "3D-LLM/VLA @ CVPR2025 | Project page:\n  https://uva-computer-vision-lab.github.io/sab3r/", "summary": "We introduce a new task, Map and Locate, which unifies the traditionally\ndistinct objectives of open-vocabulary segmentation - detecting and segmenting\nobject instances based on natural language queries - and 3D reconstruction, the\nprocess of estimating a scene's 3D structure from visual inputs. Specifically,\nMap and Locate involves generating a point cloud from an unposed video and\nsegmenting object instances based on open-vocabulary queries. This task serves\nas a critical step toward real-world embodied AI applications and introduces a\npractical task that bridges reconstruction, recognition and reorganization. To\ntackle this task, we introduce a simple yet effective baseline, which we denote\nas SAB3R. Our approach builds upon MASt3R, a recent breakthrough in 3D computer\nvision, and incorporates a lightweight distillation strategy. This method\ntransfers dense, per-pixel semantic features from 2D vision backbones (eg, CLIP\nand DINOv2) to enhance MASt3R's capabilities. Without introducing any auxiliary\nfrozen networks, our model generates per-pixel semantic features and constructs\ncohesive point maps in a single forward pass. Compared to separately deploying\nMASt3R and CLIP, our unified model, SAB3R, achieves superior performance on the\nMap and Locate benchmark. Furthermore, we evaluate SAB3R on both 2D semantic\nsegmentation and 3D tasks to comprehensively validate its effectiveness.", "AI": {"tldr": "The paper introduces 'Map and Locate,' a task combining open-vocabulary segmentation and 3D reconstruction, and proposes SAB3R, a unified model outperforming separate methods.", "motivation": "To bridge the gap between open-vocabulary segmentation and 3D reconstruction for embodied AI applications.", "method": "SAB3R builds on MASt3R, using lightweight distillation to transfer 2D semantic features (e.g., CLIP, DINOv2) for cohesive point maps in one pass.", "result": "SAB3R outperforms separate MASt3R and CLIP deployments on the Map and Locate benchmark and excels in 2D and 3D tasks.", "conclusion": "SAB3R effectively unifies segmentation and reconstruction, advancing embodied AI with practical applications."}}
{"id": "2505.12910", "pdf": "https://arxiv.org/pdf/2505.12910", "abs": "https://arxiv.org/abs/2505.12910", "authors": ["Le Cheng", "Peican Zhu", "Yangming Guo", "Chao Gao", "Zhen Wang", "Keke Tang"], "title": "SourceDetMamba: A Graph-aware State Space Model for Source Detection in Sequential Hypergraphs", "categories": ["cs.SI", "cs.AI"], "comment": "Accepted by IJCAI25", "summary": "Source detection on graphs has demonstrated high efficacy in identifying\nrumor origins. Despite advances in machine learning-based methods, many fail to\ncapture intrinsic dynamics of rumor propagation. In this work, we present\nSourceDetMamba: A Graph-aware State Space Model for Source Detection in\nSequential Hypergraphs, which harnesses the recent success of the state space\nmodel Mamba, known for its superior global modeling capabilities and\ncomputational efficiency, to address this challenge. Specifically, we first\nemploy hypergraphs to model high-order interactions within social networks.\nSubsequently, temporal network snapshots generated during the propagation\nprocess are sequentially fed in reverse order into Mamba to infer underlying\npropagation dynamics. Finally, to empower the sequential model to effectively\ncapture propagation patterns while integrating structural information, we\npropose a novel graph-aware state update mechanism, wherein the state of each\nnode is propagated and refined by both temporal dependencies and topological\ncontext. Extensive evaluations on eight datasets demonstrate that\nSourceDetMamba consistently outperforms state-of-the-art approaches.", "AI": {"tldr": "SourceDetMamba uses Mamba's state space model to detect rumor sources in hypergraphs, outperforming existing methods by capturing propagation dynamics and structural context.", "motivation": "Existing machine learning methods for rumor source detection often miss intrinsic propagation dynamics.", "method": "Hypergraphs model high-order interactions; temporal snapshots are fed in reverse to Mamba, with a graph-aware state update mechanism.", "result": "SourceDetMamba outperforms state-of-the-art methods on eight datasets.", "conclusion": "The approach effectively integrates temporal and structural information for superior rumor source detection."}}
{"id": "2502.16733", "pdf": "https://arxiv.org/pdf/2502.16733", "abs": "https://arxiv.org/abs/2502.16733", "authors": ["Akshay Mehra", "Trisha Mittal", "Subhadra Gopalakrishnan", "Joshua Kimball"], "title": "Coreset Selection via LLM-based Concept Bottlenecks", "categories": ["cs.LG"], "comment": null, "summary": "Coreset Selection (CS) aims to identify a subset of the training dataset that\nachieves model performance comparable to using the entire dataset. Many\nstate-of-the-art CS methods select coresets using scores whose computation\nrequires training the downstream model on the entire dataset first and\nrecording changes in the model's behavior on samples as it trains (training\ndynamics). These scores are inefficient to compute and hard to interpret, as\nthey do not indicate whether a sample is difficult to learn in general or only\nfor a specific downstream model. Our work addresses these challenges by\nproposing a score that computes a sample's difficulty using\nhuman-understandable textual attributes (concepts) independent of any\ndownstream model. Specifically, we measure the alignment between a sample's\nvisual features and concept bottlenecks, derived via large language models, by\ntraining a linear concept bottleneck layer and computing the sample's\ndifficulty score using it.We then use stratified sampling based on this score\nto generate a coreset of the dataset.Crucially, our score is efficiently\ncomputable without training the downstream model on the full dataset even once,\nleads to high-performing coresets for various downstream models, and is\ncomputable even for an unlabeled dataset. Through experiments on CIFAR-10/100,\nand ImageNet-1K, we show that our coresets outperform random subsets, even at\nhigh pruning rates, and achieve model performance comparable to or better than\ncoresets found by training dynamics-based methods.", "AI": {"tldr": "Proposes a model-independent coreset selection method using human-understandable concepts, outperforming traditional training dynamics-based methods.", "motivation": "Address inefficiency and interpretability issues in coreset selection by avoiding dependency on downstream model training.", "method": "Uses concept bottlenecks derived from large language models to compute sample difficulty scores, enabling stratified sampling for coreset generation.", "result": "Achieves high-performing coresets for various models without full dataset training, outperforming random subsets and traditional methods.", "conclusion": "Demonstrates effectiveness on CIFAR-10/100 and ImageNet-1K, offering a scalable and interpretable alternative for coreset selection."}}
{"id": "2505.23276", "pdf": "https://arxiv.org/pdf/2505.23276", "abs": "https://arxiv.org/abs/2505.23276", "authors": ["Maged S. Al-Shaibani", "Moataz Ahmed"], "title": "The Arabic AI Fingerprint: Stylometric Analysis and Detection of Large Language Models Text", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Large Language Models (LLMs) have achieved unprecedented capabilities in\ngenerating human-like text, posing subtle yet significant challenges for\ninformation integrity across critical domains, including education, social\nmedia, and academia, enabling sophisticated misinformation campaigns,\ncompromising healthcare guidance, and facilitating targeted propaganda. This\nchallenge becomes severe, particularly in under-explored and low-resource\nlanguages like Arabic. This paper presents a comprehensive investigation of\nArabic machine-generated text, examining multiple generation strategies\n(generation from the title only, content-aware generation, and text refinement)\nacross diverse model architectures (ALLaM, Jais, Llama, and GPT-4) in academic,\nand social media domains. Our stylometric analysis reveals distinctive\nlinguistic patterns differentiating human-written from machine-generated Arabic\ntext across these varied contexts. Despite their human-like qualities, we\ndemonstrate that LLMs produce detectable signatures in their Arabic outputs,\nwith domain-specific characteristics that vary significantly between different\ncontexts. Based on these insights, we developed BERT-based detection models\nthat achieved exceptional performance in formal contexts (up to 99.9\\%\nF1-score) with strong precision across model architectures. Our cross-domain\nanalysis confirms generalization challenges previously reported in the\nliterature. To the best of our knowledge, this work represents the most\ncomprehensive investigation of Arabic machine-generated text to date, uniquely\ncombining multiple prompt generation methods, diverse model architectures, and\nin-depth stylometric analysis across varied textual domains, establishing a\nfoundation for developing robust, linguistically-informed detection systems\nessential for preserving information integrity in Arabic-language contexts.", "AI": {"tldr": "The paper investigates machine-generated Arabic text, identifying detectable linguistic patterns and developing a BERT-based detection model with high accuracy.", "motivation": "Addressing the challenges LLMs pose to information integrity, especially in low-resource languages like Arabic, by detecting machine-generated text.", "method": "Examined Arabic text generation strategies (title-only, content-aware, refinement) across models (ALLaM, Jais, Llama, GPT-4) using stylometric analysis. Developed BERT-based detection models.", "result": "Detected distinctive linguistic patterns in machine-generated Arabic text. BERT models achieved up to 99.9% F1-score in formal contexts.", "conclusion": "The study provides a foundation for robust detection systems to preserve information integrity in Arabic, highlighting domain-specific challenges."}}
{"id": "2506.02294", "pdf": "https://arxiv.org/pdf/2506.02294", "abs": "https://arxiv.org/abs/2506.02294", "authors": ["Niclas Popp", "Kevin Alexander Laube", "Matthias Hein", "Lukas Schott"], "title": "Improving Knowledge Distillation Under Unknown Covariate Shift Through Confidence-Guided Data Augmentation", "categories": ["cs.CV"], "comment": null, "summary": "Large foundation models trained on extensive datasets demonstrate strong\nzero-shot capabilities in various domains. To replicate their success when data\nand model size are constrained, knowledge distillation has become an\nestablished tool for transferring knowledge from foundation models to small\nstudent networks. However, the effectiveness of distillation is critically\nlimited by the available training data. This work addresses the common\npractical issue of covariate shift in knowledge distillation, where spurious\nfeatures appear during training but not at test time. We ask the question: when\nthese spurious features are unknown, yet a robust teacher is available, is it\npossible for a student to also become robust to them? We address this problem\nby introducing a novel diffusion-based data augmentation strategy that\ngenerates images by maximizing the disagreement between the teacher and the\nstudent, effectively creating challenging samples that the student struggles\nwith. Experiments demonstrate that our approach significantly improves worst\ngroup and mean group accuracy on CelebA and SpuCo Birds as well as the spurious\nmAUC on spurious ImageNet under covariate shift, outperforming state-of-the-art\ndiffusion-based data augmentation baselines", "AI": {"tldr": "The paper proposes a diffusion-based data augmentation method to improve knowledge distillation under covariate shift, enhancing student model robustness to spurious features.", "motivation": "Address the limitation of knowledge distillation effectiveness due to covariate shift and unknown spurious features, leveraging a robust teacher to improve student robustness.", "method": "Introduces a diffusion-based data augmentation strategy that generates challenging samples by maximizing teacher-student disagreement.", "result": "Significant improvements in worst-group and mean-group accuracy on datasets like CelebA and SpuCo Birds, and spurious mAUC on ImageNet under covariate shift.", "conclusion": "The proposed method outperforms existing diffusion-based data augmentation techniques, demonstrating its effectiveness in handling covariate shift in knowledge distillation."}}
{"id": "2505.13469", "pdf": "https://arxiv.org/pdf/2505.13469", "abs": "https://arxiv.org/abs/2505.13469", "authors": ["Aayam Bansal"], "title": "Algorithmic Tradeoffs in Fair Lending: Profitability, Compliance, and Long-Term Impact", "categories": ["cs.CY", "cs.AI", "cs.CE", "cs.LG"], "comment": "8 pages", "summary": "As financial institutions increasingly rely on machine learning models to\nautomate lending decisions, concerns about algorithmic fairness have risen.\nThis paper explores the tradeoff between enforcing fairness constraints (such\nas demographic parity or equal opportunity) and maximizing lender\nprofitability. Through simulations on synthetic data that reflects real-world\nlending patterns, we quantify how different fairness interventions impact\nprofit margins and default rates. Our results demonstrate that equal\nopportunity constraints typically impose lower profit costs than demographic\nparity, but surprisingly, removing protected attributes from the model\n(fairness through unawareness) outperforms explicit fairness interventions in\nboth fairness and profitability metrics. We further identify the specific\neconomic conditions under which fair lending becomes profitable and analyze the\nfeature-specific drivers of unfairness. These findings offer practical guidance\nfor designing lending algorithms that balance ethical considerations with\nbusiness objectives.", "AI": {"tldr": "The paper examines the tradeoff between fairness constraints (demographic parity, equal opportunity) and profitability in lending algorithms. Fairness through unawareness outperforms explicit interventions in fairness and profitability.", "motivation": "Address concerns about algorithmic fairness in lending decisions while maintaining profitability.", "method": "Simulations on synthetic data reflecting real-world lending patterns to quantify impacts of fairness interventions.", "result": "Equal opportunity constraints are less costly than demographic parity, but fairness through unawareness performs best in fairness and profitability. Fair lending can be profitable under specific conditions.", "conclusion": "Provides guidance for designing lending algorithms that balance fairness and profitability, highlighting the effectiveness of fairness through unawareness."}}
{"id": "2502.18197", "pdf": "https://arxiv.org/pdf/2502.18197", "abs": "https://arxiv.org/abs/2502.18197", "authors": ["Gianluigi Silvestri", "Luca Ambrogioni", "Chieh-Hsin Lai", "Yuhta Takida", "Yuki Mitsufuji"], "title": "VCT: Training Consistency Models with Variational Noise Coupling", "categories": ["cs.LG", "cs.CV"], "comment": "23 pages, 11 figures", "summary": "Consistency Training (CT) has recently emerged as a strong alternative to\ndiffusion models for image generation. However, non-distillation CT often\nsuffers from high variance and instability, motivating ongoing research into\nits training dynamics. We propose Variational Consistency Training (VCT), a\nflexible and effective framework compatible with various forward kernels,\nincluding those in flow matching. Its key innovation is a learned noise-data\ncoupling scheme inspired by Variational Autoencoders, where a data-dependent\nencoder models noise emission. This enables VCT to adaptively learn\nnoise-todata pairings, reducing training variance relative to the fixed,\nunsorted pairings in classical CT. Experiments on multiple image datasets\ndemonstrate significant improvements: our method surpasses baselines, achieves\nstate-of-the-art FID among non-distillation CT approaches on CIFAR-10, and\nmatches SoTA performance on ImageNet 64 x 64 with only two sampling steps. Code\nis available at https://github.com/sony/vct.", "AI": {"tldr": "VCT improves Consistency Training by adaptively learning noise-data pairings, reducing variance and achieving state-of-the-art results.", "motivation": "Non-distillation CT suffers from high variance and instability, prompting the need for a more robust framework.", "method": "VCT introduces a learned noise-data coupling scheme inspired by VAEs, enabling adaptive noise-data pairings.", "result": "VCT surpasses baselines, achieves top FID on CIFAR-10, and matches SoTA on ImageNet 64x64 with minimal steps.", "conclusion": "VCT is a flexible and effective alternative to classical CT, offering improved stability and performance."}}
{"id": "2505.23811", "pdf": "https://arxiv.org/pdf/2505.23811", "abs": "https://arxiv.org/abs/2505.23811", "authors": ["Hadi Askari", "Shivanshu Gupta", "Fei Wang", "Anshuman Chhabra", "Muhao Chen"], "title": "LayerIF: Estimating Layer Quality for Large Language Models using Influence Functions", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "Under Review", "summary": "Pretrained Large Language Models (LLMs) achieve strong performance across a\nwide range of tasks, yet exhibit substantial variability in the various layers'\ntraining quality with respect to specific downstream applications, limiting\ntheir downstream performance. It is therefore critical to estimate layer-wise\ntraining quality in a manner that accounts for both model architecture and\ntraining data. However, existing approaches predominantly rely on model-centric\nheuristics (such as spectral statistics, outlier detection, or uniform\nallocation) while overlooking the influence of data. To address these\nlimitations, we propose LayerIF, a data-driven framework that leverages\nInfluence Functions to quantify the training quality of individual layers in a\nprincipled and task-sensitive manner. By isolating each layer's gradients and\nmeasuring the sensitivity of the validation loss to training examples by\ncomputing layer-wise influences, we derive data-driven estimates of layer\nimportance. Notably, our method produces task-specific layer importance\nestimates for the same LLM, revealing how layers specialize for different\ntest-time evaluation tasks. We demonstrate the utility of our scores by\nleveraging them for two downstream applications: (a) expert allocation in\nLoRA-MoE architectures and (b) layer-wise sparsity distribution for LLM\npruning. Experiments across multiple LLM architectures demonstrate that our\nmodel-agnostic, influence-guided allocation leads to consistent gains in task\nperformance.", "AI": {"tldr": "LayerIF is a data-driven framework using Influence Functions to estimate layer-wise training quality in LLMs, improving downstream task performance.", "motivation": "Existing methods overlook data influence, relying on model-centric heuristics, limiting LLM performance.", "method": "LayerIF isolates layer gradients and computes influence on validation loss to derive task-specific layer importance.", "result": "The framework improves expert allocation in LoRA-MoE and sparsity distribution for pruning, enhancing task performance.", "conclusion": "LayerIF provides a principled, task-sensitive approach for layer-wise quality estimation, benefiting LLM applications."}}
{"id": "2506.02356", "pdf": "https://arxiv.org/pdf/2506.02356", "abs": "https://arxiv.org/abs/2506.02356", "authors": ["Woojeong Jin", "Seongchan Kim", "Seungryong Kim"], "title": "InterRVOS: Interaction-aware Referring Video Object Segmentation", "categories": ["cs.CV"], "comment": null, "summary": "Referring video object segmentation aims to segment the object in a video\ncorresponding to a given natural language expression. While prior works have\nexplored various referring scenarios, including motion-centric or\nmulti-instance expressions, most approaches still focus on localizing a single\ntarget object in isolation. However, in comprehensive video understanding, an\nobject's role is often defined by its interactions with other entities, which\nare largely overlooked in existing datasets and models. In this work, we\nintroduce Interaction-aware referring video object sgementation (InterRVOS), a\nnew task that requires segmenting both actor and target entities involved in an\ninteraction. Each interactoin is described through a pair of complementary\nexpressions from different semantic perspectives, enabling fine-grained\nmodeling of inter-object relationships. To tackle this task, we propose\nInterRVOS-8K, the large-scale and automatically constructed dataset containing\ndiverse interaction-aware expressions with corresponding masks, including\nchallenging cases such as motion-only multi-instance expressions. We also\npresent a baseline architecture, ReVIOSa, designed to handle actor-target\nsegmentation from a single expression, achieving strong performance in both\nstandard and interaction-focused settings. Furthermore, we introduce an\nactor-target-aware evalaution setting that enables a more targeted assessment\nof interaction understanding. Experimental results demonstrate that our\napproach outperforms prior methods in modeling complex object interactions for\nreferring video object segmentation task, establishing a strong foundation for\nfuture research in interaction-centric video understanding. Our project page is\navailable at https://cvlab-kaist.github.io/InterRVOS.", "AI": {"tldr": "The paper introduces Interaction-aware referring video object segmentation (InterRVOS), a new task focusing on segmenting interacting objects in videos using complementary natural language expressions. It presents a dataset (InterRVOS-8K) and a baseline model (ReVIOSa) for this task, outperforming prior methods.", "motivation": "Existing referring video object segmentation methods focus on single objects, ignoring interactions between entities, which are crucial for comprehensive video understanding.", "method": "Proposes InterRVOS-8K, a large-scale dataset with interaction-aware expressions, and ReVIOSa, a baseline model for actor-target segmentation from a single expression.", "result": "ReVIOSa outperforms prior methods in modeling complex object interactions, demonstrating strong performance in both standard and interaction-focused settings.", "conclusion": "The work establishes a foundation for interaction-centric video understanding, with potential for future research in this direction."}}
{"id": "2505.14884", "pdf": "https://arxiv.org/pdf/2505.14884", "abs": "https://arxiv.org/abs/2505.14884", "authors": ["Susav Shrestha", "Brad Settlemyer", "Nikoli Dryden", "Narasimha Reddy"], "title": "Polar Sparsity: High Throughput Batched LLM Inferencing with Scalable Contextual Sparsity", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Accelerating large language model (LLM) inference is critical for real-world\ndeployments requiring high throughput and low latency. Contextual sparsity,\nwhere each token dynamically activates only a small subset of the model\nparameters, shows promise but does not scale to large batch sizes due to union\nof active neurons quickly approaching dense computation. We introduce Polar\nSparsity, highlighting a key shift in sparsity importance from MLP to Attention\nlayers as we scale batch size and sequence length. While MLP layers become more\ncompute-efficient under batching, their sparsity vanishes. In contrast,\nattention becomes increasingly more expensive at scale, while their head\nsparsity remains stable and batch-invariant. We develop hardware-efficient,\nsparsity-aware GPU kernels for selective MLP and Attention computations,\ndelivering up to \\(2.2\\times\\) end-to-end speedups for models like OPT, LLaMA-2\n\\& 3, across various batch sizes and sequence lengths without compromising\naccuracy. To our knowledge, this is the first work to demonstrate that\ncontextual sparsity can scale effectively to large batch sizes, delivering\nsubstantial inference acceleration with minimal changes, making Polar Sparsity\npractical for large-scale, high-throughput LLM deployment systems. Our code is\navailable at: https://github.com/susavlsh10/Polar-Sparsity.", "AI": {"tldr": "Polar Sparsity accelerates LLM inference by focusing on sparsity in Attention layers, achieving 2.2\u00d7 speedups for models like OPT and LLaMA-2/3 without accuracy loss.", "motivation": "To address the challenge of scaling contextual sparsity for large batch sizes in LLM inference, where traditional methods fail due to dense computation.", "method": "Introduces Polar Sparsity, emphasizing sparsity in Attention layers over MLP layers, and develops sparsity-aware GPU kernels for selective computations.", "result": "Achieves up to 2.2\u00d7 speedups across models (OPT, LLaMA-2/3) for various batch sizes and sequence lengths while maintaining accuracy.", "conclusion": "Polar Sparsity effectively scales contextual sparsity to large batch sizes, enabling practical, high-throughput LLM deployments."}}
{"id": "2503.05617", "pdf": "https://arxiv.org/pdf/2503.05617", "abs": "https://arxiv.org/abs/2503.05617", "authors": ["Prakash Thakolkaran", "Yaqi Guo", "Shivam Saini", "Mathias Peirlinck", "Benjamin Alheit", "Siddhant Kumar"], "title": "Can KAN CANs? Input-convex Kolmogorov-Arnold Networks (KANs) as hyperelastic constitutive artificial neural networks (CANs)", "categories": ["cs.LG"], "comment": "36 pages, 16 figures", "summary": "Traditional constitutive models rely on hand-crafted parametric forms with\nlimited expressivity and generalizability, while neural network-based models\ncan capture complex material behavior but often lack interpretability. To\nbalance these trade-offs, we present monotonic Input-Convex Kolmogorov-Arnold\nNetworks (ICKANs) for learning polyconvex hyperelastic constitutive laws.\nICKANs leverage the Kolmogorov-Arnold representation, decomposing the model\ninto compositions of trainable univariate spline-based activation functions for\nrich expressivity. We introduce trainable monotonic input-convex splines within\nthe KAN architecture, ensuring physically admissible polyconvex models for\nisotropic compressible hyperelasticity. The resulting models are both compact\nand interpretable, enabling explicit extraction of analytical constitutive\nrelationships through a monotonic input-convex symbolic regression technique.\nThrough unsupervised training on full-field strain data and limited global\nforce measurements, ICKANs accurately capture nonlinear stress-strain behavior\nacross diverse strain states. Finite element simulations of unseen geometries\nwith trained ICKAN hyperelastic constitutive models confirm the framework's\nrobustness and generalization capability.", "AI": {"tldr": "ICKANs balance expressivity and interpretability for hyperelastic constitutive laws using trainable spline-based functions.", "motivation": "Traditional models lack expressivity, while neural networks lack interpretability. ICKANs aim to bridge this gap.", "method": "Monotonic Input-Convex Kolmogorov-Arnold Networks (ICKANs) decompose models into trainable univariate spline functions, ensuring physical admissibility.", "result": "ICKANs accurately model stress-strain behavior and generalize well in finite element simulations.", "conclusion": "ICKANs provide a robust, interpretable framework for hyperelastic constitutive modeling."}}
{"id": "2505.24554", "pdf": "https://arxiv.org/pdf/2505.24554", "abs": "https://arxiv.org/abs/2505.24554", "authors": ["Anna Sofia Lippolis", "Minh Davide Ragagni", "Paolo Ciancarini", "Andrea Giovanni Nuzzolese", "Valentina Presutti"], "title": "Bench4KE: Benchmarking Automated Competency Question Generation", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "The availability of Large Language Models (LLMs) presents a unique\nopportunity to reinvigorate research on Knowledge Engineering (KE) automation,\na trend already evident in recent efforts developing LLM-based methods and\ntools for the automatic generation of Competency Questions (CQs). However, the\nevaluation of these tools lacks standardisation. This undermines the\nmethodological rigour and hinders the replication and comparison of results. To\naddress this gap, we introduce Bench4KE, an extensible API-based benchmarking\nsystem for KE automation. Its first release focuses on evaluating tools that\ngenerate CQs automatically. CQs are natural language questions used by ontology\nengineers to define the functional requirements of an ontology. Bench4KE\nprovides a curated gold standard consisting of CQ datasets from four real-world\nontology projects. It uses a suite of similarity metrics to assess the quality\nof the CQs generated. We present a comparative analysis of four recent CQ\ngeneration systems, which are based on LLMs, establishing a baseline for future\nresearch. Bench4KE is also designed to accommodate additional KE automation\ntasks, such as SPARQL query generation, ontology testing and drafting. Code and\ndatasets are publicly available under the Apache 2.0 license.", "AI": {"tldr": "Bench4KE is an API-based benchmarking system for evaluating Knowledge Engineering automation tools, starting with Competency Question generation, using standardized metrics and a curated gold standard.", "motivation": "The lack of standardization in evaluating LLM-based KE automation tools hinders methodological rigor and comparability.", "method": "Introduces Bench4KE, a system with a gold standard dataset and similarity metrics to assess CQ generation tools.", "result": "Provides a comparative analysis of four LLM-based CQ generation systems, setting a baseline for future work.", "conclusion": "Bench4KE addresses evaluation gaps in KE automation and is extensible for other tasks like SPARQL query generation."}}
{"id": "2506.02444", "pdf": "https://arxiv.org/pdf/2506.02444", "abs": "https://arxiv.org/abs/2506.02444", "authors": ["Lingwei Dang", "Ruizhi Shao", "Hongwen Zhang", "Wei Min", "Yebin Liu", "Qingyao Wu"], "title": "SViMo: Synchronized Diffusion for Video and Motion Generation in Hand-object Interaction Scenarios", "categories": ["cs.CV"], "comment": null, "summary": "Hand-Object Interaction (HOI) generation has significant application\npotential. However, current 3D HOI motion generation approaches heavily rely on\npredefined 3D object models and lab-captured motion data, limiting\ngeneralization capabilities. Meanwhile, HOI video generation methods prioritize\npixel-level visual fidelity, often sacrificing physical plausibility.\nRecognizing that visual appearance and motion patterns share fundamental\nphysical laws in the real world, we propose a novel framework that combines\nvisual priors and dynamic constraints within a synchronized diffusion process\nto generate the HOI video and motion simultaneously. To integrate the\nheterogeneous semantics, appearance, and motion features, our method implements\ntri-modal adaptive modulation for feature aligning, coupled with 3D\nfull-attention for modeling inter- and intra-modal dependencies. Furthermore,\nwe introduce a vision-aware 3D interaction diffusion model that generates\nexplicit 3D interaction sequences directly from the synchronized diffusion\noutputs, then feeds them back to establish a closed-loop feedback cycle. This\narchitecture eliminates dependencies on predefined object models or explicit\npose guidance while significantly enhancing video-motion consistency.\nExperimental results demonstrate our method's superiority over state-of-the-art\napproaches in generating high-fidelity, dynamically plausible HOI sequences,\nwith notable generalization capabilities in unseen real-world scenarios.\nProject page at https://github.com/Droliven/SViMo\\_project.", "AI": {"tldr": "A novel framework combines visual priors and dynamic constraints in a synchronized diffusion process to generate Hand-Object Interaction (HOI) videos and motion simultaneously, enhancing consistency and generalization.", "motivation": "Current HOI methods rely on predefined 3D models or sacrifice physical plausibility for visual fidelity, limiting generalization.", "method": "Uses tri-modal adaptive modulation for feature alignment and 3D full-attention for dependencies. Introduces a vision-aware 3D interaction diffusion model for closed-loop feedback.", "result": "Outperforms state-of-the-art in generating high-fidelity, physically plausible HOI sequences with strong generalization.", "conclusion": "The framework eliminates dependencies on predefined models and enhances video-motion consistency, showing superior performance in real-world scenarios."}}
{"id": "2505.16196", "pdf": "https://arxiv.org/pdf/2505.16196", "abs": "https://arxiv.org/abs/2505.16196", "authors": ["Xuewu Lin", "Tianwei Lin", "Lichao Huang", "Hongyu Xie", "Yiwei Jin", "Keyu Li", "Zhizhong Su"], "title": "SEM: Enhancing Spatial Understanding for Robust Robot Manipulation", "categories": ["cs.RO", "cs.AI", "cs.CV"], "comment": null, "summary": "A key challenge in robot manipulation lies in developing policy models with\nstrong spatial understanding, the ability to reason about 3D geometry, object\nrelations, and robot embodiment. Existing methods often fall short: 3D point\ncloud models lack semantic abstraction, while 2D image encoders struggle with\nspatial reasoning. To address this, we propose SEM (Spatial Enhanced\nManipulation model), a novel diffusion-based policy framework that explicitly\nenhances spatial understanding from two complementary perspectives. A spatial\nenhancer augments visual representations with 3D geometric context, while a\nrobot state encoder captures embodiment-aware structure through graphbased\nmodeling of joint dependencies. By integrating these modules, SEM significantly\nimproves spatial understanding, leading to robust and generalizable\nmanipulation across diverse tasks that outperform existing baselines.", "AI": {"tldr": "SEM, a diffusion-based policy framework, enhances spatial understanding in robot manipulation by combining 3D geometric context and robot embodiment modeling, outperforming existing methods.", "motivation": "Existing methods lack strong spatial understanding in robot manipulation, with 3D point clouds missing semantics and 2D encoders struggling with spatial reasoning.", "method": "SEM integrates a spatial enhancer for 3D geometric context and a robot state encoder for embodiment-aware structure via graph-based modeling.", "result": "SEM improves spatial understanding, enabling robust and generalizable manipulation across diverse tasks, surpassing baselines.", "conclusion": "SEM addresses spatial reasoning gaps in robot manipulation, offering a novel and effective framework."}}
{"id": "2503.09117", "pdf": "https://arxiv.org/pdf/2503.09117", "abs": "https://arxiv.org/abs/2503.09117", "authors": ["Yue Wang", "Qizhou Wang", "Feng Liu", "Wei Huang", "Yali Du", "Xiaojiang Du", "Bo Han"], "title": "GRU: Mitigating the Trade-off between Unlearning and Retention for Large Language Models", "categories": ["cs.LG", "cs.CL"], "comment": null, "summary": "Large language model (LLM) unlearning has demonstrated its essential role in\nremoving privacy and copyright-related responses, crucial for their legal and\nsafe applications. However, the pursuit of complete unlearning often comes with\nsubstantial costs due to its compromises in their general functionality,\nleading to a notorious trade-off between unlearning and retention. In examining\nthe update process for unlearning dynamically, we find gradients hold essential\ninformation for revealing this trade-off. In particular, we look at the varying\nrelationship between retention performance and directional disparities between\ngradients during unlearning. It motivates the sculpting of an update mechanism\nderived from gradients from two sources, i.e., harmful for retention and useful\nfor unlearning. Accordingly, we propose Gradient Rectified Unlearning (GRU), an\nenhanced unlearning framework controlling the updating gradients in a\ngeometry-focused and optimization-driven manner such that their side impacts on\nother, unrelated responses can be minimized. Specifically, GRU derives a\nclosed-form solution to project the unlearning gradient onto the orthogonal\nspace of that gradient harmful for retention, ensuring minimal deviation from\nits original direction under the condition that overall performance is\nretained. Comprehensive experiments are conducted to demonstrate that GRU, as a\ngeneral framework, is straightforward to implement and efficiently enhances a\nrange of baseline methods through its adaptable and compatible characteristics.\nAdditionally, experimental results show its broad effectiveness across a\ndiverse set of benchmarks for LLM unlearning.", "AI": {"tldr": "GRU is a gradient-based unlearning framework for LLMs that minimizes trade-offs between unlearning and retention by projecting gradients orthogonally.", "motivation": "Address the trade-off between unlearning harmful data and retaining useful functionality in LLMs.", "method": "Proposes Gradient Rectified Unlearning (GRU), which projects unlearning gradients orthogonally to harmful retention gradients.", "result": "GRU enhances baseline methods, is easy to implement, and performs well across benchmarks.", "conclusion": "GRU effectively balances unlearning and retention, offering a practical solution for LLM safety and legality."}}
{"id": "2505.24688", "pdf": "https://arxiv.org/pdf/2505.24688", "abs": "https://arxiv.org/abs/2505.24688", "authors": ["Qinglin Zhu", "Runcong Zhao", "Hanqi Yan", "Yulan He", "Yudong Chen", "Lin Gui"], "title": "Soft Reasoning: Navigating Solution Spaces in Large Language Models through Controlled Embedding Exploration", "categories": ["cs.CL"], "comment": "Accepted as a Spotlight at ICML 2025", "summary": "Large Language Models (LLMs) struggle with complex reasoning due to limited\ndiversity and inefficient search. We propose Soft Reasoning, an embedding-based\nsearch framework that optimises the embedding of the first token to guide\ngeneration. It combines (1) embedding perturbation for controlled exploration\nand (2) Bayesian optimisation to refine embeddings via a verifier-guided\nobjective, balancing exploration and exploitation. This approach improves\nreasoning accuracy and coherence while avoiding reliance on heuristic search.\nExperiments demonstrate superior correctness with minimal computation, making\nit a scalable, model-agnostic solution.", "AI": {"tldr": "Soft Reasoning improves LLM reasoning by embedding-based search with perturbation and Bayesian optimization, enhancing accuracy and scalability.", "motivation": "LLMs struggle with complex reasoning due to limited diversity and inefficient search.", "method": "Proposes Soft Reasoning: embedding perturbation for exploration and Bayesian optimization for refinement, guided by a verifier.", "result": "Improves reasoning accuracy and coherence with minimal computation, scalable and model-agnostic.", "conclusion": "Soft Reasoning offers a robust, efficient solution for enhancing LLM reasoning without heuristic search reliance."}}
{"id": "2506.02535", "pdf": "https://arxiv.org/pdf/2506.02535", "abs": "https://arxiv.org/abs/2506.02535", "authors": ["Juntong Li", "Lingwei Dang", "Yukun Su", "Yun Hao", "Qingxin Xiao", "Yongwei Nie", "Qingyao Wu"], "title": "MemoryOut: Learning Principal Features via Multimodal Sparse Filtering Network for Semi-supervised Video Anomaly Detection", "categories": ["cs.CV"], "comment": null, "summary": "Video Anomaly Detection (VAD) methods based on reconstruction or prediction\nface two critical challenges: (1) strong generalization capability often\nresults in accurate reconstruction or prediction of abnormal events, making it\ndifficult to distinguish normal from abnormal patterns; (2) reliance only on\nlow-level appearance and motion cues limits their ability to identify\nhigh-level semantic in abnormal events from complex scenes. To address these\nlimitations, we propose a novel VAD framework with two key innovations. First,\nto suppress excessive generalization, we introduce the Sparse Feature Filtering\nModule (SFFM) that employs bottleneck filters to dynamically and adaptively\nremove abnormal information from features. Unlike traditional memory modules,\nit does not need to memorize the normal prototypes across the training dataset.\nFurther, we design the Mixture of Experts (MoE) architecture for SFFM. Each\nexpert is responsible for extracting specialized principal features during\nrunning time, and different experts are selectively activated to ensure the\ndiversity of the learned principal features. Second, to overcome the neglect of\nsemantics in existing methods, we integrate a Vision-Language Model (VLM) to\ngenerate textual descriptions for video clips, enabling comprehensive joint\nmodeling of semantic, appearance, and motion cues. Additionally, we enforce\nmodality consistency through semantic similarity constraints and motion\nframe-difference contrastive loss. Extensive experiments on multiple public\ndatasets validate the effectiveness of our multimodal joint modeling framework\nand sparse feature filtering paradigm. Project page at\nhttps://qzfm.github.io/sfn_vad_project_page/.", "AI": {"tldr": "The paper proposes a novel Video Anomaly Detection (VAD) framework addressing generalization and semantic limitations by introducing Sparse Feature Filtering Module (SFFM) and integrating a Vision-Language Model (VLM).", "motivation": "Existing VAD methods struggle with distinguishing anomalies due to excessive generalization and lack of high-level semantic understanding.", "method": "The framework includes SFFM for adaptive abnormal feature filtering and MoE architecture for diverse feature extraction. It also integrates VLM for semantic-textual descriptions and enforces modality consistency.", "result": "Experiments on public datasets confirm the effectiveness of the multimodal joint modeling and sparse feature filtering approach.", "conclusion": "The proposed framework improves VAD by addressing generalization and semantic challenges, validated through extensive testing."}}
{"id": "2505.20290", "pdf": "https://arxiv.org/pdf/2505.20290", "abs": "https://arxiv.org/abs/2505.20290", "authors": ["Vincent Liu", "Ademi Adeniji", "Haotian Zhan", "Siddhant Haldar", "Raunaq Bhirangi", "Pieter Abbeel", "Lerrel Pinto"], "title": "EgoZero: Robot Learning from Smart Glasses", "categories": ["cs.RO", "cs.AI"], "comment": null, "summary": "Despite recent progress in general purpose robotics, robot policies still lag\nfar behind basic human capabilities in the real world. Humans interact\nconstantly with the physical world, yet this rich data resource remains largely\nuntapped in robot learning. We propose EgoZero, a minimal system that learns\nrobust manipulation policies from human demonstrations captured with Project\nAria smart glasses, $\\textbf{and zero robot data}$. EgoZero enables: (1)\nextraction of complete, robot-executable actions from in-the-wild, egocentric,\nhuman demonstrations, (2) compression of human visual observations into\nmorphology-agnostic state representations, and (3) closed-loop policy learning\nthat generalizes morphologically, spatially, and semantically. We deploy\nEgoZero policies on a gripper Franka Panda robot and demonstrate zero-shot\ntransfer with 70% success rate over 7 manipulation tasks and only 20 minutes of\ndata collection per task. Our results suggest that in-the-wild human data can\nserve as a scalable foundation for real-world robot learning - paving the way\ntoward a future of abundant, diverse, and naturalistic training data for\nrobots. Code and videos are available at https://egozero-robot.github.io.", "AI": {"tldr": "EgoZero learns robot manipulation policies from human demonstrations using smart glasses, achieving 70% success rate in zero-shot transfer tasks.", "motivation": "Leverage untapped human interaction data to improve robot learning, as current robot policies lag behind human capabilities.", "method": "Extracts robot-executable actions from human demonstrations, compresses visual observations into morphology-agnostic states, and learns closed-loop policies.", "result": "70% success rate in zero-shot transfer across 7 tasks with minimal data (20 minutes per task).", "conclusion": "Human data can scale robot learning, enabling diverse and naturalistic training for real-world applications."}}
{"id": "2503.09128", "pdf": "https://arxiv.org/pdf/2503.09128", "abs": "https://arxiv.org/abs/2503.09128", "authors": ["Fengze Sun", "Yanchuan Chang", "Egemen Tanin", "Shanika Karunasekera", "Jianzhong Qi"], "title": "FlexiReg: Flexible Urban Region Representation Learning", "categories": ["cs.LG"], "comment": "This paper is accepted at KDD 2025", "summary": "The increasing availability of urban data offers new opportunities for\nlearning region representations, which can be used as input to machine learning\nmodels for downstream tasks such as check-in or crime prediction. While\nexisting solutions have produced promising results, an issue is their fixed\nformation of regions and fixed input region features, which may not suit the\nneeds of different downstream tasks. To address this limitation, we propose a\nmodel named FlexiReg for urban region representation learning that is flexible\nwith both the formation of urban regions and the input region features.\nFlexiReg is based on a spatial grid partitioning over the spatial area of\ninterest. It learns representations for the grid cells, leveraging publicly\naccessible data, including POI, land use, satellite imagery, and street view\nimagery. We propose adaptive aggregation to fuse the cell representations and\nprompt learning techniques to tailor the representations towards different\ntasks, addressing the needs of varying formations of urban regions and\ndownstream tasks. Extensive experiments on five real-world datasets demonstrate\nthat FlexiReg outperforms state-of-the-art models by up to 202% in term of the\naccuracy of four diverse downstream tasks using the produced urban region\nrepresentations.", "AI": {"tldr": "FlexiReg is a flexible urban region representation learning model that adapts to varying region formations and features, outperforming state-of-the-art models by up to 202% in downstream tasks.", "motivation": "Existing urban region representation models use fixed region formations and features, which may not suit diverse downstream tasks.", "method": "FlexiReg uses spatial grid partitioning, learns cell representations from public data (POI, land use, imagery), and employs adaptive aggregation and prompt learning for task-specific representations.", "result": "FlexiReg achieves up to 202% better accuracy than state-of-the-art models across five real-world datasets.", "conclusion": "FlexiReg's flexibility in region formation and feature adaptation makes it highly effective for diverse urban downstream tasks."}}
{"id": "2506.00264", "pdf": "https://arxiv.org/pdf/2506.00264", "abs": "https://arxiv.org/abs/2506.00264", "authors": ["Mohammadamin Shafiei", "Hamidreza Saffari", "Nafise Sadat Moosavi"], "title": "MultiHoax: A Dataset of Multi-hop False-Premise Questions", "categories": ["cs.CL"], "comment": "accepted at ACL Findings 2025", "summary": "As Large Language Models are increasingly deployed in high-stakes domains,\ntheir ability to detect false assumptions and reason critically is crucial for\nensuring reliable outputs. False-premise questions (FPQs) serve as an important\nevaluation method by exposing cases where flawed assumptions lead to incorrect\nresponses. While existing benchmarks focus on single-hop FPQs, real-world\nreasoning often requires multi-hop inference, where models must verify\nconsistency across multiple reasoning steps rather than relying on\nsurface-level cues. To address this gap, we introduce MultiHoax, a benchmark\nfor evaluating LLMs' ability to handle false premises in complex, multi-step\nreasoning tasks. Our dataset spans seven countries and ten diverse knowledge\ncategories, using Wikipedia as the primary knowledge source to enable factual\nreasoning across regions. Experiments reveal that state-of-the-art LLMs\nstruggle to detect false premises across different countries, knowledge\ncategories, and multi-hop reasoning types, highlighting the need for improved\nfalse premise detection and more robust multi-hop reasoning capabilities in\nLLMs.", "AI": {"tldr": "The paper introduces MultiHoax, a benchmark to evaluate LLMs' ability to detect false premises in multi-step reasoning tasks, revealing their struggles in handling such complexities.", "motivation": "To address the gap in evaluating LLMs' critical reasoning skills, especially for multi-hop false-premise questions (FPQs), which are crucial for reliable outputs in high-stakes domains.", "method": "The authors create MultiHoax, a benchmark dataset spanning seven countries and ten knowledge categories, using Wikipedia for factual reasoning.", "result": "State-of-the-art LLMs struggle with false premise detection across countries, knowledge categories, and multi-hop reasoning types.", "conclusion": "Improved false premise detection and robust multi-hop reasoning capabilities are needed in LLMs."}}
{"id": "2506.02614", "pdf": "https://arxiv.org/pdf/2506.02614", "abs": "https://arxiv.org/abs/2506.02614", "authors": ["Guohang Zhuang", "Weixi Song", "Jinyang Huang", "Chenwei Yang", "Yan Lu"], "title": "High Performance Space Debris Tracking in Complex Skylight Backgrounds with a Large-Scale Dataset", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "With the rapid development of space exploration, space debris has attracted\nmore attention due to its potential extreme threat, leading to the need for\nreal-time and accurate debris tracking. However, existing methods are mainly\nbased on traditional signal processing, which cannot effectively process the\ncomplex background and dense space debris. In this paper, we propose a deep\nlearning-based Space Debris Tracking Network~(SDT-Net) to achieve highly\naccurate debris tracking. SDT-Net effectively represents the feature of debris,\nenhancing the efficiency and stability of end-to-end model learning. To train\nand evaluate this model effectively, we also produce a large-scale dataset\nSpace Debris Tracking Dataset (SDTD) by a novel observation-based data\nsimulation scheme. SDTD contains 18,040 video sequences with a total of 62,562\nframes and covers 250,000 synthetic space debris. Extensive experiments\nvalidate the effectiveness of our model and the challenging of our dataset.\nFurthermore, we test our model on real data from the Antarctic Station,\nachieving a MOTA score of 70.6%, which demonstrates its strong transferability\nto real-world scenarios. Our dataset and code will be released soon.", "AI": {"tldr": "A deep learning-based Space Debris Tracking Network (SDT-Net) is proposed for accurate debris tracking, supported by a large-scale synthetic dataset (SDTD). The model achieves strong performance in real-world tests.", "motivation": "Space debris poses a significant threat, but existing methods fail to handle complex backgrounds and dense debris effectively.", "method": "Proposes SDT-Net, a deep learning model for debris tracking, and introduces SDTD, a synthetic dataset for training and evaluation.", "result": "SDT-Net achieves a MOTA score of 70.6% on real-world data from the Antarctic Station, demonstrating strong transferability.", "conclusion": "The proposed model and dataset effectively address the challenge of space debris tracking, with potential for real-world application."}}
{"id": "2505.20573", "pdf": "https://arxiv.org/pdf/2505.20573", "abs": "https://arxiv.org/abs/2505.20573", "authors": ["Jiabao Ji", "Yongchao Chen", "Yang Zhang", "Ramana Rao Kompella", "Chuchu Fan", "Gaowen Liu", "Shiyu Chang"], "title": "Collision- and Reachability-Aware Multi-Robot Control with Grounded LLM Planners", "categories": ["cs.RO", "cs.AI"], "comment": null, "summary": "Large language models (LLMs) have demonstrated strong performance in various\nrobot control tasks. However, their deployment in real-world applications\nremains constrained. Even state-ofthe-art LLMs, such as GPT-o4mini, frequently\nproduce invalid action plans that violate physical constraints, such as\ndirecting a robot to an unreachable location or causing collisions between\nrobots. This issue primarily arises from a lack of awareness of these physical\nconstraints during the reasoning process. To address this issue, we propose a\nnovel framework that integrates reinforcement learning with verifiable rewards\n(RLVR) to incentivize knowledge of physical constraints into LLMs to induce\nconstraints-aware reasoning during plan generation. In this approach, only\nvalid action plans that successfully complete a control task receive positive\nrewards. We applied our method to two small-scale LLMs: a non-reasoning\nQwen2.5-3B-Instruct and a reasoning Qwen3-4B. The experiment results\ndemonstrate that constraint-aware small LLMs largely outperform large-scale\nmodels without constraints, grounded on both the BoxNet task and a newly\ndeveloped BoxNet3D environment built using MuJoCo. This work highlights the\neffectiveness of grounding even small LLMs with physical constraints to enable\nscalable and efficient multi-robot control in complex, physically constrained\nenvironments.", "AI": {"tldr": "A novel RLVR framework integrates reinforcement learning with verifiable rewards to improve LLMs' awareness of physical constraints in robot control tasks, outperforming larger models.", "motivation": "Current LLMs often generate invalid action plans due to unawareness of physical constraints, limiting real-world deployment.", "method": "Proposes RLVR framework to incentivize constraint-aware reasoning in LLMs, rewarding only valid action plans.", "result": "Constraint-aware small LLMs outperform larger models in tasks like BoxNet and BoxNet3D.", "conclusion": "Grounding small LLMs with physical constraints enables scalable, efficient multi-robot control in complex environments."}}
{"id": "2503.09532", "pdf": "https://arxiv.org/pdf/2503.09532", "abs": "https://arxiv.org/abs/2503.09532", "authors": ["Adam Karvonen", "Can Rager", "Johnny Lin", "Curt Tigges", "Joseph Bloom", "David Chanin", "Yeu-Tong Lau", "Eoin Farrell", "Callum McDougall", "Kola Ayonrinde", "Demian Till", "Matthew Wearden", "Arthur Conmy", "Samuel Marks", "Neel Nanda"], "title": "SAEBench: A Comprehensive Benchmark for Sparse Autoencoders in Language Model Interpretability", "categories": ["cs.LG", "cs.CL"], "comment": "Accepted to ICML 2025 main conference", "summary": "Sparse autoencoders (SAEs) are a popular technique for interpreting language\nmodel activations, and there is extensive recent work on improving SAE\neffectiveness. However, most prior work evaluates progress using unsupervised\nproxy metrics with unclear practical relevance. We introduce SAEBench, a\ncomprehensive evaluation suite that measures SAE performance across eight\ndiverse metrics, spanning interpretability, feature disentanglement and\npractical applications like unlearning. To enable systematic comparison, we\nopen-source a suite of over 200 SAEs across eight recently proposed SAE\narchitectures and training algorithms. Our evaluation reveals that gains on\nproxy metrics do not reliably translate to better practical performance. For\ninstance, while Matryoshka SAEs slightly underperform on existing proxy\nmetrics, they substantially outperform other architectures on feature\ndisentanglement metrics; moreover, this advantage grows with SAE scale. By\nproviding a standardized framework for measuring progress in SAE development,\nSAEBench enables researchers to study scaling trends and make nuanced\ncomparisons between different SAE architectures and training methodologies. Our\ninteractive interface enables researchers to flexibly visualize relationships\nbetween metrics across hundreds of open-source SAEs at:\nwww.neuronpedia.org/sae-bench", "AI": {"tldr": "SAEBench introduces a standardized evaluation suite for sparse autoencoders (SAEs), revealing that proxy metrics often fail to predict practical performance.", "motivation": "Prior work on SAEs relies on unclear proxy metrics, lacking practical relevance. SAEBench aims to provide a comprehensive evaluation framework.", "method": "SAEBench evaluates SAEs across eight metrics, including interpretability and feature disentanglement, using over 200 open-source SAEs from eight architectures.", "result": "Proxy metrics do not reliably indicate practical performance; e.g., Matryoshka SAEs excel in feature disentanglement despite underperforming on proxies.", "conclusion": "SAEBench enables systematic comparison and scaling trend analysis, advancing SAE research with a standardized framework."}}
{"id": "2506.00539", "pdf": "https://arxiv.org/pdf/2506.00539", "abs": "https://arxiv.org/abs/2506.00539", "authors": ["Ruihan Yang", "Yikai Zhang", "Aili Chen", "Xintao Wang", "Siyu Yuan", "Jiangjie Chen", "Deqing Yang", "Yanghua Xiao"], "title": "ARIA: Training Language Agents with Intention-Driven Reward Aggregation", "categories": ["cs.CL"], "comment": null, "summary": "Large language models (LLMs) have enabled agents to perform complex reasoning\nand decision-making through free-form language interactions. However, in\nopen-ended language action environments (e.g., negotiation or question-asking\ngames), the action space can be formulated as a joint distribution over tokens,\nresulting in an exponentially large action space. Sampling actions in such a\nspace can lead to extreme reward sparsity, which brings large reward variance,\nhindering effective reinforcement learning (RL). To address this, we propose\nARIA, a method that Aggregates Rewards in Intention space to enable efficient\nand effective language Agents training. ARIA aims to project natural language\nactions from the high-dimensional joint token distribution space into a\nlow-dimensional intention space, where semantically similar actions are\nclustered and assigned shared rewards. This intention-aware reward aggregation\nreduces reward variance by densifying reward signals, fostering better policy\noptimization. Extensive experiments demonstrate that ARIA not only\nsignificantly reduces policy gradient variance, but also delivers substantial\nperformance gains of an average of 9.95% across four downstream tasks,\nconsistently outperforming offline and online RL baselines.", "AI": {"tldr": "ARIA reduces reward variance in LLM-based RL by clustering actions in intention space, improving performance by 9.95% on average.", "motivation": "Addressing reward sparsity and high variance in large action spaces for LLM-based agents in open-ended environments.", "method": "Projects language actions into a low-dimensional intention space, clustering semantically similar actions for shared rewards.", "result": "Reduces policy gradient variance and achieves 9.95% average performance gain across tasks.", "conclusion": "ARIA effectively improves RL training for language agents by densifying reward signals in intention space."}}
{"id": "2506.02695", "pdf": "https://arxiv.org/pdf/2506.02695", "abs": "https://arxiv.org/abs/2506.02695", "authors": ["Linquan Wu", "Tianxiang Jiang", "Wenhao Duan", "Yini Fang", "Jacky Keung"], "title": "FaceSleuth: Learning-Driven Single-Orientation Attention Verifies Vertical Dominance in Micro-Expression Recognition", "categories": ["cs.CV"], "comment": "12 pages, 2 figures", "summary": "Micro-expression recognition (MER) demands models that can amplify\nmillisecond-level, low-amplitude facial motions while suppressing\nidentity-specific appearance. We introduce FaceSleuth, a dual-stream\narchitecture that (1) enhances motion along the empirically dominant vertical\naxix through a Continuously Vertical Attention (CVA) block, (2) localises the\nresulting signals with a Facial Position Focalizer built on hierarchical\ncross-window attention, and (3) steers feature learning toward physiologically\nmeaningful regions via lightweight Action-Unit embeddings. To examine whether\nthe hand-chosen vertical axis is indeed optimal, we further propose a\nSingle-Orientation Attention (SOA) module that learns its own pooling direction\nend-to-end. SOA is differentiable, adds only 0.16 % parameters, and collapses\nto CVA when the learned angle converges to {\\Pi}/2. In practice, SOA reliably\ndrifts to 88{\\deg}, confirming the effectiveness of the vertical prior while\ndelivering consistent gains. On three standard MER benchmarks, FaceSleuth with\nCVA already surpasses previous state-of-the-art methods; plugging in SOA lifts\naccuracy and F1 score performance to 95.1 % / 0.918 on CASME II, 87.1 % / 0.840\non SAMM, and 92.9 % / 0.917 on MMEW without sacrificing model compactness.\nThese results establish a new state of the art and, for the first time, provide\nempirical evidence that the vertical attention bias is the most discriminative\norientation for MER.", "AI": {"tldr": "FaceSleuth introduces a dual-stream architecture for micro-expression recognition, enhancing vertical motion and localizing signals, achieving state-of-the-art results.", "motivation": "Micro-expression recognition requires amplifying subtle facial motions while suppressing identity-specific features, which existing models struggle with.", "method": "FaceSleuth uses a Continuously Vertical Attention (CVA) block, Facial Position Focalizer, and Action-Unit embeddings. It also proposes a Single-Orientation Attention (SOA) module to validate the vertical axis.", "result": "FaceSleuth achieves 95.1% accuracy on CASME II, 87.1% on SAMM, and 92.9% on MMEW, outperforming previous methods.", "conclusion": "FaceSleuth sets a new benchmark for MER, empirically proving vertical attention bias as the most discriminative orientation."}}
{"id": "2505.20730", "pdf": "https://arxiv.org/pdf/2505.20730", "abs": "https://arxiv.org/abs/2505.20730", "authors": ["Shahrooz Pouryousef", "Ali Montazeralghaem"], "title": "What LLMs Miss in Recommendations: Bridging the Gap with Retrieval-Augmented Collaborative Signals", "categories": ["cs.IR", "cs.AI", "cs.CL", "cs.LG"], "comment": null, "summary": "User-item interactions contain rich collaborative signals that form the\nbackbone of many successful recommender systems. While recent work has explored\nthe use of large language models (LLMs) for recommendation, it remains unclear\nwhether LLMs can effectively reason over this type of collaborative\ninformation. In this paper, we conduct a systematic comparison between LLMs and\nclassical matrix factorization (MF) models to assess LLMs' ability to leverage\nuser-item interaction data. We further introduce a simple retrieval-augmented\ngeneration (RAG) method that enhances LLMs by grounding their predictions in\nstructured interaction data. Our experiments reveal that current LLMs often\nfall short in capturing collaborative patterns inherent to MF models, but that\nour RAG-based approach substantially improves recommendation\nquality-highlighting a promising direction for future LLM-based recommenders.", "AI": {"tldr": "LLMs struggle with collaborative signals in recommendations but improve with a retrieval-augmented generation (RAG) method.", "motivation": "Assess LLMs' ability to leverage user-item interaction data compared to classical matrix factorization (MF) models.", "method": "Systematic comparison of LLMs and MF models, plus a simple RAG method to enhance LLMs.", "result": "LLMs often fail to capture collaborative patterns like MF, but RAG significantly boosts recommendation quality.", "conclusion": "RAG is a promising direction for improving LLM-based recommenders."}}
{"id": "2503.10503", "pdf": "https://arxiv.org/pdf/2503.10503", "abs": "https://arxiv.org/abs/2503.10503", "authors": ["Jacob Comeau", "Mathieu Bazinet", "Pascal Germain", "Cem Subakan"], "title": "Sample Compression for Self Certified Continual Learning", "categories": ["cs.LG"], "comment": null, "summary": "Continual learning algorithms aim to learn from a sequence of tasks, making\nthe training distribution non-stationary. The majority of existing continual\nlearning approaches in the literature rely on heuristics and do not provide\nlearning guarantees. In this paper, we present a new method called Continual\nPick-to-Learn (CoP2L), which is able to retain the most representative samples\nfor each task in an efficient way. CoP2L combines the Pick-to-Learn algorithm\n(rooted in the sample compression theory) and the experience replay continual\nlearning scheme. This allows us to provide non-vacuous upper bounds on the\ngeneralization loss of the learned predictors, numerically computable after\neach task. We empirically evaluate our approach on several standard continual\nlearning benchmarks across Class-Incremental, Task-Incremental, and\nDomain-Incremental settings. Our results show that CoP2L is highly competitive\nacross all setups, often outperforming existing baselines, and significantly\nmitigating catastrophic forgetting compared to vanilla experience replay in the\nClass-Incremental setting. It is possible to leverage the bounds provided by\nCoP2L in practical scenarios to certify the predictor reliability on previously\nlearned tasks, in order to improve the trustworthiness of the continual\nlearning algorithm.", "AI": {"tldr": "CoP2L is a new continual learning method combining Pick-to-Learn and experience replay, providing generalization guarantees and outperforming baselines.", "motivation": "Existing continual learning methods lack theoretical guarantees and rely on heuristics. CoP2L addresses this by ensuring non-vacuous bounds on generalization loss.", "method": "CoP2L integrates Pick-to-Learn (sample compression theory) with experience replay, retaining representative samples per task efficiently.", "result": "CoP2L outperforms baselines in Class-, Task-, and Domain-Incremental settings, mitigating catastrophic forgetting.", "conclusion": "CoP2L offers reliable predictors with computable bounds, enhancing trustworthiness in continual learning."}}
{"id": "2506.01723", "pdf": "https://arxiv.org/pdf/2506.01723", "abs": "https://arxiv.org/abs/2506.01723", "authors": ["Soyoung Oh", "Xinting Huang", "Mathis Pink", "Michael Hahn", "Vera Demberg"], "title": "Tug-of-war between idiom's figurative and literal meanings in LLMs", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Idioms present a unique challenge for language models due to their\nnon-compositional figurative meanings, which often strongly diverge from the\nidiom's literal interpretation. This duality requires a model to learn\nrepresenting and deciding between the two meanings to interpret an idiom in a\nfigurative sense, or literally. In this paper, we employ tools from mechanistic\ninterpretability to trace how a large pretrained causal transformer\n(LLama3.2-1B-base) deals with this ambiguity. We localize three steps of idiom\nprocessing: First, the idiom's figurative meaning is retrieved in early\nattention and MLP sublayers. We identify specific attention heads which boost\nthe figurative meaning of the idiom while suppressing the idiom's literal\ninterpretation. The model subsequently represents the figurative representation\nthrough an intermediate path. Meanwhile, a parallel bypass route forwards\nliteral interpretation, ensuring that a both reading remain available. Overall,\nour findings provide a mechanistic evidence for idiom comprehension in an\nautoregressive transformer.", "AI": {"tldr": "The paper investigates how a large transformer model processes idioms, identifying specific mechanisms for retrieving figurative meanings while maintaining literal interpretations.", "motivation": "Idioms challenge language models due to their non-compositional meanings, requiring models to handle both figurative and literal interpretations.", "method": "Mechanistic interpretability tools are used to analyze how a pretrained transformer (LLama3.2-1B-base) processes idioms, focusing on attention and MLP layers.", "result": "Three processing steps are identified: figurative meaning retrieval in early layers, suppression of literal interpretation, and parallel paths for both meanings.", "conclusion": "The study provides mechanistic evidence for idiom comprehension in transformers, highlighting dual-path processing."}}
{"id": "2506.02738", "pdf": "https://arxiv.org/pdf/2506.02738", "abs": "https://arxiv.org/abs/2506.02738", "authors": ["Negin Baghbanzadeh", "Sajad Ashkezari", "Elham Dolatabadi", "Arash Afkanpour"], "title": "Open-PMC-18M: A High-Fidelity Large Scale Medical Dataset for Multimodal Representation Learning", "categories": ["cs.CV"], "comment": "15 pages", "summary": "Compound figures, which are multi-panel composites containing diverse\nsubfigures, are ubiquitous in biomedical literature, yet large-scale subfigure\nextraction remains largely unaddressed. Prior work on subfigure extraction has\nbeen limited in both dataset size and generalizability, leaving a critical open\nquestion: How does high-fidelity image-text alignment via large-scale subfigure\nextraction impact representation learning in vision-language models? We address\nthis gap by introducing a scalable subfigure extraction pipeline based on\ntransformer-based object detection, trained on a synthetic corpus of 500,000\ncompound figures, and achieving state-of-the-art performance on both ImageCLEF\n2016 and synthetic benchmarks. Using this pipeline, we release OPEN-PMC-18M, a\nlarge-scale high quality biomedical vision-language dataset comprising 18\nmillion clinically relevant subfigure-caption pairs spanning radiology,\nmicroscopy, and visible light photography. We train and evaluate\nvision-language models on our curated datasets and show improved performance\nacross retrieval, zero-shot classification, and robustness benchmarks,\noutperforming existing baselines. We release our dataset, models, and code to\nsupport reproducible benchmarks and further study into biomedical\nvision-language modeling and representation learning.", "AI": {"tldr": "The paper introduces a scalable subfigure extraction pipeline for biomedical compound figures, releasing a large dataset (OPEN-PMC-18M) and showing improved vision-language model performance.", "motivation": "Addressing the gap in large-scale subfigure extraction and its impact on vision-language models in biomedical literature.", "method": "A transformer-based object detection pipeline trained on 500,000 synthetic compound figures, applied to create OPEN-PMC-18M.", "result": "State-of-the-art performance on benchmarks and improved vision-language model tasks like retrieval and zero-shot classification.", "conclusion": "The work advances biomedical vision-language modeling, with released resources for reproducibility and further research."}}
{"id": "2505.20734", "pdf": "https://arxiv.org/pdf/2505.20734", "abs": "https://arxiv.org/abs/2505.20734", "authors": ["Zhuoyu Cheng", "Kohei Hatano", "Eiji Takimoto"], "title": "Adversarial bandit optimization for approximately linear functions", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "We consider a bandit optimization problem for nonconvex and non-smooth\nfunctions, where in each trial the loss function is the sum of a linear\nfunction and a small but arbitrary perturbation chosen after observing the\nplayer's choice. We give both expected and high probability regret bounds for\nthe problem. Our result also implies an improved high-probability regret bound\nfor the bandit linear optimization, a special case with no perturbation. We\nalso give a lower bound on the expected regret.", "AI": {"tldr": "The paper analyzes bandit optimization for nonconvex, nonsmooth functions with linear and perturbed losses, providing regret bounds and a lower bound.", "motivation": "To address the challenge of bandit optimization with nonconvex, nonsmooth functions and adversarial perturbations.", "method": "Analyzes regret bounds (expected and high probability) for the problem, including a special case of bandit linear optimization.", "result": "Improved high-probability regret bounds for bandit linear optimization and a lower bound on expected regret.", "conclusion": "The work advances understanding of bandit optimization under adversarial perturbations and nonconvexity."}}
{"id": "2503.20117", "pdf": "https://arxiv.org/pdf/2503.20117", "abs": "https://arxiv.org/abs/2503.20117", "authors": ["Bicheng Ying", "Zhe Li", "Haibo Yang"], "title": "Exact and Linear Convergence for Federated Learning under Arbitrary Client Participation is Attainable", "categories": ["cs.LG", "cs.DC"], "comment": "Under review", "summary": "This work tackles the fundamental challenges in Federated Learning (FL) posed\nby arbitrary client participation and data heterogeneity, prevalent\ncharacteristics in practical FL settings. It is well-established that popular\nFedAvg-style algorithms struggle with exact convergence and can suffer from\nslow convergence rates since a decaying learning rate is required to mitigate\nthese scenarios. To address these issues, we introduce the concept of\nstochastic matrix and the corresponding time-varying graphs as a novel modeling\ntool to accurately capture the dynamics of arbitrary client participation and\nthe local update procedure. Leveraging this approach, we offer a fresh\nperspective on designing FL algorithms, provide a rigorous quantitative\nanalysis of the limitations inherent in the FedAvg algorithm, and present\nFOCUS, Federated Optimization with Exact Convergence via Push-pull Strategy, a\nprovably convergent algorithm designed to effectively overcome the previously\nmentioned two challenges. More specifically, we provide a rigorous proof\ndemonstrating that FOCUS achieves exact convergence with a linear rate\nregardless of the arbitrary client participation, establishing it as the first\nwork to demonstrate this significant result.", "AI": {"tldr": "The paper introduces FOCUS, a Federated Learning algorithm with exact convergence, addressing challenges like arbitrary client participation and data heterogeneity.", "motivation": "To overcome the limitations of FedAvg-style algorithms in handling arbitrary client participation and data heterogeneity, which hinder exact and fast convergence.", "method": "Uses stochastic matrix and time-varying graphs to model client dynamics, leading to the design of FOCUS, a provably convergent algorithm with a push-pull strategy.", "result": "FOCUS achieves exact convergence with a linear rate, regardless of arbitrary client participation, a first in FL research.", "conclusion": "FOCUS provides a robust solution for FL challenges, offering exact convergence and faster rates compared to existing methods."}}
{"id": "2506.02132", "pdf": "https://arxiv.org/pdf/2506.02132", "abs": "https://arxiv.org/abs/2506.02132", "authors": ["Michael Li", "Nishant Subramani"], "title": "Model Internal Sleuthing: Finding Lexical Identity and Inflectional Morphology in Modern Language Models", "categories": ["cs.CL", "cs.LG"], "comment": null, "summary": "Large transformer-based language models dominate modern NLP, yet our\nunderstanding of how they encode linguistic information is rooted in studies of\nearly models like BERT and GPT-2. To better understand today's language models,\nwe investigate how both classical architectures (BERT, DeBERTa, GPT-2)and\ncontemporary large language models (Pythia, OLMo-2, Gemma-2, Qwen2.5,\nLlama-3.1) represent lexical identity and inflectional morphology. We train\nlinear and nonlinear classifiers on layer-wise activations to predict word\nlemmas and inflectional features. We discover that models concentrate lexical\ninformation linearly in early layers and increasingly nonlinearly in later\nlayers, while keeping inflectional information uniformly accessible and\nlinearly separable throughout the layers. Further analysis reveals that these\nmodels encode inflectional morphology through generalizable abstractions, but\nrely predominantly on memorization to encode lexical identity. Remarkably,\nthese patterns emerge across all 16 models we test, despite differences in\narchitecture, size, and training regime (including pretrained and\ninstruction-tuned variants). This consistency suggests that, despite\nsubstantial advances in LLM technologies, transformer models organize\nlinguistic information in similar ways, indicating that these properties could\nbe fundamental for next token prediction and are learned early during\npretraining. Our code is available at\nhttps://github.com/ml5885/model_internal_sleuthing", "AI": {"tldr": "The paper investigates how modern transformer-based language models encode lexical identity and inflectional morphology, revealing consistent patterns across architectures and sizes.", "motivation": "To understand how contemporary large language models (LLMs) represent linguistic information compared to early models like BERT and GPT-2.", "method": "Train linear and nonlinear classifiers on layer-wise activations to predict word lemmas and inflectional features across 16 models.", "result": "Lexical information is concentrated linearly in early layers and nonlinearly in later layers, while inflectional information remains uniformly accessible and linearly separable.", "conclusion": "Transformer models organize linguistic information similarly across architectures, suggesting these properties are fundamental for next-token prediction."}}
{"id": "2506.02845", "pdf": "https://arxiv.org/pdf/2506.02845", "abs": "https://arxiv.org/abs/2506.02845", "authors": ["Di Wen", "Lei Qi", "Kunyu Peng", "Kailun Yang", "Fei Teng", "Ao Luo", "Jia Fu", "Yufan Chen", "Ruiping Liu", "Yitian Shi", "M. Saquib Sarfraz", "Rainer Stiefelhagen"], "title": "Go Beyond Earth: Understanding Human Actions and Scenes in Microgravity Environments", "categories": ["cs.CV"], "comment": "15 pages, 3 figures, code are available at\n  https://github.com/LEI-QI-233/HAR-in-Space", "summary": "Despite substantial progress in video understanding, most existing datasets\nare limited to Earth's gravitational conditions. However, microgravity alters\nhuman motion, interactions, and visual semantics, revealing a critical gap for\nreal-world vision systems. This presents a challenge for domain-robust video\nunderstanding in safety-critical space applications. To address this, we\nintroduce MicroG-4M, the first benchmark for spatio-temporal and semantic\nunderstanding of human activities in microgravity. Constructed from real-world\nspace missions and cinematic simulations, the dataset includes 4,759 clips\ncovering 50 actions, 1,238 context-rich captions, and over 7,000\nquestion-answer pairs on astronaut activities and scene understanding.\nMicroG-4M supports three core tasks: fine-grained multi-label action\nrecognition, temporal video captioning, and visual question answering, enabling\na comprehensive evaluation of both spatial localization and semantic reasoning\nin microgravity contexts. We establish baselines using state-of-the-art models.\nAll data, annotations, and code are available at\nhttps://github.com/LEI-QI-233/HAR-in-Space.", "AI": {"tldr": "MicroG-4M is the first benchmark dataset for video understanding in microgravity, featuring 4,759 clips, 50 actions, and multiple tasks like action recognition and visual question answering.", "motivation": "Existing video datasets lack microgravity conditions, which are crucial for safety-critical space applications, highlighting the need for domain-robust video understanding.", "method": "The dataset is constructed from real-world space missions and cinematic simulations, supporting tasks like action recognition, video captioning, and visual question answering.", "result": "MicroG-4M includes 4,759 clips, 50 actions, 1,238 captions, and 7,000 QA pairs, with baselines established using state-of-the-art models.", "conclusion": "MicroG-4M fills a critical gap in video understanding for microgravity, enabling comprehensive evaluation of spatial and semantic reasoning in space-related contexts."}}
{"id": "2505.21677", "pdf": "https://arxiv.org/pdf/2505.21677", "abs": "https://arxiv.org/abs/2505.21677", "authors": ["Hung Anh Vu", "Galen Reeves", "Emily Wenger"], "title": "What happens when generative AI models train recursively on each others' generated outputs?", "categories": ["cs.LG", "cs.AI", "cs.CY"], "comment": "9 pages", "summary": "The internet is full of AI-generated content while also serving as a common\nsource of training data for generative AI (genAI) models. This duality raises\nthe possibility that future genAI models may be trained on other models'\ngenerated outputs. Prior work has studied consequences of models training on\ntheir own generated outputs, but limited work has considered what happens if\nmodels ingest content produced by other models. Given society's increasing\ndependence on genAI tools, understanding downstream effects of such\ndata-mediated model interactions is critical. To this end, we provide empirical\nevidence for how data-mediated interactions might unfold in practice, develop a\ntheoretical model for this interactive training process, and show\nexperimentally possible long-term results of such interactions. We find that\ndata-mediated interactions can benefit models by exposing them to novel\nconcepts perhaps missed in original training data, but also can homogenize\ntheir performance on shared tasks.", "AI": {"tldr": "The paper explores the effects of AI models training on outputs from other AI models, finding both benefits (exposure to new concepts) and drawbacks (performance homogenization).", "motivation": "The increasing reliance on generative AI and the potential for models to train on each other's outputs necessitates understanding the downstream effects of such interactions.", "method": "The study provides empirical evidence, develops a theoretical model, and conducts experiments to analyze data-mediated interactions between AI models.", "result": "Data-mediated interactions can introduce novel concepts to models but may also lead to homogenized performance on shared tasks.", "conclusion": "Understanding the implications of AI models training on each other's outputs is crucial for managing their long-term societal impact."}}
{"id": "2503.21224", "pdf": "https://arxiv.org/pdf/2503.21224", "abs": "https://arxiv.org/abs/2503.21224", "authors": ["Matthieu Meunier", "Christoph Reisinger", "Yufei Zhang"], "title": "Efficient Learning for Entropy-Regularized Markov Decision Processes via Multilevel Monte Carlo", "categories": ["cs.LG", "math.OC", "math.PR", "stat.ML", "65C05, 90C40 (Primary) 90C39, 60J20, 68Q32 (Secondary)"], "comment": "46 pages, 6 figures; improved bound on bias of the plain MC estimator\n  of T", "summary": "Designing efficient learning algorithms with complexity guarantees for Markov\ndecision processes (MDPs) with large or continuous state and action spaces\nremains a fundamental challenge. We address this challenge for\nentropy-regularized MDPs with Polish state and action spaces, assuming access\nto a generative model of the environment. We propose a novel family of\nmultilevel Monte Carlo (MLMC) algorithms that integrate fixed-point iteration\nwith MLMC techniques and a generic stochastic approximation of the Bellman\noperator. We quantify the precise impact of the chosen approximate Bellman\noperator on the accuracy of the resulting MLMC estimator. Leveraging this error\nanalysis, we show that using a biased plain MC estimate for the Bellman\noperator results in quasi-polynomial sample complexity, whereas an unbiased\nrandomized multilevel approximation of the Bellman operator achieves polynomial\nsample complexity in expectation. Notably, these complexity bounds are\nindependent of the dimensions or cardinalities of the state and action spaces,\ndistinguishing our approach from existing algorithms whose complexities scale\nwith the sizes of these spaces. We validate these theoretical performance\nguarantees through numerical experiments.", "AI": {"tldr": "Proposes MLMC algorithms for entropy-regularized MDPs with Polish spaces, achieving quasi-polynomial or polynomial sample complexity independent of state/action space sizes.", "motivation": "Addressing the challenge of efficient learning in large or continuous MDPs with complexity guarantees.", "method": "Novel MLMC algorithms combining fixed-point iteration, MLMC techniques, and stochastic Bellman operator approximation.", "result": "Quasi-polynomial sample complexity with biased MC, polynomial with unbiased MLMC, both independent of state/action dimensions.", "conclusion": "Theoretical and numerical validation shows improved efficiency over existing methods."}}
{"id": "2506.02426", "pdf": "https://arxiv.org/pdf/2506.02426", "abs": "https://arxiv.org/abs/2506.02426", "authors": ["Maryam Berijanian", "Kuldeep Singh", "Amin Sehati"], "title": "Comparative Analysis of AI Agent Architectures for Entity Relationship Classification", "categories": ["cs.CL", "cs.AI", "I.2.7; I.2.1"], "comment": null, "summary": "Entity relationship classification remains a challenging task in information\nextraction, especially in scenarios with limited labeled data and complex\nrelational structures. In this study, we conduct a comparative analysis of\nthree distinct AI agent architectures designed to perform relation\nclassification using large language models (LLMs). The agentic architectures\nexplored include (1) reflective self-evaluation, (2) hierarchical task\ndecomposition, and (3) a novel multi-agent dynamic example generation\nmechanism, each leveraging different modes of reasoning and prompt adaptation.\nIn particular, our dynamic example generation approach introduces real-time\ncooperative and adversarial prompting. We systematically compare their\nperformance across multiple domains and model backends. Our experiments\ndemonstrate that multi-agent coordination consistently outperforms standard\nfew-shot prompting and approaches the performance of fine-tuned models. These\nfindings offer practical guidance for the design of modular, generalizable\nLLM-based systems for structured relation extraction. The source codes and\ndataset are available at https://github.com/maryambrj/ALIEN.git.", "AI": {"tldr": "Comparative analysis of three AI agent architectures for relation classification using LLMs, showing multi-agent coordination outperforms few-shot prompting and nears fine-tuned models.", "motivation": "Address challenges in entity relationship classification with limited labeled data and complex relational structures.", "method": "Evaluate three agentic architectures: reflective self-evaluation, hierarchical task decomposition, and dynamic example generation with cooperative/adversarial prompting.", "result": "Multi-agent coordination outperforms few-shot prompting and approaches fine-tuned model performance.", "conclusion": "Provides practical guidance for designing modular, generalizable LLM-based systems for structured relation extraction."}}
{"id": "2506.02896", "pdf": "https://arxiv.org/pdf/2506.02896", "abs": "https://arxiv.org/abs/2506.02896", "authors": ["Adam Pardyl", "Dominik Matuszek", "Mateusz Przebieracz", "Marek Cygan", "Bartosz Zieli\u0144ski", "Maciej Wo\u0142czyk"], "title": "FlySearch: Exploring how vision-language models explore", "categories": ["cs.CV", "cs.LG", "cs.RO"], "comment": null, "summary": "The real world is messy and unstructured. Uncovering critical information\noften requires active, goal-driven exploration. It remains to be seen whether\nVision-Language Models (VLMs), which recently emerged as a popular zero-shot\ntool in many difficult tasks, can operate effectively in such conditions. In\nthis paper, we answer this question by introducing FlySearch, a 3D, outdoor,\nphotorealistic environment for searching and navigating to objects in complex\nscenes. We define three sets of scenarios with varying difficulty and observe\nthat state-of-the-art VLMs cannot reliably solve even the simplest exploration\ntasks, with the gap to human performance increasing as the tasks get harder. We\nidentify a set of central causes, ranging from vision hallucination, through\ncontext misunderstanding, to task planning failures, and we show that some of\nthem can be addressed by finetuning. We publicly release the benchmark,\nscenarios, and the underlying codebase.", "AI": {"tldr": "VLMs struggle with active exploration in complex 3D environments, with performance gaps widening as tasks get harder. FlySearch benchmark highlights key failure causes, some addressable by finetuning.", "motivation": "Assess whether Vision-Language Models (VLMs) can effectively perform goal-driven exploration in unstructured, real-world-like 3D environments.", "method": "Introduce FlySearch, a 3D photorealistic environment, and test VLMs on three difficulty levels of exploration tasks. Analyze failure causes like vision hallucination and task planning.", "result": "State-of-the-art VLMs fail even simple tasks, with performance gaps to humans increasing with difficulty. Some issues can be mitigated by finetuning.", "conclusion": "VLMs currently lack robustness for active exploration in complex settings, but benchmarks like FlySearch can guide improvements."}}
{"id": "2505.23786", "pdf": "https://arxiv.org/pdf/2505.23786", "abs": "https://arxiv.org/abs/2505.23786", "authors": ["Kazuki Egashira", "Robin Staab", "Mark Vero", "Jingxuan He", "Martin Vechev"], "title": "Mind the Gap: A Practical Attack on GGUF Quantization", "categories": ["cs.CR", "cs.AI", "cs.LG"], "comment": "ICML 2025", "summary": "With the increasing size of frontier LLMs, post-training quantization has\nbecome the standard for memory-efficient deployment. Recent work has shown that\nbasic rounding-based quantization schemes pose security risks, as they can be\nexploited to inject malicious behaviors into quantized models that remain\nhidden in full precision. However, existing attacks cannot be applied to more\ncomplex quantization methods, such as the GGUF family used in the popular\nollama and llama$.$cpp frameworks. In this work, we address this gap by\nintroducing the first attack on GGUF. Our key insight is that the quantization\nerror -- the difference between the full-precision weights and their\n(de-)quantized version -- provides sufficient flexibility to construct\nmalicious quantized models that appear benign in full precision. Leveraging\nthis, we develop an attack that trains the target malicious LLM while\nconstraining its weights based on quantization errors. We demonstrate the\neffectiveness of our attack on three popular LLMs across nine GGUF quantization\ndata types on three diverse attack scenarios: insecure code generation\n($\\Delta$=$88.7\\%$), targeted content injection ($\\Delta$=$85.0\\%$), and benign\ninstruction refusal ($\\Delta$=$30.1\\%$). Our attack highlights that (1) the\nmost widely used post-training quantization method is susceptible to\nadversarial interferences, and (2) the complexity of quantization schemes alone\nis insufficient as a defense.", "AI": {"tldr": "The paper introduces the first attack on GGUF quantization, showing how quantization errors can be exploited to inject hidden malicious behaviors into LLMs, despite appearing benign in full precision.", "motivation": "Existing attacks on quantization methods don't apply to complex schemes like GGUF, leaving a security gap. This work aims to address this vulnerability.", "method": "The attack trains a malicious LLM while constraining its weights based on quantization errors, leveraging the flexibility of these errors to hide malicious behaviors.", "result": "The attack succeeded in three scenarios: insecure code generation (88.7% success), targeted content injection (85.0%), and benign instruction refusal (30.1%).", "conclusion": "GGUF quantization is vulnerable to adversarial interference, and complexity alone isn't a sufficient defense against such attacks."}}
{"id": "2503.22733", "pdf": "https://arxiv.org/pdf/2503.22733", "abs": "https://arxiv.org/abs/2503.22733", "authors": ["Tomomasa Yamasaki", "Zhehui Wang", "Tao Luo", "Niangjun Chen", "Bo Wang"], "title": "RBFleX-NAS: Training-Free Neural Architecture Search Using Radial Basis Function Kernel and Hyperparameter Detection", "categories": ["cs.LG"], "comment": "15 pages, 17 figures, Published on IEEE Transactions on Neural\n  Networks and Learning Systems (TNNLS)", "summary": "Neural Architecture Search (NAS) is an automated technique to design optimal\nneural network architectures for a specific workload. Conventionally,\nevaluating candidate networks in NAS involves extensive training, which\nrequires significant time and computational resources. To address this,\ntraining-free NAS has been proposed to expedite network evaluation with minimal\nsearch time. However, state-of-the-art training-free NAS algorithms struggle to\nprecisely distinguish well-performing networks from poorly-performing networks,\nresulting in inaccurate performance predictions and consequently sub-optimal\ntop-1 network accuracy. Moreover, they are less effective in activation\nfunction exploration. To tackle the challenges, this paper proposes RBFleX-NAS,\na novel training-free NAS framework that accounts for both activation outputs\nand input features of the last layer with a Radial Basis Function (RBF) kernel.\nWe also present a detection algorithm to identify optimal hyperparameters using\nthe obtained activation outputs and input feature maps. We verify the efficacy\nof RBFleX-NAS over a variety of NAS benchmarks. RBFleX-NAS significantly\noutperforms state-of-the-art training-free NAS methods in terms of top-1\naccuracy, achieving this with short search time in NAS-Bench-201 and\nNAS-Bench-SSS. In addition, it demonstrates higher Kendall correlation compared\nto layer-based training-free NAS algorithms. Furthermore, we propose NAFBee, a\nnew activation design space that extends the activation type to encompass\nvarious commonly used functions. In this extended design space, RBFleX-NAS\ndemonstrates its superiority by accurately identifying the best-performing\nnetwork during activation function search, providing a significant advantage\nover other NAS algorithms.", "AI": {"tldr": "RBFleX-NAS is a training-free NAS framework using RBF kernels for better performance prediction and activation function exploration, outperforming existing methods in accuracy and efficiency.", "motivation": "Current training-free NAS methods struggle with accurate performance prediction and activation function exploration, leading to sub-optimal results.", "method": "Proposes RBFleX-NAS, leveraging RBF kernels for evaluating networks and a detection algorithm for hyperparameter optimization. Introduces NAFBee for extended activation function search.", "result": "RBFleX-NAS achieves higher top-1 accuracy and Kendall correlation, with shorter search time, outperforming state-of-the-art methods.", "conclusion": "RBFleX-NAS is a superior training-free NAS framework, excelling in accuracy and efficiency, especially in activation function exploration."}}
{"id": "2506.02442", "pdf": "https://arxiv.org/pdf/2506.02442", "abs": "https://arxiv.org/abs/2506.02442", "authors": ["Utsav Maskey", "Mark Dras", "Usman Naseem"], "title": "Should LLM Safety Be More Than Refusing Harmful Instructions?", "categories": ["cs.CL"], "comment": "Preprint", "summary": "This paper presents a systematic evaluation of Large Language Models' (LLMs)\nbehavior on long-tail distributed (encrypted) texts and their safety\nimplications. We introduce a two-dimensional framework for assessing LLM\nsafety: (1) instruction refusal-the ability to reject harmful obfuscated\ninstructions, and (2) generation safety-the suppression of generating harmful\nresponses. Through comprehensive experiments, we demonstrate that models that\npossess capabilities to decrypt ciphers may be susceptible to\nmismatched-generalization attacks: their safety mechanisms fail on at least one\nsafety dimension, leading to unsafe responses or over-refusal. Based on these\nfindings, we evaluate a number of pre-LLM and post-LLM safeguards and discuss\ntheir strengths and limitations. This work contributes to understanding the\nsafety of LLM in long-tail text scenarios and provides directions for\ndeveloping robust safety mechanisms.", "AI": {"tldr": "The paper evaluates LLM safety on long-tail encrypted texts, identifying vulnerabilities like mismatched-generalization attacks and assessing safeguards.", "motivation": "To understand LLM safety in handling encrypted or obfuscated texts and identify potential risks.", "method": "A two-dimensional framework tests LLM safety: instruction refusal and generation safety, followed by experiments on decryption capabilities.", "result": "Models decrypting ciphers may fail safety tests, leading to unsafe responses or over-refusal. Pre- and post-LLM safeguards are evaluated.", "conclusion": "The study highlights LLM safety gaps in long-tail scenarios and suggests directions for robust safety mechanisms."}}
{"id": "2506.03147", "pdf": "https://arxiv.org/pdf/2506.03147", "abs": "https://arxiv.org/abs/2506.03147", "authors": ["Bin Lin", "Zongjian Li", "Xinhua Cheng", "Yuwei Niu", "Yang Ye", "Xianyi He", "Shenghai Yuan", "Wangbo Yu", "Shaodong Wang", "Yunyang Ge", "Yatian Pang", "Li Yuan"], "title": "UniWorld: High-Resolution Semantic Encoders for Unified Visual Understanding and Generation", "categories": ["cs.CV", "cs.AI", "cs.CL"], "comment": null, "summary": "Although existing unified models achieve strong performance in\nvision-language understanding and text-to-image generation, they remain limited\nin addressing image perception and manipulation -- capabilities increasingly\ndemanded in practical applications. Recently, OpenAI introduced the powerful\nGPT-4o-Image model, which showcases advanced capabilities in comprehensive\nimage perception and manipulation, sparking widespread interest. Through\ncarefully designed experiments, we observe that GPT-4o-Image likely relies on\nsemantic encoders rather than VAEs for feature extraction, despite VAEs being\ncommonly regarded as crucial for image manipulation tasks. Inspired by this\ninsight, we propose UniWorld, a unified generative framework built upon\nsemantic features extracted from powerful multimodal large language models and\ncontrastive semantic encoders. Using only 2.7M training data, UniWorld achieves\nimpressive performance across diverse tasks, including image understanding,\ngeneration, manipulation, and perception. We fully open-source the UniWorld\nframework, including model weights, training and evaluation scripts, and\ndatasets to promote reproducibility and further research.", "AI": {"tldr": "UniWorld, a unified generative framework, leverages semantic features from multimodal LLMs and contrastive encoders, outperforming traditional VAE-based methods in image tasks with minimal training data.", "motivation": "Existing unified models lack advanced image perception and manipulation capabilities, despite growing demand. GPT-4o-Image's success inspired a shift from VAEs to semantic encoders.", "method": "Proposes UniWorld, using semantic features from multimodal LLMs and contrastive encoders, trained on 2.7M data points.", "result": "Achieves strong performance in image understanding, generation, manipulation, and perception.", "conclusion": "UniWorld is open-sourced to encourage reproducibility and further research in unified image tasks."}}
{"id": "2505.24293", "pdf": "https://arxiv.org/pdf/2505.24293", "abs": "https://arxiv.org/abs/2505.24293", "authors": ["James R. Golden"], "title": "Large Language Models are Locally Linear Mappings", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": "minor updates to Fig 2; code available at\n  https://github.com/jamesgolden1/llms-are-llms", "summary": "We demonstrate that the inference operations of several open-weight large\nlanguage models (LLMs) can be mapped to an exactly equivalent linear system for\nan input sequence without modifying the model weights or altering output\npredictions. Extending techniques from image diffusion models that exhibit\nlocal or piecewise linearity, we strategically alter the gradient computation\nwith respect to a given input sequence for a next-token prediction such that\nthe Jacobian of the model nearly exactly reproduces the forward prediction with\na linear system. We demonstrate this approach across models (Llama 3, Gemma 3,\nQwen 3, Phi 4, Mistral Ministral and OLMo 2, up to Llama 3.3 70B Q4) and show\nthrough the singular value decomposition of the detached Jacobian that these\nLLMs operate in extremely low-dimensional subspaces where many of the largest\nsingular vectors decode to concepts related to the most-likely output token.\nThis approach also allows us to examine the operation of each successive layer\n(and its attention and MLP components) as nearly-exact linear systems and\nobserve the emergence of semantic concepts. Despite their expressive power and\nglobal nonlinearity, modern LLMs can be interpreted through nearly-exact\nlocally linear decompositions that provide insights into their internal\nrepresentations and reveal interpretable semantic structures in the next-token\nprediction process.", "AI": {"tldr": "The paper shows that LLMs' inference operations can be mapped to linear systems without altering weights or outputs, revealing low-dimensional subspaces and interpretable semantic structures.", "motivation": "To understand and interpret the internal workings of large language models (LLMs) by mapping their inference to linear systems.", "method": "Extends techniques from image diffusion models to alter gradient computation, enabling nearly exact linear system representation of LLMs.", "result": "LLMs operate in low-dimensional subspaces with interpretable semantic concepts, and their layers can be analyzed as linear systems.", "conclusion": "Despite global nonlinearity, LLMs can be interpreted through locally linear decompositions, providing insights into their internal representations."}}
{"id": "2504.06212", "pdf": "https://arxiv.org/pdf/2504.06212", "abs": "https://arxiv.org/abs/2504.06212", "authors": ["Thomas Mulc", "Mike Anderson", "Paul Cubre", "Huikun Zhang", "Ivy Liu", "Saket Kumar"], "title": "NNN: Next-Generation Neural Networks for Marketing Measurement", "categories": ["cs.LG", "stat.AP"], "comment": "The title was updated to reflect broader scope. We clarified that our\n  method is not an MMM and emphasized its experimental nature. R2 values in\n  Tables 1 and 2 were corrected after fixing a bug that inflated NNN scores.\n  Notation in the unrolling section now uses 0-indexing. We noted NNN has not\n  been tested with many channels, added an acknowledgment, and improved grammar", "summary": "We present NNN, an experimental Transformer-based neural network approach to\nmarketing measurement. Unlike Marketing Mix Models (MMMs) which rely on scalar\ninputs and parametric decay functions, NNN uses rich embeddings to capture both\nquantitative and qualitative aspects of marketing and organic channels (e.g.,\nsearch queries, ad creatives). This, combined with its attention mechanism,\npotentially enables NNN to model complex interactions, capture long-term\neffects, and improve sales attribution accuracy. We show that L1 regularization\npermits the use of such expressive models in typical data-constrained settings.\nEvaluating NNN on simulated and real-world data demonstrates its efficacy,\nparticularly through considerable improvement in predictive power. In addition\nto marketing measurement, the NNN framework can provide valuable, complementary\ninsights through model probing, such as evaluating keyword or creative\neffectiveness.", "AI": {"tldr": "NNN is a Transformer-based neural network for marketing measurement, outperforming traditional models by capturing complex interactions and long-term effects with rich embeddings and attention mechanisms.", "motivation": "Traditional Marketing Mix Models (MMMs) lack the ability to capture qualitative aspects and complex interactions in marketing data, prompting the need for a more expressive approach.", "method": "NNN uses Transformer-based architecture with rich embeddings and attention mechanisms, enhanced by L1 regularization for data-constrained settings.", "result": "NNN shows significant improvement in predictive power on simulated and real-world data, along with additional insights from model probing.", "conclusion": "NNN is effective for marketing measurement and offers complementary insights, making it a valuable tool beyond traditional methods."}}
{"id": "2506.02544", "pdf": "https://arxiv.org/pdf/2506.02544", "abs": "https://arxiv.org/abs/2506.02544", "authors": ["Yang Tian", "Fan Liu", "Jingyuan Zhang", "Victoria W.", "Yupeng Hu", "Liqiang Nie"], "title": "CoRe-MMRAG: Cross-Source Knowledge Reconciliation for Multimodal RAG", "categories": ["cs.CL", "cs.AI"], "comment": "Accepted to ACL 2025 Main", "summary": "Multimodal Retrieval-Augmented Generation (MMRAG) has been introduced to\nenhance Multimodal Large Language Models by incorporating externally retrieved\nmultimodal knowledge, but it introduces two challenges: Parametric-Retrieved\nKnowledge Inconsistency (PRKI), where discrepancies between parametric and\nretrieved knowledge create uncertainty in determining reliability, and\nVisual-Textual Knowledge Inconsistency (VTKI), where misalignment between\nvisual and textual sources disrupts entity representation. To address these\nchallenges, we propose Cross-source knowledge \\textbf{Re}conciliation for\nMultimodal RAG (CoRe-MMRAG), a novel end-to-end framework that effectively\nreconciles inconsistencies across knowledge sources. CoRe-MMRAG follows a\nfour-stage pipeline: it first generates an internal response from parametric\nknowledge, then selects the most relevant multimodal evidence via joint\nsimilarity assessment, generates an external response, and finally integrates\nboth to produce a reliable answer. Additionally, a specialized training\nparadigm enhances knowledge source discrimination, multimodal integration, and\nunified answer generation. Experiments on KB-VQA benchmarks show that\nCoRe-MMRAG achieves substantial improvements over baseline methods, achieving\n5.6% and 9.3% performance gains on InfoSeek and Encyclopedic-VQA, respectively.", "AI": {"tldr": "CoRe-MMRAG addresses inconsistencies in multimodal knowledge retrieval by reconciling parametric and retrieved knowledge, improving reliability and performance.", "motivation": "To resolve challenges of Parametric-Retrieved Knowledge Inconsistency (PRKI) and Visual-Textual Knowledge Inconsistency (VTKI) in Multimodal RAG.", "method": "A four-stage pipeline: internal response generation, multimodal evidence selection, external response generation, and integration. Includes a specialized training paradigm.", "result": "Achieves 5.6% and 9.3% performance gains on InfoSeek and Encyclopedic-VQA benchmarks.", "conclusion": "CoRe-MMRAG effectively reconciles knowledge inconsistencies, enhancing multimodal retrieval-augmented generation."}}
{"id": "2412.03293", "pdf": "https://arxiv.org/pdf/2412.03293", "abs": "https://arxiv.org/abs/2412.03293", "authors": ["Junjie Wen", "Minjie Zhu", "Yichen Zhu", "Zhibin Tang", "Jinming Li", "Zhongyi Zhou", "Chengmeng Li", "Xiaoyu Liu", "Yaxin Peng", "Chaomin Shen", "Feifei Feng"], "title": "Diffusion-VLA: Generalizable and Interpretable Robot Foundation Model via Self-Generated Reasoning", "categories": ["cs.RO", "cs.CV"], "comment": "Accepted by ICML 2025. The project page is available at:\n  http://diffusion-vla.github.io", "summary": "In this paper, we present DiffusionVLA, a novel framework that seamlessly\ncombines the autoregression model with the diffusion model for learning\nvisuomotor policy. Central to our approach is a next-token prediction\nobjective, enabling the model to reason effectively over the user's query in\nthe context of current observations. Subsequently, a diffusion model is\nattached to generate robust action outputs. To enhance policy learning through\nself-reasoning, we introduce a novel reasoning injection module that integrates\nreasoning phrases directly into the policy learning process. The whole\nframework is simple and flexible, making it easy to deploy and upgrade. We\nconduct extensive experiments using multiple real robots to validate the\neffectiveness of DiffusionVLA. Our tests include a challenging factory sorting\ntask, where DiffusionVLA successfully categorizes objects, including those not\nseen during training. We observe that the reasoning module makes the model\ninterpretable. It allows observers to understand the model thought process and\nidentify potential causes of policy failures. Additionally, we test\nDiffusionVLA on a zero-shot bin-picking task, achieving 63.7\\% accuracy on 102\npreviously unseen objects. Our method demonstrates robustness to visual\nchanges, such as distractors and new backgrounds, and easily adapts to new\nembodiments. Furthermore, DiffusionVLA can follow novel instructions and retain\nconversational ability. Notably, DiffusionVLA is data-efficient and fast at\ninference; our smallest DiffusionVLA-2B runs 82Hz on a single A6000 GPU and can\ntrain from scratch on less than 50 demonstrations for a complex task. Finally,\nwe scale the model from 2B to 72B parameters, showcasing improved\ngeneralization capabilities with increased model size.", "AI": {"tldr": "DiffusionVLA combines autoregression and diffusion models for visuomotor policy learning, featuring a reasoning module for interpretability and robustness. It excels in zero-shot tasks and adapts to new environments, achieving high accuracy and efficiency.", "motivation": "To create a flexible, interpretable, and robust framework for visuomotor policy learning that integrates reasoning and diffusion models for improved performance and adaptability.", "method": "Uses a next-token prediction objective for reasoning over queries and observations, coupled with a diffusion model for action generation. Introduces a reasoning injection module for self-reasoning during policy learning.", "result": "Achieves 63.7% accuracy in zero-shot bin-picking, handles unseen objects, and adapts to visual changes. Runs at 82Hz on a single GPU and trains efficiently with minimal demonstrations.", "conclusion": "DiffusionVLA is a scalable, efficient, and interpretable framework for visuomotor tasks, demonstrating strong generalization and adaptability."}}
{"id": "2505.24298", "pdf": "https://arxiv.org/pdf/2505.24298", "abs": "https://arxiv.org/abs/2505.24298", "authors": ["Wei Fu", "Jiaxuan Gao", "Xujie Shen", "Chen Zhu", "Zhiyu Mei", "Chuyi He", "Shusheng Xu", "Guo Wei", "Jun Mei", "Jiashu Wang", "Tongkai Yang", "Binhang Yuan", "Yi Wu"], "title": "AReaL: A Large-Scale Asynchronous Reinforcement Learning System for Language Reasoning", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Reinforcement learning (RL) has become a dominant paradigm for training large\nlanguage models (LLMs), particularly for reasoning tasks. Effective RL for LLMs\nrequires massive parallelization and poses an urgent need for efficient\ntraining systems. Most existing large-scale RL systems for LLMs are\nsynchronous, alternating generation and training in a batch setting where\nrollouts in each training batch are generated by the same model. This approach\nstabilizes RL training but suffers from severe system-level inefficiency:\ngeneration must wait until the longest output in the batch is completed before\nmodel updates, resulting in GPU underutilization. We present AReaL, a fully\nasynchronous RL system that completely decouples generation from training.\nRollout workers in AReaL continuously generate new outputs without waiting,\nwhile training workers update the model whenever a batch of data is collected.\nAReaL also incorporates a collection of system-level optimizations, leading to\nsubstantially higher GPU utilization. To stabilize RL training, AReaL balances\nthe workload of rollout and training workers to control data staleness, and\nadopts a staleness-enhanced PPO variant to better handle outdated training\nsamples. Extensive experiments on math and code reasoning benchmarks show that\nAReaL achieves up to 2.77$\\times$ training speedup compared to synchronous\nsystems with the same number of GPUs and matched or improved final performance.\nThe code of AReaL is available at https://github.com/inclusionAI/AReaL/.", "AI": {"tldr": "AReaL is an asynchronous RL system for LLMs that decouples generation from training, improving GPU utilization and achieving faster training speeds compared to synchronous systems.", "motivation": "Existing synchronous RL systems for LLMs suffer from inefficiency due to waiting for batch generation, leading to GPU underutilization.", "method": "AReaL decouples generation and training, uses system-level optimizations, and employs a staleness-enhanced PPO variant to handle outdated data.", "result": "AReaL achieves up to 2.77\u00d7 training speedup with matched or improved performance on math and code reasoning benchmarks.", "conclusion": "AReaL offers a scalable and efficient solution for RL training in LLMs, addressing inefficiencies in synchronous systems."}}
{"id": "2504.09132", "pdf": "https://arxiv.org/pdf/2504.09132", "abs": "https://arxiv.org/abs/2504.09132", "authors": ["Matthew B. Webster", "Dongheon Lee", "Joonnyong Lee"], "title": "Self-Supervised Autoencoder Network for Robust Heart Rate Extraction from Noisy Photoplethysmogram: Applying Blind Source Separation to Biosignal Analysis", "categories": ["cs.LG", "eess.SP", "I.2.6"], "comment": "12 pages, 5 figures, 1 table, preprint", "summary": "Biosignals can be viewed as mixtures measuring particular physiological\nevents, and blind source separation (BSS) aims to extract underlying source\nsignals from mixtures. This paper proposes a self-supervised multi-encoder\nautoencoder (MEAE) to separate heartbeat-related source signals from\nphotoplethysmogram (PPG), enhancing heart rate (HR) detection in noisy PPG\ndata. The MEAE is trained on PPG signals from a large open polysomnography\ndatabase without any pre-processing or data selection. The trained network is\nthen applied to a noisy PPG dataset collected during the daily activities of\nnine subjects. The extracted heartbeat-related source signal significantly\nimproves HR detection as compared to the original PPG. The absence of\npre-processing and the self-supervised nature of the proposed method, combined\nwith its strong performance, highlight the potential of MEAE for BSS in\nbiosignal analysis.", "AI": {"tldr": "A self-supervised multi-encoder autoencoder (MEAE) is proposed to separate heartbeat-related signals from PPG, improving heart rate detection in noisy data without pre-processing.", "motivation": "To enhance heart rate detection in noisy PPG data by extracting underlying source signals using a self-supervised approach.", "method": "A multi-encoder autoencoder (MEAE) is trained on PPG signals from a polysomnography database without pre-processing, then applied to noisy PPG data.", "result": "The extracted heartbeat-related signal significantly improves heart rate detection compared to the original PPG.", "conclusion": "The MEAE's self-supervised nature and strong performance show promise for blind source separation in biosignal analysis."}}
{"id": "2506.02689", "pdf": "https://arxiv.org/pdf/2506.02689", "abs": "https://arxiv.org/abs/2506.02689", "authors": ["Liang Yue", "Yihong Tang", "Kehai Chen", "Jie Liu", "Min Zhang"], "title": "MASTER: Enhancing Large Language Model via Multi-Agent Simulated Teaching", "categories": ["cs.CL"], "comment": null, "summary": "Instruction fine-tuning is crucial in NLP tasks, enhancing pretrained models'\ninstruction-following capabilities and task-specific performance. However,\nobtaining high-quality fine-tuning data for large models is challenging due to\ndata collection difficulties and high production costs. To address this, we\npropose MASTER, a novel data augmentation method that enriches original data\nthrough interactions among multiple agents with varying cognitive levels. We\nsimulate three pedagogically grounded teaching scenarios, leveraging\nmulti-agent conversations to generate high-quality teacher-student interaction\ndata. Utilizing MASTER, we construct BOOST-QA, a fine-tuning dataset augmented\nfrom existing datasets like Orca-Math-200k, ProcQA, and OpenHermes2.5.\nExperiments show that models fine-tuned with BOOST-QA perform excellently\nacross multiple benchmarks, demonstrating strong multitask generalization.\nNotably, MASTER significantly improves models' reasoning abilities in complex\ntasks, providing valuable insights for future research.", "AI": {"tldr": "MASTER is a data augmentation method using multi-agent interactions to generate high-quality fine-tuning data, improving model performance and reasoning.", "motivation": "Obtaining high-quality fine-tuning data for large NLP models is challenging due to data collection difficulties and costs.", "method": "MASTER enriches data through multi-agent interactions, simulating teaching scenarios to create teacher-student interaction data.", "result": "Models fine-tuned with MASTER-augmented data (BOOST-QA) excel in benchmarks and show strong multitask generalization, especially in reasoning.", "conclusion": "MASTER effectively addresses data scarcity, enhancing model performance and offering insights for future research."}}
{"id": "2502.09775", "pdf": "https://arxiv.org/pdf/2502.09775", "abs": "https://arxiv.org/abs/2502.09775", "authors": ["Yuhui Zhang", "Yuchang Su", "Chenyu Wang", "Tianhong Li", "Zoe Wefers", "Jeffrey Nirschl", "James Burgess", "Daisy Ding", "Alejandro Lozano", "Emma Lundberg", "Serena Yeung-Levy"], "title": "CellFlux: Simulating Cellular Morphology Changes via Flow Matching", "categories": ["q-bio.QM", "cs.CV", "cs.LG", "q-bio.BM", "q-bio.CB"], "comment": "Published at ICML 2025", "summary": "Building a virtual cell capable of accurately simulating cellular behaviors\nin silico has long been a dream in computational biology. We introduce\nCellFlux, an image-generative model that simulates cellular morphology changes\ninduced by chemical and genetic perturbations using flow matching. Unlike prior\nmethods, CellFlux models distribution-wise transformations from unperturbed to\nperturbed cell states, effectively distinguishing actual perturbation effects\nfrom experimental artifacts such as batch effects -- a major challenge in\nbiological data. Evaluated on chemical (BBBC021), genetic (RxRx1), and combined\nperturbation (JUMP) datasets, CellFlux generates biologically meaningful cell\nimages that faithfully capture perturbation-specific morphological changes,\nachieving a 35% improvement in FID scores and a 12% increase in mode-of-action\nprediction accuracy over existing methods. Additionally, CellFlux enables\ncontinuous interpolation between cellular states, providing a potential tool\nfor studying perturbation dynamics. These capabilities mark a significant step\ntoward realizing virtual cell modeling for biomedical research. Project page:\nhttps://yuhui-zh15.github.io/CellFlux/.", "AI": {"tldr": "CellFlux is an image-generative model using flow matching to simulate cellular morphology changes from perturbations, outperforming existing methods in accuracy and prediction.", "motivation": "To address the challenge of accurately simulating cellular behaviors in silico and distinguishing actual perturbation effects from experimental artifacts.", "method": "Uses flow matching to model distribution-wise transformations from unperturbed to perturbed cell states.", "result": "Achieves 35% better FID scores and 12% higher mode-of-action prediction accuracy, generating biologically meaningful cell images.", "conclusion": "CellFlux advances virtual cell modeling, offering tools for studying perturbation dynamics in biomedical research."}}
{"id": "2505.24492", "pdf": "https://arxiv.org/pdf/2505.24492", "abs": "https://arxiv.org/abs/2505.24492", "authors": ["David Steinmann", "Wolfgang Stammer", "Antonia W\u00fcst", "Kristian Kersting"], "title": "Object Centric Concept Bottlenecks", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Developing high-performing, yet interpretable models remains a critical\nchallenge in modern AI. Concept-based models (CBMs) attempt to address this by\nextracting human-understandable concepts from a global encoding (e.g., image\nencoding) and then applying a linear classifier on the resulting concept\nactivations, enabling transparent decision-making. However, their reliance on\nholistic image encodings limits their expressiveness in object-centric\nreal-world settings and thus hinders their ability to solve complex vision\ntasks beyond single-label classification. To tackle these challenges, we\nintroduce Object-Centric Concept Bottlenecks (OCB), a framework that combines\nthe strengths of CBMs and pre-trained object-centric foundation models,\nboosting performance and interpretability. We evaluate OCB on complex image\ndatasets and conduct a comprehensive ablation study to analyze key components\nof the framework, such as strategies for aggregating object-concept encodings.\nThe results show that OCB outperforms traditional CBMs and allows one to make\ninterpretable decisions for complex visual tasks.", "AI": {"tldr": "OCB combines CBMs with object-centric models to improve performance and interpretability in complex vision tasks.", "motivation": "Addressing the limitations of CBMs in handling object-centric real-world settings and complex vision tasks.", "method": "Introduces Object-Centric Concept Bottlenecks (OCB), leveraging pre-trained object-centric models and concept activations.", "result": "OCB outperforms traditional CBMs and enables interpretable decisions for complex visual tasks.", "conclusion": "OCB successfully bridges the gap between performance and interpretability in AI models for complex vision tasks."}}
{"id": "2505.01874", "pdf": "https://arxiv.org/pdf/2505.01874", "abs": "https://arxiv.org/abs/2505.01874", "authors": ["Youssef Allouah", "Rachid Guerraoui", "John Stephan"], "title": "Towards Trustworthy Federated Learning with Untrusted Participants", "categories": ["cs.LG", "cs.CR", "cs.DC"], "comment": "ICML 2025 conference paper", "summary": "Resilience against malicious participants and data privacy are essential for\ntrustworthy federated learning, yet achieving both with good utility typically\nrequires the strong assumption of a trusted central server. This paper shows\nthat a significantly weaker assumption suffices: each pair of participants\nshares a randomness seed unknown to others. In a setting where malicious\nparticipants may collude with an untrusted server, we propose CafCor, an\nalgorithm that integrates robust gradient aggregation with correlated noise\ninjection, using shared randomness between participants. We prove that CafCor\nachieves strong privacy-utility trade-offs, significantly outperforming local\ndifferential privacy (DP) methods, which do not make any trust assumption,\nwhile approaching central DP utility, where the server is fully trusted.\nEmpirical results on standard benchmarks validate CafCor's practicality,\nshowing that privacy and robustness can coexist in distributed systems without\nsacrificing utility or trusting the server.", "AI": {"tldr": "CafCor enables privacy and resilience in federated learning without a trusted server, using shared randomness between participants and outperforming local DP methods.", "motivation": "Addressing the need for resilience against malicious participants and data privacy in federated learning without relying on a trusted central server.", "method": "Proposes CafCor, integrating robust gradient aggregation with correlated noise injection using shared randomness between participants.", "result": "Achieves strong privacy-utility trade-offs, outperforming local DP and nearing central DP utility.", "conclusion": "Privacy and robustness can coexist in distributed systems without trusting the server or sacrificing utility."}}
{"id": "2506.02701", "pdf": "https://arxiv.org/pdf/2506.02701", "abs": "https://arxiv.org/abs/2506.02701", "authors": ["Masaki Sakata", "Sho Yokoi", "Benjamin Heinzerling", "Takumi Ito", "Kentaro Inui"], "title": "On Entity Identification in Language Models", "categories": ["cs.CL"], "comment": "ACL 2025 Findings; 26 pages, 13 figures, 9 tables", "summary": "We analyze the extent to which internal representations of language models\n(LMs) identify and distinguish mentions of named entities, focusing on the\nmany-to-many correspondence between entities and their mentions. We first\nformulate two problems of entity mentions -- ambiguity and variability -- and\npropose a framework analogous to clustering quality metrics. Specifically, we\nquantify through cluster analysis of LM internal representations the extent to\nwhich mentions of the same entity cluster together and mentions of different\nentities remain separated. Our experiments examine five Transformer-based\nautoregressive models, showing that they effectively identify and distinguish\nentities with metrics analogous to precision and recall ranging from 0.66 to\n0.9. Further analysis reveals that entity-related information is compactly\nrepresented in a low-dimensional linear subspace at early LM layers.\nAdditionally, we clarify how the characteristics of entity representations\ninfluence word prediction performance. These findings are interpreted through\nthe lens of isomorphism between LM representations and entity-centric knowledge\nstructures in the real world, providing insights into how LMs internally\norganize and use entity information.", "AI": {"tldr": "The paper analyzes how language models (LMs) internally represent named entities, focusing on ambiguity and variability in mentions. It proposes a clustering-based framework to evaluate entity mention identification and distinction, achieving precision and recall metrics of 0.66 to 0.9. Findings reveal compact, low-dimensional entity representations in early LM layers and their impact on word prediction.", "motivation": "To understand how LMs internally identify and distinguish named entity mentions, addressing the challenges of ambiguity and variability in entity-mention relationships.", "method": "A clustering-based framework is applied to LM internal representations, quantifying how mentions of the same entity cluster and mentions of different entities separate. Experiments involve five Transformer-based autoregressive models.", "result": "LMs effectively identify and distinguish entities, with precision and recall metrics ranging from 0.66 to 0.9. Entity information is compactly represented in early layers and influences word prediction.", "conclusion": "The study reveals isomorphism between LM representations and real-world entity-centric knowledge, offering insights into how LMs organize and use entity information internally."}}
{"id": "2503.16424", "pdf": "https://arxiv.org/pdf/2503.16424", "abs": "https://arxiv.org/abs/2503.16424", "authors": ["Xi Liu", "Chaoyi Zhou", "Nanxuan Zhao", "Siyu Huang"], "title": "B\u00e9zier Splatting for Fast and Differentiable Vector Graphics Rendering", "categories": ["cs.GR", "cs.CV"], "comment": "Project page: https://xiliu8006.github.io/Bezier_splatting_project/", "summary": "Differentiable vector graphics (VGs) are widely used in image vectorization\nand vector synthesis, while existing representations are costly to optimize and\nstruggle to achieve high-quality rendering results for high-resolution images.\nThis work introduces a new differentiable VG representation, dubbed B\\'ezier\nSplatting, that enables fast yet high-fidelity VG rasterization. B\\'ezier\nSplatting samples 2D Gaussians along B\\'ezier curves, which naturally provide\npositional gradients at object boundaries. Thanks to the efficient\nsplatting-based differentiable rasterizer, B\\'ezier Splatting achieves 30x and\n150x faster per forward and backward rasterization step for open curves\ncompared to DiffVG. Additionally, we introduce an adaptive pruning and\ndensification strategy that dynamically adjusts the spatial distribution of\ncurves to escape local minima, further improving VG quality. Furthermore, our\nnew VG representation supports conversion to standard XML-based SVG format,\nenhancing interoperability with existing VG tools and pipelines. Experimental\nresults show that B\\'ezier Splatting significantly outperforms existing methods\nwith better visual fidelity and significant optimization speedup.", "AI": {"tldr": "B\u00e9zier Splatting introduces a fast, high-fidelity differentiable VG representation using 2D Gaussians along B\u00e9zier curves, outperforming existing methods in speed and quality.", "motivation": "Existing differentiable VG representations are slow and struggle with high-resolution rendering, prompting the need for a more efficient solution.", "method": "Uses B\u00e9zier curves with 2D Gaussian sampling for gradients and a splatting-based rasterizer, plus adaptive pruning/densification for optimization.", "result": "Achieves 30x and 150x faster forward/backward rasterization than DiffVG, with better visual fidelity and SVG compatibility.", "conclusion": "B\u00e9zier Splatting offers superior performance and quality, enhancing VG optimization and interoperability."}}
{"id": "2506.00095", "pdf": "https://arxiv.org/pdf/2506.00095", "abs": "https://arxiv.org/abs/2506.00095", "authors": ["Yuchong Li", "Xiaojun Zeng", "Chihua Fang", "Jian Yang", "Fucang Jia", "Lei Zhang"], "title": "ClinBench-HPB: A Clinical Benchmark for Evaluating LLMs in Hepato-Pancreato-Biliary Diseases", "categories": ["cs.CY", "cs.AI", "cs.CL"], "comment": null, "summary": "Hepato-pancreato-biliary (HPB) disorders represent a global public health\nchallenge due to their high morbidity and mortality. Although large language\nmodels (LLMs) have shown promising performance in general medical\nquestion-answering tasks, the current evaluation benchmarks are mostly derived\nfrom standardized examinations or manually designed questions, lacking HPB\ncoverage and clinical cases. To address these issues, we systematically\neatablish an HPB disease evaluation benchmark comprising 3,535 closed-ended\nmultiple-choice questions and 337 open-ended real diagnosis cases, which\nencompasses all the 33 main categories and 465 subcategories of HPB diseases\ndefined in the International Statistical Classification of Diseases, 10th\nRevision (ICD-10). The multiple-choice questions are curated from public\ndatasets and synthesized data, and the clinical cases are collected from\nprestigious medical journals, case-sharing platforms, and collaborating\nhospitals. By evalauting commercial and open-source general and medical LLMs on\nour established benchmark, namely ClinBench-HBP, we find that while commercial\nLLMs perform competently on medical exam questions, they exhibit substantial\nperformance degradation on HPB diagnosis tasks, especially on complex,\ninpatient clinical cases. Those medical LLMs also show limited generalizability\nto HPB diseases. Our results reveal the critical limitations of current LLMs in\nthe domain of HPB diseases, underscoring the imperative need for future medical\nLLMs to handle real, complex clinical diagnostics rather than simple medical\nexam questions. The benchmark will be released at\nhttps://clinbench-hpb.github.io.", "AI": {"tldr": "The paper introduces ClinBench-HPB, a benchmark for evaluating LLMs on HPB diseases, revealing their limitations in handling real clinical cases.", "motivation": "Current LLM benchmarks lack coverage of HPB diseases and real clinical cases, limiting their applicability in this critical medical domain.", "method": "The authors created a benchmark with 3,535 multiple-choice questions and 337 open-ended real diagnosis cases, covering all HPB disease categories in ICD-10.", "result": "Commercial and medical LLMs perform well on exam questions but poorly on complex HPB diagnosis tasks, showing limited generalizability.", "conclusion": "The study highlights the need for LLMs to improve real clinical diagnostics and releases the benchmark for future research."}}
{"id": "2505.14613", "pdf": "https://arxiv.org/pdf/2505.14613", "abs": "https://arxiv.org/abs/2505.14613", "authors": ["Emmanuel Noutahi", "Jason Hartford", "Prudencio Tossou", "Shawn Whitfield", "Alisandra K. Denton", "Cas Wognum", "Kristina Ulicna", "Michael Craig", "Jonathan Hsu", "Michael Cuccarese", "Emmanuel Bengio", "Dominique Beaini", "Christopher Gibson", "Daniel Cohen", "Berton Earnshaw"], "title": "Virtual Cells: Predict, Explain, Discover", "categories": ["cs.LG", "q-bio.QM"], "comment": null, "summary": "Drug discovery is fundamentally a process of inferring the effects of\ntreatments on patients, and would therefore benefit immensely from\ncomputational models that can reliably simulate patient responses, enabling\nresearchers to generate and test large numbers of therapeutic hypotheses safely\nand economically before initiating costly clinical trials. Even a more specific\nmodel that predicts the functional response of cells to a wide range of\nperturbations would be tremendously valuable for discovering safe and effective\ntreatments that successfully translate to the clinic. Creating such virtual\ncells has long been a goal of the computational research community that\nunfortunately remains unachieved given the daunting complexity and scale of\ncellular biology. Nevertheless, recent advances in AI, computing power, lab\nautomation, and high-throughput cellular profiling provide new opportunities\nfor reaching this goal. In this perspective, we present a vision for developing\nand evaluating virtual cells that builds on our experience at Recursion. We\nargue that in order to be a useful tool to discover novel biology, virtual\ncells must accurately predict the functional response of a cell to\nperturbations and explain how the predicted response is a consequence of\nmodifications to key biomolecular interactions. We then introduce key\nprinciples for designing therapeutically-relevant virtual cells, describe a\nlab-in-the-loop approach for generating novel insights with them, and advocate\nfor biologically-grounded benchmarks to guide virtual cell development.\nFinally, we make the case that our approach to virtual cells provides a useful\nframework for building other models at higher levels of organization, including\nvirtual patients. We hope that these directions prove useful to the research\ncommunity in developing virtual models optimized for positive impact on drug\ndiscovery outcomes.", "AI": {"tldr": "The paper discusses the potential of virtual cells in drug discovery, emphasizing the need for accurate predictions of cellular responses to perturbations and explaining biomolecular interactions. It outlines principles for designing therapeutically relevant virtual cells and advocates for biologically grounded benchmarks.", "motivation": "The motivation is to improve drug discovery by developing computational models (virtual cells) that can simulate patient responses, reducing the need for costly clinical trials.", "method": "The method involves a lab-in-the-loop approach for generating insights, designing virtual cells with therapeutic relevance, and using biologically grounded benchmarks.", "result": "The paper presents a vision for virtual cells that predict functional responses and explain biomolecular interactions, aiming to enhance drug discovery.", "conclusion": "The conclusion advocates for virtual cells as a framework for higher-level models (e.g., virtual patients) to optimize drug discovery outcomes."}}
{"id": "2506.03106", "pdf": "https://arxiv.org/pdf/2506.03106", "abs": "https://arxiv.org/abs/2506.03106", "authors": ["Xiaoying Zhang", "Hao Sun", "Yipeng Zhang", "Kaituo Feng", "Chaochao Lu", "Chao Yang", "Helen Meng"], "title": "Critique-GRPO: Advancing LLM Reasoning with Natural Language and Numerical Feedback", "categories": ["cs.CL", "cs.AI"], "comment": "38 pages", "summary": "Recent advances in reinforcement learning (RL) with numerical feedback, such\nas scalar rewards, have significantly enhanced the complex reasoning\ncapabilities of large language models (LLMs). Despite this success, we identify\nthree key challenges encountered by RL with solely numerical feedback:\nperformance plateaus, limited effectiveness of self-reflection, and persistent\nfailures. We then demonstrate that RL-finetuned models, even after exhibiting\nperformance plateaus, can generate correct refinements on persistently failed\nproblems by leveraging natural language feedback in the form of critiques.\nBuilding on this insight, we propose Critique-GRPO, an online RL framework that\nintegrates both natural language and numerical feedback for effective policy\noptimization. Critique-GRPO enables LLMs to learn from initial responses and\ncritique-guided refinements simultaneously while maintaining exploration.\nExtensive experiments using Qwen2.5-7B-Base and Qwen3-8B-Base show that\nCritique-GRPO consistently outperforms supervised learning-based and RL-based\nfine-tuning approaches across eight challenging mathematical, STEM, and general\nreasoning tasks, improving average pass@1 scores by approximately 4.5% and 5%,\nrespectively. Notably, Critique-GRPO surpasses a strong baseline that\nincorporates expert demonstrations within online RL. Further analysis reveals\ntwo critical insights about policy exploration: (1) higher entropy does not\nalways guarantee efficient learning from exploration, and (2) longer responses\ndo not necessarily lead to more effective exploration.", "AI": {"tldr": "Critique-GRPO, an RL framework combining natural language and numerical feedback, outperforms traditional methods by leveraging critiques for refinement, improving reasoning tasks by 4.5-5%.", "motivation": "Addressing performance plateaus, limited self-reflection, and persistent failures in RL with numerical feedback alone.", "method": "Proposes Critique-GRPO, integrating natural language critiques and numerical feedback for policy optimization, tested on Qwen models.", "result": "Outperforms supervised and RL-based fine-tuning, improving pass@1 scores by ~4.5-5%, surpassing expert-demonstration baselines.", "conclusion": "Critique-GRPO effectively combines feedback types for better RL performance, with insights on exploration efficiency."}}
{"id": "2505.16933", "pdf": "https://arxiv.org/pdf/2505.16933", "abs": "https://arxiv.org/abs/2505.16933", "authors": ["Zebin You", "Shen Nie", "Xiaolu Zhang", "Jun Hu", "Jun Zhou", "Zhiwu Lu", "Ji-Rong Wen", "Chongxuan Li"], "title": "LLaDA-V: Large Language Diffusion Models with Visual Instruction Tuning", "categories": ["cs.LG", "cs.CL", "cs.CV"], "comment": "Project page and codes: \\url{https://ml-gsai.github.io/LLaDA-V-demo/}", "summary": "In this work, we introduce LLaDA-V, a purely diffusion-based Multimodal Large\nLanguage Model (MLLM) that integrates visual instruction tuning with masked\ndiffusion models, representing a departure from the autoregressive paradigms\ndominant in current multimodal approaches. Built upon LLaDA, a representative\nlarge language diffusion model, LLaDA-V incorporates a vision encoder and MLP\nconnector that projects visual features into the language embedding space,\nenabling effective multimodal alignment. Our empirical investigation reveals\nseveral intriguing results: First, LLaDA-V demonstrates promising multimodal\nperformance despite its language model being weaker on purely textual tasks\nthan counterparts like LLaMA3-8B and Qwen2-7B. When trained on the same\ninstruction data, LLaDA-V is highly competitive to LLaMA3-V across multimodal\ntasks with better data scalability. It also narrows the performance gap to\nQwen2-VL, suggesting the effectiveness of its architecture for multimodal\ntasks. Second, LLaDA-V achieves state-of-the-art performance in multimodal\nunderstanding compared to existing hybrid autoregressive-diffusion and purely\ndiffusion-based MLLMs. Our findings suggest that large language diffusion\nmodels show promise in multimodal contexts and warrant further investigation in\nfuture research. Project page and codes:\nhttps://ml-gsai.github.io/LLaDA-V-demo/.", "AI": {"tldr": "LLaDA-V is a diffusion-based Multimodal Large Language Model (MLLM) that integrates visual instruction tuning, showing competitive performance in multimodal tasks despite weaker textual performance.", "motivation": "To explore the potential of diffusion-based models in multimodal contexts, diverging from dominant autoregressive approaches.", "method": "LLaDA-V combines a vision encoder and MLP connector to align visual features with language embeddings, built upon the LLaDA diffusion model.", "result": "LLaDA-V achieves competitive multimodal performance, narrowing gaps with stronger models and outperforming hybrid and purely diffusion-based MLLMs.", "conclusion": "Diffusion-based models like LLaDA-V show promise for multimodal tasks, warranting further research."}}
{"id": "2506.00100", "pdf": "https://arxiv.org/pdf/2506.00100", "abs": "https://arxiv.org/abs/2506.00100", "authors": ["Ajinkya Kulkarni", "Francisco Teixeira", "Enno Hermann", "Thomas Rolland", "Isabel Trancoso", "Mathew Magimai Doss"], "title": "Children's Voice Privacy: First Steps And Emerging Challenges", "categories": ["cs.CY", "cs.AI", "cs.CL", "cs.CR"], "comment": "Accepted at Interspeech 2025, Netherlands", "summary": "Children are one of the most under-represented groups in speech technologies,\nas well as one of the most vulnerable in terms of privacy. Despite this,\nanonymization techniques targeting this population have received little\nattention. In this study, we seek to bridge this gap, and establish a baseline\nfor the use of voice anonymization techniques designed for adult speech when\napplied to children's voices. Such an evaluation is essential, as children's\nspeech presents a distinct set of challenges when compared to that of adults.\nThis study comprises three children's datasets, six anonymization methods, and\nobjective and subjective utility metrics for evaluation. Our results show that\nexisting systems for adults are still able to protect children's voice privacy,\nbut suffer from much higher utility degradation. In addition, our subjective\nstudy displays the challenges of automatic evaluation methods for speech\nquality in children's speech, highlighting the need for further research.", "AI": {"tldr": "The study evaluates adult voice anonymization techniques on children's speech, finding they protect privacy but reduce utility more than in adults, and highlights challenges in automatic evaluation.", "motivation": "Children are underrepresented in speech tech and vulnerable in privacy, yet anonymization for them is understudied.", "method": "Uses three children's datasets, six anonymization methods, and objective/subjective utility metrics.", "result": "Adult anonymization protects children's privacy but causes higher utility loss; automatic evaluation struggles with children's speech quality.", "conclusion": "More research is needed to improve anonymization for children's speech, especially in evaluation methods."}}
{"id": "2505.17226", "pdf": "https://arxiv.org/pdf/2505.17226", "abs": "https://arxiv.org/abs/2505.17226", "authors": ["Kun Yang", "Neena Imam"], "title": "Secure and Private Federated Learning: Achieving Adversarial Resilience through Robust Aggregation", "categories": ["cs.LG", "cs.CR"], "comment": null, "summary": "Federated Learning (FL) enables collaborative machine learning across\ndecentralized data sources without sharing raw data. It offers a promising\napproach to privacy-preserving AI. However, FL remains vulnerable to\nadversarial threats from malicious participants, referred to as Byzantine\nclients, who can send misleading updates to corrupt the global model.\nTraditional aggregation methods, such as simple averaging, are not robust to\nsuch attacks. More resilient approaches, like the Krum algorithm, require prior\nknowledge of the number of malicious clients, which is often unavailable in\nreal-world scenarios. To address these limitations, we propose Average-rKrum\n(ArKrum), a novel aggregation strategy designed to enhance both the resilience\nand privacy guarantees of FL systems. Building on our previous work (rKrum),\nArKrum introduces two key innovations. First, it includes a median-based\nfiltering mechanism that removes extreme outliers before estimating the number\nof adversarial clients. Second, it applies a multi-update averaging scheme to\nimprove stability and performance, particularly when client data distributions\nare not identical. We evaluate ArKrum on benchmark image and text datasets\nunder three widely studied Byzantine attack types. Results show that ArKrum\nconsistently achieves high accuracy and stability. It performs as well as or\nbetter than other robust aggregation methods. These findings demonstrate that\nArKrum is an effective and practical solution for secure FL systems in\nadversarial environments.", "AI": {"tldr": "Proposes ArKrum, a robust aggregation strategy for Federated Learning (FL) to counter Byzantine attacks, enhancing resilience and privacy without needing prior knowledge of malicious clients.", "motivation": "FL is vulnerable to adversarial threats from Byzantine clients, and traditional methods lack robustness or require impractical prior knowledge.", "method": "ArKrum combines median-based filtering to remove outliers and multi-update averaging for stability, improving on the rKrum algorithm.", "result": "ArKrum outperforms other methods in accuracy and stability under various Byzantine attacks.", "conclusion": "ArKrum is a practical and effective solution for secure FL in adversarial settings."}}
{"id": "2505.22769", "pdf": "https://arxiv.org/pdf/2505.22769", "abs": "https://arxiv.org/abs/2505.22769", "authors": ["Yaxiong Lei", "Mingyue Zhao", "Yuheng Wang", "Shijing He", "Yusuke Sugano", "Mohamed Khamis", "Juan Ye"], "title": "MAC-Gaze: Motion-Aware Continual Calibration for Mobile Gaze Tracking", "categories": ["cs.HC", "cs.CV", "68T10, 68U35", "H.5.2; H.1.2; C.2.4; I.5.4"], "comment": "24 pages, 7 figures", "summary": "Mobile gaze tracking faces a fundamental challenge: maintaining accuracy as\nusers naturally change their postures and device orientations. Traditional\ncalibration approaches, like one-off, fail to adapt to these dynamic\nconditions, leading to degraded performance over time. We present MAC-Gaze, a\nMotion-Aware continual Calibration approach that leverages smartphone Inertial\nmeasurement unit (IMU) sensors and continual learning techniques to\nautomatically detect changes in user motion states and update the gaze tracking\nmodel accordingly. Our system integrates a pre-trained visual gaze estimator\nand an IMU-based activity recognition model with a clustering-based hybrid\ndecision-making mechanism that triggers recalibration when motion patterns\ndeviate significantly from previously encountered states. To enable\naccumulative learning of new motion conditions while mitigating catastrophic\nforgetting, we employ replay-based continual learning, allowing the model to\nmaintain performance across previously encountered motion conditions. We\nevaluate our system through extensive experiments on the publicly available\nRGBDGaze dataset and our own 10-hour multimodal MotionGaze dataset (481K+\nimages, 800K+ IMU readings), encompassing a wide range of postures under\nvarious motion conditions including sitting, standing, lying, and walking.\nResults demonstrate that our method reduces gaze estimation error by 19.9% on\nRGBDGaze (from 1.73 cm to 1.41 cm) and by 31.7% on MotionGaze (from 2.81 cm to\n1.92 cm) compared to traditional calibration approaches. Our framework provides\na robust solution for maintaining gaze estimation accuracy in mobile scenarios.", "AI": {"tldr": "MAC-Gaze introduces a motion-aware continual calibration method for mobile gaze tracking, reducing errors by 19.9%-31.7% compared to traditional approaches.", "motivation": "Traditional calibration fails in dynamic conditions; MAC-Gaze adapts to posture and device changes for sustained accuracy.", "method": "Combines IMU sensors, continual learning, and a hybrid decision mechanism to trigger recalibration based on motion state changes.", "result": "Reduces gaze error by 19.9% (RGBDGaze) and 31.7% (MotionGaze) compared to traditional methods.", "conclusion": "MAC-Gaze offers a robust solution for accurate mobile gaze tracking in dynamic scenarios."}}
{"id": "2506.00335", "pdf": "https://arxiv.org/pdf/2506.00335", "abs": "https://arxiv.org/abs/2506.00335", "authors": ["Jingyang He", "Shuai Wang", "Ang Li"], "title": "Recover Experimental Data with Selection Bias using Counterfactual Logic", "categories": ["stat.ME", "cs.AI"], "comment": null, "summary": "Selection bias, arising from the systematic inclusion or exclusion of certain\nsamples, poses a significant challenge to the validity of causal inference.\nWhile Bareinboim et al. introduced methods for recovering unbiased\nobservational and interventional distributions from biased data using partial\nexternal information, the complexity of the backdoor adjustment and the\nmethod's strong reliance on observational data limit its applicability in many\npractical settings. In this paper, we formally discover the recoverability of\n$P(Y^*_{x^*})$ under selection bias with experimental data. By explicitly\nconstructing counterfactual worlds via Structural Causal Models (SCMs), we\nanalyze how selection mechanisms in the observational world propagate to the\ncounterfactual domain. We derive a complete set of graphical and theoretical\ncriteria to determine that the experimental distribution remain unaffected by\nselection bias. Furthermore, we propose principled methods for leveraging\npartially unbiased observational data to recover $P(Y^*_{x^*})$ from biased\nexperimental datasets. Simulation studies replicating realistic research\nscenarios demonstrate the practical utility of our approach, offering concrete\nguidance for mitigating selection bias in applied causal inference.", "AI": {"tldr": "The paper addresses selection bias in causal inference, proposing methods to recover unbiased distributions from biased experimental data using Structural Causal Models (SCMs) and leveraging partial observational data.", "motivation": "Selection bias undermines causal inference validity. Existing methods rely heavily on observational data and complex adjustments, limiting practicality.", "method": "The authors use SCMs to analyze selection bias propagation and derive graphical/theoretical criteria for unbiased experimental distributions. They propose methods to recover unbiased data from biased experiments.", "result": "Simulation studies confirm the approach's practical utility in mitigating selection bias.", "conclusion": "The paper provides a principled framework for recovering unbiased causal effects from biased experimental data, enhancing applied causal inference."}}
{"id": "2505.18570", "pdf": "https://arxiv.org/pdf/2505.18570", "abs": "https://arxiv.org/abs/2505.18570", "authors": ["Tina Khezresmaeilzadeh", "Parsa Razmara", "Seyedarmin Azizi", "Mohammad Erfan Sadeghi", "Erfan Baghaei Potraghloo"], "title": "VISTA: Vision-Language Inference for Training-Free Stock Time-Series Analysis", "categories": ["cs.LG"], "comment": null, "summary": "Stock price prediction remains a complex and high-stakes task in financial\nanalysis, traditionally addressed using statistical models or, more recently,\nlanguage models. In this work, we introduce VISTA (Vision-Language Inference\nfor Stock Time-series Analysis), a novel, training-free framework that\nleverages Vision-Language Models (VLMs) for multi-modal stock forecasting.\nVISTA prompts a VLM with both textual representations of historical stock\nprices and their corresponding line charts to predict future price values. By\ncombining numerical and visual modalities in a zero-shot setting and using\ncarefully designed chain-of-thought prompts, VISTA captures complementary\npatterns that unimodal approaches often miss. We benchmark VISTA against\nstandard baselines, including ARIMA and text-only LLM-based prompting methods.\nExperimental results show that VISTA outperforms these baselines by up to\n89.83%, demonstrating the effectiveness of multi-modal inference for stock\ntime-series analysis and highlighting the potential of VLMs in financial\nforecasting tasks without requiring task-specific training.", "AI": {"tldr": "VISTA is a training-free, multi-modal framework using Vision-Language Models (VLMs) for stock price prediction, outperforming traditional methods by up to 89.83%.", "motivation": "Stock price prediction is complex and high-stakes, with existing methods often missing complementary patterns due to unimodal approaches.", "method": "VISTA combines textual and visual data (line charts) in a zero-shot setting with chain-of-thought prompts for multi-modal forecasting.", "result": "VISTA outperforms ARIMA and text-only LLM methods by up to 89.83%.", "conclusion": "Multi-modal inference with VLMs is effective for stock forecasting, offering potential without task-specific training."}}
{"id": "2505.24434", "pdf": "https://arxiv.org/pdf/2505.24434", "abs": "https://arxiv.org/abs/2505.24434", "authors": ["Md Shahriar Rahim Siddiqui", "Moshe Eliasof", "Eldad Haber"], "title": "Graph Flow Matching: Enhancing Image Generation with Neighbor-Aware Flow Fields", "categories": ["cs.LG", "cs.CV"], "comment": null, "summary": "Flow matching casts sample generation as learning a continuous-time velocity\nfield that transports noise to data. Existing flow matching networks typically\npredict each point's velocity independently, considering only its location and\ntime along its flow trajectory, and ignoring neighboring points. However, this\npointwise approach may overlook correlations between points along the\ngeneration trajectory that could enhance velocity predictions, thereby\nimproving downstream generation quality. To address this, we propose Graph Flow\nMatching (GFM), a lightweight enhancement that decomposes the learned velocity\ninto a reaction term -- any standard flow matching network -- and a diffusion\nterm that aggregates neighbor information via a graph neural module. This\nreaction-diffusion formulation retains the scalability of deep flow models\nwhile enriching velocity predictions with local context, all at minimal\nadditional computational cost. Operating in the latent space of a pretrained\nvariational autoencoder, GFM consistently improves Fr\\'echet Inception Distance\n(FID) and recall across five image generation benchmarks (LSUN Church, LSUN\nBedroom, FFHQ, AFHQ-Cat, and CelebA-HQ at $256\\times256$), demonstrating its\neffectiveness as a modular enhancement to existing flow matching architectures.", "AI": {"tldr": "Graph Flow Matching (GFM) enhances flow matching by incorporating neighbor information via a graph neural module, improving generation quality without significant computational overhead.", "motivation": "Existing flow matching methods predict velocities independently, ignoring correlations between points, which could improve generation quality.", "method": "GFM decomposes velocity into a reaction term (standard flow matching) and a diffusion term (graph neural module for neighbor aggregation).", "result": "GFM improves Fr\u00e9chet Inception Distance (FID) and recall across five image generation benchmarks.", "conclusion": "GFM is a lightweight, effective modular enhancement for flow matching architectures."}}
{"id": "2506.00486", "pdf": "https://arxiv.org/pdf/2506.00486", "abs": "https://arxiv.org/abs/2506.00486", "authors": ["Jun Wu", "Yirong Xiong", "Jiangtao Wen", "Yuxing Han"], "title": "It Takes a Good Model to Train a Good Model: Generalized Gaussian Priors for Optimized LLMs", "categories": ["cs.LG", "cs.AI", "stat.ML"], "comment": null, "summary": "Despite rapid advancements in the research and deployment of large language\nmodels (LLMs), the statistical distribution of model parameters, as well as\ntheir influence on initialization, training dynamics, and downstream\nefficiency, has received surprisingly little attention. A recent work\nintroduced BackSlash, a training-time compression algorithm. It first\ndemonstrated that pre-trained LLM parameters follow generalized Gaussian\ndistributions (GGDs) better. By optimizing GG priors during training, BackSlash\ncan reduce parameters by up to 90\\% with minimal performance loss. Building on\nthis foundational insight, we propose a unified, end-to-end framework for LLM\noptimization based on the GG model. Our contributions are threefold: (1)\nGG-based initialization scheme that aligns with the statistical structure of\ntrained models, resulting in faster convergence and improved accuracy; (2)\nDeepShape, a post-training regularization method that reshapes weight\ndistributions to match a GG profile, improving compressibility with minimized\ndegradation in performance; and (3) RF8, a compact and hardware-efficient 8-bit\nfloating-point format designed for GG-distributed-initialized BackSlash\ntraining, enabling low-cost inference without compromising accuracy.\nExperiments across diverse model architectures show that our framework\nconsistently yields smaller and faster models that match or outperform standard\ntraining baselines. By grounding LLM development in principled statistical\nmodeling, this work forges a new path toward efficient, scalable, and\nhardware-aware AI systems. The code is available on our project page:\nhttps://huggingface.co/spaces/shifeng3711/gg_prior.", "AI": {"tldr": "The paper introduces a unified framework for LLM optimization using generalized Gaussian distributions (GGDs), improving initialization, training, and compression with minimal performance loss.", "motivation": "Despite advancements in LLMs, the statistical distribution of parameters and their impact on training and efficiency is understudied. The work aims to address this gap.", "method": "Proposes GG-based initialization, DeepShape for post-training regularization, and RF8 for hardware-efficient 8-bit floating-point format.", "result": "Experiments show smaller, faster models matching or outperforming baselines.", "conclusion": "The framework advances efficient, scalable, and hardware-aware AI systems through principled statistical modeling."}}
{"id": "2505.22813", "pdf": "https://arxiv.org/pdf/2505.22813", "abs": "https://arxiv.org/abs/2505.22813", "authors": ["Josiah Couch", "Miao Li", "Rima Arnaout", "Ramy Arnaout"], "title": "X-Factor: Quality Is a Dataset-Intrinsic Property", "categories": ["cs.LG", "68T07", "I.2.6"], "comment": "13 pages, 7 figures", "summary": "In the universal quest to optimize machine-learning classifiers, three\nfactors -- model architecture, dataset size, and class balance -- have been\nshown to influence test-time performance but do not fully account for it.\nPreviously, evidence was presented for an additional factor that can be\nreferred to as dataset quality, but it was unclear whether this was actually a\njoint property of the dataset and the model architecture, or an intrinsic\nproperty of the dataset itself. If quality is truly dataset-intrinsic and\nindependent of model architecture, dataset size, and class balance, then the\nsame datasets should perform better (or worse) regardless of these other\nfactors. To test this hypothesis, here we create thousands of datasets, each\ncontrolled for size and class balance, and use them to train classifiers with a\nwide range of architectures, from random forests and support-vector machines to\ndeep networks. We find that classifier performance correlates strongly by\nsubset across architectures ($R^2=0.79$), supporting quality as an intrinsic\nproperty of datasets independent of dataset size and class balance and of model\narchitecture. Digging deeper, we find that dataset quality appears to be an\nemergent property of something more fundamental: the quality of datasets'\nconstituent classes. Thus, quality joins size, class balance, and model\narchitecture as an independent correlate of performance and a separate target\nfor optimizing machine-learning-based classification.", "AI": {"tldr": "Dataset quality is an intrinsic property, independent of model architecture, size, and class balance, and correlates strongly with classifier performance.", "motivation": "To determine if dataset quality is intrinsic or dependent on other factors like model architecture, size, and class balance.", "method": "Created controlled datasets, trained classifiers with varied architectures (random forests, SVMs, deep networks), and analyzed performance correlations.", "result": "Classifier performance strongly correlated by dataset subset across architectures (R\u00b2=0.79), indicating intrinsic dataset quality.", "conclusion": "Dataset quality is an independent factor for classifier performance, alongside size, class balance, and architecture."}}
{"id": "2505.23585", "pdf": "https://arxiv.org/pdf/2505.23585", "abs": "https://arxiv.org/abs/2505.23585", "authors": ["Yaru Hao", "Li Dong", "Xun Wu", "Shaohan Huang", "Zewen Chi", "Furu Wei"], "title": "On-Policy RL with Optimal Reward Baseline", "categories": ["cs.LG", "cs.CL"], "comment": null, "summary": "Reinforcement learning algorithms are fundamental to align large language\nmodels with human preferences and to enhance their reasoning capabilities.\nHowever, current reinforcement learning algorithms often suffer from training\ninstability due to loose on-policy constraints and computational inefficiency\ndue to auxiliary models. In this work, we propose On-Policy RL with Optimal\nreward baseline (OPO), a novel and simplified reinforcement learning algorithm\ndesigned to address these challenges. OPO emphasizes the importance of exact\non-policy training, which empirically stabilizes the training process and\nenhances exploration. Moreover, OPO integrates a practically feasible\nformulation of the optimal reward baseline that minimizes gradient variance. We\nevaluate OPO on mathematical reasoning benchmarks. The results demonstrate its\nsuperior performance and training stability without additional models or\nregularization terms. Furthermore, OPO achieves lower policy shifts and higher\noutput entropy, encouraging more diverse and less repetitive responses. These\nresults highlight OPO as a promising direction for stable and effective\nreinforcement learning in large language model alignment and reasoning tasks.\nThe implementation is merged into the verl library at\nhttps://verl.readthedocs.io/en/latest/algo/opo.html.", "AI": {"tldr": "OPO is a simplified reinforcement learning algorithm for stable and efficient training of large language models, improving performance and diversity in reasoning tasks.", "motivation": "Current reinforcement learning algorithms face instability and inefficiency due to loose on-policy constraints and auxiliary models.", "method": "OPO introduces exact on-policy training and an optimal reward baseline to minimize gradient variance.", "result": "OPO shows superior performance, stability, and diversity in responses on mathematical reasoning benchmarks.", "conclusion": "OPO is a promising approach for stable and effective reinforcement learning in language model alignment and reasoning."}}
{"id": "2506.01950", "pdf": "https://arxiv.org/pdf/2506.01950", "abs": "https://arxiv.org/abs/2506.01950", "authors": ["Jiajun Jiang", "Yiming Zhu", "Zirui Wu", "Jie Song"], "title": "DualMap: Online Open-Vocabulary Semantic Mapping for Natural Language Navigation in Dynamic Changing Scenes", "categories": ["cs.RO", "cs.CV"], "comment": "8 pages, 5 figures. Code: https://github.com/Eku127/DualMap Project\n  page: https://eku127.github.io/DualMap/", "summary": "We introduce DualMap, an online open-vocabulary mapping system that enables\nrobots to understand and navigate dynamically changing environments through\nnatural language queries. Designed for efficient semantic mapping and\nadaptability to changing environments, DualMap meets the essential requirements\nfor real-world robot navigation applications. Our proposed hybrid segmentation\nfrontend and object-level status check eliminate the costly 3D object merging\nrequired by prior methods, enabling efficient online scene mapping. The\ndual-map representation combines a global abstract map for high-level candidate\nselection with a local concrete map for precise goal-reaching, effectively\nmanaging and updating dynamic changes in the environment. Through extensive\nexperiments in both simulation and real-world scenarios, we demonstrate\nstate-of-the-art performance in 3D open-vocabulary segmentation, efficient\nscene mapping, and online language-guided navigation.", "AI": {"tldr": "DualMap is an online open-vocabulary mapping system for robots, enabling efficient semantic mapping and navigation via natural language queries. It uses a hybrid segmentation frontend and dual-map representation to handle dynamic environments, outperforming prior methods.", "motivation": "To address the challenges of real-world robot navigation in dynamically changing environments, requiring efficient semantic mapping and adaptability.", "method": "Proposes a hybrid segmentation frontend and object-level status check to avoid costly 3D merging. Uses a dual-map representation (global abstract and local concrete maps) for dynamic updates.", "result": "Achieves state-of-the-art performance in 3D open-vocabulary segmentation, efficient scene mapping, and online language-guided navigation in simulations and real-world tests.", "conclusion": "DualMap effectively meets real-world navigation needs by combining efficiency, adaptability, and natural language understanding."}}
{"id": "2506.00691", "pdf": "https://arxiv.org/pdf/2506.00691", "abs": "https://arxiv.org/abs/2506.00691", "authors": ["Junaid Muzaffar", "Khubaib Ahmed", "Ingo Frommholz", "Zeeshan Pervez", "Ahsan ul Haq"], "title": "Optimizing Sensory Neurons: Nonlinear Attention Mechanisms for Accelerated Convergence in Permutation-Invariant Neural Networks for Reinforcement Learning", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Training reinforcement learning (RL) agents often requires significant\ncomputational resources and extended training times. To address this, we build\nupon the foundation laid by Google Brain's Sensory Neuron, which introduced a\nnovel neural architecture for reinforcement learning tasks that maintained\npermutation in-variance in the sensory neuron system. While the baseline model\ndemonstrated significant performance improvements over traditional approaches,\nwe identified opportunities to enhance the efficiency of the learning process\nfurther. We propose a modified attention mechanism incorporating a non-linear\ntransformation of the key vectors (K) using a mapping function, resulting in a\nnew set of key vectors (K'). This non-linear mapping enhances the\nrepresentational capacity of the attention mechanism, allowing the model to\nencode more complex feature interactions and accelerating convergence without\ncompromising performance. Our enhanced model demonstrates significant\nimprovements in learning efficiency, showcasing the potential for non-linear\nattention mechanisms in advancing reinforcement learning algorithms.", "AI": {"tldr": "The paper proposes a modified attention mechanism with non-linear key vector transformation to improve RL training efficiency without performance loss.", "motivation": "Addressing the high computational cost and long training times in RL by enhancing the representational capacity of attention mechanisms.", "method": "Introduces a non-linear transformation of key vectors (K) in the attention mechanism, creating new vectors (K') to capture complex feature interactions.", "result": "The enhanced model shows significant improvements in learning efficiency and convergence speed.", "conclusion": "Non-linear attention mechanisms hold promise for advancing RL algorithms by boosting efficiency and maintaining performance."}}
{"id": "2505.23470", "pdf": "https://arxiv.org/pdf/2505.23470", "abs": "https://arxiv.org/abs/2505.23470", "authors": ["Chenjie Li", "Amir Gilad", "Boris Glavic", "Zhengjie Miao", "Sudeepa Roy"], "title": "Refining Labeling Functions with Limited Labeled Data", "categories": ["cs.LG", "cs.IT", "math.IT"], "comment": "techreport", "summary": "Programmatic weak supervision (PWS) significantly reduces human effort for\nlabeling data by combining the outputs of user-provided labeling functions\n(LFs) on unlabeled datapoints. However, the quality of the generated labels\ndepends directly on the accuracy of the LFs. In this work, we study the problem\nof fixing LFs based on a small set of labeled examples. Towards this goal, we\ndevelop novel techniques for repairing a set of LFs by minimally changing their\nresults on the labeled examples such that the fixed LFs ensure that (i) there\nis sufficient evidence for the correct label of each labeled datapoint and (ii)\nthe accuracy of each repaired LF is sufficiently high. We model LFs as\nconditional rules which enables us to refine them, i.e., to selectively change\ntheir output for some inputs. We demonstrate experimentally that our system\nimproves the quality of LFs based on surprisingly small sets of labeled\ndatapoints.", "AI": {"tldr": "The paper introduces techniques to repair labeling functions (LFs) in programmatic weak supervision (PWS) using minimal changes based on a small labeled dataset, improving LF accuracy and label quality.", "motivation": "The quality of labels in PWS depends on LF accuracy, but LFs may be imperfect. The goal is to fix LFs efficiently using limited labeled data.", "method": "LFs are modeled as conditional rules and refined by minimally altering their outputs on labeled examples, ensuring correctness and high accuracy.", "result": "Experimental results show the system enhances LF quality even with small labeled datasets.", "conclusion": "The proposed method effectively repairs LFs, improving label quality in PWS with minimal labeled data."}}
{"id": "2506.01969", "pdf": "https://arxiv.org/pdf/2506.01969", "abs": "https://arxiv.org/abs/2506.01969", "authors": ["Pengcuo Dege", "Qiuming Luo", "Rui Mao", "Chang Kong"], "title": "FlashMLA-ETAP: Efficient Transpose Attention Pipeline for Accelerating MLA Inference on NVIDIA H20 GPUs", "categories": ["cs.DC", "cs.AI", "cs.LG"], "comment": "15 pages, conference", "summary": "Efficient inference of Multi-Head Latent Attention (MLA) is challenged by\ndeploying the DeepSeek-R1 671B model on a single Multi-GPU server. This paper\nintroduces FlashMLA-ETAP, a novel framework that enhances MLA inference for the\nsingle-instance deployment scenario on NVIDIA H20 GPUs. We propose the\nEfficient Transpose Attention Pipeline (ETAP), which reconfigures attention\ncomputation through transposition to align the KV context length with the\n\\(M\\)-dimension in WGMMA operations, significantly reducing redundant\ncomputations. FlashMLA-ETAP achieves a 2.78x speedup over FlashMLA at 64K\nsequence length (batch size 16), with 5.24x and 4.94x improvements over\nFlashAttention-3 and FlashInfer, respectively, while maintaining numerical\nstability with a 15.2x lower RMSE (\\(1.25 \\times 10^{-5}\\)) than\nFlashAttention-3. Furthermore, ETAP's design enables seamless integration into\nframeworks like FlashAttention-3 and FlashInfer, supported by a detailed\ntheoretical analysis. Our work addresses a critical gap in resource-constrained\ninference, offering a scalable solution for mid-tier GPUs and paving the way\nfor broader adoption in hardware-aware optimization. Code is available at\nhttps://github.com/pengcuo/FlashMLA-ETAP.", "AI": {"tldr": "FlashMLA-ETAP is a framework improving Multi-Head Latent Attention inference on single-GPU servers, achieving significant speedups and numerical stability.", "motivation": "Addressing challenges in efficient MLA inference for single-instance deployment on mid-tier GPUs like NVIDIA H20.", "method": "Introduces Efficient Transpose Attention Pipeline (ETAP), reconfiguring attention computation to reduce redundant operations.", "result": "Achieves 2.78x speedup over FlashMLA, 5.24x over FlashAttention-3, and 4.94x over FlashInfer, with lower RMSE.", "conclusion": "Provides a scalable solution for resource-constrained inference, enabling broader adoption in hardware-aware optimization."}}
{"id": "2505.23527", "pdf": "https://arxiv.org/pdf/2505.23527", "abs": "https://arxiv.org/abs/2505.23527", "authors": ["Raj Ghugare", "Benjamin Eysenbach"], "title": "Normalizing Flows are Capable Models for RL", "categories": ["cs.LG"], "comment": "Project page with code - https://rajghugare19.github.io/nf4rl/", "summary": "Modern reinforcement learning (RL) algorithms have found success by using\npowerful probabilistic models, such as transformers, energy-based models, and\ndiffusion/flow-based models. To this end, RL researchers often choose to pay\nthe price of accommodating these models into their algorithms -- diffusion\nmodels are expressive, but are computationally intensive due to their reliance\non solving differential equations, while autoregressive transformer models are\nscalable but typically require learning discrete representations. Normalizing\nflows (NFs), by contrast, seem to provide an appealing alternative, as they\nenable likelihoods and sampling without solving differential equations or\nautoregressive architectures. However, their potential in RL has received\nlimited attention, partly due to the prevailing belief that normalizing flows\nlack sufficient expressivity. We show that this is not the case. Building on\nrecent work in NFs, we propose a single NF architecture which integrates\nseamlessly into RL algorithms, serving as a policy, Q-function, and occupancy\nmeasure. Our approach leads to much simpler algorithms, and achieves higher\nperformance in imitation learning, offline, goal conditioned RL and\nunsupervised RL.", "AI": {"tldr": "The paper challenges the belief that normalizing flows (NFs) lack expressivity in RL, proposing a unified NF architecture that simplifies algorithms and improves performance across various RL tasks.", "motivation": "To address the computational and representational limitations of existing probabilistic models (e.g., diffusion models, transformers) in RL by leveraging the untapped potential of NFs.", "method": "Introduces a single NF architecture that serves as a policy, Q-function, and occupancy measure, integrating it into RL algorithms.", "result": "The proposed NF-based approach simplifies algorithms and achieves higher performance in imitation learning, offline, goal-conditioned, and unsupervised RL.", "conclusion": "NFs are a viable and effective alternative to other probabilistic models in RL, offering simplicity and superior performance."}}
{"id": "2506.01982", "pdf": "https://arxiv.org/pdf/2506.01982", "abs": "https://arxiv.org/abs/2506.01982", "authors": ["Vassilis Lyberatos", "Spyridon Kantarelis", "Ioanna Zioga", "Christina Anagnostopoulou", "Giorgos Stamou", "Anastasia Georgaki"], "title": "Music Interpretation and Emotion Perception: A Computational and Neurophysiological Investigation", "categories": ["cs.HC", "cs.AI"], "comment": "Accepted at SMC 2025", "summary": "This study investigates emotional expression and perception in music\nperformance using computational and neurophysiological methods. The influence\nof different performance settings, such as repertoire, diatonic modal etudes,\nand improvisation, as well as levels of expressiveness, on performers'\nemotional communication and listeners' reactions is explored. Professional\nmusicians performed various tasks, and emotional annotations were provided by\nboth performers and the audience. Audio analysis revealed that expressive and\nimprovisational performances exhibited unique acoustic features, while emotion\nanalysis showed stronger emotional responses. Neurophysiological measurements\nindicated greater relaxation in improvisational performances. This multimodal\nstudy highlights the significance of expressivity in enhancing emotional\ncommunication and audience engagement.", "AI": {"tldr": "The study explores emotional expression in music performance using computational and neurophysiological methods, finding that expressive and improvisational performances enhance emotional communication and audience engagement.", "motivation": "To understand how different performance settings and expressiveness levels influence emotional communication and listener reactions in music.", "method": "Professional musicians performed tasks (repertoire, diatonic modal etudes, improvisation) with emotional annotations from performers and audience. Audio and neurophysiological data were analyzed.", "result": "Expressive and improvisational performances had unique acoustic features and stronger emotional responses. Improvisation led to greater relaxation in neurophysiological measurements.", "conclusion": "Expressivity in music performance significantly enhances emotional communication and audience engagement, as shown by multimodal analysis."}}
{"id": "2505.24603", "pdf": "https://arxiv.org/pdf/2505.24603", "abs": "https://arxiv.org/abs/2505.24603", "authors": ["Omri Lev", "Vishwak Srinivasan", "Moshe Shenfeld", "Katrina Ligett", "Ayush Sekhari", "Ashia C. Wilson"], "title": "The Gaussian Mixing Mechanism: Renyi Differential Privacy via Gaussian Sketches", "categories": ["cs.LG"], "comment": null, "summary": "Gaussian sketching, which consists of pre-multiplying the data with a random\nGaussian matrix, is a widely used technique for multiple problems in data\nscience and machine learning, with applications spanning computationally\nefficient optimization, coded computing, and federated learning. This operation\nalso provides differential privacy guarantees due to its inherent randomness.\nIn this work, we revisit this operation through the lens of Renyi Differential\nPrivacy (RDP), providing a refined privacy analysis that yields significantly\ntighter bounds than prior results. We then demonstrate how this improved\nanalysis leads to performance improvement in different linear regression\nsettings, establishing theoretical utility guarantees. Empirically, our methods\nimprove performance across multiple datasets and, in several cases, reduce\nruntime.", "AI": {"tldr": "The paper refines the privacy analysis of Gaussian sketching using Renyi Differential Privacy (RDP), providing tighter bounds and demonstrating improved performance in linear regression.", "motivation": "To enhance the understanding and utility of Gaussian sketching in data science by leveraging RDP for tighter privacy bounds.", "method": "Revisits Gaussian sketching with RDP, providing a refined privacy analysis and applying it to linear regression.", "result": "Tighter privacy bounds and improved performance in linear regression, with empirical validation across datasets.", "conclusion": "The refined RDP analysis of Gaussian sketching offers stronger privacy guarantees and practical performance gains."}}
{"id": "2506.02120", "pdf": "https://arxiv.org/pdf/2506.02120", "abs": "https://arxiv.org/abs/2506.02120", "authors": ["Mariana A. Londe", "Luciana S. Pessoa", "Carlos E. Andrade", "Jos\u00e9 F. Gon\u00e7alves", "Mauricio G. C. Resende"], "title": "Random-key genetic algorithms: Principles and applications", "categories": ["cs.NE", "cs.AI", "math.OC", "90-02, 90B40, 90C27", "G.1.6; G.2.1; I.2.8"], "comment": "21 pages, 1 figure, 1 table, 1 algorithm, forthcoming in Handbook of\n  Heuristics, 2nd edition, SpringerNature, New York", "summary": "A random-key genetic algorithm is an evolutionary metaheuristic for discrete\nand global optimization. Each solution is encoded as a vector of N random keys,\nwhere a random key is a real number randomly generated in the continuous\ninterval [0, 1). A decoder maps each vector of random keys to a solution of the\noptimization problem being solved and computes its cost. The benefit of this\napproach is that all genetic operators and transformations can be maintained\nwithin the unitary hypercube, regardless of the problem being addressed. This\nenhances the productivity and maintainability of the core framework. The\nalgorithm starts with a population of P vectors of random keys. At each\niteration, the vectors are partitioned into two sets: a smaller set of\nhigh-valued elite solutions and the remaining non-elite solutions. All elite\nelements are copied, without change, to the next population. A small number of\nrandom-key vectors (the mutants) is added to the population of the next\niteration. The remaining elements of the population of the next iteration are\ngenerated by combining, with the parametrized uniform crossover of Spears and\nDeJong (1991), pairs of solutions. This chapter reviews random-key genetic\nalgorithms and describes an effective variant called biased random-key genetic\nalgorithms.", "AI": {"tldr": "A random-key genetic algorithm encodes solutions as vectors of random keys in [0,1), using a decoder to map them to problem solutions. It maintains genetic operations within the unitary hypercube, enhancing framework productivity. The algorithm evolves populations by partitioning elite and non-elite solutions, copying elites, adding mutants, and using crossover for the rest. A variant, biased random-key genetic algorithms, is also discussed.", "motivation": "The motivation is to provide a flexible and maintainable evolutionary metaheuristic for discrete and global optimization by encoding solutions as random keys, simplifying genetic operations.", "method": "Solutions are encoded as random-key vectors in [0,1). A decoder maps these to problem solutions. The algorithm partitions populations into elite and non-elite solutions, copies elites, adds mutants, and uses parametrized uniform crossover for the rest.", "result": "The approach maintains genetic operations within the unitary hypercube, enhancing productivity and maintainability. The algorithm effectively evolves solutions through elite preservation, mutation, and crossover.", "conclusion": "Random-key genetic algorithms offer a robust framework for optimization. The biased variant further improves effectiveness, making the method versatile for various problems."}}
{"id": "2506.01016", "pdf": "https://arxiv.org/pdf/2506.01016", "abs": "https://arxiv.org/abs/2506.01016", "authors": ["Olya Mastikhina", "Dhruv Sreenivas", "Pablo Samuel Castro"], "title": "Optimistic critics can empower small actors", "categories": ["cs.LG", "stat.ML"], "comment": "RLC 2025", "summary": "Actor-critic methods have been central to many of the recent advances in deep\nreinforcement learning. The most common approach is to use symmetric\narchitectures, whereby both actor and critic have the same network topology and\nnumber of parameters. However, recent works have argued for the advantages of\nasymmetric setups, specifically with the use of smaller actors. We perform\nbroad empirical investigations and analyses to better understand the\nimplications of this and find that, in general, smaller actors result in\nperformance degradation and overfit critics. Our analyses suggest poor data\ncollection, due to value underestimation, as one of the main causes for this\nbehavior, and further highlight the crucial role the critic can play in\nalleviating this pathology. We explore techniques to mitigate the observed\nvalue underestimation, which enables further research in asymmetric\nactor-critic methods.", "AI": {"tldr": "Smaller actors in asymmetric actor-critic methods degrade performance and cause critic overfitting, primarily due to value underestimation. Mitigating this issue can aid further research.", "motivation": "To understand the implications of asymmetric actor-critic setups, particularly with smaller actors, and identify causes of performance degradation.", "method": "Broad empirical investigations and analyses of asymmetric actor-critic architectures, focusing on smaller actors and their impact.", "result": "Smaller actors lead to performance degradation and critic overfitting, driven by value underestimation and poor data collection.", "conclusion": "Addressing value underestimation can mitigate these issues, enabling progress in asymmetric actor-critic research."}}
{"id": "2506.02308", "pdf": "https://arxiv.org/pdf/2506.02308", "abs": "https://arxiv.org/abs/2506.02308", "authors": ["Xiaojun Shan", "Qi Cao", "Xing Han", "Haofei Yu", "Paul Pu Liang"], "title": "MINT: Multimodal Instruction Tuning with Multimodal Interaction Grouping", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Recent advances in multimodal foundation models have achieved\nstate-of-the-art performance across a range of tasks. These breakthroughs are\nlargely driven by new pre-training paradigms that leverage large-scale,\nunlabeled multimodal data, followed by instruction fine-tuning on curated\nlabeled datasets and high-quality prompts. While there is growing interest in\nscaling instruction fine-tuning to ever-larger datasets in both quantity and\nscale, our findings reveal that simply increasing the number of\ninstruction-tuning tasks does not consistently yield better performance.\nInstead, we observe that grouping tasks by the common interactions across\nmodalities, such as discovering redundant shared information, prioritizing\nmodality selection with unique information, or requiring synergistic fusion to\ndiscover new information from both modalities, encourages the models to learn\ntransferrable skills within a group while suppressing interference from\nmismatched tasks. To this end, we introduce MINT, a simple yet surprisingly\neffective task-grouping strategy based on the type of multimodal interaction.\nWe demonstrate that the proposed method greatly outperforms existing task\ngrouping baselines for multimodal instruction tuning, striking an effective\nbalance between generalization and specialization.", "AI": {"tldr": "Scaling instruction fine-tuning with larger datasets doesn't always improve performance. Grouping tasks by multimodal interactions (e.g., shared or unique information) is more effective, leading to the introduction of MINT, a task-grouping strategy that outperforms baselines.", "motivation": "To address the inefficiency of simply increasing instruction-tuning tasks and improve multimodal model performance by focusing on task interactions.", "method": "Introduces MINT, a task-grouping strategy based on multimodal interaction types (e.g., shared information, modality selection, synergistic fusion).", "result": "MINT outperforms existing baselines, balancing generalization and specialization in multimodal instruction tuning.", "conclusion": "Task grouping by multimodal interactions is more effective than scaling task quantity, with MINT demonstrating superior performance."}}
{"id": "2506.02965", "pdf": "https://arxiv.org/pdf/2506.02965", "abs": "https://arxiv.org/abs/2506.02965", "authors": ["Ze Yu Zhang", "Bolin Ding", "Bryan Kian Hsiang Low"], "title": "PC-MoE: Memory-Efficient and Privacy-Preserving Collaborative Training for Mixture-of-Experts LLMs", "categories": ["cs.LG"], "comment": "20 pages, 4 figures", "summary": "Mixture-of-Experts (MoE) has been gaining popularity due to its successful\nadaptation to large language models (LLMs). In this work, we introduce\nPrivacy-preserving Collaborative Mixture-of-Experts (PC-MoE), which leverages\nthe sparsity of the MoE architecture for memory-efficient decentralized\ncollaborative LLM training, enabling multiple parties with limited GPU-memory\nand data resources to collectively train more capable LLMs than they could\nachieve individually. At the same time, this approach protects training data\nprivacy of each participant by keeping training data, as well as parts of the\nforward pass signal and gradients locally within each party. By design, PC-MoE\nsynergistically combines the strengths of distributed computation with strong\nconfidentiality assurances. Unlike most privacy-preserving schemes, which pay\nfor confidentiality with lower task accuracy, our framework breaks that\ntrade-off: across seven popular LLM benchmarks, it almost matches (and\nsometimes exceeds) the performance and convergence rate of a fully centralized\nmodel, enjoys near 70% peak GPU RAM reduction, while being fully robust against\nreconstruction attacks.", "AI": {"tldr": "PC-MoE enables decentralized, privacy-preserving collaborative training of LLMs with reduced GPU memory usage, matching centralized model performance.", "motivation": "To allow multiple parties with limited resources to collaboratively train LLMs while preserving data privacy.", "method": "Leverages MoE sparsity for memory-efficient decentralized training, keeping data and gradients local.", "result": "Matches centralized model performance, reduces GPU RAM by 70%, and resists reconstruction attacks.", "conclusion": "PC-MoE breaks the privacy-accuracy trade-off, offering efficient, secure collaborative LLM training."}}
{"id": "2506.02606", "pdf": "https://arxiv.org/pdf/2506.02606", "abs": "https://arxiv.org/abs/2506.02606", "authors": ["Baoyang Chen", "Xian Xu", "Huamin Qu"], "title": "Multi Layered Autonomy and AI Ecologies in Robotic Art Installations", "categories": ["cs.RO", "cs.AI"], "comment": null, "summary": "Symbiosis of Agents is a large-scale installation by Baoyang Chen\n(baoyangchen.com) that embeds AI-driven robots in an immersive, mirror-lined\narena, probing the tension between machine agency and artistic authorship.\nDrawing on early cybernetics, rule-based conceptual art, and seminal robotic\nworks, it orchestrates fluid exchanges among robotic arms, quadruped machines,\ntheir environment, and the public. A three tier faith system pilots the\necology: micro-level adaptive tactics, meso-level narrative drives, and a\nmacro-level prime directive. This hierarchy lets behaviors evolve organically\nin response to environmental cues and even a viewer's breath, turning\nspectators into co-authors of the unfolding drama. Framed by a speculative\nterraforming scenario that recalls the historical exploitation of marginalized\nlabor, the piece asks who bears responsibility in AI-mediated futures.\nChoreographed motion, AI-generated scripts, reactive lighting, and drifting fog\ncast the robots as collaborators rather than tools, forging a living, emergent\nartwork. Exhibited internationally, Symbiosis of Agents shows how cybernetic\nfeedback, robotic experimentation, and conceptual rule-making can converge to\nredefine agency, authorship, and ethics in contemporary art.", "AI": {"tldr": "A large-scale installation exploring AI-driven robots in an immersive setting, blending cybernetics, robotics, and art to question agency and authorship.", "motivation": "To probe the tension between machine agency and artistic authorship, and explore ethical responsibility in AI-mediated futures.", "method": "Uses a three-tier system (micro, meso, macro) to guide robotic interactions with the environment and viewers, creating emergent, collaborative art.", "result": "Robots act as collaborators, transforming spectators into co-authors, and showcasing the convergence of cybernetics, robotics, and conceptual art.", "conclusion": "The work redefines agency, authorship, and ethics in art, demonstrating the potential of AI and robotics in creative collaboration."}}
{"id": "2204.08031", "pdf": "https://arxiv.org/pdf/2204.08031", "abs": "https://arxiv.org/abs/2204.08031", "authors": ["Zhexiao Lin", "Fang Han"], "title": "Limit theorems of Chatterjee's rank correlation", "categories": ["math.ST", "cs.LG", "math.PR", "stat.TH"], "comment": "Multiple minor improvements were made in this version, including (1)\n  a proof of the existence of the limiting variance, (2) some numeric studies,\n  and (3) an analysis of the Sobol' indices", "summary": "Establishing the limiting distribution of Chatterjee's rank correlation for a\ngeneral, possibly non-independent, pair of random variables has been eagerly\nawaited by many. This paper shows that (a) Chatterjee's rank correlation is\nasymptotically normal as long as one variable is not a measurable function of\nthe other, (b) the corresponding asymptotic variance is uniformly bounded by\n36, and (c) a consistent variance estimator exists. Similar results also hold\nfor Azadkia-Chatterjee's graph-based correlation coefficient, a multivariate\nanalogue of Chatterjee's original proposal. The proof is given by appealing to\nH\\'ajek representation and Chatterjee's nearest-neighbor CLT.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2205.11486", "pdf": "https://arxiv.org/pdf/2205.11486", "abs": "https://arxiv.org/abs/2205.11486", "authors": ["Nathan Kallus", "Miruna Oprescu"], "title": "Robust and Agnostic Learning of Conditional Distributional Treatment Effects", "categories": ["stat.ML", "cs.LG", "econ.EM", "stat.ME"], "comment": "24 pages, 6 figures, AISTATS 2023", "summary": "The conditional average treatment effect (CATE) is the best measure of\nindividual causal effects given baseline covariates. However, the CATE only\ncaptures the (conditional) average, and can overlook risks and tail events,\nwhich are important to treatment choice. In aggregate analyses, this is usually\naddressed by measuring the distributional treatment effect (DTE), such as\ndifferences in quantiles or tail expectations between treatment groups.\nHypothetically, one can similarly fit conditional quantile regressions in each\ntreatment group and take their difference, but this would not be robust to\nmisspecification or provide agnostic best-in-class predictions. We provide a\nnew robust and model-agnostic methodology for learning the conditional DTE\n(CDTE) for a class of problems that includes conditional quantile treatment\neffects, conditional super-quantile treatment effects, and conditional\ntreatment effects on coherent risk measures given by $f$-divergences. Our\nmethod is based on constructing a special pseudo-outcome and regressing it on\ncovariates using any regression learner. Our method is model-agnostic in that\nit can provide the best projection of CDTE onto the regression model class. Our\nmethod is robust in that even if we learn these nuisances nonparametrically at\nvery slow rates, we can still learn CDTEs at rates that depend on the class\ncomplexity and even conduct inferences on linear projections of CDTEs. We\ninvestigate the behavior of our proposal in simulations, as well as in a case\nstudy of 401(k) eligibility effects on wealth.", "AI": {"tldr": "A robust, model-agnostic method for learning conditional distributional treatment effects (CDTE) is proposed, addressing limitations of CATE by focusing on risks and tail events.", "motivation": "CATE overlooks risks and tail events, which are crucial for treatment decisions. Existing methods lack robustness and model-agnosticism.", "method": "Constructs a pseudo-outcome and regresses it on covariates using any regression learner, ensuring robustness and model-agnosticism.", "result": "The method provides best-in-class CDTE predictions, works with slow nuisance learning rates, and allows inference on linear projections.", "conclusion": "The proposed approach effectively learns CDTEs, validated through simulations and a 401(k) case study."}}
{"id": "2305.18270", "pdf": "https://arxiv.org/pdf/2305.18270", "abs": "https://arxiv.org/abs/2305.18270", "authors": ["Yatin Dandi", "Florent Krzakala", "Bruno Loureiro", "Luca Pesce", "Ludovic Stephan"], "title": "How Two-Layer Neural Networks Learn, One (Giant) Step at a Time", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "For high-dimensional Gaussian data, we investigate theoretically how the\nfeatures of a two-layer neural network adapt to the structure of the target\nfunction through a few large batch gradient descent steps, leading to an\nimprovement in the approximation capacity from initialization. First, we\ncompare the influence of batch size to that of multiple steps. For a single\nstep, a batch of size $n = \\mathcal{O}(d)$ is both necessary and sufficient to\nalign with the target function, although only a single direction can be\nlearned. In contrast, $n = \\mathcal{O}(d^2)$ is essential for neurons to\nspecialize in multiple relevant directions of the target with a single gradient\nstep. Even in this case, we show there might exist ``hard'' directions\nrequiring $n = \\mathcal{O}(d^\\ell)$ samples to be learned, where $\\ell$ is\nknown as the leap index of the target. Second, we show that the picture\ndrastically improves over multiple gradient steps: a batch size of $n =\n\\mathcal{O}(d)$ is indeed sufficient to learn multiple target directions\nsatisfying a staircase property, where more and more directions can be learned\nover time. Finally, we discuss how these directions allow for a drastic\nimprovement in the approximation capacity and generalization error over the\ninitialization, illustrating a separation of scale between the random\nfeatures/lazy regime and the feature learning regime. Our technical analysis\nleverages a combination of techniques related to concentration,\nprojection-based conditioning, and Gaussian equivalence, which we believe are\nof independent interest. By pinning down the conditions necessary for\nspecialization and learning, our results highlight the intertwined role of the\nstructure of the task to learn, the details of the algorithm, and the\narchitecture, shedding new light on how neural networks adapt to the feature\nand learn complex task from data over time.", "AI": {"tldr": "The paper explores how two-layer neural networks adapt to high-dimensional Gaussian data through gradient descent, showing how batch size and steps influence learning of target function directions and improve approximation capacity.", "motivation": "To understand how neural networks adapt to the structure of target functions in high-dimensional settings, focusing on the interplay between batch size, gradient steps, and feature learning.", "method": "Theoretical analysis using techniques like concentration, projection-based conditioning, and Gaussian equivalence to study the impact of batch size and gradient steps on learning target directions.", "result": "Single-step learning requires larger batch sizes for multiple directions, while multiple steps allow learning with smaller batches. Hard directions may need exponentially more samples. Feature learning improves approximation and generalization.", "conclusion": "The study reveals the critical role of task structure, algorithm details, and architecture in neural network adaptation, distinguishing between lazy and feature learning regimes."}}
{"id": "2402.17732", "pdf": "https://arxiv.org/pdf/2402.17732", "abs": "https://arxiv.org/abs/2402.17732", "authors": ["Rong Jiang", "Cong Ma"], "title": "Batched Nonparametric Contextual Bandits", "categories": ["math.ST", "cs.LG", "stat.ML", "stat.TH"], "comment": "Accepted to IEEE Transactions on Information Theory", "summary": "We study nonparametric contextual bandits under batch constraints, where the\nexpected reward for each action is modeled as a smooth function of covariates,\nand the policy updates are made at the end of each batch of observations. We\nestablish a minimax regret lower bound for this setting and propose a novel\nbatch learning algorithm that achieves the optimal regret (up to logarithmic\nfactors). In essence, our procedure dynamically splits the covariate space into\nsmaller bins, carefully aligning their widths with the batch size. Our\ntheoretical results suggest that for nonparametric contextual bandits, a nearly\nconstant number of policy updates can attain optimal regret in the fully online\nsetting.", "AI": {"tldr": "The paper studies nonparametric contextual bandits with batch constraints, proposing an algorithm that achieves near-optimal regret by dynamically splitting the covariate space.", "motivation": "To address the challenge of optimizing regret in nonparametric contextual bandits under batch constraints, where policy updates are limited.", "method": "A novel batch learning algorithm dynamically splits the covariate space into bins, aligning their widths with batch size.", "result": "The algorithm achieves optimal regret (up to logarithmic factors), suggesting nearly constant policy updates can suffice for optimal performance.", "conclusion": "The proposed method efficiently balances batch constraints and regret optimization in nonparametric contextual bandits."}}
{"id": "2403.03702", "pdf": "https://arxiv.org/pdf/2403.03702", "abs": "https://arxiv.org/abs/2403.03702", "authors": ["Alban Farchi", "Marcin Chrust", "Marc Bocquet", "Massimo Bonavita"], "title": "Development of an offline and online hybrid model for the Integrated Forecasting System", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "In recent years, there has been significant progress in the development of\nfully data-driven global numerical weather prediction models. These machine\nlearning weather prediction models have their strength, notably accuracy and\nlow computational requirements, but also their weakness: they struggle to\nrepresent fundamental dynamical balances, and they are far from being suitable\nfor data assimilation experiments. Hybrid modelling emerges as a promising\napproach to address these limitations. Hybrid models integrate a physics-based\ncore component with a statistical component, typically a neural network, to\nenhance prediction capabilities. In this article, we propose to develop a model\nerror correction for the operational Integrated Forecasting System (IFS) of the\nEuropean Centre for Medium-Range Weather Forecasts using a neural network. The\nneural network is initially pre-trained offline using a large dataset of\noperational analyses and analysis increments. Subsequently, the trained network\nis integrated into the IFS within the Object-Oriented Prediction System (OOPS)\nso as to be used in data assimilation and forecast experiments. It is then\nfurther trained online using a recently developed variant of weak-constraint\n4D-Var. The results show that the pre-trained neural network already provides a\nreliable model error correction, which translates into reduced forecast errors\nin many conditions and that the online training further improves the accuracy\nof the hybrid model in many conditions.", "AI": {"tldr": "Hybrid models combining physics-based and neural network components improve weather prediction accuracy and address limitations of purely data-driven models.", "motivation": "To overcome the weaknesses of fully data-driven weather prediction models, such as poor representation of dynamical balances and unsuitability for data assimilation.", "method": "Develop a neural network for model error correction in the IFS, pre-trained offline and integrated into OOPS for online training via weak-constraint 4D-Var.", "result": "Pre-trained neural network reduces forecast errors; online training further enhances hybrid model accuracy.", "conclusion": "Hybrid modeling with neural networks effectively improves weather prediction, offering a reliable and adaptable solution."}}
{"id": "2404.17589", "pdf": "https://arxiv.org/pdf/2404.17589", "abs": "https://arxiv.org/abs/2404.17589", "authors": ["Peng Liu", "Cong Xu", "Ming Zhao", "Jiawei Zhu", "Bin Wang", "Yi Ren"], "title": "An Offline Reinforcement Learning Algorithm Customized for Multi-Task Fusion in Large-Scale Recommender Systems", "categories": ["cs.IR", "cs.LG"], "comment": null, "summary": "As the last critical stage of RSs, Multi-Task Fusion (MTF) is responsible for\ncombining multiple scores outputted by Multi-Task Learning (MTL) into a final\nscore to maximize user satisfaction, which determines the ultimate\nrecommendation results. Recently, to optimize long-term user satisfaction\nwithin a recommendation session, Reinforcement Learning (RL) is used for MTF in\nthe industry. However, the offline RL algorithms used for MTF so far have the\nfollowing severe problems: 1) to avoid out-of-distribution (OOD) problem, their\nconstraints are overly strict, which seriously damage their performance; 2)\nthey are unaware of the exploration policy used for producing training data and\nnever interact with real environment, so only suboptimal policy can be learned;\n3) the traditional exploration policies are inefficient and hurt user\nexperience. To solve the above problems, we propose a novel method named\nIntegratedRL-MTF customized for MTF in large-scale RSs. IntegratedRL-MTF\nintegrates offline RL model with our online exploration policy to relax\noverstrict and complicated constraints, which significantly improves its\nperformance. We also design an extremely efficient exploration policy, which\neliminates low-value exploration space and focuses on exploring potential\nhigh-value state-action pairs. Moreover, we adopt progressive training mode to\nfurther enhance our model's performance with the help of our exploration\npolicy. We conduct extensive offline and online experiments in the short video\nchannel of Tencent News. The results demonstrate that our model outperforms\nother models remarkably. IntegratedRL-MTF has been fully deployed in our RS and\nother large-scale RSs in Tencent, which have achieved significant improvements.", "AI": {"tldr": "The paper introduces IntegratedRL-MTF, a novel method combining offline RL with an efficient online exploration policy to improve Multi-Task Fusion (MTF) in recommendation systems, addressing limitations of current offline RL approaches.", "motivation": "Current offline RL methods for MTF suffer from strict constraints, suboptimal policies due to lack of real-environment interaction, and inefficient exploration policies, harming performance and user experience.", "method": "IntegratedRL-MTF integrates offline RL with an online exploration policy, relaxes constraints, and uses a focused exploration strategy. It also employs progressive training for enhanced performance.", "result": "Extensive experiments on Tencent News' short video channel show IntegratedRL-MTF outperforms other models, with significant improvements in real-world deployment.", "conclusion": "IntegratedRL-MTF effectively addresses the limitations of offline RL for MTF, achieving superior performance and user satisfaction in large-scale recommendation systems."}}
{"id": "2407.13858", "pdf": "https://arxiv.org/pdf/2407.13858", "abs": "https://arxiv.org/abs/2407.13858", "authors": ["Mohammad Aamir Sohail", "Mohsen Heidari", "S. Sandeep Pradhan"], "title": "Quantum Natural Stochastic Pairwise Coordinate Descent", "categories": ["quant-ph", "cs.LG", "math.OC"], "comment": null, "summary": "Variational quantum algorithms, optimized using gradient-based methods, often\nexhibit sub-optimal convergence performance due to their dependence on\nEuclidean geometry. Quantum natural gradient descent (QNGD) is a more efficient\nmethod that incorporates the geometry of the state space via a quantum\ninformation metric. However, QNGD is computationally intensive and suffers from\nhigh sample complexity. In this work, we formulate a novel quantum information\nmetric and construct an unbiased estimator for this metric using single-shot\nmeasurements. We develop a quantum optimization algorithm that leverages the\ngeometry of the state space via this estimator while avoiding full-state\ntomography, as in conventional techniques. We provide the convergence analysis\nof the algorithm under mild conditions. Furthermore, we provide experimental\nresults that demonstrate the better sample complexity and faster convergence of\nour algorithm compared to the state-of-the-art approaches. Our results\nillustrate the algorithm's ability to avoid saddle points and local minima.", "AI": {"tldr": "A novel quantum optimization algorithm is introduced, using a new quantum information metric and unbiased estimator, to improve convergence and sample complexity over traditional methods.", "motivation": "Traditional gradient-based variational quantum algorithms suffer from sub-optimal convergence due to Euclidean geometry reliance, while QNGD is computationally intensive.", "method": "Develops a quantum information metric and unbiased estimator using single-shot measurements, avoiding full-state tomography.", "result": "Demonstrates better sample complexity, faster convergence, and avoidance of saddle points/local minima compared to state-of-the-art methods.", "conclusion": "The proposed algorithm efficiently leverages quantum state space geometry, outperforming existing approaches."}}
{"id": "2410.00075", "pdf": "https://arxiv.org/pdf/2410.00075", "abs": "https://arxiv.org/abs/2410.00075", "authors": ["Daan Caljon", "Jente Van Belle", "Jeroen Berrevoets", "Wouter Verbeke"], "title": "Optimizing Treatment Allocation in the Presence of Interference", "categories": ["cs.SI", "cs.LG", "stat.ML"], "comment": null, "summary": "In Influence Maximization (IM), the objective is to -- given a budget --\nselect the optimal set of entities in a network to target with a treatment so\nas to maximize the total effect. For instance, in marketing, the objective is\nto target the set of customers that maximizes the total response rate,\nresulting from both direct treatment effects on targeted customers and\nindirect, spillover, effects that follow from targeting these customers.\nRecently, new methods to estimate treatment effects in the presence of network\ninterference have been proposed. However, the issue of how to leverage these\nmodels to make better treatment allocation decisions has been largely\noverlooked. Traditionally, in Uplift Modeling (UM), entities are ranked\naccording to estimated treatment effect, and the top entities are allocated\ntreatment. Since, in a network context, entities influence each other, the UM\nranking approach will be suboptimal. The problem of finding the optimal\ntreatment allocation in a network setting is \\textcolor{red}{NP-hard,} and\ngenerally has to be solved heuristically. To fill the gap between IM and UM, we\npropose OTAPI: Optimizing Treatment Allocation in the Presence of Interference\nto find solutions to the IM problem using treatment effect estimates. OTAPI\nconsists of two steps. First, a causal estimator is trained to predict\ntreatment effects in a network setting. Second, this estimator is leveraged to\nidentify an optimal treatment allocation by integrating it into classic IM\nalgorithms. We demonstrate that this novel method outperforms classic IM and UM\napproaches on both synthetic and semi-synthetic datasets.", "AI": {"tldr": "OTAPI bridges Influence Maximization (IM) and Uplift Modeling (UM) by optimizing treatment allocation in networks, outperforming traditional methods.", "motivation": "Traditional UM ranking is suboptimal in networks due to interference; IM lacks integration with treatment effect estimates.", "method": "OTAPI combines causal estimation of treatment effects with IM algorithms for optimal allocation.", "result": "OTAPI outperforms classic IM and UM approaches on synthetic and semi-synthetic datasets.", "conclusion": "OTAPI effectively addresses the gap between IM and UM, improving treatment allocation in networked settings."}}
{"id": "2502.07975", "pdf": "https://arxiv.org/pdf/2502.07975", "abs": "https://arxiv.org/abs/2502.07975", "authors": ["Oliver Biggar", "Christos Papadimitriou"], "title": "Sink equilibria and the attractors of learning in games", "categories": ["cs.GT", "cs.LG"], "comment": null, "summary": "Characterizing the limit behavior -- that is, the attractors -- of learning\ndynamics is one of the most fundamental open questions in game theory. In\nrecent work in this front, it was conjectured that the attractors of the\nreplicator dynamic are in one-to-one correspondence with the sink equilibria of\nthe game -- the sink strongly connected components of a game's preference graph\n-- , and it was established that they do stand in at least one-to-many\ncorrespondence with them. We make threefold progress on the problem of\ncharacterizing attractors. First, we show through a topological construction\nthat the one-to-one conjecture is false. The counterexamples derive from\nobjects called local sources -- fixed points which lie within the sink\nequilibrium yet are locally repelling. Second, we make progress on the\nattractor characterization problem for two-player games by establishing that\nthe one-to-one conjecture is true when a local property called pseudoconvexity\nholds. Pseudoconvexity prevents the existence of local sources, and generalizes\nthe existing cases -- such as zero-sum games and potential games -- where the\nconjecture was known to be true.", "AI": {"tldr": "The paper disproves a conjecture about the one-to-one correspondence between attractors of replicator dynamics and sink equilibria in game theory, introduces local sources as counterexamples, and validates the conjecture for pseudoconvex two-player games.", "motivation": "To address the fundamental open question of characterizing attractors in learning dynamics and test the conjecture linking them to sink equilibria.", "method": "Topological construction to disprove the conjecture and analysis of pseudoconvexity in two-player games to validate it under specific conditions.", "result": "The one-to-one conjecture is false due to local sources, but holds for pseudoconvex two-player games, generalizing known cases.", "conclusion": "The study advances the understanding of attractors in game dynamics, disproving a conjecture while identifying conditions where it remains valid."}}
{"id": "2502.08001", "pdf": "https://arxiv.org/pdf/2502.08001", "abs": "https://arxiv.org/abs/2502.08001", "authors": ["Haonan Shi", "Tu Ouyang", "An Wang"], "title": "Unveiling Client Privacy Leakage from Public Dataset Usage in Federated Distillation", "categories": ["cs.CR", "cs.LG"], "comment": "To appear in Proceedings of Privacy Enhancing Technologies 2025", "summary": "Federated Distillation (FD) has emerged as a popular federated training\nframework, enabling clients to collaboratively train models without sharing\nprivate data. Public Dataset-Assisted Federated Distillation (PDA-FD), which\nleverages public datasets for knowledge sharing, has become widely adopted.\nAlthough PDA-FD enhances privacy compared to traditional Federated Learning, we\ndemonstrate that the use of public datasets still poses significant privacy\nrisks to clients' private training data. This paper presents the first\ncomprehensive privacy analysis of PDA-FD in presence of an honest-but-curious\nserver. We show that the server can exploit clients' inference results on\npublic datasets to extract two critical types of private information: label\ndistributions and membership information of the private training dataset. To\nquantify these vulnerabilities, we introduce two novel attacks specifically\ndesigned for the PDA-FD setting: a label distribution inference attack and\ninnovative membership inference methods based on Likelihood Ratio Attack\n(LiRA). Through extensive evaluation of three representative PDA-FD frameworks\n(FedMD, DS-FL, and Cronus), our attacks achieve state-of-the-art performance,\nwith label distribution attacks reaching minimal KL-divergence and membership\ninference attacks maintaining high True Positive Rates under low False Positive\nRate constraints. Our findings reveal significant privacy risks in current\nPDA-FD frameworks and emphasize the need for more robust privacy protection\nmechanisms in collaborative learning systems.", "AI": {"tldr": "This paper analyzes privacy risks in Public Dataset-Assisted Federated Distillation (PDA-FD), showing how an honest-but-curious server can exploit inference results to extract private data details like label distributions and membership information.", "motivation": "To highlight the privacy vulnerabilities in PDA-FD frameworks despite their use of public datasets for knowledge sharing.", "method": "Introduces two novel attacks: label distribution inference and membership inference (based on Likelihood Ratio Attack). Evaluates these on three PDA-FD frameworks (FedMD, DS-FL, Cronus).", "result": "The attacks achieve state-of-the-art performance, exposing significant privacy risks in PDA-FD.", "conclusion": "Current PDA-FD frameworks lack robust privacy protections, necessitating stronger mechanisms for collaborative learning."}}
{"id": "2502.12089", "pdf": "https://arxiv.org/pdf/2502.12089", "abs": "https://arxiv.org/abs/2502.12089", "authors": ["Alessandro Favero", "Antonio Sclocchi", "Francesco Cagnetta", "Pascal Frossard", "Matthieu Wyart"], "title": "How Compositional Generalization and Creativity Improve as Diffusion Models are Trained", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "Natural data is often organized as a hierarchical composition of features.\nHow many samples do generative models need in order to learn the composition\nrules, so as to produce a combinatorially large number of novel data? What\nsignal in the data is exploited to learn those rules? We investigate these\nquestions in the context of diffusion models both theoretically and\nempirically. Theoretically, we consider a simple probabilistic context-free\ngrammar - a tree-like graphical model used to represent the hierarchical and\ncompositional structure of data such as language and images. We demonstrate\nthat diffusion models learn the grammar's composition rules with the sample\ncomplexity required for clustering features with statistically similar context,\na process similar to the word2vec algorithm. However, this clustering emerges\nhierarchically: higher-level features associated with longer contexts require\nmore data to be identified. This mechanism leads to a sample complexity that\nscales polynomially with the said context size. As a result, diffusion models\ntrained on an intermediate dataset size generate data coherent up to a certain\nscale, but lacking global coherence. We test these predictions across different\ndomains and find remarkable agreement: both generated texts and images achieve\nprogressively larger coherence lengths as the training time or dataset size\ngrows. We discuss connections between the hierarchical clustering mechanism we\nintroduce here and the renormalization group in physics.", "AI": {"tldr": "Diffusion models learn hierarchical composition rules from data, with sample complexity scaling polynomially with context size, leading to coherent but locally limited outputs.", "motivation": "To understand how generative models learn hierarchical composition rules and the data requirements for producing novel, coherent outputs.", "method": "Theoretical analysis using a probabilistic context-free grammar and empirical testing with diffusion models across domains.", "result": "Diffusion models hierarchically cluster features, with higher-level features requiring more data. Generated outputs show progressive coherence with increased training.", "conclusion": "The study links hierarchical clustering in diffusion models to renormalization group theory, highlighting data-driven coherence scaling."}}
{"id": "2502.18284", "pdf": "https://arxiv.org/pdf/2502.18284", "abs": "https://arxiv.org/abs/2502.18284", "authors": ["Zonghao Chen", "Masha Naslidnyk", "Fran\u00e7ois-Xavier Briol"], "title": "Nested Expectations with Kernel Quadrature", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "This paper considers the challenging computational task of estimating nested\nexpectations. Existing algorithms, such as nested Monte Carlo or multilevel\nMonte Carlo, are known to be consistent but require a large number of samples\nat both inner and outer levels to converge. Instead, we propose a novel\nestimator consisting of nested kernel quadrature estimators and we prove that\nit has a faster convergence rate than all baseline methods when the integrands\nhave sufficient smoothness. We then demonstrate empirically that our proposed\nmethod does indeed require fewer samples to estimate nested expectations on\nreal-world applications including Bayesian optimisation, option pricing, and\nhealth economics.", "AI": {"tldr": "Proposes a nested kernel quadrature estimator for faster convergence in estimating nested expectations, outperforming existing methods like nested Monte Carlo.", "motivation": "Existing methods (e.g., nested Monte Carlo) require many samples for convergence, motivating a more efficient estimator.", "method": "Introduces nested kernel quadrature estimators, leveraging integrand smoothness for faster convergence.", "result": "Proven faster convergence rate; empirical validation shows fewer samples needed in real-world applications.", "conclusion": "The proposed method is efficient and practical for nested expectation estimation."}}
{"id": "2503.02407", "pdf": "https://arxiv.org/pdf/2503.02407", "abs": "https://arxiv.org/abs/2503.02407", "authors": ["Nikita Kazeev", "Wei Nong", "Ignat Romanov", "Ruiming Zhu", "Andrey Ustyuzhanin", "Shuya Yamazaki", "Kedar Hippalgaonkar"], "title": "Wyckoff Transformer: Generation of Symmetric Crystals", "categories": ["cond-mat.mtrl-sci", "cs.LG", "physics.comp-ph", "I.2.6"], "comment": "https://github.com/SymmetryAdvantage/WyckoffTransformer", "summary": "Crystal symmetry plays a fundamental role in determining its physical,\nchemical, and electronic properties such as electrical and thermal\nconductivity, optical and polarization behavior, and mechanical strength.\nAlmost all known crystalline materials have internal symmetry. However, this is\noften inadequately addressed by existing generative models, making the\nconsistent generation of stable and symmetrically valid crystal structures a\nsignificant challenge. We introduce WyFormer, a generative model that directly\ntackles this by formally conditioning on space group symmetry. It achieves this\nby using Wyckoff positions as the basis for an elegant, compressed, and\ndiscrete structure representation. To model the distribution, we develop a\npermutation-invariant autoregressive model based on the Transformer encoder and\nan absence of positional encoding. Extensive experimentation demonstrates\nWyFormer's compelling combination of attributes: it achieves best-in-class\nsymmetry-conditioned generation, incorporates a physics-motivated inductive\nbias, produces structures with competitive stability, predicts material\nproperties with competitive accuracy even without atomic coordinates, and\nexhibits unparalleled inference speed.", "AI": {"tldr": "WyFormer is a generative model for crystal structures that ensures symmetry validity by using Wyckoff positions, outperforming existing methods in symmetry-conditioned generation, stability, and speed.", "motivation": "Existing generative models often fail to adequately address crystal symmetry, leading to challenges in generating stable and symmetrically valid structures.", "method": "WyFormer uses Wyckoff positions for a compressed structure representation and employs a permutation-invariant autoregressive Transformer encoder without positional encoding.", "result": "WyFormer achieves best-in-class symmetry-conditioned generation, competitive stability, accurate property prediction without atomic coordinates, and fast inference.", "conclusion": "WyFormer effectively addresses the symmetry challenge in crystal structure generation, offering superior performance and practical advantages."}}
{"id": "2503.04091", "pdf": "https://arxiv.org/pdf/2503.04091", "abs": "https://arxiv.org/abs/2503.04091", "authors": ["Ziqiao Wang", "Cheng Long", "Yongyi Mao"], "title": "Generalization in Federated Learning: A Conditional Mutual Information Framework", "categories": ["stat.ML", "cs.IT", "cs.LG", "math.IT"], "comment": "Accepted to ICML 2025", "summary": "Federated learning (FL) is a widely adopted privacy-preserving distributed\nlearning framework, yet its generalization performance remains less explored\ncompared to centralized learning. In FL, the generalization error consists of\ntwo components: the out-of-sample gap, which measures the gap between the\nempirical and true risk for participating clients, and the participation gap,\nwhich quantifies the risk difference between participating and\nnon-participating clients. In this work, we apply an information-theoretic\nanalysis via the conditional mutual information (CMI) framework to study FL's\ntwo-level generalization. Beyond the traditional supersample-based CMI\nframework, we introduce a superclient construction to accommodate the two-level\ngeneralization setting in FL. We derive multiple CMI-based bounds, including\nhypothesis-based CMI bounds, illustrating how privacy constraints in FL can\nimply generalization guarantees. Furthermore, we propose fast-rate evaluated\nCMI bounds that recover the best-known convergence rate for two-level FL\ngeneralization in the small empirical risk regime. For specific FL model\naggregation strategies and structured loss functions, we refine our bounds to\nachieve improved convergence rates with respect to the number of participating\nclients. Empirical evaluations confirm that our evaluated CMI bounds are\nnon-vacuous and accurately capture the generalization behavior of FL\nalgorithms.", "AI": {"tldr": "The paper analyzes federated learning's generalization performance using an information-theoretic approach, introducing a superclient construction and deriving CMI-based bounds to study two-level generalization errors.", "motivation": "To explore the generalization performance of federated learning, which remains less understood compared to centralized learning, focusing on the out-of-sample and participation gaps.", "method": "Applies an information-theoretic analysis via the conditional mutual information (CMI) framework, introducing a superclient construction for FL's two-level generalization. Derives hypothesis-based and fast-rate evaluated CMI bounds.", "result": "Proposes CMI-based bounds that recover the best-known convergence rate for FL generalization and refines them for specific FL strategies, achieving improved convergence rates. Empirical evaluations confirm non-vacuous bounds.", "conclusion": "The CMI framework effectively captures FL's generalization behavior, providing theoretical guarantees and improved convergence rates, validated empirically."}}
{"id": "2503.09492", "pdf": "https://arxiv.org/pdf/2503.09492", "abs": "https://arxiv.org/abs/2503.09492", "authors": ["Yunli Wang", "Zhen Zhang", "Zhiqiang Wang", "Zixuan Yang", "Yu Li", "Jian Yang", "Shiyang Wen", "Peng Jiang", "Kun Gai"], "title": "Learning Cascade Ranking as One Network", "categories": ["cs.IR", "cs.LG"], "comment": "Accepted by ICML 2025", "summary": "Cascade Ranking is a prevalent architecture in large-scale top-k selection\nsystems like recommendation and advertising platforms. Traditional training\nmethods focus on single-stage optimization, neglecting interactions between\nstages. Recent advances have introduced interaction-aware training paradigms,\nbut still struggle to 1) align training objectives with the goal of the entire\ncascade ranking (i.e., end-to-end recall of ground-truth items) and 2) learn\neffective collaboration patterns for different stages. To address these\nchallenges, we propose LCRON, which introduces a novel surrogate loss function\nderived from the lower bound probability that ground truth items are selected\nby cascade ranking, ensuring alignment with the overall objective of the\nsystem. According to the properties of the derived bound, we further design an\nauxiliary loss for each stage to drive the reduction of this bound, leading to\na more robust and effective top-k selection. LCRON enables end-to-end training\nof the entire cascade ranking system as a unified network. Experimental results\ndemonstrate that LCRON achieves significant improvement over existing methods\non public benchmarks and industrial applications, addressing key limitations in\ncascade ranking training and significantly enhancing system performance.", "AI": {"tldr": "LCRON introduces a surrogate loss function for cascade ranking systems, aligning training with end-to-end recall goals and improving stage collaboration, outperforming existing methods.", "motivation": "Traditional cascade ranking training neglects stage interactions and misaligns with end-to-end recall objectives. LCRON addresses these gaps.", "method": "LCRON uses a novel surrogate loss derived from the lower bound probability of ground-truth item selection, with auxiliary losses for each stage.", "result": "LCRON outperforms existing methods on benchmarks and industrial applications, enhancing system performance.", "conclusion": "LCRON effectively aligns training with cascade ranking goals, improving robustness and effectiveness in top-k selection."}}
{"id": "2504.09567", "pdf": "https://arxiv.org/pdf/2504.09567", "abs": "https://arxiv.org/abs/2504.09567", "authors": ["Chenxuan He", "Yuan Gao", "Liping Zhu", "Jian Huang"], "title": "Conditional Independence Test Based on Transport Maps", "categories": ["stat.ML", "cs.LG", "stat.ME", "62G05, 62G08, 68T07"], "comment": "48 pages", "summary": "Testing conditional independence between two random vectors given a third is\na fundamental and challenging problem in statistics, particularly in\nmultivariate nonparametric settings due to the complexity of conditional\nstructures. We propose a innovative framework for testing conditional\nindependence using transport maps. At the population level, we show that two\nwell-defined transport maps can transform the conditional independence test\ninto an unconditional independence test, this substantially simplifies the\nproblem. These transport maps are estimated from data using conditional\ncontinuous normalizing flow models. Within this framework, we derive a test\nstatistic and prove its asymptotic validity under both the null and alternative\nhypotheses. A permutation-based procedure is employed to evaluate the\nsignificance of the test. We validate the proposed method through extensive\nsimulations and real-data analysis. Our numerical studies demonstrate the\npractical effectiveness of the proposed method for conditional independence\ntesting.", "AI": {"tldr": "A novel framework for testing conditional independence using transport maps simplifies the problem by transforming it into an unconditional test, validated through simulations and real-data analysis.", "motivation": "Conditional independence testing is complex in multivariate nonparametric settings, necessitating innovative solutions.", "method": "Uses transport maps estimated via conditional continuous normalizing flow models to transform the problem, with a permutation-based test for significance.", "result": "The proposed method is asymptotically valid and practically effective, as shown in simulations and real-data studies.", "conclusion": "The framework offers a simplified and effective approach for conditional independence testing."}}
{"id": "2504.17959", "pdf": "https://arxiv.org/pdf/2504.17959", "abs": "https://arxiv.org/abs/2504.17959", "authors": ["Yinlong Dai", "Robert Ramirez Sanchez", "Ryan Jeronimus", "Shahabedin Sagheb", "Cara M. Nunez", "Heramb Nemlekar", "Dylan P. Losey"], "title": "CIVIL: Causal and Intuitive Visual Imitation Learning", "categories": ["cs.RO", "cs.LG", "cs.SY", "eess.SY"], "comment": null, "summary": "Today's robots learn new tasks by imitating human examples. However, this\nstandard approach to visual imitation learning is fundamentally limited: the\nrobot observes what the human does, but not why the human chooses those\nbehaviors. Without understanding the features that factor into the human's\ndecisions, robot learners often misinterpret the data and fail to perform the\ntask when the environment changes. We therefore propose a shift in perspective:\ninstead of asking human teachers just to show what actions the robot should\ntake, we also enable humans to indicate task-relevant features using markers\nand language prompts. Our proposed algorithm, CIVIL, leverages this augmented\ndata to filter the robot's visual observations and extract a feature\nrepresentation that causally informs human actions. CIVIL then applies these\ncausal features to train a transformer-based policy that emulates human\nbehaviors without being confused by visual distractors. Our simulations,\nreal-world experiments, and user study demonstrate that robots trained with\nCIVIL can learn from fewer human demonstrations and perform better than\nstate-of-the-art baselines, especially in previously unseen scenarios. See\nvideos at our project website: https://civil2025.github.io", "AI": {"tldr": "The paper proposes CIVIL, an algorithm that improves robot learning by incorporating human explanations of task-relevant features, outperforming traditional imitation learning methods.", "motivation": "Standard visual imitation learning lacks understanding of human decision-making, leading to poor performance in changing environments.", "method": "CIVIL uses human-provided markers and language prompts to filter visual observations and extract causal features, training a transformer-based policy.", "result": "CIVIL-trained robots learn faster and perform better, especially in unseen scenarios, compared to state-of-the-art baselines.", "conclusion": "Incorporating human explanations into robot learning enhances adaptability and performance, addressing limitations of traditional imitation learning."}}
{"id": "2504.18791", "pdf": "https://arxiv.org/pdf/2504.18791", "abs": "https://arxiv.org/abs/2504.18791", "authors": ["Uday Kiran Reddy Tadipatri", "Benjamin D. Haeffele", "Joshua Agterberg", "Ingvar Ziemann", "Ren\u00e9 Vidal"], "title": "Nonconvex Linear System Identification with Minimal State Representation", "categories": ["eess.SY", "cs.LG", "cs.SY", "eess.SP", "stat.ML"], "comment": "Accepted to the 7th Annual Conference on Learning for Dynamics and\n  Control (L4DC) 2025. The full version including appendix", "summary": "Low-order linear System IDentification (SysID) addresses the challenge of\nestimating the parameters of a linear dynamical system from finite samples of\nobservations and control inputs with minimal state representation. Traditional\napproaches often utilize Hankel-rank minimization, which relies on convex\nrelaxations that can require numerous, costly singular value decompositions\n(SVDs) to optimize. In this work, we propose two nonconvex reformulations to\ntackle low-order SysID (i) Burer-Monterio (BM) factorization of the Hankel\nmatrix for efficient nuclear norm minimization, and (ii) optimizing directly\nover system parameters for real, diagonalizable systems with an atomic norm\nstyle decomposition. These reformulations circumvent the need for repeated\nheavy SVD computations, significantly improving computational efficiency.\nMoreover, we prove that optimizing directly over the system parameters yields\nlower statistical error rates, and lower sample complexities that do not scale\nlinearly with trajectory length like in Hankel-nuclear norm minimization.\nAdditionally, while our proposed formulations are nonconvex, we provide\ntheoretical guarantees of achieving global optimality in polynomial time.\nFinally, we demonstrate algorithms that solve these nonconvex programs and\nvalidate our theoretical claims on synthetic data.", "AI": {"tldr": "The paper proposes two nonconvex methods for low-order linear system identification (SysID), avoiding costly SVDs and improving efficiency and accuracy.", "motivation": "Traditional SysID methods rely on Hankel-rank minimization with expensive SVDs, which are computationally inefficient.", "method": "Two nonconvex approaches: (1) Burer-Monterio factorization for nuclear norm minimization, and (2) direct optimization over system parameters using atomic norm decomposition.", "result": "The methods reduce computational cost, lower statistical error rates, and achieve better sample complexities. Theoretical guarantees for global optimality are provided.", "conclusion": "The proposed nonconvex methods outperform traditional approaches in efficiency and accuracy, with validated results on synthetic data."}}
{"id": "2505.00237", "pdf": "https://arxiv.org/pdf/2505.00237", "abs": "https://arxiv.org/abs/2505.00237", "authors": ["Ze Zhang", "Georg Hess", "Junjie Hu", "Emmanuel Dean", "Lennart Svensson", "Knut \u00c5kesson"], "title": "Future-Oriented Navigation: Dynamic Obstacle Avoidance with One-Shot Energy-Based Multimodal Motion Prediction", "categories": ["cs.RO", "cs.LG", "cs.SY", "eess.SY"], "comment": "Published in IEEE Robotics and Automation Letters (RA-L)", "summary": "This paper proposes an integrated approach for the safe and efficient control\nof mobile robots in dynamic and uncertain environments. The approach consists\nof two key steps: one-shot multimodal motion prediction to anticipate motions\nof dynamic obstacles and model predictive control to incorporate these\npredictions into the motion planning process. Motion prediction is driven by an\nenergy-based neural network that generates high-resolution, multi-step\npredictions in a single operation. The prediction outcomes are further utilized\nto create geometric shapes formulated as mathematical constraints. Instead of\ntreating each dynamic obstacle individually, predicted obstacles are grouped by\nproximity in an unsupervised way to improve performance and efficiency. The\noverall collision-free navigation is handled by model predictive control with a\nspecific design for proactive dynamic obstacle avoidance. The proposed approach\nallows mobile robots to navigate effectively in dynamic environments. Its\nperformance is accessed across various scenarios that represent typical\nwarehouse settings. The results demonstrate that the proposed approach\noutperforms other existing dynamic obstacle avoidance methods.", "AI": {"tldr": "An integrated approach for safe and efficient mobile robot control in dynamic environments, combining multimodal motion prediction and model predictive control, outperforming existing methods.", "motivation": "To enable mobile robots to navigate safely and efficiently in dynamic and uncertain environments by anticipating obstacle motions and proactively avoiding collisions.", "method": "Uses energy-based neural networks for one-shot multimodal motion prediction and model predictive control for collision-free navigation, grouping obstacles by proximity for efficiency.", "result": "Outperforms existing dynamic obstacle avoidance methods in typical warehouse scenarios.", "conclusion": "The proposed approach effectively enhances mobile robot navigation in dynamic environments, demonstrating superior performance."}}
{"id": "2505.04627", "pdf": "https://arxiv.org/pdf/2505.04627", "abs": "https://arxiv.org/abs/2505.04627", "authors": ["Jean-Michel Tucny", "Mihir Durve", "Sauro Succi"], "title": "Is the end of Insight in Sight ?", "categories": ["physics.comp-ph", "cs.LG", "physics.data-an"], "comment": "15 pages, 2 figures", "summary": "The rise of deep learning challenges the longstanding scientific ideal of\ninsight - the human capacity to understand phenomena by uncovering underlying\nmechanisms. In many modern applications, accurate predictions no longer require\ninterpretable models, prompting debate about whether explainability is a\nrealistic or even meaningful goal. From our perspective in physics, we examine\nthis tension through a concrete case study: a physics-informed neural network\n(PINN) trained on a rarefied gas dynamics problem governed by the Boltzmann\nequation. Despite the system's clear structure and well-understood governing\nlaws, the trained network's weights resemble Gaussian-distributed random\nmatrices, with no evident trace of the physical principles involved. This\nsuggests that deep learning and traditional simulation may follow distinct\ncognitive paths to the same outcome - one grounded in mechanistic insight, the\nother in statistical interpolation. Our findings raise critical questions about\nthe limits of explainable AI and whether interpretability can - or\nshould-remain a universal standard in artificial reasoning.", "AI": {"tldr": "Deep learning challenges traditional scientific insight, as shown by a physics-informed neural network (PINN) that lacks interpretability despite solving a well-understood physics problem.", "motivation": "To explore the tension between deep learning's predictive power and the scientific ideal of mechanistic insight, using a physics case study.", "method": "A physics-informed neural network (PINN) was trained on a rarefied gas dynamics problem governed by the Boltzmann equation.", "result": "The trained network's weights resembled random matrices, showing no trace of the underlying physics, suggesting deep learning and traditional simulation follow different cognitive paths.", "conclusion": "The study questions whether interpretability should remain a universal standard in AI, given deep learning's distinct approach to problem-solving."}}
{"id": "2505.17836", "pdf": "https://arxiv.org/pdf/2505.17836", "abs": "https://arxiv.org/abs/2505.17836", "authors": ["Anna Van Elst", "Igor Colin", "Stephan Cl\u00e9men\u00e7on"], "title": "Robust Distributed Estimation: Extending Gossip Algorithms to Ranking and Trimmed Means", "categories": ["stat.ML", "cs.LG", "stat.AP"], "comment": null, "summary": "This paper addresses the problem of robust estimation in gossip algorithms\nover arbitrary communication graphs. Gossip algorithms are fully decentralized,\nrelying only on local neighbor-to-neighbor communication, making them\nwell-suited for situations where communication is constrained. A fundamental\nchallenge in existing mean-based gossip algorithms is their vulnerability to\nmalicious or corrupted nodes. In this paper, we show that an outlier-robust\nmean can be computed by globally estimating a robust statistic. More\nspecifically, we propose a novel gossip algorithm for rank estimation, referred\nto as \\textsc{GoRank}, and leverage it to design a gossip procedure dedicated\nto trimmed mean estimation, coined \\textsc{GoTrim}. In addition to a detailed\ndescription of the proposed methods, a key contribution of our work is a\nprecise convergence analysis: we establish an $\\mathcal{O}(1/t)$ rate for rank\nestimation and an $\\mathcal{O}(\\log(t)/\\sqrt{t})$ rate for trimmed mean\nestimation, where by $t$ is meant the number of iterations. Moreover, we\nprovide a breakdown point analysis of \\textsc{GoTrim}. We empirically validate\nour theoretical results through experiments on diverse network topologies, data\ndistributions and contamination schemes.", "AI": {"tldr": "The paper introduces robust gossip algorithms, GoRank and GoTrim, for outlier-resistant mean estimation in decentralized networks, with proven convergence rates and empirical validation.", "motivation": "Existing gossip algorithms are vulnerable to malicious nodes; this work aims to enhance robustness in decentralized mean estimation.", "method": "Proposes GoRank for rank estimation and GoTrim for trimmed mean estimation, with detailed convergence analysis.", "result": "Achieves O(1/t) convergence for rank estimation and O(log(t)/\u221at) for trimmed mean, validated empirically.", "conclusion": "The algorithms effectively address robustness in gossip-based mean estimation, with theoretical and empirical support."}}
{"id": "2506.01226", "pdf": "https://arxiv.org/pdf/2506.01226", "abs": "https://arxiv.org/abs/2506.01226", "authors": ["Nicholas H. Barbara", "Ruigang Wang", "Alexandre Megretski", "Ian R. Manchester"], "title": "React to Surprises: Stable-by-Design Neural Feedback Control and the Youla-REN", "categories": ["eess.SY", "cs.LG", "cs.SY"], "comment": null, "summary": "We study parameterizations of stabilizing nonlinear policies for\nlearning-based control. We propose a structure based on a nonlinear version of\nthe Youla-Kucera parameterization combined with robust neural networks such as\nthe recurrent equilibrium network (REN). The resulting parameterizations are\nunconstrained, and hence can be searched over with first-order optimization\nmethods, while always ensuring closed-loop stability by construction. We study\nthe combination of (a) nonlinear dynamics, (b) partial observation, and (c)\nincremental closed-loop stability requirements (contraction and Lipschitzness).\nWe find that with any two of these three difficulties, a contracting and\nLipschitz Youla parameter always leads to contracting and Lipschitz closed\nloops. However, if all three hold, then incremental stability can be lost with\nexogenous disturbances. Instead, a weaker condition is maintained, which we\ncall d-tube contraction and Lipschitzness. We further obtain converse results\nshowing that the proposed parameterization covers all contracting and Lipschitz\nclosed loops for certain classes of nonlinear systems. Numerical experiments\nillustrate the utility of our parameterization when learning controllers with\nbuilt-in stability certificates for: (i) \"economic\" rewards without stabilizing\neffects; (ii) short training horizons; and (iii) uncertain systems.", "AI": {"tldr": "The paper introduces a parameterization method for stabilizing nonlinear control policies using a nonlinear Youla-Kucera framework and robust neural networks, ensuring stability while allowing unconstrained optimization.", "motivation": "To address challenges in learning-based control, such as nonlinear dynamics, partial observation, and incremental stability, while ensuring closed-loop stability.", "method": "Combines nonlinear Youla-Kucera parameterization with robust neural networks (e.g., REN) for unconstrained optimization and guaranteed stability.", "result": "Shows that incremental stability is maintained with two of three challenges but weakens to d-tube contraction with all three. Converse results confirm coverage of all stable closed loops for certain systems.", "conclusion": "The proposed method effectively learns stable controllers for complex scenarios, validated by numerical experiments."}}
{"id": "2506.03074", "pdf": "https://arxiv.org/pdf/2506.03074", "abs": "https://arxiv.org/abs/2506.03074", "authors": ["Junghyun Lee", "Kyoungseok Jang", "Kwang-Sung Jun", "Milan Vojnovi\u0107", "Se-Young Yun"], "title": "GL-LowPopArt: A Nearly Instance-Wise Minimax-Optimal Estimator for Generalized Low-Rank Trace Regression", "categories": ["stat.ML", "cs.LG"], "comment": "53 pages, 2 figures, 3 tables; Accepted as a Spotlight Poster to the\n  42nd International Conference on Machine Learning (ICML 2025). Minor\n  correction to the arXiv title in v2 ;)", "summary": "We present `GL-LowPopArt`, a novel Catoni-style estimator for generalized\nlow-rank trace regression. Building on `LowPopArt` (Jang et al., 2024), it\nemploys a two-stage approach: nuclear norm regularization followed by matrix\nCatoni estimation. We establish state-of-the-art estimation error bounds,\nsurpassing existing guarantees (Fan et al., 2019; Kang et al., 2022), and\nreveal a novel experimental design objective, $\\mathrm{GL}(\\pi)$. The key\ntechnical challenge is controlling bias from the nonlinear inverse link\nfunction, which we address by our two-stage approach. We prove a *local*\nminimax lower bound, showing that our `GL-LowPopArt` enjoys instance-wise\noptimality up to the condition number of the ground-truth Hessian. Applications\ninclude generalized linear matrix completion, where `GL-LowPopArt` achieves a\nstate-of-the-art Frobenius error guarantee, and **bilinear dueling bandits**, a\nnovel setting inspired by general preference learning (Zhang et al., 2024). Our\nanalysis of a `GL-LowPopArt`-based explore-then-commit algorithm reveals a new,\npotentially interesting problem-dependent quantity, along with improved Borda\nregret bound than vectorization (Wu et al., 2024).", "AI": {"tldr": "GL-LowPopArt is a Catoni-style estimator for generalized low-rank trace regression, improving error bounds and introducing a new experimental design objective.", "motivation": "To address bias from nonlinear inverse link functions and achieve optimal estimation in generalized low-rank trace regression.", "method": "Two-stage approach: nuclear norm regularization followed by matrix Catoni estimation.", "result": "State-of-the-art estimation error bounds, instance-wise optimality, and improved Frobenius error in applications like matrix completion.", "conclusion": "GL-LowPopArt is a robust estimator with broad applications, including novel settings like bilinear dueling bandits."}}
